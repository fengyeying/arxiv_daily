<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en">
<head>
<title>Computer Science  authors/titles &quot;new&quot;</title>
<link rel="shortcut icon" href="/favicon.ico" type="image/x-icon" />
<link rel="stylesheet" type="text/css" media="screen" href="//static.arxiv.org/static/browse/0.3.2.8/css/arXiv.css?v=20220215" />
<link rel="stylesheet" type="text/css" media="screen" href="/bibex/bibex.css?20181009">
<link rel="stylesheet" type="text/css" media="screen" href="https://static.arxiv.org/static/browse/0.3.8/css/browse_search.css" />
<link rel="alternate" type="application/rss+xml" title="Computer Science " href="http://arxiv.org/rss/cs"/>
<script src="/js/mathjaxToggle.min.js" type="text/javascript"></script>


</head>
<body class="with-cu-identity">

<div id="cu-identity">
<div id="cu-logo">
<a href="https://www.cornell.edu/"><img src="//static.arxiv.org/icons/cu/cornell-reduced-white-SMALL.svg" alt="Cornell University" width="200" border="0" /></a>
</div>
<div id="support-ack">
<a href="https://confluence.cornell.edu/x/ALlRF">We gratefully acknowledge support from<br /> the Simons Foundation and member institutions.</a>
</div>
</div>
<div id="header">
<h1 class="header-breadcrumbs"><a href="/"><img src="//static.arxiv.org/images/arxiv-logo-one-color-white.svg" aria-label="logo" alt="arxiv logo" width="85" style="width:85px;margin-right:8px;"></a> <span>&gt;</span> <a href="/list/cs/recent">cs</a></h1>
<div class="search-block level-right">
<form class="level-item mini-search" method="GET" action="https://arxiv.org/search" _lpchecked="1">
<div class="field has-addons">
<div class="control">
<input class="input is-small" type="text" name="query" placeholder="Search..." aria-label="Search term or terms" data-com.agilebits.onepassword.user-edited="yes">
<p class="help"><a href="https://arxiv.org/help">Help</a> | <a href="https://arxiv.org/search/advanced">Advanced Search</a></p>
</div>
<div class="control">
<div class="select is-small">
<select name="searchtype" aria-label="Field to search">
<option value="all" selected="selected">All fields</option>
<option value="title">Title</option>
<option value="author">Author</option>
<option value="abstract">Abstract</option>
<option value="comments">Comments</option>
<option value="journal_ref">Journal reference</option>
<option value="acm_class">ACM classification</option>
<option value="msc_class">MSC classification</option>
<option value="report_num">Report number</option>
<option value="paper_id">arXiv identifier</option>
<option value="doi">DOI</option>
<option value="orcid">ORCID</option>
<option value="author_id">arXiv author ID</option>
<option value="help">Help pages</option>
<option value="full_text">Full text</option>
</select>
</div>
</div>
<button class="button is-small is-cul-darker">Search</button>
</div>
</form>
</div>
</div>
<div id="content">
<div id="dlpage">
<h1>Computer Science </h1>
<h2>New submissions</h2>
<div class="list-dateline">Submissions received from  Fri  1 Sep 23  to  Tue  5 Sep 23, announced Wed,  6 Sep 23</div>
<ul>
<li><a href="/list/cs/new?skip=0&amp;show=2000">New submissions</a></li>
<li><a href="#item742">Cross-lists</a></li>
<li><a href="#item862">Replacements</a></li>
</ul>
<small>[ total of 1342 entries:  <b>1-1342</b>  ]</small><br />
<small>[ showing up to 2000 entries per page:  <a href="/list/cs/new?skip=0&amp;show=1000">fewer</a> |  <font color="#999999">more</font> ]</small><br />
<h3>New submissions for Wed,  6 Sep 23</h3>
<dl>
<dt><a name="item1">[1]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.00625" title="Abstract">arXiv:2309.00625</a> [<a href="/pdf/2309.00625" title="Download PDF">pdf</a>, <a href="/format/2309.00625" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Identifying Secure Operating Ranges for DER Control using Bilevel  Optimization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Girigoudar%2C+K">Kshitij Girigoudar</a>, 
<a href="/search/eess?searchtype=author&query=Roald%2C+L+A">Line A. Roald</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Optimization and Control (math.OC)

</div>
<p class="mathjax">Active distribution grids are accommodating an increasing number of
controllable electric loads and distributed energy resources (DERs). A majority
of these DERs are managed by entities other than the distribution utility, such
as individual customers or third-party aggregators, who control the loads and
DERs without consideration of any distribution grid constraints. This makes it
challenging for a distribution system operator (DSO) to allow third-party
aggregators and transmission operators to fully exploit the flexibility offered
by these resources while also ensuring that distribution grid constraints such
as voltage magnitude limits are not violated. In this paper, we develop a
bilevel optimization-based framework to determine the aggregate power
flexibility that can be obtained from an unbalanced distribution grid while
ensuring that there is no disaggregation solution that leads to grid constraint
violations. The results are a set of constraints and operating rules that are
easy to communicate, and which provide the entities that procure flexibility
from DERs (e.g. transmission operators or third-party aggregators) with the
ability to freely implement their own disaggregation strategy without
intervention from the DSO. The proposed approach is tested on two unbalanced
distribution feeders and our simulation results indicate that it is possible to
determine a wide range of aggregate power flexibility, as long as a simple set
of rules for DER control activation are followed.
</p>
</div>
</dd>
<dt><a name="item2">[2]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.00628" title="Abstract">arXiv:2309.00628</a> [<a href="/pdf/2309.00628" title="Download PDF">pdf</a>, <a href="/format/2309.00628" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Algoritmos para Multiplica&#xe7;&#xe3;o Matricial
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Poloi%2C+M+S+O">M. S. O. Poloi</a>, 
<a href="/search/cs?searchtype=author&query=Quinelato%2C+T+O">T. O. Quinelato</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> in Portuguese language
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Symbolic Computation (cs.SC)</span>

</div>
<p class="mathjax">The goal of this article is to study algorithms that compute the product
between two matrixes, specifically using the ingenuous methods of Strassen and
Strassen-Winograd, which will be presented in Section 2. At present, the cited
methods are not the most optimal considering the arithmetic complexity of these
algorithms (see Table 1). However, changes to the Strassen and
Strassen-Winograd methods will be exposed which will result in a reduction in
their memory allocation and/or execution time. The algorithms in this study
were implemented using the Julia programming language, version 1.9.1, with the
aid of the packages Pluto (notebooks), Plots (graphic visualization of the
results) and BenchmarkTools (measurement of memory allocation and execution
time of the algorithms).
<br />--
<br />O objetivo deste artigo \'e estudar algoritmos que computam o produto entre
duas matrizes, mais especificamente utilizando os m\'etodos ing\^enuo, de
Strassen e de Strassen-Winograd, que ser\~ao apresentados na Se\c{c}\~ao 2.
Atualmente, os m\'etodos citados n\~ao s\~ao os mais otimizados considerando a
complexidade aritm\'etica de seus algoritmos (vide Tabela 1). No entanto,
ser\~ao expostas modifica\c{c}\~oes dos m\'etodos de Strassen e
Strassen-Winograd que conseguem reduzir sua aloca\c{c}\~ao de mem\'oria e/ou
tempo de execu\c{c}\~ao. Os algoritmos do problema em estudo foram
implementados utilizando a linguagem de programa\c{c}\~ao Julia, na vers\~ao
1.9.1, com o aux\'ilio dos pacotes Pluto (notebooks), Plots (visualiza\c{c}\~ao
gr\'afica dos resultados) e BenchmarkTools (medi\c{c}\~ao de aloca\c{c}\~ao de
mem\'oria e tempo de execu\c{c}\~ao dos algoritmos).
</p>
</div>
</dd>
<dt><a name="item3">[3]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.00637" title="Abstract">arXiv:2309.00637</a> [<a href="/pdf/2309.00637" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Finite Element Analysis and Machine Learning Guided Design of Carbon  Fiber Organosheet-based Battery Enclosures for Crashworthiness
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shaikh%2C+S+A">Shadab Anwar Shaikh</a>, 
<a href="/search/cs?searchtype=author&query=Taufique%2C+M+F+N">M.F.N. Taufique</a>, 
<a href="/search/cs?searchtype=author&query=Kranthi">Kranthi</a>, 
<a href="/search/cs?searchtype=author&query=Balusu">Balusu</a>, 
<a href="/search/cs?searchtype=author&query=Kulkarni%2C+S+S">Shank S. Kulkarni</a>, 
<a href="/search/cs?searchtype=author&query=Hale%2C+F">Forrest Hale</a>, 
<a href="/search/cs?searchtype=author&query=Oleson%2C+J">Jonathan Oleson</a>, 
<a href="/search/cs?searchtype=author&query=Devanathan%2C+R">Ram Devanathan</a>, 
<a href="/search/cs?searchtype=author&query=Soulami%2C+A">Ayoub Soulami</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">Carbon fiber composite can be a potential candidate for replacing metal-based
battery enclosures of current electric vehicles (E.V.s) owing to its better
strength-to-weight ratio and corrosion resistance. However, the strength of
carbon fiber-based structures depends on several parameters that should be
carefully chosen. In this work, we implemented high throughput finite element
analysis (FEA) based thermoforming simulation to virtually manufacture the
battery enclosure using different design and processing parameters.
Subsequently, we performed virtual crash simulations to mimic a side pole crash
to evaluate the crashworthiness of the battery enclosures. This high throughput
crash simulation dataset was utilized to build predictive models to understand
the crashworthiness of an unknown set. Our machine learning (ML) models showed
excellent performance (R2 &gt; 0.97) in predicting the crashworthiness metrics,
i.e., crush load efficiency, absorbed energy, intrusion, and maximum
deceleration during a crash. We believe that this FEA-ML work framework will be
helpful in down select process parameters for carbon fiber-based component
design and can be transferrable to other manufacturing technologies.
</p>
</div>
</dd>
<dt><a name="item4">[4]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.00639" title="Abstract">arXiv:2309.00639</a> [<a href="/pdf/2309.00639" title="Download PDF">pdf</a>, <a href="/format/2309.00639" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Misinformation Concierge: A Proof-of-Concept with Curated Twitter  Dataset on COVID-19 Vaccination
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sharma%2C+S">Shakshi Sharma</a>, 
<a href="/search/cs?searchtype=author&query=Datta%2C+A">Anwitaman Datta</a>, 
<a href="/search/cs?searchtype=author&query=Shankaran%2C+V">Vigneshwaran Shankaran</a>, 
<a href="/search/cs?searchtype=author&query=Sharma%2C+R">Rajesh Sharma</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This is a preprinted version of our CIKM paper. Please cite our CIKM paper
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Social and Information Networks (cs.SI)

</div>
<p class="mathjax">We demonstrate the Misinformation Concierge, a proof-of-concept that provides
actionable intelligence on misinformation prevalent in social media.
Specifically, it uses language processing and machine learning tools to
identify subtopics of discourse and discern non/misleading posts; presents
statistical reports for policy-makers to understand the big picture of
prevalent misinformation in a timely manner; and recommends rebuttal messages
for specific pieces of misinformation, identified from within the corpus of
data - providing means to intervene and counter misinformation promptly. The
Misinformation Concierge proof-of-concept using a curated dataset is accessible
at: https://demo-frontend-uy34.onrender.com/
</p>
</div>
</dd>
<dt><a name="item5">[5]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.00641" title="Abstract">arXiv:2309.00641</a> [<a href="/pdf/2309.00641" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Modified Lagrangian Formulation of Gear Tooth Crack Analysis using  Combined Approach of Variable Mode Decomposition (VMD) and Time Synchronous  Averaging (TSA)
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Mukherjee%2C+S">Subrata Mukherjee</a>, 
<a href="/search/eess?searchtype=author&query=Kumar%2C+V">Vikash Kumar</a>, 
<a href="/search/eess?searchtype=author&query=Sarangi%2C+S">Somnath Sarangi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 17 pages, 36 figures, 6th Joint International Conference on Multibody System Dynamics and the 10th Asian Conference on Multibody Dynamics 2022
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">This paper discusses the possible observation of an integrated gear tooth
crack analysis procedure that employs the combined approach of variable mode
decomposition (VMD) and time synchronous averaging (TSA) based on the coupled
electromechanical gearbox (CEMG) system. This paper also incorporates the
modified Lagrangian formulation to model the CEMG system by considering
Rayleigh's dissipative potential. An analytical improved time-varying mesh
stiffness (IAM-TVMS) with different levels of gear tooth crack depts is also
incorporated into the CEMG system to inspect the influence of cracks on the
system's dynamic behavior. Dynamic responses of the CEMG system with different
tooth crack levels have been used for further investigations. For the first
time, the integrated approach of variable mode decomposition (VMD) and
time-synchronous averaging (TSA) has been presented to analyze the dynamic
behaviour of CEMG systems at the different gear tooth cracks have been
experienced as non-stationary and complex vibration signals with noise. Based
on the integrated approach of VMD-TSA, two types of nonlinear features, i.e.,
Lyapunov Exponent (LE) and Correlation Dimension (CD), were calculated to
predict the level of chaotic vibration and complexity of the CEMG system at the
different levels of gear tooth cracks. Also, the LE and CD are used as chaotic
behaviour features to predict the gear tooth crack propagation level. The
results of the proposed approach show significant improvements in the gear
tooth crack analysis based on the chaotic features. Also, this is one of the
first attempts to study the CEMG system using chaotic features based on the
combined approach of VMD-TSA.
</p>
</div>
</dd>
<dt><a name="item6">[6]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.00642" title="Abstract">arXiv:2309.00642</a> [<a href="/pdf/2309.00642" title="Download PDF">pdf</a>, <a href="/format/2309.00642" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Extracting Mathematical Concepts with Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=de+Paiva%2C+V">Valeria de Paiva</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+Q">Qiyue Gao</a>, 
<a href="/search/cs?searchtype=author&query=Kovalev%2C+P">Pavel Kovalev</a>, 
<a href="/search/cs?searchtype=author&query=Moss%2C+L+S">Lawrence S. Moss</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, 4 figures, presented to the 14th MathUI Workshop 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">We extract mathematical concepts from mathematical text using generative
large language models (LLMs) like ChatGPT, contributing to the field of
automatic term extraction (ATE) and mathematical text processing, and also to
the study of LLMs themselves. Our work builds on that of others in that we aim
for automatic extraction of terms (keywords) in one mathematical field,
category theory, using as a corpus the 755 abstracts from a snapshot of the
online journal "Theory and Applications of Categories", circa 2020. Where our
study diverges from previous work is in (1) providing a more thorough analysis
of what makes mathematical term extraction a difficult problem to begin with;
(2) paying close attention to inter-annotator disagreements; (3) providing a
set of guidelines which both human and machine annotators could use to
standardize the extraction process; (4) introducing a new annotation tool to
help humans with ATE, applicable to any mathematical field and even beyond
mathematics; (5) using prompts to ChatGPT as part of the extraction process,
and proposing best practices for such prompts; and (6) raising the question of
whether ChatGPT could be used as an annotator on the same level as human
experts. Our overall findings are that the matter of mathematical ATE is an
interesting field which can benefit from participation by LLMs, but LLMs
themselves cannot at this time surpass human performance on it.
</p>
</div>
</dd>
<dt><a name="item7">[7]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.00643" title="Abstract">arXiv:2309.00643</a> [<a href="/pdf/2309.00643" title="Download PDF">pdf</a>, <a href="/format/2309.00643" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Simulation--Based Optimization approach for analyzing the ambulance  diversion phenomenon in an Emergency-Department network
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Piermarini%2C+C">Christian Piermarini</a>, 
<a href="/search/eess?searchtype=author&query=Roma%2C+M">Massimo Roma</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 22 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">Ambulance Diversion (AD) is one of the possible strategies for relieving the
worldwide phenomenon of Emergency Department (ED) overcrowding. It can be
carried out when an ED is overloaded and consists of redirecting incoming by
ambulance patients to neighboring EDs. Properly implemented, AD should result
in reducing delays of patient treatment, ensuring safety and rescue of
life-threatening patients. From an operational point of view, AD corresponds to
a resource pooling policy among EDs in a network. In this paper we propose a
novel model for studying the effectiveness of AD strategies, based on the
Simulation-Based Optimization (SBO) approach. In particular, we developed a
discrete event simulation model for reproducing the ED network operation. Then,
for each AD policy considered, we formulate and solve an optimal resources
allocation problem consisting of a bi-objective SBO problem where the target is
the minimization of the non-value added time spent by patients and the overall
cost incurred by the ED network. A set of optimal points belonging to the
Pareto frontier is obtained for each policy. To show the reliability of the
proposed approach, a real case study consisting of six large EDs in the Lazio
region of Italy is considered, analyzing the effects of adopting different AD
policies.
</p>
</div>
</dd>
<dt><a name="item8">[8]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.00649" title="Abstract">arXiv:2309.00649</a> [<a href="/pdf/2309.00649" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GPT has become financially literate: Insights from financial literacy  tests of GPT and a preliminary test of how people use it as a source of  advice
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Niszczota%2C+P">Pawe&#x142; Niszczota</a>, 
<a href="/search/cs?searchtype=author&query=Abbas%2C+S">Sami Abbas</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 43 pages, 2 figures and 2 tables in main text
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Finance Research Letters, 2023, 58, 104333
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Computers and Society (cs.CY); General Economics (econ.GN)

</div>
<p class="mathjax">We assess the ability of GPT -- a large language model -- to serve as a
financial robo-advisor for the masses, by using a financial literacy test.
Davinci and ChatGPT based on GPT-3.5 score 66% and 65% on the financial
literacy test, respectively, compared to a baseline of 33%. However, ChatGPT
based on GPT-4 achieves a near-perfect 99% score, pointing to financial
literacy becoming an emergent ability of state-of-the-art models. We use the
Judge-Advisor System and a savings dilemma to illustrate how researchers might
assess advice-utilization from large language models. We also present a number
of directions for future research.
</p>
</div>
</dd>
<dt><a name="item9">[9]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.00650" title="Abstract">arXiv:2309.00650</a> [<a href="/pdf/2309.00650" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Reducing Errors in Excel Models with Component-Based Software  Engineering
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hatmaker%2C+C">Craig Hatmaker</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 27 pages
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> EuSpRIG Proceedings 2023, ISBN: 978-1-905404-57-5
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
<p class="mathjax">Model errors are pervasive and can be catastrophic. We can reduce model
errors and time to market by applying Component-Based Software Engineering
(CBSE) concepts to Excel models. CBSE assembles solutions from pre-built,
pre-tested components rather than written from formulas. This is made possible
by the introduction of LAMBDA. LAMBDA is an Excel function that creates
functions from Excel's formulas. CBSE-compliant LAMBDA functions can be reused
in any project just like any Excel function. They also look exactly like
Excel's native functions such as SUM(). This makes it possible for even junior
modelers to leverage CBSE-compliant LAMBDAs to develop models quicker with
fewer errors.
</p>
</div>
</dd>
<dt><a name="item10">[10]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.00652" title="Abstract">arXiv:2309.00652</a> [<a href="/pdf/2309.00652" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Use of Synthetic Data to Train AI Models: Opportunities and Risks  for Sustainable Development
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Marwala%2C+T">Tshilidzi Marwala</a>, 
<a href="/search/cs?searchtype=author&query=Fournier-Tombs%2C+E">Eleonore Fournier-Tombs</a>, 
<a href="/search/cs?searchtype=author&query=Stinckwich%2C+S">Serge Stinckwich</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">In the current data driven era, synthetic data, artificially generated data
that resembles the characteristics of real world data without containing actual
personal information, is gaining prominence. This is due to its potential to
safeguard privacy, increase the availability of data for research, and reduce
bias in machine learning models. This paper investigates the policies governing
the creation, utilization, and dissemination of synthetic data. Synthetic data
can be a powerful instrument for protecting the privacy of individuals, but it
also presents challenges, such as ensuring its quality and authenticity. A well
crafted synthetic data policy must strike a balance between privacy concerns
and the utility of data, ensuring that it can be utilized effectively without
compromising ethical or legal standards. Organizations and institutions must
develop standardized guidelines and best practices in order to capitalize on
the benefits of synthetic data while addressing its inherent challenges.
</p>
</div>
</dd>
<dt><a name="item11">[11]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.00655" title="Abstract">arXiv:2309.00655</a> [<a href="/pdf/2309.00655" title="Download PDF">pdf</a>, <a href="/format/2309.00655" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> RigNet++: Efficient Repetitive Image Guided Network for Depth Completion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yan%2C+Z">Zhiqiang Yan</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xiang Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zhenyu Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jun Li</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+J">Jian Yang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 15 pages. arXiv admin note: text overlap with <a href="/abs/2107.13802">arXiv:2107.13802</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Depth completion aims to recover dense depth maps from sparse ones, where
color images are often used to facilitate this task. Recent depth methods
primarily focus on image guided learning frameworks. However, blurry guidance
in the image and unclear structure in the depth still impede their performance.
To tackle these challenges, we explore an efficient repetitive design in our
image guided network to gradually and sufficiently recover depth values.
Specifically, the efficient repetition is embodied in both the image guidance
branch and depth generation branch. In the former branch, we design a dense
repetitive hourglass network to extract discriminative image features of
complex environments, which can provide powerful contextual instruction for
depth prediction. In the latter branch, we introduce a repetitive guidance
module based on dynamic convolution, in which an efficient convolution
factorization is proposed to reduce the complexity while modeling
high-frequency structures progressively. Extensive experiments indicate that
our approach achieves superior or competitive results on KITTI, VKITTI, NYUv2,
3D60, and Matterport3D datasets.
</p>
</div>
</dd>
<dt><a name="item12">[12]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.00656" title="Abstract">arXiv:2309.00656</a> [<a href="/pdf/2309.00656" title="Download PDF">pdf</a>, <a href="/format/2309.00656" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Local and adaptive mirror descents in extensive-form games
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fiegel%2C+C">C&#xf4;me Fiegel</a>, 
<a href="/search/cs?searchtype=author&query=M%C3%A9nard%2C+P">Pierre M&#xe9;nard</a>, 
<a href="/search/cs?searchtype=author&query=Kozuno%2C+T">Tadashi Kozuno</a>, 
<a href="/search/cs?searchtype=author&query=Munos%2C+R">R&#xe9;mi Munos</a>, 
<a href="/search/cs?searchtype=author&query=Perchet%2C+V">Vianney Perchet</a>, 
<a href="/search/cs?searchtype=author&query=Valko%2C+M">Michal Valko</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>; Machine Learning (cs.LG); Machine Learning (stat.ML)

</div>
<p class="mathjax">We study how to learn $\epsilon$-optimal strategies in zero-sum imperfect
information games (IIG) with trajectory feedback. In this setting, players
update their policies sequentially based on their observations over a fixed
number of episodes, denoted by $T$. Existing procedures suffer from high
variance due to the use of importance sampling over sequences of actions
(Steinberger et al., 2020; McAleer et al., 2022). To reduce this variance, we
consider a fixed sampling approach, where players still update their policies
over time, but with observations obtained through a given fixed sampling
policy. Our approach is based on an adaptive Online Mirror Descent (OMD)
algorithm that applies OMD locally to each information set, using individually
decreasing learning rates and a regularized loss. We show that this approach
guarantees a convergence rate of $\tilde{\mathcal{O}}(T^{-1/2})$ with high
probability and has a near-optimal dependence on the game parameters when
applied with the best theoretical choices of learning rates and sampling
policies. To achieve these results, we generalize the notion of OMD
stabilization, allowing for time-varying regularization with convex increments.
</p>
</div>
</dd>
<dt><a name="item13">[13]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.00661" title="Abstract">arXiv:2309.00661</a> [<a href="/pdf/2309.00661" title="Download PDF">pdf</a>, <a href="/format/2309.00661" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Zero-Shot Video Moment Retrieval from Frozen Vision-Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Luo%2C+D">Dezhao Luo</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+J">Jiabo Huang</a>, 
<a href="/search/cs?searchtype=author&query=Gong%2C+S">Shaogang Gong</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+H">Hailin Jin</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yang Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by WACV 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Accurate video moment retrieval (VMR) requires universal visual-textual
correlations that can handle unknown vocabulary and unseen scenes. However, the
learned correlations are likely either biased when derived from a limited
amount of moment-text data which is hard to scale up because of the prohibitive
annotation cost (fully-supervised), or unreliable when only the video-text
pairwise relationships are available without fine-grained temporal annotations
(weakly-supervised). Recently, the vision-language models (VLM) demonstrate a
new transfer learning paradigm to benefit different vision tasks through the
universal visual-textual correlations derived from large-scale vision-language
pairwise web data, which has also shown benefits to VMR by fine-tuning in the
target domains. In this work, we propose a zero-shot method for adapting
generalisable visual-textual priors from arbitrary VLM to facilitate
moment-text alignment, without the need for accessing the VMR data. To this
end, we devise a conditional feature refinement module to generate
boundary-aware visual features conditioned on text queries to enable better
moment boundary understanding. Additionally, we design a bottom-up proposal
generation strategy that mitigates the impact of domain discrepancies and
breaks down complex-query retrieval tasks into individual action retrievals,
thereby maximizing the benefits of VLM. Extensive experiments conducted on
three VMR benchmark datasets demonstrate the notable performance advantages of
our zero-shot algorithm, especially in the novel-word and novel-location
out-of-distribution setups.
</p>
</div>
</dd>
<dt><a name="item14">[14]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.00663" title="Abstract">arXiv:2309.00663</a> [<a href="/pdf/2309.00663" title="Download PDF">pdf</a>, <a href="/format/2309.00663" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Polynomial-Model-Based Optimization for Blackbox Objectives
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Schreiber%2C+J">Janina Schreiber</a>, 
<a href="/search/cs?searchtype=author&query=Wicaksono%2C+D">Damar Wicaksono</a>, 
<a href="/search/cs?searchtype=author&query=Hecht%2C+M">Michael Hecht</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Numerical Analysis (math.NA)

</div>
<p class="mathjax">For a wide range of applications the structure of systems like Neural
Networks or complex simulations, is unknown and approximation is costly or even
impossible. Black-box optimization seeks to find optimal (hyper-) parameters
for these systems such that a pre-defined objective function is minimized.
Polynomial-Model-Based Optimization (PMBO) is a novel blackbox optimizer that
finds the minimum by fitting a polynomial surrogate to the objective function.
<br />Motivated by Bayesian optimization the model is iteratively updated according
to the acquisition function Expected Improvement, thus balancing the
exploitation and exploration rate and providing an uncertainty estimate of the
model. PMBO is benchmarked against other state-of-the-art algorithms for a
given set of artificial, analytical functions. PMBO competes successfully with
those algorithms and even outperforms all of them in some cases. As the results
suggest, we believe PMBO is the pivotal choice for solving blackbox
optimization tasks occurring in a wide range of disciplines.
</p>
</div>
</dd>
<dt><a name="item15">[15]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.00664" title="Abstract">arXiv:2309.00664</a> [<a href="/pdf/2309.00664" title="Download PDF">pdf</a>, <a href="/format/2309.00664" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ICDARTS: Improving the Stability and Performance of Cyclic DARTS
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Herron%2C+E">Emily Herron</a>, 
<a href="/search/cs?searchtype=author&query=Rose%2C+D">Derek Rose</a>, 
<a href="/search/cs?searchtype=author&query=Young%2C+S">Steven Young</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> NOTE: This is an expanded version of a previously published conference paper. This paper includes an expanded study of the importance of each algorithm change, an ablation study of the importance of each layer choice, a study of the effect of different layer choices, and a study of performing ICDARTS NAS on a dynamic search space
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">This work introduces improvements to the stability and generalizability of
Cyclic DARTS (CDARTS). CDARTS is a Differentiable Architecture Search
(DARTS)-based approach to neural architecture search (NAS) that uses a cyclic
feedback mechanism to train search and evaluation networks concurrently. This
training protocol aims to optimize the search process by enforcing that the
search and evaluation networks produce similar outputs. However, CDARTS
introduces a loss function for the evaluation network that is dependent on the
search network. The dissimilarity between the loss functions used by the
evaluation networks during the search and retraining phases results in a
search-phase evaluation network that is a sub-optimal proxy for the final
evaluation network that is utilized during retraining. We present ICDARTS, a
revised approach that eliminates the dependency of the evaluation network
weights upon those of the search network, along with a modified process for
discretizing the search network's \textit{zero} operations that allows these
operations to be retained in the final evaluation networks. We pair the results
of these changes with ablation studies on ICDARTS' algorithm and network
template. Finally, we explore methods for expanding the search space of ICDARTS
by expanding its operation set and exploring alternate methods for discretizing
its continuous search cells. These experiments resulted in networks with
improved generalizability and the implementation of a novel method for
incorporating a dynamic search space into ICDARTS.
</p>
</div>
</dd>
<dt><a name="item16">[16]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.00665" title="Abstract">arXiv:2309.00665</a> [<a href="/pdf/2309.00665" title="Download PDF">pdf</a>, <a href="/format/2309.00665" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fused Classification For Differential Face Morphing Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Medvedev%2C+I">Iurii Medvedev</a>, 
<a href="/search/cs?searchtype=author&query=Pimenta%2C+J">Joana Pimenta</a>, 
<a href="/search/cs?searchtype=author&query=Gon%C3%A7alves%2C+N">Nuno Gon&#xe7;alves</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 3 figures, 2 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Face morphing, a sophisticated presentation attack technique, poses
significant security risks to face recognition systems. Traditional methods
struggle to detect morphing attacks, which involve blending multiple face
images to create a synthetic image that can match different individuals. In
this paper, we focus on the differential detection of face morphing and propose
an extended approach based on fused classification method for no-reference
scenario. We introduce a public face morphing detection benchmark for the
differential scenario and utilize a specific data mining technique to enhance
the performance of our approach. Experimental results demonstrate the
effectiveness of our method in detecting morphing attacks.
</p>
</div>
</dd>
<dt><a name="item17">[17]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.00667" title="Abstract">arXiv:2309.00667</a> [<a href="/pdf/2309.00667" title="Download PDF">pdf</a>, <a href="/format/2309.00667" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Taken out of context: On measuring situational awareness in LLMs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Berglund%2C+L">Lukas Berglund</a>, 
<a href="/search/cs?searchtype=author&query=Stickland%2C+A+C">Asa Cooper Stickland</a>, 
<a href="/search/cs?searchtype=author&query=Balesni%2C+M">Mikita Balesni</a>, 
<a href="/search/cs?searchtype=author&query=Kaufmann%2C+M">Max Kaufmann</a>, 
<a href="/search/cs?searchtype=author&query=Tong%2C+M">Meg Tong</a>, 
<a href="/search/cs?searchtype=author&query=Korbak%2C+T">Tomasz Korbak</a>, 
<a href="/search/cs?searchtype=author&query=Kokotajlo%2C+D">Daniel Kokotajlo</a>, 
<a href="/search/cs?searchtype=author&query=Evans%2C+O">Owain Evans</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">We aim to better understand the emergence of `situational awareness' in large
language models (LLMs). A model is situationally aware if it's aware that it's
a model and can recognize whether it's currently in testing or deployment.
Today's LLMs are tested for safety and alignment before they are deployed. An
LLM could exploit situational awareness to achieve a high score on safety
tests, while taking harmful actions after deployment. Situational awareness may
emerge unexpectedly as a byproduct of model scaling. One way to better foresee
this emergence is to run scaling experiments on abilities necessary for
situational awareness. As such an ability, we propose `out-of-context
reasoning' (in contrast to in-context learning). We study out-of-context
reasoning experimentally. First, we finetune an LLM on a description of a test
while providing no examples or demonstrations. At test time, we assess whether
the model can pass the test. To our surprise, we find that LLMs succeed on this
out-of-context reasoning task. Their success is sensitive to the training setup
and only works when we apply data augmentation. For both GPT-3 and LLaMA-1,
performance improves with model size. These findings offer a foundation for
further empirical study, towards predicting and potentially controlling the
emergence of situational awareness in LLMs. Code is available at:
https://github.com/AsaCooperStickland/situational-awareness-evals.
</p>
</div>
</dd>
<dt><a name="item18">[18]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.00682" title="Abstract">arXiv:2309.00682</a> [<a href="/pdf/2309.00682" title="Download PDF">pdf</a>, <a href="/format/2309.00682" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Randomized Polar Codes for Anytime Distributed Machine Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bartan%2C+B">Burak Bartan</a>, 
<a href="/search/cs?searchtype=author&query=Pilanci%2C+M">Mert Pilanci</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>; Information Theory (cs.IT); Machine Learning (cs.LG)

</div>
<p class="mathjax">We present a novel distributed computing framework that is robust to slow
compute nodes, and is capable of both approximate and exact computation of
linear operations. The proposed mechanism integrates the concepts of randomized
sketching and polar codes in the context of coded computation. We propose a
sequential decoding algorithm designed to handle real valued data while
maintaining low computational complexity for recovery. Additionally, we provide
an anytime estimator that can generate provably accurate estimates even when
the set of available node outputs is not decodable. We demonstrate the
potential applications of this framework in various contexts, such as
large-scale matrix multiplication and black-box optimization. We present the
implementation of these methods on a serverless cloud computing system and
provide numerical results to demonstrate their scalability in practice,
including ImageNet scale computations.
</p>
</div>
</dd>
<dt><a name="item19">[19]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.00685" title="Abstract">arXiv:2309.00685</a> [<a href="/pdf/2309.00685" title="Download PDF">pdf</a>, <a href="/format/2309.00685" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Shared Control Based on Extended Lipschitz Analysis With Application to  Human-Superlimb Collaboration
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Song%2C+H">Hanjun Song</a>, 
<a href="/search/cs?searchtype=author&query=Asada%2C+H+H">H. Harry Asada</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">This paper presents a quantitative method to construct voluntary manual
control and sensor-based reactive control in human-robot collaboration based on
Lipschitz conditions. To collaborate with a human, the robot observes the
human's motions and predicts a desired action. This predictor is constructed
from data of human demonstrations observed through the robot's sensors.
Analysis of demonstration data based on Lipschitz quotients evaluates a)
whether the desired action is predictable and b) to what extent the action is
predictable. If the quotients are low for all the input-output pairs of
demonstration data, a predictor can be constructed with a smooth function. In
dealing with human demonstration data, however, the Lipschitz quotients tend to
be very high in some situations due to the discrepancy between the information
that humans use and the one robots can obtain. This paper a) presents a method
for seeking missing information or a new variable that can lower the Lipschitz
quotients by adding the new variable to the input space, and b) constructs a
human-robot shared control system based on the Lipschitz analysis. Those
predictable situations are assigned to the robot's reactive control, while
human voluntary control is assigned to those situations where the Lipschitz
quotients are high even after the new variable is added. The latter situations
are deemed unpredictable and are rendered to the human. This human-robot shared
control method is applied to assist hemiplegic patients in a bimanual eating
task with a Supernumerary Robotic Limb, which works in concert with an
unaffected functional hand.
</p>
</div>
</dd>
<dt><a name="item20">[20]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.00686" title="Abstract">arXiv:2309.00686</a> [<a href="/pdf/2309.00686" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Watching Stars in Pixels: The Interplay of Traffic Shaping and YouTube  Streaming QoE over GEO Satellite Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jiamo Liu</a>, 
<a href="/search/cs?searchtype=author&query=Lerner%2C+D">David Lerner</a>, 
<a href="/search/cs?searchtype=author&query=Chung%2C+J">Jae Chung</a>, 
<a href="/search/cs?searchtype=author&query=Paul%2C+U">Udit Paul</a>, 
<a href="/search/cs?searchtype=author&query=Gupta%2C+A">Arpit Gupta</a>, 
<a href="/search/cs?searchtype=author&query=Belding%2C+E">Elizabeth Belding</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>

</div>
<p class="mathjax">Geosynchronous satellite (GEO) networks are a crucial option for users beyond
terrestrial connectivity. However, unlike terrestrial networks, GEO networks
exhibit high latency and deploy TCP proxies and traffic shapers. The deployment
of proxies effectively mitigates the impact of high network latency in GEO
networks, while traffic shapers help realize customer-controlled data-saver
options that optimize data usage. It is unclear how the interplay between GEO
networks' high latency, TCP proxies, and traffic-shaping policies affects the
quality of experience (QoE) for commonly used video applications. To fill this
gap, we analyze the quality of over $2$k YouTube video sessions streamed across
a production GEO network with a $900$Kbps shaping rate. Given the average bit
rates for the selected videos, we expected seamless streaming at $360$p or
lower resolutions. However, our analysis reveals that this is not the case:
$28\%$ of TCP sessions and $18\%$ of gQUIC sessions experience rebuffering
events, while the median average resolution is only $380$p for TCP and $299$p
for gQUIC. Our analysis identifies two key factors contributing to sub-optimal
performance: (i)unlike TCP, gQUIC only utilizes $63\%$ of network capacity; and
(ii)YouTube's imperfect chunk request pipelining. As a result of our study, the
partner GEO ISP discontinued support for the low-bandwidth data-saving option
in U.S. business and residential markets to avoid potential degradation of
video quality -- highlighting the practical significance of our findings.
</p>
</div>
</dd>
<dt><a name="item21">[21]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.00687" title="Abstract">arXiv:2309.00687</a> [<a href="/pdf/2309.00687" title="Download PDF">pdf</a>, <a href="/ps/2309.00687" title="Download PostScript">ps</a>, <a href="/format/2309.00687" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On Linear Codes with Random Multiplier Vectors and the Maximum Trace  Dimension Property
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Erd%C3%A9lyi%2C+M">M&#xe1;rton Erd&#xe9;lyi</a>, 
<a href="/search/cs?searchtype=author&query=Heged%C3%BCs%2C+P">P&#xe1;l Heged&#xfc;s</a>, 
<a href="/search/cs?searchtype=author&query=Kiss%2C+S+Z">S&#xe1;ndor Z. Kiss</a>, 
<a href="/search/cs?searchtype=author&query=Nagy%2C+G+P">G&#xe1;bor P. Nagy</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Number Theory (math.NT)

</div>
<p class="mathjax">Let $C$ be a linear code of length $n$ and dimension $k$ over the finite
field $\mathbb{F}_{q^m}$. The trace code $\mathrm{Tr}(C)$ is a linear code of
the same length $n$ over the subfield $\mathbb{F}_q$. The obvious upper bound
for the dimension of the trace code over $\mathbb{F}_q$ is $mk$. If equality
holds, then we say that $C$ has maximum trace dimension. The problem of finding
the true dimension of trace codes and their duals is relevant for the size of
the public key of various code-based cryptographic protocols. Let
$C_{\mathbf{a}}$ denote the code obtained from $C$ and a multiplier vector
$\mathbf{a}\in (\mathbb{F}_{q^m})^n$. In this paper, we give a lower bound for
the probability that a random multiplier vector produces a code
$C_{\mathbf{a}}$ of maximum trace dimension. We give an interpretation of the
bound for the class of algebraic geometry codes in terms of the degree of the
defining divisor. The bound explains the experimental fact that random
alternant codes have minimal dimension. Our bound holds whenever $n\geq
m(k+h)$, where $h\geq 0$ is the Singleton defect of $C$. For the extremal case
$n=m(h+k)$, numerical experiments reveal a closed connection between the
probability of having maximum trace dimension and the probability that a random
matrix has full rank.
</p>
</div>
</dd>
<dt><a name="item22">[22]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.00688" title="Abstract">arXiv:2309.00688</a> [<a href="/pdf/2309.00688" title="Download PDF">pdf</a>, <a href="/format/2309.00688" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Jointly Exploring Client Drift and Catastrophic Forgetting in Dynamic  Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Babendererde%2C+N">Niklas Babendererde</a>, 
<a href="/search/cs?searchtype=author&query=Fuchs%2C+M">Moritz Fuchs</a>, 
<a href="/search/cs?searchtype=author&query=Gonzalez%2C+C">Camila Gonzalez</a>, 
<a href="/search/cs?searchtype=author&query=Tolkach%2C+Y">Yuri Tolkach</a>, 
<a href="/search/cs?searchtype=author&query=Mukhopadhyay%2C+A">Anirban Mukhopadhyay</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Federated and Continual Learning have emerged as potential paradigms for the
robust and privacy-aware use of Deep Learning in dynamic environments. However,
Client Drift and Catastrophic Forgetting are fundamental obstacles to
guaranteeing consistent performance. Existing work only addresses these
problems separately, which neglects the fact that the root cause behind both
forms of performance deterioration is connected. We propose a unified analysis
framework for building a controlled test environment for Client Drift -- by
perturbing a defined ratio of clients -- and Catastrophic Forgetting -- by
shifting all clients with a particular strength. Our framework further
leverages this new combined analysis by generating a 3D landscape of the
combined performance impact from both. We demonstrate that the performance drop
through Client Drift, caused by a certain share of shifted clients, is
correlated to the drop from Catastrophic Forgetting resulting from a
corresponding shift strength. Correlation tests between both problems for
Computer Vision (CelebA) and Medical Imaging (PESO) support this new
perspective, with an average Pearson rank correlation coefficient of over 0.94.
Our framework's novel ability of combined spatio-temporal shift analysis allows
us to investigate how both forms of distribution shift behave in mixed
scenarios, opening a new pathway for better generalization. We show that a
combination of moderate Client Drift and Catastrophic Forgetting can even
improve the performance of the resulting model (causing a "Generalization
Bump") compared to when only one of the shifts occurs individually. We apply a
simple and commonly used method from Continual Learning in the federated
setting and observe this phenomenon to be reoccurring, leveraging the ability
of our framework to analyze existing and novel methods for Federated and
Continual Learning.
</p>
</div>
</dd>
<dt><a name="item23">[23]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.00690" title="Abstract">arXiv:2309.00690</a> [<a href="/pdf/2309.00690" title="Download PDF">pdf</a>, <a href="/format/2309.00690" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Polarizing Political Polls: How Visualization Design Choices Can Shape  Public Opinion and Increase Political Polarization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Holder%2C+E">Eli Holder</a>, 
<a href="/search/cs?searchtype=author&query=Bearfield%2C+C+X">Cindy Xiong Bearfield</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">While we typically focus on data visualization as a tool for facilitating
cognitive tasks (e.g., learning facts, making decisions), we know relatively
little about their second-order impacts on our opinions, attitudes, and values.
For example, could design or framing choices interact with viewers' social
cognitive biases in ways that promote political polarization? When reporting on
U.S. attitudes toward public policies, it is popular to highlight the gap
between Democrats and Republicans (e.g., with blue vs red connected dot plots).
But these charts may encourage social-normative conformity, influencing
viewers' attitudes to match the divided opinions shown in the visualization. We
conducted three experiments examining visualization framing in the context of
social conformity and polarization. Crowdworkers viewed charts showing
simulated polling results for public policy proposals. We varied framing
(aggregating data as non-partisan "All US Adults," or partisan "Democrat" and
"Republican") and the visualized groups' support levels. Participants then
reported their own support for each policy. We found that participants'
attitudes biased significantly toward the group attitudes shown in the stimuli
and this can increase inter-party attitude divergence. These results
demonstrate that data visualizations can induce social conformity and
accelerate political polarization. Choosing to visualize partisan divisions can
divide us further.
</p>
</div>
</dd>
<dt><a name="item24">[24]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.00696" title="Abstract">arXiv:2309.00696</a> [<a href="/pdf/2309.00696" title="Download PDF">pdf</a>, <a href="/format/2309.00696" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AAN: Attributes-Aware Network for Temporal Action Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dai%2C+R">Rui Dai</a>, 
<a href="/search/cs?searchtype=author&query=Das%2C+S">Srijan Das</a>, 
<a href="/search/cs?searchtype=author&query=Ryoo%2C+M+S">Michael S. Ryoo</a>, 
<a href="/search/cs?searchtype=author&query=Bremond%2C+F">Francois Bremond</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">The challenge of long-term video understanding remains constrained by the
efficient extraction of object semantics and the modelling of their
relationships for downstream tasks. Although the CLIP visual features exhibit
discriminative properties for various vision tasks, particularly in object
encoding, they are suboptimal for long-term video understanding. To address
this issue, we present the Attributes-Aware Network (AAN), which consists of
two key components: the Attributes Extractor and a Graph Reasoning block. These
components facilitate the extraction of object-centric attributes and the
modelling of their relationships within the video. By leveraging CLIP features,
AAN outperforms state-of-the-art approaches on two popular action detection
datasets: Charades and Toyota Smarthome Untrimmed datasets.
</p>
</div>
</dd>
<dt><a name="item25">[25]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.00697" title="Abstract">arXiv:2309.00697</a> [<a href="/pdf/2309.00697" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Monitoring and Maintenance of Telecommunication Systems: Challenges and  Research Perspectives
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Silva%2C+L">Lakmal Silva</a>, 
<a href="/search/cs?searchtype=author&query=Unterkalmsteiner%2C+M">Michael Unterkalmsteiner</a>, 
<a href="/search/cs?searchtype=author&query=Wnuk%2C+K">Krzysztof Wnuk</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Proceedings KKIO Software Engineering Conference 2018: 166-172
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
<p class="mathjax">In this paper, we present challenges associated with monitoring and
maintaining a large telecom system at Ericsson that was developed with high
degree of component reuse. The system constitutes of multiple services,
composed of both legacy and modern systems that are constantly changing and
need to be adapted to changing business needs. The paper is based on firsthand
experience from architecting, developing and maintaining such a system,
pointing out current challenges and potential avenues for future research that
might contribute to addressing them.
</p>
</div>
</dd>
<dt><a name="item26">[26]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.00698" title="Abstract">arXiv:2309.00698</a> [<a href="/pdf/2309.00698" title="Download PDF">pdf</a>, <a href="/ps/2309.00698" title="Download PostScript">ps</a>, <a href="/format/2309.00698" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A novel Newton-Raphson style root finding algorithm
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Agbalenyo%2C+K">Komi Agbalenyo</a>, 
<a href="/search/math?searchtype=author&query=Cailliez%2C+V">Vincent Cailliez</a>, 
<a href="/search/math?searchtype=author&query=Cailliez%2C+J">Jonathan Cailliez</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages, 3 tables, submited to Applied Mathematics and Computation
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">Many problems in applied mathematics require root finding algorithms.
Unfortunately, root finding methods have limitations. Firstly, regarding the
convergence, there is a trade-off between the size of it's domain and it's
rate. Secondly the numerous evaluations of the function and its derivatives
penalize the efficiency of high order methods. In this article, we present a
family of high order methods, that require few functional evaluations ( One for
each step plus one for each considered derivative at the start of the method),
thus increasing the efficiency of the methods.
</p>
</div>
</dd>
<dt><a name="item27">[27]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.00699" title="Abstract">arXiv:2309.00699</a> [<a href="/pdf/2309.00699" title="Download PDF">pdf</a>, <a href="/format/2309.00699" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Geometric Deep Learning: a Temperature Based Analysis of Graph Neural  Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lapenna%2C+M">M. Lapenna</a>, 
<a href="/search/cs?searchtype=author&query=Faglioni%2C+F">F. Faglioni</a>, 
<a href="/search/cs?searchtype=author&query=Zanchetta%2C+F">F. Zanchetta</a>, 
<a href="/search/cs?searchtype=author&query=Fioresi%2C+R">R. Fioresi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Published on Proceedings of GSI 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">We examine a Geometric Deep Learning model as a thermodynamic system treating
the weights as non-quantum and non-relativistic particles. We employ the notion
of temperature previously defined in [7] and study it in the various layers for
GCN and GAT models. Potential future applications of our findings are
discussed.
</p>
</div>
</dd>
<dt><a name="item28">[28]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.00700" title="Abstract">arXiv:2309.00700</a> [<a href="/pdf/2309.00700" title="Download PDF">pdf</a>, <a href="/format/2309.00700" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Cross-temporal Detection of Novel Ransomware Campaigns: A Multi-Modal  Alert Approach
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Murli%2C+S">Sathvik Murli</a>, 
<a href="/search/cs?searchtype=author&query=Nandakumar%2C+D">Dhruv Nandakumar</a>, 
<a href="/search/cs?searchtype=author&query=Kushwaha%2C+P+K">Prabhat Kumar Kushwaha</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+C">Cheng Wang</a>, 
<a href="/search/cs?searchtype=author&query=Redino%2C+C">Christopher Redino</a>, 
<a href="/search/cs?searchtype=author&query=Rahman%2C+A">Abdul Rahman</a>, 
<a href="/search/cs?searchtype=author&query=Israni%2C+S">Shalini Israni</a>, 
<a href="/search/cs?searchtype=author&query=Singh%2C+T">Tarun Singh</a>, 
<a href="/search/cs?searchtype=author&query=Bowen%2C+E">Edward Bowen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Preprint. Under Review
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">We present a novel approach to identify ransomware campaigns derived from
attack timelines representations within victim networks. Malicious activity
profiles developed from multiple alert sources support the construction of
alert graphs. This approach enables an effective and scalable representation of
the attack timelines where individual nodes represent malicious activity
detections with connections describing the potential attack paths. This work
demonstrates adaptability to different attack patterns through implementing a
novel method for parsing and classifying alert graphs while maintaining
efficacy despite potentially low-dimension node features.
</p>
</div>
</dd>
<dt><a name="item29">[29]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.00705" title="Abstract">arXiv:2309.00705</a> [<a href="/pdf/2309.00705" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Indexing Irises by Intrinsic Dimension
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rozmus%2C+J+M">J. Michael Rozmus</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages, 6 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Image and Video Processing (eess.IV)

</div>
<p class="mathjax">28,000+ high-quality iris images of 1350 distinct eyes from 650+ different
individuals from a relatively diverse university town population were
collected. A small defined unobstructed portion of the normalized iris image is
selected as a key portion for quickly identifying an unknown individual when
submitting an iris image to be matched to a database of enrolled irises of the
1350 distinct eyes. The intrinsic dimension of a set of these key portions of
the 1350 enrolled irises is measured to be about four (4). This set is mapped
to a four-dimensional intrinsic space by principal components analysis (PCA).
When an iris image is presented to the iris database for identification, the
search begins in the neighborhood of the location of its key portion in the 4D
intrinsic space, typically finding a correct identifying match after comparison
to only a few percent of the database.
</p>
</div>
</dd>
<dt><a name="item30">[30]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.00707" title="Abstract">arXiv:2309.00707</a> [<a href="/pdf/2309.00707" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Power of Patents: Leveraging Text Mining and Social Network Analysis  to Forecast IoT Trends
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Maghsoudi%2C+M">Mehrdad Maghsoudi</a>, 
<a href="/search/cs?searchtype=author&query=Nourbakhsh%2C+R">Reza Nourbakhsh</a>, 
<a href="/search/cs?searchtype=author&query=Kermani%2C+M+A+M">Mehrdad Agha Mohammadali Kermani</a>, 
<a href="/search/cs?searchtype=author&query=Khanizad%2C+R">Rahim Khanizad</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>

</div>
<p class="mathjax">Technology has become an indispensable competitive tool as science and
technology have progressed throughout history. Organizations can compete on an
equal footing by implementing technology appropriately. Technology trends or
technology lifecycles begin during the initiation phase. Finally, it reaches
saturation after entering the maturity phase. As technology reaches saturation,
it will be removed or replaced by another. This makes investing in technologies
during this phase unjustifiable. Technology forecasting is a critical tool for
research and development to determine the future direction of technology. Based
on registered patents, this study examined the trends of IOT technologies. A
total of 3697 patents related to the Internet of Things from the last six years
of patenting have been gathered using lens.org for this purpose. The main
people and companies were identified through the creation of the IOT patent
registration cooperation network, and the main groups active in patent
registration were identified by the community detection technique. The patents
were then divided into six technology categories: Safety and Security,
Information Services, Public Safety and Environment Monitoring, Collaborative
Aware Systems, Smart Homes/Buildings, and Smart Grid. And their technical
maturity was identified and examined using the Sigma Plot program. Based on the
findings, information services technologies are in the saturation stage, while
both smart homes/buildings, and smart grid technologies are in the saturation
stage. Three technologies, Safety and Security, Public Safety and Environment
Monitoring, and Collaborative Aware Systems are in the maturity stage.
</p>
</div>
</dd>
<dt><a name="item31">[31]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.00709" title="Abstract">arXiv:2309.00709</a> [<a href="/pdf/2309.00709" title="Download PDF">pdf</a>, <a href="/format/2309.00709" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Reinforcement Learning with Human Feedback for Realistic Traffic  Simulation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cao%2C+Y">Yulong Cao</a>, 
<a href="/search/cs?searchtype=author&query=Ivanovic%2C+B">Boris Ivanovic</a>, 
<a href="/search/cs?searchtype=author&query=Xiao%2C+C">Chaowei Xiao</a>, 
<a href="/search/cs?searchtype=author&query=Pavone%2C+M">Marco Pavone</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages, 4 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Machine Learning (cs.LG); Robotics (cs.RO)

</div>
<p class="mathjax">In light of the challenges and costs of real-world testing, autonomous
vehicle developers often rely on testing in simulation for the creation of
reliable systems. A key element of effective simulation is the incorporation of
realistic traffic models that align with human knowledge, an aspect that has
proven challenging due to the need to balance realism and diversity. This works
aims to address this by developing a framework that employs reinforcement
learning with human preference (RLHF) to enhance the realism of existing
traffic models. This study also identifies two main challenges: capturing the
nuances of human preferences on realism and the unification of diverse traffic
simulation models. To tackle these issues, we propose using human feedback for
alignment and employ RLHF due to its sample efficiency. We also introduce the
first dataset for realism alignment in traffic modeling to support such
research. Our framework, named TrafficRLHF, demonstrates its proficiency in
generating realistic traffic scenarios that are well-aligned with human
preferences, as corroborated by comprehensive evaluations on the nuScenes
dataset.
</p>
</div>
</dd>
<dt><a name="item32">[32]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.00711" title="Abstract">arXiv:2309.00711</a> [<a href="/pdf/2309.00711" title="Download PDF">pdf</a>, <a href="/format/2309.00711" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning Shared Safety Constraints from Multi-task Demonstrations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kim%2C+K">Konwoo Kim</a>, 
<a href="/search/cs?searchtype=author&query=Swamy%2C+G">Gokul Swamy</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zuxin Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+D">Ding Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Choudhury%2C+S">Sanjiban Choudhury</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Z+S">Zhiwei Steven Wu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Regardless of the particular task we want them to perform in an environment,
there are often shared safety constraints we want our agents to respect. For
example, regardless of whether it is making a sandwich or clearing the table, a
kitchen robot should not break a plate. Manually specifying such a constraint
can be both time-consuming and error-prone. We show how to learn constraints
from expert demonstrations of safe task completion by extending inverse
reinforcement learning (IRL) techniques to the space of constraints.
Intuitively, we learn constraints that forbid highly rewarding behavior that
the expert could have taken but chose not to. Unfortunately, the constraint
learning problem is rather ill-posed and typically leads to overly conservative
constraints that forbid all behavior that the expert did not take. We counter
this by leveraging diverse demonstrations that naturally occur in multi-task
settings to learn a tighter set of constraints. We validate our method with
simulation experiments on high-dimensional continuous control tasks.
</p>
</div>
</dd>
<dt><a name="item33">[33]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.00718" title="Abstract">arXiv:2309.00718</a> [<a href="/pdf/2309.00718" title="Download PDF">pdf</a>, <a href="/format/2309.00718" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Multisensory Approach to Virtual Reality Stress Reduction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Masters%2C+R">Rachel Masters</a>, 
<a href="/search/cs?searchtype=author&query=Ortega%2C+F">Francisco Ortega</a>, 
<a href="/search/cs?searchtype=author&query=Interrante%2C+V">Victoria Interrante</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages, 2 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">Forest bathing is a nature immersion practice that reduces stress, restores
mental resources, and has a wide variety of use cases in the treatment of
mental illnesses. Since many people who need the benefits of forest bathing
have little access to nature, virtual reality (VR) is being explored as a tool
for delivering accessible immersive nature experiences via virtual nature
environments (VNE's). Research on VNE's mainly utilizes the audiovisual
capabilities of VR, but since forest bathing is a fully multisensory
experience, further investigations into the integration of other sensory
technologies, namely smell and temperature, are essential for the future of VNE
research.
</p>
</div>
</dd>
<dt><a name="item34">[34]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.00721" title="Abstract">arXiv:2309.00721</a> [<a href="/pdf/2309.00721" title="Download PDF">pdf</a>, <a href="/ps/2309.00721" title="Download PostScript">ps</a>, <a href="/format/2309.00721" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Geometric Tracking on $\mathcal{S}^{3}$ Based on Sliding Mode Control
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Espindola%2C+E">Eduardo Espindola</a>, 
<a href="/search/eess?searchtype=author&query=Tang%2C+Y">Yu Tang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">Attitude tracking on the unit sphere of dimension $3$ based on sliding mode
is considered in this paper. The tangent bundle of Lagrangian dynamics that
describes the rotational motion of a rigid body is first shown to be a Lie
group, and then a sliding surface that emerged on it is defined. Next, a
sliding-mode controller is designed for attitude tracking that relies on an
intrinsic error defined on the Lie group. Almost global asymptotic stability of
the closed loop is demonstrated using the Lyapunov analysis. Numerical
simulations are included to compare the performance of the sliding mode
controller designed on the Lie group with that designed in the embedding
Euclidean space.
</p>
</div>
</dd>
<dt><a name="item35">[35]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.00723" title="Abstract">arXiv:2309.00723</a> [<a href="/pdf/2309.00723" title="Download PDF">pdf</a>, <a href="/format/2309.00723" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Contextual Biasing of Named-Entities with Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sun%2C+C">Chuanneng Sun</a>, 
<a href="/search/cs?searchtype=author&query=Ahmed%2C+Z">Zeeshan Ahmed</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+Y">Yingyi Ma</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zhe Liu</a>, 
<a href="/search/cs?searchtype=author&query=Pang%2C+Y">Yutong Pang</a>, 
<a href="/search/cs?searchtype=author&query=Kalinli%2C+O">Ozlem Kalinli</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages, 4 figures. Conference: ICASSP 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Sound (cs.SD); Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">This paper studies contextual biasing with Large Language Models (LLMs),
where during second-pass rescoring additional contextual information is
provided to a LLM to boost Automatic Speech Recognition (ASR) performance. We
propose to leverage prompts for a LLM without fine tuning during rescoring
which incorporate a biasing list and few-shot examples to serve as additional
information when calculating the score for the hypothesis. In addition to
few-shot prompt learning, we propose multi-task training of the LLM to predict
both the entity class and the next token. To improve the efficiency for
contextual biasing and to avoid exceeding LLMs' maximum sequence lengths, we
propose dynamic prompting, where we select the most likely class using the
class tag prediction, and only use entities in this class as contexts for next
token prediction. Word Error Rate (WER) evaluation is performed on i) an
internal calling, messaging, and dictation dataset, and ii) the SLUE-Voxpopuli
dataset. Results indicate that biasing lists and few-shot examples can achieve
17.8% and 9.6% relative improvement compared to first pass ASR, and that
multi-task training and dynamic prompting can achieve 20.0% and 11.3% relative
WER improvement, respectively.
</p>
</div>
</dd>
<dt><a name="item36">[36]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.00726" title="Abstract">arXiv:2309.00726</a> [<a href="/pdf/2309.00726" title="Download PDF">pdf</a>, <a href="/format/2309.00726" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An Anisotropic $hp$-Adaptation Framework for Ultraweak Discontinuous  Petrov-Galerkin Formulations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chakraborty%2C+A">Ankit Chakraborty</a>, 
<a href="/search/cs?searchtype=author&query=Henneking%2C+S">Stefan Henneking</a>, 
<a href="/search/cs?searchtype=author&query=Demkowicz%2C+L">Leszek Demkowicz</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Engineering, Finance, and Science (cs.CE)</span>; Numerical Analysis (math.NA)

</div>
<p class="mathjax">In this article, we present a three-dimensional anisotropic $hp$-mesh
refinement strategy for ultraweak discontinuous Petrov--Galerkin (DPG)
formulations with optimal test functions. The refinement strategy utilizes the
built-in residual-based error estimator accompanying the DPG discretization.
The refinement strategy is a two-step process: (a) use the built-in error
estimator to mark and isotropically $hp$-refine elements of the (coarse) mesh
to generate a finer mesh; (b) use the reference solution on the finer mesh to
compute optimal $h$- and $p$-refinements of the selected elements in the coarse
mesh. The process is repeated with coarse and fine mesh being generated in
every adaptation cycle, until a prescribed error tolerance is achieved. We
demonstrate the performance of the proposed refinement strategy using several
numerical examples on hexahedral meshes.
</p>
</div>
</dd>
<dt><a name="item37">[37]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.00733" title="Abstract">arXiv:2309.00733</a> [<a href="/pdf/2309.00733" title="Download PDF">pdf</a>, <a href="/format/2309.00733" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learned Visual Features to Textual Explanations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Taghanaki%2C+S+A">Saeid Asgari Taghanaki</a>, 
<a href="/search/cs?searchtype=author&query=Khani%2C+A">Aliasghar Khani</a>, 
<a href="/search/cs?searchtype=author&query=Khasahmadi%2C+A">Amir Khasahmadi</a>, 
<a href="/search/cs?searchtype=author&query=Sanghi%2C+A">Aditya Sanghi</a>, 
<a href="/search/cs?searchtype=author&query=Willis%2C+K+D+D">Karl D.D. Willis</a>, 
<a href="/search/cs?searchtype=author&query=Mahdavi-Amiri%2C+A">Ali Mahdavi-Amiri</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Interpreting the learned features of vision models has posed a longstanding
challenge in the field of machine learning. To address this issue, we propose a
novel method that leverages the capabilities of large language models (LLMs) to
interpret the learned features of pre-trained image classifiers. Our method,
called TExplain, tackles this task by training a neural network to establish a
connection between the feature space of image classifiers and LLMs. Then,
during inference, our approach generates a vast number of sentences to explain
the features learned by the classifier for a given image. These sentences are
then used to extract the most frequent words, providing a comprehensive
understanding of the learned features and patterns within the classifier. Our
method, for the first time, utilizes these frequent words corresponding to a
visual representation to provide insights into the decision-making process of
the independently trained classifier, enabling the detection of spurious
correlations, biases, and a deeper comprehension of its behavior. To validate
the effectiveness of our approach, we conduct experiments on diverse datasets,
including ImageNet-9L and Waterbirds. The results demonstrate the potential of
our method to enhance the interpretability and robustness of image classifiers.
</p>
</div>
</dd>
<dt><a name="item38">[38]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.00735" title="Abstract">arXiv:2309.00735</a> [<a href="/pdf/2309.00735" title="Download PDF">pdf</a>, <a href="/format/2309.00735" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SoK: Safer Digital-Safety Research Involving At-Risk Users
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bellini%2C+R">Rosanna Bellini</a>, 
<a href="/search/cs?searchtype=author&query=Tseng%2C+E">Emily Tseng</a>, 
<a href="/search/cs?searchtype=author&query=Warford%2C+N">Noel Warford</a>, 
<a href="/search/cs?searchtype=author&query=Daffalla%2C+A">Alaa Daffalla</a>, 
<a href="/search/cs?searchtype=author&query=Matthews%2C+T">Tara Matthews</a>, 
<a href="/search/cs?searchtype=author&query=Consolvo%2C+S">Sunny Consolvo</a>, 
<a href="/search/cs?searchtype=author&query=Woelfer%2C+J+P">Jill Palzkill Woelfer</a>, 
<a href="/search/cs?searchtype=author&query=Kelley%2C+P+G">Patrick Gage Kelley</a>, 
<a href="/search/cs?searchtype=author&query=Mazurek%2C+M+L">Michelle L. Mazurek</a>, 
<a href="/search/cs?searchtype=author&query=Cuomo%2C+D">Dana Cuomo</a>, 
<a href="/search/cs?searchtype=author&query=Dell%2C+N">Nicola Dell</a>, 
<a href="/search/cs?searchtype=author&query=Ristenpart%2C+T">Thomas Ristenpart</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, 3 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>; Cryptography and Security (cs.CR); Human-Computer Interaction (cs.HC)

</div>
<p class="mathjax">Research involving at-risk users -- that is, users who are more likely to
experience a digital attack or to be disproportionately affected when harm from
such an attack occurs -- can pose significant safety challenges to both users
and researchers. Nevertheless, pursuing research in computer security and
privacy is crucial to understanding how to meet the digital-safety needs of
at-risk users and to design safer technology for all. To standardize and
bolster safer research involving such users, we offer an analysis of 196
academic works to elicit 14 research risks and 36 safety practices used by a
growing community of researchers. We pair this inconsistent set of reported
safety practices with oral histories from 12 domain experts to contribute
scaffolded and consolidated pragmatic guidance that researchers can use to
plan, execute, and share safer digital-safety research involving at-risk users.
We conclude by suggesting areas for future research regarding the reporting,
study, and funding of at-risk user research
</p>
</div>
</dd>
<dt><a name="item39">[39]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.00738" title="Abstract">arXiv:2309.00738</a> [<a href="/pdf/2309.00738" title="Download PDF">pdf</a>, <a href="/format/2309.00738" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Universal Normalization Enhanced Graph Representation Learning for Gene  Network Prediction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dong%2C+Z">Zehao Dong</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+M">Muhan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Q">Qihang Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Payne%2C+P+R+O">Philip R.O. Payne</a>, 
<a href="/search/cs?searchtype=author&query=Province%2C+M">Michael Province</a>, 
<a href="/search/cs?searchtype=author&query=Cruchaga%2C+C">Carlos Cruchaga</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+T">Tianyu Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yixin Chen</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+F">Fuhai Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Effective gene network representation learning is of great importance in
bioinformatics to predict/understand the relation of gene profiles and disease
phenotypes. Though graph neural networks (GNNs) have been the dominant
architecture for analyzing various graph-structured data like social networks,
their predicting on gene networks often exhibits subpar performance. In this
paper, we formally investigate the gene network representation learning problem
and characterize a notion of \textit{universal graph normalization}, where
graph normalization can be applied in an universal manner to maximize the
expressive power of GNNs while maintaining the stability. We propose a novel
UNGNN (Universal Normalized GNN) framework, which leverages universal graph
normalization in both the message passing phase and readout layer to enhance
the performance of a base GNN. UNGNN has a plug-and-play property and can be
combined with any GNN backbone in practice. A comprehensive set of experiments
on gene-network-based bioinformatical tasks demonstrates that our UNGNN model
significantly outperforms popular GNN benchmarks and provides an overall
performance improvement of 16 $\%$ on average compared to previous
state-of-the-art (SOTA) baselines. Furthermore, we also evaluate our
theoretical findings on other graph datasets where the universal graph
normalization is solvable, and we observe that UNGNN consistently achieves the
superior performance.
</p>
</div>
</dd>
<dt><a name="item40">[40]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.00742" title="Abstract">arXiv:2309.00742</a> [<a href="/pdf/2309.00742" title="Download PDF">pdf</a>, <a href="/format/2309.00742" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning Robust Model Predictive Control for Voltage Control of Islanded  Microgrid
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Kiani%2C+S">Sahand Kiani</a>, 
<a href="/search/eess?searchtype=author&query=Kebriaei%2C+H">Hamed Kebriaei</a>, 
<a href="/search/eess?searchtype=author&query=Hamzeh%2C+M">Mohsen Hamzeh</a>, 
<a href="/search/eess?searchtype=author&query=Salmanpour%2C+A">Ali Salmanpour</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">This paper proposes a novel control design for voltage tracking of an
islanded AC microgrid in the presence of {nonlinear} loads and parametric
uncertainties at the primary level of control. The proposed method is based on
the Tube-Based Robust Model Predictive Control (RMPC), an online
optimization-based method which can handle the constraints and uncertainties as
well. The challenge with this method is the conservativeness imposed by
designing the tube based on the worst-case scenario of the uncertainties. This
weakness is amended in this paper by employing a combination of a
learning-based Gaussian Process (GP) regression and RMPC. The advantage of
using GP is that both the mean and variance of the loads are predicted at each
iteration based on the real data, and the resulted values of mean and the bound
of confidence are utilized to design the tube in RMPC. The theoretical results
are also provided to prove the recursive feasibility and stability of the
proposed learning based RMPC. Finally, the simulation results are carried out
on both single and multiple DG (Distributed Generation) units.
</p>
</div>
</dd>
<dt><a name="item41">[41]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.00743" title="Abstract">arXiv:2309.00743</a> [<a href="/pdf/2309.00743" title="Download PDF">pdf</a>, <a href="/format/2309.00743" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Language-Conditioned Change-point Detection to Identify Sub-Tasks in  Robotics Domains
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Raj%2C+D">Divyanshu Raj</a>, 
<a href="/search/cs?searchtype=author&query=Baral%2C+C">Chitta Baral</a>, 
<a href="/search/cs?searchtype=author&query=Gopalan%2C+N">Nakul Gopalan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 Pages, 13 figures, Accepted paper at the RSS 2023 Workshop on Articulate Robots: Utilizing Language for Robot Learning
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL)

</div>
<p class="mathjax">In this work, we present an approach to identify sub-tasks within a
demonstrated robot trajectory using language instructions. We identify these
sub-tasks using language provided during demonstrations as guidance to identify
sub-segments of a longer robot trajectory. Given a sequence of natural language
instructions and a long trajectory consisting of image frames and discrete
actions, we want to map an instruction to a smaller fragment of the trajectory.
Unlike previous instruction following works which directly learn the mapping
from language to a policy, we propose a language-conditioned change-point
detection method to identify sub-tasks in a problem. Our approach learns the
relationship between constituent segments of a long language command and
corresponding constituent segments of a trajectory. These constituent
trajectory segments can be used to learn subtasks or sub-goals for planning or
options as demonstrated by previous related work. Our insight in this work is
that the language-conditioned robot change-point detection problem is similar
to the existing video moment retrieval works used to identify sub-segments
within online videos. Through extensive experimentation, we demonstrate a
$1.78_{\pm 0.82}\%$ improvement over a baseline approach in accurately
identifying sub-tasks within a trajectory using our proposed method. Moreover,
we present a comprehensive study investigating sample complexity requirements
on learning this mapping, between language and trajectory sub-segments, to
understand if the video retrieval-based methods are realistic in real robot
scenarios.
</p>
</div>
</dd>
<dt><a name="item42">[42]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.00744" title="Abstract">arXiv:2309.00744</a> [<a href="/pdf/2309.00744" title="Download PDF">pdf</a>, <a href="/format/2309.00744" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> &quot;Make Them Change it Every Week!&quot;: A Qualitative Exploration of Online  Developer Advice on Usable and Secure Authentication
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Klemmer%2C+J+H">Jan H. Klemmer</a> (1), 
<a href="/search/cs?searchtype=author&query=Gutfleisch%2C+M">Marco Gutfleisch</a> (2), 
<a href="/search/cs?searchtype=author&query=Stransky%2C+C">Christian Stransky</a> (3), 
<a href="/search/cs?searchtype=author&query=Acar%2C+Y">Yasemin Acar</a> (4), 
<a href="/search/cs?searchtype=author&query=Sasse%2C+M+A">M. Angela Sasse</a> (2), 
<a href="/search/cs?searchtype=author&query=Fahl%2C+S">Sascha Fahl</a> (3) ((1) Leibniz University Hannover, (2) Ruhr University Bochum, (3) CISPA Helmholtz Center for Information Security, (4) Paderborn University)
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Extended version of the paper that appears at ACM CCS 2023. 18 pages, 4 figures, 11 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">Usable and secure authentication on the web and beyond is mission-critical.
While password-based authentication is still widespread, users have trouble
dealing with potentially hundreds of online accounts and their passwords.
Alternatives or extensions such as multi-factor authentication have their own
challenges and find only limited adoption. Finding the right balance between
security and usability is challenging for developers. Previous work found that
developers use online resources to inform security decisions when writing code.
Similar to other areas, lots of authentication advice for developers is
available online, including blog posts, discussions on Stack Overflow, research
papers, or guidelines by institutions like OWASP or NIST.
<br />We are the first to explore developer advice on authentication that affects
usable security for end-users. Based on a survey with 18 professional web
developers, we obtained 406 documents and qualitatively analyzed 272 contained
pieces of advice in depth. We aim to understand the accessibility and quality
of online advice and provide insights into how online advice might contribute
to (in)secure and (un)usable authentication. We find that advice is scattered
and that finding recommendable, consistent advice is a challenge for
developers, among others. The most common advice is for password-based
authentication, but little for more modern alternatives. Unfortunately, many
pieces of advice are debatable (e.g., complex password policies), outdated
(e.g., enforcing regular password changes), or contradicting and might lead to
unusable or insecure authentication. Based on our findings, we make
recommendations for developers, advice providers, official institutions, and
academia on how to improve online advice for developers.
</p>
</div>
</dd>
<dt><a name="item43">[43]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.00748" title="Abstract">arXiv:2309.00748</a> [<a href="/pdf/2309.00748" title="Download PDF">pdf</a>, <a href="/format/2309.00748" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PathLDM: Text conditioned Latent Diffusion Model for Histopathology
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yellapragada%2C+S">Srikar Yellapragada</a>, 
<a href="/search/cs?searchtype=author&query=Graikos%2C+A">Alexandros Graikos</a>, 
<a href="/search/cs?searchtype=author&query=Prasanna%2C+P">Prateek Prasanna</a>, 
<a href="/search/cs?searchtype=author&query=Kurc%2C+T">Tahsin Kurc</a>, 
<a href="/search/cs?searchtype=author&query=Saltz%2C+J">Joel Saltz</a>, 
<a href="/search/cs?searchtype=author&query=Samaras%2C+D">Dimitris Samaras</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">To achieve high-quality results, diffusion models must be trained on large
datasets. This can be notably prohibitive for models in specialized domains,
such as computational pathology. Conditioning on labeled data is known to help
in data-efficient model training. Therefore, histopathology reports, which are
rich in valuable clinical information, are an ideal choice as guidance for a
histopathology generative model. In this paper, we introduce PathLDM, the first
text-conditioned Latent Diffusion Model tailored for generating high-quality
histopathology images. Leveraging the rich contextual information provided by
pathology text reports, our approach fuses image and textual data to enhance
the generation process. By utilizing GPT's capabilities to distill and
summarize complex text reports, we establish an effective conditioning
mechanism. Through strategic conditioning and necessary architectural
enhancements, we achieved a SoTA FID score of 7.64 for text-to-image generation
on the TCGA-BRCA dataset, significantly outperforming the closest
text-conditioned competitor with FID 30.1.
</p>
</div>
</dd>
<dt><a name="item44">[44]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.00751" title="Abstract">arXiv:2309.00751</a> [<a href="/pdf/2309.00751" title="Download PDF">pdf</a>, <a href="/format/2309.00751" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Let the Models Respond: Interpreting Language Model Detoxification  Through the Lens of Prompt Dependence
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Scalena%2C+D">Daniel Scalena</a>, 
<a href="/search/cs?searchtype=author&query=Sarti%2C+G">Gabriele Sarti</a>, 
<a href="/search/cs?searchtype=author&query=Nissim%2C+M">Malvina Nissim</a>, 
<a href="/search/cs?searchtype=author&query=Fersini%2C+E">Elisabetta Fersini</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 4 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Due to language models' propensity to generate toxic or hateful responses,
several techniques were developed to align model generations with users'
preferences. Despite the effectiveness of such methods in improving the safety
of model interactions, their impact on models' internal processes is still
poorly understood. In this work, we apply popular detoxification approaches to
several language models and quantify their impact on the resulting models'
prompt dependence using feature attribution methods. We evaluate the
effectiveness of counter-narrative fine-tuning and compare it with
reinforcement learning-driven detoxification, observing differences in prompt
reliance between the two methods despite their similar detoxification
performances.
</p>
</div>
</dd>
<dt><a name="item45">[45]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.00752" title="Abstract">arXiv:2309.00752</a> [<a href="/pdf/2309.00752" title="Download PDF">pdf</a>, <a href="/format/2309.00752" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Affine-Transformation-Invariant Image Classification by Differentiable  Arithmetic Distribution Module
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tan%2C+Z">Zijie Tan</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+G">Guanfang Dong</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+C">Chenqiu Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Basu%2C+A">Anup Basu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Although Convolutional Neural Networks (CNNs) have achieved promising results
in image classification, they still are vulnerable to affine transformations
including rotation, translation, flip and shuffle. The drawback motivates us to
design a module which can alleviate the impact from different affine
transformations. Thus, in this work, we introduce a more robust substitute by
incorporating distribution learning techniques, focusing particularly on
learning the spatial distribution information of pixels in images. To rectify
the issue of non-differentiability of prior distribution learning methods that
rely on traditional histograms, we adopt the Kernel Density Estimation (KDE) to
formulate differentiable histograms. On this foundation, we present a novel
Differentiable Arithmetic Distribution Module (DADM), which is designed to
extract the intrinsic probability distributions from images. The proposed
approach is able to enhance the model's robustness to affine transformations
without sacrificing its feature extraction capabilities, thus bridging the gap
between traditional CNNs and distribution-based learning. We validate the
effectiveness of the proposed approach through ablation study and comparative
experiments with LeNet.
</p>
</div>
</dd>
<dt><a name="item46">[46]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.00753" title="Abstract">arXiv:2309.00753</a> [<a href="/pdf/2309.00753" title="Download PDF">pdf</a>, <a href="/ps/2309.00753" title="Download PostScript">ps</a>, <a href="/format/2309.00753" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Jamming Suppression Via Resource Hopping in High-Mobility OTFS-SCMA  Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Deng%2C+Q">Qinwen Deng</a>, 
<a href="/search/cs?searchtype=author&query=Ge%2C+Y">Yao Ge</a>, 
<a href="/search/cs?searchtype=author&query=Ding%2C+Z">Zhi Ding</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">This letter studies the mechanism of uplink multiple access and jamming
suppression in an OTFS system. Specifically, we propose a novel resource
hopping mechanism for orthogonal time frequency space (OTFS) systems with delay
or Doppler partitioned sparse code multiple access (SCMA) to mitigate the
effect of jamming in controlled multiuser uplink. We analyze the non-uniform
impact of classic jamming signals such as narrowband interference (NBI) and
periodic impulse noise (PIN) in delay-Doppler (DD) domain on OTFS systems.
Leveraging turbo equalization, our proposed hopping method demonstrates
consistent BER performance improvement under jamming over conventional
OTFS-SCMA systems compared to static resource allocation schemes.
</p>
</div>
</dd>
<dt><a name="item47">[47]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.00754" title="Abstract">arXiv:2309.00754</a> [<a href="/pdf/2309.00754" title="Download PDF">pdf</a>, <a href="/format/2309.00754" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Efficient RLHF: Reducing the Memory Usage of PPO
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Santacroce%2C+M">Michael Santacroce</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+Y">Yadong Lu</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+H">Han Yu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yuanzhi Li</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+Y">Yelong Shen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL)

</div>
<p class="mathjax">Reinforcement Learning with Human Feedback (RLHF) has revolutionized language
modeling by aligning models with human preferences. However, the RL stage,
Proximal Policy Optimization (PPO), requires over 3x the memory of Supervised
Fine-Tuning (SFT), making it infeasible to use for most practitioners. To
address this issue, we present a comprehensive analysis the memory usage,
performance, and training time of memory-savings techniques for PPO. We
introduce Hydra-RLHF by first integrating the SFT and Reward models and then
dynamically turning LoRA "off" during training. Our experiments show: 1. Using
LoRA during PPO reduces its memory usage to be smaller than SFT while improving
alignment across four public benchmarks, and 2. Hydra-PPO reduces the latency
per sample of LoRA-PPO by up to 65% while maintaining its performance. Our
results demonstrate that Hydra-PPO is a simple and promising solution for
enabling more widespread usage of RLHF.
</p>
</div>
</dd>
<dt><a name="item48">[48]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.00768" title="Abstract">arXiv:2309.00768</a> [<a href="/pdf/2309.00768" title="Download PDF">pdf</a>, <a href="/format/2309.00768" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Space-Time Block Preconditioning for Incompressible Resistive  Magnetohydrodynamics
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Danieli%2C+F">Federico Danieli</a>, 
<a href="/search/math?searchtype=author&query=Southworth%2C+B+S">Ben S. Southworth</a>, 
<a href="/search/math?searchtype=author&query=Schroder%2C+J+B">Jacob B. Schroder</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 25 pages, 4 figures, 3 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">This work develops a novel all-at-once space-time preconditioning approach
for resistive magnetohydrodynamics (MHD), with a focus on model problems
targeting fusion reactor design. We consider parallel-in-time due to the long
time domains required to capture the physics of interest, as well as the
complexity of the underlying system and thereby computational cost of long-time
integration. To ameliorate this cost by using many processors, we thus develop
a novel approach to solving the whole space-time system that is parallelizable
in both space and time. We develop a space-time block preconditioning for
resistive MHD, following the space-time block preconditioning concept first
introduced by Danieli et al. in 2022 for incompressible flow, where an
effective preconditioner for classic sequential time-stepping is extended to
the space-time setting. The starting point for our derivation is the continuous
Schur complement preconditioner by Cyr et al. in 2021, which we proceed to
generalise in order to produce, to our knowledge, the first space-time block
preconditioning approach for the challenging equations governing incompressible
resistive MHD. The numerical results are promising for the model problems of
island coalescence and tearing mode, with the overhead computational cost
associated with space-time preconditioning versus sequential time-stepping
being modest and primarily in the range of 2x-5x, which is low for
parallel-in-time schemes in general. Additionally, the scaling results for
inner (linear) and outer (nonlinear) iterations are flat in the case of fixed
time-step size and only grow very slowly in the case of time-step refinement.
</p>
</div>
</dd>
<dt><a name="item49">[49]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.00770" title="Abstract">arXiv:2309.00770</a> [<a href="/pdf/2309.00770" title="Download PDF">pdf</a>, <a href="/format/2309.00770" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Bias and Fairness in Large Language Models: A Survey
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gallegos%2C+I+O">Isabel O. Gallegos</a>, 
<a href="/search/cs?searchtype=author&query=Rossi%2C+R+A">Ryan A. Rossi</a>, 
<a href="/search/cs?searchtype=author&query=Barrow%2C+J">Joe Barrow</a>, 
<a href="/search/cs?searchtype=author&query=Tanjim%2C+M+M">Md Mehrab Tanjim</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+S">Sungchul Kim</a>, 
<a href="/search/cs?searchtype=author&query=Dernoncourt%2C+F">Franck Dernoncourt</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+T">Tong Yu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+R">Ruiyi Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Ahmed%2C+N+K">Nesreen K. Ahmed</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Computers and Society (cs.CY); Machine Learning (cs.LG)

</div>
<p class="mathjax">Rapid advancements of large language models (LLMs) have enabled the
processing, understanding, and generation of human-like text, with increasing
integration into systems that touch our social sphere. Despite this success,
these models can learn, perpetuate, and amplify harmful social biases. In this
paper, we present a comprehensive survey of bias evaluation and mitigation
techniques for LLMs. We first consolidate, formalize, and expand notions of
social bias and fairness in natural language processing, defining distinct
facets of harm and introducing several desiderata to operationalize fairness
for LLMs. We then unify the literature by proposing three intuitive taxonomies,
two for bias evaluation, namely metrics and datasets, and one for mitigation.
Our first taxonomy of metrics for bias evaluation disambiguates the
relationship between metrics and evaluation datasets, and organizes metrics by
the different levels at which they operate in a model: embeddings,
probabilities, and generated text. Our second taxonomy of datasets for bias
evaluation categorizes datasets by their structure as counterfactual inputs or
prompts, and identifies the targeted harms and social groups; we also release a
consolidation of publicly-available datasets for improved access. Our third
taxonomy of techniques for bias mitigation classifies methods by their
intervention during pre-processing, in-training, intra-processing, and
post-processing, with granular subcategories that elucidate research trends.
Finally, we identify open problems and challenges for future work. Synthesizing
a wide range of recent research, we aim to provide a clear guide of the
existing literature that empowers researchers and practitioners to better
understand and prevent the propagation of bias in LLMs.
</p>
</div>
</dd>
<dt><a name="item50">[50]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.00773" title="Abstract">arXiv:2309.00773</a> [<a href="/pdf/2309.00773" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deep Reinforcement Learning in Surgical Robotics: Enhancing the  Automation Level
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Qian%2C+C">Cheng Qian</a>, 
<a href="/search/cs?searchtype=author&query=Ren%2C+H">Hongliang Ren</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Surgical robotics is a rapidly evolving field that is transforming the
landscape of surgeries. Surgical robots have been shown to enhance precision,
minimize invasiveness, and alleviate surgeon fatigue. One promising area of
research in surgical robotics is the use of reinforcement learning to enhance
the automation level. Reinforcement learning is a type of machine learning that
involves training an agent to make decisions based on rewards and punishments.
This literature review aims to comprehensively analyze existing research on
reinforcement learning in surgical robotics. The review identified various
applications of reinforcement learning in surgical robotics, including
pre-operative, intra-body, and percutaneous procedures, listed the typical
studies, and compared their methodologies and results. The findings show that
reinforcement learning has great potential to improve the autonomy of surgical
robots. Reinforcement learning can teach robots to perform complex surgical
tasks, such as suturing and tissue manipulation. It can also improve the
accuracy and precision of surgical robots, making them more effective at
performing surgeries.
</p>
</div>
</dd>
<dt><a name="item51">[51]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.00775" title="Abstract">arXiv:2309.00775</a> [<a href="/pdf/2309.00775" title="Download PDF">pdf</a>, <a href="/format/2309.00775" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Contrastive Feature Masking Open-Vocabulary Vision Transformer
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kim%2C+D">Dahun Kim</a>, 
<a href="/search/cs?searchtype=author&query=Angelova%2C+A">Anelia Angelova</a>, 
<a href="/search/cs?searchtype=author&query=Kuo%2C+W">Weicheng Kuo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to ICCV 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">We present Contrastive Feature Masking Vision Transformer (CFM-ViT) - an
image-text pretraining methodology that achieves simultaneous learning of
image- and region-level representation for open-vocabulary object detection
(OVD). Our approach combines the masked autoencoder (MAE) objective into the
contrastive learning objective to improve the representation for localization
tasks. Unlike standard MAE, we perform reconstruction in the joint image-text
embedding space, rather than the pixel space as is customary with the classical
MAE method, which causes the model to better learn region-level semantics.
Moreover, we introduce Positional Embedding Dropout (PED) to address scale
variation between image-text pretraining and detection finetuning by randomly
dropping out the positional embeddings during pretraining. PED improves
detection performance and enables the use of a frozen ViT backbone as a region
classifier, preventing the forgetting of open-vocabulary knowledge during
detection finetuning. On LVIS open-vocabulary detection benchmark, CFM-ViT
achieves a state-of-the-art 33.9 AP$r$, surpassing the best approach by 7.6
points and achieves better zero-shot detection transfer. Finally, CFM-ViT
acquires strong image-level representation, outperforming the state of the art
on 8 out of 12 metrics on zero-shot image-text retrieval benchmarks.
</p>
</div>
</dd>
<dt><a name="item52">[52]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.00776" title="Abstract">arXiv:2309.00776</a> [<a href="/pdf/2309.00776" title="Download PDF">pdf</a>, <a href="/format/2309.00776" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Are Current CCPA Compliant Banners Conveying User&#x27;s Desired Opt-Out  Decisions? An Empirical Study of Cookie Consent Banners
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mazumdar%2C+T">Torsha Mazumdar</a>, 
<a href="/search/cs?searchtype=author&query=Timko%2C+D">Daniel Timko</a>, 
<a href="/search/cs?searchtype=author&query=Rahman%2C+M+L">Muhammad Lutfor Rahman</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">The California Consumer Privacy Act (CCPA) secures the right to Opt-Out for
consumers in California. However, websites may implement complex consent
mechanisms that potentially do not capture the user's true choices. We
investigated the user choices in Cookie Consent Banner of US residents, the
plurality of whom were from California, through an online experiment of 257
participants and compared the results with how they perceived to these Cookie
Consent Banner. Our results show a contradiction between how often participants
self-report their Opt-Out rates and their actual Opt-Out rate when interacting
with a complex, CCPA-compliant website. This discrepancy expands the context
with which modern websites may implement the CCPA without providing users
sufficient information or instruction on how to successfully Opt-Out. We
further elaborate on how US residents respond to and perceive the GDPR-like
Opt-In model. Our results indicate that even though very few consumers actually
exercised their right to Opt-Out, the majority of US consumers desire more
transparent privacy policies that the current implementation of CCPA on
websites lacks.
</p>
</div>
</dd>
<dt><a name="item53">[53]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.00777" title="Abstract">arXiv:2309.00777</a> [<a href="/pdf/2309.00777" title="Download PDF">pdf</a>, <a href="/format/2309.00777" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards High-Frequency Tracking and Fast Edge-Aware Optimization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bapat%2C+A">Akash Bapat</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> PhD thesis
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">This dissertation advances the state of the art for AR/VR tracking systems by
increasing the tracking frequency by orders of magnitude and proposes an
efficient algorithm for the problem of edge-aware optimization.
<br />AR/VR is a natural way of interacting with computers, where the physical and
digital worlds coexist. We are on the cusp of a radical change in how humans
perform and interact with computing. Humans are sensitive to small
misalignments between the real and the virtual world, and tracking at
kilo-Hertz frequencies becomes essential. Current vision-based systems fall
short, as their tracking frequency is implicitly limited by the frame-rate of
the camera. This thesis presents a prototype system which can track at orders
of magnitude higher than the state-of-the-art methods using multiple commodity
cameras. The proposed system exploits characteristics of the camera
traditionally considered as flaws, namely rolling shutter and radial
distortion. The experimental evaluation shows the effectiveness of the method
for various degrees of motion.
<br />Furthermore, edge-aware optimization is an indispensable tool in the computer
vision arsenal for accurate filtering of depth-data and image-based rendering,
which is increasingly being used for content creation and geometry processing
for AR/VR. As applications increasingly demand higher resolution and speed,
there exists a need to develop methods that scale accordingly. This
dissertation proposes such an edge-aware optimization framework which is
efficient, accurate, and algorithmically scales well, all of which are much
desirable traits not found jointly in the state of the art. The experiments
show the effectiveness of the framework in a multitude of computer vision tasks
such as computational photography and stereo.
</p>
</div>
</dd>
<dt><a name="item54">[54]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.00779" title="Abstract">arXiv:2309.00779</a> [<a href="/pdf/2309.00779" title="Download PDF">pdf</a>, <a href="/format/2309.00779" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Value Kaleidoscope: Engaging AI with Pluralistic Human Values, Rights,  and Duties
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sorensen%2C+T">Taylor Sorensen</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+L">Liwei Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Hwang%2C+J">Jena Hwang</a>, 
<a href="/search/cs?searchtype=author&query=Levine%2C+S">Sydney Levine</a>, 
<a href="/search/cs?searchtype=author&query=Pyatkin%2C+V">Valentina Pyatkin</a>, 
<a href="/search/cs?searchtype=author&query=West%2C+P">Peter West</a>, 
<a href="/search/cs?searchtype=author&query=Dziri%2C+N">Nouha Dziri</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+X">Ximing Lu</a>, 
<a href="/search/cs?searchtype=author&query=Rao%2C+K">Kavel Rao</a>, 
<a href="/search/cs?searchtype=author&query=Bhagavatula%2C+C">Chandra Bhagavatula</a>, 
<a href="/search/cs?searchtype=author&query=Sap%2C+M">Maarten Sap</a>, 
<a href="/search/cs?searchtype=author&query=Tasioulas%2C+J">John Tasioulas</a>, 
<a href="/search/cs?searchtype=author&query=Choi%2C+Y">Yejin Choi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Human values are crucial to human decision-making. Value pluralism is the
view that multiple correct values may be held in tension with one another
(e.g., when considering lying to a friend to protect their feelings, how does
one balance honesty with friendship?). As statistical learners, AI systems fit
to averages by default, washing out these potentially irreducible value
conflicts. To improve AI systems to better reflect value pluralism, the
first-order challenge is to explore the extent to which AI systems can model
pluralistic human values, rights, and duties as well as their interaction.
<br />We introduce ValuePrism, a large-scale dataset of 218k values, rights, and
duties connected to 31k human-written situations. ValuePrism's contextualized
values are generated by GPT-4 and deemed high-quality by human annotators 91%
of the time. We conduct a large-scale study with annotators across diverse
social and demographic backgrounds to try to understand whose values are
represented.
<br />With ValuePrism, we build Kaleido, an open, light-weight, and structured
language-based multi-task model that generates, explains, and assesses the
relevance and valence (i.e., support or oppose) of human values, rights, and
duties within a specific context. Humans prefer the sets of values output by
our system over the teacher GPT-4, finding them more accurate and with broader
coverage. In addition, we demonstrate that Kaleido can help explain variability
in human decision-making by outputting contrasting values. Finally, we show
that Kaleido's representations transfer to other philosophical frameworks and
datasets, confirming the benefit of an explicit, modular, and interpretable
approach to value pluralism. We hope that our work will serve as a step to
making more explicit the implicit values behind human decision-making and to
steering AI systems to make decisions that are more in accordance with them.
</p>
</div>
</dd>
<dt><a name="item55">[55]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.00781" title="Abstract">arXiv:2309.00781</a> [<a href="/pdf/2309.00781" title="Download PDF">pdf</a>, <a href="/format/2309.00781" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Structured Radial Basis Function Network: Modelling Diversity for  Multiple Hypotheses Prediction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dominguez%2C+A+R">Alejandro Rodriguez Dominguez</a>, 
<a href="/search/cs?searchtype=author&query=Shahzad%2C+M">Muhammad Shahzad</a>, 
<a href="/search/cs?searchtype=author&query=Hong%2C+X">Xia Hong</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 63 Pages, 40 Figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
<p class="mathjax">Multi-modal regression is important in forecasting nonstationary processes or
with a complex mixture of distributions. It can be tackled with multiple
hypotheses frameworks but with the difficulty of combining them efficiently in
a learning model. A Structured Radial Basis Function Network is presented as an
ensemble of multiple hypotheses predictors for regression problems. The
predictors are regression models of any type that can form centroidal Voronoi
tessellations which are a function of their losses during training. It is
proved that this structured model can efficiently interpolate this tessellation
and approximate the multiple hypotheses target distribution and is equivalent
to interpolating the meta-loss of the predictors, the loss being a zero set of
the interpolation error. This model has a fixed-point iteration algorithm
between the predictors and the centers of the basis functions. Diversity in
learning can be controlled parametrically by truncating the tessellation
formation with the losses of individual predictors. A closed-form solution with
least-squares is presented, which to the authors knowledge, is the fastest
solution in the literature for multiple hypotheses and structured predictions.
Superior generalization performance and computational efficiency is achieved
using only two-layer neural networks as predictors controlling diversity as a
key component of success. A gradient-descent approach is introduced which is
loss-agnostic regarding the predictors. The expected value for the loss of the
structured model with Gaussian basis functions is computed, finding that
correlation between predictors is not an appropriate tool for diversification.
The experiments show outperformance with respect to the top competitors in the
literature.
</p>
</div>
</dd>
<dt><a name="item56">[56]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.00783" title="Abstract">arXiv:2309.00783</a> [<a href="/pdf/2309.00783" title="Download PDF">pdf</a>, <a href="/format/2309.00783" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Diffusion Modeling with Domain-conditioned Prior Guidance for  Accelerated MRI and qMRI Reconstruction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bian%2C+W">Wanyu Bian</a>, 
<a href="/search/cs?searchtype=author&query=Jang%2C+A">Albert Jang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+F">Fang Liu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">This study introduces a novel approach for image reconstruction based on a
diffusion model conditioned on the native data domain. Our method is applied to
multi-coil MRI and quantitative MRI reconstruction, leveraging the
domain-conditioned diffusion model within the frequency and parameter domains.
The prior MRI physics are used as embeddings in the diffusion model, enforcing
data consistency to guide the training and sampling process, characterizing MRI
k-space encoding in MRI reconstruction, and leveraging MR signal modeling for
qMRI reconstruction. Furthermore, a gradient descent optimization is
incorporated into the diffusion steps, enhancing feature learning and improving
denoising. The proposed method demonstrates a significant promise, particularly
for reconstructing images at high acceleration factors. Notably, it maintains
great reconstruction accuracy and efficiency for static and quantitative MRI
reconstruction across diverse anatomical structures. Beyond its immediate
applications, this method provides potential generalization capability, making
it adaptable to inverse problems across various domains.
</p>
</div>
</dd>
<dt><a name="item57">[57]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.00785" title="Abstract">arXiv:2309.00785</a> [<a href="/pdf/2309.00785" title="Download PDF">pdf</a>, <a href="/format/2309.00785" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Weak Boundary Conditions for Lagrangian Shock Hydrodynamics: A  High-Order Finite Element Implementation on Curved Boundaries
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Atallah%2C+N+M">Nabil M. Atallah</a>, 
<a href="/search/math?searchtype=author&query=Tomov%2C+V+Z">Vladimir Z. Tomov</a>, 
<a href="/search/math?searchtype=author&query=Scovazzi%2C+G">Guglielmo Scovazzi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">We propose a new Nitsche-type approach for weak enforcement of normal
velocity boundary conditions for a Lagrangian discretization of the
compressible shock-hydrodynamics equations using high-order finite elements on
curved boundaries. Specifically, the variational formulation is appropriately
modified to enforce free-slip wall boundary conditions, without perturbing the
structure of the function spaces used to represent the solution, with a
considerable simplification with respect to traditional approaches. Total
energy is conserved and the resulting mass matrices are constant in time. The
robustness and accuracy of the proposed method are validated with an extensive
set of tests involving nontrivial curved boundaries.
</p>
</div>
</dd>
<dt><a name="item58">[58]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.00787" title="Abstract">arXiv:2309.00787</a> [<a href="/pdf/2309.00787" title="Download PDF">pdf</a>, <a href="/format/2309.00787" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Online Targetless Radar-Camera Extrinsic Calibration Based on the Common  Features of Radar and Camera
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cheng%2C+L">Lei Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+S">Siyang Cao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Image and Video Processing (eess.IV); Signal Processing (eess.SP); Systems and Control (eess.SY)

</div>
<p class="mathjax">Sensor fusion is essential for autonomous driving and autonomous robots, and
radar-camera fusion systems have gained popularity due to their complementary
sensing capabilities. However, accurate calibration between these two sensors
is crucial to ensure effective fusion and improve overall system performance.
Calibration involves intrinsic and extrinsic calibration, with the latter being
particularly important for achieving accurate sensor fusion. Unfortunately,
many target-based calibration methods require complex operating procedures and
well-designed experimental conditions, posing challenges for researchers
attempting to reproduce the results. To address this issue, we introduce a
novel approach that leverages deep learning to extract a common feature from
raw radar data (i.e., Range-Doppler-Angle data) and camera images. Instead of
explicitly representing these common features, our method implicitly utilizes
these common features to match identical objects from both data sources.
Specifically, the extracted common feature serves as an example to demonstrate
an online targetless calibration method between the radar and camera systems.
The estimation of the extrinsic transformation matrix is achieved through this
feature-based approach. To enhance the accuracy and robustness of the
calibration, we apply the RANSAC and Levenberg-Marquardt (LM) nonlinear
optimization algorithm for deriving the matrix. Our experiments in the real
world demonstrate the effectiveness and accuracy of our proposed method.
</p>
</div>
</dd>
<dt><a name="item59">[59]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.00788" title="Abstract">arXiv:2309.00788</a> [<a href="/pdf/2309.00788" title="Download PDF">pdf</a>, <a href="/ps/2309.00788" title="Download PostScript">ps</a>, <a href="/format/2309.00788" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Spectral Barron space and deep neural network approximation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Liao%2C+Y">Yulei Liao</a>, 
<a href="/search/math?searchtype=author&query=Ming%2C+P">Pingbing Ming</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 30 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">We prove the sharp embedding between the spectral Barron space and the Besov
space. Given the spectral Barron space as the target function space, we prove a
dimension-free result that if the neural network contains $L$ hidden layers
with $N$ units per layer, then the upper and lower bounds of the
$L^2$-approximation error are $\mathcal{O}(N^{-sL})$ with $0 &lt; sL\le 1/2$,
where $s$ is the smoothness index of the spectral Barron space.
</p>
</div>
</dd>
<dt><a name="item60">[60]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.00789" title="Abstract">arXiv:2309.00789</a> [<a href="/pdf/2309.00789" title="Download PDF">pdf</a>, <a href="/format/2309.00789" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LinkTransformer: A Unified Package for Record Linkage with Transformer  Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Arora%2C+A">Abhishek Arora</a>, 
<a href="/search/cs?searchtype=author&query=Dell%2C+M">Melissa Dell</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Linking information across sources is fundamental to a variety of analyses in
social science, business, and government. While large language models (LLMs)
offer enormous promise for improving record linkage in noisy datasets, in many
domains approximate string matching packages in popular softwares such as R and
Stata remain predominant. These packages have clean, simple interfaces and can
be easily extended to a diversity of languages. Our open-source package
LinkTransformer aims to extend the familiarity and ease-of-use of popular
string matching methods to deep learning. It is a general purpose package for
record linkage with transformer LLMs that treats record linkage as a text
retrieval problem. At its core is an off-the-shelf toolkit for applying
transformer models to record linkage with four lines of code. LinkTransformer
contains a rich repository of pre-trained transformer semantic similarity
models for multiple languages and supports easy integration of any transformer
language model from Hugging Face or OpenAI. It supports standard functionality
such as blocking and linking on multiple noisy fields. LinkTransformer APIs
also perform other common text data processing tasks, e.g., aggregation, noisy
de-duplication, and translation-free cross-lingual linkage. Importantly,
LinkTransformer also contains comprehensive tools for efficient model tuning,
to facilitate different levels of customization when off-the-shelf models do
not provide the required accuracy. Finally, to promote reusability,
reproducibility, and extensibility, LinkTransformer makes it easy for users to
contribute their custom-trained models to its model hub. By combining
transformer language models with intuitive APIs that will be familiar to many
users of popular string matching packages, LinkTransformer aims to democratize
the benefits of LLMs among those who may be less familiar with deep learning
frameworks.
</p>
</div>
</dd>
<dt><a name="item61">[61]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.00790" title="Abstract">arXiv:2309.00790</a> [<a href="/pdf/2309.00790" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PFL-LSTR: A privacy-preserving framework for driver intention inference  based on in-vehicle and out-vehicle information
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Du%2C+R">Runjia Du</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+P">Pei Li</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+S">Sikai Chen</a>, 
<a href="/search/cs?searchtype=author&query=Labi%2C+S">Samuel Labi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted for presentation only at the 2024 Annual Meeting of the Transportation Research Board
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Intelligent vehicle anticipation of the movement intentions of other drivers
can reduce collisions. Typically, when a human driver of another vehicle
(referred to as the target vehicle) engages in specific behaviors such as
checking the rearview mirror prior to lane change, a valuable clue is therein
provided on the intentions of the target vehicle's driver. Furthermore, the
target driver's intentions can be influenced and shaped by their driving
environment. For example, if the target vehicle is too close to a leading
vehicle, it may renege the lane change decision. On the other hand, a following
vehicle in the target lane is too close to the target vehicle could lead to its
reversal of the decision to change lanes. Knowledge of such intentions of all
vehicles in a traffic stream can help enhance traffic safety. Unfortunately,
such information is often captured in the form of images/videos. Utilization of
personally identifiable data to train a general model could violate user
privacy. Federated Learning (FL) is a promising tool to resolve this conundrum.
FL efficiently trains models without exposing the underlying data. This paper
introduces a Personalized Federated Learning (PFL) model embedded a long
short-term transformer (LSTR) framework. The framework predicts drivers'
intentions by leveraging in-vehicle videos (of driver movement, gestures, and
expressions) and out-of-vehicle videos (of the vehicle's surroundings -
frontal/rear areas). The proposed PFL-LSTR framework is trained and tested
through real-world driving data collected from human drivers at Interstate 65
in Indiana. The results suggest that the PFL-LSTR exhibits high adaptability
and high precision, and that out-of-vehicle information (particularly, the
driver's rear-mirror viewing actions) is important because it helps reduce
false positives and thereby enhances the precision of driver intention
inference.
</p>
</div>
</dd>
<dt><a name="item62">[62]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.00792" title="Abstract">arXiv:2309.00792</a> [<a href="/pdf/2309.00792" title="Download PDF">pdf</a>, <a href="/ps/2309.00792" title="Download PostScript">ps</a>, <a href="/format/2309.00792" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Delay-Doppler Alignment Modulation for Spatially Sparse Massive MIMO  Communication
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lu%2C+H">Haiquan Lu</a>, 
<a href="/search/cs?searchtype=author&query=Zeng%2C+Y">Yong Zeng</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 15 pages, 12 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">Delay alignment modulation (DAM) is an emerging technique for achieving
inter-symbol interference (ISI)-free wideband communications using
spatial-delay processing, without relying on channel equalization or
multi-carrier transmission. However, existing works on DAM only consider
multiple-input single-output (MISO) communication systems and assume
time-invariant channels. In this paper, by extending DAM to time-variant
frequency-selective multiple-input multiple-output (MIMO) channels, we propose
a novel technique termed \emph{delay-Doppler alignment modulation} (DDAM).
Specifically, by leveraging \emph{delay-Doppler compensation} and
\emph{path-based beamforming}, the Doppler effect of each multi-path can be
eliminated and all multi-path signal components may reach the receiver
concurrently and constructively. We first show that by applying path-based
zero-forcing (ZF) precoding and receive combining, DDAM can transform the
original time-variant frequency-selective channels into time-invariant ISI-free
channels. The necessary and/or sufficient conditions to achieve such a
transformation are derived. Then an asymptotic analysis is provided by showing
that when the number of base station (BS) antennas is much larger than that of
channel paths, DDAM enables time-invariant ISI-free channels with the simple
delay-Doppler compensation and path-based maximal-ratio transmission (MRT)
beamforming. Furthermore, for the general DDAM design with some tolerable ISI,
the path-based transmit precoding and receive combining matrices are optimized
to maximize the spectral efficiency. Numerical results are provided to compare
the proposed DDAM technique with various benchmarking schemes, including
MIMO-orthogonal time frequency space (OTFS), MIMO-orthogonal frequency-division
multiplexing (OFDM) without or with carrier frequency offset (CFO)
compensation, and beam alignment along the dominant path.
</p>
</div>
</dd>
<dt><a name="item63">[63]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.00794" title="Abstract">arXiv:2309.00794</a> [<a href="/pdf/2309.00794" title="Download PDF">pdf</a>, <a href="/format/2309.00794" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FastPoseGait: A Toolbox and Benchmark for Efficient Pose-based Gait  Recognition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Meng%2C+S">Shibei Meng</a>, 
<a href="/search/cs?searchtype=author&query=Fu%2C+Y">Yang Fu</a>, 
<a href="/search/cs?searchtype=author&query=Hou%2C+S">Saihui Hou</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+C">Chunshui Cao</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xu Liu</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+Y">Yongzhen Huang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 4 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">We present FastPoseGait, an open-source toolbox for pose-based gait
recognition based on PyTorch. Our toolbox supports a set of cutting-edge
pose-based gait recognition algorithms and a variety of related benchmarks.
Unlike other pose-based projects that focus on a single algorithm, FastPoseGait
integrates several state-of-the-art (SOTA) algorithms under a unified
framework, incorporating both the latest advancements and best practices to
ease the comparison of effectiveness and efficiency. In addition, to promote
future research on pose-based gait recognition, we provide numerous pre-trained
models and detailed benchmark results, which offer valuable insights and serve
as a reference for further investigations. By leveraging the highly modular
structure and diverse methods offered by FastPoseGait, researchers can quickly
delve into pose-based gait recognition and promote development in the field. In
this paper, we outline various features of this toolbox, aiming that our
toolbox and benchmarks can further foster collaboration, facilitate
reproducibility, and encourage the development of innovative algorithms for
pose-based gait recognition. FastPoseGait is available at
https://github.com//BNU-IVC/FastPoseGait and is actively maintained. We will
continue updating this report as we add new features.
</p>
</div>
</dd>
<dt><a name="item64">[64]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.00796" title="Abstract">arXiv:2309.00796</a> [<a href="/pdf/2309.00796" title="Download PDF">pdf</a>, <a href="/format/2309.00796" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AttT2M: Text-Driven Human Motion Generation with Multi-Perspective  Attention Mechanism
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhong%2C+C">Chongyang Zhong</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+L">Lei Hu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zihao Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Xia%2C+S">Shihong Xia</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> IEEE International Conference on Computer Vision 2023, 9 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Generating 3D human motion based on textual descriptions has been a research
focus in recent years. It requires the generated motion to be diverse, natural,
and conform to the textual description. Due to the complex spatio-temporal
nature of human motion and the difficulty in learning the cross-modal
relationship between text and motion, text-driven motion generation is still a
challenging problem. To address these issues, we propose \textbf{AttT2M}, a
two-stage method with multi-perspective attention mechanism: \textbf{body-part
attention} and \textbf{global-local motion-text attention}. The former focuses
on the motion embedding perspective, which means introducing a body-part
spatio-temporal encoder into VQ-VAE to learn a more expressive discrete latent
space. The latter is from the cross-modal perspective, which is used to learn
the sentence-level and word-level motion-text cross-modal relationship. The
text-driven motion is finally generated with a generative transformer.
Extensive experiments conducted on HumanML3D and KIT-ML demonstrate that our
method outperforms the current state-of-the-art works in terms of qualitative
and quantitative evaluation, and achieve fine-grained synthesis and
action2motion. Our code is in https://github.com/ZcyMonkey/AttT2M
</p>
</div>
</dd>
<dt><a name="item65">[65]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.00799" title="Abstract">arXiv:2309.00799</a> [<a href="/pdf/2309.00799" title="Download PDF">pdf</a>, <a href="/format/2309.00799" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An Elementary Construction of Modified Hamiltonians and Modified  Measures of 2D Kahan Maps
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Gubbiotti%2C+G">Giorgio Gubbiotti</a>, 
<a href="/search/math?searchtype=author&query=McLaren%2C+D">David McLaren</a>, 
<a href="/search/math?searchtype=author&query=Quispel%2C+R">Reinout Quispel</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 30 pages, 7 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">We show how to construct in an elementary way the invariant of the KHK
discretisation of a cubic Hamiltonian system in two dimensions. That is, we
show that this invariant is expressible as the product of the ratios of affine
polynomials defining the prolongation of the three parallel sides of a hexagon.
On the vertices of such a hexagon lie the indeterminacy points of the KHK map.
This result is obtained analysing the structure of the singular fibres of the
known invariant. We apply this construction to several examples, and we prove
that a similar result holds true for a case outside the hypotheses of the main
theorem, leading us to conjecture that further extensions are possible.
</p>
</div>
</dd>
<dt><a name="item66">[66]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.00801" title="Abstract">arXiv:2309.00801</a> [<a href="/pdf/2309.00801" title="Download PDF">pdf</a>, <a href="/format/2309.00801" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Accelerating LSTM-based High-Rate Dynamic System Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kabir%2C+E">Ehsan Kabir</a>, 
<a href="/search/cs?searchtype=author&query=Coble%2C+D">Daniel Coble</a>, 
<a href="/search/cs?searchtype=author&query=Satme%2C+J+N">Joud N. Satme</a>, 
<a href="/search/cs?searchtype=author&query=Downey%2C+A+R+J">Austin R.J. Downey</a>, 
<a href="/search/cs?searchtype=author&query=Bakos%2C+J+D">Jason D. Bakos</a>, 
<a href="/search/cs?searchtype=author&query=Andrews%2C+D">David Andrews</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+M">Miaoqing Huang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at 33rd International Conference on Field-Programmable Logic and Applications (FPL)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Hardware Architecture (cs.AR)</span>

</div>
<p class="mathjax">In this paper, we evaluate the use of a trained Long Short-Term Memory (LSTM)
network as a surrogate for a Euler-Bernoulli beam model, and then we describe
and characterize an FPGA-based deployment of the model for use in real-time
structural health monitoring applications. The focus of our efforts is the
DROPBEAR (Dynamic Reproduction of Projectiles in Ballistic Environments for
Advanced Research) dataset, which was generated as a benchmark for the study of
real-time structural modeling applications. The purpose of DROPBEAR is to
evaluate models that take vibration data as input and give the initial
conditions of the cantilever beam on which the measurements were taken as
output. DROPBEAR is meant to serve an exemplar for emerging high-rate "active
structures" that can be actively controlled with feedback latencies of less
than one microsecond. Although the Euler-Bernoulli beam model is a well-known
solution to this modeling problem, its computational cost is prohibitive for
the time scales of interest. It has been previously shown that a properly
structured LSTM network can achieve comparable accuracy with less workload, but
achieving sub-microsecond model latency remains a challenge. Our approach is to
deploy the LSTM optimized specifically for latency on FPGA. We designed the
model using both high-level synthesis (HLS) and hardware description language
(HDL). The lowest latency of 1.42 $\mu$S and the highest throughput of 7.87
Gops/s were achieved on Alveo U55C platform for HDL design.
</p>
</div>
</dd>
<dt><a name="item67">[67]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.00802" title="Abstract">arXiv:2309.00802</a> [<a href="/pdf/2309.00802" title="Download PDF">pdf</a>, <a href="/format/2309.00802" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deep Learning and Inverse Problems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mohammad-Djafari%2C+A">Ali Mohammad-Djafari</a>, 
<a href="/search/cs?searchtype=author&query=Chu%2C+N">Ning Chu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+L">Li Wang</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+L">Liang Yu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: text overlap with <a href="/abs/2308.15492">arXiv:2308.15492</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Machine Learning (ML) methods and tools have gained great success in many
data, signal, image and video processing tasks, such as classification,
clustering, object detection, semantic segmentation, language processing,
Human-Machine interface, etc. In computer vision, image and video processing,
these methods are mainly based on Neural Networks (NN) and in particular
Convolutional NN (CNN), and more generally Deep NN. Inverse problems arise
anywhere we have indirect measurement. As, in general, those inverse problems
are ill-posed, to obtain satisfactory solutions for them needs prior
information. Different regularization methods have been proposed, where the
problem becomes the optimization of a criterion with a likelihood term and a
regularization term. The main difficulty, however, in great dimensional real
applications, remains the computational cost. Using NN, and in particular Deep
Learning (DL) surrogate models and approximate computation, can become very
helpful. In this work, we focus on NN and DL particularly adapted for inverse
problems. We consider two cases: First the case where the forward operator is
known and used as physics constraint, the second more general data driven DL
methods.
</p>
</div>
</dd>
<dt><a name="item68">[68]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.00803" title="Abstract">arXiv:2309.00803</a> [<a href="/pdf/2309.00803" title="Download PDF">pdf</a>, <a href="/format/2309.00803" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Value-oriented Renewable Energy Forecasting for Coordinated Energy  Dispatch Problems at Two Stages
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Zhang%2C+Y">Yufan Zhang</a>, 
<a href="/search/eess?searchtype=author&query=Jia%2C+M">Mengshuo Jia</a>, 
<a href="/search/eess?searchtype=author&query=Wen%2C+H">Honglin Wen</a>, 
<a href="/search/eess?searchtype=author&query=Shi%2C+Y">Yuanyuan Shi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> submitted to European Journal of Operational Research
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">Energy forecasting is deemed an essential task in power system operations.
Operators usually issue forecasts and leverage them to schedule energy dispatch
ahead of time (referred to as the 'predict, then optimize' paradigm). However,
forecast models are often developed via optimizing statistical scores while
overlooking the value of the forecasts in operation. In this paper, we design a
value-oriented point forecasting approach for energy dispatch problems with
renewable energy sources (RESs). At the training phase, this approach
incorporates forecasting with day-ahead/real-time operations for power systems,
thereby achieving reduced operation costs of the two stages. To this end, we
formulate the forecast model parameter estimation as a bilevel program at the
training phase, where the lower level solves the day-ahead and real-time energy
dispatch problems, with the forecasts as parameters; the optimal solutions of
the lower level are then returned to the upper level, which optimizes the model
parameters given the contextual information and minimizes the expected
operation cost of the two stages. Under mild assumptions, we propose a novel
iterative solution strategy for this bilevel program. Under such an iterative
scheme, we show that the upper level objective is locally linear regarding the
forecast model output, and can act as the loss function. Numerical experiments
demonstrate that, compared to commonly used point forecasting methods, the
forecasts obtained by the proposed approach result in lower operation costs in
the subsequent energy dispatch problems. Meanwhile, the proposed approach is
more computationally efficient than traditional two-stage stochastic program.
</p>
</div>
</dd>
<dt><a name="item69">[69]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.00810" title="Abstract">arXiv:2309.00810</a> [<a href="/pdf/2309.00810" title="Download PDF">pdf</a>, <a href="/format/2309.00810" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> RenAIssance: A Survey into AI Text-to-Image Generation in the Era of  Large Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bie%2C+F">Fengxiang Bie</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yibo Yang</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Z">Zhongzhu Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Ghanem%2C+A">Adam Ghanem</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+M">Minjia Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Yao%2C+Z">Zhewei Yao</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+X">Xiaoxia Wu</a>, 
<a href="/search/cs?searchtype=author&query=Holmes%2C+C">Connor Holmes</a>, 
<a href="/search/cs?searchtype=author&query=Golnari%2C+P">Pareesa Golnari</a>, 
<a href="/search/cs?searchtype=author&query=Clifton%2C+D+A">David A. Clifton</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+Y">Yuxiong He</a>, 
<a href="/search/cs?searchtype=author&query=Tao%2C+D">Dacheng Tao</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+S+L">Shuaiwen Leon Song</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Text-to-image generation (TTI) refers to the usage of models that could
process text input and generate high fidelity images based on text
descriptions. Text-to-image generation using neural networks could be traced
back to the emergence of Generative Adversial Network (GAN), followed by the
autoregressive Transformer. Diffusion models are one prominent type of
generative model used for the generation of images through the systematic
introduction of noises with repeating steps. As an effect of the impressive
results of diffusion models on image synthesis, it has been cemented as the
major image decoder used by text-to-image models and brought text-to-image
generation to the forefront of machine-learning (ML) research. In the era of
large models, scaling up model size and the integration with large language
models have further improved the performance of TTI models, resulting the
generation result nearly indistinguishable from real-world images,
revolutionizing the way we retrieval images. Our explorative study has
incentivised us to think that there are further ways of scaling text-to-image
models with the combination of innovative model architectures and prediction
enhancement techniques. We have divided the work of this survey into five main
sections wherein we detail the frameworks of major literature in order to delve
into the different types of text-to-image generation methods. Following this we
provide a detailed comparison and critique of these methods and offer possible
pathways of improvement for future work. In the future work, we argue that TTI
development could yield impressive productivity improvements for creation,
particularly in the context of the AIGC era, and could be extended to more
complex tasks such as video generation and 3D generation.
</p>
</div>
</dd>
<dt><a name="item70">[70]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.00811" title="Abstract">arXiv:2309.00811</a> [<a href="/pdf/2309.00811" title="Download PDF">pdf</a>, <a href="/ps/2309.00811" title="Download PostScript">ps</a>, <a href="/format/2309.00811" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A double-decomposition based parallel exact algorithm for the feedback  length minimization problem
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shang%2C+Z">Zhen Shang</a> (1), 
<a href="/search/cs?searchtype=author&query=Hao%2C+J">Jin-Kao Hao</a> (2), 
<a href="/search/cs?searchtype=author&query=Ma%2C+F">Fei Ma</a> (1) ((1) School of Economics and Management, Chang&#x27;an University, China, (2) LERIA, Universit&#xe9; d&#x27;Angers, Angers, France)
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This paper has been accepted by PeerJ Computer Science on August 28, 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>

</div>
<p class="mathjax">Product development projects usually contain many interrelated activities
with complex information dependences, which induce activity rework, project
delay and cost overrun. To reduce negative impacts, scheduling interrelated
activities in an appropriate sequence is an important issue for project
managers. This study develops a double-decomposition based parallel
branch-and-prune algorithm, to determine the optimal activity sequence that
minimizes the total feedback length (FLMP). This algorithm decomposes FLMP from
two perspectives, which enables the use of all available computing resources to
solve subproblems concurrently. In addition, we propose a result-compression
strategy and a hash-address strategy to enhance this algorithm. Experimental
results indicate that our algorithm can find the optimal sequence for FLMP up
to 27 activities within 1 hour, and outperforms state of the art exact
algorithms.
</p>
</div>
</dd>
<dt><a name="item71">[71]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.00814" title="Abstract">arXiv:2309.00814</a> [<a href="/pdf/2309.00814" title="Download PDF">pdf</a>, <a href="/ps/2309.00814" title="Download PostScript">ps</a>, <a href="/format/2309.00814" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Bypassing the Simulator: Near-Optimal Adversarial Linear Contextual  Bandits
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+H">Haolin Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+C">Chen-Yu Wei</a>, 
<a href="/search/cs?searchtype=author&query=Zimmert%2C+J">Julian Zimmert</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Machine Learning (stat.ML)

</div>
<p class="mathjax">We consider the adversarial linear contextual bandit problem, where the loss
vectors are selected fully adversarially and the per-round action set (i.e. the
context) is drawn from a fixed distribution. Existing methods for this problem
either require access to a simulator to generate free i.i.d. contexts, achieve
a sub-optimal regret no better than $\widetilde{O}(T^{\frac{5}{6}})$, or are
computationally inefficient. We greatly improve these results by achieving a
regret of $\widetilde{O}(\sqrt{T})$ without a simulator, while maintaining
computational efficiency when the action set in each round is small. In the
special case of sleeping bandits with adversarial loss and stochastic arm
availability, our result answers affirmatively the open question by Saha et al.
[2020] on whether there exists a polynomial-time algorithm with
$poly(d)\sqrt{T}$ regret. Our approach naturally handles the case where the
loss is linear up to an additive misspecification error, and our regret shows
near-optimal dependence on the magnitude of the error.
</p>
</div>
</dd>
<dt><a name="item72">[72]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.00816" title="Abstract">arXiv:2309.00816</a> [<a href="/pdf/2309.00816" title="Download PDF">pdf</a>, <a href="/format/2309.00816" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Trustworthiness-Driven Graph Convolutional Networks for Signed Network  Embedding
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kim%2C+M">Min-Jeong Kim</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+Y">Yeon-Chang Lee</a>, 
<a href="/search/cs?searchtype=author&query=Kang%2C+D+Y">David Y. Kang</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+S">Sang-Wook Kim</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 8 figures, 9 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">The problem of representing nodes in a signed network as low-dimensional
vectors, known as signed network embedding (SNE), has garnered considerable
attention in recent years. While several SNE methods based on graph
convolutional networks (GCN) have been proposed for this problem, we point out
that they significantly rely on the assumption that the decades-old balance
theory always holds in the real-world. To address this limitation, we propose a
novel GCN-based SNE approach, named as TrustSGCN, which corrects for incorrect
embedding propagation in GCN by utilizing the trustworthiness on edge signs for
high-order relationships inferred by the balance theory. The proposed approach
consists of three modules: (M1) generation of each node's extended ego-network;
(M2) measurement of trustworthiness on edge signs; and (M3)
trustworthiness-aware propagation of embeddings. Furthermore, TrustSGCN learns
the node embeddings by leveraging two well-known societal theories, i.e.,
balance and status. The experiments on four real-world signed network datasets
demonstrate that TrustSGCN consistently outperforms five state-of-the-art
GCN-based SNE methods. The code is available at
https://github.com/kmj0792/TrustSGCN.
</p>
</div>
</dd>
<dt><a name="item73">[73]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.00817" title="Abstract">arXiv:2309.00817</a> [<a href="/pdf/2309.00817" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Soil Image Segmentation Based on Mask R-CNN
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yida Chen</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+K">Kang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Xin%2C+Y">Yi Xin</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+X">Xinru Zhao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 4 pages, 5 figures, Published in 2023 3rd International Conference on Consumer Electronics and Computer Engineering
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> 2023 3rd International Conference on Consumer Electronics and
  Computer Engineering (ICCECE)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">The complex background in the soil image collected in the field natural
environment will affect the subsequent soil image recognition based on machine
vision. Segmenting the soil center area from the soil image can eliminate the
influence of the complex background, which is an important preprocessing work
for subsequent soil image recognition. For the first time, the deep learning
method was applied to soil image segmentation, and the Mask R-CNN model was
selected to complete the positioning and segmentation of soil images. Construct
a soil image dataset based on the collected soil images, use the EISeg
annotation tool to mark the soil area as soil, and save the annotation
information; train the Mask R-CNN soil image instance segmentation model. The
trained model can obtain accurate segmentation results for soil images, and can
show good performance on soil images collected in different environments; the
trained instance segmentation model has a loss value of 0.1999 in the training
set, and the mAP of the validation set segmentation (IoU=0.5) is 0.8804, and it
takes only 0.06s to complete image segmentation based on GPU acceleration,
which can meet the real-time segmentation and detection of soil images in the
field under natural conditions. You can get our code in the Conclusions. The
homepage is https://github.com/YidaMyth.
</p>
</div>
</dd>
<dt><a name="item74">[74]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.00819" title="Abstract">arXiv:2309.00819</a> [<a href="/pdf/2309.00819" title="Download PDF">pdf</a>, <a href="/format/2309.00819" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Mixed Reality: The Interface of the Future
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gyawali%2C+D">Dipesh Gyawali</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages, 8 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">The world is slowly moving towards everything being simulated digitally and
virtually. Mixed Reality (MR) is the amalgam of the real world with virtual
stimuli. It has great prospects in the future in terms of various applications
additionally with some challenges. This paper focuses on how Mixed Reality
could be used in the future along with the challenges that could arise. Several
application areas along with the potential benefits are studied in this
research. Three research questions are proposed, analyzed, and concluded
through the experiments. While the availability of MR devices could introduce a
lot of potential, specific challenges need to be scrutinized by the developers
and manufacturers. Overall, MR technology has a chance to enhance personalized,
supportive, and interactive experiences for human lives.
</p>
</div>
</dd>
<dt><a name="item75">[75]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.00824" title="Abstract">arXiv:2309.00824</a> [<a href="/pdf/2309.00824" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Leveraging Semi-Supervised Graph Learning for Enhanced Diabetic  Retinopathy Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dhinakaran%2C+D">D. Dhinakaran</a>, 
<a href="/search/cs?searchtype=author&query=Srinivasan%2C+L">L. Srinivasan</a>, 
<a href="/search/cs?searchtype=author&query=Selvaraj%2C+D">D. Selvaraj</a>, 
<a href="/search/cs?searchtype=author&query=Sankar%2C+S+M+U">S. M. Udhaya Sankar</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, 6 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Diabetic Retinopathy (DR) is a significant cause of blindness globally,
highlighting the urgent need for early detection and effective treatment.
Recent advancements in Machine Learning (ML) techniques have shown promise in
DR detection, but the availability of labeled data often limits their
performance. This research proposes a novel Semi-Supervised Graph Learning SSGL
algorithm tailored for DR detection, which capitalizes on the relationships
between labelled and unlabeled data to enhance accuracy. The work begins by
investigating data augmentation and preprocessing techniques to address the
challenges of image quality and feature variations. Techniques such as image
cropping, resizing, contrast adjustment, normalization, and data augmentation
are explored to optimize feature extraction and improve the overall quality of
retinal images. Moreover, apart from detection and diagnosis, this work delves
into applying ML algorithms for predicting the risk of developing DR or the
likelihood of disease progression. Personalized risk scores for individual
patients are generated using comprehensive patient data encompassing
demographic information, medical history, and retinal images. The proposed
Semi-Supervised Graph learning algorithm is rigorously evaluated on two
publicly available datasets and is benchmarked against existing methods.
Results indicate significant improvements in classification accuracy,
specificity, and sensitivity while demonstrating robustness against noise and
outlie rs.Notably, the proposed algorithm addresses the challenge of imbalanced
datasets, common in medical image analysis, further enhancing its practical
applicability.
</p>
</div>
</dd>
<dt><a name="item76">[76]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.00827" title="Abstract">arXiv:2309.00827</a> [<a href="/pdf/2309.00827" title="Download PDF">pdf</a>, <a href="/format/2309.00827" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Few shot font generation via transferring similarity guided global style  and quantization local style
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pan%2C+W">Wei Pan</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+A">Anna Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+X">Xinyu Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Iwana%2C+B+K">Brian Kenji Iwana</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+S">Shilin Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by ICCV 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Automatic few-shot font generation (AFFG), aiming at generating new fonts
with only a few glyph references, reduces the labor cost of manually designing
fonts. However, the traditional AFFG paradigm of style-content disentanglement
cannot capture the diverse local details of different fonts. So, many
component-based approaches are proposed to tackle this problem. The issue with
component-based approaches is that they usually require special pre-defined
glyph components, e.g., strokes and radicals, which is infeasible for AFFG of
different languages. In this paper, we present a novel font generation approach
by aggregating styles from character similarity-guided global features and
stylized component-level representations. We calculate the similarity scores of
the target character and the referenced samples by measuring the distance along
the corresponding channels from the content features, and assigning them as the
weights for aggregating the global style features. To better capture the local
styles, a cross-attention-based style transfer module is adopted to transfer
the styles of reference glyphs to the components, where the components are
self-learned discrete latent codes through vector quantization without manual
definition. With these designs, our AFFG method could obtain a complete set of
component-level style representations, and also control the global glyph
characteristics. The experimental results reflect the effectiveness and
generalization of the proposed method on different linguistic scripts, and also
show its superiority when compared with other state-of-the-art methods. The
source code can be found at https://github.com/awei669/VQ-Font.
</p>
</div>
</dd>
<dt><a name="item77">[77]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.00828" title="Abstract">arXiv:2309.00828</a> [<a href="/pdf/2309.00828" title="Download PDF">pdf</a>, <a href="/format/2309.00828" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> When 3D Bounding-Box Meets SAM: Point Cloud Instance Segmentation with  Weak-and-Noisy Supervision
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yu%2C+Q">Qingtao Yu</a>, 
<a href="/search/cs?searchtype=author&query=Du%2C+H">Heming Du</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+C">Chen Liu</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+X">Xin Yu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Learning from bounding-boxes annotations has shown great potential in
weakly-supervised 3D point cloud instance segmentation. However, we observed
that existing methods would suffer severe performance degradation with
perturbed bounding box annotations. To tackle this issue, we propose a
complementary image prompt-induced weakly-supervised point cloud instance
segmentation (CIP-WPIS) method. CIP-WPIS leverages pretrained knowledge
embedded in the 2D foundation model SAM and 3D geometric prior to achieve
accurate point-wise instance labels from the bounding box annotations.
Specifically, CP-WPIS first selects image views in which 3D candidate points of
an instance are fully visible. Then, we generate complementary background and
foreground prompts from projections to obtain SAM 2D instance mask predictions.
According to these, we assign the confidence values to points indicating the
likelihood of points belonging to the instance. Furthermore, we utilize 3D
geometric homogeneity provided by superpoints to decide the final instance
label assignments. In this fashion, we achieve high-quality 3D point-wise
instance labels. Extensive experiments on both Scannet-v2 and S3DIS benchmarks
demonstrate that our method is robust against noisy 3D bounding-box annotations
and achieves state-of-the-art performance.
</p>
</div>
</dd>
<dt><a name="item78">[78]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.00832" title="Abstract">arXiv:2309.00832</a> [<a href="/pdf/2309.00832" title="Download PDF">pdf</a>, <a href="/format/2309.00832" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ObjectLab: Automated Diagnosis of Mislabeled Images in Object Detection  Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tkachenko%2C+U">Ulyana Tkachenko</a>, 
<a href="/search/cs?searchtype=author&query=Thyagarajan%2C+A">Aditya Thyagarajan</a>, 
<a href="/search/cs?searchtype=author&query=Mueller%2C+J">Jonas Mueller</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ICML Workshop on Data-centric Machine Learning Research
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Despite powering sensitive systems like autonomous vehicles, object detection
remains fairly brittle in part due to annotation errors that plague most
real-world training datasets. We propose ObjectLab, a straightforward algorithm
to detect diverse errors in object detection labels, including: overlooked
bounding boxes, badly located boxes, and incorrect class label assignments.
ObjectLab utilizes any trained object detection model to score the label
quality of each image, such that mislabeled images can be automatically
prioritized for label review/correction. Properly handling erroneous data
enables training a better version of the same object detection model, without
any change in existing modeling code. Across different object detection
datasets (including COCO) and different models (including Detectron-X101 and
Faster-RCNN), ObjectLab consistently detects annotation errors with much better
precision/recall compared to other label quality scores.
</p>
</div>
</dd>
<dt><a name="item79">[79]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.00834" title="Abstract">arXiv:2309.00834</a> [<a href="/pdf/2309.00834" title="Download PDF">pdf</a>, <a href="/format/2309.00834" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Approximating Fair $k$-Min-Sum-Radii in $\mathbb{R}^d$
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Drexler%2C+L">Lukas Drexler</a>, 
<a href="/search/cs?searchtype=author&query=Hennes%2C+A">Annika Hennes</a>, 
<a href="/search/cs?searchtype=author&query=Lahiri%2C+A">Abhiruk Lahiri</a>, 
<a href="/search/cs?searchtype=author&query=Schmidt%2C+M">Melanie Schmidt</a>, 
<a href="/search/cs?searchtype=author&query=Wargalla%2C+J">Julian Wargalla</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">The $k$-center problem is a classical clustering problem in which one is
asked to find a partitioning of a point set $P$ into $k$ clusters such that the
maximum radius of any cluster is minimized. It is well-studied. But what if we
add up the radii of the clusters instead of only considering the cluster with
maximum radius? This natural variant is called the $k$-min-sum-radii problem.
It has become the subject of more and more interest in recent years, inspiring
the development of approximation algorithms for the $k$-min-sum-radii problem
in its plain version as well as in constrained settings.
<br />We study the problem for Euclidean spaces $\mathbb{R}^d$ of arbitrary
dimension but assume the number $k$ of clusters to be constant. In this case, a
PTAS for the problem is known (see Bandyapadhyay, Lochet and Saurabh, SoCG,
2023). Our aim is to extend the knowledge base for $k$-min-sum-radii to the
domain of fair clustering. We study several group fairness constraints, such as
the one introduced by Chierichetti et al. (NeurIPS, 2017). In this model, input
points have an additional attribute (e.g., colors such as red and blue), and
clusters have to preserve the ratio between different attribute values (e.g.,
have the same fraction of red and blue points as the ground set). Different
variants of this general idea have been studied in the literature. To the best
of our knowledge, no approximative results for the fair $k$-min-sum-radii
problem are known, despite the immense amount of work on the related fair
$k$-center problem.
<br />We propose a PTAS for the fair $k$-min-sum-radii problem in Euclidean spaces
of arbitrary dimension for the case of constant $k$. To the best of our
knowledge, this is the first PTAS for the problem. It works for different
notions of group fairness.
</p>
</div>
</dd>
<dt><a name="item80">[80]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.00837" title="Abstract">arXiv:2309.00837</a> [<a href="/pdf/2309.00837" title="Download PDF">pdf</a>, <a href="/format/2309.00837" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Autonomous Soft Tissue Retraction Using Demonstration-Guided  Reinforcement Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Singh%2C+A">Amritpal Singh</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+W">Wenqi Shi</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+M+D">May D Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 Pages, 5 figures, MICCAI 2023 conference (AECAI workshop)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Robotics (cs.RO)

</div>
<p class="mathjax">In the context of surgery, robots can provide substantial assistance by
performing small, repetitive tasks such as suturing, needle exchange, and
tissue retraction, thereby enabling surgeons to concentrate on more complex
aspects of the procedure. However, existing surgical task learning mainly
pertains to rigid body interactions, whereas the advancement towards more
sophisticated surgical robots necessitates the manipulation of soft bodies.
Previous work focused on tissue phantoms for soft tissue task learning, which
can be expensive and can be an entry barrier to research. Simulation
environments present a safe and efficient way to learn surgical tasks before
their application to actual tissue. In this study, we create a Robot Operating
System (ROS)-compatible physics simulation environment with support for both
rigid and soft body interactions within surgical tasks. Furthermore, we
investigate the soft tissue interactions facilitated by the patient-side
manipulator of the DaVinci surgical robot. Leveraging the pybullet physics
engine, we simulate kinematics and establish anchor points to guide the robotic
arm when manipulating soft tissue. Using demonstration-guided reinforcement
learning (RL) algorithms, we investigate their performance in comparison to
traditional reinforcement learning algorithms. Our in silico trials demonstrate
a proof-of-concept for autonomous surgical soft tissue retraction. The results
corroborate the feasibility of learning soft body manipulation through the
application of reinforcement learning agents. This work lays the foundation for
future research into the development and refinement of surgical robots capable
of managing both rigid and soft tissue interactions. Code is available at
https://github.com/amritpal-001/tissue_retract.
</p>
</div>
</dd>
<dt><a name="item81">[81]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.00841" title="Abstract">arXiv:2309.00841</a> [<a href="/pdf/2309.00841" title="Download PDF">pdf</a>, <a href="/format/2309.00841" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LeanContext: Cost-Efficient Domain-Specific Question Answering Using  LLMs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Arefeen%2C+M+A">Md Adnan Arefeen</a>, 
<a href="/search/cs?searchtype=author&query=Debnath%2C+B">Biplob Debnath</a>, 
<a href="/search/cs?searchtype=author&query=Chakradhar%2C+S">Srimat Chakradhar</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> The paper is under review
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Information Retrieval (cs.IR)

</div>
<p class="mathjax">Question-answering (QA) is a significant application of Large Language Models
(LLMs), shaping chatbot capabilities across healthcare, education, and customer
service. However, widespread LLM integration presents a challenge for small
businesses due to the high expenses of LLM API usage. Costs rise rapidly when
domain-specific data (context) is used alongside queries for accurate
domain-specific LLM responses. One option is to summarize the context by using
LLMs and reduce the context. However, this can also filter out useful
information that is necessary to answer some domain-specific queries. In this
paper, we shift from human-oriented summarizers to AI model-friendly summaries.
Our approach, LeanContext, efficiently extracts $k$ key sentences from the
context that are closely aligned with the query. The choice of $k$ is neither
static nor random; we introduce a reinforcement learning technique that
dynamically determines $k$ based on the query and context. The rest of the less
important sentences are reduced using a free open source text reduction method.
We evaluate LeanContext against several recent query-aware and query-unaware
context reduction approaches on prominent datasets (arxiv papers and BBC news
articles). Despite cost reductions of $37.29\%$ to $67.81\%$, LeanContext's
ROUGE-1 score decreases only by $1.41\%$ to $2.65\%$ compared to a baseline
that retains the entire context (no summarization). Additionally, if free
pretrained LLM-based summarizers are used to reduce context (into human
consumable summaries), LeanContext can further modify the reduced context to
enhance the accuracy (ROUGE-1 score) by $13.22\%$ to $24.61\%$.
</p>
</div>
</dd>
<dt><a name="item82">[82]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.00842" title="Abstract">arXiv:2309.00842</a> [<a href="/pdf/2309.00842" title="Download PDF">pdf</a>, <a href="/format/2309.00842" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DualStream: Spatially Sharing Selves and Surroundings using Mobile  Devices and Augmented Reality
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Vanukuru%2C+R">Rishi Vanukuru</a>, 
<a href="/search/cs?searchtype=author&query=Weng%2C+S+C">Suibi Che-Chuan Weng</a>, 
<a href="/search/cs?searchtype=author&query=Ranjan%2C+K">Krithik Ranjan</a>, 
<a href="/search/cs?searchtype=author&query=Hopkins%2C+T">Torin Hopkins</a>, 
<a href="/search/cs?searchtype=author&query=Banic%2C+A">Amy Banic</a>, 
<a href="/search/cs?searchtype=author&query=Gross%2C+M+D">Mark D. Gross</a>, 
<a href="/search/cs?searchtype=author&query=Do%2C+E+Y">Ellen Yi-Luen Do</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 4 figures, 1 table; To appear in the proceedings of the IEEE International Symposium on Mixed and Augmented Reality (ISMAR) 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">In-person human interaction relies on our spatial perception of each other
and our surroundings. Current remote communication tools partially address each
of these aspects. Video calls convey real user representations but without
spatial interactions. Augmented and Virtual Reality (AR/VR) experiences are
immersive and spatial but often use virtual environments and characters instead
of real-life representations. Bridging these gaps, we introduce DualStream, a
system for synchronous mobile AR remote communication that captures, streams,
and displays spatial representations of users and their surroundings.
DualStream supports transitions between user and environment representations
with different levels of visuospatial fidelity, as well as the creation of
persistent shared spaces using environment snapshots. We demonstrate how
DualStream can enable spatial communication in real-world contexts, and support
the creation of blended spaces for collaboration. A formative evaluation of
DualStream revealed that users valued the ability to interact spatially and
move between representations, and could see DualStream fitting into their own
remote communication practices in the near future. Drawing from these findings,
we discuss new opportunities for designing more widely accessible spatial
communication tools, centered around the mobile phone.
</p>
</div>
</dd>
<dt><a name="item83">[83]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.00843" title="Abstract">arXiv:2309.00843</a> [<a href="/pdf/2309.00843" title="Download PDF">pdf</a>, <a href="/format/2309.00843" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Remote ID for separation provision and multi-agent navigation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Vinogradov%2C+E">Evgenii Vinogradov</a>, 
<a href="/search/cs?searchtype=author&query=Kumar%2C+A+V+S+S+B">A.V.S. Sai Bhargav Kumar</a>, 
<a href="/search/cs?searchtype=author&query=Minucci%2C+F">Franco Minucci</a>, 
<a href="/search/cs?searchtype=author&query=Pollin%2C+S">Sofie Pollin</a>, 
<a href="/search/cs?searchtype=author&query=Natalizio%2C+E">Enrico Natalizio</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 8 figures, 2023 IEEE/AIAA 42nd Digital Avionics Systems Conference (DASC)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Networking and Internet Architecture (cs.NI)

</div>
<p class="mathjax">In this paper, we investigate the integration of drone identification data
(Remote ID) with collision avoidance mechanisms to improve the safety and
efficiency of multi-drone operations. We introduce an improved Near Mid-Air
Collision (NMAC) definition, termed as UAV NMAC (uNMAC), which accounts for
uncertainties in the drone's location due to self-localization errors and
possible displacements between two location reports. Our proposed uNMAC-based
Reciprocal Velocity Obstacle (RVO) model integrates Remote ID messages with RVO
to enable enhanced collision-free navigation. We propose modifications to the
Remote ID format to include data on localization accuracy and drone airframe
size, facilitating more efficient collision avoidance decisions. Through
extensive simulations, we demonstrate that our approach halves mission
execution times compared to a conservative standard Remote ID-based RVO.
Importantly, it ensures collision-free operations even under localization
uncertainties. By integrating the improved Remote ID messages and uNMAC-based
RVO, we offer a solution to significantly increase airspace capacity while
adhering to strict safety standards. Our study emphasizes the potential to
augment the safety and efficiency of future drone operations, thereby
benefiting industries reliant on drone technologies.
</p>
</div>
</dd>
<dt><a name="item84">[84]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.00844" title="Abstract">arXiv:2309.00844</a> [<a href="/pdf/2309.00844" title="Download PDF">pdf</a>, <a href="/format/2309.00844" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Domain Generalization via Balancing Training Difficulty and Model  Capability
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jiang%2C+X">Xueying Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+J">Jiaxing Huang</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+S">Sheng Jin</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+S">Shijian Lu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages, 6 figures, Accepted by ICCV 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Domain generalization (DG) aims to learn domain-generalizable models from one
or multiple source domains that can perform well in unseen target domains.
Despite its recent progress, most existing work suffers from the misalignment
between the difficulty level of training samples and the capability of
contemporarily trained models, leading to over-fitting or under-fitting in the
trained generalization model. We design MoDify, a Momentum Difficulty framework
that tackles the misalignment by balancing the seesaw between the model's
capability and the samples' difficulties along the training process. MoDify
consists of two novel designs that collaborate to fight against the
misalignment while learning domain-generalizable models. The first is
MoDify-based Data Augmentation which exploits an RGB Shuffle technique to
generate difficulty-aware training samples on the fly. The second is
MoDify-based Network Optimization which dynamically schedules the training
samples for balanced and smooth learning with appropriate difficulty. Without
bells and whistles, a simple implementation of MoDify achieves superior
performance across multiple benchmarks. In addition, MoDify can complement
existing methods as a plug-in, and it is generic and can work for different
visual recognition tasks.
</p>
</div>
</dd>
<dt><a name="item85">[85]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.00846" title="Abstract">arXiv:2309.00846</a> [<a href="/pdf/2309.00846" title="Download PDF">pdf</a>, <a href="/format/2309.00846" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> pSTarC: Pseudo Source Guided Target Clustering for Fully Test-Time  Adaptation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sreenivas%2C+M">Manogna Sreenivas</a>, 
<a href="/search/cs?searchtype=author&query=Chakrabarty%2C+G">Goirik Chakrabarty</a>, 
<a href="/search/cs?searchtype=author&query=Biswas%2C+S">Soma Biswas</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Test Time Adaptation (TTA) is a pivotal concept in machine learning, enabling
models to perform well in real-world scenarios, where test data distribution
differs from training. In this work, we propose a novel approach called pseudo
Source guided Target Clustering (pSTarC) addressing the relatively unexplored
area of TTA under real-world domain shifts. This method draws inspiration from
target clustering techniques and exploits the source classifier for generating
pseudo-source samples. The test samples are strategically aligned with these
pseudo-source samples, facilitating their clustering and thereby enhancing TTA
performance. pSTarC operates solely within the fully test-time adaptation
protocol, removing the need for actual source data. Experimental validation on
a variety of domain shift datasets, namely VisDA, Office-Home, DomainNet-126,
CIFAR-100C verifies pSTarC's effectiveness. This method exhibits significant
improvements in prediction accuracy along with efficient computational
requirements. Furthermore, we also demonstrate the universality of the pSTarC
framework by showing its effectiveness for the continuous TTA framework.
</p>
</div>
</dd>
<dt><a name="item86">[86]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.00848" title="Abstract">arXiv:2309.00848</a> [<a href="/pdf/2309.00848" title="Download PDF">pdf</a>, <a href="/format/2309.00848" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Post-Processing Based Bengali Document Layout Analysis with YOLOV8
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ahmed%2C+N+S">Nazmus Sakib Ahmed</a>, 
<a href="/search/cs?searchtype=author&query=Noor%2C+S+S">Saad Sakib Noor</a>, 
<a href="/search/cs?searchtype=author&query=Sikder%2C+A+I+S">Ashraful Islam Shanto Sikder</a>, 
<a href="/search/cs?searchtype=author&query=Paul%2C+A">Abhijit Paul</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">This paper focuses on enhancing Bengali Document Layout Analysis (DLA) using
the YOLOv8 model and innovative post-processing techniques. We tackle
challenges unique to the complex Bengali script by employing data augmentation
for model robustness. After meticulous validation set evaluation, we fine-tune
our approach on the complete dataset, leading to a two-stage prediction
strategy for accurate element segmentation. Our ensemble model, combined with
post-processing, outperforms individual base architectures, addressing issues
identified in the BaDLAD dataset. By leveraging this approach, we aim to
advance Bengali document analysis, contributing to improved OCR and document
comprehension and BaDLAD serves as a foundational resource for this endeavor,
aiding future research in the field. Furthermore, our experiments provided key
insights to incorporate new strategies into the established solution.
</p>
</div>
</dd>
<dt><a name="item87">[87]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.00851" title="Abstract">arXiv:2309.00851</a> [<a href="/pdf/2309.00851" title="Download PDF">pdf</a>, <a href="/format/2309.00851" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Drift Analysis with Fitness Levels for Elitist Evolutionary Algorithms
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=He%2C+J">Jun He</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Y">Yuren Zhou</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neural and Evolutionary Computing (cs.NE)</span>

</div>
<p class="mathjax">The fitness level method is a popular tool for analyzing the computation time
of elitist evolutionary algorithms. Its idea is to divide the search space into
multiple fitness levels and estimate lower and upper bounds on the computation
time using transition probabilities between fitness levels. However, the lower
bound generated from this method is often not tight. To improve the lower
bound, this paper rigorously studies an open question about the fitness level
method: what are the tightest lower and upper time bounds that can be
constructed based on fitness levels? To answer this question, drift analysis
with fitness levels is developed, and the tightest bound problem is formulated
as a constrained multi-objective optimization problem subject to fitness level
constraints. The tightest metric bounds from fitness levels are constructed and
proven for the first time. Then the metric bounds are converted into linear
bounds, where existing linear bounds are special cases. This paper establishes
a general framework that can cover various linear bounds from trivial to best
coefficients. It is generic and promising, as it can be used not only to draw
the same bounds as existing ones, but also to draw tighter bounds, especially
on fitness landscapes where shortcuts exist. This is demonstrated in the case
study of the (1+1) EA maximizing the TwoPath function.
</p>
</div>
</dd>
<dt><a name="item88">[88]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.00854" title="Abstract">arXiv:2309.00854</a> [<a href="/pdf/2309.00854" title="Download PDF">pdf</a>, <a href="/format/2309.00854" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Unifying Variational Framework for Gaussian Process Motion Planning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cosier%2C+L">Lucas Cosier</a>, 
<a href="/search/cs?searchtype=author&query=Iordan%2C+R">Rares Iordan</a>, 
<a href="/search/cs?searchtype=author&query=Zwane%2C+S">Sicelukwanda Zwane</a>, 
<a href="/search/cs?searchtype=author&query=Franzese%2C+G">Giovanni Franzese</a>, 
<a href="/search/cs?searchtype=author&query=Wilson%2C+J+T">James T. Wilson</a>, 
<a href="/search/cs?searchtype=author&query=Deisenroth%2C+M+P">Marc Peter Deisenroth</a>, 
<a href="/search/cs?searchtype=author&query=Terenin%2C+A">Alexander Terenin</a>, 
<a href="/search/cs?searchtype=author&query=Bekiroglu%2C+Y">Yasemin Bekiroglu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">To control how a robot moves, motion planning algorithms must compute paths
in high-dimensional state spaces while accounting for physical constraints
related to motors and joints, generating smooth and stable motions, avoiding
obstacles, and preventing collisions. A motion planning algorithm must
therefore balance competing demands, and should ideally incorporate uncertainty
to handle noise, model errors, and facilitate deployment in complex
environments. To address these issues, we introduce a framework for robot
motion planning based on variational Gaussian Processes, which unifies and
generalizes various probabilistic-inference-based motion planning algorithms.
Our framework provides a principled and flexible way to incorporate
equality-based, inequality-based, and soft motion-planning constraints during
end-to-end training, is straightforward to implement, and provides both
interval-based and Monte-Carlo-based uncertainty estimates. We conduct
experiments using different environments and robots, comparing against baseline
approaches based on the feasibility of the planned paths, and obstacle
avoidance quality. Results show that our proposed approach yields a good
balance between success rates and path quality.
</p>
</div>
</dd>
<dt><a name="item89">[89]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.00855" title="Abstract">arXiv:2309.00855</a> [<a href="/pdf/2309.00855" title="Download PDF">pdf</a>, <a href="/format/2309.00855" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DoRA: Domain-Based Self-Supervised Learning Framework for Low-Resource  Real Estate Appraisal
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Du%2C+W">Wei-Wei Du</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+W">Wei-Yao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+W">Wen-Chih Peng</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">The marketplace system connecting demands and supplies has been explored to
develop unbiased decision-making in valuing properties. Real estate appraisal
serves as one of the high-cost property valuation tasks for financial
institutions since it requires domain experts to appraise the estimation based
on the corresponding knowledge and the judgment of the market. Existing
automated valuation models reducing the subjectivity of domain experts require
a large number of transactions for effective evaluation, which is predominantly
limited to not only the labeling efforts of transactions but also the
generalizability of new developing and rural areas. To learn representations
from unlabeled real estate sets, existing self-supervised learning (SSL) for
tabular data neglects various important features, and fails to incorporate
domain knowledge. In this paper, we propose DoRA, a Domain-based
self-supervised learning framework for low-resource Real estate Appraisal. DoRA
is pre-trained with an intra-sample geographic prediction as the pretext task
based on the metadata of the real estate for equipping the real estate
representations with prior domain knowledge. Furthermore, inter-sample
contrastive learning is employed to generalize the representations to be robust
for limited transactions of downstream tasks. Our benchmark results on three
property types of real-world transactions show that DoRA significantly
outperforms the SSL baselines for tabular data, the graph-based methods, and
the supervised approaches in the few-shot scenarios by at least 7.6% for MAPE,
11.59% for MAE, and 3.34% for HR10%. We expect DoRA to be useful to other
financial practitioners with similar marketplace applications who need general
models for properties that are newly built and have limited records. The source
code is available at https://github.com/wwweiwei/DoRA.
</p>
</div>
</dd>
<dt><a name="item90">[90]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.00857" title="Abstract">arXiv:2309.00857</a> [<a href="/pdf/2309.00857" title="Download PDF">pdf</a>, <a href="/format/2309.00857" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Evaluating Transformer&#x27;s Ability to Learn Mildly Context-Sensitive  Languages
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Shunjie Wang</a>, 
<a href="/search/cs?searchtype=author&query=Steinert-Threlkeld%2C+S">Shane Steinert-Threlkeld</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Despite that Transformers perform well in NLP tasks, recent studies suggest
that self-attention is theoretically limited in learning even some regular and
context-free languages. These findings motivated us to think about their
implications in modeling natural language, which is hypothesized to be mildly
context-sensitive. We test Transformer's ability to learn a variety of mildly
context-sensitive languages of varying complexities, and find that they
generalize well to unseen in-distribution data, but their ability to
extrapolate to longer strings is worse than that of LSTMs. Our analyses show
that the learned self-attention patterns and representations modeled dependency
relations and demonstrated counting behavior, which may have helped the models
solve the languages.
</p>
</div>
</dd>
<dt><a name="item91">[91]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.00859" title="Abstract">arXiv:2309.00859</a> [<a href="/pdf/2309.00859" title="Download PDF">pdf</a>, <a href="/format/2309.00859" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DeepScaler: Holistic Autoscaling for Microservices Based on  Spatiotemporal GNN with Adaptive Graph Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Meng%2C+C">Chunyang Meng</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+S">Shijie Song</a>, 
<a href="/search/cs?searchtype=author&query=Tong%2C+H">Haogang Tong</a>, 
<a href="/search/cs?searchtype=author&query=Pan%2C+M">Maolin Pan</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+Y">Yang Yu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To be published in the 38th IEEE/ACM International Conference on Automated Software Engineering (ASE 2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
<p class="mathjax">Autoscaling functions provide the foundation for achieving elasticity in the
modern cloud computing paradigm. It enables dynamic provisioning or
de-provisioning resources for cloud software services and applications without
human intervention to adapt to workload fluctuations. However, autoscaling
microservice is challenging due to various factors. In particular, complex,
time-varying service dependencies are difficult to quantify accurately and can
lead to cascading effects when allocating resources. This paper presents
DeepScaler, a deep learning-based holistic autoscaling approach for
microservices that focus on coping with service dependencies to optimize
service-level agreements (SLA) assurance and cost efficiency. DeepScaler
employs (i) an expectation-maximization-based learning method to adaptively
generate affinity matrices revealing service dependencies and (ii) an
attention-based graph convolutional network to extract spatio-temporal features
of microservices by aggregating neighbors' information of graph-structural
data. Thus DeepScaler can capture more potential service dependencies and
accurately estimate the resource requirements of all services under dynamic
workloads. It allows DeepScaler to reconfigure the resources of the interacting
services simultaneously in one resource provisioning operation, avoiding the
cascading effect caused by service dependencies. Experimental results
demonstrate that our method implements a more effective autoscaling mechanism
for microservice that not only allocates resources accurately but also adapts
to dependencies changes, significantly reducing SLA violations by an average of
41% at lower costs.
</p>
</div>
</dd>
<dt><a name="item92">[92]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.00860" title="Abstract">arXiv:2309.00860</a> [<a href="/pdf/2309.00860" title="Download PDF">pdf</a>, <a href="/format/2309.00860" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Code Watermarking with Dual-Channel Transformations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+B">Borui Yang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+W">Wei Li</a>, 
<a href="/search/cs?searchtype=author&query=Xiang%2C+L">Liyao Xiang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+B">Bo Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">The expansion of the open source community and the rise of large language
models have raised ethical and security concerns on the distribution of source
code, such as misconduct on copyrighted code, distributions without proper
licenses, or misuse of the code for malicious purposes. Hence it is important
to track the ownership of source code, in wich watermarking is a major
technique. Yet, drastically different from natural languages, source code
watermarking requires far stricter and more complicated rules to ensure the
readability as well as the functionality of the source code. Hence we introduce
SrcMarker, a watermarking system to unobtrusively encode ID bitstrings into
source code, without affecting the usage and semantics of the code. To this
end, SrcMarker performs transformations on an AST-based intermediate
representation that enables unified transformations across different
programming languages. The core of the system utilizes learning-based embedding
and extraction modules to select rule-based transformations for watermarking.
In addition, a novel feature-approximation technique is designed to tackle the
inherent non-differentiability of rule selection, thus seamlessly integrating
the rule-based transformations and learning-based networks into an
interconnected system to enable end-to-end training. Extensive experiments
demonstrate the superiority of SrcMarker over existing methods in various
watermarking requirements.
</p>
</div>
</dd>
<dt><a name="item93">[93]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.00861" title="Abstract">arXiv:2309.00861</a> [<a href="/pdf/2309.00861" title="Download PDF">pdf</a>, <a href="/ps/2309.00861" title="Download PostScript">ps</a>, <a href="/format/2309.00861" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Survey of Local Differential Privacy and Its Variants
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Qin%2C+L">Likun Qin</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+N">Nan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Qiu%2C+T">Tianshuo Qiu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">The introduction and advancements in Local Differential Privacy (LDP)
variants have become a cornerstone in addressing the privacy concerns
associated with the vast data produced by smart devices, which forms the
foundation for data-driven decision-making in crowdsensing. While harnessing
the power of these immense data sets can offer valuable insights, it
simultaneously poses significant privacy risks for the users involved. LDP, a
distinguished privacy model with a decentralized architecture, stands out for
its capability to offer robust privacy assurances for individual users during
data collection and analysis. The essence of LDP is its method of locally
perturbing each user's data on the client-side before transmission to the
server-side, safeguarding against potential privacy breaches at both ends. This
article offers an in-depth exploration of LDP, emphasizing its models, its
myriad variants, and the foundational structure of LDP algorithms.
</p>
</div>
</dd>
<dt><a name="item94">[94]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.00862" title="Abstract">arXiv:2309.00862</a> [<a href="/pdf/2309.00862" title="Download PDF">pdf</a>, <a href="/format/2309.00862" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Big-model Driven Few-shot Continual Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gu%2C+Z">Ziqi Gu</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+C">Chunyan Xu</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+Z">Zihan Lu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xin Liu</a>, 
<a href="/search/cs?searchtype=author&query=Dai%2C+A">Anbo Dai</a>, 
<a href="/search/cs?searchtype=author&query=Cui%2C+Z">Zhen Cui</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages 6 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Few-shot continual learning (FSCL) has attracted intensive attention and
achieved some advances in recent years, but now it is difficult to again make a
big stride in accuracy due to the limitation of only few-shot incremental
samples. Inspired by distinctive human cognition ability in life learning, in
this work, we propose a novel Big-model driven Few-shot Continual Learning
(B-FSCL) framework to gradually evolve the model under the traction of the
world's big-models (like human accumulative knowledge). Specifically, we
perform the big-model driven transfer learning to leverage the powerful
encoding capability of these existing big-models, which can adapt the continual
model to a few of newly added samples while avoiding the over-fitting problem.
Considering that the big-model and the continual model may have different
perceived results for the identical images, we introduce an instance-level
adaptive decision mechanism to provide the high-level flexibility cognitive
support adjusted to varying samples. In turn, the adaptive decision can be
further adopted to optimize the parameters of the continual model, performing
the adaptive distillation of big-model's knowledge information. Experimental
results of our proposed B-FSCL on three popular datasets (including CIFAR100,
minilmageNet and CUB200) completely surpass all state-of-the-art FSCL methods.
</p>
</div>
</dd>
<dt><a name="item95">[95]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.00864" title="Abstract">arXiv:2309.00864</a> [<a href="/pdf/2309.00864" title="Download PDF">pdf</a>, <a href="/format/2309.00864" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Equitable-FL: Federated Learning with Sparsity for Resource-Constrained  Environment
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sinha%2C+I+K">Indrajeet Kumar Sinha</a>, 
<a href="/search/cs?searchtype=author&query=Verma%2C+S">Shekhar Verma</a>, 
<a href="/search/cs?searchtype=author&query=Singh%2C+K+P">Krishna Pratap Singh</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 7 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV); Distributed, Parallel, and Cluster Computing (cs.DC)

</div>
<p class="mathjax">In Federated Learning, model training is performed across multiple computing
devices, where only parameters are shared with a common central server without
exchanging their data instances. This strategy assumes abundance of resources
on individual clients and utilizes these resources to build a richer model as
user's models. However, when the assumption of the abundance of resources is
violated, learning may not be possible as some nodes may not be able to
participate in the process. In this paper, we propose a sparse form of
federated learning that performs well in a Resource Constrained Environment.
Our goal is to make learning possible, regardless of a node's space, computing,
or bandwidth scarcity. The method is based on the observation that model size
viz a viz available resources defines resource scarcity, which entails that
reduction of the number of parameters without affecting accuracy is key to
model training in a resource-constrained environment. In this work, the Lottery
Ticket Hypothesis approach is utilized to progressively sparsify models to
encourage nodes with resource scarcity to participate in collaborative
training. We validate Equitable-FL on the $MNIST$, $F-MNIST$, and $CIFAR-10$
benchmark datasets, as well as the $Brain-MRI$ data and the $PlantVillage$
datasets. Further, we examine the effect of sparsity on performance, model size
compaction, and speed-up for training. Results obtained from experiments
performed for training convolutional neural networks validate the efficacy of
Equitable-FL in heterogeneous resource-constrained learning environment.
</p>
</div>
</dd>
<dt><a name="item96">[96]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.00871" title="Abstract">arXiv:2309.00871</a> [<a href="/pdf/2309.00871" title="Download PDF">pdf</a>, <a href="/format/2309.00871" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Boosting Weakly-Supervised Image Segmentation via Representation,  Transform, and Compensator
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+C">Chunyan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+D">Dong Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+R">Rui Yan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Weakly-supervised image segmentation (WSIS) is a critical task in computer
vision that relies on image-level class labels. Multi-stage training procedures
have been widely used in existing WSIS approaches to obtain high-quality
pseudo-masks as ground-truth, resulting in significant progress. However,
single-stage WSIS methods have recently gained attention due to their potential
for simplifying training procedures, despite often suffering from low-quality
pseudo-masks that limit their practical applications. To address this issue, we
propose a novel single-stage WSIS method that utilizes a siamese network with
contrastive learning to improve the quality of class activation maps (CAMs) and
achieve a self-refinement process. Our approach employs a cross-representation
refinement method that expands reliable object regions by utilizing different
feature representations from the backbone. Additionally, we introduce a
cross-transform regularization module that learns robust class prototypes for
contrastive learning and captures global context information to feed back rough
CAMs, thereby improving the quality of CAMs. Our final high-quality CAMs are
used as pseudo-masks to supervise the segmentation result. Experimental results
on the PASCAL VOC 2012 dataset demonstrate that our method significantly
outperforms other state-of-the-art methods, achieving 67.2% and 68.76% mIoU on
PASCAL VOC 2012 val set and test set, respectively. Furthermore, our method has
been extended to weakly supervised object localization task, and experimental
results demonstrate that our method continues to achieve very competitive
results.
</p>
</div>
</dd>
<dt><a name="item97">[97]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.00872" title="Abstract">arXiv:2309.00872</a> [<a href="/pdf/2309.00872" title="Download PDF">pdf</a>, <a href="/format/2309.00872" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fearless Luminance Adaptation: A Macro-Micro-Hierarchical Transformer  for Exposure Correction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+G">Gehui Li</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jinyuan Liu</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+L">Long Ma</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+Z">Zhiying Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Fan%2C+X">Xin Fan</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+R">Risheng Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by ACM MM 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Photographs taken with less-than-ideal exposure settings often display poor
visual quality. Since the correction procedures vary significantly, it is
difficult for a single neural network to handle all exposure problems.
Moreover, the inherent limitations of convolutions, hinder the models ability
to restore faithful color or details on extremely over-/under- exposed regions.
To overcome these limitations, we propose a Macro-Micro-Hierarchical
transformer, which consists of a macro attention to capture long-range
dependencies, a micro attention to extract local features, and a hierarchical
structure for coarse-to-fine correction. In specific, the complementary
macro-micro attention designs enhance locality while allowing global
interactions. The hierarchical structure enables the network to correct
exposure errors of different scales layer by layer. Furthermore, we propose a
contrast constraint and couple it seamlessly in the loss function, where the
corrected image is pulled towards the positive sample and pushed away from the
dynamically generated negative samples. Thus the remaining color distortion and
loss of detail can be removed. We also extend our method as an image enhancer
for low-light face recognition and low-light semantic segmentation. Experiments
demonstrate that our approach obtains more attractive results than
state-of-the-art methods quantitatively and qualitatively.
</p>
</div>
</dd>
<dt><a name="item98">[98]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.00876" title="Abstract">arXiv:2309.00876</a> [<a href="/pdf/2309.00876" title="Download PDF">pdf</a>, <a href="/format/2309.00876" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Multiscale Method for Two-Component, Two-Phase Flow with a Neural  Network Surrogate
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Magiera%2C+J">Jim Magiera</a>, 
<a href="/search/math?searchtype=author&query=Rohde%2C+C">Christian Rohde</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Computational Physics (physics.comp-ph); Fluid Dynamics (physics.flu-dyn)

</div>
<p class="mathjax">Understanding the dynamics of phase boundaries in fluids requires
quantitative knowledge about the microscale processes at the interface. We
consider the sharp-interface motion of compressible two-component flow, and
propose a heterogeneous multiscale method (HMM) to describe the flow fields
accurately. The multiscale approach combines a hyperbolic system of balance
laws on the continuum scale with molecular-dynamics simulations on the
microscale level. Notably, the multiscale approach is necessary to compute the
interface dynamics because there is -- at present -- no closed continuum-scale
model. The basic HMM relies on a moving-mesh finite-volume method, and has been
introduced recently for compressible one-component flow with phase transitions
in [Magiera and Rohde, JCP. 469 (2022)]. To overcome the numerical complexity
of the molecular-dynamics microscale model a deep neural network is employed as
an efficient surrogate model. The entire approach is finally applied to
simulate droplet dynamics for argon-methane mixtures in several
space-dimensions. Up to our knowledge such compressible two-phase dynamics
accounting for microscale phase-change transfer rates have not yet been
computed.
</p>
</div>
</dd>
<dt><a name="item99">[99]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.00878" title="Abstract">arXiv:2309.00878</a> [<a href="/pdf/2309.00878" title="Download PDF">pdf</a>, <a href="/format/2309.00878" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Pretraining Representations for Bioacoustic Few-shot Detection using  Supervised Contrastive Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Moummad%2C+I">Ilyass Moummad</a>, 
<a href="/search/cs?searchtype=author&query=Serizel%2C+R">Romain Serizel</a>, 
<a href="/search/cs?searchtype=author&query=Farrugia%2C+N">Nicolas Farrugia</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Machine Learning (cs.LG); Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">Deep learning has been widely used recently for sound event detection and
classification. Its success is linked to the availability of sufficiently large
datasets, possibly with corresponding annotations when supervised learning is
considered. In bioacoustic applications, most tasks come with few labelled
training data, because annotating long recordings is time consuming and costly.
Therefore supervised learning is not the best suited approach to solve
bioacoustic tasks. The bioacoustic community recasted the problem of sound
event detection within the framework of few-shot learning, i.e. training a
system with only few labeled examples. The few-shot bioacoustic sound event
detection task in the DCASE challenge focuses on detecting events in long audio
recordings given only five annotated examples for each class of interest. In
this paper, we show that learning a rich feature extractor from scratch can be
achieved by leveraging data augmentation using a supervised contrastive
learning framework. We highlight the ability of this framework to transfer well
for five-shot event detection on previously unseen classes in the training
data. We obtain an F-score of 63.46\% on the validation set and 42.7\% on the
test set, ranking second in the DCASE challenge. We provide an ablation study
for the critical choices of data augmentation techniques as well as for the
learning strategy applied on the training set.
</p>
</div>
</dd>
<dt><a name="item100">[100]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.00879" title="Abstract">arXiv:2309.00879</a> [<a href="/pdf/2309.00879" title="Download PDF">pdf</a>, <a href="/format/2309.00879" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Certified Probabilistic Robustness with High Accuracy
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+R">Ruihan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+P">Peixin Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+J">Jun Sun</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Adversarial examples pose a security threat to many critical systems built on
neural networks (such as face recognition systems, and self-driving cars).
While many methods have been proposed to build robust models, how to build
certifiably robust yet accurate neural network models remains an open problem.
For example, adversarial training improves empirical robustness, but they do
not provide certification of the model's robustness. On the other hand,
certified training provides certified robustness but at the cost of a
significant accuracy drop. In this work, we propose a novel approach that aims
to achieve both high accuracy and certified probabilistic robustness. Our
method has two parts, i.e., a probabilistic robust training method with an
additional goal of minimizing variance in terms of divergence and a runtime
inference method for certified probabilistic robustness of the prediction. The
latter enables efficient certification of the model's probabilistic robustness
at runtime with statistical guarantees. This is supported by our training
objective, which minimizes the variance of the model's predictions in a given
vicinity, derived from a general definition of model robustness. Our approach
works for a variety of perturbations and is reasonably efficient. Our
experiments on multiple models trained on different datasets demonstrate that
our approach significantly outperforms existing approaches in terms of both
certification rate and accuracy.
</p>
</div>
</dd>
<dt><a name="item101">[101]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.00882" title="Abstract">arXiv:2309.00882</a> [<a href="/pdf/2309.00882" title="Download PDF">pdf</a>, <a href="/format/2309.00882" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Experimental Validation of a Dynamic Virtual Power Plant Concept Based  on Multiple-Converter Power Hardware-In-the-Loop Test Bench
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Andrejewski%2C+M">Moritz Andrejewski</a>, 
<a href="/search/eess?searchtype=author&query=H%C3%A4berle%2C+V">Verena H&#xe4;berle</a>, 
<a href="/search/eess?searchtype=author&query=Goldschmidt%2C+N">Nico Goldschmidt</a>, 
<a href="/search/eess?searchtype=author&query=D%C3%B6rfler%2C+F">Florian D&#xf6;rfler</a>, 
<a href="/search/eess?searchtype=author&query=Schulte%2C+H">Horst Schulte</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 Pages, 11 Figures, 22nd Wind &amp; Solar Integration Workshop 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">Recently, the concept of dynamic virtual power plants (DVPP) has been
proposed to collectively provide desired dynamic ancillary services such as
fast frequency and voltage control by a heterogeneous ensemble of distributed
energy resources (DER). This paper presents an experimental validation of a
recent DVPP control design approach on a multi-converter power
hardware-in-the-loop (PHIL) test bed system. More specifically, we consider a
DVPP composed of a wind generation system, a photovoltaic (PV) system, and a
STATCOM with small storage capacity to collectively provide grid-following fast
frequency regulation in the presence of grid-frequency and load variations. The
performance of the aggregated DVPP response is evaluated with respect to its
ability to match a desired dynamic behavior while taking practical limitations
of the individual DVPP units into account.
</p>
</div>
</dd>
<dt><a name="item102">[102]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.00883" title="Abstract">arXiv:2309.00883</a> [<a href="/pdf/2309.00883" title="Download PDF">pdf</a>, <a href="/format/2309.00883" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DiCLET-TTS: Diffusion Model based Cross-lingual Emotion Transfer for  Text-to-Speech -- A Study between English and Mandarin
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+T">Tao Li</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+C">Chenxu Hu</a>, 
<a href="/search/cs?searchtype=author&query=Cong%2C+J">Jian Cong</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+X">Xinfa Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jingbei Li</a>, 
<a href="/search/cs?searchtype=author&query=Tian%2C+Q">Qiao Tian</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yuping Wang</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+L">Lei Xie</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> accepted by TASLP
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">While the performance of cross-lingual TTS based on monolingual corpora has
been significantly improved recently, generating cross-lingual speech still
suffers from the foreign accent problem, leading to limited naturalness.
Besides, current cross-lingual methods ignore modeling emotion, which is
indispensable paralinguistic information in speech delivery. In this paper, we
propose DiCLET-TTS, a Diffusion model based Cross-Lingual Emotion Transfer
method that can transfer emotion from a source speaker to the intra- and
cross-lingual target speakers. Specifically, to relieve the foreign accent
problem while improving the emotion expressiveness, the terminal distribution
of the forward diffusion process is parameterized into a speaker-irrelevant but
emotion-related linguistic prior by a prior text encoder with the emotion
embedding as a condition. To address the weaker emotional expressiveness
problem caused by speaker disentanglement in emotion embedding, a novel
orthogonal projection based emotion disentangling module (OP-EDM) is proposed
to learn the speaker-irrelevant but emotion-discriminative embedding. Moreover,
a condition-enhanced DPM decoder is introduced to strengthen the modeling
ability of the speaker and the emotion in the reverse diffusion process to
further improve emotion expressiveness in speech delivery. Cross-lingual
emotion transfer experiments show the superiority of DiCLET-TTS over various
competitive models and the good design of OP-EDM in learning speaker-irrelevant
but emotion-discriminative embedding.
</p>
</div>
</dd>
<dt><a name="item103">[103]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.00886" title="Abstract">arXiv:2309.00886</a> [<a href="/pdf/2309.00886" title="Download PDF">pdf</a>, <a href="/ps/2309.00886" title="Download PostScript">ps</a>, <a href="/format/2309.00886" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Tight Bounds for Machine Unlearning via Differential Privacy
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+Y">Yiyang Huang</a>, 
<a href="/search/cs?searchtype=author&query=Canonne%2C+C+L">Cl&#xe9;ment L. Canonne</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Comments and feedback welcome
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">We consider the formulation of "machine unlearning" of Sekhari, Acharya,
Kamath, and Suresh (NeurIPS 2021), which formalizes the so-called "right to be
forgotten" by requiring that a trained model, upon request, should be able to
"unlearn" a number of points from the training data, as if they had never been
included in the first place. Sekhari et al. established some positive and
negative results about the number of data points that can be successfully
unlearnt by a trained model without impacting the model's accuracy (the
"deletion capacity"), showing that machine unlearning could be achieved by
using differentially private (DP) algorithms. However, their results left open
a gap between upper and lower bounds on the deletion capacity of these
algorithms: our work fully closes this gap, obtaining tight bounds on the
deletion capacity achievable by DP-based machine unlearning algorithms.
</p>
</div>
</dd>
<dt><a name="item104">[104]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.00889" title="Abstract">arXiv:2309.00889</a> [<a href="/pdf/2309.00889" title="Download PDF">pdf</a>, <a href="/format/2309.00889" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Discovering Predictive Relational Object Symbols with Symbolic Attentive  Layers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ahmetoglu%2C+A">Alper Ahmetoglu</a>, 
<a href="/search/cs?searchtype=author&query=Celik%2C+B">Batuhan Celik</a>, 
<a href="/search/cs?searchtype=author&query=Oztop%2C+E">Erhan Oztop</a>, 
<a href="/search/cs?searchtype=author&query=Ugur%2C+E">Emre Ugur</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: text overlap with <a href="/abs/2208.01021">arXiv:2208.01021</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">In this paper, we propose and realize a new deep learning architecture for
discovering symbolic representations for objects and their relations based on
the self-supervised continuous interaction of a manipulator robot with multiple
objects on a tabletop environment. The key feature of the model is that it can
handle a changing number number of objects naturally and map the object-object
relations into symbolic domain explicitly. In the model, we employ a
self-attention layer that computes discrete attention weights from object
features, which are treated as relational symbols between objects. These
relational symbols are then used to aggregate the learned object symbols and
predict the effects of executed actions on each object. The result is a
pipeline that allows the formation of object symbols and relational symbols
from a dataset of object features, actions, and effects in an end-to-end
manner. We compare the performance of our proposed architecture with
state-of-the-art symbol discovery methods in a simulated tabletop environment
where the robot needs to discover symbols related to the relative positions of
objects to predict the observed effect successfully. Our experiments show that
the proposed architecture performs better than other baselines in effect
prediction while forming not only object symbols but also relational symbols.
Furthermore, we analyze the learned symbols and relational patterns between
objects to learn about how the model interprets the environment. Our analysis
shows that the learned symbols relate to the relative positions of objects,
object types, and their horizontal alignment on the table, which reflect the
regularities in the environment.
</p>
</div>
</dd>
<dt><a name="item105">[105]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.00894" title="Abstract">arXiv:2309.00894</a> [<a href="/pdf/2309.00894" title="Download PDF">pdf</a>, <a href="/format/2309.00894" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Regularly Truncated M-estimators for Learning with Noisy Labels
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xia%2C+X">Xiaobo Xia</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+P">Pengqian Lu</a>, 
<a href="/search/cs?searchtype=author&query=Gong%2C+C">Chen Gong</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+B">Bo Han</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+J">Jun Yu</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+J">Jun Yu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+T">Tongliang Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 pages, 11 tables, 9 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">The sample selection approach is very popular in learning with noisy labels.
As deep networks learn pattern first, prior methods built on sample selection
share a similar training procedure: the small-loss examples can be regarded as
clean examples and used for helping generalization, while the large-loss
examples are treated as mislabeled ones and excluded from network parameter
updates. However, such a procedure is arguably debatable from two folds: (a) it
does not consider the bad influence of noisy labels in selected small-loss
examples; (b) it does not make good use of the discarded large-loss examples,
which may be clean or have meaningful information for generalization. In this
paper, we propose regularly truncated M-estimators (RTME) to address the above
two issues simultaneously. Specifically, RTME can alternately switch modes
between truncated M-estimators and original M-estimators. The former can
adaptively select small-losses examples without knowing the noise rate and
reduce the side-effects of noisy labels in them. The latter makes the possibly
clean examples but with large losses involved to help generalization.
Theoretically, we demonstrate that our strategies are label-noise-tolerant.
Empirically, comprehensive experimental results show that our method can
outperform multiple baselines and is robust to broad noise types and levels.
</p>
</div>
</dd>
<dt><a name="item106">[106]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.00898" title="Abstract">arXiv:2309.00898</a> [<a href="/pdf/2309.00898" title="Download PDF">pdf</a>, <a href="/format/2309.00898" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CoRD: Converged RDMA Dataplane for High-Performance Clouds
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Planeta%2C+M">Maksym Planeta</a>, 
<a href="/search/cs?searchtype=author&query=Bierbaum%2C+J">Jan Bierbaum</a>, 
<a href="/search/cs?searchtype=author&query=Roitzsch%2C+M">Michael Roitzsch</a>, 
<a href="/search/cs?searchtype=author&query=H%C3%A4rtig%2C+H">Hermann H&#xe4;rtig</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Operating Systems (cs.OS)</span>

</div>
<p class="mathjax">High-performance networking is often characterized by kernel bypass which is
considered mandatory in high-performance parallel and distributed applications.
But kernel bypass comes at a price because it breaks the traditional OS
architecture, requiring applications to use special APIs and limiting the OS
control over existing network connections. We make the case, that kernel bypass
is not mandatory. Rather, high-performance networking relies on multiple
performance-improving techniques, with kernel bypass being the least effective.
CoRD removes kernel bypass from RDMA networks, enabling efficient OS-level
control over RDMA dataplane.
</p>
</div>
</dd>
<dt><a name="item107">[107]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.00900" title="Abstract">arXiv:2309.00900</a> [<a href="/pdf/2309.00900" title="Download PDF">pdf</a>, <a href="/format/2309.00900" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Large Process Models: Business Process Management in the Age of  Generative AI
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kampik%2C+T">Timotheus Kampik</a>, 
<a href="/search/cs?searchtype=author&query=Warmuth%2C+C">Christian Warmuth</a>, 
<a href="/search/cs?searchtype=author&query=Rebmann%2C+A">Adrian Rebmann</a>, 
<a href="/search/cs?searchtype=author&query=Agam%2C+R">Ron Agam</a>, 
<a href="/search/cs?searchtype=author&query=Egger%2C+L+N+P">Lukas N.P. Egger</a>, 
<a href="/search/cs?searchtype=author&query=Gerber%2C+A">Andreas Gerber</a>, 
<a href="/search/cs?searchtype=author&query=Hoffart%2C+J">Johannes Hoffart</a>, 
<a href="/search/cs?searchtype=author&query=Kolk%2C+J">Jonas Kolk</a>, 
<a href="/search/cs?searchtype=author&query=Herzig%2C+P">Philipp Herzig</a>, 
<a href="/search/cs?searchtype=author&query=Decker%2C+G">Gero Decker</a>, 
<a href="/search/cs?searchtype=author&query=van+der+Aa%2C+H">Han van der Aa</a>, 
<a href="/search/cs?searchtype=author&query=Polyvyanyy%2C+A">Artem Polyvyanyy</a>, 
<a href="/search/cs?searchtype=author&query=Rinderle-Ma%2C+S">Stefanie Rinderle-Ma</a>, 
<a href="/search/cs?searchtype=author&query=Weber%2C+I">Ingo Weber</a>, 
<a href="/search/cs?searchtype=author&query=Weidlich%2C+M">Matthias Weidlich</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">The continued success of Large Language Models (LLMs) and other generative
artificial intelligence approaches highlights the advantages that large
information corpora can have over rigidly defined symbolic models, but also
serves as a proof-point of the challenges that purely statistics-based
approaches have in terms of safety and trustworthiness. As a framework for
contextualizing the potential, as well as the limitations of LLMs and other
foundation model-based technologies, we propose the concept of a Large Process
Model (LPM) that combines the correlation power of LLMs with the analytical
precision and reliability of knowledge-based systems and automated reasoning
approaches. LPMs are envisioned to directly utilize the wealth of process
management experience that experts have accumulated, as well as process
performance data of organizations with diverse characteristics, e.g., regarding
size, region, or industry. In this vision, the proposed LPM would allow
organizations to receive context-specific (tailored) process and other business
models, analytical deep-dives, and improvement recommendations. As such, they
would allow to substantially decrease the time and effort required for business
transformation, while also allowing for deeper, more impactful, and more
actionable insights than previously possible. We argue that implementing an LPM
is feasible, but also highlight limitations and research challenges that need
to be solved to implement particular aspects of the LPM vision.
</p>
</div>
</dd>
<dt><a name="item108">[108]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.00903" title="Abstract">arXiv:2309.00903</a> [<a href="/pdf/2309.00903" title="Download PDF">pdf</a>, <a href="/format/2309.00903" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A 3D explainability framework to uncover learning patterns and crucial  sub-regions in variable sulci recognition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mamalakis%2C+M">Michail Mamalakis</a>, 
<a href="/search/cs?searchtype=author&query=de+Vareilles%2C+H">Heloise de Vareilles</a>, 
<a href="/search/cs?searchtype=author&query=AI-Manea%2C+A">Atheer AI-Manea</a>, 
<a href="/search/cs?searchtype=author&query=Mitchell%2C+S+C">Samantha C. Mitchell</a>, 
<a href="/search/cs?searchtype=author&query=Arartz%2C+I">Ingrid Arartz</a>, 
<a href="/search/cs?searchtype=author&query=Morch-Johnsen%2C+L+E">Lynn Egeland Morch-Johnsen</a>, 
<a href="/search/cs?searchtype=author&query=Garrison%2C+J">Jane Garrison</a>, 
<a href="/search/cs?searchtype=author&query=Simons%2C+J">Jon Simons</a>, 
<a href="/search/cs?searchtype=author&query=Lio%2C+P">Pietro Lio</a>, 
<a href="/search/cs?searchtype=author&query=Suckling%2C+J">John Suckling</a>, 
<a href="/search/cs?searchtype=author&query=Murray%2C+G">Graham Murray</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Precisely identifying sulcal features in brain MRI is made challenging by the
variability of brain folding. This research introduces an innovative 3D
explainability frame-work that validates outputs from deep learning networks in
their ability to detect the paracingulate sulcus, an anatomical feature that
may or may not be present on the frontal medial surface of the human brain.
This study trained and tested two networks, amalgamating local explainability
techniques GradCam and SHAP with a dimensionality reduction method. The
explainability framework provided both localized and global explanations, along
with accuracy of classification results, revealing pertinent sub-regions
contributing to the decision process through a post-fusion transformation of
explanatory and statistical features. Leveraging the TOP-OSLO dataset of MRI
acquired from patients with schizophrenia, greater accuracies of paracingulate
sulcus detection (presence or absence) were found in the left compared to right
hemispheres with distinct, but extensive sub-regions contributing to each
classification outcome. The study also inadvertently highlighted the critical
role of an unbiased annotation protocol in maintaining network performance
fairness. Our proposed method not only offers automated, impartial annotations
of a variable sulcus but also provides insights into the broader anatomical
variations associated with its presence throughout the brain. The adoption of
this methodology holds promise for instigating further explorations and
inquiries in the field of neuroscience.
</p>
</div>
</dd>
<dt><a name="item109">[109]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.00904" title="Abstract">arXiv:2309.00904</a> [<a href="/pdf/2309.00904" title="Download PDF">pdf</a>, <a href="/format/2309.00904" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Developmental Scaffolding with Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Celik%2C+B">Batuhan Celik</a>, 
<a href="/search/cs?searchtype=author&query=Ahmetoglu%2C+A">Alper Ahmetoglu</a>, 
<a href="/search/cs?searchtype=author&query=Ugur%2C+E">Emre Ugur</a>, 
<a href="/search/cs?searchtype=author&query=Oztop%2C+E">Erhan Oztop</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Exploratoration and self-observation are key mechanisms of infant
sensorimotor development. These processes are further guided by parental
scaffolding accelerating skill and knowledge acquisition. In developmental
robotics, this approach has been adopted often by having a human acting as the
source of scaffolding. In this study, we investigate whether Large Language
Models (LLMs) can act as a scaffolding agent for a robotic system that aims to
learn to predict the effects of its actions. To this end, an object
manipulation setup is considered where one object can be picked and placed on
top of or in the vicinity of another object. The adopted LLM is asked to guide
the action selection process through algorithmically generated state
descriptions and action selection alternatives in natural language. The
simulation experiments that include cubes in this setup show that LLM-guided
(GPT3.5-guided) learning yields significantly faster discovery of novel
structures compared to random exploration. However, we observed that GPT3.5
fails to effectively guide the robot in generating structures with different
affordances such as cubes and spheres. Overall, we conclude that even without
fine-tuning, LLMs may serve as a moderate scaffolding agent for improving robot
learning, however, they still lack affordance understanding which limits the
applicability of the current LLMs in robotic scaffolding tasks.
</p>
</div>
</dd>
<dt><a name="item110">[110]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.00908" title="Abstract">arXiv:2309.00908</a> [<a href="/pdf/2309.00908" title="Download PDF">pdf</a>, <a href="/format/2309.00908" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MagicProp: Diffusion-based Video Editing via Motion-aware Appearance  Propagation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yan%2C+H">Hanshu Yan</a>, 
<a href="/search/cs?searchtype=author&query=Liew%2C+J+H">Jun Hao Liew</a>, 
<a href="/search/cs?searchtype=author&query=Mai%2C+L">Long Mai</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+S">Shanchuan Lin</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+J">Jiashi Feng</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">This paper addresses the issue of modifying the visual appearance of videos
while preserving their motion. A novel framework, named MagicProp, is proposed,
which disentangles the video editing process into two stages: appearance
editing and motion-aware appearance propagation. In the first stage, MagicProp
selects a single frame from the input video and applies image-editing
techniques to modify the content and/or style of the frame. The flexibility of
these techniques enables the editing of arbitrary regions within the frame. In
the second stage, MagicProp employs the edited frame as an appearance reference
and generates the remaining frames using an autoregressive rendering approach.
To achieve this, a diffusion-based conditional generation model, called
PropDPM, is developed, which synthesizes the target frame by conditioning on
the reference appearance, the target motion, and its previous appearance. The
autoregressive editing approach ensures temporal consistency in the resulting
videos. Overall, MagicProp combines the flexibility of image-editing techniques
with the superior temporal consistency of autoregressive modeling, enabling
flexible editing of object types and aesthetic styles in arbitrary regions of
input videos while maintaining good temporal consistency across frames.
Extensive experiments in various video editing scenarios demonstrate the
effectiveness of MagicProp.
</p>
</div>
</dd>
<dt><a name="item111">[111]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.00912" title="Abstract">arXiv:2309.00912</a> [<a href="/pdf/2309.00912" title="Download PDF">pdf</a>, <a href="/format/2309.00912" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Enable people to identify science news based on retracted articles on  social media
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yaqub%2C+W">Waheeb Yaqub</a>, 
<a href="/search/cs?searchtype=author&query=Kay%2C+J">Judy Kay</a>, 
<a href="/search/cs?searchtype=author&query=Goldwater%2C+M">Micah Goldwater</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">For many people, social media is an important way to consume news on
important topics like health. Unfortunately, some influential health news is
misinformation because it is based on retracted scientific work. Ours is the
first work to explore how people can understand this form of misinformation and
how an augmented social media interface can enable them to make use of
information about retraction. We report a between subjects think-aloud study
with 44 participants, where the experimental group used our augmented
interface. Our results indicate that this helped them consider retraction when
judging the credibility of news. Our key contributions are foundational
insights for tackling the problem, revealing the interplay between people's
understanding of scientific retraction, their prior beliefs about a topic, and
the way they use a social media interface that provides access to retraction
information.
</p>
</div>
</dd>
<dt><a name="item112">[112]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.00913" title="Abstract">arXiv:2309.00913</a> [<a href="/pdf/2309.00913" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Advanced spike sorting approaches in implantable VLSI wireless brain  computer interfaces: a survey
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sarkar%2C+S">Soujatya Sarkar</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to 37th International Conference on VLSI Design 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">Brain Computer/Machine Interfaces (BCI/BMIs) have substantial potential for
enhancing the lives of disabled individuals by restoring functionalities of
missing body parts or allowing paralyzed individuals to regain speech and other
motor capabilities. Due to severe health hazards arising from skull incisions
required for wired BCI/BMIs, scientists are focusing on developing VLSI
wireless BCI implants using biomaterials. However, significant challenges, like
power efficiency and implant size, persist in creating reliable and efficient
wireless BCI implants. With advanced spike sorting techniques, VLSI wireless
BCI implants can function within the power and size constraints while
maintaining neural spike classification accuracy. This study explores advanced
spike sorting techniques to overcome these hurdles and enable VLSI wireless
BCI/BMI implants to transmit data efficiently and achieve high accuracy.
</p>
</div>
</dd>
<dt><a name="item113">[113]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.00915" title="Abstract">arXiv:2309.00915</a> [<a href="/pdf/2309.00915" title="Download PDF">pdf</a>, <a href="/ps/2309.00915" title="Download PostScript">ps</a>, <a href="/format/2309.00915" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Manifesting Unobtainable Secrets: Threshold Elliptic Curve Key  Generation using Nested Shamir Secret Sharing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hall%2C+J+L">J.L. Hall</a>, 
<a href="/search/cs?searchtype=author&query=Hertzog%2C+Y">Y. Hertzog</a>, 
<a href="/search/cs?searchtype=author&query=Loewy%2C+M">M. Loewy</a>, 
<a href="/search/cs?searchtype=author&query=Skerritt%2C+M+P">M. P. Skerritt</a>, 
<a href="/search/cs?searchtype=author&query=Valladolid%2C+D">D. Valladolid</a>, 
<a href="/search/cs?searchtype=author&query=Verma%2C+G">G. Verma</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">We present a mechanism to manifest unobtainable secrets using a nested Shamir
secret sharing scheme to create public/private key pairs for elliptic curves. A
threshold secret sharing scheme can be used as a decentralised trust mechanism
with applications in identity validation, message decryption, and agreement
empowerment. Decentralising trust means that there is no single point
vulnerability which could enable compromise of a system. Our primary interest
is in twisted Edwards curves as used in EdDSA, and the related Diffie-Hellman
key-exchange algorithms. The key generation is also decentralised, so can be
used as a decentralised secret RNG suitable for use in other algorithms. The
algorithms presented could be used to fill a ``[TBS]'' in the draft IETF
specification ``Threshold modes in elliptic curves'' published in 2020 and
updated in 2022.
</p>
</div>
</dd>
<dt><a name="item114">[114]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.00916" title="Abstract">arXiv:2309.00916</a> [<a href="/pdf/2309.00916" title="Download PDF">pdf</a>, <a href="/format/2309.00916" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> BLSP: Bootstrapping Language-Speech Pre-training via Behavior Alignment  of Continuation Writing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+C">Chen Wang</a>, 
<a href="/search/cs?searchtype=author&query=Liao%2C+M">Minpeng Liao</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+Z">Zhongqiang Huang</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+J">Jinliang Lu</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+J">Junhong Wu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yuchen Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zong%2C+C">Chengqing Zong</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jiajun Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Sound (cs.SD); Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">The emergence of large language models (LLMs) has sparked significant
interest in extending their remarkable language capabilities to speech.
However, modality alignment between speech and text still remains an open
problem. Current solutions can be categorized into two strategies. One is a
cascaded approach where outputs (tokens or states) of a separately trained
speech recognition system are used as inputs for LLMs, which limits their
potential in modeling alignment between speech and text. The other is an
end-to-end approach that relies on speech instruction data, which is very
difficult to collect in large quantities. In this paper, we address these
issues and propose the BLSP approach that Bootstraps Language-Speech
Pre-training via behavior alignment of continuation writing. We achieve this by
learning a lightweight modality adapter between a frozen speech encoder and an
LLM, ensuring that the LLM exhibits the same generation behavior regardless of
the modality of input: a speech segment or its transcript. The training process
can be divided into two steps. The first step prompts an LLM to generate texts
with speech transcripts as prefixes, obtaining text continuations. In the
second step, these continuations are used as supervised signals to train the
modality adapter in an end-to-end manner. We demonstrate that this
straightforward process can extend the capabilities of LLMs to speech, enabling
speech recognition, speech translation, spoken language understanding, and
speech conversation, even in zero-shot cross-lingual scenarios.
</p>
</div>
</dd>
<dt><a name="item115">[115]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.00917" title="Abstract">arXiv:2309.00917</a> [<a href="/pdf/2309.00917" title="Download PDF">pdf</a>, <a href="/format/2309.00917" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Knowledge Graph Embeddings for Multi-Lingual Structured Representations  of Radiology Reports
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=van+Sonsbeek%2C+T">Tom van Sonsbeek</a>, 
<a href="/search/cs?searchtype=author&query=Zhen%2C+X">Xiantong Zhen</a>, 
<a href="/search/cs?searchtype=author&query=Warring%2C+M">Marcel Warring</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">The way we analyse clinical texts has undergone major changes over the last
years. The introduction of language models such as BERT led to adaptations for
the (bio)medical domain like PubMedBERT and ClinicalBERT. These models rely on
large databases of archived medical documents. While performing well in terms
of accuracy, both the lack of interpretability and limitations to transfer
across languages limit their use in clinical setting. We introduce a novel
light-weight graph-based embedding method specifically catering radiology
reports. It takes into account the structure and composition of the report,
while also connecting medical terms in the report through the multi-lingual
SNOMED Clinical Terms knowledge base. The resulting graph embedding uncovers
the underlying relationships among clinical terms, achieving a representation
that is better understandable for clinicians and clinically more accurate,
without reliance on large pre-training datasets. We show the use of this
embedding on two tasks namely disease classification of X-ray reports and image
classification. For disease classification our model is competitive with its
BERT-based counterparts, while being magnitudes smaller in size and training
data requirements. For image classification, we show the effectiveness of the
graph embedding leveraging cross-modal knowledge transfer and show how this
method is usable across different languages.
</p>
</div>
</dd>
<dt><a name="item116">[116]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.00920" title="Abstract">arXiv:2309.00920</a> [<a href="/pdf/2309.00920" title="Download PDF">pdf</a>, <a href="/format/2309.00920" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Trustworthy Distributed Average Consensus based on Locally Assessed  Trust Evaluations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hadjicostis%2C+C+N">Christoforos N. Hadjicostis</a>, 
<a href="/search/cs?searchtype=author&query=Dominguez-Garcia%2C+A+D">Alejandro D. Dominguez-Garcia</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Multiagent Systems (cs.MA)</span>

</div>
<p class="mathjax">This paper proposes a distributed algorithm for average consensus in a
multi-agent system under a fixed bidirectional communication topology, in the
presence of malicious agents (nodes) that may try to influence the average
consensus outcome by manipulating their updates. The proposed algorithm
converges asymptotically to the average of the initial values of the
non-malicious nodes, which we refer to as the trustworthy average, as long as
the underlying topology that describes the information exchange among the
non-malicious nodes is connected. We first present a distributed iterative
algorithm that assumes that each node receives (at each iteration or
periodically) side information about the trustworthiness of the other nodes,
and it uses such trust assessments to determine whether or not to incorporate
messages received from its neighbors, as well as to make proper adjustments in
its calculation depending on whether a previously trustworthy neighbor becomes
untrustworthy or vice-versa. We show that, as long as the trust assessments for
each non-malicious node eventually reflect correctly the status (malicious or
non-malicious) of its neighboring nodes, the algorithm guarantees asymptotic
convergence to the trustworthy average. We subsequently discuss how the
proposed algorithm can be enhanced with functionality that enables each node to
obtain trust assessments about its neighbors by utilizing information that it
receives from its two-hop neighbors at infrequent, perhaps randomly chosen,
time instants.
</p>
</div>
</dd>
<dt><a name="item117">[117]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.00921" title="Abstract">arXiv:2309.00921</a> [<a href="/pdf/2309.00921" title="Download PDF">pdf</a>, <a href="/ps/2309.00921" title="Download PostScript">ps</a>, <a href="/format/2309.00921" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An iterative scheme for finite horizon model reduction of  continuous-time linear time-varying systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Das%2C+K">Kasturi Das</a>, 
<a href="/search/eess?searchtype=author&query=Krishnaswamy%2C+S">Srinivasan Krishnaswamy</a>, 
<a href="/search/eess?searchtype=author&query=Majhi%2C+S">Somanath Majhi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">In this paper, we obtain the functional derivatives of a finite horizon error
norm between a full-order and a reduced-order continuous-time linear
time-varying (LTV) system. Based on the functional derivatives, first-order
necessary conditions for optimality of the error norm are derived, and a
projection-based iterative scheme for model reduction is proposed. The
iterative scheme upon convergence produces reduced-order models satisfying the
optimality conditions. Finally, through a numerical example, we demonstrate the
better performance of the proposed model reduction scheme in comparison to the
finite horizon balanced truncation algorithm for continuous-time LTV systems.
</p>
</div>
</dd>
<dt><a name="item118">[118]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.00923" title="Abstract">arXiv:2309.00923</a> [<a href="/pdf/2309.00923" title="Download PDF">pdf</a>, <a href="/format/2309.00923" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GBE-MLZSL: A Group Bi-Enhancement Framework for Multi-Label Zero-Shot  Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Ziming Liu</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+J">Jingcai Guo</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+X">Xiaocheng Lu</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+S">Song Guo</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+P">Peiran Dong</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jiewei Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages, 8 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">This paper investigates a challenging problem of zero-shot learning in the
multi-label scenario (MLZSL), wherein, the model is trained to recognize
multiple unseen classes within a sample (e.g., an image) based on seen classes
and auxiliary knowledge, e.g., semantic information. Existing methods usually
resort to analyzing the relationship of various seen classes residing in a
sample from the dimension of spatial or semantic characteristics, and transfer
the learned model to unseen ones. But they ignore the effective integration of
local and global features. That is, in the process of inferring unseen classes,
global features represent the principal direction of the image in the feature
space, while local features should maintain uniqueness within a certain range.
This integrated neglect will make the model lose its grasp of the main
components of the image. Relying only on the local existence of seen classes
during the inference stage introduces unavoidable bias. In this paper, we
propose a novel and effective group bi-enhancement framework for MLZSL, dubbed
GBE-MLZSL, to fully make use of such properties and enable a more accurate and
robust visual-semantic projection. Specifically, we split the feature maps into
several feature groups, of which each feature group can be trained
independently with the Local Information Distinguishing Module (LID) to ensure
uniqueness. Meanwhile, a Global Enhancement Module (GEM) is designed to
preserve the principal direction. Besides, a static graph structure is designed
to construct the correlation of local features. Experiments on large-scale
MLZSL benchmark datasets NUS-WIDE and Open-Images-v4 demonstrate that the
proposed GBE-MLZSL outperforms other state-of-the-art methods with large
margins.
</p>
</div>
</dd>
<dt><a name="item119">[119]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.00928" title="Abstract">arXiv:2309.00928</a> [<a href="/pdf/2309.00928" title="Download PDF">pdf</a>, <a href="/format/2309.00928" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> S$^3$-MonoDETR: Supervised Shape&amp;Scale-perceptive Deformable Transformer  for Monocular 3D Object Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=He%2C+X">Xuan He</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+K">Kailun Yang</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+J">Junwei Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+J">Jin Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Bergasa%2C+L+M">Luis M. Bergasa</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Hui Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zhiyong Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> The source code will be made publicly available at <a href="https://github.com/mikasa3lili/S3-MonoDETR">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Robotics (cs.RO); Image and Video Processing (eess.IV)

</div>
<p class="mathjax">Recently, transformer-based methods have shown exceptional performance in
monocular 3D object detection, which can predict 3D attributes from a single 2D
image. These methods typically use visual and depth representations to generate
query points on objects, whose quality plays a decisive role in the detection
accuracy. However, current unsupervised attention mechanisms without any
geometry appearance awareness in transformers are susceptible to producing
noisy features for query points, which severely limits the network performance
and also makes the model have a poor ability to detect multi-category objects
in a single training process. To tackle this problem, this paper proposes a
novel "Supervised Shape&amp;Scale-perceptive Deformable Attention" (S$^3$-DA)
module for monocular 3D object detection. Concretely, S$^3$-DA utilizes visual
and depth features to generate diverse local features with various shapes and
scales and predict the corresponding matching distribution simultaneously to
impose valuable shape&amp;scale perception for each query. Benefiting from this,
S$^3$-DA effectively estimates receptive fields for query points belonging to
any category, enabling them to generate robust query features. Besides, we
propose a Multi-classification-based Shape$\&amp;$Scale Matching (MSM) loss to
supervise the above process. Extensive experiments on KITTI and Waymo Open
datasets demonstrate that S$^3$-DA significantly improves the detection
accuracy, yielding state-of-the-art performance of single-category and
multi-category 3D object detection in a single training process compared to the
existing approaches. The source code will be made publicly available at
https://github.com/mikasa3lili/S3-MonoDETR.
</p>
</div>
</dd>
<dt><a name="item120">[120]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.00929" title="Abstract">arXiv:2309.00929</a> [<a href="/pdf/2309.00929" title="Download PDF">pdf</a>, <a href="/format/2309.00929" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Timbre-reserved Adversarial Attack in Speaker Identification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Q">Qing Wang</a>, 
<a href="/search/cs?searchtype=author&query=Yao%2C+J">Jixun Yao</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+L">Li Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+P">Pengcheng Guo</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+L">Lei Xie</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages, 8 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">As a type of biometric identification, a speaker identification (SID) system
is confronted with various kinds of attacks. The spoofing attacks typically
imitate the timbre of the target speakers, while the adversarial attacks
confuse the SID system by adding a well-designed adversarial perturbation to an
arbitrary speech. Although the spoofing attack copies a similar timbre as the
victim, it does not exploit the vulnerability of the SID model and may not make
the SID system give the attacker's desired decision. As for the adversarial
attack, despite the SID system can be led to a designated decision, it cannot
meet the specified text or speaker timbre requirements for the specific attack
scenarios. In this study, to make the attack in SID not only leverage the
vulnerability of the SID model but also reserve the timbre of the target
speaker, we propose a timbre-reserved adversarial attack in the speaker
identification. We generate the timbre-reserved adversarial audios by adding an
adversarial constraint during the different training stages of the voice
conversion (VC) model. Specifically, the adversarial constraint is using the
target speaker label to optimize the adversarial perturbation added to the VC
model representations and is implemented by a speaker classifier joining in the
VC model training. The adversarial constraint can help to control the VC model
to generate the speaker-wised audio. Eventually, the inference of the VC model
is the ideal adversarial fake audio, which is timbre-reserved and can fool the
SID system.
</p>
</div>
</dd>
<dt><a name="item121">[121]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.00931" title="Abstract">arXiv:2309.00931</a> [<a href="/pdf/2309.00931" title="Download PDF">pdf</a>, <a href="/format/2309.00931" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Parametric Finite-Element Discretization of the Surface Stokes  Equations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Hardering%2C+H">Hanne Hardering</a>, 
<a href="/search/math?searchtype=author&query=Praetorius%2C+S">Simon Praetorius</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 36 pages, 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">We study a higher-order surface finite-element (SFEM) penalty-based
discretization of the tangential surface Stokes problem. Several discrete
formulations are investigated which are equivalent in the continuous setting.
The impact of the choice of discretization of the diffusion term and of the
divergence term on numerical accuracy and convergence, as well as on
implementation advantages, is discussed. We analyze the inf-sup stability of
the discrete scheme in a generic approach by lifting stable finite-element
pairs known from the literature. A discretization error analysis in tangential
norms then shows optimal order convergence of an isogeometric setting that
requires only geometric knowledge of the discrete surface.
</p>
</div>
</dd>
<dt><a name="item122">[122]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.00932" title="Abstract">arXiv:2309.00932</a> [<a href="/pdf/2309.00932" title="Download PDF">pdf</a>, <a href="/format/2309.00932" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deep supervised hashing for fast retrieval of radio image cubes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ndung%27u%2C+S">Steven Ndung&#x27;u</a>, 
<a href="/search/cs?searchtype=author&query=Grobler%2C+T">Trienko Grobler</a>, 
<a href="/search/cs?searchtype=author&query=Wijnholds%2C+S+J">Stefan J. Wijnholds</a>, 
<a href="/search/cs?searchtype=author&query=Karastoyanova%2C+D">Dimka Karastoyanova</a>, 
<a href="/search/cs?searchtype=author&query=Azzopardi%2C+G">George Azzopardi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 4 pages, 4 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">The shear number of sources that will be detected by next-generation radio
surveys will be astronomical, which will result in serendipitous discoveries.
Data-dependent deep hashing algorithms have been shown to be efficient at image
retrieval tasks in the fields of computer vision and multimedia. However, there
are limited applications of these methodologies in the field of astronomy. In
this work, we utilize deep hashing to rapidly search for similar images in a
large database. The experiment uses a balanced dataset of 2708 samples
consisting of four classes: Compact, FRI, FRII, and Bent. The performance of
the method was evaluated using the mean average precision (mAP) metric where a
precision of 88.5\% was achieved. The experimental results demonstrate the
capability to search and retrieve similar radio images efficiently and at
scale. The retrieval is based on the Hamming distance between the binary hash
of the query image and those of the reference images in the database.
</p>
</div>
</dd>
<dt><a name="item123">[123]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.00933" title="Abstract">arXiv:2309.00933</a> [<a href="/pdf/2309.00933" title="Download PDF">pdf</a>, <a href="/format/2309.00933" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Two-in-One Depth: Bridging the Gap Between Monocular and Binocular  Self-supervised Depth Estimation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Z">Zhengming Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+Q">Qiulei Dong</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to ICCV 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Monocular and binocular self-supervised depth estimations are two important
and related tasks in computer vision, which aim to predict scene depths from
single images and stereo image pairs respectively. In literature, the two tasks
are usually tackled separately by two different kinds of models, and binocular
models generally fail to predict depth from single images, while the prediction
accuracy of monocular models is generally inferior to binocular models. In this
paper, we propose a Two-in-One self-supervised depth estimation network, called
TiO-Depth, which could not only compatibly handle the two tasks, but also
improve the prediction accuracy. TiO-Depth employs a Siamese architecture and
each sub-network of it could be used as a monocular depth estimation model. For
binocular depth estimation, a Monocular Feature Matching module is proposed for
incorporating the stereo knowledge between the two images, and the full
TiO-Depth is used to predict depths. We also design a multi-stage
joint-training strategy for improving the performances of TiO-Depth in both two
tasks by combining the relative advantages of them. Experimental results on the
KITTI, Cityscapes, and DDAD datasets demonstrate that TiO-Depth outperforms
both the monocular and binocular state-of-the-art methods in most cases, and
further verify the feasibility of a two-in-one network for monocular and
binocular depth estimation. The code is available at
https://github.com/ZM-Zhou/TiO-Depth_pytorch.
</p>
</div>
</dd>
<dt><a name="item124">[124]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.00938" title="Abstract">arXiv:2309.00938</a> [<a href="/pdf/2309.00938" title="Download PDF">pdf</a>, <a href="/format/2309.00938" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exploring the Robustness of Human Parsers Towards Common Corruptions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+S">Sanyi Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+X">Xiaochun Cao</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+R">Rui Wang</a>, 
<a href="/search/cs?searchtype=author&query=Qi%2C+G">Guo-Jun Qi</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+J">Jie Zhou</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by IEEE Transactions on Image Processing (TIP)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Human parsing aims to segment each pixel of the human image with fine-grained
semantic categories. However, current human parsers trained with clean data are
easily confused by numerous image corruptions such as blur and noise. To
improve the robustness of human parsers, in this paper, we construct three
corruption robustness benchmarks, termed LIP-C, ATR-C, and
Pascal-Person-Part-C, to assist us in evaluating the risk tolerance of human
parsing models. Inspired by the data augmentation strategy, we propose a novel
heterogeneous augmentation-enhanced mechanism to bolster robustness under
commonly corrupted conditions. Specifically, two types of data augmentations
from different views, i.e., image-aware augmentation and model-aware
image-to-image transformation, are integrated in a sequential manner for
adapting to unforeseen image corruptions. The image-aware augmentation can
enrich the high diversity of training images with the help of common image
operations. The model-aware augmentation strategy that improves the diversity
of input data by considering the model's randomness. The proposed method is
model-agnostic, and it can plug and play into arbitrary state-of-the-art human
parsing frameworks. The experimental results show that the proposed method
demonstrates good universality which can improve the robustness of the human
parsing models and even the semantic segmentation models when facing various
image common corruptions. Meanwhile, it can still obtain approximate
performance on clean data.
</p>
</div>
</dd>
<dt><a name="item125">[125]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.00939" title="Abstract">arXiv:2309.00939</a> [<a href="/pdf/2309.00939" title="Download PDF">pdf</a>, <a href="/format/2309.00939" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Data Repurposing through Compatibility: A Computational Perspective
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Biega%2C+A+J">Asia J. Biega</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To appear in the Special Issue of the Journal of Institutional and Theoretical Economics on "Machine Learning and the Law". Written for the Symposium on Machine Learning and the Law of the Max Planck Institute for Research on Collective Goods: <a href="https://www.coll.mpg.de/329557/segovia?c=67659">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>

</div>
<p class="mathjax">Reuse of data in new contexts beyond the purposes for which it was originally
collected has contributed to technological innovation and reducing the consent
burden on data subjects. One of the legal mechanisms that makes such reuse
possible is purpose compatibility assessment. In this paper, I offer an
in-depth analysis of this mechanism through a computational lens. I moreover
consider what should qualify as repurposing apart from using data for a
completely new task, and argue that typical purpose formulations are an
impediment to meaningful repurposing. Overall, the paper positions
compatibility assessment as a constructive practice beyond an ineffective
standard.
</p>
</div>
</dd>
<dt><a name="item126">[126]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.00940" title="Abstract">arXiv:2309.00940</a> [<a href="/pdf/2309.00940" title="Download PDF">pdf</a>, <a href="/format/2309.00940" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Content Prompting: Modeling Content Provider Dynamics to Improve User  Welfare in Recommender Ecosystems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Prasad%2C+S">Siddharth Prasad</a>, 
<a href="/search/cs?searchtype=author&query=Mladenov%2C+M">Martin Mladenov</a>, 
<a href="/search/cs?searchtype=author&query=Boutilier%2C+C">Craig Boutilier</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Multiagent Systems (cs.MA)</span>; Artificial Intelligence (cs.AI); Computer Science and Game Theory (cs.GT); Information Retrieval (cs.IR)

</div>
<p class="mathjax">Users derive value from a recommender system (RS) only to the extent that it
is able to surface content (or items) that meet their needs/preferences. While
RSs often have a comprehensive view of user preferences across the entire user
base, content providers, by contrast, generally have only a local view of the
preferences of users that have interacted with their content. This limits a
provider's ability to offer new content to best serve the broader population.
In this work, we tackle this information asymmetry with content prompting
policies. A content prompt is a hint or suggestion to a provider to make
available novel content for which the RS predicts unmet user demand. A
prompting policy is a sequence of such prompts that is responsive to the
dynamics of a provider's beliefs, skills and incentives. We aim to determine a
joint prompting policy that induces a set of providers to make content
available that optimizes user social welfare in equilibrium, while respecting
the incentives of the providers themselves. Our contributions include: (i) an
abstract model of the RS ecosystem, including content provider behaviors, that
supports such prompting; (ii) the design and theoretical analysis of sequential
prompting policies for individual providers; (iii) a mixed integer programming
formulation for optimal joint prompting using path planning in content space;
and (iv) simple, proof-of-concept experiments illustrating how such policies
improve ecosystem health and user welfare.
</p>
</div>
</dd>
<dt><a name="item127">[127]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.00941" title="Abstract">arXiv:2309.00941</a> [<a href="/pdf/2309.00941" title="Download PDF">pdf</a>, <a href="/format/2309.00941" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Emergent Linear Representations in World Models of Self-Supervised  Sequence Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nanda%2C+N">Neel Nanda</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+A">Andrew Lee</a>, 
<a href="/search/cs?searchtype=author&query=Wattenberg%2C+M">Martin Wattenberg</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">How do sequence models represent their decision-making process? Prior work
suggests that Othello-playing neural network learned nonlinear models of the
board state (Li et al., 2023). In this work, we provide evidence of a closely
related linear representation of the board. In particular, we show that probing
for ``my colour'' vs. ``opponent's colour'' may be a simple yet powerful way to
interpret the model's internal state. This precise understanding of the
internal representations allows us to control the model's behaviour with simple
vector arithmetic. Linear representations enable significant interpretability
progress, which we demonstrate with further exploration of how the world model
is computed.
</p>
</div>
</dd>
<dt><a name="item128">[128]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.00942" title="Abstract">arXiv:2309.00942</a> [<a href="/pdf/2309.00942" title="Download PDF">pdf</a>, <a href="/format/2309.00942" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Tracking without Label: Unsupervised Multiple Object Tracking via  Contrastive Similarity Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Meng%2C+S">Sha Meng</a>, 
<a href="/search/cs?searchtype=author&query=Shao%2C+D">Dian Shao</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+J">Jiacheng Guo</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+S">Shan Gao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Unsupervised learning is a challenging task due to the lack of labels.
Multiple Object Tracking (MOT), which inevitably suffers from mutual object
interference, occlusion, etc., is even more difficult without label
supervision. In this paper, we explore the latent consistency of sample
features across video frames and propose an Unsupervised Contrastive Similarity
Learning method, named UCSL, including three contrast modules: self-contrast,
cross-contrast, and ambiguity contrast. Specifically, i) self-contrast uses
intra-frame direct and inter-frame indirect contrast to obtain discriminative
representations by maximizing self-similarity. ii) Cross-contrast aligns cross-
and continuous-frame matching results, mitigating the persistent negative
effect caused by object occlusion. And iii) ambiguity contrast matches
ambiguous objects with each other to further increase the certainty of
subsequent object association through an implicit manner. On existing
benchmarks, our method outperforms the existing unsupervised methods using only
limited help from ReID head, and even provides higher accuracy than lots of
fully supervised methods.
</p>
</div>
</dd>
<dt><a name="item129">[129]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.00944" title="Abstract">arXiv:2309.00944</a> [<a href="/pdf/2309.00944" title="Download PDF">pdf</a>, <a href="/format/2309.00944" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Pressmatch: Automated journalist recommendation for media coverage with  Nearest Neighbor search
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Parekh%2C+S">Soumya Parekh</a>, 
<a href="/search/cs?searchtype=author&query=Patel%2C+J">Jay Patel</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages, 8 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Slating a product for release often involves pitching journalists to run
stories on your press release. Good media coverage often ensures greater
product reach and drives audience engagement for those products. Hence,
ensuring that those releases are pitched to the right journalists with relevant
interests is crucial, since they receive several pitches daily. Keeping up with
journalist beats and curating a media contacts list is often a huge and
time-consuming task. This study proposes a model to automate and expedite the
process by recommending suitable journalists to run media coverage on the press
releases provided by the user.
</p>
</div>
</dd>
<dt><a name="item130">[130]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.00946" title="Abstract">arXiv:2309.00946</a> [<a href="/pdf/2309.00946" title="Download PDF">pdf</a>, <a href="/format/2309.00946" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> From Specific to Generic Learned Sorted Set Dictionaries: A  Theoretically Sound Paradigm Yelding Competitive Data Structural Boosters in  Practice
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Amato%2C+D">Domenico Amato</a>, 
<a href="/search/cs?searchtype=author&query=Bosco%2C+G+L">Giosu&#xe9; Lo Bosco</a>, 
<a href="/search/cs?searchtype=author&query=Giancarlo%2C+R">Raffaele Giancarlo</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>; Artificial Intelligence (cs.AI); Databases (cs.DB); Information Retrieval (cs.IR); Machine Learning (cs.LG)

</div>
<p class="mathjax">This research concerns Learned Data Structures, a recent area that has
emerged at the crossroad of Machine Learning and Classic Data Structures. It is
methodologically important and with a high practical impact. We focus on
Learned Indexes, i.e., Learned Sorted Set Dictionaries. The proposals available
so far are specific in the sense that they can boost, indeed impressively, the
time performance of Table Search Procedures with a sorted layout only, e.g.,
Binary Search. We propose a novel paradigm that, complementing known
specialized ones, can produce Learned versions of any Sorted Set Dictionary,
for instance, Balanced Binary Search Trees or Binary Search on layouts other
that sorted, i.e., Eytzinger. Theoretically, based on it, we obtain several
results of interest, such as (a) the first Learned Optimum Binary Search
Forest, with mean access time bounded by the Entropy of the probability
distribution of the accesses to the Dictionary; (b) the first Learned Sorted
Set Dictionary that, in the Dynamic Case and in an amortized analysis setting,
matches the same time bounds known for Classic Dictionaries. This latter under
widely accepted assumptions regarding the size of the Universe. The
experimental part, somewhat complex in terms of software development, clearly
indicates the nonobvious finding that the generalization we propose can yield
effective and competitive Learned Data Structural Booster, even with respect to
specific benchmark models.
</p>
</div>
</dd>
<dt><a name="item131">[131]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.00949" title="Abstract">arXiv:2309.00949</a> [<a href="/pdf/2309.00949" title="Download PDF">pdf</a>, <a href="/ps/2309.00949" title="Download PostScript">ps</a>, <a href="/format/2309.00949" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multilingual Text Representation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Faisal%2C+F">Fahim Faisal</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> PhD Comprehensive exam report
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Modern NLP breakthrough includes large multilingual models capable of
performing tasks across more than 100 languages. State-of-the-art language
models came a long way, starting from the simple one-hot representation of
words capable of performing tasks like natural language understanding,
common-sense reasoning, or question-answering, thus capturing both the syntax
and semantics of texts. At the same time, language models are expanding beyond
our known language boundary, even competitively performing over very
low-resource dialects of endangered languages. However, there are still
problems to solve to ensure an equitable representation of texts through a
unified modeling space across language and speakers. In this survey, we shed
light on this iterative progression of multilingual text representation and
discuss the driving factors that ultimately led to the current
state-of-the-art. Subsequently, we discuss how the full potential of language
democratization could be obtained, reaching beyond the known limits and what is
the scope of improvement in that space.
</p>
</div>
</dd>
<dt><a name="item132">[132]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.00952" title="Abstract">arXiv:2309.00952</a> [<a href="/pdf/2309.00952" title="Download PDF">pdf</a>, <a href="/format/2309.00952" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Bridge Diffusion Model: bridge non-English language-native text-to-image  diffusion model with English communities
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+S">Shanyuan Liu</a>, 
<a href="/search/cs?searchtype=author&query=Leng%2C+D">Dawei Leng</a>, 
<a href="/search/cs?searchtype=author&query=Yin%2C+Y">Yuhui Yin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Text-to-Image generation (TTI) technologies are advancing rapidly, especially
in the English language communities. However, English-native TTI models
inherently carry biases from English world centric training data, which creates
a dilemma for development of other language-native TTI models. One common
choice is fine-tuning the English-native TTI model with translated samples from
non-English communities. It falls short of fully addressing the model bias
problem. Alternatively, training non-English language native models from
scratch can effectively resolve the English world bias, but diverges from the
English TTI communities, thus not able to utilize the strides continuously
gaining in the English TTI communities any more. To build non-English language
native TTI model meanwhile keep compatability with the English TTI communities,
we propose a novel model structure referred as "Bridge Diffusion Model" (BDM).
The proposed BDM employs a backbone-branch network structure to learn the
non-English language semantics while keep the latent space compatible with the
English-native TTI backbone, in an end-to-end manner. The unique advantages of
the proposed BDM are that it's not only adept at generating images that
precisely depict non-English language semantics, but also compatible with
various English-native TTI plugins, such as different checkpoints, LoRA,
ControlNet, Dreambooth, and Textual Inversion, etc. Moreover, BDM can
concurrently generate content seamlessly combining both non-English native and
English-native semantics within a single image, fostering cultural interaction.
We verify our method by applying BDM to build a Chinese-native TTI model,
whereas the method is generic and applicable to any other language.
</p>
</div>
</dd>
<dt><a name="item133">[133]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.00954" title="Abstract">arXiv:2309.00954</a> [<a href="/pdf/2309.00954" title="Download PDF">pdf</a>, <a href="/ps/2309.00954" title="Download PostScript">ps</a>, <a href="/format/2309.00954" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On Decidability and Expressive Power of Fusion Grammars
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pshenitsyn%2C+T">Tikhon Pshenitsyn</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Formal Languages and Automata Theory (cs.FL)</span>

</div>
<p class="mathjax">We prove decidability of the non-emptiness problems for fusion grammars and
decidability of the membership problem for fusion grammars without markers and
connectors. Additionally, we prove the Parikh theorem for connection-preserving
fusion grammars.
</p>
</div>
</dd>
<dt><a name="item134">[134]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.00956" title="Abstract">arXiv:2309.00956</a> [<a href="/pdf/2309.00956" title="Download PDF">pdf</a>, <a href="/format/2309.00956" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ASF-Net: Robust Video Deraining via Temporal Alignment and Online  Adaptive Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xue%2C+X">Xinwei Xue</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+J">Jia He</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+L">Long Ma</a>, 
<a href="/search/cs?searchtype=author&query=Meng%2C+X">Xiangyu Meng</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+W">Wenlin Li</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+R">Risheng Liu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">In recent times, learning-based methods for video deraining have demonstrated
commendable results. However, there are two critical challenges that these
methods are yet to address: exploiting temporal correlations among adjacent
frames and ensuring adaptability to unknown real-world scenarios. To overcome
these challenges, we explore video deraining from a paradigm design perspective
to learning strategy construction. Specifically, we propose a new computational
paradigm, Alignment-Shift-Fusion Network (ASF-Net), which incorporates a
temporal shift module. This module is novel to this field and provides deeper
exploration of temporal information by facilitating the exchange of
channel-level information within the feature space. To fully discharge the
model's characterization capability, we further construct a LArge-scale RAiny
video dataset (LARA) which also supports the development of this community. On
the basis of the newly-constructed dataset, we explore the parameters learning
process by developing an innovative re-degraded learning strategy. This
strategy bridges the gap between synthetic and real-world scenes, resulting in
stronger scene adaptability. Our proposed approach exhibits superior
performance in three benchmarks and compelling visual quality in real-world
scenarios, underscoring its efficacy. The code is available at
https://github.com/vis-opt-group/ASF-Net.
</p>
</div>
</dd>
<dt><a name="item135">[135]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.00957" title="Abstract">arXiv:2309.00957</a> [<a href="/pdf/2309.00957" title="Download PDF">pdf</a>, <a href="/format/2309.00957" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Visual-Kinematics Graph Learning for Procedure-agnostic Instrument Tip  Segmentation in Robotic Surgeries
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jiaqi Liu</a>, 
<a href="/search/cs?searchtype=author&query=Long%2C+Y">Yonghao Long</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+K">Kai Chen</a>, 
<a href="/search/cs?searchtype=author&query=Leung%2C+C+H">Cheuk Hei Leung</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zerui Wang</a>, 
<a href="/search/cs?searchtype=author&query=Dou%2C+Q">Qi Dou</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to IROS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Robotics (cs.RO)

</div>
<p class="mathjax">Accurate segmentation of surgical instrument tip is an important task for
enabling downstream applications in robotic surgery, such as surgical skill
assessment, tool-tissue interaction and deformation modeling, as well as
surgical autonomy. However, this task is very challenging due to the small
sizes of surgical instrument tips, and significant variance of surgical scenes
across different procedures. Although much effort has been made on visual-based
methods, existing segmentation models still suffer from low robustness thus not
usable in practice. Fortunately, kinematics data from the robotic system can
provide reliable prior for instrument location, which is consistent regardless
of different surgery types. To make use of such multi-modal information, we
propose a novel visual-kinematics graph learning framework to accurately
segment the instrument tip given various surgical procedures. Specifically, a
graph learning framework is proposed to encode relational features of
instrument parts from both image and kinematics. Next, a cross-modal
contrastive loss is designed to incorporate robust geometric prior from
kinematics to image for tip segmentation. We have conducted experiments on a
private paired visual-kinematics dataset including multiple procedures, i.e.,
prostatectomy, total mesorectal excision, fundoplication and distal gastrectomy
on cadaver, and distal gastrectomy on porcine. The leave-one-procedure-out
cross validation demonstrated that our proposed multi-modal segmentation method
significantly outperformed current image-based state-of-the-art approaches,
exceeding averagely 11.2% on Dice.
</p>
</div>
</dd>
<dt><a name="item136">[136]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.00958" title="Abstract">arXiv:2309.00958</a> [<a href="/pdf/2309.00958" title="Download PDF">pdf</a>, <a href="/format/2309.00958" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Index-aware learning of circuits
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Garcia%2C+I+C">Idoia Cortes Garcia</a>, 
<a href="/search/cs?searchtype=author&query=F%C3%B6rster%2C+P">Peter F&#xf6;rster</a>, 
<a href="/search/cs?searchtype=author&query=Jansen%2C+L">Lennart Jansen</a>, 
<a href="/search/cs?searchtype=author&query=Schilders%2C+W">Wil Schilders</a>, 
<a href="/search/cs?searchtype=author&query=Sch%C3%B6ps%2C+S">Sebastian Sch&#xf6;ps</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 15 pages, 15 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Engineering, Finance, and Science (cs.CE)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Electrical circuits are present in a variety of technologies, making their
design an important part of computer aided engineering. The growing number of
tunable parameters that affect the final design leads to a need for new
approaches of quantifying their impact. Machine learning may play a key role in
this regard, however current approaches often make suboptimal use of existing
knowledge about the system at hand. In terms of circuits, their description via
modified nodal analysis is well-understood. This particular formulation leads
to systems of differential-algebraic equations (DAEs) which bring with them a
number of peculiarities, e.g. hidden constraints that the solution needs to
fulfill. We aim to use the recently introduced dissection concept for DAEs that
can decouple a given system into ordinary differential equations, only
depending on differential variables, and purely algebraic equations that
describe the relations between differential and algebraic variables. The idea
then is to only learn the differential variables and reconstruct the algebraic
ones using the relations from the decoupling. This approach guarantees that the
algebraic constraints are fulfilled up to the accuracy of the nonlinear system
solver, which represents the main benefit highlighted in this article.
</p>
</div>
</dd>
<dt><a name="item137">[137]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.00960" title="Abstract">arXiv:2309.00960</a> [<a href="/pdf/2309.00960" title="Download PDF">pdf</a>, <a href="/format/2309.00960" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Network Topology Inference with Sparsity and Laplacian Constraints
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ying%2C+J">Jiaxi Ying</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+X">Xi Han</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+R">Rui Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xiwen Wang</a>, 
<a href="/search/cs?searchtype=author&query=So%2C+H+C">Hing Cheung So</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">We tackle the network topology inference problem by utilizing Laplacian
constrained Gaussian graphical models, which recast the task as estimating a
precision matrix in the form of a graph Laplacian. Recent research
\cite{ying2020nonconvex} has uncovered the limitations of the widely used
$\ell_1$-norm in learning sparse graphs under this model: empirically, the
number of nonzero entries in the solution grows with the regularization
parameter of the $\ell_1$-norm; theoretically, a large regularization parameter
leads to a fully connected (densest) graph. To overcome these challenges, we
propose a graph Laplacian estimation method incorporating the $\ell_0$-norm
constraint. An efficient gradient projection algorithm is developed to solve
the resulting optimization problem, characterized by sparsity and Laplacian
constraints. Through numerical experiments with synthetic and financial
time-series datasets, we demonstrate the effectiveness of the proposed method
in network topology inference.
</p>
</div>
</dd>
<dt><a name="item138">[138]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.00962" title="Abstract">arXiv:2309.00962</a> [<a href="/pdf/2309.00962" title="Download PDF">pdf</a>, <a href="/format/2309.00962" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> NTU4DRadLM: 4D Radar-centric Multi-Modal Dataset for Localization and  Mapping
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jun Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhuge%2C+H">Huayang Zhuge</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yiyao Liu</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+G">Guohao Peng</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Z">Zhenyu Wu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Haoyuan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Lyu%2C+Q">Qiyang Lyu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Heshan Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+C">Chunyang Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Kircali%2C+D">Dogan Kircali</a>, 
<a href="/search/cs?searchtype=author&query=Mharolkar%2C+S">Sanat Mharolkar</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+X">Xun Yang</a>, 
<a href="/search/cs?searchtype=author&query=Yi%2C+S">Su Yi</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yuanzhe Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+D">Danwei Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 2023 IEEE International Intelligent Transportation Systems Conference (ITSC 2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Simultaneous Localization and Mapping (SLAM) is moving towards a robust
perception age. However, LiDAR- and visual- SLAM may easily fail in adverse
conditions (rain, snow, smoke and fog, etc.). In comparison, SLAM based on 4D
Radar, thermal camera and IMU can work robustly. But only a few literature can
be found. A major reason is the lack of related datasets, which seriously
hinders the research. Even though some datasets are proposed based on 4D radar
in past four years, they are mainly designed for object detection, rather than
SLAM. Furthermore, they normally do not include thermal camera. Therefore, in
this paper, NTU4DRadLM is presented to meet this requirement. The main
characteristics are: 1) It is the only dataset that simultaneously includes all
6 sensors: 4D radar, thermal camera, IMU, 3D LiDAR, visual camera and RTK GPS.
2) Specifically designed for SLAM tasks, which provides fine-tuned ground truth
odometry and intentionally formulated loop closures. 3) Considered both
low-speed robot platform and fast-speed unmanned vehicle platform. 4) Covered
structured, unstructured and semi-structured environments. 5) Considered both
middle- and large- scale outdoor environments, i.e., the 6 trajectories range
from 246m to 6.95km. 6) Comprehensively evaluated three types of SLAM
algorithms. Totally, the dataset is around 17.6km, 85mins, 50GB and it will be
accessible from this link: https://github.com/junzhang2016/NTU4DRadLM
</p>
</div>
</dd>
<dt><a name="item139">[139]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.00964" title="Abstract">arXiv:2309.00964</a> [<a href="/pdf/2309.00964" title="Download PDF">pdf</a>, <a href="/format/2309.00964" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> eDKM: An Efficient and Accurate Train-time Weight Clustering for Large  Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cho%2C+M">Minsik Cho</a>, 
<a href="/search/cs?searchtype=author&query=Vahid%2C+K+A">Keivan A. Vahid</a>, 
<a href="/search/cs?searchtype=author&query=Fu%2C+Q">Qichen Fu</a>, 
<a href="/search/cs?searchtype=author&query=Adya%2C+S">Saurabh Adya</a>, 
<a href="/search/cs?searchtype=author&query=Del+Mundo%2C+C+C">Carlo C Del Mundo</a>, 
<a href="/search/cs?searchtype=author&query=Rastegari%2C+M">Mohammad Rastegari</a>, 
<a href="/search/cs?searchtype=author&query=Naik%2C+D">Devang Naik</a>, 
<a href="/search/cs?searchtype=author&query=Zatloukal%2C+P">Peter Zatloukal</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> preprint
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Since Large Language Models or LLMs have demonstrated high-quality
performance on many complex language tasks, there is a great interest in
bringing these LLMs to mobile devices for faster responses and better privacy
protection. However, the size of LLMs (i.e., billions of parameters) requires
highly effective compression to fit into storage-limited devices. Among many
compression techniques, weight-clustering, a form of non-linear quantization,
is one of the leading candidates for LLM compression, and supported by modern
smartphones. Yet, its training overhead is prohibitively significant for LLM
fine-tuning. Especially, Differentiable KMeans Clustering, or DKM, has shown
the state-of-the-art trade-off between compression ratio and accuracy
regression, but its large memory complexity makes it nearly impossible to apply
to train-time LLM compression. In this paper, we propose a memory-efficient DKM
implementation, eDKM powered by novel techniques to reduce the memory footprint
of DKM by orders of magnitudes. For a given tensor to be saved on CPU for the
backward pass of DKM, we compressed the tensor by applying uniquification and
sharding after checking if there is no duplicated tensor previously copied to
CPU. Our experimental results demonstrate that \prjname can fine-tune and
compress a pretrained LLaMA 7B model from 12.6 GB to 2.5 GB (3bit/weight) with
the Alpaca dataset by reducing the train-time memory footprint of a decoder
layer by 130$\times$, while delivering good accuracy on broader LLM benchmarks
(i.e., 77.7\% for PIQA, 66.1\% for Winograde, and so on).
</p>
</div>
</dd>
<dt><a name="item140">[140]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.00966" title="Abstract">arXiv:2309.00966</a> [<a href="/pdf/2309.00966" title="Download PDF">pdf</a>, <a href="/format/2309.00966" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Compositional Diffusion-Based Continuous Constraint Solvers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+Z">Zhutian Yang</a>, 
<a href="/search/cs?searchtype=author&query=Mao%2C+J">Jiayuan Mao</a>, 
<a href="/search/cs?searchtype=author&query=Du%2C+Y">Yilun Du</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+J">Jiajun Wu</a>, 
<a href="/search/cs?searchtype=author&query=Tenenbaum%2C+J+B">Joshua B. Tenenbaum</a>, 
<a href="/search/cs?searchtype=author&query=Lozano-P%C3%A9rez%2C+T">Tom&#xe1;s Lozano-P&#xe9;rez</a>, 
<a href="/search/cs?searchtype=author&query=Kaelbling%2C+L+P">Leslie Pack Kaelbling</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Proceedings of CoRL 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">This paper introduces an approach for learning to solve continuous constraint
satisfaction problems (CCSP) in robotic reasoning and planning. Previous
methods primarily rely on hand-engineering or learning generators for specific
constraint types and then rejecting the value assignments when other
constraints are violated. By contrast, our model, the compositional diffusion
continuous constraint solver (Diffusion-CCSP) derives global solutions to CCSPs
by representing them as factor graphs and combining the energies of diffusion
models trained to sample for individual constraint types. Diffusion-CCSP
exhibits strong generalization to novel combinations of known constraints, and
it can be integrated into a task and motion planner to devise long-horizon
plans that include actions with both discrete and continuous parameters.
Project site: https://diffusion-ccsp.github.io/
</p>
</div>
</dd>
<dt><a name="item141">[141]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.00968" title="Abstract">arXiv:2309.00968</a> [<a href="/pdf/2309.00968" title="Download PDF">pdf</a>, <a href="/format/2309.00968" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multiscale Modeling with Differential Equations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Astuto%2C+C">Clarissa Astuto</a>, 
<a href="/search/math?searchtype=author&query=Russo%2C+G">Giovanni Russo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 40 pages, 20 figures, to be published as a book chapter in a SIAM book
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">Many physical systems are governed by ordinary or partial differential
equations (see, for example, Chapter ''Differential equations'', ''System of
Differential Equations''). Typically the solution of such systems are functions
of time or of a single space variable (in the case of ODE's), or they depend on
multidimensional space coordinates or on space and time (in the case of PDE's).
In some cases, the solutions may depend on several time or space scales. An
example governed by ODE's is the damped harmonic oscillator, in the two extreme
cases of very small or very large damping, the cardiovascular system, where the
thickness of the arteries and veins varies from centimeters to microns, shallow
water equations, which are valid when water depth is small compared to typical
wavelength of surface waves, and sorption kinetics, in which the range of
interaction of a surfactant with an air bubble is much smaller than the size of
the bubble itself. In all such cases a detailed simulation of the models which
resolves all space or time scales is often inefficient or intractable, and
usually even unnecessary to provide a reasonable description of the behavior of
the system. In the Chapter ''Multiscale modeling with differential equations''
we present examples of systems described by ODE's and PDE's which are
intrinsically multiscale, and illustrate how suitable modeling provide an
effective way to capture the essential behavior of the solutions of such
systems without resolving the small scales.
</p>
</div>
</dd>
<dt><a name="item142">[142]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.00974" title="Abstract">arXiv:2309.00974</a> [<a href="/pdf/2309.00974" title="Download PDF">pdf</a>, <a href="/format/2309.00974" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deep-Learning Framework for Optimal Selection of Soil Sampling Sites
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pham%2C+T">Tan-Hanh Pham</a>, 
<a href="/search/cs?searchtype=author&query=Acharya%2C+P">Praneel Acharya</a>, 
<a href="/search/cs?searchtype=author&query=Bachina%2C+S">Sravanthi Bachina</a>, 
<a href="/search/cs?searchtype=author&query=Osterloh%2C+K">Kristopher Osterloh</a>, 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+K">Kim-Doang Nguyen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This paper is the full version of a poster presented at the AI in Agriculture Conference 2023 in Orlando, FL, USA
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">This work leverages the recent advancements of deep learning in image
processing to find optimal locations that present the important characteristics
of a field. The data for training are collected at different fields in local
farms with five features: aspect, flow accumulation, slope, NDVI (normalized
difference vegetation index), and yield. The soil sampling dataset is
challenging because the ground truth is highly imbalanced binary images.
Therefore, we approached the problem with two methods, the first approach
involves utilizing a state-of-the-art model with the convolutional neural
network (CNN) backbone, while the second is to innovate a deep-learning design
grounded in the concepts of transformer and self-attention. Our framework is
constructed with an encoder-decoder architecture with the self-attention
mechanism as the backbone. In the encoder, the self-attention mechanism is the
key feature extractor, which produces feature maps. In the decoder, we
introduce atrous convolution networks to concatenate, fuse the extracted
features, and then export the optimal locations for soil sampling. Currently,
the model has achieved impressive results on the testing dataset, with a mean
accuracy of 99.52%, a mean Intersection over Union (IoU) of 57.35%, and a mean
Dice Coefficient of 71.47%, while the performance metrics of the
state-of-the-art CNN-based model are 66.08%, 3.85%, and 1.98%, respectively.
This indicates that our proposed model outperforms the CNN-based method on the
soil-sampling dataset. To the best of our knowledge, our work is the first to
provide a soil-sampling dataset with multiple attributes and leverage deep
learning techniques to enable the automatic selection of soil-sampling sites.
This work lays a foundation for novel applications of data science and
machine-learning technologies to solve other emerging agricultural problems.
</p>
</div>
</dd>
<dt><a name="item143">[143]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.00976" title="Abstract">arXiv:2309.00976</a> [<a href="/pdf/2309.00976" title="Download PDF">pdf</a>, <a href="/format/2309.00976" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Pure Message Passing Can Estimate Common Neighbor for Link Prediction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dong%2C+K">Kaiwen Dong</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+Z">Zhichun Guo</a>, 
<a href="/search/cs?searchtype=author&query=Chawla%2C+N+V">Nitesh V. Chawla</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> preprint
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Information Retrieval (cs.IR); Social and Information Networks (cs.SI)

</div>
<p class="mathjax">Message Passing Neural Networks (MPNNs) have emerged as the {\em de facto}
standard in graph representation learning. However, when it comes to link
prediction, they often struggle, surpassed by simple heuristics such as Common
Neighbor (CN). This discrepancy stems from a fundamental limitation: while
MPNNs excel in node-level representation, they stumble with encoding the joint
structural features essential to link prediction, like CN. To bridge this gap,
we posit that, by harnessing the orthogonality of input vectors, pure
message-passing can indeed capture joint structural features. Specifically, we
study the proficiency of MPNNs in approximating CN heuristics. Based on our
findings, we introduce the Message Passing Link Predictor (MPLP), a novel link
prediction model. MPLP taps into quasi-orthogonal vectors to estimate
link-level structural features, all while preserving the node-level
complexities. Moreover, our approach demonstrates that leveraging
message-passing to capture structural features could offset MPNNs'
expressiveness limitations at the expense of estimation variance. We conduct
experiments on benchmark datasets from various domains, where our method
consistently outperforms the baseline methods.
</p>
</div>
</dd>
<dt><a name="item144">[144]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.00979" title="Abstract">arXiv:2309.00979</a> [<a href="/pdf/2309.00979" title="Download PDF">pdf</a>, <a href="/format/2309.00979" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ADI schemes for heat equations with irregular boundaries and interfaces  in 3D with applications
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Zhou%2C+H">Han Zhou</a>, 
<a href="/search/math?searchtype=author&query=Huang%2C+M">Minsheng Huang</a>, 
<a href="/search/math?searchtype=author&query=Ying%2C+W">Wenjun Ying</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Computational Physics (physics.comp-ph)

</div>
<p class="mathjax">In this paper, efficient alternating direction implicit (ADI) schemes are
proposed to solve three-dimensional heat equations with irregular boundaries
and interfaces. Starting from the well-known Douglas-Gunn ADI scheme, a
modified ADI scheme is constructed to mitigate the issue of accuracy loss in
solving problems with time-dependent boundary conditions. The unconditional
stability of the new ADI scheme is also rigorously proven with the Fourier
analysis. Then, by combining the ADI schemes with a 1D kernel-free boundary
integral (KFBI) method, KFBI-ADI schemes are developed to solve the heat
equation with irregular boundaries. In 1D sub-problems of the KFBI-ADI schemes,
the KFBI discretization takes advantage of the Cartesian grid and preserves the
structure of the coefficient matrix so that the fast Thomas algorithm can be
applied to solve the linear system efficiently. Second-order accuracy and
unconditional stability of the KFBI-ADI schemes are verified through several
numerical tests for both the heat equation and a reaction-diffusion equation.
For the Stefan problem, which is a free boundary problem of the heat equation,
a level set method is incorporated into the ADI method to capture the
time-dependent interface. Numerical examples for simulating 3D dendritic
solidification phenomenons are also presented.
</p>
</div>
</dd>
<dt><a name="item145">[145]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.00985" title="Abstract">arXiv:2309.00985</a> [<a href="/pdf/2309.00985" title="Download PDF">pdf</a>, <a href="/format/2309.00985" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multi-agent Collective Construction using 3D Decomposition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Srinivasan%2C+A+K">Akshaya Kesarimangalam Srinivasan</a>, 
<a href="/search/cs?searchtype=author&query=Singh%2C+S">Shambhavi Singh</a>, 
<a href="/search/cs?searchtype=author&query=Gutow%2C+G">Geordan Gutow</a>, 
<a href="/search/cs?searchtype=author&query=Choset%2C+H">Howie Choset</a>, 
<a href="/search/cs?searchtype=author&query=Vundurthy%2C+B">Bhaskar Vundurthy</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Presented at the Multi-agent Path Finding Workshop at AAAI 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Multiagent Systems (cs.MA)

</div>
<p class="mathjax">This paper addresses a Multi-Agent Collective Construction (MACC) problem
that aims to build a three-dimensional structure comprised of cubic blocks. We
use cube-shaped robots that can carry one cubic block at a time, and move
forward, reverse, left, and right to an adjacent cell of the same height or
climb up and down one cube height. To construct structures taller than one
cube, the robots must build supporting stairs made of blocks and remove the
stairs once the structure is built. Conventional techniques solve for the
entire structure at once and quickly become intractable for larger workspaces
and complex structures, especially in a multi-agent setting. To this end, we
present a decomposition algorithm that computes valid substructures based on
intrinsic structural dependencies. We use Mixed Integer Linear Programming
(MILP) to solve for each of these substructures and then aggregate the
solutions to construct the entire structure. Extensive testing on 200 randomly
generated structures shows an order of magnitude improvement in the solution
computation time compared to an MILP approach without decomposition.
Additionally, compared to Reinforcement Learning (RL) based and
heuristics-based approaches drawn from the literature, our solution indicates
orders of magnitude improvement in the number of pick-up and drop-off actions
required to construct a structure. Furthermore, we leverage the independence
between substructures to detect which sub-structures can be built in parallel.
With this parallelization technique, we illustrate a further improvement in the
number of time steps required to complete building the structure. This work is
a step towards applying multi-agent collective construction for real-world
structures by significantly reducing solution computation time with a bounded
increase in the number of time steps required to build the structure.
</p>
</div>
</dd>
<dt><a name="item146">[146]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.00986" title="Abstract">arXiv:2309.00986</a> [<a href="/pdf/2309.00986" title="Download PDF">pdf</a>, <a href="/format/2309.00986" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ModelScope-Agent: Building Your Customizable Agent System with  Open-source Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+C">Chenliang Li</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+H">Hehong Chen</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+M">Ming Yan</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+W">Weizhou Shen</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+H">Haiyang Xu</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Z">Zhikai Wu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zhicheng Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+W">Wenmeng Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yingda Chen</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+C">Chen Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+H">Hongzhu Shi</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Ji Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+F">Fei Huang</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+J">Jingren Zhou</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Large language models (LLMs) have recently demonstrated remarkable
capabilities to comprehend human intentions, engage in reasoning, and design
planning-like behavior. To further unleash the power of LLMs to accomplish
complex tasks, there is a growing trend to build agent framework that equips
LLMs, such as ChatGPT, with tool-use abilities to connect with massive external
APIs. In this work, we introduce ModelScope-Agent, a general and customizable
agent framework for real-world applications, based on open-source LLMs as
controllers. It provides a user-friendly system library, with customizable
engine design to support model training on multiple open-source LLMs, while
also enabling seamless integration with both model APIs and common APIs in a
unified way. To equip the LLMs with tool-use abilities, a comprehensive
framework has been proposed spanning over tool-use data collection, tool
retrieval, tool registration, memory control, customized model training, and
evaluation for practical real-world applications. Finally, we showcase
ModelScopeGPT, a real-world intelligent assistant of ModelScope Community based
on the ModelScope-Agent framework, which is able to connect open-source LLMs
with more than 1000 public AI models and localized community knowledge in
ModelScope. The ModelScope-Agent
library\footnote{https://github.com/modelscope/modelscope-agent} and online
demo\footnote{https://modelscope.cn/studios/damo/ModelScopeGPT/summary} are now
publicly available.
</p>
</div>
</dd>
<dt><a name="item147">[147]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.00987" title="Abstract">arXiv:2309.00987</a> [<a href="/pdf/2309.00987" title="Download PDF">pdf</a>, <a href="/format/2309.00987" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Sequential Dexterity: Chaining Dexterous Policies for Long-Horizon  Manipulation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yuanpei Chen</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+C">Chen Wang</a>, 
<a href="/search/cs?searchtype=author&query=Fei-Fei%2C+L">Li Fei-Fei</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+C+K">C. Karen Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> CoRL 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Many real-world manipulation tasks consist of a series of subtasks that are
significantly different from one another. Such long-horizon, complex tasks
highlight the potential of dexterous hands, which possess adaptability and
versatility, capable of seamlessly transitioning between different modes of
functionality without the need for re-grasping or external tools. However, the
challenges arise due to the high-dimensional action space of dexterous hand and
complex compositional dynamics of the long-horizon tasks. We present Sequential
Dexterity, a general system based on reinforcement learning (RL) that chains
multiple dexterous policies for achieving long-horizon task goals. The core of
the system is a transition feasibility function that progressively finetunes
the sub-policies for enhancing chaining success rate, while also enables
autonomous policy-switching for recovery from failures and bypassing redundant
stages. Despite being trained only in simulation with a few task objects, our
system demonstrates generalization capability to novel object shapes and is
able to zero-shot transfer to a real-world robot equipped with a dexterous
hand. More details and video results could be found at
https://sequential-dexterity.github.io
</p>
</div>
</dd>
<dt><a name="item148">[148]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.00993" title="Abstract">arXiv:2309.00993</a> [<a href="/pdf/2309.00993" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Boosted Machine Learning Framework for the Improvement of Phase and  Crystal Structure Prediction of High Entropy Alloys Using Thermodynamic and  Configurational Parameters
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dey%2C+D">Debsundar Dey</a>, 
<a href="/search/cs?searchtype=author&query=Das%2C+S">Suchandan Das</a>, 
<a href="/search/cs?searchtype=author&query=Pal%2C+A">Anik Pal</a>, 
<a href="/search/cs?searchtype=author&query=Dey%2C+S">Santanu Dey</a>, 
<a href="/search/cs?searchtype=author&query=Raul%2C+C+K">Chandan Kumar Raul</a>, 
<a href="/search/cs?searchtype=author&query=Chatterjee%2C+A">Arghya Chatterjee</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">The reason behind the remarkable properties of High-Entropy Alloys (HEAs) is
rooted in the diverse phases and the crystal structures they contain. In the
realm of material informatics, employing machine learning (ML) techniques to
classify phases and crystal structures of HEAs has gained considerable
significance. In this study, we assembled a new collection of 1345 HEAs with
varying compositions to predict phases. Within this collection, there were 705
sets of data that were utilized to predict the crystal structures with the help
of thermodynamics and electronic configuration. Our study introduces a
methodical framework i.e., the Pearson correlation coefficient that helps in
selecting the strongly co-related features to increase the prediction accuracy.
This study employed five distinct boosting algorithms to predict phases and
crystal structures, offering an enhanced guideline for improving the accuracy
of these predictions. Among all these algorithms, XGBoost gives the highest
accuracy of prediction (94.05%) for phases and LightGBM gives the highest
accuracy of prediction of crystal structure of the phases (90.07%). The
quantification of the influence exerted by parameters on the model's accuracy
was conducted and a new approach was made to elucidate the contribution of
individual parameters in the process of phase prediction and crystal structure
prediction.
</p>
</div>
</dd>
<dt><a name="item149">[149]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.00997" title="Abstract">arXiv:2309.00997</a> [<a href="/pdf/2309.00997" title="Download PDF">pdf</a>, <a href="/format/2309.00997" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Switch and Conquer: Efficient Algorithms By Switching Stochastic  Gradient Oracles For Decentralized Saddle Point Problems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sharma%2C+C">Chhavi Sharma</a>, 
<a href="/search/cs?searchtype=author&query=Narayanan%2C+V">Vishnu Narayanan</a>, 
<a href="/search/cs?searchtype=author&query=Balamurugan%2C+P">P. Balamurugan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: substantial text overlap with <a href="/abs/2205.14452">arXiv:2205.14452</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Distributed, Parallel, and Cluster Computing (cs.DC); Data Structures and Algorithms (cs.DS); Optimization and Control (math.OC)

</div>
<p class="mathjax">We consider a class of non-smooth strongly convex-strongly concave saddle
point problems in a decentralized setting without a central server. To solve a
consensus formulation of problems in this class, we develop an inexact primal
dual hybrid gradient (inexact PDHG) procedure that allows generic gradient
computation oracles to update the primal and dual variables. We first
investigate the performance of inexact PDHG with stochastic variance reduction
gradient (SVRG) oracle. Our numerical study uncovers a significant phenomenon
of initial conservative progress of iterates of IPDHG with SVRG oracle. To
tackle this, we develop a simple and effective switching idea, where a
generalized stochastic gradient (GSG) computation oracle is employed to hasten
the iterates' progress to a saddle point solution during the initial phase of
updates, followed by a switch to the SVRG oracle at an appropriate juncture.
The proposed algorithm is named Decentralized Proximal Switching Stochastic
Gradient method with Compression (C-DPSSG), and is proven to converge to an
$\epsilon$-accurate saddle point solution with linear rate. Apart from
delivering highly accurate solutions, our study reveals that utilizing the best
convergence phases of GSG and SVRG oracles makes C-DPSSG well suited for
obtaining solutions of low/medium accuracy faster, useful for certain
applications. Numerical experiments on two benchmark machine learning
applications show C-DPSSG's competitive performance which validate our
theoretical findings.
</p>
</div>
</dd>
<dt><a name="item150">[150]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01000" title="Abstract">arXiv:2309.01000</a> [<a href="/pdf/2309.01000" title="Download PDF">pdf</a>, <a href="/ps/2309.01000" title="Download PostScript">ps</a>, <a href="/format/2309.01000" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Real Time Vehicle Identification: A Synchronous-Transmission Based  Approach
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shekhar%2C+C">Chandra Shekhar</a>, 
<a href="/search/cs?searchtype=author&query=H%2C+M+K">Manish Kausik H</a>, 
<a href="/search/cs?searchtype=author&query=Saha%2C+S">Sudipta Saha</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>

</div>
<p class="mathjax">Identification of the vehicles passing over the roads is a very important
component of traffic monitoring/surveillance. There have been many attempts to
design and develop efficient strategies to carry out the job. However, from the
point of view of practical usefulness and real-time operation, most of them do
not score well. In the current work, we perceive the problem as efficient
real-time communication and data-sharing between the units in charge of
recording the identities of the vehicles, i.e., Vehicle Recorders (VR), and the
Vehicles (VE). We propose a strategy to address the issue with the help of
Synchronous-Transmission (ST), which is a newer paradigm of communication
compared to the traditional paradigm based on Asynchronous-Transmission (AT).
First, we theoretically show that the presence of the physical layer phenomena
called Capture-Effect in ST brings a significant benefit. Next, we also
implement the strategy in a well-known IoT-Operating System Contiki, and
compare its performance with the existing best-known strategy.
</p>
</div>
</dd>
<dt><a name="item151">[151]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01002" title="Abstract">arXiv:2309.01002</a> [<a href="/pdf/2309.01002" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Adaptive output feedback tracking control for bilinear systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Zare%2C+A+R">Amir Reza Zare</a>, 
<a href="/search/eess?searchtype=author&query=shoorehdeli%2C+M+A">Mahdi Aliyari shoorehdeli</a>, 
<a href="/search/eess?searchtype=author&query=Tavan%2C+M">Mehdi Tavan</a>, 
<a href="/search/eess?searchtype=author&query=Sabahi%2C+K">Kamran Sabahi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">This paper deals with the trajectory tracking control problem for a class of
bilinear systems with unmeasurable states and unknown parameters. Firstly, a
full-information controller is suggested that guarantees global tracking under
a persistency of excitation (PE) condition on the desired trajectories. Next, a
model-based observer is designed for the system, which is further developed
into an adaptive observer through dynamic regressor and mixing (DREM) parameter
estimator. This enables global estimation under a weaker convergence condition
where the regressor is PE. The estimated states and parameters are then
replaced in the full-information controller, instead of their respective
unavailable states and parameters, to construct the output feedback controller
and its adaptive version. The proposed algorithm is applied to control lossless
power factor precompensator (PFP) circuit with an unmeasurable input current
and an unknown load conductance.
</p>
</div>
</dd>
<dt><a name="item152">[152]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01004" title="Abstract">arXiv:2309.01004</a> [<a href="/pdf/2309.01004" title="Download PDF">pdf</a>, <a href="/format/2309.01004" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Projection-based reduced order modeling of an iterative coupling scheme  for thermo-poroelasticity
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Ballarin%2C+F">Francesco Ballarin</a>, 
<a href="/search/math?searchtype=author&query=Lee%2C+S">Sanghyun Lee</a>, 
<a href="/search/math?searchtype=author&query=Yi%2C+S">Son-Young Yi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">This paper explores an iterative coupling approach to solve
thermo-poroelasticity problems, with its application as a high-fidelity
discretization utilizing finite elements during the training of
projection-based reduced order models. One of the main challenges in addressing
coupled multi-physics problems is the complexity and computational expenses
involved. In this study, we introduce a decoupled iterative solution approach,
integrated with reduced order modeling, aimed at augmenting the efficiency of
the computational algorithm. The iterative coupling technique we employ builds
upon the established fixed-stress splitting scheme that has been extensively
investigated for Biot's poroelasticity. By leveraging solutions derived from
this coupled iterative scheme, the reduced order model employs an additional
Galerkin projection onto a reduced basis space formed by a small number of
modes obtained through proper orthogonal decomposition. The effectiveness of
the proposed algorithm is demonstrated through numerical experiments,
showcasing its computational prowess.
</p>
</div>
</dd>
<dt><a name="item153">[153]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01005" title="Abstract">arXiv:2309.01005</a> [<a href="/pdf/2309.01005" title="Download PDF">pdf</a>, <a href="/format/2309.01005" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> RevColV2: Exploring Disentangled Representations in Masked Image  Modeling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Han%2C+Q">Qi Han</a>, 
<a href="/search/cs?searchtype=author&query=Cai%2C+Y">Yuxuan Cai</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xiangyu Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Masked image modeling (MIM) has become a prevalent pre-training setup for
vision foundation models and attains promising performance. Despite its
success, existing MIM methods discard the decoder network during downstream
applications, resulting in inconsistent representations between pre-training
and fine-tuning and can hamper downstream task performance. In this paper, we
propose a new architecture, RevColV2, which tackles this issue by keeping the
entire autoencoder architecture during both pre-training and fine-tuning. The
main body of RevColV2 contains bottom-up columns and top-down columns, between
which information is reversibly propagated and gradually disentangled. Such
design enables our architecture with the nice property: maintaining
disentangled low-level and semantic information at the end of the network in
MIM pre-training. Our experimental results suggest that a foundation model with
decoupled features can achieve competitive performance across multiple
downstream vision tasks such as image classification, semantic segmentation and
object detection. For example, after intermediate fine-tuning on ImageNet-22K
dataset, RevColV2-L attains 88.4% top-1 accuracy on ImageNet-1K classification
and 58.6 mIoU on ADE20K semantic segmentation. With extra teacher and large
scale dataset, RevColv2-L achieves 62.1 box AP on COCO detection and 60.4 mIoU
on ADE20K semantic segmentation. Code and models are released at
https://github.com/megvii-research/RevCol
</p>
</div>
</dd>
<dt><a name="item154">[154]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01010" title="Abstract">arXiv:2309.01010</a> [<a href="/pdf/2309.01010" title="Download PDF">pdf</a>, <a href="/format/2309.01010" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Mitigating Motion Blur for Robust 3D Baseball Player Pose Modeling for  Pitch Analysis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bright%2C+J">Jerrin Bright</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yuhao Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zelek%2C+J">John Zelek</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted in the 6th International Workshop on Multimedia Content Analysis in Sports (MMSports'23) @ ACM Multimedia
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Using videos to analyze pitchers in baseball can play a vital role in
strategizing and injury prevention. Computer vision-based pose analysis offers
a time-efficient and cost-effective approach. However, the use of accessible
broadcast videos, with a 30fps framerate, often results in partial body motion
blur during fast actions, limiting the performance of existing pose keypoint
estimation models. Previous works have primarily relied on fixed backgrounds,
assuming minimal motion differences between frames, or utilized multiview data
to address this problem. To this end, we propose a synthetic data augmentation
pipeline to enhance the model's capability to deal with the pitcher's blurry
actions. In addition, we leverage in-the-wild videos to make our model robust
under different real-world conditions and camera positions. By carefully
optimizing the augmentation parameters, we observed a notable reduction in the
loss by 54.2% and 36.2% on the test dataset for 2D and 3D pose estimation
respectively. By applying our approach to existing state-of-the-art pose
estimators, we demonstrate an average improvement of 29.2%. The findings
highlight the effectiveness of our method in mitigating the challenges posed by
motion blur, thereby enhancing the overall quality of pose estimation.
</p>
</div>
</dd>
<dt><a name="item155">[155]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01012" title="Abstract">arXiv:2309.01012</a> [<a href="/pdf/2309.01012" title="Download PDF">pdf</a>, <a href="/format/2309.01012" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Investigating the Day-to-Day Experiences of Users with Traumatic Brain  Injury with Conversational Agents
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hu%2C+Y">Yaxin Hu</a>, 
<a href="/search/cs?searchtype=author&query=Lim%2C+H">Hajin Lim</a>, 
<a href="/search/cs?searchtype=author&query=Johnson%2C+H+L">Hailey L. Johnson</a>, 
<a href="/search/cs?searchtype=author&query=O%27Shaughnessy%2C+J+M">Josephine M. O&#x27;Shaughnessy</a>, 
<a href="/search/cs?searchtype=author&query=Kakonge%2C+L">Lisa Kakonge</a>, 
<a href="/search/cs?searchtype=author&query=Turkstra%2C+L+S">Lyn S. Turkstra</a>, 
<a href="/search/cs?searchtype=author&query=Duff%2C+M+C">Melissa C. Duff</a>, 
<a href="/search/cs?searchtype=author&query=Toma%2C+C+L">Catalina L. Toma</a>, 
<a href="/search/cs?searchtype=author&query=Mutlu%2C+B">Bilge Mutlu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> In Proceedings The 25th International ACM SIGACCESS Conference on Computers and Accessibility (ASSETS'23)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">Traumatic brain injury (TBI) can cause cognitive, communication, and
psychological challenges that profoundly limit independence in everyday life.
Conversational Agents (CAs) can provide individuals with TBI with cognitive and
communication support, although little is known about how they make use of CAs
to address injury-related needs. In this study, we gave nine adults with TBI an
at-home CA for four weeks to investigate use patterns, challenges, and design
requirements, focusing particularly on injury-related use. The findings
revealed significant gaps between the current capabilities of CAs and
accessibility challenges faced by TBI users. We also identified 14 TBI-related
activities that participants engaged in with CAs. We categorized those
activities into four groups: mental health, cognitive activities, healthcare
and rehabilitation, and routine activities. Design implications focus on
accessibility improvements and functional designs of CAs that can better
support the day-to-day needs of people with TBI.
</p>
</div>
</dd>
<dt><a name="item156">[156]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01013" title="Abstract">arXiv:2309.01013</a> [<a href="/pdf/2309.01013" title="Download PDF">pdf</a>, <a href="/format/2309.01013" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Streaming Active Learning for Regression Problems Using Regression via  Classification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Horiguchi%2C+S">Shota Horiguchi</a>, 
<a href="/search/cs?searchtype=author&query=Dohi%2C+K">Kota Dohi</a>, 
<a href="/search/cs?searchtype=author&query=Kawaguchi%2C+Y">Yohei Kawaguchi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">One of the challenges in deploying a machine learning model is that the
model's performance degrades as the operating environment changes. To maintain
the performance, streaming active learning is used, in which the model is
retrained by adding a newly annotated sample to the training dataset if the
prediction of the sample is not certain enough. Although many streaming active
learning methods have been proposed for classification, few efforts have been
made for regression problems, which are often handled in the industrial field.
In this paper, we propose to use the regression-via-classification framework
for streaming active learning for regression. Regression-via-classification
transforms regression problems into classification problems so that streaming
active learning methods proposed for classification problems can be applied
directly to regression problems. Experimental validation on four real data sets
shows that the proposed method can perform regression with higher accuracy at
the same annotation cost.
</p>
</div>
</dd>
<dt><a name="item157">[157]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01015" title="Abstract">arXiv:2309.01015</a> [<a href="/pdf/2309.01015" title="Download PDF">pdf</a>, <a href="/format/2309.01015" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MPTopic: Improving topic modeling via Masked Permuted pre-training
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xinche Zhang</a>, 
<a href="/search/cs?searchtype=author&query=milios%2C+E">Evangelos milios</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, will submit to ECIR 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Topic modeling is pivotal in discerning hidden semantic structures within
texts, thereby generating meaningful descriptive keywords. While innovative
techniques like BERTopic and Top2Vec have recently emerged in the forefront,
they manifest certain limitations. Our analysis indicates that these methods
might not prioritize the refinement of their clustering mechanism, potentially
compromising the quality of derived topic clusters. To illustrate, Top2Vec
designates the centroids of clustering results to represent topics, whereas
BERTopic harnesses C-TF-IDF for its topic extraction.In response to these
challenges, we introduce "TF-RDF" (Term Frequency - Relative Document
Frequency), a distinctive approach to assess the relevance of terms within a
document. Building on the strengths of TF-RDF, we present MPTopic, a clustering
algorithm intrinsically driven by the insights of TF-RDF. Through comprehensive
evaluation, it is evident that the topic keywords identified with the synergy
of MPTopic and TF-RDF outperform those extracted by both BERTopic and Top2Vec.
</p>
</div>
</dd>
<dt><a name="item158">[158]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01017" title="Abstract">arXiv:2309.01017</a> [<a href="/pdf/2309.01017" title="Download PDF">pdf</a>, <a href="/format/2309.01017" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Contrastive Grouping with Transformer for Referring Image Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tang%2C+J">Jiajin Tang</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+G">Ge Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+C">Cheng Shi</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+S">Sibei Yang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by CVPR 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Referring image segmentation aims to segment the target referent in an image
conditioning on a natural language expression. Existing one-stage methods
employ per-pixel classification frameworks, which attempt straightforwardly to
align vision and language at the pixel level, thus failing to capture critical
object-level information. In this paper, we propose a mask classification
framework, Contrastive Grouping with Transformer network (CGFormer), which
explicitly captures object-level information via token-based querying and
grouping strategy. Specifically, CGFormer first introduces learnable query
tokens to represent objects and then alternately queries linguistic features
and groups visual features into the query tokens for object-aware cross-modal
reasoning. In addition, CGFormer achieves cross-level interaction by jointly
updating the query tokens and decoding masks in every two consecutive layers.
Finally, CGFormer cooperates contrastive learning to the grouping strategy to
identify the token and its mask corresponding to the referent. Experimental
results demonstrate that CGFormer outperforms state-of-the-art methods in both
segmentation and generalization settings consistently and significantly.
</p>
</div>
</dd>
<dt><a name="item159">[159]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01020" title="Abstract">arXiv:2309.01020</a> [<a href="/pdf/2309.01020" title="Download PDF">pdf</a>, <a href="/format/2309.01020" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the training and generalization of deep operator networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Lee%2C+S">Sanghyun Lee</a>, 
<a href="/search/math?searchtype=author&query=Shin%2C+Y">Yeonjong Shin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Machine Learning (cs.LG); Machine Learning (stat.ML)

</div>
<p class="mathjax">We present a novel training method for deep operator networks (DeepONets),
one of the most popular neural network models for operators. DeepONets are
constructed by two sub-networks, namely the branch and trunk networks.
Typically, the two sub-networks are trained simultaneously, which amounts to
solving a complex optimization problem in a high dimensional space. In
addition, the nonconvex and nonlinear nature makes training very challenging.
To tackle such a challenge, we propose a two-step training method that trains
the trunk network first and then sequentially trains the branch network. The
core mechanism is motivated by the divide-and-conquer paradigm and is the
decomposition of the entire complex training task into two subtasks with
reduced complexity. Therein the Gram-Schmidt orthonormalization process is
introduced which significantly improves stability and generalization ability.
On the theoretical side, we establish a generalization error estimate in terms
of the number of training data, the width of DeepONets, and the number of input
and output sensors. Numerical examples are presented to demonstrate the
effectiveness of the two-step training method, including Darcy flow in
heterogeneous porous media.
</p>
</div>
</dd>
<dt><a name="item160">[160]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01026" title="Abstract">arXiv:2309.01026</a> [<a href="/pdf/2309.01026" title="Download PDF">pdf</a>, <a href="/format/2309.01026" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Zero-Shot Recommendations with Pre-Trained Large Language Models for  Multimodal Nudging
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Harrison%2C+R">Rachel Harrison</a>, 
<a href="/search/cs?searchtype=author&query=Dereventsov%2C+A">Anton Dereventsov</a>, 
<a href="/search/cs?searchtype=author&query=Bibin%2C+A">Anton Bibin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computation and Language (cs.CL); Information Retrieval (cs.IR); Machine Learning (cs.LG); Multimedia (cs.MM)

</div>
<p class="mathjax">We present a method for zero-shot recommendation of multimodal non-stationary
content that leverages recent advancements in the field of generative AI. We
propose rendering inputs of different modalities as textual descriptions and to
utilize pre-trained LLMs to obtain their numerical representations by computing
semantic embeddings. Once unified representations of all content items are
obtained, the recommendation can be performed by computing an appropriate
similarity metric between them without any additional learning. We demonstrate
our approach on a synthetic multimodal nudging environment, where the inputs
consist of tabular, textual, and visual data.
</p>
</div>
</dd>
<dt><a name="item161">[161]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01029" title="Abstract">arXiv:2309.01029</a> [<a href="/pdf/2309.01029" title="Download PDF">pdf</a>, <a href="/format/2309.01029" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Explainability for Large Language Models: A Survey
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhao%2C+H">Haiyan Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+H">Hanjie Chen</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+F">Fan Yang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+N">Ninghao Liu</a>, 
<a href="/search/cs?searchtype=author&query=Deng%2C+H">Huiqi Deng</a>, 
<a href="/search/cs?searchtype=author&query=Cai%2C+H">Hengyi Cai</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Shuaiqiang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Yin%2C+D">Dawei Yin</a>, 
<a href="/search/cs?searchtype=author&query=Du%2C+M">Mengnan Du</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Large language models (LLMs) have demonstrated impressive capabilities in
natural language processing. However, their internal mechanisms are still
unclear and this lack of transparency poses unwanted risks for downstream
applications. Therefore, understanding and explaining these models is crucial
for elucidating their behaviors, limitations, and social impacts. In this
paper, we introduce a taxonomy of explainability techniques and provide a
structured overview of methods for explaining Transformer-based language
models. We categorize techniques based on the training paradigms of LLMs:
traditional fine-tuning-based paradigm and prompting-based paradigm. For each
paradigm, we summarize the goals and dominant approaches for generating local
explanations of individual predictions and global explanations of overall model
knowledge. We also discuss metrics for evaluating generated explanations, and
discuss how explanations can be leveraged to debug models and improve
performance. Lastly, we examine key challenges and emerging opportunities for
explanation techniques in the era of LLMs in comparison to conventional machine
learning models.
</p>
</div>
</dd>
<dt><a name="item162">[162]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01030" title="Abstract">arXiv:2309.01030</a> [<a href="/pdf/2309.01030" title="Download PDF">pdf</a>, <a href="/format/2309.01030" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Online Adaptive Mahalanobis Distance Estimation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Qin%2C+L">Lianke Qin</a>, 
<a href="/search/cs?searchtype=author&query=Reddy%2C+A">Aravind Reddy</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+Z">Zhao Song</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Mahalanobis metrics are widely used in machine learning in conjunction with
methods like $k$-nearest neighbors, $k$-means clustering, and $k$-medians
clustering. Despite their importance, there has not been any prior work on
applying sketching techniques to speed up algorithms for Mahalanobis metrics.
In this paper, we initiate the study of dimension reduction for Mahalanobis
metrics. In particular, we provide efficient data structures for solving the
Approximate Distance Estimation (ADE) problem for Mahalanobis distances. We
first provide a randomized Monte Carlo data structure. Then, we show how we can
adapt it to provide our main data structure which can handle sequences of
\textit{adaptive} queries and also online updates to both the Mahalanobis
metric matrix and the data points, making it amenable to be used in conjunction
with prior algorithms for online learning of Mahalanobis metrics.
</p>
</div>
</dd>
<dt><a name="item163">[163]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01032" title="Abstract">arXiv:2309.01032</a> [<a href="/pdf/2309.01032" title="Download PDF">pdf</a>, <a href="/format/2309.01032" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Hessian-aware Quantized Node Embeddings for Recommendation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+H">Huiyuan Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+K">Kaixiong Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Lai%2C+K">Kwei-Herng Lai</a>, 
<a href="/search/cs?searchtype=author&query=Yeh%2C+C+M">Chin-Chia Michael Yeh</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+Y">Yan Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+X">Xia Hu</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+H">Hao Yang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>

</div>
<p class="mathjax">Graph Neural Networks (GNNs) have achieved state-of-the-art performance in
recommender systems. Nevertheless, the process of searching and ranking from a
large item corpus usually requires high latency, which limits the widespread
deployment of GNNs in industry-scale applications. To address this issue, many
methods compress user/item representations into the binary embedding space to
reduce space requirements and accelerate inference. Also, they use the
Straight-through Estimator (STE) to prevent vanishing gradients during
back-propagation. However, the STE often causes the gradient mismatch problem,
leading to sub-optimal results.
<br />In this work, we present the Hessian-aware Quantized GNN (HQ-GNN) as an
effective solution for discrete representations of users/items that enable fast
retrieval. HQ-GNN is composed of two components: a GNN encoder for learning
continuous node embeddings and a quantized module for compressing
full-precision embeddings into low-bit ones. Consequently, HQ-GNN benefits from
both lower memory requirements and faster inference speeds compared to vanilla
GNNs. To address the gradient mismatch problem in STE, we further consider the
quantized errors and its second-order derivatives for better stability. The
experimental results on several large-scale datasets show that HQ-GNN achieves
a good balance between latency and performance.
</p>
</div>
</dd>
<dt><a name="item164">[164]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01035" title="Abstract">arXiv:2309.01035</a> [<a href="/pdf/2309.01035" title="Download PDF">pdf</a>, <a href="/format/2309.01035" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deep Deformable Models: Learning 3D Shape Abstractions with Part  Consistency
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+D">Di Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+L">Long Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Zhangli%2C+Q">Qilong Zhangli</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+Y">Yunhe Gao</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+T">Ting Liu</a>, 
<a href="/search/cs?searchtype=author&query=Metaxas%2C+D+N">Dimitris N. Metaxas</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">The task of shape abstraction with semantic part consistency is challenging
due to the complex geometries of natural objects. Recent methods learn to
represent an object shape using a set of simple primitives to fit the target.
\textcolor{black}{However, in these methods, the primitives used do not always
correspond to real parts or lack geometric flexibility for semantic
interpretation.} In this paper, we investigate salient and efficient primitive
descriptors for accurate shape abstractions, and propose \textit{Deep
Deformable Models (DDMs)}. DDM employs global deformations and diffeomorphic
local deformations. These properties enable DDM to abstract complex object
shapes with significantly fewer primitives that offer broader geometry coverage
and finer details. DDM is also capable of learning part-level semantic
correspondences due to the differentiable and invertible properties of our
primitive deformation. Moreover, DDM learning formulation is based on dynamic
and kinematic modeling, which enables joint regularization of each
sub-transformation during primitive fitting. Extensive experiments on
\textit{ShapeNet} demonstrate that DDM outperforms the state-of-the-art in
terms of reconstruction and part consistency by a notable margin.
</p>
</div>
</dd>
<dt><a name="item165">[165]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01036" title="Abstract">arXiv:2309.01036</a> [<a href="/pdf/2309.01036" title="Download PDF">pdf</a>, <a href="/format/2309.01036" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SEPAL: Spatial Gene Expression Prediction from Local Graphs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mejia%2C+G">Gabriel Mejia</a>, 
<a href="/search/cs?searchtype=author&query=C%C3%A1rdenas%2C+P">Paula C&#xe1;rdenas</a>, 
<a href="/search/cs?searchtype=author&query=Ruiz%2C+D">Daniela Ruiz</a>, 
<a href="/search/cs?searchtype=author&query=Castillo%2C+A">Angela Castillo</a>, 
<a href="/search/cs?searchtype=author&query=Arbel%C3%A1ez%2C+P">Pablo Arbel&#xe1;ez</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Spatial transcriptomics is an emerging technology that aligns histopathology
images with spatially resolved gene expression profiling. It holds the
potential for understanding many diseases but faces significant bottlenecks
such as specialized equipment and domain expertise. In this work, we present
SEPAL, a new model for predicting genetic profiles from visual tissue
appearance. Our method exploits the biological biases of the problem by
directly supervising relative differences with respect to mean expression, and
leverages local visual context at every coordinate to make predictions using a
graph neural network. This approach closes the gap between complete locality
and complete globality in current methods. In addition, we propose a novel
benchmark that aims to better define the task by following current best
practices in transcriptomics and restricting the prediction variables to only
those with clear spatial patterns. Our extensive evaluation in two different
human breast cancer datasets indicates that SEPAL outperforms previous
state-of-the-art methods and other mechanisms of including spatial context.
</p>
</div>
</dd>
<dt><a name="item166">[166]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01038" title="Abstract">arXiv:2309.01038</a> [<a href="/pdf/2309.01038" title="Download PDF">pdf</a>, <a href="/format/2309.01038" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Neurosymbolic Reinforcement Learning and Planning: A Survey
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Acharya%2C+K">K. Acharya</a>, 
<a href="/search/cs?searchtype=author&query=Raza%2C+W">W. Raza</a>, 
<a href="/search/cs?searchtype=author&query=Dourado%2C+C+M+J+M">C. M. J. M. Dourado Jr</a>, 
<a href="/search/cs?searchtype=author&query=Velasquez%2C+A">A. Velasquez</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+H">H. Song</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 pages, 9 figures, IEEE Transactions on Artificial Intelligence
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">The area of Neurosymbolic Artificial Intelligence (Neurosymbolic AI) is
rapidly developing and has become a popular research topic, encompassing
sub-fields such as Neurosymbolic Deep Learning (Neurosymbolic DL) and
Neurosymbolic Reinforcement Learning (Neurosymbolic RL). Compared to
traditional learning methods, Neurosymbolic AI offers significant advantages by
simplifying complexity and providing transparency and explainability.
Reinforcement Learning(RL), a long-standing Artificial Intelligence(AI) concept
that mimics human behavior using rewards and punishment, is a fundamental
component of Neurosymbolic RL, a recent integration of the two fields that has
yielded promising results. The aim of this paper is to contribute to the
emerging field of Neurosymbolic RL by conducting a literature survey. Our
evaluation focuses on the three components that constitute Neurosymbolic RL:
neural, symbolic, and RL. We categorize works based on the role played by the
neural and symbolic parts in RL, into three taxonomies:Learning for Reasoning,
Reasoning for Learning and Learning-Reasoning. These categories are further
divided into sub-categories based on their applications. Furthermore, we
analyze the RL components of each research work, including the state space,
action space, policy module, and RL algorithm. Additionally, we identify
research opportunities and challenges in various applications within this
dynamic field.
</p>
</div>
</dd>
<dt><a name="item167">[167]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01040" title="Abstract">arXiv:2309.01040</a> [<a href="/pdf/2309.01040" title="Download PDF">pdf</a>, <a href="/ps/2309.01040" title="Download PostScript">ps</a>, <a href="/format/2309.01040" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Efficient Covariance Matrix Reconstruction with Iterative Spatial  Spectrum Sampling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mohammadzadeh%2C+S">S. Mohammadzadeh</a>, 
<a href="/search/cs?searchtype=author&query=Nascimento%2C+V+H">V. H. Nascimento</a>, 
<a href="/search/cs?searchtype=author&query=de+Lamare%2C+R+C">R. C. de Lamare</a>, 
<a href="/search/cs?searchtype=author&query=Kukrer%2C+O">O. Kukrer</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages, 8 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">This work presents a cost-effective technique for designing robust adaptive
beamforming algorithms based on efficient covariance matrix reconstruction with
iterative spatial power spectrum (CMR-ISPS). The proposed CMR-ISPS approach
reconstructs the interference-plus-noise covariance (INC) matrix based on a
simplified maximum entropy power spectral density function that can be used to
shape the directional response of the beamformer. Firstly, we estimate the
directions of arrival (DoAs) of the interfering sources with the available
snapshots. We then develop an algorithm to reconstruct the INC matrix using a
weighted sum of outer products of steering vectors whose coefficients can be
estimated in the vicinity of the DoAs of the interferences which lie in a small
angular sector. We also devise a cost-effective adaptive algorithm based on
conjugate gradient techniques to update the beamforming weights and a method to
obtain estimates of the signal of interest (SOI) steering vector from the
spatial power spectrum. The proposed CMR-ISPS beamformer can suppress
interferers close to the direction of the SOI by producing notches in the
directional response of the array with sufficient depths. Simulation results
are provided to confirm the validity of the proposed method and make a
comparison to existing approaches
</p>
</div>
</dd>
<dt><a name="item168">[168]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01042" title="Abstract">arXiv:2309.01042</a> [<a href="/pdf/2309.01042" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Digital Twins and Blockchain for IoT Management
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Samaniego%2C+M">Mayra Samaniego</a>, 
<a href="/search/cs?searchtype=author&query=Deters%2C+R">Ralph Deters</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Reference: Mayra, Samaniego and Ralph, Deters. 2023. Digital Twins and Blockchain for IoT Management. In The 5th ACM International Symposium on Blockchain and Secure Critical Infrastructure (BSCI '23), July 10-14, 2023, Melbourne, VIC, Australia. ACM, New York, NY, USA, 11 pages. <a href="https://doi.org/10.1145/3594556.3594611">this https URL</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> The 5th ACM International Symposium on Blockchain and Secure
  Critical Infrastructure (BSCI '23), July 10-14, 2023, Melbourne, VIC,
  Australia. 11 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Distributed, Parallel, and Cluster Computing (cs.DC)

</div>
<p class="mathjax">Security and privacy are primary concerns in IoT management. Security
breaches in IoT resources, such as smart sensors, can leak sensitive data and
compromise the privacy of individuals. Effective IoT management requires a
comprehensive approach to prioritize access security and data privacy
protection. Digital twins create virtual representations of IoT resources.
Blockchain adds decentralization, transparency, and reliability to IoT systems.
This research integrates digital twins and blockchain to manage access to IoT
data streaming. Digital twins are used to encapsulate data access and view
configurations. Access is enabled on digital twins, not on IoT resources
directly. Trust structures programmed as smart contracts are the ones that
manage access to digital twins. Consequently, IoT resources are not exposed to
third parties, and access security breaches can be prevented. Blockchain has
been used to validate digital twins and store their configuration. The research
presented in this paper enables multitenant access and customization of data
streaming views and abstracts the complexity of data access management. This
approach provides access and configuration security and data privacy
protection.
</p>
</div>
</dd>
<dt><a name="item169">[169]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01050" title="Abstract">arXiv:2309.01050</a> [<a href="/pdf/2309.01050" title="Download PDF">pdf</a>, <a href="/format/2309.01050" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Efficient Curriculum based Continual Learning with Informative Subset  Selection for Remote Sensing Scene Classification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bhat%2C+S+D">S Divakar Bhat</a>, 
<a href="/search/cs?searchtype=author&query=Banerjee%2C+B">Biplab Banerjee</a>, 
<a href="/search/cs?searchtype=author&query=Chaudhuri%2C+S">Subhasis Chaudhuri</a>, 
<a href="/search/cs?searchtype=author&query=Bhattacharya%2C+A">Avik Bhattacharya</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">We tackle the problem of class incremental learning (CIL) in the realm of
landcover classification from optical remote sensing (RS) images in this paper.
The paradigm of CIL has recently gained much prominence given the fact that
data are generally obtained in a sequential manner for real-world phenomenon.
However, CIL has not been extensively considered yet in the domain of RS
irrespective of the fact that the satellites tend to discover new classes at
different geographical locations temporally. With this motivation, we propose a
novel CIL framework inspired by the recent success of replay-memory based
approaches and tackling two of their shortcomings. In order to reduce the
effect of catastrophic forgetting of the old classes when a new stream arrives,
we learn a curriculum of the new classes based on their similarity with the old
classes. This is found to limit the degree of forgetting substantially. Next
while constructing the replay memory, instead of randomly selecting samples
from the old streams, we propose a sample selection strategy which ensures the
selection of highly confident samples so as to reduce the effects of noise. We
observe a sharp improvement in the CIL performance with the proposed
components. Experimental results on the benchmark NWPU-RESISC45, PatternNet,
and EuroSAT datasets confirm that our method offers improved
stability-plasticity trade-off than the literature.
</p>
</div>
</dd>
<dt><a name="item170">[170]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01051" title="Abstract">arXiv:2309.01051</a> [<a href="/pdf/2309.01051" title="Download PDF">pdf</a>, <a href="/ps/2309.01051" title="Download PostScript">ps</a>, <a href="/format/2309.01051" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On Galois self-orthogonal algebraic geometry codes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ding%2C+Y">Yun Ding</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+S">Shixin Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yang Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 18papers
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>

</div>
<p class="mathjax">Galois self-orthogonal (SO) codes are generalizations of Euclidean and
Hermitian SO codes. Algebraic geometry (AG) codes are the first known class of
linear codes exceeding the Gilbert-Varshamov bound. Both of them have attracted
much attention for their rich algebraic structures and wide applications in
these years. In this paper, we consider them together and study Galois SO AG
codes. A criterion for an AG code being Galois SO is presented. Based on this
criterion, we construct several new classes of maximum distance separable (MDS)
Galois SO AG codes from projective lines and several new classes of Galois SO
AG codes from projective elliptic curves, hyper-elliptic curves and hermitian
curves. In addition, we give an embedding method that allows us to obtain more
MDS Galois SO codes from known MDS Galois SO AG codes.
</p>
</div>
</dd>
<dt><a name="item171">[171]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01055" title="Abstract">arXiv:2309.01055</a> [<a href="/pdf/2309.01055" title="Download PDF">pdf</a>, <a href="/format/2309.01055" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Integration of Vision-based Object Detection and Grasping for  Articulated Manipulator in Lunar Conditions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Boucher%2C+C">Camille Boucher</a>, 
<a href="/search/cs?searchtype=author&query=Diaz%2C+G+H">Gustavo H. Diaz</a>, 
<a href="/search/cs?searchtype=author&query=Santra%2C+S">Shreya Santra</a>, 
<a href="/search/cs?searchtype=author&query=Uno%2C+K">Kentaro Uno</a>, 
<a href="/search/cs?searchtype=author&query=Yoshida%2C+K">Kazuya Yoshida</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">The integration of vision-based frameworks to achieve lunar robot
applications faces numerous challenges such as terrain configuration or extreme
lighting conditions. This paper presents a generic task pipeline using object
detection, instance segmentation and grasp detection, that can be used for
various applications by using the results of these vision-based systems in a
different way. We achieve a rock stacking task on a non-flat surface in
difficult lighting conditions with a very good success rate of 92%. Eventually,
we present an experiment to assemble 3D printed robot components to initiate
more complex tasks in the future.
</p>
</div>
</dd>
<dt><a name="item172">[172]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01063" title="Abstract">arXiv:2309.01063</a> [<a href="/pdf/2309.01063" title="Download PDF">pdf</a>, <a href="/format/2309.01063" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Semi-supervised 3D Video Information Retrieval with Deep Neural Network  and Bi-directional Dynamic-time Warping Algorithm
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ma%2C+Y">Yintai Ma</a>, 
<a href="/search/cs?searchtype=author&query=Klabjan%2C+D">Diego Klabjan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, submitted to IEEE Conference Big Data 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">This paper presents a novel semi-supervised deep learning algorithm for
retrieving similar 2D and 3D videos based on visual content. The proposed
approach combines the power of deep convolutional and recurrent neural networks
with dynamic time warping as a similarity measure. The proposed algorithm is
designed to handle large video datasets and retrieve the most related videos to
a given inquiry video clip based on its graphical frames and contents. We split
both the candidate and the inquiry videos into a sequence of clips and convert
each clip to a representation vector using an autoencoder-backed deep neural
network. We then calculate a similarity measure between the sequences of
embedding vectors using a bi-directional dynamic time-warping method. This
approach is tested on multiple public datasets, including CC\_WEB\_VIDEO,
Youtube-8m, S3DIS, and Synthia, and showed good results compared to
state-of-the-art. The algorithm effectively solves video retrieval tasks and
outperforms the benchmarked state-of-the-art deep learning model.
</p>
</div>
</dd>
<dt><a name="item173">[173]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01064" title="Abstract">arXiv:2309.01064</a> [<a href="/pdf/2309.01064" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Influence of Publication Capacity on Journal Impact Factor for  International Open Access Journals from China: Insights from Microeconomic  Analysis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+X">Xinyi Chen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Digital Libraries (cs.DL)</span>; Applications (stat.AP)

</div>
<p class="mathjax">The evolving landscape of open access (OA) journal publishing holds
significant importance for policymakers and stakeholders who seek to make
informed decisions and develop strategies that foster sustainable growth and
advancements in open access initiatives within China. This study addressed the
shortcomings of the current journal evaluation system and recognized the
necessity of researching the elasticity of annual publication capacity (PUB) in
relation to the Journal Impact Factor (JIF). By constructing an economic model
of elasticity, a comparative analysis of the characteristics and dynamics of
international OA journals from China and overseas was conducted. The analysis
categorized OA journals based on their respective elasticity values and
provided specific recommendations tailored to each category. These
recommendations offer valuable insights into the development and growth
potential of both OA journals from China and overseas. Moreover, the findings
underscore the importance of strategic decision-making to strike a balance
between quantity and quality in OA journal management. By comprehending the
dynamic nature of elasticity, China can enhance its OA journal landscape,
effectively meet the academic demand from domestic researchers, minimize the
outflow of OA publications to overseas markets, and fortify its position within
the global scholarly community.
</p>
</div>
</dd>
<dt><a name="item174">[174]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01065" title="Abstract">arXiv:2309.01065</a> [<a href="/pdf/2309.01065" title="Download PDF">pdf</a>, <a href="/format/2309.01065" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Optimizing Mobile-Edge AI-Generated Everything (AIGX) Services by Prompt  Engineering: Fundamental, Framework, and Case Study
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yinqiu Liu</a>, 
<a href="/search/cs?searchtype=author&query=Du%2C+H">Hongyang Du</a>, 
<a href="/search/cs?searchtype=author&query=Niyato%2C+D">Dusit Niyato</a>, 
<a href="/search/cs?searchtype=author&query=Kang%2C+J">Jiawen Kang</a>, 
<a href="/search/cs?searchtype=author&query=Cui%2C+S">Shuguang Cui</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+X">Xuemin Shen</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+P">Ping Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages, 6 figure
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>

</div>
<p class="mathjax">As the next-generation paradigm for content creation, AI-Generated Content
(AIGC), i.e., generating content automatically by Generative AI (GAI) based on
user prompts, has gained great attention and success recently. With the
ever-increasing power of GAI, especially the emergence of Pretrained Foundation
Models (PFMs) that contain billions of parameters and prompt engineering
methods (i.e., finding the best prompts for the given task), the application
range of AIGC is rapidly expanding, covering various forms of information for
human, systems, and networks, such as network designs, channel coding, and
optimization solutions. In this article, we present the concept of mobile-edge
AI-Generated Everything (AIGX). Specifically, we first review the building
blocks of AIGX, the evolution from AIGC to AIGX, as well as practical AIGX
applications. Then, we present a unified mobile-edge AIGX framework, which
employs edge devices to provide PFM-empowered AIGX services and optimizes such
services via prompt engineering. More importantly, we demonstrate that
suboptimal prompts lead to poor generation quality, which adversely affects
user satisfaction, edge network performance, and resource utilization.
Accordingly, we conduct a case study, showcasing how to train an effective
prompt optimizer using ChatGPT and investigating how much improvement is
possible with prompt engineering in terms of user experience, quality of
generation, and network performance.
</p>
</div>
</dd>
<dt><a name="item175">[175]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01066" title="Abstract">arXiv:2309.01066</a> [<a href="/pdf/2309.01066" title="Download PDF">pdf</a>, <a href="/format/2309.01066" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AB2CD: AI for Building Climate Damage Classification and Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nitsche%2C+M">Maximilian Nitsche</a> (1 and 2), 
<a href="/search/cs?searchtype=author&query=Mukkavilli%2C+S+K">S. Karthik Mukkavilli</a> (3), 
<a href="/search/cs?searchtype=author&query=K%C3%BChl%2C+N">Niklas K&#xfc;hl</a> (4 and 1), 
<a href="/search/cs?searchtype=author&query=Brunschwiler%2C+T">Thomas Brunschwiler</a> (3) ((1) IBM Consulting, Germany, (2) Karlsruhe Institute of Technology, Germany, (3) IBM Research - Europe, Switzerland (4) University of Bayreuth, Germany)
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages, 4 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Computers and Society (cs.CY); Image and Video Processing (eess.IV); Geophysics (physics.geo-ph)

</div>
<p class="mathjax">We explore the implementation of deep learning techniques for precise
building damage assessment in the context of natural hazards, utilizing remote
sensing data. The xBD dataset, comprising diverse disaster events from across
the globe, serves as the primary focus, facilitating the evaluation of deep
learning models. We tackle the challenges of generalization to novel disasters
and regions while accounting for the influence of low-quality and noisy labels
inherent in natural hazard data. Furthermore, our investigation quantitatively
establishes that the minimum satellite imagery resolution essential for
effective building damage detection is 3 meters and below 1 meter for
classification using symmetric and asymmetric resolution perturbation analyses.
To achieve robust and accurate evaluations of building damage detection and
classification, we evaluated different deep learning models with residual,
squeeze and excitation, and dual path network backbones, as well as ensemble
techniques. Overall, the U-Net Siamese network ensemble with F-1 score of 0.812
performed the best against the xView2 challenge benchmark. Additionally, we
evaluate a Universal model trained on all hazards against a flood expert model
and investigate generalization gaps across events, and out of distribution from
field data in the Ahr Valley. Our research findings showcase the potential and
limitations of advanced AI solutions in enhancing the impact assessment of
climate change-induced extreme weather events, such as floods and hurricanes.
These insights have implications for disaster impact assessment in the face of
escalating climate challenges.
</p>
</div>
</dd>
<dt><a name="item176">[176]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01067" title="Abstract">arXiv:2309.01067</a> [<a href="/pdf/2309.01067" title="Download PDF">pdf</a>, <a href="/format/2309.01067" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MQENet: A Mesh Quality Evaluation Neural Network Based on Dynamic Graph  Attention
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Haoxuan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Haisheng Li</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+N">Nan Li</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xiaochuan Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Engineering, Finance, and Science (cs.CE)</span>; Machine Learning (cs.LG); Numerical Analysis (math.NA)

</div>
<p class="mathjax">With the development of computational fluid dynamics, the requirements for
the fluid simulation accuracy in industrial applications have also increased.
The quality of the generated mesh directly affects the simulation accuracy.
However, previous mesh quality metrics and models cannot evaluate meshes
comprehensively and objectively. To this end, we propose MQENet, a structured
mesh quality evaluation neural network based on dynamic graph attention. MQENet
treats the mesh evaluation task as a graph classification task for classifying
the quality of the input structured mesh. To make graphs generated from
structured meshes more informative, MQENet introduces two novel structured mesh
preprocessing algorithms. These two algorithms can also improve the conversion
efficiency of structured mesh data. Experimental results on the benchmark
structured mesh dataset NACA-Market show the effectiveness of MQENet in the
mesh quality evaluation task.
</p>
</div>
</dd>
<dt><a name="item177">[177]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01068" title="Abstract">arXiv:2309.01068</a> [<a href="/pdf/2309.01068" title="Download PDF">pdf</a>, <a href="/format/2309.01068" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Cartesian grid-based boundary integral method for moving interface  problems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Zhou%2C+H">Han Zhou</a>, 
<a href="/search/math?searchtype=author&query=Ying%2C+W">Wenjun Ying</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Computational Physics (physics.comp-ph)

</div>
<p class="mathjax">This paper proposes a Cartesian grid-based boundary integral method for
efficiently and stably solving two representative moving interface problems,
the Hele-Shaw flow and the Stefan problem. Elliptic and parabolic partial
differential equations (PDEs) are reformulated into boundary integral equations
and are then solved with the matrix-free generalized minimal residual (GMRES)
method. The evaluation of boundary integrals is performed by solving equivalent
and simple interface problems with finite difference methods, allowing the use
of fast PDE solvers, such as fast Fourier transform (FFT) and geometric
multigrid methods. The interface curve is evolved utilizing the $\theta-L$
variables instead of the more commonly used $x-y$ variables. This choice
simplifies the preservation of mesh quality during the interface evolution. In
addition, the $\theta-L$ approach enables the design of efficient and stable
time-stepping schemes to remove the stiffness that arises from the curvature
term. Ample numerical examples, including simulations of complex viscous
fingering and dendritic solidification problems, are presented to showcase the
capability of the proposed method to handle challenging moving interface
problems.
</p>
</div>
</dd>
<dt><a name="item178">[178]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01069" title="Abstract">arXiv:2309.01069</a> [<a href="/pdf/2309.01069" title="Download PDF">pdf</a>, <a href="/format/2309.01069" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Separable Hamiltonian Neural Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Khoo%2C+Z">Zi-Yu Khoo</a>, 
<a href="/search/cs?searchtype=author&query=Low%2C+J+S+C">Jonathan Sze Choong Low</a>, 
<a href="/search/cs?searchtype=author&query=Bressan%2C+S">St&#xe9;phane Bressan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">The modelling of dynamical systems from discrete observations is a challenge
faced by modern scientific and engineering data systems. Hamiltonian systems
are one such fundamental and ubiquitous class of dynamical systems. Hamiltonian
neural networks are state-of-the-art models that unsupervised-ly regress the
Hamiltonian of a dynamical system from discrete observations of its vector
field under the learning bias of Hamilton's equations. Yet Hamiltonian dynamics
are often complicated, especially in higher dimensions where the state space of
the Hamiltonian system is large relative to the number of samples. A recently
discovered remedy to alleviate the complexity between state variables in the
state space is to leverage the additive separability of the Hamiltonian system
and embed that additive separability into the Hamiltonian neural network.
Following the nomenclature of physics-informed machine learning, we propose
three separable Hamiltonian neural networks. These models embed additive
separability within Hamiltonian neural networks. The first model uses additive
separability to quadratically scale the amount of data for training Hamiltonian
neural networks. The second model embeds additive separability within the loss
function of the Hamiltonian neural network. The third model embeds additive
separability through the architecture of the Hamiltonian neural network using
conjoined multilayer perceptions. We empirically compare the three models
against state-of-the-art Hamiltonian neural networks, and demonstrate that the
separable Hamiltonian neural networks, which alleviate complexity between the
state variables, are more effective at regressing the Hamiltonian and its
vector field.
</p>
</div>
</dd>
<dt><a name="item179">[179]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01070" title="Abstract">arXiv:2309.01070</a> [<a href="/pdf/2309.01070" title="Download PDF">pdf</a>, <a href="/format/2309.01070" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multidomain transformer-based deep learning for early detection of  network intrusion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jinxin Liu</a>, 
<a href="/search/cs?searchtype=author&query=Simsek%2C+M">Murat Simsek</a>, 
<a href="/search/cs?searchtype=author&query=Nogueira%2C+M">Michele Nogueira</a>, 
<a href="/search/cs?searchtype=author&query=Kantarci%2C+B">Burak Kantarci</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages, 7 figures, 3 tables, IEEE Global Communications Conference (Globecom) 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Timely response of Network Intrusion Detection Systems (NIDS) is constrained
by the flow generation process which requires accumulation of network packets.
This paper introduces Multivariate Time Series (MTS) early detection into NIDS
to identify malicious flows prior to their arrival at target systems. With this
in mind, we first propose a novel feature extractor, Time Series Network Flow
Meter (TS-NFM), that represents network flow as MTS with explainable features,
and a new benchmark dataset is created using TS-NFM and the meta-data of
CICIDS2017, called SCVIC-TS-2022. Additionally, a new deep learning-based early
detection model called Multi-Domain Transformer (MDT) is proposed, which
incorporates the frequency domain into Transformer. This work further proposes
a Multi-Domain Multi-Head Attention (MD-MHA) mechanism to improve the ability
of MDT to extract better features. Based on the experimental results, the
proposed methodology improves the earliness of the conventional NIDS (i.e.,
percentage of packets that are used for classification) by 5x10^4 times and
duration-based earliness (i.e., percentage of duration of the classified
packets of a flow) by a factor of 60, resulting in a 84.1% macro F1 score (31%
higher than Transformer) on SCVIC-TS-2022. Additionally, the proposed MDT
outperforms the state-of-the-art early detection methods by 5% and 6% on ECG
and Wafer datasets, respectively.
</p>
</div>
</dd>
<dt><a name="item180">[180]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01071" title="Abstract">arXiv:2309.01071</a> [<a href="/pdf/2309.01071" title="Download PDF">pdf</a>, <a href="/format/2309.01071" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Business Process Text Sketch Automation Generation Using Large Language  Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhu%2C+R">Rui Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+Q">Quanzhou Hu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+W">Wenxin Li</a>, 
<a href="/search/cs?searchtype=author&query=Xiao%2C+H">Honghao Xiao</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+C">Chaogang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Z">Zixin Zhou</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 7 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Business Process Management (BPM) is gaining increasing attention as it has
the potential to cut costs while boosting output and quality. Business process
document generation is a crucial stage in BPM. However, due to a shortage of
datasets, data-driven deep learning techniques struggle to deliver the expected
results. We propose an approach to transform Conditional Process Trees (CPTs)
into Business Process Text Sketches (BPTSs) using Large Language Models (LLMs).
The traditional prompting approach (Few-shot In-Context Learning) tries to get
the correct answer in one go, and it can find the pattern of transforming
simple CPTs into BPTSs, but for close-domain and CPTs with complex hierarchy,
the traditional prompts perform weakly and with low correctness. We suggest
using this technique to break down a difficult CPT into a number of basic CPTs
and then solve each one in turn, drawing inspiration from the
divide-and-conquer strategy. We chose 100 process trees with depths ranging
from 2 to 5 at random, as well as CPTs with many nodes, many degrees of
selection, and cyclic nesting. Experiments show that our method can achieve a
correct rate of 93.42%, which is 45.17% better than traditional prompting
methods. Our proposed method provides a solution for business process document
generation in the absence of datasets, and secondly, it becomes potentially
possible to provide a large number of datasets for the process model extraction
(PME) domain.
</p>
</div>
</dd>
<dt><a name="item181">[181]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01073" title="Abstract">arXiv:2309.01073</a> [<a href="/pdf/2309.01073" title="Download PDF">pdf</a>, <a href="/format/2309.01073" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Spatial and Visual Perspective-Taking via View Rotation and Relation  Reasoning for Embodied Reference Understanding
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shi%2C+C">Cheng Shi</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+S">Sibei Yang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ECCV 2022. Code: <a href="http://github.com/ChengShiest/REP-ERU">this http URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Embodied Reference Understanding studies the reference understanding in an
embodied fashion, where a receiver is required to locate a target object
referred to by both language and gesture of the sender in a shared physical
environment. Its main challenge lies in how to make the receiver with the
egocentric view access spatial and visual information relative to the sender to
judge how objects are oriented around and seen from the sender, i.e., spatial
and visual perspective-taking. In this paper, we propose a REasoning from your
Perspective (REP) method to tackle the challenge by modeling relations between
the receiver and the sender and the sender and the objects via the proposed
novel view rotation and relation reasoning. Specifically, view rotation first
rotates the receiver to the position of the sender by constructing an embodied
3D coordinate system with the position of the sender as the origin. Then, it
changes the orientation of the receiver to the orientation of the sender by
encoding the body orientation and gesture of the sender. Relation reasoning
models the nonverbal and verbal relations between the sender and the objects by
multi-modal cooperative reasoning in gesture, language, visual content, and
spatial position. Experiment results demonstrate the effectiveness of REP,
which consistently surpasses all existing state-of-the-art algorithms by a
large margin, i.e., +5.22% absolute accuracy in terms of Prec0.5 on YouRefIt.
</p>
</div>
</dd>
<dt><a name="item182">[182]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01074" title="Abstract">arXiv:2309.01074</a> [<a href="/pdf/2309.01074" title="Download PDF">pdf</a>, <a href="/format/2309.01074" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Efficient Modeling and Inference in Multi-Dimensional Gaussian  Process State-Space Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lin%2C+Z">Zhidi Lin</a>, 
<a href="/search/cs?searchtype=author&query=Maro%C3%B1as%2C+J">Juan Maro&#xf1;as</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Ying Li</a>, 
<a href="/search/cs?searchtype=author&query=Yin%2C+F">Feng Yin</a>, 
<a href="/search/cs?searchtype=author&query=Theodoridis%2C+S">Sergios Theodoridis</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Signal Processing (eess.SP); Systems and Control (eess.SY)

</div>
<p class="mathjax">The Gaussian process state-space model (GPSSM) has attracted extensive
attention for modeling complex nonlinear dynamical systems. However, the
existing GPSSM employs separate Gaussian processes (GPs) for each latent state
dimension, leading to escalating computational complexity and parameter
proliferation, thus posing challenges for modeling dynamical systems with
high-dimensional latent states. To surmount this obstacle, we propose to
integrate the efficient transformed Gaussian process (ETGP) into the GPSSM,
which involves pushing a shared GP through multiple normalizing flows to
efficiently model the transition function in high-dimensional latent state
space. Additionally, we develop a corresponding variational inference algorithm
that surpasses existing methods in terms of parameter count and computational
complexity. Experimental results on diverse synthetic and real-world datasets
corroborate the efficiency of the proposed method, while also demonstrating its
ability to achieve similar inference performance compared to existing methods.
Code is available at \url{https://github.com/zhidilin/gpssmProj}.
</p>
</div>
</dd>
<dt><a name="item183">[183]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01075" title="Abstract">arXiv:2309.01075</a> [<a href="/pdf/2309.01075" title="Download PDF">pdf</a>, <a href="/format/2309.01075" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Muti-Stage Hierarchical Food Classification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pan%2C+X">Xinyue Pan</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+J">Jiangpeng He</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+F">Fengqing Zhu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> accepted for ACM MM 2023 Madima
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Food image classification serves as a fundamental and critical step in
image-based dietary assessment, facilitating nutrient intake analysis from
captured food images. However, existing works in food classification
predominantly focuses on predicting 'food types', which do not contain direct
nutritional composition information. This limitation arises from the inherent
discrepancies in nutrition databases, which are tasked with associating each
'food item' with its respective information. Therefore, in this work we aim to
classify food items to align with nutrition database. To this end, we first
introduce VFN-nutrient dataset by annotating each food image in VFN with a food
item that includes nutritional composition information. Such annotation of food
items, being more discriminative than food types, creates a hierarchical
structure within the dataset. However, since the food item annotations are
solely based on nutritional composition information, they do not always show
visual relations with each other, which poses significant challenges when
applying deep learning-based techniques for classification. To address this
issue, we then propose a multi-stage hierarchical framework for food item
classification by iteratively clustering and merging food items during the
training process, which allows the deep model to extract image features that
are discriminative across labels. Our method is evaluated on VFN-nutrient
dataset and achieve promising results compared with existing work in terms of
both food type and food item classification.
</p>
</div>
</dd>
<dt><a name="item184">[184]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01076" title="Abstract">arXiv:2309.01076</a> [<a href="/pdf/2309.01076" title="Download PDF">pdf</a>, <a href="/format/2309.01076" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Federated Few-shot Learning for Cough Classification with Edge Devices
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hoang%2C+N+D">Ngan Dao Hoang</a>, 
<a href="/search/cs?searchtype=author&query=Tran-Anh%2C+D">Dat Tran-Anh</a>, 
<a href="/search/cs?searchtype=author&query=Luong%2C+M">Manh Luong</a>, 
<a href="/search/cs?searchtype=author&query=Tran%2C+C">Cong Tran</a>, 
<a href="/search/cs?searchtype=author&query=Pham%2C+C">Cuong Pham</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 21 pages, 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Sound (cs.SD); Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">Automatically classifying cough sounds is one of the most critical tasks for
the diagnosis and treatment of respiratory diseases. However, collecting a huge
amount of labeled cough dataset is challenging mainly due to high laborious
expenses, data scarcity, and privacy concerns. In this work, our aim is to
develop a framework that can effectively perform cough classification even in
situations when enormous cough data is not available, while also addressing
privacy concerns. Specifically, we formulate a new problem to tackle these
challenges and adopt few-shot learning and federated learning to design a novel
framework, termed F2LCough, for solving the newly formulated problem. We
illustrate the superiority of our method compared with other approaches on
COVID-19 Thermal Face &amp; Cough dataset, in which F2LCough achieves an average
F1-Score of 86%. Our results show the feasibility of few-shot learning combined
with federated learning to build a classification model of cough sounds. This
new methodology is able to classify cough sounds in data-scarce situations and
maintain privacy properties. The outcomes of this work can be a fundamental
framework for building support systems for the detection and diagnosis of
cough-related diseases.
</p>
</div>
</dd>
<dt><a name="item185">[185]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01077" title="Abstract">arXiv:2309.01077</a> [<a href="/pdf/2309.01077" title="Download PDF">pdf</a>, <a href="/format/2309.01077" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Robust Adversarial Defense by Tensor Factorization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bhattarai%2C+M">Manish Bhattarai</a>, 
<a href="/search/cs?searchtype=author&query=Kaymak%2C+M+C">Mehmet Cagri Kaymak</a>, 
<a href="/search/cs?searchtype=author&query=Barron%2C+R">Ryan Barron</a>, 
<a href="/search/cs?searchtype=author&query=Nebgen%2C+B">Ben Nebgen</a>, 
<a href="/search/cs?searchtype=author&query=Rasmussen%2C+K">Kim Rasmussen</a>, 
<a href="/search/cs?searchtype=author&query=Alexandrov%2C+B">Boian Alexandrov</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at 2023 ICMLA Conference
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Cryptography and Security (cs.CR); Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">As machine learning techniques become increasingly prevalent in data
analysis, the threat of adversarial attacks has surged, necessitating robust
defense mechanisms. Among these defenses, methods exploiting low-rank
approximations for input data preprocessing and neural network (NN) parameter
factorization have shown potential. Our work advances this field further by
integrating the tensorization of input data with low-rank decomposition and
tensorization of NN parameters to enhance adversarial defense. The proposed
approach demonstrates significant defense capabilities, maintaining robust
accuracy even when subjected to the strongest known auto-attacks. Evaluations
against leading-edge robust performance benchmarks reveal that our results not
only hold their ground against the best defensive methods available but also
exceed all current defense strategies that rely on tensor factorizations. This
study underscores the potential of integrating tensorization and low-rank
decomposition as a robust defense against adversarial attacks in machine
learning.
</p>
</div>
</dd>
<dt><a name="item186">[186]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01078" title="Abstract">arXiv:2309.01078</a> [<a href="/pdf/2309.01078" title="Download PDF">pdf</a>, <a href="/format/2309.01078" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> UnsMOT: Unified Framework for Unsupervised Multi-Object Tracking with  Geometric Topology Guidance
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tran%2C+S">Son Tran</a>, 
<a href="/search/cs?searchtype=author&query=Tran%2C+C">Cong Tran</a>, 
<a href="/search/cs?searchtype=author&query=Tran%2C+A">Anh Tran</a>, 
<a href="/search/cs?searchtype=author&query=Pham%2C+C">Cuong Pham</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Object detection has long been a topic of high interest in computer vision
literature. Motivated by the fact that annotating data for the multi-object
tracking (MOT) problem is immensely expensive, recent studies have turned their
attention to the unsupervised learning setting. In this paper, we push forward
the state-of-the-art performance of unsupervised MOT methods by proposing
UnsMOT, a novel framework that explicitly combines the appearance and motion
features of objects with geometric information to provide more accurate
tracking. Specifically, we first extract the appearance and motion features
using CNN and RNN models, respectively. Then, we construct a graph of objects
based on their relative distances in a frame, which is fed into a GNN model
together with CNN features to output geometric embedding of objects optimized
using an unsupervised loss function. Finally, associations between objects are
found by matching not only similar extracted features but also geometric
embedding of detections and tracklets. Experimental results show remarkable
performance in terms of HOTA, IDF1, and MOTA metrics in comparison with
state-of-the-art methods.
</p>
</div>
</dd>
<dt><a name="item187">[187]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01081" title="Abstract">arXiv:2309.01081</a> [<a href="/pdf/2309.01081" title="Download PDF">pdf</a>, <a href="/format/2309.01081" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Orientation-Independent Chinese Text Recognition in Scene Images
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yu%2C+H">Haiyang Yu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xiaocong Wang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+B">Bin Li</a>, 
<a href="/search/cs?searchtype=author&query=Xue%2C+X">Xiangyang Xue</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> IJCAI 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Scene text recognition (STR) has attracted much attention due to its broad
applications. The previous works pay more attention to dealing with the
recognition of Latin text images with complex backgrounds by introducing
language models or other auxiliary networks. Different from Latin texts, many
vertical Chinese texts exist in natural scenes, which brings difficulties to
current state-of-the-art STR methods. In this paper, we take the first attempt
to extract orientation-independent visual features by disentangling content and
orientation information of text images, thus recognizing both horizontal and
vertical texts robustly in natural scenes. Specifically, we introduce a
Character Image Reconstruction Network (CIRN) to recover corresponding printed
character images with disentangled content and orientation information. We
conduct experiments on a scene dataset for benchmarking Chinese text
recognition, and the results demonstrate that the proposed method can indeed
improve performance through disentangling content and orientation information.
To further validate the effectiveness of our method, we additionally collect a
Vertical Chinese Text Recognition (VCTR) dataset. The experimental results show
that the proposed method achieves 45.63% improvement on VCTR when introducing
CIRN to the baseline model.
</p>
</div>
</dd>
<dt><a name="item188">[188]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01083" title="Abstract">arXiv:2309.01083</a> [<a href="/pdf/2309.01083" title="Download PDF">pdf</a>, <a href="/format/2309.01083" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Chinese Text Recognition with A Pre-Trained CLIP-Like Model Through  Image-IDS Aligning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yu%2C+H">Haiyang Yu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xiaocong Wang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+B">Bin Li</a>, 
<a href="/search/cs?searchtype=author&query=Xue%2C+X">Xiangyang Xue</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ICCV 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Scene text recognition has been studied for decades due to its broad
applications. However, despite Chinese characters possessing different
characteristics from Latin characters, such as complex inner structures and
large categories, few methods have been proposed for Chinese Text Recognition
(CTR). Particularly, the characteristic of large categories poses challenges in
dealing with zero-shot and few-shot Chinese characters. In this paper, inspired
by the way humans recognize Chinese texts, we propose a two-stage framework for
CTR. Firstly, we pre-train a CLIP-like model through aligning printed character
images and Ideographic Description Sequences (IDS). This pre-training stage
simulates humans recognizing Chinese characters and obtains the canonical
representation of each character. Subsequently, the learned representations are
employed to supervise the CTR model, such that traditional single-character
recognition can be improved to text-line recognition through image-IDS
matching. To evaluate the effectiveness of the proposed method, we conduct
extensive experiments on both Chinese character recognition (CCR) and CTR. The
experimental results demonstrate that the proposed method performs best in CCR
and outperforms previous methods in most scenarios of the CTR benchmark. It is
worth noting that the proposed method can recognize zero-shot Chinese
characters in text images without fine-tuning, whereas previous methods require
fine-tuning when new classes appear. The code is available at
https://github.com/FudanVI/FudanOCR/tree/main/image-ids-CTR.
</p>
</div>
</dd>
<dt><a name="item189">[189]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01086" title="Abstract">arXiv:2309.01086</a> [<a href="/pdf/2309.01086" title="Download PDF">pdf</a>, <a href="/format/2309.01086" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MILA: Memory-Based Instance-Level Adaptation for Cross-Domain Object  Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Krishna%2C+O">Onkar Krishna</a>, 
<a href="/search/cs?searchtype=author&query=Ohashi%2C+H">Hiroki Ohashi</a>, 
<a href="/search/cs?searchtype=author&query=Sinha%2C+S">Saptarshi Sinha</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Cross-domain object detection is challenging, and it involves aligning
labeled source and unlabeled target domains. Previous approaches have used
adversarial training to align features at both image-level and instance-level.
At the instance level, finding a suitable source sample that aligns with a
target sample is crucial. A source sample is considered suitable if it differs
from the target sample only in domain, without differences in unimportant
characteristics such as orientation and color, which can hinder the model's
focus on aligning the domain difference. However, existing instance-level
feature alignment methods struggle to find suitable source instances because
their search scope is limited to mini-batches. Mini-batches are often so small
in size that they do not always contain suitable source instances. The
insufficient diversity of mini-batches becomes problematic particularly when
the target instances have high intra-class variance. To address this issue, we
propose a memory-based instance-level domain adaptation framework. Our method
aligns a target instance with the most similar source instance of the same
category retrieved from a memory storage. Specifically, we introduce a memory
module that dynamically stores the pooled features of all labeled source
instances, categorized by their labels. Additionally, we introduce a simple yet
effective memory retrieval module that retrieves a set of matching memory slots
for target instances. Our experiments on various domain shift scenarios
demonstrate that our approach outperforms existing non-memory-based methods
significantly.
</p>
</div>
</dd>
<dt><a name="item190">[190]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01087" title="Abstract">arXiv:2309.01087</a> [<a href="/pdf/2309.01087" title="Download PDF">pdf</a>, <a href="/format/2309.01087" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Stabilize to Act: Learning to Coordinate for Bimanual Manipulation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Grannen%2C+J">Jennifer Grannen</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Y">Yilin Wu</a>, 
<a href="/search/cs?searchtype=author&query=Vu%2C+B">Brandon Vu</a>, 
<a href="/search/cs?searchtype=author&query=Sadigh%2C+D">Dorsa Sadigh</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Conference on Robot Learning, 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Key to rich, dexterous manipulation in the real world is the ability to
coordinate control across two hands. However, while the promise afforded by
bimanual robotic systems is immense, constructing control policies for dual arm
autonomous systems brings inherent difficulties. One such difficulty is the
high-dimensionality of the bimanual action space, which adds complexity to both
model-based and data-driven methods. We counteract this challenge by drawing
inspiration from humans to propose a novel role assignment framework: a
stabilizing arm holds an object in place to simplify the environment while an
acting arm executes the task. We instantiate this framework with BimanUal
Dexterity from Stabilization (BUDS), which uses a learned restabilizing
classifier to alternate between updating a learned stabilization position to
keep the environment unchanged, and accomplishing the task with an acting
policy learned from demonstrations. We evaluate BUDS on four bimanual tasks of
varying complexities on real-world robots, such as zipping jackets and cutting
vegetables. Given only 20 demonstrations, BUDS achieves 76.9% task success
across our task suite, and generalizes to out-of-distribution objects within a
class with a 52.7% success rate. BUDS is 56.0% more successful than an
unstructured baseline that instead learns a BC stabilizing policy due to the
precision required of these complex tasks. Supplementary material and videos
can be found at https://sites.google.com/view/stabilizetoact .
</p>
</div>
</dd>
<dt><a name="item191">[191]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01090" title="Abstract">arXiv:2309.01090</a> [<a href="/pdf/2309.01090" title="Download PDF">pdf</a>, <a href="/format/2309.01090" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Liquid Democracy in DPoS Blockchains
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+C">Chao Li</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+R">Runhua Xu</a>, 
<a href="/search/cs?searchtype=author&query=Duan%2C+L">Li Duan</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> ACM BSCI 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">Voting mechanisms play a crucial role in decentralized governance of
blockchain systems. Liquid democracy, also known as delegative voting, allows
voters to vote directly or delegate their voting power to others, thereby
contributing to the resolution of problems such as low voter turnout. In recent
years, liquid democracy has been widely adopted by Delegated-Proof-of-Stake
(DPoS) blockchains and implemented successfully on platforms with millions of
users. However, little is known regarding the characteristics and actual
effectiveness of liquid democracy in decentralized governance. This paper
explored for the first time the practical implementation of liquid democracy in
DPoS blockchain systems. Using actual data collected from two major DPoS
blockchains, EOS and Steem, our study compared and evaluated the participation
of different types of users of DPoS blockchain systems in liquid democracy, as
well as extracting and analyzing the delegation chains and networks formed
during the process of liquid democracy within the systems. We believe that the
findings of this paper will contribute to further studies on the design and
implementation of liquid democracy and other voting mechanisms in decentralized
governance.
</p>
</div>
</dd>
<dt><a name="item192">[192]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01092" title="Abstract">arXiv:2309.01092</a> [<a href="/pdf/2309.01092" title="Download PDF">pdf</a>, <a href="/format/2309.01092" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Face Clustering for Connection Discovery from Event Images
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cheung%2C+M">Ming Cheung</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 18 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Social graphs are very useful for many applications, such as recommendations
and community detections. However, they are only accessible to big social
network operators due to both data availability and privacy concerns. Event
images also capture the interactions among the participants, from which social
connections can be discovered to form a social graph. Unlike online social
graphs, social connections carried by event images can be extracted without
user inputs, and hence many social graph-based applications become possible,
even without access to online social graphs. This paper proposes a system to
discover social connections from event images. By utilizing the social
information from even images, such as co-occurrence, a face clustering method
is proposed and implemented, and connections can be discovered without the
identity of the event participants. By collecting over 40000 faces from over
3000 participants, it is shown that the faces can be well clustered with 80% in
F1 score, and social graphs can be constructed. Utilizing offline event images
may create a long-term impact on social network analytics.
</p>
</div>
</dd>
<dt><a name="item193">[193]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01093" title="Abstract">arXiv:2309.01093</a> [<a href="/pdf/2309.01093" title="Download PDF">pdf</a>, <a href="/format/2309.01093" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CoTDet: Affordance Knowledge Prompting for Task Driven Object Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tang%2C+J">Jiajin Tang</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+G">Ge Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+J">Jingyi Yu</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+S">Sibei Yang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by ICCV 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Task driven object detection aims to detect object instances suitable for
affording a task in an image. Its challenge lies in object categories available
for the task being too diverse to be limited to a closed set of object
vocabulary for traditional object detection. Simply mapping categories and
visual features of common objects to the task cannot address the challenge. In
this paper, we propose to explore fundamental affordances rather than object
categories, i.e., common attributes that enable different objects to accomplish
the same task. Moreover, we propose a novel multi-level chain-of-thought
prompting (MLCoT) to extract the affordance knowledge from large language
models, which contains multi-level reasoning steps from task to object examples
to essential visual attributes with rationales. Furthermore, to fully exploit
knowledge to benefit object recognition and localization, we propose a
knowledge-conditional detection framework, namely CoTDet. It conditions the
detector from the knowledge to generate object queries and regress boxes.
Experimental results demonstrate that our CoTDet outperforms state-of-the-art
methods consistently and significantly (+15.6 box AP and +14.8 mask AP) and can
generate rationales for why objects are detected to afford the task.
</p>
</div>
</dd>
<dt><a name="item194">[194]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01098" title="Abstract">arXiv:2309.01098</a> [<a href="/pdf/2309.01098" title="Download PDF">pdf</a>, <a href="/format/2309.01098" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> martFL: Enabling Utility-Driven Data Marketplace with a Robust and  Verifiable Federated Learning Architecture
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+Q">Qi Li</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zhuotao Liu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Q">Qi Li</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+K">Ke Xu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">The development of machine learning models requires a large amount of
training data. Data marketplaces are essential for trading high-quality,
private-domain data not publicly available online. However, due to growing data
privacy concerns, direct data exchange is inappropriate. Federated Learning
(FL) is a distributed machine learning paradigm that exchanges data utilities
(in form of local models or gradients) among multiple parties without directly
sharing the raw data. However, several challenges exist when applying existing
FL architectures to construct a data marketplace: (i) In existing FL
architectures, Data Acquirers (DAs) cannot privately evaluate local models from
Data Providers (DPs) prior to trading; (ii) Model aggregation protocols in
existing FL designs struggle to exclude malicious DPs without "overfitting" to
the DA's (possibly biased) root dataset; (iii) Prior FL designs lack a proper
billing mechanism to enforce the DA to fairly allocate the reward according to
contributions made by different DPs. To address above challenges, we propose
martFL, the first federated learning architecture that is specifically designed
to enable a secure utility-driven data marketplace. At a high level, martFL is
powered by two innovative designs: (i) a quality-aware model aggregation
protocol that achieves robust local model aggregation even when the DA's root
dataset is biased; (ii) a verifiable data transaction protocol that enables the
DA to prove, both succinctly and in zero-knowledge, that it has faithfully
aggregates the local models submitted by different DPs according to the
committed aggregation weights, based on which the DPs can unambiguously claim
the corresponding reward. We implement a prototype of martFL and evaluate it
extensively over various tasks. The results show that martFL can improve the
model accuracy by up to 25% while saving up to 64% data acquisition cost.
</p>
</div>
</dd>
<dt><a name="item195">[195]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01099" title="Abstract">arXiv:2309.01099</a> [<a href="/pdf/2309.01099" title="Download PDF">pdf</a>, <a href="/format/2309.01099" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Enhancing Infrared Small Target Detection Robustness with Bi-Level  Adversarial Framework
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zhu Liu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Z">Zihang Chen</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jinyuan Liu</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+L">Long Ma</a>, 
<a href="/search/cs?searchtype=author&query=Fan%2C+X">Xin Fan</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+R">Risheng Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages, 6 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">The detection of small infrared targets against blurred and cluttered
backgrounds has remained an enduring challenge. In recent years, learning-based
schemes have become the mainstream methodology to establish the mapping
directly. However, these methods are susceptible to the inherent complexities
of changing backgrounds and real-world disturbances, leading to unreliable and
compromised target estimations. In this work, we propose a bi-level adversarial
framework to promote the robustness of detection in the presence of distinct
corruptions. We first propose a bi-level optimization formulation to introduce
dynamic adversarial learning. Specifically, it is composited by the learnable
generation of corruptions to maximize the losses as the lower-level objective
and the robustness promotion of detectors as the upper-level one. We also
provide a hierarchical reinforced learning strategy to discover the most
detrimental corruptions and balance the performance between robustness and
accuracy. To better disentangle the corruptions from salient features, we also
propose a spatial-frequency interaction network for target detection. Extensive
experiments demonstrate our scheme remarkably improves 21.96% IOU across a wide
array of corruptions and notably promotes 4.97% IOU on the general benchmark.
The source codes are available at https://github.com/LiuZhu-CV/BALISTD.
</p>
</div>
</dd>
<dt><a name="item196">[196]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01101" title="Abstract">arXiv:2309.01101</a> [<a href="/pdf/2309.01101" title="Download PDF">pdf</a>, <a href="/format/2309.01101" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> M2HGCL: Multi-Scale Meta-Path Integrated Heterogeneous Graph Contrastive  Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Guo%2C+Y">Yuanyuan Guo</a>, 
<a href="/search/cs?searchtype=author&query=Xia%2C+Y">Yu Xia</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+R">Rui Wang</a>, 
<a href="/search/cs?searchtype=author&query=Duan%2C+R">Rongcheng Duan</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+L">Lu Li</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jiangmeng Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to the conference of ADMA2023 as an Oral presentation
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Inspired by the successful application of contrastive learning on graphs,
researchers attempt to impose graph contrastive learning approaches on
heterogeneous information networks. Orthogonal to homogeneous graphs, the types
of nodes and edges in heterogeneous graphs are diverse so that specialized
graph contrastive learning methods are required. Most existing methods for
heterogeneous graph contrastive learning are implemented by transforming
heterogeneous graphs into homogeneous graphs, which may lead to ramifications
that the valuable information carried by non-target nodes is undermined thereby
exacerbating the performance of contrastive learning models. Additionally,
current heterogeneous graph contrastive learning methods are mainly based on
initial meta-paths given by the dataset, yet according to our deep-going
exploration, we derive empirical conclusions: only initial meta-paths cannot
contain sufficiently discriminative information; and various types of
meta-paths can effectively promote the performance of heterogeneous graph
contrastive learning methods. To this end, we propose a new multi-scale
meta-path integrated heterogeneous graph contrastive learning (M2HGCL) model,
which discards the conventional heterogeneity-homogeneity transformation and
performs the graph contrastive learning in a joint manner. Specifically, we
expand the meta-paths and jointly aggregate the direct neighbor information,
the initial meta-path neighbor information and the expanded meta-path neighbor
information to sufficiently capture discriminative information. A specific
positive sampling strategy is further imposed to remedy the intrinsic
deficiency of contrastive learning, i.e., the hard negative sample sampling
issue. Through extensive experiments on three real-world datasets, we
demonstrate that M2HGCL outperforms the current state-of-the-art baseline
models.
</p>
</div>
</dd>
<dt><a name="item197">[197]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01102" title="Abstract">arXiv:2309.01102</a> [<a href="/pdf/2309.01102" title="Download PDF">pdf</a>, <a href="/format/2309.01102" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Dual Adversarial Resilience for Collaborating Robust Underwater Image  Enhancement and Perception
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zengxi Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+Z">Zhiying Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+Z">Zeru Shi</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jinyuan Liu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+R">Risheng Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages, 9 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Due to the uneven scattering and absorption of different light wavelengths in
aquatic environments, underwater images suffer from low visibility and clear
color deviations. With the advancement of autonomous underwater vehicles,
extensive research has been conducted on learning-based underwater enhancement
algorithms. These works can generate visually pleasing enhanced images and
mitigate the adverse effects of degraded images on subsequent perception tasks.
However, learning-based methods are susceptible to the inherent fragility of
adversarial attacks, causing significant disruption in results. In this work,
we introduce a collaborative adversarial resilience network, dubbed CARNet, for
underwater image enhancement and subsequent detection tasks. Concretely, we
first introduce an invertible network with strong perturbation-perceptual
abilities to isolate attacks from underwater images, preventing interference
with image enhancement and perceptual tasks. Furthermore, we propose a
synchronized attack training strategy with both visual-driven and
perception-driven attacks enabling the network to discern and remove various
types of attacks. Additionally, we incorporate an attack pattern discriminator
to heighten the robustness of the network against different attacks. Extensive
experiments demonstrate that the proposed method outputs visually appealing
enhancement images and perform averagely 6.71% higher detection mAP than
state-of-the-art methods.
</p>
</div>
</dd>
<dt><a name="item198">[198]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01103" title="Abstract">arXiv:2309.01103</a> [<a href="/pdf/2309.01103" title="Download PDF">pdf</a>, <a href="/format/2309.01103" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multi-Relational Contrastive Learning for Recommendation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wei%2C+W">Wei Wei</a>, 
<a href="/search/cs?searchtype=author&query=Xia%2C+L">Lianghao Xia</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+C">Chao Huang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This paper has been published as a full paper at RecSys 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>

</div>
<p class="mathjax">Personalized recommender systems play a crucial role in capturing users'
evolving preferences over time to provide accurate and effective
recommendations on various online platforms. However, many recommendation
models rely on a single type of behavior learning, which limits their ability
to represent the complex relationships between users and items in real-life
scenarios. In such situations, users interact with items in multiple ways,
including clicking, tagging as favorite, reviewing, and purchasing. To address
this issue, we propose the Relation-aware Contrastive Learning (RCL) framework,
which effectively models dynamic interaction heterogeneity. The RCL model
incorporates a multi-relational graph encoder that captures short-term
preference heterogeneity while preserving the dedicated relation semantics for
different types of user-item interactions. Moreover, we design a dynamic
cross-relational memory network that enables the RCL model to capture users'
long-term multi-behavior preferences and the underlying evolving cross-type
behavior dependencies over time. To obtain robust and informative user
representations with both commonality and diversity across multi-behavior
interactions, we introduce a multi-relational contrastive learning paradigm
with heterogeneous short- and long-term interest modeling. Our extensive
experimental studies on several real-world datasets demonstrate the superiority
of the RCL recommender system over various state-of-the-art baselines in terms
of recommendation accuracy and effectiveness.
</p>
</div>
</dd>
<dt><a name="item199">[199]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01104" title="Abstract">arXiv:2309.01104</a> [<a href="/pdf/2309.01104" title="Download PDF">pdf</a>, <a href="/format/2309.01104" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Turn Fake into Real: Adversarial Head Turn Attacks Against Deepfake  Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+W">Weijie Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Z">Zhengyu Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Sebe%2C+N">Nicu Sebe</a>, 
<a href="/search/cs?searchtype=author&query=Lepri%2C+B">Bruno Lepri</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Cryptography and Security (cs.CR); Machine Learning (cs.LG); Multimedia (cs.MM)

</div>
<p class="mathjax">Malicious use of deepfakes leads to serious public concerns and reduces
people's trust in digital media. Although effective deepfake detectors have
been proposed, they are substantially vulnerable to adversarial attacks. To
evaluate the detector's robustness, recent studies have explored various
attacks. However, all existing attacks are limited to 2D image perturbations,
which are hard to translate into real-world facial changes. In this paper, we
propose adversarial head turn (AdvHeat), the first attempt at 3D adversarial
face views against deepfake detectors, based on face view synthesis from a
single-view fake image. Extensive experiments validate the vulnerability of
various detectors to AdvHeat in realistic, black-box scenarios. For example,
AdvHeat based on a simple random search yields a high attack success rate of
96.8% with 360 searching steps. When additional query access is allowed, we can
further reduce the step budget to 50. Additional analyses demonstrate that
AdvHeat is better than conventional attacks on both the cross-detector
transferability and robustness to defenses. The adversarial images generated by
AdvHeat are also shown to have natural looks. Our code, including that for
generating a multi-view dataset consisting of 360 synthetic views for each of
1000 IDs from FaceForensics++, is available at
https://github.com/twowwj/AdvHeaT.
</p>
</div>
</dd>
<dt><a name="item200">[200]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01105" title="Abstract">arXiv:2309.01105</a> [<a href="/pdf/2309.01105" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Study on the Implementation of Generative AI Services Using an  Enterprise Data-Based LLM Application Architecture
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jeong%2C+C">Cheonsu Jeong</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computation and Language (cs.CL)

</div>
<p class="mathjax">This study presents a method for implementing generative AI services by
utilizing the Large Language Model (LLM) application architecture. With recent
advancements in generative AI technology, LLMs have gained prominence across
various domains. In this context, the research addresses the challenge of
information scarcity and proposes specific remedies by harnessing LLM
capabilities. The investigation delves into strategies for mitigating the issue
of inadequate data, offering tailored solutions. The study delves into the
efficacy of employing fine-tuning techniques and direct document integration to
alleviate data insufficiency. A significant contribution of this work is the
development of a Retrieval-Augmented Generation (RAG) model, which tackles the
aforementioned challenges. The RAG model is carefully designed to enhance
information storage and retrieval processes, ensuring improved content
generation. The research elucidates the key phases of the information storage
and retrieval methodology underpinned by the RAG model. A comprehensive
analysis of these steps is undertaken, emphasizing their significance in
addressing the scarcity of data. The study highlights the efficacy of the
proposed method, showcasing its applicability through illustrative instances.
By implementing the RAG model for information storage and retrieval, the
research not only contributes to a deeper comprehension of generative AI
technology but also facilitates its practical usability within enterprises
utilizing LLMs. This work holds substantial value in advancing the field of
generative AI, offering insights into enhancing data-driven content generation
and fostering active utilization of LLM-based services within corporate
settings.
</p>
</div>
</dd>
<dt><a name="item201">[201]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01106" title="Abstract">arXiv:2309.01106</a> [<a href="/pdf/2309.01106" title="Download PDF">pdf</a>, <a href="/format/2309.01106" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AdvMono3D: Advanced Monocular 3D Object Detection with Depth-Aware  Robust Adversarial Training
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xingyuan Li</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jinyuan Liu</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+L">Long Ma</a>, 
<a href="/search/cs?searchtype=author&query=Fan%2C+X">Xin Fan</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+R">Risheng Liu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Monocular 3D object detection plays a pivotal role in the field of autonomous
driving and numerous deep learning-based methods have made significant
breakthroughs in this area. Despite the advancements in detection accuracy and
efficiency, these models tend to fail when faced with such attacks, rendering
them ineffective. Therefore, bolstering the adversarial robustness of 3D
detection models has become a crucial issue that demands immediate attention
and innovative solutions. To mitigate this issue, we propose a depth-aware
robust adversarial training method for monocular 3D object detection, dubbed
DART3D. Specifically, we first design an adversarial attack that iteratively
degrades the 2D and 3D perception capabilities of 3D object detection
models(IDP), serves as the foundation for our subsequent defense mechanism. In
response to this attack, we propose an uncertainty-based residual learning
method for adversarial training. Our adversarial training approach capitalizes
on the inherent uncertainty, enabling the model to significantly improve its
robustness against adversarial attacks. We conducted extensive experiments on
the KITTI 3D datasets, demonstrating that DART3D surpasses direct adversarial
training (the most popular approach) under attacks in 3D object detection
$AP_{R40}$ of car category for the Easy, Moderate, and Hard settings, with
improvements of 4.415%, 4.112%, and 3.195%, respectively.
</p>
</div>
</dd>
<dt><a name="item202">[202]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01107" title="Abstract">arXiv:2309.01107</a> [<a href="/pdf/2309.01107" title="Download PDF">pdf</a>, <a href="/format/2309.01107" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Solving Non-Rectangular Reward-Robust MDPs via Frequency Regularization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gadot%2C+U">Uri Gadot</a>, 
<a href="/search/cs?searchtype=author&query=Derman%2C+E">Esther Derman</a>, 
<a href="/search/cs?searchtype=author&query=Kumar%2C+N">Navdeep Kumar</a>, 
<a href="/search/cs?searchtype=author&query=Elfatihi%2C+M+M">Maxence Mohamed Elfatihi</a>, 
<a href="/search/cs?searchtype=author&query=Levy%2C+K">Kfir Levy</a>, 
<a href="/search/cs?searchtype=author&query=Mannor%2C+S">Shie Mannor</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">In robust Markov decision processes (RMDPs), it is assumed that the reward
and the transition dynamics lie in a given uncertainty set. By targeting
maximal return under the most adversarial model from that set, RMDPs address
performance sensitivity to misspecified environments. Yet, to preserve
computational tractability, the uncertainty set is traditionally independently
structured for each state. This so-called rectangularity condition is solely
motivated by computational concerns. As a result, it lacks a practical
incentive and may lead to overly conservative behavior. In this work, we study
coupled reward RMDPs where the transition kernel is fixed, but the reward
function lies within an $\alpha$-radius from a nominal one. We draw a direct
connection between this type of non-rectangular reward-RMDPs and applying
policy visitation frequency regularization. We introduce a policy-gradient
method, and prove its convergence. Numerical experiments illustrate the learned
policy's robustness and its less conservative behavior when compared to
rectangular uncertainty.
</p>
</div>
</dd>
<dt><a name="item203">[203]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01110" title="Abstract">arXiv:2309.01110</a> [<a href="/pdf/2309.01110" title="Download PDF">pdf</a>, <a href="/format/2309.01110" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Relaxed Agreement Forests
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Martinez%2C+V+A">Virginia Aardevol Martinez</a>, 
<a href="/search/cs?searchtype=author&query=Chaplick%2C+S">Steven Chaplick</a>, 
<a href="/search/cs?searchtype=author&query=Kelk%2C+S">Steven Kelk</a>, 
<a href="/search/cs?searchtype=author&query=Meuwese%2C+R">Ruben Meuwese</a>, 
<a href="/search/cs?searchtype=author&query=Mihalak%2C+M">Matus Mihalak</a>, 
<a href="/search/cs?searchtype=author&query=Stamoulis%2C+G">Georgios Stamoulis</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages plus appendix
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>; Populations and Evolution (q-bio.PE)

</div>
<p class="mathjax">There are multiple factors which can cause the phylogenetic inference process
to produce two or more conflicting hypotheses of the evolutionary history of a
set X of biological entities. That is: phylogenetic trees with the same set of
leaf labels X but with distinct topologies. This leads naturally to the goal of
quantifying the difference between two such trees T_1 and T_2. Here we
introduce the problem of computing a 'maximum relaxed agreement forest' (MRAF)
and use this as a proxy for the dissimilarity of T_1 and T_2, which in this
article we assume to be unrooted binary phylogenetic trees. MRAF asks for a
partition of the leaf labels X into a minimum number of blocks S_1, S_2, ...
S_k such that for each i, the subtrees induced in T_1 and T_2 by S_i are
isomorphic up to suppression of degree-2 nodes and taking the labels X into
account. Unlike the earlier introduced maximum agreement forest (MAF) model,
the subtrees induced by the S_i are allowed to overlap. We prove that it is
NP-hard to compute MRAF, by reducing from the problem of partitioning a
permutation into a minimum number of monotonic subsequences (PIMS).
Furthermore, we show that MRAF has a polynomial time O(log n)-approximation
algorithm where n=|X| and permits exact algorithms with single-exponential
running time. When at least one of the two input trees has a caterpillar
topology, we prove that testing whether a MRAF has size at most k can be
answered in polynomial time when k is fixed. We also note that on two
caterpillars the approximability of MRAF is related to that of PIMS. Finally,
we establish a number of bounds on MRAF, compare its behaviour to MAF both in
theory and in an experimental setting and discuss a number of open problems.
</p>
</div>
</dd>
<dt><a name="item204">[204]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01111" title="Abstract">arXiv:2309.01111</a> [<a href="/pdf/2309.01111" title="Download PDF">pdf</a>, <a href="/format/2309.01111" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ArSDM: Colonoscopy Images Synthesis with Adaptive Refinement Semantic  Diffusion Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Du%2C+Y">Yuhao Du</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+Y">Yuncheng Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Tan%2C+S">Shuangyi Tan</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+X">Xusheng Wu</a>, 
<a href="/search/cs?searchtype=author&query=Dou%2C+Q">Qi Dou</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zhen Li</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+G">Guanbin Li</a>, 
<a href="/search/cs?searchtype=author&query=Wan%2C+X">Xiang Wan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by MICCAI-2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Colonoscopy analysis, particularly automatic polyp segmentation and
detection, is essential for assisting clinical diagnosis and treatment.
However, as medical image annotation is labour- and resource-intensive, the
scarcity of annotated data limits the effectiveness and generalization of
existing methods. Although recent research has focused on data generation and
augmentation to address this issue, the quality of the generated data remains a
challenge, which limits the contribution to the performance of subsequent
tasks. Inspired by the superiority of diffusion models in fitting data
distributions and generating high-quality data, in this paper, we propose an
Adaptive Refinement Semantic Diffusion Model (ArSDM) to generate colonoscopy
images that benefit the downstream tasks. Specifically, ArSDM utilizes the
ground-truth segmentation mask as a prior condition during training and adjusts
the diffusion loss for each input according to the polyp/background size ratio.
Furthermore, ArSDM incorporates a pre-trained segmentation model to refine the
training process by reducing the difference between the ground-truth mask and
the prediction mask. Extensive experiments on segmentation and detection tasks
demonstrate the generated data by ArSDM could significantly boost the
performance of baseline methods.
</p>
</div>
</dd>
<dt><a name="item205">[205]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01112" title="Abstract">arXiv:2309.01112</a> [<a href="/pdf/2309.01112" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Swing Leg Motion Strategy for Heavy-load Legged Robot Based on Force  Sensing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fu%2C+Z">Ze Fu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yinghui Li</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+W">Weizhong Guo</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Systems and Control (eess.SY)

</div>
<p class="mathjax">The heavy-load legged robot has strong load carrying capacity and can adapt
to various unstructured terrains. But the large weight results in higher
requirements for motion stability and environmental perception ability. In
order to utilize force sensing information to improve its motion performance,
in this paper, we propose a finite state machine model for the swing leg in the
static gait by imitating the movement of the elephant. Based on the presence or
absence of additional terrain information, different trajectory planning
strategies are provided for the swing leg to enhance the success rate of
stepping and save energy. The experimental results on a novel quadruped robot
show that our method has strong robustness and can enable heavy-load legged
robots to pass through various complex terrains autonomously and smoothly.
</p>
</div>
</dd>
<dt><a name="item206">[206]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01113" title="Abstract">arXiv:2309.01113</a> [<a href="/pdf/2309.01113" title="Download PDF">pdf</a>, <a href="/format/2309.01113" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Hybrid-Supervised Dual-Search: Leveraging Automatic Learning for  Loss-free Multi-Exposure Image Fusion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+G">Guanyao Wu</a>, 
<a href="/search/cs?searchtype=author&query=Fu%2C+H">Hongming Fu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jinyuan Liu</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+L">Long Ma</a>, 
<a href="/search/cs?searchtype=author&query=Fan%2C+X">Xin Fan</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+R">Risheng Liu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Multi-exposure image fusion (MEF) has emerged as a prominent solution to
address the limitations of digital imaging in representing varied exposure
levels. Despite its advancements, the field grapples with challenges, notably
the reliance on manual designs for network structures and loss functions, and
the constraints of utilizing simulated reference images as ground truths.
Consequently, current methodologies often suffer from color distortions and
exposure artifacts, further complicating the quest for authentic image
representation. In addressing these challenges, this paper presents a
Hybrid-Supervised Dual-Search approach for MEF, dubbed HSDS-MEF, which
introduces a bi-level optimization search scheme for automatic design of both
network structures and loss functions. More specifically, we harnesses a unique
dual research mechanism rooted in a novel weighted structure refinement
architecture search. Besides, a hybrid supervised contrast constraint
seamlessly guides and integrates with searching process, facilitating a more
adaptive and comprehensive search for optimal loss functions. We realize the
state-of-the-art performance in comparison to various competitive schemes,
yielding a 10.61% and 4.38% improvement in Visual Information Fidelity (VIF)
for general and no-reference scenarios, respectively, while providing results
with high contrast, rich details and colors.
</p>
</div>
</dd>
<dt><a name="item207">[207]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01114" title="Abstract">arXiv:2309.01114</a> [<a href="/pdf/2309.01114" title="Download PDF">pdf</a>, <a href="/format/2309.01114" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MedChatZH: a Better Medical Adviser Learns from Better Instructions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tan%2C+Y">Yang Tan</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+M">Mingchen Li</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+Z">Zijie Huang</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+H">Huiqun Yu</a>, 
<a href="/search/cs?searchtype=author&query=Fan%2C+G">Guisheng Fan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, 3 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Generative large language models (LLMs) have shown great success in various
applications, including question-answering (QA) and dialogue systems. However,
in specialized domains like traditional Chinese medical QA, these models may
perform unsatisfactorily without fine-tuning on domain-specific datasets. To
address this, we introduce MedChatZH, a dialogue model designed specifically
for traditional Chinese medical QA. Our model is pre-trained on Chinese
traditional medical books and fine-tuned with a carefully curated medical
instruction dataset. It outperforms several solid baselines on a real-world
medical dialogue dataset. We release our model, code, and dataset on
https://github.com/tyang816/MedChatZH to facilitate further research in the
domain of traditional Chinese medicine and LLMs.
</p>
</div>
</dd>
<dt><a name="item208">[208]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01115" title="Abstract">arXiv:2309.01115</a> [<a href="/pdf/2309.01115" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Carbon Emission Prediction and Clean Industry Transformation Based on  Machine Learning: A Case Study of Sichuan Province
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xuanming Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xiaoxue Wang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yonghang Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 21 pages,19 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">This study preprocessed 2000-2019 energy consumption data for 46 key Sichuan
industries using matrix normalization. DBSCAN clustering identified 16 feature
classes to objectively group industries. Penalized regression models were then
applied for their advantages in overfitting control, high-dimensional data
processing, and feature selection - well-suited for the complex energy data.
Results showed the second cluster around coal had highest emissions due to
production needs. Emissions from gasoline-focused and coke-focused clusters
were also significant. Based on this, emission reduction suggestions included
clean coal technologies, transportation management, coal-electricity
replacement in steel, and industry standardization. The research introduced
unsupervised learning to objectively select factors and aimed to explore new
emission reduction avenues. In summary, the study identified industry
groupings, assessed emissions drivers, and proposed scientific reduction
strategies to better inform decision-making using algorithms like DBSCAN and
penalized regression models.
</p>
</div>
</dd>
<dt><a name="item209">[209]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01116" title="Abstract">arXiv:2309.01116</a> [<a href="/pdf/2309.01116" title="Download PDF">pdf</a>, <a href="/format/2309.01116" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Who Made This Copy? An Empirical Analysis of Code Clone Authorship
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yokomori%2C+R">Reishi Yokomori</a>, 
<a href="/search/cs?searchtype=author&query=Inoue%2C+K">Katsuro Inoue</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> An extended version of the 17th International Workshop on Software Clones IWSC 2023 in Bogota, Colombia
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
<p class="mathjax">Code clones are code snippets that are identical or similar to other snippets
within the same or different files. They are often created through
copy-and-paste practices during development and maintenance activities. Since
code clones may require consistent updates and coherent management, they
present a challenging issue in software maintenance. Therefore, many studies
have been conducted to find various types of clones with accuracy, scalability,
or performance. However, the exploration of the nature of code clones has been
limited. Even the fundamental question of whether code snippets in the same
clone set were written by the same author or different authors has not been
thoroughly investigated.
<br />In this paper, we investigate the characteristics of code clones with a focus
on authorship. We analyzed the authorship of code clones at the line-level
granularity for Java files in 153 Apache projects stored on GitHub and
addressed three research questions.
<br />Based on these research questions, we found that there are a substantial
number of clone lines across all projects (an average of 18.5\% for all
projects). Furthermore, authors who contribute to many non-clone lines also
contribute to many clone lines. Additionally, we found that one-third of clone
sets are primarily contributed to by multiple leading authors.
<br />These results confirm our intuitive understanding of clone characteristics,
although no previous publications have provided empirical validation data from
multiple projects. As the results could assist in designing better clone
management techniques, we will explore the implications of developing an
effective clone management tool.
</p>
</div>
</dd>
<dt><a name="item210">[210]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01120" title="Abstract">arXiv:2309.01120</a> [<a href="/pdf/2309.01120" title="Download PDF">pdf</a>, <a href="/format/2309.01120" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Double Clipping: Less-Biased Variance Reduction in Off-Policy Evaluation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lichtenberg%2C+J+M">Jan Malte Lichtenberg</a>, 
<a href="/search/cs?searchtype=author&query=Buchholz%2C+A">Alexander Buchholz</a>, 
<a href="/search/cs?searchtype=author&query=Di+Benedetto%2C+G">Giuseppe Di Benedetto</a>, 
<a href="/search/cs?searchtype=author&query=Ruffini%2C+M">Matteo Ruffini</a>, 
<a href="/search/cs?searchtype=author&query=London%2C+B">Ben London</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Presented at CONSEQUENCES '23 workshop at RecSys 2023 conference in Singapore
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">"Clipping" (a.k.a. importance weight truncation) is a widely used
variance-reduction technique for counterfactual off-policy estimators. Like
other variance-reduction techniques, clipping reduces variance at the cost of
increased bias. However, unlike other techniques, the bias introduced by
clipping is always a downward bias (assuming non-negative rewards), yielding a
lower bound on the true expected reward. In this work we propose a simple
extension, called $\textit{double clipping}$, which aims to compensate this
downward bias and thus reduce the overall bias, while maintaining the variance
reduction properties of the original estimator.
</p>
</div>
</dd>
<dt><a name="item211">[211]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01124" title="Abstract">arXiv:2309.01124</a> [<a href="/pdf/2309.01124" title="Download PDF">pdf</a>, <a href="/format/2309.01124" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Distribution System Power-Flow Solution by Hierarchical Artificial  Neural Networks Structure
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Yaniv%2C+A">Arbel Yaniv</a>, 
<a href="/search/eess?searchtype=author&query=Beck%2C+Y">Yuval Beck</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">In this paper, a new method for solving the power flow problem in
distribution systems which is fast, parallel, as well as modular,
straightforward, simplified and generic is proposed. This approach is based on
a hierarchical construction of an ANNs tree. The power system is divided into
multiple clusters, with a modular architecture. For each cluster an ANN is
constructed, were the ANNs of the different clusters are organized in a
hierarchical manner in which the data from a lower-level layer is fed into an
upper layer in accordance with the electric correlation between the clusters.
The solution time is fast as it is based on the neural networks predictions and
also enables parallel computing of all clusters in any given layer. The various
clusters have a uniform designed single-hidden-layer ANNs, thus providing a
straightforward, simple and generic architectural implementation. The suggested
methodology is an important milestone for bypassing power flow classical
methods and introducing a novel machine learning based approach. The solution
for three-phase unbalance IEEE-123 system as well as EPRI Ckt5 system are
presented. The predictions of the ANNs of the hierarchical structures are
compared to the solution as calculated by OpenDSS simulation software, with
very promising results.
</p>
</div>
</dd>
<dt><a name="item212">[212]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01125" title="Abstract">arXiv:2309.01125</a> [<a href="/pdf/2309.01125" title="Download PDF">pdf</a>, <a href="/format/2309.01125" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AutoML-GPT: Large Language Model for AutoML
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tsai%2C+Y">Yun-Da Tsai</a>, 
<a href="/search/cs?searchtype=author&query=Tsai%2C+Y">Yu-Che Tsai</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+B">Bo-Wei Huang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+C">Chun-Pai Yang</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+S">Shou-De Lin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">With the emerging trend of GPT models, we have established a framework called
AutoML-GPT that integrates a comprehensive set of tools and libraries. This
framework grants users access to a wide range of data preprocessing techniques,
feature engineering methods, and model selection algorithms. Through a
conversational interface, users can specify their requirements, constraints,
and evaluation metrics. Throughout the process, AutoML-GPT employs advanced
techniques for hyperparameter optimization and model selection, ensuring that
the resulting model achieves optimal performance. The system effectively
manages the complexity of the machine learning pipeline, guiding users towards
the best choices without requiring deep domain knowledge. Through our
experimental results on diverse datasets, we have demonstrated that AutoML-GPT
significantly reduces the time and effort required for machine learning tasks.
Its ability to leverage the vast knowledge encoded in large language models
enables it to provide valuable insights, identify potential pitfalls, and
suggest effective solutions to common challenges faced during model training.
</p>
</div>
</dd>
<dt><a name="item213">[213]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01126" title="Abstract">arXiv:2309.01126</a> [<a href="/html/2309.01126" title="Download HTML">html</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Proceedings of the 16th International Conference on Automata and Formal  Languages
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gazdag%2C+Z">Zsolt Gazdag</a> (University of Szeged, Hungary), 
<a href="/search/cs?searchtype=author&query=Iv%C3%A1n%2C+S">Szabolcs Iv&#xe1;n</a> (University of Szeged, Hungary), 
<a href="/search/cs?searchtype=author&query=Kov%C3%A1sznai%2C+G">Gergely Kov&#xe1;sznai</a> (Eszterh&#xe1;zy K&#xe1;roly Catholic University of Eger, Hungary)
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> EPTCS 386, 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Formal Languages and Automata Theory (cs.FL)</span>

</div>
<p class="mathjax">The 16th International Conference on Automata and Formal Languages (AFL 2023)
was held in Eger, September 5-7, 2023. It was organized by the Eszterh\'azy
K\'aroly Catholic University of Eger, Hungary, and the University of Szeged,
Hungary. Topics of interest covered the theory and applications of automata and
formal languages and related areas.
<br />This volume contains the texts of the 3 invited presentations and the 18
papers selected by the International Program Committee from a total of 23
submissions. We would like to thank everybody who submitted a paper to the
conference.
</p>
</div>
</dd>
<dt><a name="item214">[214]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01130" title="Abstract">arXiv:2309.01130</a> [<a href="/pdf/2309.01130" title="Download PDF">pdf</a>, <a href="/format/2309.01130" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The End of the Canonical IoT Botnet: A Measurement Study of Mirai&#x27;s  Descendants
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=B%C3%B6ck%2C+L">Leon B&#xf6;ck</a> (1), 
<a href="/search/cs?searchtype=author&query=Sundermann%2C+V">Valentin Sundermann</a> (1), 
<a href="/search/cs?searchtype=author&query=Fusari%2C+I">Isabella Fusari</a> (2), 
<a href="/search/cs?searchtype=author&query=Karuppayah%2C+S">Shankar Karuppayah</a> (3), 
<a href="/search/cs?searchtype=author&query=M%C3%BChlh%C3%A4user%2C+M">Max M&#xfc;hlh&#xe4;user</a> (1), 
<a href="/search/cs?searchtype=author&query=Levin%2C+D">Dave Levin</a> (4) ((1) Technical University of Darmstadt, (2) George Mason University, (3) Universiti Sains Malaysia, (4) University of Maryland)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">Since the burgeoning days of IoT, Mirai has been established as the canonical
IoT botnet. Not long after the public release of its code, researchers found
many Mirai variants compete with one another for many of the same vulnerable
hosts. Over time, the myriad Mirai variants evolved to incorporate unique
vulnerabilities, defenses, and regional concentrations. In this paper, we ask:
have Mirai variants evolved to the point that they are fundamentally distinct?
We answer this question by measuring two of the most popular Mirai descendants:
Hajime and Mozi. To actively scan both botnets simultaneously, we developed a
robust measurement infrastructure, BMS, and ran it for more than eight months.
The resulting datasets show that these two popular botnets have diverged in
their evolutions from their common ancestor in multiple ways: they have
virtually no overlapping IP addresses, they exhibit different behavior to
network events such as diurnal rate limiting in China, and more. Collectively,
our results show that there is no longer one canonical IoT botnet. We discuss
the implications of this finding for researchers and practitioners.
</p>
</div>
</dd>
<dt><a name="item215">[215]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01131" title="Abstract">arXiv:2309.01131</a> [<a href="/pdf/2309.01131" title="Download PDF">pdf</a>, <a href="/format/2309.01131" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Attention Where It Matters: Rethinking Visual Document Understanding  with Selective Region Concentration
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cao%2C+H">Haoyu Cao</a>, 
<a href="/search/cs?searchtype=author&query=Bao%2C+C">Changcun Bao</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+C">Chaohu Liu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+H">Huang Chen</a>, 
<a href="/search/cs?searchtype=author&query=Yin%2C+K">Kun Yin</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+H">Hao Liu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yinsong Liu</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+D">Deqiang Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+X">Xing Sun</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to ICCV 2023 main conference
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Computation and Language (cs.CL)

</div>
<p class="mathjax">We propose a novel end-to-end document understanding model called SeRum
(SElective Region Understanding Model) for extracting meaningful information
from document images, including document analysis, retrieval, and office
automation.
<br />Unlike state-of-the-art approaches that rely on multi-stage technical schemes
and are computationally expensive,
<br />SeRum converts document image understanding and recognition tasks into a
local decoding process of the visual tokens of interest, using a content-aware
token merge module.
<br />This mechanism enables the model to pay more attention to regions of interest
generated by the query decoder, improving the model's effectiveness and
speeding up the decoding speed of the generative scheme.
<br />We also designed several pre-training tasks to enhance the understanding and
local awareness of the model.
<br />Experimental results demonstrate that SeRum achieves state-of-the-art
performance on document understanding tasks and competitive results on text
spotting tasks.
<br />SeRum represents a substantial advancement towards enabling efficient and
effective end-to-end document understanding.
</p>
</div>
</dd>
<dt><a name="item216">[216]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01136" title="Abstract">arXiv:2309.01136</a> [<a href="/pdf/2309.01136" title="Download PDF">pdf</a>, <a href="/ps/2309.01136" title="Download PostScript">ps</a>, <a href="/format/2309.01136" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> $(\min,+)$ Matrix and Vector Products for Inputs Decomposable into Few  Monotone Subsequences
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lingas%2C+A">Andrzej Lingas</a>, 
<a href="/search/cs?searchtype=author&query=Persson%2C+M">Mia Persson</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 pages, accepted by COCOON 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>; Computational Complexity (cs.CC)

</div>
<p class="mathjax">We study the time complexity of computing the $(\min,+)$ matrix
<br />product of two $n\times n$ integer matrices in terms of $n$ and the
<br />number of monotone subsequences the rows of the first matrix and the
<br />columns of the second matrix can be decomposed into. In particular,
<br />we show that if each row of the first matrix can be decomposed into
<br />at most $m_1$ monotone subsequences and each column of the second
<br />matrix can be decomposed into at most $m_2$ monotone subsequences
<br />such that all the subsequences are non-decreasing or all of them are
<br />non-increasing then the $(\min,+)$ product of the matrices can be
<br />computed in $O(m_1m_2n^{2.569})$ time. On the other hand, we observe
<br />that if all the rows of the first matrix are non-decreasing and all
<br />columns of the second matrix are non-increasing or {\em vice versa}
<br />then this case is as hard as the general one.
<br />Similarly, we also study the time complexity of computing the
<br />$(\min,+)$ convolution of two $n$-dimensional integer vectors in
<br />terms of $n$ and the number of monotone subsequences the two vectors
<br />can be decomposed into. We show that if the first vector can be
<br />decomposed into at most $m_1$ monotone subsequences and the second
<br />vector can be decomposed into at most $m_2$ subsequences such that
<br />all the subsequences of the first vector are non-decreasing and all
<br />the subsequences of the second vector are non-increasing or {\em
<br />vice versa} then their $(\min,+)$ convolution can be computed in
<br />$\tilde{O}(m_1m_2n^{1.5})$ time. On the other, the case when both
<br />vectors are non-decreasing or both of them are non-increasing is as
<br />hard as the general case.
</p>
</div>
</dd>
<dt><a name="item217">[217]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01140" title="Abstract">arXiv:2309.01140</a> [<a href="/pdf/2309.01140" title="Download PDF">pdf</a>, <a href="/format/2309.01140" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Interpretable Sequence Clustering
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dong%2C+J">Junjie Dong</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+X">Xinyi Yang</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+M">Mudi Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+L">Lianyu Hu</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+Z">Zengyou He</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages, 6 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Categorical sequence clustering plays a crucial role in various fields, but
the lack of interpretability in cluster assignments poses significant
challenges. Sequences inherently lack explicit features, and existing sequence
clustering algorithms heavily rely on complex representations, making it
difficult to explain their results. To address this issue, we propose a method
called Interpretable Sequence Clustering Tree (ISCT), which combines sequential
patterns with a concise and interpretable tree structure. ISCT leverages k-1
patterns to generate k leaf nodes, corresponding to k clusters, which provides
an intuitive explanation on how each cluster is formed. More precisely, ISCT
first projects sequences into random subspaces and then utilizes the k-means
algorithm to obtain high-quality initial cluster assignments. Subsequently, it
constructs a pattern-based decision tree using a boosting-based construction
strategy in which sequences are re-projected and re-clustered at each node
before mining the top-1 discriminative splitting pattern. Experimental results
on 14 real-world data sets demonstrate that our proposed method provides an
interpretable tree structure while delivering fast and accurate cluster
assignments.
</p>
</div>
</dd>
<dt><a name="item218">[218]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01141" title="Abstract">arXiv:2309.01141</a> [<a href="/pdf/2309.01141" title="Download PDF">pdf</a>, <a href="/format/2309.01141" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> VGDiffZero: Text-to-image Diffusion Models Can Be Zero-shot Visual  Grounders
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xuyang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+S">Siteng Huang</a>, 
<a href="/search/cs?searchtype=author&query=Kang%2C+Y">Yachen Kang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+H">Honggang Chen</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+D">Donglin Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Large-scale text-to-image diffusion models have shown impressive capabilities
across various generative tasks, enabled by strong vision-language alignment
obtained through pre-training. However, most vision-language discriminative
tasks require extensive fine-tuning on carefully-labeled datasets to acquire
such alignment, with great cost in time and computing resources. In this work,
we explore directly applying a pre-trained generative diffusion model to the
challenging discriminative task of visual grounding without any fine-tuning and
additional training dataset. Specifically, we propose VGDiffZero, a simple yet
effective zero-shot visual grounding framework based on text-to-image diffusion
models. We also design a comprehensive region-scoring method considering both
global and local contexts of each isolated proposal. Extensive experiments on
RefCOCO, RefCOCO+, and RefCOCOg show that VGDiffZero achieves strong
performance on zero-shot visual grounding.
</p>
</div>
</dd>
<dt><a name="item219">[219]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01144" title="Abstract">arXiv:2309.01144</a> [<a href="/pdf/2309.01144" title="Download PDF">pdf</a>, <a href="/format/2309.01144" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Distributed averaging for accuracy prediction in networked systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Sirocchi%2C+C">Christel Sirocchi</a>, 
<a href="/search/eess?searchtype=author&query=Bogliolo%2C+A">Alessandro Bogliolo</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Distributed, Parallel, and Cluster Computing (cs.DC)

</div>
<p class="mathjax">Distributed averaging is among the most relevant cooperative control
problems, with applications in sensor and robotic networks, distributed signal
processing, data fusion, and load balancing. Consensus and gossip algorithms
have been investigated and successfully deployed in multi-agent systems to
perform distributed averaging in synchronous and asynchronous settings. This
study proposes a heuristic approach to estimate the convergence rate of
averaging algorithms in a distributed manner, relying on the computation and
propagation of local graph metrics while entailing simple data elaboration and
small message passing. The protocol enables nodes to predict the time (or the
number of interactions) needed to estimate the global average with the desired
accuracy. Consequently, nodes can make informed decisions on their use of
measured and estimated data while gaining awareness of the global structure of
the network, as well as their role in it. The study presents relevant
applications to outliers identification and performance evaluation in switching
topologies.
</p>
</div>
</dd>
<dt><a name="item220">[220]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01149" title="Abstract">arXiv:2309.01149</a> [<a href="/pdf/2309.01149" title="Download PDF">pdf</a>, <a href="/format/2309.01149" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An Iterative Approach for Collision Feee Routing and Scheduling in  Multirobot Stations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Spensieri%2C+D">Domenico Spensieri</a>, 
<a href="/search/cs?searchtype=author&query=Carlson%2C+J+S">Johan S. Carlson</a>, 
<a href="/search/cs?searchtype=author&query=Ekstedt%2C+F">Fredrik Ekstedt</a>, 
<a href="/search/cs?searchtype=author&query=Bohlin%2C+R">Robert Bohlin</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> IEEE Transactions on Automation Science and Engineering, Vol. 13,
  n. 2, pp. 950-962, 2016
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Systems and Control (eess.SY)

</div>
<p class="mathjax">This work is inspired by the problem of planning sequences of operations, as
welding, in car manufacturing stations where multiple industrial robots
cooperate. The goal is to minimize the station cycle time, \emph{i.e.} the time
it takes for the last robot to finish its cycle. This is done by dispatching
the tasks among the robots, and by routing and scheduling the robots in a
collision-free way, such that they perform all predefined tasks. We propose an
iterative and decoupled approach in order to cope with the high complexity of
the problem. First, collisions among robots are neglected, leading to a min-max
Multiple Generalized Traveling Salesman Problem (MGTSP). Then, when the sets of
robot loads have been obtained and fixed, we sequence and schedule their tasks,
with the aim to avoid conflicts. The first problem (min-max MGTSP) is solved by
an exact branch and bound method, where different lower bounds are presented by
combining the solutions of a min-max set partitioning problem and of a
Generalized Traveling Salesman Problem (GTSP). The second problem is approached
by assuming that robots move synchronously: a novel transformation of this
synchronous problem into a GTSP is presented. Eventually, in order to provide
complete robot solutions, we include path planning functionalities, allowing
the robots to avoid collisions with the static environment and among
themselves. These steps are iterated until a satisfying solution is obtained.
Experimental results are shown for both problems and for their combination. We
even show the results of the iterative method, applied to an industrial test
case adapted from a stud welding station in a car manufacturing line.
</p>
</div>
</dd>
<dt><a name="item221">[221]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01150" title="Abstract">arXiv:2309.01150</a> [<a href="/pdf/2309.01150" title="Download PDF">pdf</a>, <a href="/format/2309.01150" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FedFwd: Federated Learning without Backpropagation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Park%2C+S">Seonghwan Park</a>, 
<a href="/search/cs?searchtype=author&query=Shin%2C+D">Dahun Shin</a>, 
<a href="/search/cs?searchtype=author&query=Chung%2C+J">Jinseok Chung</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+N">Namhoon Lee</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ICML 2023 Workshop (Federated Learning and Analytics in Practice: Algorithms, Systems, Applications, and Opportunities)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">In federated learning (FL), clients with limited resources can disrupt the
training efficiency. A potential solution to this problem is to leverage a new
learning procedure that does not rely on backpropagation (BP). We present a
novel approach to FL called FedFwd that employs a recent BP-free method by
Hinton (2022), namely the Forward Forward algorithm, in the local training
process. FedFwd can reduce a significant amount of computations for updating
parameters by performing layer-wise local updates, and therefore, there is no
need to store all intermediate activation values during training. We conduct
various experiments to evaluate FedFwd on standard datasets including MNIST and
CIFAR-10, and show that it works competitively to other BP-dependent FL
methods.
</p>
</div>
</dd>
<dt><a name="item222">[222]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01151" title="Abstract">arXiv:2309.01151</a> [<a href="/pdf/2309.01151" title="Download PDF">pdf</a>, <a href="/format/2309.01151" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> EdaDet: Open-Vocabulary Object Detection Using Early Dense Alignment
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shi%2C+C">Cheng Shi</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+S">Sibei Yang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ICCV 2023; Project Page: <a href="https://chengshiest.github.io/edadet">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Vision-language models such as CLIP have boosted the performance of
open-vocabulary object detection, where the detector is trained on base
categories but required to detect novel categories. Existing methods leverage
CLIP's strong zero-shot recognition ability to align object-level embeddings
with textual embeddings of categories. However, we observe that using CLIP for
object-level alignment results in overfitting to base categories, i.e., novel
categories most similar to base categories have particularly poor performance
as they are recognized as similar base categories. In this paper, we first
identify that the loss of critical fine-grained local image semantics hinders
existing methods from attaining strong base-to-novel generalization. Then, we
propose Early Dense Alignment (EDA) to bridge the gap between generalizable
local semantics and object-level prediction. In EDA, we use object-level
supervision to learn the dense-level rather than object-level alignment to
maintain the local fine-grained semantics. Extensive experiments demonstrate
our superior performance to competing approaches under the same strict setting
and without using external training resources, i.e., improving the +8.4% novel
box AP50 on COCO and +3.9% rare mask AP on LVIS.
</p>
</div>
</dd>
<dt><a name="item223">[223]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01154" title="Abstract">arXiv:2309.01154</a> [<a href="/pdf/2309.01154" title="Download PDF">pdf</a>, <a href="/format/2309.01154" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Survey on What Developers Think About Testing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Straubinger%2C+P">Philipp Straubinger</a>, 
<a href="/search/cs?searchtype=author&query=Fraser%2C+G">Gordon Fraser</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
<p class="mathjax">Software is infamous for its poor quality and frequent occurrence of bugs.
While there is no doubt that thorough testing is an appropriate answer to
ensure sufficient quality, the poor state of software generally suggests that
developers may not always engage as thoroughly with testing as they should.
This observation aligns with the prevailing belief that developers simply do
not like writing tests. In order to determine the truth of this belief, we
conducted a comprehensive survey with 21 questions aimed at (1) assessing
developers' current engagement with testing and (2) identifying factors
influencing their inclination toward testing; that is, whether they would
actually like to test more but are inhibited by their work environment, or
whether they would really prefer to test even less if given the choice. Drawing
on 284 responses from professional software developers, we uncover reasons that
positively and negatively impact developers' motivation to test. Notably,
reasons for motivation to write more tests encompass not only a general pursuit
of software quality but also personal satisfaction. However, developers
nevertheless perceive testing as mundane and tend to prioritize other tasks.
One approach emerging from the responses to mitigate these negative factors is
by providing better recognition for developers' testing efforts.
</p>
</div>
</dd>
<dt><a name="item224">[224]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01155" title="Abstract">arXiv:2309.01155</a> [<a href="/pdf/2309.01155" title="Download PDF">pdf</a>, <a href="/format/2309.01155" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LoGoPrompt: Synthetic Text Images Can Be Good Visual Prompts for  Vision-Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shi%2C+C">Cheng Shi</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+S">Sibei Yang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ICCV 2023; Project Page:<a href="https://chengshiest.github.io/logo">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Prompt engineering is a powerful tool used to enhance the performance of
pre-trained models on downstream tasks. For example, providing the prompt
``Let's think step by step" improved GPT-3's reasoning accuracy to 63% on
MutiArith while prompting ``a photo of" filled with a class name enables CLIP
to achieve $80$\% zero-shot accuracy on ImageNet. While previous research has
explored prompt learning for the visual modality, analyzing what constitutes a
good visual prompt specifically for image recognition is limited. In addition,
existing visual prompt tuning methods' generalization ability is worse than
text-only prompting tuning. This paper explores our key insight: synthetic text
images are good visual prompts for vision-language models! To achieve that, we
propose our LoGoPrompt, which reformulates the classification objective to the
visual prompt selection and addresses the chicken-and-egg challenge of first
adding synthetic text images as class-wise visual prompts or predicting the
class first. Without any trainable visual prompt parameters, experimental
results on 16 datasets demonstrate that our method consistently outperforms
state-of-the-art methods in few-shot learning, base-to-new generalization, and
domain generalization.
</p>
</div>
</dd>
<dt><a name="item225">[225]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01157" title="Abstract">arXiv:2309.01157</a> [<a href="/pdf/2309.01157" title="Download PDF">pdf</a>, <a href="/format/2309.01157" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Large Language Models for Generative Recommendation: A Survey and  Visionary Discussions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+L">Lei Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yongfeng Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+D">Dugang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+L">Li Chen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL)

</div>
<p class="mathjax">Recent years have witnessed the wide adoption of large language models (LLM)
in different fields, especially natural language processing and computer
vision. Such a trend can also be observed in recommender systems (RS). However,
most of related work treat LLM as a component of the conventional
recommendation pipeline (e.g., as a feature extractor) which may not be able to
fully leverage the generative power of LLM. Instead of separating the
recommendation process into multiple stages such as score computation and
re-ranking, this process can be simplified to one stage with LLM: directly
generating recommendations from the complete pool of items. This survey reviews
the progress, methods and future directions of LLM-based generative
recommendation by examining three questions: 1) What generative recommendation
is, 2) Why RS should advance to generative recommendation, and 3) How to
implement LLM-based generative recommendation for various RS tasks. We hope
that the survey can provide the context and guidance needed to explore this
interesting and emerging topic.
</p>
</div>
</dd>
<dt><a name="item226">[226]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01158" title="Abstract">arXiv:2309.01158</a> [<a href="/pdf/2309.01158" title="Download PDF">pdf</a>, <a href="/format/2309.01158" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An Accurate Graph Generative Model with Tunable Features
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yokoyama%2C+T">Takahiro Yokoyama</a>, 
<a href="/search/cs?searchtype=author&query=Sato%2C+Y">Yoshiki Sato</a>, 
<a href="/search/cs?searchtype=author&query=Tsugawa%2C+S">Sho Tsugawa</a>, 
<a href="/search/cs?searchtype=author&query=Watabe%2C+K">Kohei Watabe</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This paper was presented at the 32nd International Conference on Computer Communications and Networks (ICCCN 2023) Poster Track
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Networking and Internet Architecture (cs.NI); Social and Information Networks (cs.SI)

</div>
<p class="mathjax">A graph is a very common and powerful data structure used for modeling
communication and social networks. Models that generate graphs with arbitrary
features are important basic technologies in repeated simulations of networks
and prediction of topology changes. Although existing generative models for
graphs are useful for providing graphs similar to real-world graphs, graph
generation models with tunable features have been less explored in the field.
Previously, we have proposed GraphTune, a generative model for graphs that
continuously tune specific graph features of generated graphs while maintaining
most of the features of a given graph dataset. However, the tuning accuracy of
graph features in GraphTune has not been sufficient for practical applications.
In this paper, we propose a method to improve the accuracy of GraphTune by
adding a new mechanism to feed back errors of graph features of generated
graphs and by training them alternately and independently. Experiments on a
real-world graph dataset showed that the features in the generated graphs are
accurately tuned compared with conventional models.
</p>
</div>
</dd>
<dt><a name="item227">[227]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01159" title="Abstract">arXiv:2309.01159</a> [<a href="/pdf/2309.01159" title="Download PDF">pdf</a>, <a href="/format/2309.01159" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An Asynchronous Linear Filter Architecture for Hybrid Event-Frame  Cameras
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Ziwei Wang</a>, 
<a href="/search/cs?searchtype=author&query=Ng%2C+Y">Yonhon Ng</a>, 
<a href="/search/cs?searchtype=author&query=Scheerlinck%2C+C">Cedric Scheerlinck</a>, 
<a href="/search/cs?searchtype=author&query=Mahony%2C+R">Robert Mahony</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 17 pages, 10 figures, Accepted by IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI) in August 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Event cameras are ideally suited to capture High Dynamic Range (HDR) visual
information without blur but provide poor imaging capability for static or
slowly varying scenes. Conversely, conventional image sensors measure absolute
intensity of slowly changing scenes effectively but do poorly on HDR or quickly
changing scenes. In this paper, we present an asynchronous linear filter
architecture, fusing event and frame camera data, for HDR video reconstruction
and spatial convolution that exploits the advantages of both sensor modalities.
The key idea is the introduction of a state that directly encodes the
integrated or convolved image information and that is updated asynchronously as
each event or each frame arrives from the camera. The state can be read-off
as-often-as and whenever required to feed into subsequent vision modules for
real-time robotic systems. Our experimental results are evaluated on both
publicly available datasets with challenging lighting conditions and fast
motions, along with a new dataset with HDR reference that we provide. The
proposed AKF pipeline outperforms other state-of-the-art methods in both
absolute intensity error (69.4% reduction) and image similarity indexes
(average 35.5% improvement). We also demonstrate the integration of image
convolution with linear spatial kernels Gaussian, Sobel, and Laplacian as an
application of our architecture.
</p>
</div>
</dd>
<dt><a name="item228">[228]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01166" title="Abstract">arXiv:2309.01166</a> [<a href="/pdf/2309.01166" title="Download PDF">pdf</a>, <a href="/format/2309.01166" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Spatial-temporal Vehicle Re-identification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kim%2C+H">Hye-Geun Kim</a>, 
<a href="/search/cs?searchtype=author&query=Na%2C+Y">YouKyoung Na</a>, 
<a href="/search/cs?searchtype=author&query=Joe%2C+H">Hae-Won Joe</a>, 
<a href="/search/cs?searchtype=author&query=Moon%2C+Y">Yong-Hyuk Moon</a>, 
<a href="/search/cs?searchtype=author&query=Cho%2C+Y">Yeong-Jun Cho</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 6 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Vehicle re-identification (ReID) in a large-scale camera network is important
in public safety, traffic control, and security. However, due to the appearance
ambiguities of vehicle, the previous appearance-based ReID methods often fail
to track vehicle across multiple cameras. To overcome the challenge, we propose
a spatial-temporal vehicle ReID framework that estimates reliable camera
network topology based on the adaptive Parzen window method and optimally
combines the appearance and spatial-temporal similarities through the fusion
network. Based on the proposed methods, we performed superior performance on
the public dataset (VeRi776) by 99.64% of rank-1 accuracy. The experimental
results support that utilizing spatial and temporal information for ReID can
leverage the accuracy of appearance-based methods and effectively deal with
appearance ambiguities.
</p>
</div>
</dd>
<dt><a name="item229">[229]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01169" title="Abstract">arXiv:2309.01169</a> [<a href="/pdf/2309.01169" title="Download PDF">pdf</a>, <a href="/ps/2309.01169" title="Download PostScript">ps</a>, <a href="/format/2309.01169" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> End-to-End Learning on Multimodal Knowledge Graphs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wilcke%2C+W+X">W. X. Wilcke</a>, 
<a href="/search/cs?searchtype=author&query=Bloem%2C+P">P. Bloem</a>, 
<a href="/search/cs?searchtype=author&query=de+Boer%2C+V">V. de Boer</a>, 
<a href="/search/cs?searchtype=author&query=van+t+Veer%2C+R+H">R. H. van t Veer</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Under submission. arXiv admin note: substantial text overlap with <a href="/abs/2003.12383">arXiv:2003.12383</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Knowledge graphs enable data scientists to learn end-to-end on heterogeneous
knowledge. However, most end-to-end models solely learn from the relational
information encoded in graphs' structure: raw values, encoded as literal nodes,
are either omitted completely or treated as regular nodes without consideration
for their values. In either case we lose potentially relevant information which
could have otherwise been exploited by our learning methods. We propose a
multimodal message passing network which not only learns end-to-end from the
structure of graphs, but also from their possibly divers set of multimodal node
features. Our model uses dedicated (neural) encoders to naturally learn
embeddings for node features belonging to five different types of modalities,
including numbers, texts, dates, images and geometries, which are projected
into a joint representation space together with their relational information.
We implement and demonstrate our model on node classification and link
prediction for artificial and real-worlds datasets, and evaluate the effect
that each modality has on the overall performance in an inverse ablation study.
Our results indicate that end-to-end multimodal learning from any arbitrary
knowledge graph is indeed possible, and that including multimodal information
can significantly affect performance, but that much depends on the
characteristics of the data.
</p>
</div>
</dd>
<dt><a name="item230">[230]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01172" title="Abstract">arXiv:2309.01172</a> [<a href="/pdf/2309.01172" title="Download PDF">pdf</a>, <a href="/format/2309.01172" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FusionAI: Decentralized Training and Deploying LLMs with Massive  Consumer-Level GPUs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tang%2C+Z">Zhenheng Tang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yuxin Wang</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+X">Xin He</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+L">Longteng Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Pan%2C+X">Xinglin Pan</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Q">Qiang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zeng%2C+R">Rongfei Zeng</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+K">Kaiyong Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+S">Shaohuai Shi</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+B">Bingsheng He</a>, 
<a href="/search/cs?searchtype=author&query=Chu%2C+X">Xiaowen Chu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Networking and Internet Architecture (cs.NI)

</div>
<p class="mathjax">The rapid growth of memory and computation requirements of large language
models (LLMs) has outpaced the development of hardware, hindering people who
lack large-scale high-end GPUs from training or deploying LLMs. However,
consumer-level GPUs, which constitute a larger market share, are typically
overlooked in LLM due to their weaker computing performance, smaller storage
capacity, and lower communication bandwidth. Additionally, users may have
privacy concerns when interacting with remote LLMs. In this paper, we envision
a decentralized system unlocking the potential vast untapped consumer-level
GPUs in pre-training, inference and fine-tuning of LLMs with privacy
protection. However, this system faces critical challenges, including limited
CPU and GPU memory, low network bandwidth, the variability of peer and device
heterogeneity. To address these challenges, our system design incorporates: 1)
a broker with backup pool to implement dynamic join and quit of computing
providers; 2) task scheduling with hardware performance to improve system
efficiency; 3) abstracting ML procedures into directed acyclic graphs (DAGs) to
achieve model and task universality; 4) abstracting intermediate represention
and execution planes to ensure compatibility of various devices and deep
learning (DL) frameworks. Our performance analysis demonstrates that 50 RTX
3080 GPUs can achieve throughputs comparable to those of 4 H100 GPUs, which are
significantly more expensive.
</p>
</div>
</dd>
<dt><a name="item231">[231]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01173" title="Abstract">arXiv:2309.01173</a> [<a href="/pdf/2309.01173" title="Download PDF">pdf</a>, <a href="/ps/2309.01173" title="Download PostScript">ps</a>, <a href="/format/2309.01173" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Logic of subjective probability
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Vovk%2C+V">Vladimir Vovk</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 19 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Other Statistics (stat.OT)

</div>
<p class="mathjax">In this paper I discuss both syntax and semantics of subjective probability.
The semantics determines ways of testing probability statements. Among
important varieties of subjective probabilities are intersubjective
probabilities and impersonal probabilities, and I will argue that well-tested
impersonal probabilities acquire features of objective probabilities.
Jeffreys's law, my next topic, states that two successful probability
forecasters must issue forecasts that are close to each other, thus supporting
the idea of objective probabilities. Finally, I will discuss connections
between subjective and frequentist probability.
</p>
</div>
</dd>
<dt><a name="item232">[232]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01174" title="Abstract">arXiv:2309.01174</a> [<a href="/pdf/2309.01174" title="Download PDF">pdf</a>, <a href="/ps/2309.01174" title="Download PostScript">ps</a>, <a href="/format/2309.01174" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A method based on hierarchical spatiotemporal features for trojan  traffic detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xie%2C+J">Jiang Xie</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+S">Shuhao Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yongzheng Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Yun%2C+X">Xiaochun Yun</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jia Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 7 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>

</div>
<p class="mathjax">Trojans are one of the most threatening network attacks currently. HTTP-based
Trojan, in particular, accounts for a considerable proportion of them.
Moreover, as the network environment becomes more complex, HTTP-based Trojan is
more concealed than others. At present, many intrusion detection systems (IDSs)
are increasingly difficult to effectively detect such Trojan traffic due to the
inherent shortcomings of the methods used and the backwardness of training
data. Classical anomaly detection and traditional machine learning-based
(TML-based) anomaly detection are highly dependent on expert knowledge to
extract features artificially, which is difficult to implement in HTTP-based
Trojan traffic detection. Deep learning-based (DL-based) anomaly detection has
been locally applied to IDSs, but it cannot be transplanted to HTTP-based
Trojan traffic detection directly. To solve this problem, in this paper, we
propose a neural network detection model (HSTF-Model) based on hierarchical
spatiotemporal features of traffic. Meanwhile, we combine deep learning
algorithms with expert knowledge through feature encoders and statistical
characteristics to improve the self-learning ability of the model. Experiments
indicate that F1 of HSTF-Model can reach 99.4% in real traffic. In addition, we
present a dataset BTHT consisting of HTTP-based benign and Trojan traffic to
facilitate related research in the field.
</p>
</div>
</dd>
<dt><a name="item233">[233]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01179" title="Abstract">arXiv:2309.01179</a> [<a href="/pdf/2309.01179" title="Download PDF">pdf</a>, <a href="/format/2309.01179" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Cognition-Mode Aware Variational Representation Learning Framework for  Knowledge Tracing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+M">Moyu Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+X">Xinning Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+C">Chunhong Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Pan%2C+F">Feng Pan</a>, 
<a href="/search/cs?searchtype=author&query=Qian%2C+W">Wenchen Qian</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+H">Hui Zhao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by ICDM 2023, 10 pages, 5 figures, 4 tables
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> 2023 ICDM
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computers and Society (cs.CY)

</div>
<p class="mathjax">The Knowledge Tracing (KT) task plays a crucial role in personalized
learning, and its purpose is to predict student responses based on their
historical practice behavior sequence. However, the KT task suffers from data
sparsity, which makes it challenging to learn robust representations for
students with few practice records and increases the risk of model overfitting.
Therefore, in this paper, we propose a Cognition-Mode Aware Variational
Representation Learning Framework (CMVF) that can be directly applied to
existing KT methods. Our framework uses a probabilistic model to generate a
distribution for each student, accounting for uncertainty in those with limited
practice records, and estimate the student's distribution via variational
inference (VI). In addition, we also introduce a cognition-mode aware
multinomial distribution as prior knowledge that constrains the posterior
student distributions learning, so as to ensure that students with similar
cognition modes have similar distributions, avoiding overwhelming
personalization for students with few practice records. At last, extensive
experimental results confirm that CMVF can effectively aid existing KT methods
in learning more robust student representations. Our code is available at
https://github.com/zmy-9/CMVF.
</p>
</div>
</dd>
<dt><a name="item234">[234]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01180" title="Abstract">arXiv:2309.01180</a> [<a href="/pdf/2309.01180" title="Download PDF">pdf</a>, <a href="/ps/2309.01180" title="Download PostScript">ps</a>, <a href="/format/2309.01180" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Usage-Aware Sequent Calculus for Differential Dynamic Logic
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dotzel%2C+M">Myra Dotzel</a>, 
<a href="/search/cs?searchtype=author&query=Mitsch%2C+S">Stefan Mitsch</a>, 
<a href="/search/cs?searchtype=author&query=Platzer%2C+A">Andre Platzer</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Formal Languages and Automata Theory (cs.FL)</span>

</div>
<p class="mathjax">Modeling languages like differential dynamic logic (dL) have proof calculi
capable of proving guarantees for safety-critical applications. However, dL
programmers may unintentionally over-specify assumptions and program
statements, which results in overly constrained models, and consequently, weak
or vacuous guarantees. In hybrid systems models, such constraints come from
multiple places, ranging from initial conditions to domain constraints in the
middle of differential equations, thereby making it nontrivial to consistently
track the conglomerate. We present a novel sequent calculus for dL that tracks
which constraints to weaken or remove while preserving correctness guarantees.
When properties follow entirely from constraints uninfluenced by program
statements, this analysis spots outright flaws in models. We prove soundness
and completeness of our proof calculus.
</p>
</div>
</dd>
<dt><a name="item235">[235]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01183" title="Abstract">arXiv:2309.01183</a> [<a href="/pdf/2309.01183" title="Download PDF">pdf</a>, <a href="/format/2309.01183" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Holistic Dynamic Frequency Transformer for Image Fusion and Exposure  Correction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shang%2C+X">Xiaoke Shang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+G">Gehui Li</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+Z">Zhiying Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+S">Shaomin Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Ding%2C+N">Nai Ding</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jinyuan Liu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">The correction of exposure-related issues is a pivotal component in enhancing
the quality of images, offering substantial implications for various computer
vision tasks. Historically, most methodologies have predominantly utilized
spatial domain recovery, offering limited consideration to the potentialities
of the frequency domain. Additionally, there has been a lack of a unified
perspective towards low-light enhancement, exposure correction, and
multi-exposure fusion, complicating and impeding the optimization of image
processing. In response to these challenges, this paper proposes a novel
methodology that leverages the frequency domain to improve and unify the
handling of exposure correction tasks. Our method introduces Holistic Frequency
Attention and Dynamic Frequency Feed-Forward Network, which replace
conventional correlation computation in the spatial-domain. They form a
foundational building block that facilitates a U-shaped Holistic Dynamic
Frequency Transformer as a filter to extract global information and dynamically
select important frequency bands for image restoration. Complementing this, we
employ a Laplacian pyramid to decompose images into distinct frequency bands,
followed by multiple restorers, each tuned to recover specific frequency-band
information. The pyramid fusion allows a more detailed and nuanced image
restoration process. Ultimately, our structure unifies the three tasks of
low-light enhancement, exposure correction, and multi-exposure fusion, enabling
comprehensive treatment of all classical exposure errors. Benchmarking on
mainstream datasets for these tasks, our proposed method achieves
state-of-the-art results, paving the way for more sophisticated and unified
solutions in exposure correction.
</p>
</div>
</dd>
<dt><a name="item236">[236]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01185" title="Abstract">arXiv:2309.01185</a> [<a href="/pdf/2309.01185" title="Download PDF">pdf</a>, <a href="/format/2309.01185" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Cooperative Filtering with Range Measurements: A Distributed Constrained  Zonotopic Method
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ding%2C+Y">Yu Ding</a>, 
<a href="/search/cs?searchtype=author&query=Cong%2C+Y">Yirui Cong</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xiangke Wang</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+L">Long Cheng</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 15 pages 6 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Multiagent Systems (cs.MA)</span>

</div>
<p class="mathjax">This article studies the distributed estimation problem of a multi-agent
system with bounded absolute and relative range measurements. Parts of the
agents are with high-accuracy absolute measurements, which are considered as
anchors; the other agents utilize lowaccuracy absolute and relative range
measurements, each derives an uncertain range that contains its true state in a
distributed manner. Different from previous studies, we design a distributed
algorithm to handle the range measurements based on extended constrained
zonotopes, which has low computational complexity and high precision. With our
proposed algorithm, agents can derive their uncertain range sequentially along
the chain topology, such that agents with low-accuracy sensors can benefit from
the high-accuracy absolute measurements of anchors and improve the estimation
performance. Simulation results corroborate the effectiveness of our proposed
algorithm and verify our method can significantly improve the estimation
accuracy.
</p>
</div>
</dd>
<dt><a name="item237">[237]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01188" title="Abstract">arXiv:2309.01188</a> [<a href="/pdf/2309.01188" title="Download PDF">pdf</a>, <a href="/format/2309.01188" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Pre-trained Neural Recommenders: A Transferable Zero-Shot Framework for  Recommendation Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Junting Wang</a>, 
<a href="/search/cs?searchtype=author&query=Krishnan%2C+A">Adit Krishnan</a>, 
<a href="/search/cs?searchtype=author&query=Sundaram%2C+H">Hari Sundaram</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yunzhe Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Modern neural collaborative filtering techniques are critical to the success
of e-commerce, social media, and content-sharing platforms. However, despite
technical advances -- for every new application domain, we need to train an NCF
model from scratch. In contrast, pre-trained vision and language models are
routinely applied to diverse applications directly (zero-shot) or with limited
fine-tuning. Inspired by the impact of pre-trained models, we explore the
possibility of pre-trained recommender models that support building recommender
systems in new domains, with minimal or no retraining, without the use of any
auxiliary user or item information. Zero-shot recommendation without auxiliary
information is challenging because we cannot form associations between users
and items across datasets when there are no overlapping users or items. Our
fundamental insight is that the statistical characteristics of the user-item
interaction matrix are universally available across different domains and
datasets. Thus, we use the statistical characteristics of the user-item
interaction matrix to identify dataset-independent representations for users
and items. We show how to learn universal (i.e., supporting zero-shot
adaptation without user or item auxiliary information) representations for
nodes and edges from the bipartite user-item interaction graph. We learn
representations by exploiting the statistical properties of the interaction
data, including user and item marginals, and the size and density distributions
of their clusters.
</p>
</div>
</dd>
<dt><a name="item238">[238]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01189" title="Abstract">arXiv:2309.01189</a> [<a href="/pdf/2309.01189" title="Download PDF">pdf</a>, <a href="/format/2309.01189" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LogGPT: Exploring ChatGPT for Log-Based Anomaly Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Qi%2C+J">Jiaxing Qi</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+S">Shaohan Huang</a>, 
<a href="/search/cs?searchtype=author&query=Luan%2C+Z">Zhongzhi Luan</a>, 
<a href="/search/cs?searchtype=author&query=Fung%2C+C">Carol Fung</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+H">Hailong Yang</a>, 
<a href="/search/cs?searchtype=author&query=Qian%2C+D">Depei Qian</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Software Engineering (cs.SE)

</div>
<p class="mathjax">The increasing volume of log data produced by software-intensive systems
makes it impractical to analyze them manually. Many deep learning-based methods
have been proposed for log-based anomaly detection. These methods face several
challenges such as high-dimensional and noisy log data, class imbalance,
generalization, and model interpretability. Recently, ChatGPT has shown
promising results in various domains. However, there is still a lack of study
on the application of ChatGPT for log-based anomaly detection. In this work, we
proposed LogGPT, a log-based anomaly detection framework based on ChatGPT. By
leveraging the ChatGPT's language interpretation capabilities, LogGPT aims to
explore the transferability of knowledge from large-scale corpora to log-based
anomaly detection. We conduct experiments to evaluate the performance of LogGPT
and compare it with three deep learning-based methods on BGL and Spirit
datasets. LogGPT shows promising results and has good interpretability. This
study provides preliminary insights into prompt-based models, such as ChatGPT,
for the log-based anomaly detection task.
</p>
</div>
</dd>
<dt><a name="item239">[239]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01194" title="Abstract">arXiv:2309.01194</a> [<a href="/pdf/2309.01194" title="Download PDF">pdf</a>, <a href="/format/2309.01194" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Survey on Service Route and Time Prediction in Instant Delivery:  Taxonomy, Progress, and Prospects
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wen%2C+H">Haomin Wen</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+Y">Youfang Lin</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+L">Lixia Wu</a>, 
<a href="/search/cs?searchtype=author&query=Mao%2C+X">Xiaowei Mao</a>, 
<a href="/search/cs?searchtype=author&query=Cai%2C+T">Tianyue Cai</a>, 
<a href="/search/cs?searchtype=author&query=Hou%2C+Y">Yunfeng Hou</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+S">Shengnan Guo</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+Y">Yuxuan Liang</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+G">Guangyin Jin</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Y">Yiji Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Zimmermann%2C+R">Roger Zimmermann</a>, 
<a href="/search/cs?searchtype=author&query=Ye%2C+J">Jieping Ye</a>, 
<a href="/search/cs?searchtype=author&query=Wan%2C+H">Huaiyu Wan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
<p class="mathjax">Instant delivery services, such as food delivery and package delivery, have
achieved explosive growth in recent years by providing customers with
daily-life convenience. An emerging research area within these services is
service Route\&amp;Time Prediction (RTP), which aims to estimate the future service
route as well as the arrival time of a given worker. As one of the most crucial
tasks in those service platforms, RTP stands central to enhancing user
satisfaction and trimming operational expenditures on these platforms. Despite
a plethora of algorithms developed to date, there is no systematic,
comprehensive survey to guide researchers in this domain. To fill this gap, our
work presents the first comprehensive survey that methodically categorizes
recent advances in service route and time prediction. We start by defining the
RTP challenge and then delve into the metrics that are often employed.
Following that, we scrutinize the existing RTP methodologies, presenting a
novel taxonomy of them. We categorize these methods based on three criteria:
(i) type of task, subdivided into only-route prediction, only-time prediction,
and joint route\&amp;time prediction; (ii) model architecture, which encompasses
sequence-based and graph-based models; and (iii) learning paradigm, including
Supervised Learning (SL) and Deep Reinforcement Learning (DRL). Conclusively,
we highlight the limitations of current research and suggest prospective
avenues. We believe that the taxonomy, progress, and prospects introduced in
this paper can significantly promote the development of this field.
</p>
</div>
</dd>
<dt><a name="item240">[240]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01196" title="Abstract">arXiv:2309.01196</a> [<a href="/pdf/2309.01196" title="Download PDF">pdf</a>, <a href="/format/2309.01196" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Visual Interpretation-Based Self-Improved Classification System Using  Virtual Adversarial Training
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jiang%2C+S">Shuai Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Kamei%2C+S">Sayaka Kamei</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+C">Chen Li</a>, 
<a href="/search/cs?searchtype=author&query=Hou%2C+S">Shengzhe Hou</a>, 
<a href="/search/cs?searchtype=author&query=Morimoto%2C+Y">Yasuhiko Morimoto</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">The successful application of large pre-trained models such as BERT in
natural language processing has attracted more attention from researchers.
Since the BERT typically acts as an end-to-end black box, classification
systems based on it usually have difficulty in interpretation and low
robustness. This paper proposes a visual interpretation-based self-improving
classification model with a combination of virtual adversarial training (VAT)
and BERT models to address the above problems. Specifically, a fine-tuned BERT
model is used as a classifier to classify the sentiment of the text. Then, the
predicted sentiment classification labels are used as part of the input of
another BERT for spam classification via a semi-supervised training manner
using VAT. Additionally, visualization techniques, including visualizing the
importance of words and normalizing the attention head matrix, are employed to
analyze the relevance of each component to classification accuracy. Moreover,
brand-new features will be found in the visual analysis, and classification
performance will be improved. Experimental results on Twitter's tweet dataset
demonstrate the effectiveness of the proposed model on the classification task.
Furthermore, the ablation study results illustrate the effect of different
components of the proposed model on the classification results.
</p>
</div>
</dd>
<dt><a name="item241">[241]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01199" title="Abstract">arXiv:2309.01199</a> [<a href="/pdf/2309.01199" title="Download PDF">pdf</a>, <a href="/format/2309.01199" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DKWS: A Distributed System for Keyword Search on Massive Graphs  (Complete Version)
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jiang%2C+J">Jiaxin Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Choi%2C+B">Byron Choi</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+X">Xin Huang</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+J">Jianliang Xu</a>, 
<a href="/search/cs?searchtype=author&query=Bhowmick%2C+S+S">Sourav S Bhowmick</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Databases (cs.DB)</span>

</div>
<p class="mathjax">Due to the unstructuredness and the lack of schemas of graphs, such as
knowledge graphs, social networks, and RDF graphs, keyword search for querying
such graphs has been proposed. As graphs have become voluminous, large-scale
distributed processing has attracted much interest from the database research
community. While there have been several distributed systems, distributed
querying techniques for keyword search are still limited. This paper proposes a
novel distributed keyword search system called $\DKWS$. First, we
\revise{present} a {\em monotonic} property with keyword search algorithms that
guarantees correct parallelization. Second, we present a keyword search
algorithm as monotonic backward and forward search phases. Moreover, we propose
new tight bounds for pruning nodes being searched. Third, we propose a {\em
notify-push} paradigm and $\PINE$ {\em programming model} of $\DKWS$. The
notify-push paradigm allows {\em asynchronously} exchanging the upper bounds of
matches across the workers and the coordinator in $\DKWS$. The $\PINE$
programming model naturally fits keyword search algorithms, as they have
distinguished phases, to allow {\em preemptive} searches to mitigate staleness
in a distributed system. Finally, we investigate the performance and
effectiveness of $\DKWS$ through experiments using real-world datasets. We find
that $\DKWS$ is up to two orders of magnitude faster than related techniques,
and its communication costs are $7.6$ times smaller than those of other
techniques.
</p>
</div>
</dd>
<dt><a name="item242">[242]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01200" title="Abstract">arXiv:2309.01200</a> [<a href="/pdf/2309.01200" title="Download PDF">pdf</a>, <a href="/format/2309.01200" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An analysis of Ermakov-Zolotukhin quadrature using kernels
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Belhadji%2C+A">Ayoub Belhadji</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Advances in Neural Information Processing Systems 34 (2021):
  27278-27289
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Computation (stat.CO)

</div>
<p class="mathjax">We study a quadrature, proposed by Ermakov and Zolotukhin in the sixties,
through the lens of kernel methods. The nodes of this quadrature rule follow
the distribution of a determinantal point process, while the weights are
defined through a linear system, similarly to the optimal kernel quadrature. In
this work, we show how these two classes of quadrature are related, and we
prove a tractable formula of the expected value of the squared worst-case
integration error on the unit ball of an RKHS of the former quadrature. In
particular, this formula involves the eigenvalues of the corresponding kernel
and leads to improving on the existing theoretical guarantees of the optimal
kernel quadrature with determinantal point processes.
</p>
</div>
</dd>
<dt><a name="item243">[243]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01202" title="Abstract">arXiv:2309.01202</a> [<a href="/pdf/2309.01202" title="Download PDF">pdf</a>, <a href="/format/2309.01202" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MAGMA: Music Aligned Generative Motion Autodecoder
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Anisetty%2C+S">Sohan Anisetty</a>, 
<a href="/search/cs?searchtype=author&query=Raj%2C+A">Amit Raj</a>, 
<a href="/search/cs?searchtype=author&query=Hays%2C+J">James Hays</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Graphics (cs.GR)</span>; Computer Vision and Pattern Recognition (cs.CV); Multimedia (cs.MM); Sound (cs.SD); Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">Mapping music to dance is a challenging problem that requires spatial and
temporal coherence along with a continual synchronization with the music's
progression. Taking inspiration from large language models, we introduce a
2-step approach for generating dance using a Vector Quantized-Variational
Autoencoder (VQ-VAE) to distill motion into primitives and train a Transformer
decoder to learn the correct sequencing of these primitives. We also evaluate
the importance of music representations by comparing naive music feature
extraction using Librosa to deep audio representations generated by
state-of-the-art audio compression algorithms. Additionally, we train
variations of the motion generator using relative and absolute positional
encodings to determine the effect on generated motion quality when generating
arbitrarily long sequence lengths. Our proposed approach achieve
state-of-the-art results in music-to-motion generation benchmarks and enables
the real-time generation of considerably longer motion sequences, the ability
to chain multiple motion sequences seamlessly, and easy customization of motion
sequences to meet style requirements.
</p>
</div>
</dd>
<dt><a name="item244">[244]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01206" title="Abstract">arXiv:2309.01206</a> [<a href="/pdf/2309.01206" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Comparative Safety Performance of Autonomous- and Human Drivers: A  Real-World Case Study of the Waymo One Service
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Di+Lillo%2C+L">Luigi Di Lillo</a>, 
<a href="/search/cs?searchtype=author&query=Gode%2C+T">Tilia Gode</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+X">Xilin Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Atzei%2C+M">Margherita Atzei</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+R">Ruoshu Chen</a>, 
<a href="/search/cs?searchtype=author&query=Victor%2C+T">Trent Victor</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">This study compares the safety of autonomous- and human drivers. It finds
that the Waymo One autonomous service is significantly safer towards other road
users than human drivers are, as measured via collision causation. The result
is determined by comparing Waymo's third party liability insurance claims data
with mileage- and zip-code-calibrated Swiss Re (human driver) private passenger
vehicle baselines. A liability claim is a request for compensation when someone
is responsible for damage to property or injury to another person, typically
following a collision. Liability claims reporting and their development is
designed using insurance industry best practices to assess crash causation
contribution and predict future crash contributions. In over 3.8 million miles
driven without a human being behind the steering wheel in rider-only (RO) mode,
the Waymo Driver incurred zero bodily injury claims in comparison with the
human driver baseline of 1.11 claims per million miles (cpmm). The Waymo Driver
also significantly reduced property damage claims to 0.78 cpmm in comparison
with the human driver baseline of 3.26 cpmm. Similarly, in a more statistically
robust dataset of over 35 million miles during autonomous testing operations
(TO), the Waymo Driver, together with a human autonomous specialist behind the
steering wheel monitoring the automation, also significantly reduced both
bodily injury and property damage cpmm compared to the human driver baselines.
</p>
</div>
</dd>
<dt><a name="item245">[245]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01208" title="Abstract">arXiv:2309.01208</a> [<a href="/pdf/2309.01208" title="Download PDF">pdf</a>, <a href="/ps/2309.01208" title="Download PostScript">ps</a>, <a href="/format/2309.01208" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Streaming and Query Once Space Complexity of Longest Increasing  Subsequence
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xin Li</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+Y">Yu Zheng</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This paper has been accepted to COCOON 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Complexity (cs.CC)</span>

</div>
<p class="mathjax">Longest Increasing Subsequence (LIS) is a fundamental problem in
combinatorics and computer science. Previously, there have been numerous works
on both upper bounds and lower bounds of the time complexity of computing and
approximating LIS, yet only a few on the equally important space complexity.
<br />In this paper, we further study the space complexity of computing and
approximating LIS in various models. Specifically, we prove non-trivial space
lower bounds in the following two models: (1) the adaptive query-once model or
read-once branching programs, and (2) the streaming model where the order of
streaming is different from the natural order.
<br />As far as we know, there are no previous works on the space complexity of LIS
in these models. Besides the bounds, our work also leaves many intriguing open
problems.
</p>
</div>
</dd>
<dt><a name="item246">[246]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01211" title="Abstract">arXiv:2309.01211</a> [<a href="/pdf/2309.01211" title="Download PDF">pdf</a>, <a href="/format/2309.01211" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Physics-inspired Neural Networks for Parameter Learning of Adaptive  Cruise Control Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Apostolakis%2C+T">Theocharis Apostolakis</a>, 
<a href="/search/eess?searchtype=author&query=Ampountolas%2C+K">Konstantinos Ampountolas</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages, 8 figures, 3 tables, submitted to IEEE-T-VT
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">This paper proposes and develops a physics-inspired neural network (PiNN) for
learning the parameters of commercially implemented adaptive cruise control
(ACC) systems in automotive industry. To emulate the core functionality of
stock ACC systems, which have proprietary control logic and undisclosed
parameters, the constant time-headway policy (CTHP) is adopted. Leveraging the
multi-layer artificial neural networks as universal approximators, the
developed PiNN serves as a surrogate model for the longitudinal dynamics of
ACC-engaged vehicles, efficiently learning the unknown parameters of the CTHP.
The ability of the PiNN to infer the unknown ACC parameters is meticulous
evaluated using both synthetic and high-fidelity empirical data of space-gap
and relative velocity involving ACC-engaged vehicles in platoon formation. The
results have demonstrated the superior predictive ability of the proposed PiNN
in learning the unknown design parameters of stock ACC systems from different
car manufacturers. The set of ACC model parameters obtained from the PiNN
revealed that the stock ACC systems of the considered vehicles in three
experimental campaigns are neither $L_2$ nor $L_\infty$ string stable.
</p>
</div>
</dd>
<dt><a name="item247">[247]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01212" title="Abstract">arXiv:2309.01212</a> [<a href="/pdf/2309.01212" title="Download PDF">pdf</a>, <a href="/format/2309.01212" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> NADiffuSE: Noise-aware Diffusion-based Model for Speech Enhancement
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+W">Wen Wang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+D">Dongchao Yang</a>, 
<a href="/search/cs?searchtype=author&query=Ye%2C+Q">Qichen Ye</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+B">Bowen Cao</a>, 
<a href="/search/cs?searchtype=author&query=Zou%2C+Y">Yuexian Zou</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">The goal of speech enhancement (SE) is to eliminate the background
interference from the noisy speech signal. Generative models such as diffusion
models (DM) have been applied to the task of SE because of better
generalization in unseen noisy scenes. Technical routes for the DM-based SE
methods can be summarized into three types: task-adapted diffusion process
formulation, generator-plus-conditioner (GPC) structures and the multi-stage
frameworks. We focus on the first two approaches, which are constructed under
the GPC architecture and use the task-adapted diffusion process to better deal
with the real noise. However, the performance of these SE models is limited by
the following issues: (a) Non-Gaussian noise estimation in the task-adapted
diffusion process. (b) Conditional domain bias caused by the weak conditioner
design in the GPC structure. (c) Large amount of residual noise caused by
unreasonable interpolation operations during inference. To solve the above
problems, we propose a noise-aware diffusion-based SE model (NADiffuSE) to
boost the SE performance, where the noise representation is extracted from the
noisy speech signal and introduced as a global conditional information for
estimating the non-Gaussian components. Furthermore, the anchor-based inference
algorithm is employed to achieve a compromise between the speech distortion and
noise residual. In order to mitigate the performance degradation caused by the
conditional domain bias in the GPC framework, we investigate three model
variants, all of which can be viewed as multi-stage SE based on the
preprocessing networks for Mel spectrograms. Experimental results show that
NADiffuSE outperforms other DM-based SE models under the GPC infrastructure.
Audio samples are available at: https://square-of-w.github.io/NADiffuSE-demo/.
</p>
</div>
</dd>
<dt><a name="item248">[248]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01214" title="Abstract">arXiv:2309.01214</a> [<a href="/pdf/2309.01214" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Immersive Technologies in Virtual Companions: A Systematic Literature  Review
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Momand%2C+Z">Ziaullah Momand</a>, 
<a href="/search/cs?searchtype=author&query=Chan%2C+J+H">Jonathan H. Chan</a>, 
<a href="/search/cs?searchtype=author&query=Mongkolnam%2C+P">Pornchai Mongkolnam</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">The emergence of virtual companions is transforming the evolution of
intelligent systems that effortlessly cater to the unique requirements of
users. These advanced systems not only take into account the user present
capabilities, preferences, and needs but also possess the capability to adapt
dynamically to changes in the environment, as well as fluctuations in the users
emotional state or behavior. A virtual companion is an intelligent software or
application that offers support, assistance, and companionship across various
aspects of users lives. Various enabling technologies are involved in building
virtual companion, among these, Augmented Reality (AR), and Virtual Reality
(VR) are emerging as transformative tools. While their potential for use in
virtual companions or digital assistants is promising, their applications in
these domains remain relatively unexplored. To address this gap, a systematic
review was conducted to investigate the applications of VR, AR, and MR
immersive technologies in the development of virtual companions. A
comprehensive search across PubMed, Scopus, and Google Scholar yielded 28
relevant articles out of a pool of 644. The review revealed that immersive
technologies, particularly VR and AR, play a significant role in creating
digital assistants, offering a wide range of applications that brings various
facilities in the individuals life in areas such as addressing social
isolation, enhancing cognitive abilities and dementia care, facilitating
education, and more. Additionally, AR and MR hold potential for enhancing
Quality of life (QoL) within the context of virtual companion technology. The
findings of this review provide a valuable foundation for further research in
this evolving field.
</p>
</div>
</dd>
<dt><a name="item249">[249]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01219" title="Abstract">arXiv:2309.01219</a> [<a href="/pdf/2309.01219" title="Download PDF">pdf</a>, <a href="/format/2309.01219" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Siren&#x27;s Song in the AI Ocean: A Survey on Hallucination in Large  Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yue Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yafu Li</a>, 
<a href="/search/cs?searchtype=author&query=Cui%2C+L">Leyang Cui</a>, 
<a href="/search/cs?searchtype=author&query=Cai%2C+D">Deng Cai</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+L">Lemao Liu</a>, 
<a href="/search/cs?searchtype=author&query=Fu%2C+T">Tingchen Fu</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+X">Xinting Huang</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+E">Enbo Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yu Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yulong Chen</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+L">Longyue Wang</a>, 
<a href="/search/cs?searchtype=author&query=Luu%2C+A+T">Anh Tuan Luu</a>, 
<a href="/search/cs?searchtype=author&query=Bi%2C+W">Wei Bi</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+F">Freda Shi</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+S">Shuming Shi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> work in progress; 32 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Computers and Society (cs.CY); Machine Learning (cs.LG)

</div>
<p class="mathjax">While large language models (LLMs) have demonstrated remarkable capabilities
across a range of downstream tasks, a significant concern revolves around their
propensity to exhibit hallucinations: LLMs occasionally generate content that
diverges from the user input, contradicts previously generated context, or
misaligns with established world knowledge. This phenomenon poses a substantial
challenge to the reliability of LLMs in real-world scenarios. In this paper, we
survey recent efforts on the detection, explanation, and mitigation of
hallucination, with an emphasis on the unique challenges posed by LLMs. We
present taxonomies of the LLM hallucination phenomena and evaluation
benchmarks, analyze existing approaches aiming at mitigating LLM hallucination,
and discuss potential directions for future research.
</p>
</div>
</dd>
<dt><a name="item250">[250]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01220" title="Abstract">arXiv:2309.01220</a> [<a href="/pdf/2309.01220" title="Download PDF">pdf</a>, <a href="/format/2309.01220" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the numerical approximation of the distance to singularity for  matrix-valued functions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Gnazzo%2C+M">Miryam Gnazzo</a>, 
<a href="/search/math?searchtype=author&query=Guglielmi%2C+N">Nicola Guglielmi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 21 pages, 2 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">Given a matrix-valued function $\mathcal{F}(\lambda)=\sum_{i=1}^d
f_i(\lambda) A_i$, with complex matrices $A_i$ and $f_i(\lambda)$ analytic
functions for $i=1,\ldots,d$, we discuss a method for the numerical
approximation of the distance to singularity for $\mathcal{F}(\lambda)$. The
closest matrix-valued function $\widetilde {\mathcal{F}}(\lambda)$ with respect
to the Frobenius norm is approximated using an iterative method. The condition
of singularity on the matrix-valued function is translated into a numerical
constraint for a suitable minimization problem. Unlike the case of matrix
polynomials, in the general setting of matrix-valued functions the main issue
is that the function $\det ( \widetilde{\mathcal{F}}(\lambda) )$ may have an
infinite number of roots. The main feature of the numerical method consists in
the possibility of extending it to different structures, such as sparsity
patterns induced by the matrix coefficients.
</p>
</div>
</dd>
<dt><a name="item251">[251]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01224" title="Abstract">arXiv:2309.01224</a> [<a href="/pdf/2309.01224" title="Download PDF">pdf</a>, <a href="/format/2309.01224" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Quasi-static Soft Fixture Analysis of Rigid and Deformable Objects
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dong%2C+Y">Yifei Dong</a>, 
<a href="/search/cs?searchtype=author&query=Pokorny%2C+F+T">Florian T. Pokorny</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Paper submitted to ICRA 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">We present a sampling-based approach to reasoning about the caging-based
manipulation of rigid and a simplified class of deformable 3D objects subject
to energy constraints. Towards this end, we propose the notion of soft fixtures
extending earlier work on energy-bounded caging to include a broader set of
energy function constraints and settings, such as gravitational and elastic
potential energy of 3D deformable objects. Previous methods focused on
establishing provably correct algorithms to compute lower bounds or
analytically exact estimates of escape energy for a very restricted class of
known objects with low-dimensional C-spaces, such as planar polygons. We
instead propose a practical sampling-based approach that is applicable in
higher-dimensional C-spaces but only produces a sequence of upper-bound
estimates that, however, appear to converge rapidly to actual escape energy. We
present 8 simulation experiments demonstrating the applicability of our
approach to various complex quasi-static manipulation scenarios. Quantitative
results indicate the effectiveness of our approach in providing upper-bound
estimates for escape energy in quasi-static manipulation scenarios. Two
real-world experiments also show that the computed normalized escape energy
estimates appear to correlate strongly with the probability of escape of an
object under randomized pose perturbation.
</p>
</div>
</dd>
<dt><a name="item252">[252]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01225" title="Abstract">arXiv:2309.01225</a> [<a href="/pdf/2309.01225" title="Download PDF">pdf</a>, <a href="/format/2309.01225" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Stabilization of parareal algorithms for long time computation of a  class of highly oscillatory Hamiltonian flows using data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Fang%2C+R">Rui Fang</a>, 
<a href="/search/math?searchtype=author&query=Tsai%2C+R">Richard Tsai</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">Applying parallel-in-time algorithms to multiscale Hamiltonian systems to
obtain stable long time simulations is very challenging. In this paper, we
present novel data-driven methods aimed at improving the standard parareal
algorithm developed by Lion, Maday, and Turinici in 2001, for multiscale
Hamiltonian systems. The first method involves constructing a correction
operator to improve a given inaccurate coarse solver through solving a
Procrustes problem using data collected online along parareal trajectories. The
second method involves constructing an efficient, high-fidelity solver by a
neural network trained with offline generated data. For the second method, we
address the issues of effective data generation and proper loss function design
based on the Hamiltonian function. We show proof-of-concept by applying the
proposed methods to a Fermi-Pasta-Ulum (FPU) problem. The numerical results
demonstrate that the Procrustes parareal method is able to produce solutions
that are more stable in energy compared to the standard parareal. The neural
network solver can achieve comparable or better runtime performance compared to
numerical solvers of similar accuracy. When combined with the standard parareal
algorithm, the improved neural network solutions are slightly more stable in
energy than the improved numerical coarse solutions.
</p>
</div>
</dd>
<dt><a name="item253">[253]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01226" title="Abstract">arXiv:2309.01226</a> [<a href="/pdf/2309.01226" title="Download PDF">pdf</a>, <a href="/format/2309.01226" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Saturn: An Optimized Data System for Large Model Deep Learning Workloads
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nagrecha%2C+K">Kabir Nagrecha</a>, 
<a href="/search/cs?searchtype=author&query=Kumar%2C+A">Arun Kumar</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Under submission at VLDB. Code available: <a href="https://github.com/knagrecha/saturn.">this https URL</a> 12 pages + 3 pages references + 2 pages appendix
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Distributed, Parallel, and Cluster Computing (cs.DC)

</div>
<p class="mathjax">Large language models such as GPT-3 &amp; ChatGPT have transformed deep learning
(DL), powering applications that have captured the public's imagination. These
models are rapidly being adopted across domains for analytics on various
modalities, often by finetuning pre-trained base models. Such models need
multiple GPUs due to both their size and computational load, driving the
development of a bevy of "model parallelism" techniques &amp; tools. Navigating
such parallelism choices, however, is a new burden for end users of DL such as
data scientists, domain scientists, etc. who may lack the necessary systems
knowhow. The need for model selection, which leads to many models to train due
to hyper-parameter tuning or layer-wise finetuning, compounds the situation
with two more burdens: resource apportioning and scheduling. In this work, we
tackle these three burdens for DL users in a unified manner by formalizing them
as a joint problem that we call SPASE: Select a Parallelism, Allocate
resources, and SchedulE. We propose a new information system architecture to
tackle the SPASE problem holistically, representing a key step toward enabling
wider adoption of large DL models. We devise an extensible template for
existing parallelism schemes and combine it with an automated empirical
profiler for runtime estimation. We then formulate SPASE as an MILP.
<br />We find that direct use of an MILP-solver is significantly more effective
than several baseline heuristics. We optimize the system runtime further with
an introspective scheduling approach. We implement all these techniques into a
new data system we call Saturn. Experiments with benchmark DL workloads show
that Saturn achieves 39-49% lower model selection runtimes than typical current
DL practice.
</p>
</div>
</dd>
<dt><a name="item254">[254]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01230" title="Abstract">arXiv:2309.01230</a> [<a href="/pdf/2309.01230" title="Download PDF">pdf</a>, <a href="/format/2309.01230" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> lfads-torch: A modular and extensible implementation of latent factor  analysis via dynamical systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sedler%2C+A+R">Andrew R. Sedler</a>, 
<a href="/search/cs?searchtype=author&query=Pandarinath%2C+C">Chethan Pandarinath</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 4 pages, 1 figure, 1 table
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Neurons and Cognition (q-bio.NC)

</div>
<p class="mathjax">Latent factor analysis via dynamical systems (LFADS) is an RNN-based
variational sequential autoencoder that achieves state-of-the-art performance
in denoising high-dimensional neural activity for downstream applications in
science and engineering. Recently introduced variants and extensions continue
to demonstrate the applicability of the architecture to a wide variety of
problems in neuroscience. Since the development of the original implementation
of LFADS, new technologies have emerged that use dynamic computation graphs,
minimize boilerplate code, compose model configuration files, and simplify
large-scale training. Building on these modern Python libraries, we introduce
lfads-torch -- a new open-source implementation of LFADS that unifies existing
variants and is designed to be easier to understand, configure, and extend.
Documentation, source code, and issue tracking are available at
https://github.com/arsedler9/lfads-torch .
</p>
</div>
</dd>
<dt><a name="item255">[255]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01236" title="Abstract">arXiv:2309.01236</a> [<a href="/pdf/2309.01236" title="Download PDF">pdf</a>, <a href="/format/2309.01236" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> BodySLAM++: Fast and Tightly-Coupled Visual-Inertial Camera and Human  Motion Tracking
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Henning%2C+D+F">Dorian F. Henning</a>, 
<a href="/search/cs?searchtype=author&query=Choi%2C+C">Christopher Choi</a>, 
<a href="/search/cs?searchtype=author&query=Schaefer%2C+S">Simon Schaefer</a>, 
<a href="/search/cs?searchtype=author&query=Leutenegger%2C+S">Stefan Leutenegger</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> IROS 2023. Video: <a href="https://youtu.be/UcutiHQwbGk">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Robotics (cs.RO)

</div>
<p class="mathjax">Robust, fast, and accurate human state - 6D pose and posture - estimation
remains a challenging problem. For real-world applications, the ability to
estimate the human state in real-time is highly desirable. In this paper, we
present BodySLAM++, a fast, efficient, and accurate human and camera state
estimation framework relying on visual-inertial data. BodySLAM++ extends an
existing visual-inertial state estimation framework, OKVIS2, to solve the dual
task of estimating camera and human states simultaneously. Our system improves
the accuracy of both human and camera state estimation with respect to baseline
methods by 26% and 12%, respectively, and achieves real-time performance at 15+
frames per second on an Intel i7-model CPU. Experiments were conducted on a
custom dataset containing both ground truth human and camera poses collected
with an indoor motion tracking system.
</p>
</div>
</dd>
<dt><a name="item256">[256]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01237" title="Abstract">arXiv:2309.01237</a> [<a href="/pdf/2309.01237" title="Download PDF">pdf</a>, <a href="/ps/2309.01237" title="Download PostScript">ps</a>, <a href="/format/2309.01237" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Information Geometry of UMAP
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kolpakov%2C+A">Alexander Kolpakov</a>, 
<a href="/search/cs?searchtype=author&query=Rocke%2C+A">Aidan Rocke</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Geometry (cs.CG)</span>; Discrete Mathematics (cs.DM); Information Theory (cs.IT); Geometric Topology (math.GT)

</div>
<p class="mathjax">In this note we highlight some connections of UMAP to the basic principles of
Information Geometry. Originally, UMAP was derived from Category Theory
observations. However, we posit that it also has a natural geometric
interpretation.
</p>
</div>
</dd>
<dt><a name="item257">[257]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01238" title="Abstract">arXiv:2309.01238</a> [<a href="/pdf/2309.01238" title="Download PDF">pdf</a>, <a href="/format/2309.01238" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Performance-Sensitive Potential Functions for Efficient Flow of  Connected and Automated Vehicles
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Tzortzoglou%2C+F+N">Filippos N. Tzortzoglou</a>, 
<a href="/search/eess?searchtype=author&query=Theodosis%2C+D">Dionysios Theodosis</a>, 
<a href="/search/eess?searchtype=author&query=Dave%2C+A">Aditya Dave</a>, 
<a href="/search/eess?searchtype=author&query=Malikopoulos%2C+A">Andreas Malikopoulos</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">Connected and automated vehicles (CAVs) provide the most intriguing
opportunity for enabling users to monitor transportation network conditions and
make better decisions for improving safety and transportation efficiency. In
this paper, we address the problem of effectively coordinating CAVs on
lane-based roadways. Our approach utilizes potential functions to generate
repulsive forces between CAVs that ensure collision avoidance. However, such
potential functions can lead to unrealistic acceleration profiles and large
inter-vehicle distances. The primary contribution of this work is the
introduction of performance-sensitive potential functions to address these
challenges. In our approach, the parameters of a potential function are
determined through an optimization problem aiming to reduce both acceleration
and inter-vehicle distances. To circumvent the computational implications due
to the complexity of the resulting optimization problem that prevents the
derivation of a real-time solution, we train a neural network model to learn
the mapping of initial conditions to optimal parameters derived offline. Then,
we prove sufficient criteria for the sampled-data model to ensure that the
neural network output does not activate any of the state and safety
constraints. Finally, we provide simulation results to demonstrate the
effectiveness of the proposed approach.
</p>
</div>
</dd>
<dt><a name="item258">[258]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01240" title="Abstract">arXiv:2309.01240</a> [<a href="/pdf/2309.01240" title="Download PDF">pdf</a>, <a href="/format/2309.01240" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Decentralized shape formation and force-based interactive formation  control in robot swarms
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=S%2C+A+C">Akshaya C S</a>, 
<a href="/search/cs?searchtype=author&query=Soma%2C+K">Karthik Soma</a>, 
<a href="/search/cs?searchtype=author&query=B%2C+V">Visweswaran B</a>, 
<a href="/search/cs?searchtype=author&query=Ravichander%2C+A">Aditya Ravichander</a>, 
<a href="/search/cs?searchtype=author&query=PM%2C+V+N">Venkata Nagarjun PM</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages, 10 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Multiagent Systems (cs.MA)</span>; Robotics (cs.RO)

</div>
<p class="mathjax">Swarm robotic systems utilize collective behaviour to achieve goals that
might be too complex for a lone entity, but become attainable with localized
communication and collective decision making. In this paper, a behaviour-based
distributed approach to shape formation is proposed. Flocking into strategic
formations is observed in migratory birds and fish to avoid predators and also
for energy conservation. The formation is maintained throughout long periods
without collapsing and is advantageous for communicating within the flock.
Similar behaviour can be deployed in multi-agent systems to enhance
coordination within the swarm. Existing methods for formation control are
either dependent on the size and geometry of the formation or rely on
maintaining the formation with a single reference in the swarm (the leader).
These methods are not resilient to failure and involve a high degree of
deformation upon obstacle encounter before the shape is recovered again. To
improve the performance, artificial force-based interaction amongst the
entities of the swarm to maintain shape integrity while encountering obstacles
is elucidated.
</p>
</div>
</dd>
<dt><a name="item259">[259]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01242" title="Abstract">arXiv:2309.01242</a> [<a href="/pdf/2309.01242" title="Download PDF">pdf</a>, <a href="/format/2309.01242" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On input-to-state stability verification of identified models obtained  by Koopman operator
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Mei%2C+W">Wenjie Mei</a>, 
<a href="/search/eess?searchtype=author&query=Zhou%2C+Y">Yu Zhou</a>, 
<a href="/search/eess?searchtype=author&query=Taha%2C+A">Ahmad Taha</a>, 
<a href="/search/eess?searchtype=author&query=Zhao%2C+C">Chengyan Zhao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">This paper proposes a class of basis functions for realizing the
input-to-state stability verification of identified models obtained from the
true system (assumed to be input-to-state stable) using the Koopman operator.
The formulated input-to-state stability conditions are in the form of linear
matrix inequalities. We also present extensions to relax the imposed
restrictions on the basis functions. A numerical example is provided to
demonstrate the efficacy of the proposed results.
</p>
</div>
</dd>
<dt><a name="item260">[260]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01243" title="Abstract">arXiv:2309.01243</a> [<a href="/pdf/2309.01243" title="Download PDF">pdf</a>, <a href="/format/2309.01243" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Privacy-Utility Tradeoff of OLS with Random Projections
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lu%2C+Y">Yun Lu</a>, 
<a href="/search/cs?searchtype=author&query=Magdon-Ismail%2C+M">Malik Magdon-Ismail</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+Y">Yu Wei</a>, 
<a href="/search/cs?searchtype=author&query=Zikas%2C+V">Vassilis Zikas</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">We study the differential privacy (DP) of a core ML problem, linear ordinary
least squares (OLS), a.k.a. $\ell_2$-regression. Our key result is that the
approximate LS algorithm (ALS) (Sarlos, 2006), a randomized solution to the OLS
problem primarily used to improve performance on large datasets, also preserves
privacy. ALS achieves a better privacy/utility tradeoff, without modifications
or further noising, when compared to alternative private OLS algorithms which
modify and/or noise OLS. We give the first {\em tight} DP-analysis for the ALS
algorithm and the standard Gaussian mechanism (Dwork et al., 2014) applied to
OLS. Our methodology directly improves the privacy analysis of (Blocki et al.,
2012) and (Sheffet, 2019)) and introduces new tools which may be of independent
interest: (1) the exact spectrum of $(\epsilon, \delta)$-DP parameters (``DP
spectrum") for mechanisms whose output is a $d$-dimensional Gaussian, and (2)
an improved DP spectrum for random projection (compared to (Blocki et al.,
2012) and (Sheffet, 2019)).
<br />All methods for private OLS (including ours) assume, often implicitly,
restrictions on the input database, such as bounds on leverage and residuals.
We prove that such restrictions are necessary. Hence, computing the privacy of
mechanisms such as ALS must estimate these database parameters, which can be
infeasible in big datasets. For more complex ML models, DP bounds may not even
be tractable. There is a need for blackbox DP-estimators (Lu et al., 2022)
which empirically estimate a data-dependent privacy. We demonstrate the
effectiveness of such a DP-estimator by empirically recovering a DP-spectrum
that matches our theory for OLS. This validates the DP-estimator in a
nontrivial ML application, opening the door to its use in more complex
nonlinear ML settings where theory is unavailable.
</p>
</div>
</dd>
<dt><a name="item261">[261]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01245" title="Abstract">arXiv:2309.01245</a> [<a href="/pdf/2309.01245" title="Download PDF">pdf</a>, <a href="/ps/2309.01245" title="Download PostScript">ps</a>, <a href="/format/2309.01245" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Representations Matter: Embedding Modes of Large Language Models using  Dynamic Mode Decomposition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Akrout%2C+M">Mohamed Akrout</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Existing large language models (LLMs) are known for generating "hallucinated"
content, namely a fabricated text of plausibly looking, yet unfounded, facts.
To identify when these hallucination scenarios occur, we examine the properties
of the generated text in the embedding space. Specifically, we draw inspiration
from the dynamic mode decomposition (DMD) tool in analyzing the pattern
evolution of text embeddings across sentences. We empirically demonstrate how
the spectrum of sentence embeddings over paragraphs is constantly low-rank for
the generated text, unlike that of the ground-truth text. Importantly, we find
that evaluation cases having LLM hallucinations correspond to ground-truth
embedding patterns with a higher number of modes being poorly approximated by
the few modes associated with LLM embedding patterns. In analogy to near-field
electromagnetic evanescent waves, the embedding DMD eigenmodes of the generated
text with hallucinations vanishes quickly across sentences as opposed to those
of the ground-truth text. This suggests that the hallucinations result from
both the generation techniques and the underlying representation.
</p>
</div>
</dd>
<dt><a name="item262">[262]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01246" title="Abstract">arXiv:2309.01246</a> [<a href="/pdf/2309.01246" title="Download PDF">pdf</a>, <a href="/format/2309.01246" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Generic Image Manipulation Detection with Weakly-Supervised  Self-Consistency Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhai%2C+Y">Yuanhao Zhai</a>, 
<a href="/search/cs?searchtype=author&query=Luan%2C+T">Tianyu Luan</a>, 
<a href="/search/cs?searchtype=author&query=Doermann%2C+D">David Doermann</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+J">Junsong Yuan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to ICCV 2023, code: <a href="https://github.com/yhZhai/WSCL">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">As advanced image manipulation techniques emerge, detecting the manipulation
becomes increasingly important. Despite the success of recent learning-based
approaches for image manipulation detection, they typically require expensive
pixel-level annotations to train, while exhibiting degraded performance when
testing on images that are differently manipulated compared with training
images. To address these limitations, we propose weakly-supervised image
manipulation detection, such that only binary image-level labels (authentic or
tampered with) are required for training purpose. Such a weakly-supervised
setting can leverage more training images and has the potential to adapt
quickly to new manipulation techniques. To improve the generalization ability,
we propose weakly-supervised self-consistency learning (WSCL) to leverage the
weakly annotated images. Specifically, two consistency properties are learned:
multi-source consistency (MSC) and inter-patch consistency (IPC). MSC exploits
different content-agnostic information and enables cross-source learning via an
online pseudo label generation and refinement process. IPC performs global
pair-wise patch-patch relationship reasoning to discover a complete region of
manipulation. Extensive experiments validate that our WSCL, even though is
weakly supervised, exhibits competitive performance compared with
fully-supervised counterpart under both in-distribution and out-of-distribution
evaluations, as well as reasonable manipulation localization ability.
</p>
</div>
</dd>
<dt><a name="item263">[263]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01248" title="Abstract">arXiv:2309.01248</a> [<a href="/pdf/2309.01248" title="Download PDF">pdf</a>, <a href="/format/2309.01248" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Modified Step Size for Enhanced Stochastic Gradient Descent: Convergence  and Experiments
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shamaee%2C+M+S">M. Soheil Shamaee</a>, 
<a href="/search/cs?searchtype=author&query=Hafshejani%2C+S+F">S. Fathi Hafshejani</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Mathematics Interdisciplinary Research 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Optimization and Control (math.OC)

</div>
<p class="mathjax">This paper introduces a novel approach to enhance the performance of the
stochastic gradient descent (SGD) algorithm by incorporating a modified decay
step size based on $\frac{1}{\sqrt{t}}$. The proposed step size integrates a
logarithmic term, leading to the selection of smaller values in the final
iterations. Our analysis establishes a convergence rate of $O(\frac{\ln
T}{\sqrt{T}})$ for smooth non-convex functions without the
Polyak-{\L}ojasiewicz condition. To evaluate the effectiveness of our approach,
we conducted numerical experiments on image classification tasks using the
FashionMNIST, and CIFAR10 datasets, and the results demonstrate significant
improvements in accuracy, with enhancements of $0.5\%$ and $1.4\%$ observed,
respectively, compared to the traditional $\frac{1}{\sqrt{t}}$ step size. The
source code can be found at \\\url{https://github.com/Shamaeem/LNSQRTStepSize}.
</p>
</div>
</dd>
<dt><a name="item264">[264]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01249" title="Abstract">arXiv:2309.01249</a> [<a href="/pdf/2309.01249" title="Download PDF">pdf</a>, <a href="/format/2309.01249" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Large AI Model Empowered Multimodal Semantic Communications
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jiang%2C+F">Feibo Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+Y">Yubo Peng</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+L">Li Dong</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+K">Kezhi Wang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+K">Kun Yang</a>, 
<a href="/search/cs?searchtype=author&query=Pan%2C+C">Cunhua Pan</a>, 
<a href="/search/cs?searchtype=author&query=You%2C+X">Xiaohu You</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To be submitted for journal publication
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computation and Language (cs.CL); Machine Learning (cs.LG)

</div>
<p class="mathjax">Multimodal signals, including text, audio, image and video, can be integrated
into Semantic Communication (SC) for providing an immersive experience with low
latency and high quality at the semantic level. However, the multimodal SC has
several challenges, including data heterogeneity, semantic ambiguity, and
signal fading. Recent advancements in large AI models, particularly in
Multimodal Language Model (MLM) and Large Language Model (LLM), offer potential
solutions for these issues. To this end, we propose a Large AI Model-based
Multimodal SC (LAM-MSC) framework, in which we first present the MLM-based
Multimodal Alignment (MMA) that utilizes the MLM to enable the transformation
between multimodal and unimodal data while preserving semantic consistency.
Then, a personalized LLM-based Knowledge Base (LKB) is proposed, which allows
users to perform personalized semantic extraction or recovery through the LLM.
This effectively addresses the semantic ambiguity. Finally, we apply the
Conditional Generative adversarial networks-based channel Estimation (CGE) to
obtain Channel State Information (CSI). This approach effectively mitigates the
impact of fading channels in SC. Finally, we conduct simulations that
demonstrate the superior performance of the LAM-MSC framework.
</p>
</div>
</dd>
<dt><a name="item265">[265]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01250" title="Abstract">arXiv:2309.01250</a> [<a href="/pdf/2309.01250" title="Download PDF">pdf</a>, <a href="/ps/2309.01250" title="Download PostScript">ps</a>, <a href="/format/2309.01250" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Longest Common Substring and Longest Palindromic Substring in  $\tilde{\mathcal{O}}(\sqrt{n})$ Time
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cantone%2C+D">Domenico Cantone</a>, 
<a href="/search/cs?searchtype=author&query=Faro%2C+S">Simone Faro</a>, 
<a href="/search/cs?searchtype=author&query=Pavone%2C+A">Arianna Pavone</a>, 
<a href="/search/cs?searchtype=author&query=Viola%2C+C">Caterina Viola</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>; Quantum Physics (quant-ph)

</div>
<p class="mathjax">The Longest Common Substring (LCS) and Longest Palindromic Substring (LPS)
are classical problems in computer science, representing fundamental challenges
in string processing. Both problems can be solved in linear time using a
classical model of computation, by means of very similar algorithms, both
relying on the use of suffix trees. Very recently, two sublinear algorithms for
LCS and LPS in the quantum query model have been presented by Le Gall and
Seddighin~\cite{GallS23}, requiring $\tilde{\mathcal{O}}(n^{5/6})$ and
$\tilde{\mathcal{O}}(\sqrt{n})$ queries, respectively. However, while the query
model is fascinating from a theoretical standpoint, its practical applicability
becomes limited when it comes to crafting algorithms meant for actual execution
on real hardware. In this paper we present, for the first time, a
$\tilde{\mathcal{O}}(\sqrt{n})$ quantum algorithm for both LCS and LPS working
in the circuit model of computation. Our solutions are simpler than previous
ones and can be easily translated into quantum procedures. We also present
actual implementations of the two algorithms as quantum circuits working in
$\mathcal{O}(\sqrt{n}\log^5(n))$ and $\mathcal{O}(\sqrt{n}\log^4(n))$ time,
respectively.
</p>
</div>
</dd>
<dt><a name="item266">[266]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01252" title="Abstract">arXiv:2309.01252</a> [<a href="/pdf/2309.01252" title="Download PDF">pdf</a>, <a href="/format/2309.01252" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> S2RF: Semantically Stylized Radiance Fields
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lahiri%2C+D">Dishani Lahiri</a>, 
<a href="/search/cs?searchtype=author&query=Panse%2C+N">Neeraj Panse</a>, 
<a href="/search/cs?searchtype=author&query=Kumar%2C+M">Moneish Kumar</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> AI for 3D Content Creation at International Conference on Computer Vision 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">We present our method for transferring style from any arbitrary image(s) to
object(s) within a 3D scene. Our primary objective is to offer more control in
3D scene stylization, facilitating the creation of customizable and stylized
scene images from arbitrary viewpoints. To achieve this, we propose a novel
approach that incorporates nearest neighborhood-based loss, allowing for
flexible 3D scene reconstruction while effectively capturing intricate style
details and ensuring multi-view consistency.
</p>
</div>
</dd>
<dt><a name="item267">[267]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01255" title="Abstract">arXiv:2309.01255</a> [<a href="/pdf/2309.01255" title="Download PDF">pdf</a>, <a href="/format/2309.01255" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the structure of the Schur complement matrix for the Stokes equation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Pimanov%2C+V">Vladislav Pimanov</a>, 
<a href="/search/math?searchtype=author&query=Muravleva%2C+E">Ekaterina Muravleva</a>, 
<a href="/search/math?searchtype=author&query=Oseledets%2C+I">Ivan Oseledets</a>, 
<a href="/search/math?searchtype=author&query=Iliev%2C+O">Oleg Iliev</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">In this paper, we investigate the structure of the Schur complement matrix
for the fully-staggered finite-difference discretization of the stationary
Stokes equation. Specifically, we demonstrate that the structure of the Schur
complement matrix depends qualitatively on a particular characteristic, namely
the number of non-unit eigenvalues, and the two limiting cases are of special
interest.
</p>
</div>
</dd>
<dt><a name="item268">[268]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01256" title="Abstract">arXiv:2309.01256</a> [<a href="/pdf/2309.01256" title="Download PDF">pdf</a>, <a href="/format/2309.01256" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> BDC-Adapter: Brownian Distance Covariance for Better Vision-Language  Reasoning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yi Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+C">Ce Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Liao%2C+Z">Zihan Liao</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+Y">Yushun Tang</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+Z">Zhihai He</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by BMVC 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Computation and Language (cs.CL)

</div>
<p class="mathjax">Large-scale pre-trained Vision-Language Models (VLMs), such as CLIP and
ALIGN, have introduced a new paradigm for learning transferable visual
representations. Recently, there has been a surge of interest among researchers
in developing lightweight fine-tuning techniques to adapt these models to
downstream visual tasks. We recognize that current state-of-the-art fine-tuning
methods, such as Tip-Adapter, simply consider the covariance between the query
image feature and features of support few-shot training samples, which only
captures linear relations and potentially instigates a deceptive perception of
independence. To address this issue, in this work, we innovatively introduce
Brownian Distance Covariance (BDC) to the field of vision-language reasoning.
The BDC metric can model all possible relations, providing a robust metric for
measuring feature dependence. Based on this, we present a novel method called
BDC-Adapter, which integrates BDC prototype similarity reasoning and
multi-modal reasoning network prediction to perform classification tasks. Our
extensive experimental results show that the proposed BDC-Adapter can freely
handle non-linear relations and fully characterize independence, outperforming
the current state-of-the-art methods by large margins.
</p>
</div>
</dd>
<dt><a name="item269">[269]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01257" title="Abstract">arXiv:2309.01257</a> [<a href="/pdf/2309.01257" title="Download PDF">pdf</a>, <a href="/format/2309.01257" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A dynamic state-based model of crowds
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Amos%2C+M">Martyn Amos</a>, 
<a href="/search/cs?searchtype=author&query=Gwynne%2C+S">Steve Gwynne</a>, 
<a href="/search/cs?searchtype=author&query=Templeton%2C+A">Anne Templeton</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Presented at the 2023 Pedestrian and Evacuation Dynamics Conference, Eindhoven, The Netherlands, June 28-30 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Multiagent Systems (cs.MA)</span>

</div>
<p class="mathjax">We consider the problem of categorizing and describing the dynamic properties
and behaviours of crowds over time. Previous work has tended to focus on a
relatively static "typology"-based approach, which does not account for the
fact that crowds can change, often quite rapidly. Moreover, the labels attached
to crowd behaviours are often subjective and/or value-laden. Here, we present
an alternative approach, loosely based on the statechart formalism from
computer science. This uses relatively "agnostic" labels, which means that we
do not prescribe the behaviour of an individual, but provide a context within
which an individual might behave. This naturally describes the time-series
evolution of a crowd as "threads" of states, and allows for the dynamic
handling of an arbitrary number of "sub-crowds".
</p>
</div>
</dd>
<dt><a name="item270">[270]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01261" title="Abstract">arXiv:2309.01261</a> [<a href="/pdf/2309.01261" title="Download PDF">pdf</a>, <a href="/format/2309.01261" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Worst-Case Input Generation for Concurrent Programs under Non-Monotone  Resource Metrics
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pham%2C+L">Long Pham</a>, 
<a href="/search/cs?searchtype=author&query=Hoffmann%2C+J">Jan Hoffmann</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Programming Languages (cs.PL)</span>; Distributed, Parallel, and Cluster Computing (cs.DC); Logic in Computer Science (cs.LO)

</div>
<p class="mathjax">Worst-case input generation aims to automatically generate inputs that
exhibit the worst-case performance of programs. It has several applications,
and can, for example, detect vulnerabilities to denial-of-service attacks.
However, it is non-trivial to generate worst-case inputs for concurrent
programs, particularly for resources like memory where the peak cost depends on
how processes are scheduled.
<br />This article presents the first sound worst-case input generation algorithm
for concurrent programs under non-monotone resource metrics like memory. The
key insight is to leverage resource-annotated session types and symbolic
execution. Session types describe communication protocols on channels in
process calculi. Equipped with resource annotations, resource-annotated session
types not only encode cost bounds but also indicate how many resources can be
reused and transferred between processes. This information is critical for
identifying a worst-case execution path during symbolic execution. The
algorithm is sound: if it returns any input, it is guaranteed to be a valid
worst-case input. The algorithm is also relatively complete: as long as
resource-annotated session types are sufficiently expressive and the background
theory for SMT solving is decidable, a worst-case input is guaranteed to be
returned. A simple case study of a web server's memory usage demonstrates the
utility of the worst-case input generation algorithm.
</p>
</div>
</dd>
<dt><a name="item271">[271]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01262" title="Abstract">arXiv:2309.01262</a> [<a href="/pdf/2309.01262" title="Download PDF">pdf</a>, <a href="/format/2309.01262" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multimodal Contrastive Learning with Hard Negative Sampling for Human  Activity Recognition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Choi%2C+H">Hyeongju Choi</a>, 
<a href="/search/cs?searchtype=author&query=Beedu%2C+A">Apoorva Beedu</a>, 
<a href="/search/cs?searchtype=author&query=Essa%2C+I">Irfan Essa</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Human-Computer Interaction (cs.HC); Machine Learning (cs.LG); Signal Processing (eess.SP)

</div>
<p class="mathjax">Human Activity Recognition (HAR) systems have been extensively studied by the
vision and ubiquitous computing communities due to their practical applications
in daily life, such as smart homes, surveillance, and health monitoring.
<br />Typically, this process is supervised in nature and the development of such
systems requires access to large quantities of annotated data.
<br />However, the higher costs and challenges associated with obtaining good
quality annotations have rendered the application of self-supervised methods an
attractive option and contrastive learning comprises one such method.
<br />However, a major component of successful contrastive learning is the
selection of good positive and negative samples.
<br />Although positive samples are directly obtainable, sampling good negative
samples remain a challenge.
<br />As human activities can be recorded by several modalities like camera and IMU
sensors, we propose a hard negative sampling method for multimodal HAR with a
hard negative sampling loss for skeleton and IMU data pairs.
<br />We exploit hard negatives that have different labels from the anchor but are
projected nearby in the latent space using an adjustable concentration
parameter.
<br />Through extensive experiments on two benchmark datasets: UTD-MHAD and MMAct,
we demonstrate the robustness of our approach forlearning strong feature
representation for HAR tasks, and on the limited data setting.
<br />We further show that our model outperforms all other state-of-the-art methods
for UTD-MHAD dataset, and self-supervised methods for MMAct: Cross session,
even when uni-modal data are used during downstream activity recognition.
</p>
</div>
</dd>
<dt><a name="item272">[272]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01264" title="Abstract">arXiv:2309.01264</a> [<a href="/pdf/2309.01264" title="Download PDF">pdf</a>, <a href="/format/2309.01264" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Upward and Orthogonal Planarity are W[1]-hard Parameterized by Treewidth
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jansen%2C+B+M+P">Bart M. P. Jansen</a>, 
<a href="/search/cs?searchtype=author&query=Khazaliya%2C+L">Liana Khazaliya</a>, 
<a href="/search/cs?searchtype=author&query=Kindermann%2C+P">Philipp Kindermann</a>, 
<a href="/search/cs?searchtype=author&query=Liotta%2C+G">Giuseppe Liotta</a>, 
<a href="/search/cs?searchtype=author&query=Montecchiani%2C+F">Fabrizio Montecchiani</a>, 
<a href="/search/cs?searchtype=author&query=Simonov%2C+K">Kirill Simonov</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Appears in the Proceedings of the 31st International Symposium on Graph Drawing and Network Visualization (GD 2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Geometry (cs.CG)</span>; Computational Complexity (cs.CC)

</div>
<p class="mathjax">Upward planarity testing and Rectilinear planarity testing are central
problems in graph drawing. It is known that they are both NP-complete, but XP
when parameterized by treewidth. In this paper we show that these two problems
are W[1]-hard parameterized by treewidth, which answers open problems posed in
two earlier papers. The key step in our proof is an analysis of the
All-or-Nothing Flow problem, a generalization of which was used as an
intermediate step in the NP-completeness proof for both planarity testing
problems. We prove that the flow problem is W[1]-hard parameterized by
treewidth on planar graphs, and that the existing chain of reductions to the
planarity testing problems can be adapted without blowing up the treewidth. Our
reductions also show that the known $n^{O(tw)}$-time algorithms cannot be
improved to run in time $n^{o(tw)}$ unless ETH fails.
</p>
</div>
</dd>
<dt><a name="item273">[273]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01265" title="Abstract">arXiv:2309.01265</a> [<a href="/pdf/2309.01265" title="Download PDF">pdf</a>, <a href="/format/2309.01265" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SOAR: Scene-debiasing Open-set Action Recognition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhai%2C+Y">Yuanhao Zhai</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Ziyi Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Z">Zhenyu Wu</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Y">Yi Wu</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+C">Chunluan Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Doermann%2C+D">David Doermann</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+J">Junsong Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Hua%2C+G">Gang Hua</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to ICCV 2023, code:<a href="https://github.com/yhZhai/SOAR">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Deep learning models have a risk of utilizing spurious clues to make
predictions, such as recognizing actions based on the background scene. This
issue can severely degrade the open-set action recognition performance when the
testing samples have different scene distributions from the training samples.
To mitigate this problem, we propose a novel method, called Scene-debiasing
Open-set Action Recognition (SOAR), which features an adversarial scene
reconstruction module and an adaptive adversarial scene classification module.
The former prevents the decoder from reconstructing the video background given
video features, and thus helps reduce the background information in feature
learning. The latter aims to confuse scene type classification given video
features, with a specific emphasis on the action foreground, and helps to learn
scene-invariant information. In addition, we design an experiment to quantify
the scene bias. The results indicate that the current open-set action
recognizers are biased toward the scene, and our proposed SOAR method better
mitigates such bias. Furthermore, our extensive experiments demonstrate that
our method outperforms state-of-the-art methods, and the ablation studies
confirm the effectiveness of our proposed modules.
</p>
</div>
</dd>
<dt><a name="item274">[274]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01267" title="Abstract">arXiv:2309.01267</a> [<a href="/pdf/2309.01267" title="Download PDF">pdf</a>, <a href="/format/2309.01267" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning-Aware Safety for Interactive Autonomy
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hu%2C+H">Haimin Hu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zixu Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Nakamura%2C+K">Kensuke Nakamura</a>, 
<a href="/search/cs?searchtype=author&query=Bajcsy%2C+A">Andrea Bajcsy</a>, 
<a href="/search/cs?searchtype=author&query=Fisac%2C+J+F">Jaime F. Fisac</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Conference on Robot Learning 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Systems and Control (eess.SY)

</div>
<p class="mathjax">One of the outstanding challenges for the widespread deployment of robotic
systems like autonomous vehicles is ensuring safe interaction with humans
without sacrificing efficiency. Existing safety analysis methods often neglect
the robot's ability to learn and adapt at runtime, leading to overly
conservative behavior. This paper proposes a new closed-loop paradigm for
synthesizing safe control policies that explicitly account for the system's
evolving uncertainty under possible future scenarios. The formulation reasons
jointly about the physical dynamics and the robot's learning algorithm, which
updates its internal belief over time. We leverage adversarial deep
reinforcement learning (RL) for scaling to high dimensions, enabling tractable
safety analysis even for implicit learning dynamics induced by state-of-the-art
prediction models. We demonstrate our framework's ability to work with both
Bayesian belief propagation and the implicit learning induced by a large
pre-trained neural trajectory predictor.
</p>
</div>
</dd>
<dt><a name="item275">[275]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01269" title="Abstract">arXiv:2309.01269</a> [<a href="/pdf/2309.01269" title="Download PDF">pdf</a>, <a href="/format/2309.01269" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Outlining the design space of eXplainable swarm (xSwarm): experts  perspective
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Naiseh%2C+M">Mohammad Naiseh</a>, 
<a href="/search/cs?searchtype=author&query=Soorati%2C+M+D">Mohammad D. Soorati</a>, 
<a href="/search/cs?searchtype=author&query=Ramchurn%2C+S">Sarvapali Ramchurn</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> In the 16th International Symposium on Distributed Autonomous Robotic Systems 2022, November 28-30, 2022, Montbeliard, France
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Computers and Society (cs.CY); Human-Computer Interaction (cs.HC)

</div>
<p class="mathjax">In swarm robotics, agents interact through local roles to solve complex tasks
beyond an individual's ability. Even though swarms are capable of carrying out
some operations without the need for human intervention, many safety-critical
applications still call for human operators to control and monitor the swarm.
There are novel challenges to effective Human-Swarm Interaction (HSI) that are
only beginning to be addressed. Explainability is one factor that can
facilitate effective and trustworthy HSI and improve the overall performance of
Human-Swarm team. Explainability was studied across various Human-AI domains,
such as Human-Robot Interaction and Human-Centered ML. However, it is still
ambiguous whether explanations studied in Human-AI literature would be
beneficial in Human-Swarm research and development. Furthermore, the literature
lacks foundational research on the prerequisites for explainability
requirements in swarm robotics, i.e., what kind of questions an explainable
swarm is expected to answer, and what types of explanations a swarm is expected
to generate. By surveying 26 swarm experts, we seek to answer these questions
and identify challenges experts faced to generate explanations in Human-Swarm
environments. Our work contributes insights into defining a new area of
research of eXplainable Swarm (xSwarm) which looks at how explainability can be
implemented and developed in swarm systems. This paper opens the discussion on
xSwarm and paves the way for more research in the field.
</p>
</div>
</dd>
<dt><a name="item276">[276]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01270" title="Abstract">arXiv:2309.01270</a> [<a href="/pdf/2309.01270" title="Download PDF">pdf</a>, <a href="/format/2309.01270" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> COMEDIAN: Self-Supervised Learning and Knowledge Distillation for Action  Spotting using Transformers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Denize%2C+J">Julien Denize</a>, 
<a href="/search/cs?searchtype=author&query=Liashuha%2C+M">Mykola Liashuha</a>, 
<a href="/search/cs?searchtype=author&query=Rabarisoa%2C+J">Jaonary Rabarisoa</a>, 
<a href="/search/cs?searchtype=author&query=Orcesi%2C+A">Astrid Orcesi</a>, 
<a href="/search/cs?searchtype=author&query=H%C3%A9rault%2C+R">Romain H&#xe9;rault</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Source code is available here: <a href="https://github.com/juliendenize/eztorch">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">We present COMEDIAN, a novel pipeline to initialize spatio-temporal
transformers for action spotting, which involves self-supervised learning and
knowledge distillation. Action spotting is a timestamp-level temporal action
detection task. Our pipeline consists of three steps, with two initialization
stages. First, we perform self-supervised initialization of a spatial
transformer using short videos as input. Additionally, we initialize a temporal
transformer that enhances the spatial transformer's outputs with global context
through knowledge distillation from a pre-computed feature bank aligned with
each short video segment. In the final step, we fine-tune the transformers to
the action spotting task. The experiments, conducted on the SoccerNet-v2
dataset, demonstrate state-of-the-art performance and validate the
effectiveness of COMEDIAN's pretraining paradigm. Our results highlight several
advantages of our pretraining pipeline, including improved performance and
faster convergence compared to non-pretrained models.
</p>
</div>
</dd>
<dt><a name="item277">[277]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01273" title="Abstract">arXiv:2309.01273</a> [<a href="/pdf/2309.01273" title="Download PDF">pdf</a>, <a href="/format/2309.01273" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> WindMill: A Parameterized and Pluggable CGRA Implemented by DIAG Design  Flow
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hui%2C+H">Haojia Hui</a>, 
<a href="/search/cs?searchtype=author&query=Gu%2C+J">Jiangyuan Gu</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+X">Xunbo Hu</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+Y">Yang Hu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+L">Leibo Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+S">Shaojun Wei</a>, 
<a href="/search/cs?searchtype=author&query=Yin%2C+S">Shouyi Yin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, 10 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Hardware Architecture (cs.AR)</span>; Systems and Control (eess.SY)

</div>
<p class="mathjax">With the cross-fertilization of applications and the ever-increasing scale of
models, the efficiency and productivity of hardware computing architectures
have become inadequate. This inadequacy further exacerbates issues in design
flexibility, design complexity, development cycle, and development costs (4-d
problems) in divergent scenarios. To address these challenges, this paper
proposed a flexible design flow called DIAG based on plugin techniques. The
proposed flow guides hardware development through four layers: definition(D),
implementation(I), application(A), and generation(G). Furthermore, a versatile
CGRA generator called WindMill is implemented, allowing for agile generation of
customized hardware accelerators based on specific application demands.
Applications and algorithm tasks from three aspects is experimented. In the
case of reinforcement learning algorithm, a significant performance improvement
of $2.3\times$ compared to GPU is achieved.
</p>
</div>
</dd>
<dt><a name="item278">[278]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01274" title="Abstract">arXiv:2309.01274</a> [<a href="/pdf/2309.01274" title="Download PDF">pdf</a>, <a href="/format/2309.01274" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Diffusion Models with Deterministic Normalizing Flow Priors
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zand%2C+M">Mohsen Zand</a>, 
<a href="/search/cs?searchtype=author&query=Etemad%2C+A">Ali Etemad</a>, 
<a href="/search/cs?searchtype=author&query=Greenspan%2C+M">Michael Greenspan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 7 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">For faster sampling and higher sample quality, we propose DiNof
($\textbf{Di}$ffusion with $\textbf{No}$rmalizing $\textbf{f}$low priors), a
technique that makes use of normalizing flows and diffusion models. We use
normalizing flows to parameterize the noisy data at any arbitrary step of the
diffusion process and utilize it as the prior in the reverse diffusion process.
More specifically, the forward noising process turns a data distribution into
partially noisy data, which are subsequently transformed into a Gaussian
distribution by a nonlinear process. The backward denoising procedure begins
with a prior created by sampling from the Gaussian distribution and applying
the invertible normalizing flow transformations deterministically. To generate
the data distribution, the prior then undergoes the remaining diffusion
stochastic denoising procedure. Through the reduction of the number of total
diffusion steps, we are able to speed up both the forward and backward
processes. More importantly, we improve the expressive power of diffusion
models by employing both deterministic and stochastic mappings. Experiments on
standard image generation datasets demonstrate the advantage of the proposed
method over existing approaches. On the unconditional CIFAR10 dataset, for
example, we achieve an FID of 2.01 and an Inception score of 9.96. Our method
also demonstrates competitive performance on CelebA-HQ-256 dataset as it
obtains an FID score of 7.11. Code is available at
https://github.com/MohsenZand/DiNof.
</p>
</div>
</dd>
<dt><a name="item279">[279]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01275" title="Abstract">arXiv:2309.01275</a> [<a href="/pdf/2309.01275" title="Download PDF">pdf</a>, <a href="/format/2309.01275" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Comparative Evaluation of FedAvg and Per-FedAvg Algorithms for  Dirichlet Distributed Heterogeneous Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Reguieg%2C+H">Hamza Reguieg</a>, 
<a href="/search/cs?searchtype=author&query=Hanjri%2C+M+E">Mohammed El Hanjri</a>, 
<a href="/search/cs?searchtype=author&query=Kamili%2C+M+E">Mohamed El Kamili</a>, 
<a href="/search/cs?searchtype=author&query=Kobbane%2C+A">Abdellatif Kobbane</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages, 5 figures, conference
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Probability (math.PR)

</div>
<p class="mathjax">In this paper, we investigate Federated Learning (FL), a paradigm of machine
learning that allows for decentralized model training on devices without
sharing raw data, there by preserving data privacy. In particular, we compare
two strategies within this paradigm: Federated Averaging (FedAvg) and
Personalized Federated Averaging (Per-FedAvg), focusing on their performance
with Non-Identically and Independently Distributed (Non-IID) data. Our analysis
shows that the level of data heterogeneity, modeled using a Dirichlet
distribution, significantly affects the performance of both strategies, with
Per-FedAvg showing superior robustness in conditions of high heterogeneity. Our
results provide insights into the development of more effective and efficient
machine learning strategies in a decentralized setting.
</p>
</div>
</dd>
<dt><a name="item280">[280]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01276" title="Abstract">arXiv:2309.01276</a> [<a href="/pdf/2309.01276" title="Download PDF">pdf</a>, <a href="/format/2309.01276" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Verifying the Unknown: Correct-by-Design Control Synthesis for Networks  of Stochastic Uncertain Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Sch%C3%B6n%2C+O">Oliver Sch&#xf6;n</a>, 
<a href="/search/eess?searchtype=author&query=van+Huijgevoort%2C+B">Birgit van Huijgevoort</a>, 
<a href="/search/eess?searchtype=author&query=Haesaert%2C+S">Sofie Haesaert</a>, 
<a href="/search/eess?searchtype=author&query=Soudjani%2C+S">Sadegh Soudjani</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages, 4 figures, accepted to CDC 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Logic in Computer Science (cs.LO); Symbolic Computation (cs.SC)

</div>
<p class="mathjax">In this paper, we present an approach for designing correct-by-design
controllers for cyber-physical systems composed of multiple dynamically
interconnected uncertain systems. We consider networked discrete-time uncertain
nonlinear systems with additive stochastic noise and model parametric
uncertainty. Such settings arise when multiple systems interact in an uncertain
environment and only observational data is available. We address two
limitations of existing approaches for formal synthesis of controllers for
networks of uncertain systems satisfying complex temporal specifications.
Firstly, whilst existing approaches rely on the stochasticity to be Gaussian,
the heterogeneous nature of composed systems typically yields a more complex
stochastic behavior. Secondly, exact models of the systems involved are
generally not available or difficult to acquire. To address these challenges,
we show how abstraction-based control synthesis for uncertain systems based on
sub-probability couplings can be extended to networked systems. We design
controllers based on parameter uncertainty sets identified from observational
data and approximate possibly arbitrary noise distributions using Gaussian
mixture models whilst quantifying the incurred stochastic coupling. Finally, we
demonstrate the effectiveness of our approach on a nonlinear package delivery
case study with a complex specification, and a platoon of cars.
</p>
</div>
</dd>
<dt><a name="item281">[281]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01278" title="Abstract">arXiv:2309.01278</a> [<a href="/pdf/2309.01278" title="Download PDF">pdf</a>, <a href="/format/2309.01278" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Under-frequency Load Shedding for Power Reserve Management in Islanded  Microgrids
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Xu%2C+B">Bei Xu</a>, 
<a href="/search/eess?searchtype=author&query=Paduani%2C+V">Victor Paduani</a>, 
<a href="/search/eess?searchtype=author&query=Xiao%2C+Q">Qi Xiao</a>, 
<a href="/search/eess?searchtype=author&query=Song%2C+L">Lidong Song</a>, 
<a href="/search/eess?searchtype=author&query=Lubkeman%2C+D">David Lubkeman</a>, 
<a href="/search/eess?searchtype=author&query=Lu%2C+N">Ning Lu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages, 15 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">This paper introduces under-frequency load shedding (UFLS) schemes specially
designed to fulfill the power reserve requirements in islanded microgrids,
where only one grid-forming resource is available for frequency regulation.
When the power consumption of the microgrid exceeds a pre-defined threshold,
the microgrid frequency will be lowered to various setpoints, thereby
triggering UFLS for different levels of load reduction. Three types of
controllable devices are considered for executing UFLS: sectionalizers, smart
meters, and controllable appliances. To avoid unnecessary UFLS activation,
various time delay settings are analyzed, allowing short-lived power spikes
caused by events like motor startups or cold-load pickups to be disregarded. We
tested the proposed UFLS schemes on a modified IEEE 123-bus system on the
OPAL-RT eMEGASIM platform. Simulation results verify the efficacy of the
proposed approaches in restoring power reserves, maintaining phase power
balance, and effectively handling short-lived power fluctuations. Furthermore,
in comparison to sectionalizer-based UFLS, using smart meters or controllable
loads for UFLS allows for a more accurate per-phase load shedding in a
progressive manner. As a result, it leads to better balanced three-phase
voltage and serves more loads.
</p>
</div>
</dd>
<dt><a name="item282">[282]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01279" title="Abstract">arXiv:2309.01279</a> [<a href="/pdf/2309.01279" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FOR-instance: a UAV laser scanning benchmark dataset for semantic and  instance segmentation of individual trees
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Puliti%2C+S">Stefano Puliti</a>, 
<a href="/search/cs?searchtype=author&query=Pearse%2C+G">Grant Pearse</a>, 
<a href="/search/cs?searchtype=author&query=Surov%C3%BD%2C+P">Peter Surov&#xfd;</a>, 
<a href="/search/cs?searchtype=author&query=Wallace%2C+L">Luke Wallace</a>, 
<a href="/search/cs?searchtype=author&query=Hollaus%2C+M">Markus Hollaus</a>, 
<a href="/search/cs?searchtype=author&query=Wielgosz%2C+M">Maciej Wielgosz</a>, 
<a href="/search/cs?searchtype=author&query=Astrup%2C+R">Rasmus Astrup</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">The FOR-instance dataset (available at
https://doi.org/10.5281/zenodo.8287792) addresses the challenge of accurate
individual tree segmentation from laser scanning data, crucial for
understanding forest ecosystems and sustainable management. Despite the growing
need for detailed tree data, automating segmentation and tracking scientific
progress remains difficult. Existing methodologies often overfit small datasets
and lack comparability, limiting their applicability. Amid the progress
triggered by the emergence of deep learning methodologies, standardized
benchmarking assumes paramount importance in these research domains. This data
paper introduces a benchmarking dataset for dense airborne laser scanning data,
aimed at advancing instance and semantic segmentation techniques and promoting
progress in 3D forest scene segmentation. The FOR-instance dataset comprises
five curated and ML-ready UAV-based laser scanning data collections from
diverse global locations, representing various forest types. The laser scanning
data were manually annotated into individual trees (instances) and different
semantic classes (e.g. stem, woody branches, live branches, terrain, low
vegetation). The dataset is divided into development and test subsets, enabling
method advancement and evaluation, with specific guidelines for utilization. It
supports instance and semantic segmentation, offering adaptability to deep
learning frameworks and diverse segmentation strategies, while the inclusion of
diameter at breast height data expands its utility to the measurement of a
classic tree variable. In conclusion, the FOR-instance dataset contributes to
filling a gap in the 3D forest research, enhancing the development and
benchmarking of segmentation algorithms for dense airborne laser scanning data.
</p>
</div>
</dd>
<dt><a name="item283">[283]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01281" title="Abstract">arXiv:2309.01281</a> [<a href="/pdf/2309.01281" title="Download PDF">pdf</a>, <a href="/format/2309.01281" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Game Theory in Distributed Systems Security: Foundations, Challenges,  and Future Directions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Abdallah%2C+M">Mustafa Abdallah</a>, 
<a href="/search/cs?searchtype=author&query=Bagchi%2C+S">Saurabh Bagchi</a>, 
<a href="/search/cs?searchtype=author&query=Bopardikar%2C+S+D">Shaunak D. Bopardikar</a>, 
<a href="/search/cs?searchtype=author&query=Chan%2C+K">Kevin Chan</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+X">Xing Gao</a>, 
<a href="/search/cs?searchtype=author&query=Kantarcioglu%2C+M">Murat Kantarcioglu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+C">Congmiao Li</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+P">Peng Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+Q">Quanyan Zhu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages in IEEE Computer Society magazine format, including references and author bios. There is 1 figure
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Distributed, Parallel, and Cluster Computing (cs.DC); Computer Science and Game Theory (cs.GT)

</div>
<p class="mathjax">Many of our critical infrastructure systems and personal computing systems
have a distributed computing systems structure. The incentives to attack them
have been growing rapidly as has their attack surface due to increasing levels
of connectedness. Therefore, we feel it is time to bring in rigorous reasoning
to secure such systems. The distributed system security and the game theory
technical communities can come together to effectively address this challenge.
In this article, we lay out the foundations from each that we can build upon to
achieve our goals. Next, we describe a set of research challenges for the
community, organized into three categories -- analytical, systems, and
integration challenges, each with "short term" time horizon (2-3 years) and
"long term" (5-10 years) items. This article was conceived of through a
community discussion at the 2022 NSF SaTC PI meeting.
</p>
</div>
</dd>
<dt><a name="item284">[284]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01286" title="Abstract">arXiv:2309.01286</a> [<a href="/pdf/2309.01286" title="Download PDF">pdf</a>, <a href="/format/2309.01286" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MAP: Domain Generalization via Meta-Learning on Anatomy-Consistent  Pseudo-Modalities
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hu%2C+D">Dewei Hu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Hao Li</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+H">Han Liu</a>, 
<a href="/search/cs?searchtype=author&query=Yao%2C+X">Xing Yao</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jiacheng Wang</a>, 
<a href="/search/cs?searchtype=author&query=Oguz%2C+I">Ipek Oguz</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Deep models suffer from limited generalization capability to unseen domains,
which has severely hindered their clinical applicability. Specifically for the
retinal vessel segmentation task, although the model is supposed to learn the
anatomy of the target, it can be distracted by confounding factors like
intensity and contrast. We propose Meta learning on Anatomy-consistent
Pseudo-modalities (MAP), a method that improves model generalizability by
learning structural features. We first leverage a feature extraction network to
generate three distinct pseudo-modalities that share the vessel structure of
the original image. Next, we use the episodic learning paradigm by selecting
one of the pseudo-modalities as the meta-train dataset, and perform
meta-testing on a continuous augmented image space generated through Dirichlet
mixup of the remaining pseudo-modalities. Further, we introduce two loss
functions that facilitate the model's focus on shape information by clustering
the latent vectors obtained from images featuring identical vasculature. We
evaluate our model on seven public datasets of various retinal imaging
modalities and we conclude that MAP has substantially better generalizability.
Our code is publically available at https://github.com/DeweiHu/MAP.
</p>
</div>
</dd>
<dt><a name="item285">[285]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01288" title="Abstract">arXiv:2309.01288</a> [<a href="/pdf/2309.01288" title="Download PDF">pdf</a>, <a href="/format/2309.01288" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> How Crowd Worker Factors Influence Subjective Annotations: A Study of  Tagging Misogynistic Hate Speech in Tweets
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hettiachchi%2C+D">Danula Hettiachchi</a>, 
<a href="/search/cs?searchtype=author&query=Holcombe-James%2C+I">Indigo Holcombe-James</a>, 
<a href="/search/cs?searchtype=author&query=Livingstone%2C+S">Stephanie Livingstone</a>, 
<a href="/search/cs?searchtype=author&query=de+Silva%2C+A">Anjalee de Silva</a>, 
<a href="/search/cs?searchtype=author&query=Lease%2C+M">Matthew Lease</a>, 
<a href="/search/cs?searchtype=author&query=Salim%2C+F+D">Flora D. Salim</a>, 
<a href="/search/cs?searchtype=author&query=Sanderson%2C+M">Mark Sanderson</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to the 11th AAAI Conference on Human Computation and Crowdsourcing (HCOMP 2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">Crowdsourced annotation is vital to both collecting labelled data to train
and test automated content moderation systems and to support human-in-the-loop
review of system decisions. However, annotation tasks such as judging hate
speech are subjective and thus highly sensitive to biases stemming from
annotator beliefs, characteristics and demographics. We conduct two
crowdsourcing studies on Mechanical Turk to examine annotator bias in labelling
sexist and misogynistic hate speech. Results from 109 annotators show that
annotator political inclination, moral integrity, personality traits, and
sexist attitudes significantly impact annotation accuracy and the tendency to
tag content as hate speech. In addition, semi-structured interviews with nine
crowd workers provide further insights regarding the influence of subjectivity
on annotations. In exploring how workers interpret a task - shaped by complex
negotiations between platform structures, task instructions, subjective
motivations, and external contextual factors - we see annotations not only
impacted by worker factors but also simultaneously shaped by the structures
under which they labour.
</p>
</div>
</dd>
<dt><a name="item286">[286]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01289" title="Abstract">arXiv:2309.01289</a> [<a href="/pdf/2309.01289" title="Download PDF">pdf</a>, <a href="/format/2309.01289" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Federated Orthogonal Training: Mitigating Global Catastrophic Forgetting  in Continual Federated Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bakman%2C+Y+F">Yavuz Faruk Bakman</a>, 
<a href="/search/cs?searchtype=author&query=Yaldiz%2C+D+N">Duygu Nur Yaldiz</a>, 
<a href="/search/cs?searchtype=author&query=Ezzeldin%2C+Y+H">Yahya H. Ezzeldin</a>, 
<a href="/search/cs?searchtype=author&query=Avestimehr%2C+S">Salman Avestimehr</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Federated Learning (FL) has gained significant attraction due to its ability
to enable privacy-preserving training over decentralized data. Current
literature in FL mostly focuses on single-task learning. However, over time,
new tasks may appear in the clients and the global model should learn these
tasks without forgetting previous tasks. This real-world scenario is known as
Continual Federated Learning (CFL). The main challenge of CFL is Global
Catastrophic Forgetting, which corresponds to the fact that when the global
model is trained on new tasks, its performance on old tasks decreases. There
have been a few recent works on CFL to propose methods that aim to address the
global catastrophic forgetting problem. However, these works either have
unrealistic assumptions on the availability of past data samples or violate the
privacy principles of FL. We propose a novel method, Federated Orthogonal
Training (FOT), to overcome these drawbacks and address the global catastrophic
forgetting in CFL. Our algorithm extracts the global input subspace of each
layer for old tasks and modifies the aggregated updates of new tasks such that
they are orthogonal to the global principal subspace of old tasks for each
layer. This decreases the interference between tasks, which is the main cause
for forgetting. We empirically show that FOT outperforms state-of-the-art
continual learning methods in the CFL setting, achieving an average accuracy
gain of up to 15% with 27% lower forgetting while only incurring a minimal
computation and communication cost.
</p>
</div>
</dd>
<dt><a name="item287">[287]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01291" title="Abstract">arXiv:2309.01291</a> [<a href="/pdf/2309.01291" title="Download PDF">pdf</a>, <a href="/format/2309.01291" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Generative Social Choice
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fish%2C+S">Sara Fish</a>, 
<a href="/search/cs?searchtype=author&query=G%C3%B6lz%2C+P">Paul G&#xf6;lz</a>, 
<a href="/search/cs?searchtype=author&query=Parkes%2C+D+C">David C. Parkes</a>, 
<a href="/search/cs?searchtype=author&query=Procaccia%2C+A+D">Ariel D. Procaccia</a>, 
<a href="/search/cs?searchtype=author&query=Rusak%2C+G">Gili Rusak</a>, 
<a href="/search/cs?searchtype=author&query=Shapira%2C+I">Itai Shapira</a>, 
<a href="/search/cs?searchtype=author&query=W%C3%BCthrich%2C+M">Manuel W&#xfc;thrich</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Traditionally, social choice theory has only been applicable to choices among
a few predetermined alternatives but not to more complex decisions such as
collectively selecting a textual statement. We introduce generative social
choice, a framework that combines the mathematical rigor of social choice
theory with large language models' capability to generate text and extrapolate
preferences. This framework divides the design of AI-augmented democratic
processes into two components: first, proving that the process satisfies
rigorous representation guarantees when given access to oracle queries; second,
empirically validating that these queries can be approximately implemented
using a large language model. We illustrate this framework by applying it to
the problem of generating a slate of statements that is representative of
opinions expressed as free-form text, for instance in an online deliberative
process.
</p>
</div>
</dd>
<dt><a name="item288">[288]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01293" title="Abstract">arXiv:2309.01293</a> [<a href="/pdf/2309.01293" title="Download PDF">pdf</a>, <a href="/format/2309.01293" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fortifying Public Safety: A Dynamic Role-Based Access Control Paradigm  for Cloud-Centric IoT
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mohseni-Ejiyeh%2C+A">Atefeh Mohseni-Ejiyeh</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">The evolution of communication technologies, exemplified by the Internet of
Things (IoT) and cloud computing, has significantly enhanced the speed and
accessibility of Public Safety (PS) services, critical to ensuring the safety
and security of our environment. However, these advancements also introduce
inherent security and privacy challenges. In response, this research presents a
novel and adaptable access control scheme tailored to PS services in
cloud-supported IoT environments. Our proposed access control protocol
leverages the strengths of Key Policy Attribute Based Encryption (KP-ABE) and
Identity-Based Broadcast Encryption (IDBB), combining them to establish a
robust security framework for cloud-supported IoT in the context of PS
services. Through the implementation of an Elliptic Curve Diffie-Hellman (ECDH)
scheme between entities, we ensure entity authentication, data confidentiality,
and integrity, addressing fundamental security requirements. A noteworthy
aspect of our lightweight protocol is the delegation of user private key
generation within the KP-ABE scheme to an untrusted cloud entity. This
strategic offloading of computational and communication overhead preserves data
privacy, as the cloud is precluded from accessing sensitive information. To
achieve this, we employ an IDBB scheme to generate secret private keys for
system users based on their roles, requiring the logical conjunction ('AND') of
user attributes to access data. This architecture effectively conceals user
identities from the cloud service provider. Comprehensive analysis validates
the efficacy of the proposed protocol, confirming its ability to ensure system
security and availability within acceptable parameters.
</p>
</div>
</dd>
<dt><a name="item289">[289]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01294" title="Abstract">arXiv:2309.01294</a> [<a href="/pdf/2309.01294" title="Download PDF">pdf</a>, <a href="/format/2309.01294" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AlphaZero Gomoku
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liang%2C+W">Wen Liang</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+C">Chao Yu</a>, 
<a href="/search/cs?searchtype=author&query=Whiteaker%2C+B">Brian Whiteaker</a>, 
<a href="/search/cs?searchtype=author&query=Huh%2C+I">Inyoung Huh</a>, 
<a href="/search/cs?searchtype=author&query=Shao%2C+H">Hua Shao</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+Y">Youzhi Liang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">In the past few years, AlphaZero's exceptional capability in mastering
intricate board games has garnered considerable interest. Initially designed
for the game of Go, this revolutionary algorithm merges deep learning
techniques with the Monte Carlo tree search (MCTS) to surpass earlier top-tier
methods. In our study, we broaden the use of AlphaZero to Gomoku, an age-old
tactical board game also referred to as "Five in a Row." Intriguingly, Gomoku
has innate challenges due to a bias towards the initial player, who has a
theoretical advantage. To add value, we strive for a balanced game-play. Our
tests demonstrate AlphaZero's versatility in adapting to games other than Go.
MCTS has become a predominant algorithm for decision processes in intricate
scenarios, especially board games. MCTS creates a search tree by examining
potential future actions and uses random sampling to predict possible results.
By leveraging the best of both worlds, the AlphaZero technique fuses deep
learning from Reinforcement Learning with the balancing act of MCTS,
establishing a fresh standard in game-playing AI. Its triumph is notably
evident in board games such as Go, chess, and shogi.
</p>
</div>
</dd>
<dt><a name="item290">[290]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01296" title="Abstract">arXiv:2309.01296</a> [<a href="/pdf/2309.01296" title="Download PDF">pdf</a>, <a href="/format/2309.01296" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> EMR-MSF: Self-Supervised Recurrent Monocular Scene Flow Exploiting  Ego-Motion Rigidity
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jiang%2C+Z">Zijie Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Okutomi%2C+M">Masatoshi Okutomi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To appear at ICCV 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Self-supervised monocular scene flow estimation, aiming to understand both 3D
structures and 3D motions from two temporally consecutive monocular images, has
received increasing attention for its simple and economical sensor setup.
However, the accuracy of current methods suffers from the bottleneck of
less-efficient network architecture and lack of motion rigidity for
regularization. In this paper, we propose a superior model named EMR-MSF by
borrowing the advantages of network architecture design under the scope of
supervised learning. We further impose explicit and robust geometric
constraints with an elaborately constructed ego-motion aggregation module where
a rigidity soft mask is proposed to filter out dynamic regions for stable
ego-motion estimation using static regions. Moreover, we propose a motion
consistency loss along with a mask regularization loss to fully exploit static
regions. Several efficient training strategies are integrated including a
gradient detachment technique and an enhanced view synthesis process for better
performance. Our proposed method outperforms the previous self-supervised works
by a large margin and catches up to the performance of supervised methods. On
the KITTI scene flow benchmark, our approach improves the SF-all metric of the
state-of-the-art self-supervised monocular method by 44% and demonstrates
superior performance across sub-tasks including depth and visual odometry,
amongst other self-supervised single-task or multi-task methods.
</p>
</div>
</dd>
<dt><a name="item291">[291]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01297" title="Abstract">arXiv:2309.01297</a> [<a href="/pdf/2309.01297" title="Download PDF">pdf</a>, <a href="/format/2309.01297" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Communication-Efficient Design of Learning System for Energy Demand  Forecasting of Electrical Vehicles
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+J">Jiacong Xu</a>, 
<a href="/search/cs?searchtype=author&query=Kilfoyle%2C+R">Riley Kilfoyle</a>, 
<a href="/search/cs?searchtype=author&query=Xiong%2C+Z">Zixiang Xiong</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+L">Ligang Lu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, 6 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">Machine learning (ML) applications to time series energy utilization
forecasting problems are a challenging assignment due to a variety of factors.
Chief among these is the non-homogeneity of the energy utilization datasets and
the geographical dispersion of energy consumers. Furthermore, these ML models
require vast amounts of training data and communications overhead in order to
develop an effective model. In this paper, we propose a communication-efficient
time series forecasting model combining the most recent advancements in
transformer architectures implemented across a geographically dispersed series
of EV charging stations and an efficient variant of federated learning (FL) to
enable distributed training. The time series prediction performance and
communication overhead cost of our FL are compared against their counterpart
models and shown to have parity in performance while consuming significantly
lower data rates during training. Additionally, the comparison is made across
EV charging as well as other time series datasets to demonstrate the
flexibility of our proposed model in generalized time series prediction beyond
energy demand. The source code for this work is available at
https://github.com/XuJiacong/LoGTST_PSGF
</p>
</div>
</dd>
<dt><a name="item292">[292]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01299" title="Abstract">arXiv:2309.01299</a> [<a href="/pdf/2309.01299" title="Download PDF">pdf</a>, <a href="/format/2309.01299" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Scalable Hierarchical Instruction Cache for Ultra-Low-Power Processors  Clusters
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Jie Chen</a>, 
<a href="/search/cs?searchtype=author&query=Loi%2C+I">Igor Loi</a>, 
<a href="/search/cs?searchtype=author&query=Flamand%2C+E">Eric Flamand</a>, 
<a href="/search/cs?searchtype=author&query=Tagliavini%2C+G">Giuseppe Tagliavini</a>, 
<a href="/search/cs?searchtype=author&query=Benini%2C+L">Luca Benini</a>, 
<a href="/search/cs?searchtype=author&query=Rossi%2C+D">Davide Rossi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> IEEE Transactions on Very Large Scale Integration (VLSI) Systems (
  Volume: 31, Issue: 4, April 2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Hardware Architecture (cs.AR)</span>

</div>
<p class="mathjax">High Performance and Energy Efficiency are critical requirements for Internet
of Things (IoT) end-nodes. Exploiting tightly-coupled clusters of programmable
processors (CMPs) has recently emerged as a suitable solution to address this
challenge. One of the main bottlenecks limiting the performance and energy
efficiency of these systems is the instruction cache architecture due to its
criticality in terms of timing (i.e., maximum operating frequency), bandwidth,
and power. We propose a hierarchical instruction cache tailored to
ultra-low-power tightly-coupled processor clusters where a relatively large
cache (L1.5) is shared by L1 private caches through a two-cycle latency
interconnect. To address the performance loss caused by the L1 capacity misses,
we introduce a next-line prefetcher with cache probe filtering (CPF) from L1 to
L1.5. We optimize the core instruction fetch (IF) stage by removing the
critical core-to-L1 combinational path. We present a detailed comparison of
instruction cache architectures' performance and energy efficiency for parallel
ultra-low-power (ULP) clusters. Focusing on the implementation, our two-level
instruction cache provides better scalability than existing shared caches,
delivering up to 20\% higher operating frequency. On average, the proposed
two-level cache improves maximum performance by up to 17\% compared to the
state-of-the-art while delivering similar energy efficiency for most relevant
applications.
</p>
</div>
</dd>
<dt><a name="item293">[293]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01302" title="Abstract">arXiv:2309.01302</a> [<a href="/pdf/2309.01302" title="Download PDF">pdf</a>, <a href="/ps/2309.01302" title="Download PostScript">ps</a>, <a href="/format/2309.01302" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Partial Proof of a Conjecture with Implications for Spectral  Majorization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Uhlmann%2C+J">Jeffrey Uhlmann</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Symbolic Computation (cs.SC)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">In this paper we report on new results relating to a conjecture regarding
properties of $n\times n$, $n\leq 6$, positive definite matrices. The
conjecture has been proven for $n\leq 4$ using computer-assisted sum of squares
(SoS) methods for proving polynomial nonnegativity. Based on these proven
cases, we report on the recent identification of a new family of matrices with
the property that their diagonals majorize their spectrum. We then present new
results showing that this family can extended via Kronecker composition to
$n&gt;6$ while retaining the special majorization property. We conclude with
general considerations on the future of computer-assisted and AI-based proofs.
</p>
</div>
</dd>
<dt><a name="item294">[294]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01310" title="Abstract">arXiv:2309.01310</a> [<a href="/pdf/2309.01310" title="Download PDF">pdf</a>, <a href="/format/2309.01310" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ExMobileViT: Lightweight Classifier Extension for Mobile Vision  Transformer
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+G">Gyeongdong Yang</a>, 
<a href="/search/cs?searchtype=author&query=Kwon%2C+Y">Yungwook Kwon</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+H">Hyunjin Kim</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Under Review
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">The paper proposes an efficient structure for enhancing the performance of
mobile-friendly vision transformer with small computational overhead. The
vision transformer (ViT) is very attractive in that it reaches outperforming
results in image classification, compared to conventional convolutional neural
networks (CNNs). Due to its need of high computational resources,
MobileNet-based ViT models such as MobileViT-S have been developed. However,
their performance cannot reach the original ViT model. The proposed structure
relieves the above weakness by storing the information from early attention
stages and reusing it in the final classifier. This paper is motivated by the
idea that the data itself from early attention stages can have important
meaning for the final classification. In order to reuse the early information
in attention stages, the average pooling results of various scaled features
from early attention stages are used to expand channels in the fully-connected
layer of the final classifier. It is expected that the inductive bias
introduced by the averaged features can enhance the final performance. Because
the proposed structure only needs the average pooling of features from the
attention stages and channel expansions in the final classifier, its
computational and storage overheads are very small, keeping the benefits of
low-cost MobileNet-based ViT (MobileViT). Compared with the original MobileViTs
on the ImageNet dataset, the proposed ExMobileViT has noticeable accuracy
enhancements, having only about 5% additional parameters.
</p>
</div>
</dd>
<dt><a name="item295">[295]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01314" title="Abstract">arXiv:2309.01314</a> [<a href="/pdf/2309.01314" title="Download PDF">pdf</a>, <a href="/format/2309.01314" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Model Review: a PROMISEing Opportunity
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Menzies%2C+T">Tim Menzies</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages, 1 figure
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
<p class="mathjax">In the past, humans have had difficulty accurately assessing complex models,
leading to unreliable and sometimes dangerous results. To reduce the cognitive
load on humans, large models must be simplified and summarized into smaller
ones. Data mining has proven to be an effective tool for finding useful,
concise models. Therefore, the PROMISE community has the necessary skills and
experience to redefine and simplify and improve the relationship between humans
and AI.
</p>
</div>
</dd>
<dt><a name="item296">[296]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01317" title="Abstract">arXiv:2309.01317</a> [<a href="/pdf/2309.01317" title="Download PDF">pdf</a>, <a href="/ps/2309.01317" title="Download PostScript">ps</a>, <a href="/format/2309.01317" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multirole Logic and Multiparty Channels
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xi%2C+H">Hongwei Xi</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+H">Hanwen Wu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: text overlap with <a href="/abs/1604.03020">arXiv:1604.03020</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Programming Languages (cs.PL)</span>; Distributed, Parallel, and Cluster Computing (cs.DC)

</div>
<p class="mathjax">We identify multirole logic as a new form of logic in which
conjunction/disjunction is interpreted as an ultrafilter on some underlying set
of roles and the notion of negation is generalized to endomorphisms on this
set. We formulate both multirole logic (MRL) and linear multirole logic (LMRL)
as natural generalizations of classical logic (CL) and classical linear logic
(CLL), respectively. Among various meta-properties established for MRL and
LMRL, we obtain one named multiparty cut-elimination stating that every cut
involving one or more sequents (as a generalization of a binary cut involving
exactly two sequents) can be eliminated, thus extending the celebrated result
of cut-elimination by Gentzen. As a side note, we also give an
ultrafilter-based interpretation for intuitionism, formulating MRLJ as a
natural generalization of intuitionistic logic (IL). An immediate application
of LMRL can be found in a formulation of session types for channels that
support multiparty communication in distributed programming. We present a
multi-threaded lambda-calculus (MTLC) where threads communicate on linearly
typed multiparty channels that are directly rooted in LMRL, establishing for
MTLC both type preservation and global progress. The primary contribution of
the paper consists of both identifying multirole logic as a new form of logic
and establishing a theoretical foundation for it, and the secondary
contribution lies in applying multirole logic to the practical domain of
distributed programming.
</p>
</div>
</dd>
<dt><a name="item297">[297]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01318" title="Abstract">arXiv:2309.01318</a> [<a href="/pdf/2309.01318" title="Download PDF">pdf</a>, <a href="/format/2309.01318" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An FPGA smart camera implementation of segmentation models for drone  wildfire imagery
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Guardu%C3%B1o-Martinez%2C+E">Eduardo Guardu&#xf1;o-Martinez</a>, 
<a href="/search/cs?searchtype=author&query=Ciprian-Sanchez%2C+J">Jorge Ciprian-Sanchez</a>, 
<a href="/search/cs?searchtype=author&query=Valente%2C+G">Gerardo Valente</a>, 
<a href="/search/cs?searchtype=author&query=Vazquez-Garcia">Vazquez-Garcia</a>, 
<a href="/search/cs?searchtype=author&query=Rodriguez-Hernandez%2C+G">Gerardo Rodriguez-Hernandez</a>, 
<a href="/search/cs?searchtype=author&query=Palacios-Rosas%2C+A">Adriana Palacios-Rosas</a>, 
<a href="/search/cs?searchtype=author&query=Rossi-Tisson%2C+L">Lucile Rossi-Tisson</a>, 
<a href="/search/cs?searchtype=author&query=Ochoa-Ruiz%2C+G">Gilberto Ochoa-Ruiz</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This paper has been accepted at the 22nd Mexican International Conference on Artificial Intelligence (MICAI 2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Image and Video Processing (eess.IV)

</div>
<p class="mathjax">Wildfires represent one of the most relevant natural disasters worldwide, due
to their impact on various societal and environmental levels. Thus, a
significant amount of research has been carried out to investigate and apply
computer vision techniques to address this problem. One of the most promising
approaches for wildfire fighting is the use of drones equipped with visible and
infrared cameras for the detection, monitoring, and fire spread assessment in a
remote manner but in close proximity to the affected areas. However,
implementing effective computer vision algorithms on board is often prohibitive
since deploying full-precision deep learning models running on GPU is not a
viable option, due to their high power consumption and the limited payload a
drone can handle. Thus, in this work, we posit that smart cameras, based on
low-power consumption field-programmable gate arrays (FPGAs), in tandem with
binarized neural networks (BNNs), represent a cost-effective alternative for
implementing onboard computing on the edge. Herein we present the
implementation of a segmentation model applied to the Corsican Fire Database.
We optimized an existing U-Net model for such a task and ported the model to an
edge device (a Xilinx Ultra96-v2 FPGA). By pruning and quantizing the original
model, we reduce the number of parameters by 90%. Furthermore, additional
optimizations enabled us to increase the throughput of the original model from
8 frames per second (FPS) to 33.63 FPS without loss in the segmentation
performance: our model obtained 0.912 in Matthews correlation coefficient
(MCC),0.915 in F1 score and 0.870 in Hafiane quality index (HAF), and
comparable qualitative segmentation results when contrasted to the original
full-precision model. The final model was integrated into a low-cost FPGA,
which was used to implement a neural network accelerator.
</p>
</div>
</dd>
<dt><a name="item298">[298]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01320" title="Abstract">arXiv:2309.01320</a> [<a href="/pdf/2309.01320" title="Download PDF">pdf</a>, <a href="/format/2309.01320" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Evaluation Mappings of Spatial Accelerator Based On Data Placement
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Wu%2C+Z">Zhipeng Wu</a>, 
<a href="/search/eess?searchtype=author&query=Liu%2C+Y">Yu Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages,8 figures,3 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">The scheduling strategies of workloads are critical to fully exploiting the
performance of spatial accelerators, accurate performance models are required
to evaluate the mapping of workloads.Recent works proposed various cost-model
to describe the dataflow of the spatial accelerator. However, they are less
expressive about customized memory hierarchies and thus lead to inaccurate
performance models. In this paper, we propose, PolyAcc, a framework for
evaluating the mappings of workload on spatial accelerator based on data
placement. The Data placement relation describes the temporal-spatial relation
of data at different memory levels, which can accurately capture the runtime
behavior of hardware units. Based on data placement relations, polyAcc
accurately analyzes the data volume for different reuse patterns and estimate
metrics, including data reuse, latency, and energy. Overall, polyAcc closely
matches the ideal execution time and PE utilization for GEMM and Conv
workloads, respectively achieves 0.82%, 18.8% improvements for execution time
and energy consumption estimates in validation against Eyeriss architecture
compared to the state-of-the-art framework.
</p>
</div>
</dd>
<dt><a name="item299">[299]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01321" title="Abstract">arXiv:2309.01321</a> [<a href="/pdf/2309.01321" title="Download PDF">pdf</a>, <a href="/format/2309.01321" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Joint Oscillation Damping and Inertia Provision Service for  Converter-Interfaced Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Feng%2C+C">Cheng Feng</a>, 
<a href="/search/eess?searchtype=author&query=Huang%2C+L">Linbin Huang</a>, 
<a href="/search/eess?searchtype=author&query=He%2C+X">Xiuqiang He</a>, 
<a href="/search/eess?searchtype=author&query=Wang%2C+Y">Yi Wang</a>, 
<a href="/search/eess?searchtype=author&query=D%C3%B6rfler%2C+F">Florian D&#xf6;rfler</a>, 
<a href="/search/eess?searchtype=author&query=Chen%2C+Q">Qixin Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted for IEEE PES journal for possible publications
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Optimization and Control (math.OC)

</div>
<p class="mathjax">As renewable generation becomes more prevalent, traditional power systems
dominated by synchronous generators are transitioning to systems dominated by
converter-interfaced generation. These devices, with their weaker damping
capabilities and lower inertia, compromise the system's ability to withstand
disturbances, pose a threat to system stability, and lead to oscillations and
poor frequency response performance. While some new converter-interfaced
generations are capable of providing superior damping and fast frequency
control, there is a lack of effective measures to incentivize manufacturers to
adopt them. To address this gap, this paper defines the joint oscillation
damping and inertia provision services at the system level, seeking to
encourage converter-interfaced generation to provide enhanced damping and fast
frequency response capabilities. Our approach is anchored in a novel convex
parametric formulation that combines oscillation mode and frequency stability
constraints. These constraints ensure a sufficient damping ratio for all
oscillation modes and maintain transient frequency trajectories within
acceptable limits. They are designed to integrate smoothly into various
operational and planning optimization frameworks. Using this formulation, we
introduce a joint service for oscillation damping and inertia provision based
on a cost-minimization problem. This facilitates the optimal allocation of
damping and virtual inertia to converters, achieving both small-signal
stability and frequency stability. Furthermore, we investigate the economic
effects of introducing this service into a new ancillary service market,
assessing its impact on system operations and cost-efficiency. Numerical tests
highlight the service's efficacy in ensuring both small-signal stability and
frequency stability, and offer insights into potential economic benefits.
</p>
</div>
</dd>
<dt><a name="item300">[300]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01324" title="Abstract">arXiv:2309.01324</a> [<a href="/pdf/2309.01324" title="Download PDF">pdf</a>, <a href="/format/2309.01324" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SKoPe3D: A Synthetic Dataset for Vehicle Keypoint Perception in 3D from  Traffic Monitoring Cameras
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pahadia%2C+H">Himanshu Pahadia</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+D">Duo Lu</a>, 
<a href="/search/cs?searchtype=author&query=Chakravarthi%2C+B">Bharatesh Chakravarthi</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yezhou Yang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to IEEE ITSC 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Intelligent transportation systems (ITS) have revolutionized modern road
infrastructure, providing essential functionalities such as traffic monitoring,
road safety assessment, congestion reduction, and law enforcement. Effective
vehicle detection and accurate vehicle pose estimation are crucial for ITS,
particularly using monocular cameras installed on the road infrastructure. One
fundamental challenge in vision-based vehicle monitoring is keypoint detection,
which involves identifying and localizing specific points on vehicles (such as
headlights, wheels, taillights, etc.). However, this task is complicated by
vehicle model and shape variations, occlusion, weather, and lighting
conditions. Furthermore, existing traffic perception datasets for keypoint
detection predominantly focus on frontal views from ego vehicle-mounted
sensors, limiting their usability in traffic monitoring. To address these
issues, we propose SKoPe3D, a unique synthetic vehicle keypoint dataset
generated using the CARLA simulator from a roadside perspective. This
comprehensive dataset includes generated images with bounding boxes, tracking
IDs, and 33 keypoints for each vehicle. Spanning over 25k images across 28
scenes, SKoPe3D contains over 150k vehicle instances and 4.9 million keypoints.
To demonstrate its utility, we trained a keypoint R-CNN model on our dataset as
a baseline and conducted a thorough evaluation. Our experiments highlight the
dataset's applicability and the potential for knowledge transfer between
synthetic and real-world data. By leveraging the SKoPe3D dataset, researchers
and practitioners can overcome the limitations of existing datasets, enabling
advancements in vehicle keypoint detection for ITS.
</p>
</div>
</dd>
<dt><a name="item301">[301]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01327" title="Abstract">arXiv:2309.01327</a> [<a href="/pdf/2309.01327" title="Download PDF">pdf</a>, <a href="/format/2309.01327" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Can I Trust Your Answer? Visually Grounded Video Question Answering
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xiao%2C+J">Junbin Xiao</a>, 
<a href="/search/cs?searchtype=author&query=Yao%2C+A">Angela Yao</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yicong Li</a>, 
<a href="/search/cs?searchtype=author&query=Chua%2C+T+S">Tat Seng Chua</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Preprint. Data and code: <a href="https://github.com/doc-doc/NExT-GQA">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Multimedia (cs.MM)

</div>
<p class="mathjax">We study visually grounded VideoQA in response to the emerging trends of
utilizing pretraining techniques for video-language understanding.
Specifically, by forcing vision-language models (VLMs) to answer questions and
simultaneously provide visual evidence, we seek to ascertain the extent to
which the predictions of such techniques are genuinely anchored in relevant
video content, versus spurious correlations from language or irrelevant visual
context. Towards this, we construct NExT-GQA -- an extension of NExT-QA with
10.5$K$ temporal grounding (or location) labels tied to the original QA pairs.
With NExT-GQA, we scrutinize a variety of state-of-the-art VLMs. Through
post-hoc attention analysis, we find that these models are weak in
substantiating the answers despite their strong QA performance. This exposes a
severe limitation of these models in making reliable predictions. As a remedy,
we further explore and suggest a video grounding mechanism via Gaussian mask
optimization and cross-modal learning. Experiments with different backbones
demonstrate that this grounding mechanism improves both video grounding and QA.
Our dataset and code are released. With these efforts, we aim to push towards
the reliability of deploying VLMs in VQA systems.
</p>
</div>
</dd>
<dt><a name="item302">[302]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01328" title="Abstract">arXiv:2309.01328</a> [<a href="/pdf/2309.01328" title="Download PDF">pdf</a>, <a href="/ps/2309.01328" title="Download PostScript">ps</a>, <a href="/format/2309.01328" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Restoration Guarantee of Image Inpainting via Low Rank Patch Matrix  Completion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cai%2C+J">Jian-Feng Cai</a>, 
<a href="/search/cs?searchtype=author&query=Choi%2C+J+K">Jae Kyu Choi</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jingyang Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>

</div>
<p class="mathjax">In recent years, patch-based image restoration approaches have demonstrated
superior performance compared to conventional variational methods. This paper
delves into the mathematical foundations underlying patch-based image
restoration methods, with a specific focus on establishing restoration
guarantees for patch-based image inpainting, leveraging the assumption of
self-similarity among patches. To accomplish this, we present a reformulation
of the image inpainting problem as structured low-rank matrix completion,
accomplished by grouping image patches with potential overlaps. By making
certain incoherence assumptions, we establish a restoration guarantee, given
that the number of samples exceeds the order of $rlog^2(N)$, where $N\times N$
denotes the size of the image and $r &gt; 0$ represents the sum of ranks for each
group of image patches. Through our rigorous mathematical analysis, we provide
valuable insights into the theoretical foundations of patch-based image
restoration methods, shedding light on their efficacy and offering guidelines
for practical implementation.
</p>
</div>
</dd>
<dt><a name="item303">[303]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01331" title="Abstract">arXiv:2309.01331</a> [<a href="/pdf/2309.01331" title="Download PDF">pdf</a>, <a href="/format/2309.01331" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Semantic-Constraint Matching Transformer for Weakly Supervised Object  Localization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cao%2C+Y">Yiwen Cao</a>, 
<a href="/search/cs?searchtype=author&query=Su%2C+Y">Yukun Su</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+W">Wenjun Wang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yanxia Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Q">Qingyao Wu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Weakly supervised object localization (WSOL) strives to learn to localize
objects with only image-level supervision. Due to the local receptive fields
generated by convolution operations, previous CNN-based methods suffer from
partial activation issues, concentrating on the object's discriminative part
instead of the entire entity scope. Benefiting from the capability of the
self-attention mechanism to acquire long-range feature dependencies, Vision
Transformer has been recently applied to alleviate the local activation
drawbacks. However, since the transformer lacks the inductive localization bias
that are inherent in CNNs, it may cause a divergent activation problem
resulting in an uncertain distinction between foreground and background. In
this work, we proposed a novel Semantic-Constraint Matching Network (SCMN) via
a transformer to converge on the divergent activation. Specifically, we first
propose a local patch shuffle strategy to construct the image pairs, disrupting
local patches while guaranteeing global consistency. The paired images that
contain the common object in spatial are then fed into the Siamese network
encoder. We further design a semantic-constraint matching module, which aims to
mine the co-object part by matching the coarse class activation maps (CAMs)
extracted from the pair images, thus implicitly guiding and calibrating the
transformer network to alleviate the divergent activation. Extensive
experimental results conducted on two challenging benchmarks, including
CUB-200-2011 and ILSVRC datasets show that our method can achieve the new
state-of-the-art performance and outperform the previous method by a large
margin.
</p>
</div>
</dd>
<dt><a name="item304">[304]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01332" title="Abstract">arXiv:2309.01332</a> [<a href="/pdf/2309.01332" title="Download PDF">pdf</a>, <a href="/format/2309.01332" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Synchro: Block-generation Protocol to Synchronously Process Cross-shard  Transactions in State Sharding
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Asanuma%2C+T">Takaki Asanuma</a>, 
<a href="/search/cs?searchtype=author&query=Miyamae%2C+T">Takeshi Miyamae</a>, 
<a href="/search/cs?searchtype=author&query=Yamaoka%2C+Y">Yuji Yamaoka</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">Traditional blockchains cannot achieve the same transaction throughput as
Web2, so their use cases are limited. Therefore, state sharding has been
proposed to improve transaction throughput by dividing the blockchain network
and managing states and transactions in parallel. However, Nightshade in the
NEAR Protocol, a type of state sharding, provides a rollback protocol to cancel
the generation of blocks containing inconsistent transaction results because
processing cross-shard transactions (CSTXs) in a 2-phase commit may cause state
inconsistency. We present a new attack that interferes with the generation of
new blocks by repeatedly executing CSTXs that certainly causes state
inconsistency, causing continuous rollback. We also propose a block-generation
protocol called Synchro to incorporate all the state changes of each CSTX into
the same block by coordinating the block prior to approving transactions in
each shard. Synchro eliminates the occurrence of the state inconsistency caused
by the CSTXs and the necessity of the rollback protocol. We use zero-knowledge
proof to make Synchro scalable in the global validation phase. Although the
actual overhead of the zero-knowledge proof has not yet been evaluated, we show
that Synchro could achieve the same transaction throughput as Nightshade
theoretically, depending on the future innovations in zero-knowledge proof
techniques.
</p>
</div>
</dd>
<dt><a name="item305">[305]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01335" title="Abstract">arXiv:2309.01335</a> [<a href="/pdf/2309.01335" title="Download PDF">pdf</a>, <a href="/format/2309.01335" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> In-processing User Constrained Dominant Sets for User-Oriented Fairness  in Recommender Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Han%2C+Z">Zhongxuan Han</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+C">Chaochao Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+X">Xiaolin Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+W">Weiming Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jun Wang</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+W">Wenjie Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yuyuan Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Computers and Society (cs.CY); Machine Learning (cs.LG)

</div>
<p class="mathjax">Recommender systems are typically biased toward a small group of users,
leading to severe unfairness in recommendation performance, i.e., User-Oriented
Fairness (UOF) issue. The existing research on UOF is limited and fails to deal
with the root cause of the UOF issue: the learning process between advantaged
and disadvantaged users is unfair. To tackle this issue, we propose an
In-processing User Constrained Dominant Sets (In-UCDS) framework, which is a
general framework that can be applied to any backbone recommendation model to
achieve user-oriented fairness. We split In-UCDS into two stages, i.e., the
UCDS modeling stage and the in-processing training stage. In the UCDS modeling
stage, for each disadvantaged user, we extract a constrained dominant set (a
user cluster) containing some advantaged users that are similar to it. In the
in-processing training stage, we move the representations of disadvantaged
users closer to their corresponding cluster by calculating a fairness loss. By
combining the fairness loss with the original backbone model loss, we address
the UOF issue and maintain the overall recommendation performance
simultaneously. Comprehensive experiments on three real-world datasets
demonstrate that In-UCDS outperforms the state-of-the-art methods, leading to a
fairer model with better overall recommendation performance.
</p>
</div>
</dd>
<dt><a name="item306">[306]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01336" title="Abstract">arXiv:2309.01336</a> [<a href="/pdf/2309.01336" title="Download PDF">pdf</a>, <a href="/format/2309.01336" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning for Interval Prediction of Electricity Demand: A Cluster-based  Bootstrapping Approach
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dube%2C+R">Rohit Dube</a>, 
<a href="/search/cs?searchtype=author&query=Gautam%2C+N">Natarajan Gautam</a>, 
<a href="/search/cs?searchtype=author&query=Banerjee%2C+A">Amarnath Banerjee</a>, 
<a href="/search/cs?searchtype=author&query=Nagarajan%2C+H">Harsha Nagarajan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Accurate predictions of electricity demands are necessary for managing
operations in a small aggregation load setting like a Microgrid. Due to low
aggregation, the electricity demands can be highly stochastic and point
estimates would lead to inflated errors. Interval estimation in this scenario,
would provide a range of values within which the future values might lie and
helps quantify the errors around the point estimates. This paper introduces a
residual bootstrap algorithm to generate interval estimates of day-ahead
electricity demand. A machine learning algorithm is used to obtain the point
estimates of electricity demand and respective residuals on the training set.
The obtained residuals are stored in memory and the memory is further
partitioned. Days with similar demand patterns are grouped in clusters using an
unsupervised learning algorithm and these clusters are used to partition the
memory. The point estimates for test day are used to find the closest cluster
of similar days and the residuals are bootstrapped from the chosen cluster.
This algorithm is evaluated on the real electricity demand data from EULR(End
Use Load Research) and is compared to other bootstrapping methods for varying
confidence intervals.
</p>
</div>
</dd>
<dt><a name="item307">[307]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01339" title="Abstract">arXiv:2309.01339</a> [<a href="/pdf/2309.01339" title="Download PDF">pdf</a>, <a href="/format/2309.01339" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> UniSA: Unified Generative Framework for Sentiment Analysis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zaijing Li</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+T">Ting-En Lin</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Y">Yuchuan Wu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+M">Meng Liu</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+F">Fengxiao Tang</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+M">Ming Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yongbin Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to ACM MM 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV); Multimedia (cs.MM)

</div>
<p class="mathjax">Sentiment analysis is a crucial task that aims to understand people's
emotional states and predict emotional categories based on multimodal
information. It consists of several subtasks, such as emotion recognition in
conversation (ERC), aspect-based sentiment analysis (ABSA), and multimodal
sentiment analysis (MSA). However, unifying all subtasks in sentiment analysis
presents numerous challenges, including modality alignment, unified
input/output forms, and dataset bias. To address these challenges, we propose a
Task-Specific Prompt method to jointly model subtasks and introduce a
multimodal generative framework called UniSA. Additionally, we organize the
benchmark datasets of main subtasks into a new Sentiment Analysis Evaluation
benchmark, SAEval. We design novel pre-training tasks and training methods to
enable the model to learn generic sentiment knowledge among subtasks to improve
the model's multimodal sentiment perception ability. Our experimental results
show that UniSA performs comparably to the state-of-the-art on all subtasks and
generalizes well to various subtasks in sentiment analysis.
</p>
</div>
</dd>
<dt><a name="item308">[308]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01340" title="Abstract">arXiv:2309.01340</a> [<a href="/pdf/2309.01340" title="Download PDF">pdf</a>, <a href="/format/2309.01340" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MDSC: Towards Evaluating the Style Consistency Between Music and
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Z">Zixiang Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+B">Baoyuan Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 17 pages, 17 figure
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Computer Vision and Pattern Recognition (cs.CV); Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">We propose MDSC(Music-Dance-Style Consistency), the first evaluation metric
which assesses to what degree the dance moves and music match. Existing metrics
can only evaluate the fidelity and diversity of motion and the degree of
rhythmic matching between music and motion. MDSC measures how stylistically
correlated the generated dance motion sequences and the conditioning music
sequences are. We found that directly measuring the embedding distance between
motion and music is not an optimal solution. We instead tackle this through
modelling it as a clustering problem. Specifically, 1) we pre-train a music
encoder and a motion encoder, then 2) we learn to map and align the motion and
music embedding in joint space by jointly minimizing the intra-cluster distance
and maximizing the inter-cluster distance, and 3) for evaluation purpose, we
encode the dance moves into embedding and measure the intra-cluster and
inter-cluster distances, as well as the ratio between them. We evaluate our
metric on the results of several music-conditioned motion generation methods,
combined with user study, we found that our proposed metric is a robust
evaluation metric in measuring the music-dance style correlation. The code is
available at: https://github.com/zixiangzhou916/MDSC.
</p>
</div>
</dd>
<dt><a name="item309">[309]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01342" title="Abstract">arXiv:2309.01342</a> [<a href="/pdf/2309.01342" title="Download PDF">pdf</a>, <a href="/format/2309.01342" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Adaptive Parametric Prototype Learning for Cross-Domain Few-Shot  Classification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Heidari%2C+M">Marzi Heidari</a>, 
<a href="/search/cs?searchtype=author&query=Alchihabi%2C+A">Abdullah Alchihabi</a>, 
<a href="/search/cs?searchtype=author&query=En%2C+Q">Qing En</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+Y">Yuhong Guo</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Cross-domain few-shot classification induces a much more challenging problem
than its in-domain counterpart due to the existence of domain shifts between
the training and test tasks. In this paper, we develop a novel Adaptive
Parametric Prototype Learning (APPL) method under the meta-learning convention
for cross-domain few-shot classification. Different from existing prototypical
few-shot methods that use the averages of support instances to calculate the
class prototypes, we propose to learn class prototypes from the concatenated
features of the support set in a parametric fashion and meta-learn the model by
enforcing prototype-based regularization on the query set. In addition, we
fine-tune the model in the target domain in a transductive manner using a
weighted-moving-average self-training approach on the query instances. We
conduct experiments on multiple cross-domain few-shot benchmark datasets. The
empirical results demonstrate that APPL yields superior performance than many
state-of-the-art cross-domain few-shot learning methods.
</p>
</div>
</dd>
<dt><a name="item310">[310]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01343" title="Abstract">arXiv:2309.01343</a> [<a href="/pdf/2309.01343" title="Download PDF">pdf</a>, <a href="/format/2309.01343" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Distributional Domain-Invariant Preference Matching for Cross-Domain  Recommendation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Du%2C+J">Jing Du</a>, 
<a href="/search/cs?searchtype=author&query=Ye%2C+Z">Zesheng Ye</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+B">Bin Guo</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+Z">Zhiwen Yu</a>, 
<a href="/search/cs?searchtype=author&query=Yao%2C+L">Lina Yao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages, 5 figures, full research paper accepted by ICDM 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>

</div>
<p class="mathjax">Learning accurate cross-domain preference mappings in the absence of
overlapped users/items has presented a persistent challenge in Non-overlapping
Cross-domain Recommendation (NOCDR). Despite the efforts made in previous
studies to address NOCDR, several limitations still exist. Specifically, 1)
while some approaches substitute overlapping users/items with overlapping
behaviors, they cannot handle NOCDR scenarios where such auxiliary information
is unavailable; 2) often, cross-domain preference mapping is modeled by
learning deterministic explicit representation matchings between sampled users
in two domains. However, this can be biased due to individual preferences and
thus fails to incorporate preference continuity and universality of the general
population. In light of this, we assume that despite the scattered nature of
user behaviors, there exists a consistent latent preference distribution shared
among common people. Modeling such distributions further allows us to capture
the continuity in user behaviors within each domain and discover preference
invariance across domains. To this end, we propose a Distributional
domain-invariant Preference Matching method for non-overlapping Cross-Domain
Recommendation (DPMCDR). For each domain, we hierarchically approximate a
posterior of domain-level preference distribution with empirical evidence
derived from user-item interactions. Next, we aim to build distributional
implicit matchings between the domain-level preferences of two domains. This
process involves mapping them to a shared latent space and seeking a consensus
on domain-invariant preference by minimizing the distance between their
distributional representations therein. In this way, we can identify the
alignment of two non-overlapping domains if they exhibit similar patterns of
domain-invariant preference.
</p>
</div>
</dd>
<dt><a name="item311">[311]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01346" title="Abstract">arXiv:2309.01346</a> [<a href="/pdf/2309.01346" title="Download PDF">pdf</a>, <a href="/format/2309.01346" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> White paper on LiDAR performance against selected Automotive Paints
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shung%2C+J+L+W">James Lee Wei Shung</a>, 
<a href="/search/cs?searchtype=author&query=Hibbard%2C+P">Paul Hibbard</a>, 
<a href="/search/cs?searchtype=author&query=Vijay%2C+R">Roshan Vijay</a>, 
<a href="/search/cs?searchtype=author&query=Kin%2C+L+A+H">Lincoln Ang Hon Kin</a>, 
<a href="/search/cs?searchtype=author&query=de+Boer%2C+N">Niels de Boer</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 23 pages, 29 figures. This white paper was developed with support from the Urban Mobility Grand Challenge Fund by the Land Transport Authority of Singapore (No. UMGC-L010). For associated dataset, see <a href="https://researchdata.ntu.edu.sg/dataset.xhtml?persistentId=doi:10.21979/N9/CGDKMZ">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">LiDAR (Light Detection and Ranging) is a useful sensing technique and an
important source of data for autonomous vehicles (AVs). In this publication we
present the results of a study undertaken to understand the impact of
automotive paint on LiDAR performance along with a methodology used to conduct
this study. Our approach consists of evaluating the average reflected intensity
output by different LiDAR sensor models when tested with different types of
automotive paints. The paints were chosen to represent common paints found on
vehicles in Singapore.
<br />The experiments were conducted with LiDAR sensors commonly used by autonomous
vehicle (AV) developers and OEMs. The paints used were also selected based on
those observed in real-world conditions. This stems from a desire to model
real-world performance of actual sensing systems when exposed to the physical
world. The goal is then to inform regulators of AVs in Singapore of the impact
of automotive paint on LiDAR performance, so that they can determine testing
standards and specifications which will better reflect real-world performance
and also better assess the adequacy of LiDAR systems installed for local AV
operations.
<br />The tests were conducted for a combination of 13 different paint panels and 3
LiDAR sensors. In general, it was observed that darker coloured paints have
lower reflection intensity whereas lighter coloured paints exhibited higher
intensity values.
</p>
</div>
</dd>
<dt><a name="item312">[312]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01350" title="Abstract">arXiv:2309.01350</a> [<a href="/pdf/2309.01350" title="Download PDF">pdf</a>, <a href="/format/2309.01350" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MalwareDNA: Simultaneous Classification of Malware, Malware Families,  and Novel Malware
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Eren%2C+M+E">Maksim E. Eren</a>, 
<a href="/search/cs?searchtype=author&query=Bhattarai%2C+M">Manish Bhattarai</a>, 
<a href="/search/cs?searchtype=author&query=Rasmussen%2C+K">Kim Rasmussen</a>, 
<a href="/search/cs?searchtype=author&query=Alexandrov%2C+B+S">Boian S. Alexandrov</a>, 
<a href="/search/cs?searchtype=author&query=Nicholas%2C+C">Charles Nicholas</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at IEEE ISI 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Malware is one of the most dangerous and costly cyber threats to national
security and a crucial factor in modern cyber-space. However, the adoption of
machine learning (ML) based solutions against malware threats has been
relatively slow. Shortcomings in the existing ML approaches are likely
contributing to this problem. The majority of current ML approaches ignore
real-world challenges such as the detection of novel malware. In addition,
proposed ML approaches are often designed either for malware/benign-ware
classification or malware family classification. Here we introduce and showcase
preliminary capabilities of a new method that can perform precise
identification of novel malware families, while also unifying the capability
for malware/benign-ware classification and malware family classification into a
single framework.
</p>
</div>
</dd>
<dt><a name="item313">[313]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01351" title="Abstract">arXiv:2309.01351</a> [<a href="/pdf/2309.01351" title="Download PDF">pdf</a>, <a href="/format/2309.01351" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Adv3D: Generating 3D Adversarial Examples in Driving Scenarios with NeRF
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+L">Leheng Li</a>, 
<a href="/search/cs?searchtype=author&query=Lian%2C+Q">Qing Lian</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Ying-Cong Chen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Deep neural networks (DNNs) have been proven extremely susceptible to
adversarial examples, which raises special safety-critical concerns for
DNN-based autonomous driving stacks (i.e., 3D object detection). Although there
are extensive works on image-level attacks, most are restricted to 2D pixel
spaces, and such attacks are not always physically realistic in our 3D world.
Here we present Adv3D, the first exploration of modeling adversarial examples
as Neural Radiance Fields (NeRFs). Advances in NeRF provide photorealistic
appearances and 3D accurate generation, yielding a more realistic and
realizable adversarial example. We train our adversarial NeRF by minimizing the
surrounding objects' confidence predicted by 3D detectors on the training set.
Then we evaluate Adv3D on the unseen validation set and show that it can cause
a large performance reduction when rendering NeRF in any sampled pose. To
generate physically realizable adversarial examples, we propose primitive-aware
sampling and semantic-guided regularization that enable 3D patch attacks with
camouflage adversarial texture. Experimental results demonstrate that the
trained adversarial NeRF generalizes well to different poses, scenes, and 3D
detectors. Finally, we provide a defense method to our attacks that involves
adversarial training through data augmentation. Project page:
https://len-li.github.io/adv3d-web
</p>
</div>
</dd>
<dt><a name="item314">[314]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01352" title="Abstract">arXiv:2309.01352</a> [<a href="/pdf/2309.01352" title="Download PDF">pdf</a>, <a href="/format/2309.01352" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Self-driven Grounding: Large Language Model Agents with Automatical  Language-aligned Skill Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Peng%2C+S">Shaohui Peng</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+X">Xing Hu</a>, 
<a href="/search/cs?searchtype=author&query=Yi%2C+Q">Qi Yi</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+R">Rui Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+J">Jiaming Guo</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+D">Di Huang</a>, 
<a href="/search/cs?searchtype=author&query=Tian%2C+Z">Zikang Tian</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+R">Ruizhi Chen</a>, 
<a href="/search/cs?searchtype=author&query=Du%2C+Z">Zidong Du</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+Q">Qi Guo</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yunji Chen</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+L">Ling Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Large language models (LLMs) show their powerful automatic reasoning and
planning capability with a wealth of semantic knowledge about the human world.
However, the grounding problem still hinders the applications of LLMs in the
real-world environment. Existing studies try to fine-tune the LLM or utilize
pre-defined behavior APIs to bridge the LLMs and the environment, which not
only costs huge human efforts to customize for every single task but also
weakens the generality strengths of LLMs. To autonomously ground the LLM onto
the environment, we proposed the Self-Driven Grounding (SDG) framework to
automatically and progressively ground the LLM with self-driven skill learning.
SDG first employs the LLM to propose the hypothesis of sub-goals to achieve
tasks and then verify the feasibility of the hypothesis via interacting with
the underlying environment. Once verified, SDG can then learn generalized
skills with the guidance of these successfully grounded subgoals. These skills
can be further utilized to accomplish more complex tasks which fail to pass the
verification phase. Verified in the famous instruction following task
set-BabyAI, SDG achieves comparable performance in the most challenging tasks
compared with imitation learning methods that cost millions of demonstrations,
proving the effectiveness of learned skills and showing the feasibility and
efficiency of our framework.
</p>
</div>
</dd>
<dt><a name="item315">[315]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01353" title="Abstract">arXiv:2309.01353</a> [<a href="/pdf/2309.01353" title="Download PDF">pdf</a>, <a href="/format/2309.01353" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Real-time pedestrian recognition on low computational resources
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Weng%2C+G">Guifan Weng</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Pedestrian recognition has successfully been applied to security, autonomous
cars, Aerial photographs. For most applications, pedestrian recognition on
small mobile devices is important. However, the limitations of the computing
hardware make this a challenging task. In this work, we investigate real-time
pedestrian recognition on small physical-size computers with low computational
resources for faster speed. This paper presents three methods that work on the
small physical size CPUs system. First, we improved the Local Binary Pattern
(LBP) features and Adaboost classifier. Second, we optimized the Histogram of
Oriented Gradients (HOG) and Support Vector Machine. Third, We implemented fast
Convolutional Neural Networks (CNNs). The results demonstrate that the three
methods achieved real-time pedestrian recognition at an accuracy of more than
95% and a speed of more than 5 fps on a small physical size computational
platform with a 1.8 GHz Intel i5 CPU. Our methods can be easily applied to
small mobile devices with high compatibility and generality.
</p>
</div>
</dd>
<dt><a name="item316">[316]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01356" title="Abstract">arXiv:2309.01356</a> [<a href="/pdf/2309.01356" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AZB Rectangle Shrinkage Method and Heterogeneous Computing Accelerated  Full Image Theory Method Ray Tracing Enabling Complex and Massive Outdoor 6G  Propagation Modeling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Kim%2C+Y">Yongwan Kim</a>, 
<a href="/search/math?searchtype=author&query=Yang%2C+H">Hyunjun Yang</a>, 
<a href="/search/math?searchtype=author&query=Oh%2C+J">Jungsuek Oh</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">Until now, despite their high accuracy, the utilization of the conventional
image theory method ray tracers was limited to simple simulation environments
with small number of field observation points and low maximum ray bouncing
order due to their poor computational efficiency. This study presents a novel
full-3D AZB rectangle shrinkage method and heterogeneous computing accelerated
image theory method ray tracing framework for complex and massive outdoor
propagation modeling. The proposed framework is divided into three parts: 1.
Visibility preprocessing part. 2. Visibility tree generation part: in this
part, a novel AZB rectangle shrinkage method that accelerates and reduces
generation speed and size of visibility tree is proposed. 3. Shadow testing and
field calculation part: in this part, a heterogeneous computing algorithm that
can make possible to handle a large amount of field observation points is
proposed. It is demonstrated that the proposed framework is faster more than
651 times than the image theory method solver of WinProp. Also, it is confirmed
that the proposed ray tracing framework can handle 1km x 1km wide and dense
urban outdoor simulation with up to the maximum ray bouncing order of 6 and
thousands of field observation points. The proposed ray tracing framework would
be a cornerstone of future image theory method ray tracing techniques for
complex and massive scenarios that was exclusive to the shooting and bouncing
rays method ray tracers.
</p>
</div>
</dd>
<dt><a name="item317">[317]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01357" title="Abstract">arXiv:2309.01357</a> [<a href="/pdf/2309.01357" title="Download PDF">pdf</a>, <a href="/format/2309.01357" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Adapting Classifiers To Changing Class Priors During Deployment
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Daba%2C+N">Natnael Daba</a>, 
<a href="/search/cs?searchtype=author&query=McIntosh%2C+B">Bruce McIntosh</a>, 
<a href="/search/cs?searchtype=author&query=Mahalanobis%2C+A">Abhijit Mahalanobis</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Conventional classifiers are trained and evaluated using balanced data sets
in which all classes are equally present. Classifiers are now trained on large
data sets such as ImageNet, and are now able to classify hundreds (if not
thousands) of different classes. On one hand, it is desirable to train such
general-purpose classifier on a very large number of classes so that it
performs well regardless of the settings in which it is deployed. On the other
hand, it is unlikely that all classes known to the classifier will occur in
every deployment scenario, or that they will occur with the same prior
probability. In reality, only a relatively small subset of the known classes
may be present in a particular setting or environment. For example, a
classifier will encounter mostly animals if its deployed in a zoo or for
monitoring wildlife, aircraft and service vehicles at an airport, or various
types of automobiles and commercial vehicles if it is used for monitoring
traffic. Furthermore, the exact class priors are generally unknown and can vary
over time. In this paper, we explore different methods for estimating the class
priors based on the output of the classifier itself. We then show that
incorporating the estimated class priors in the overall decision scheme enables
the classifier to increase its run-time accuracy in the context of its
deployment scenario.
</p>
</div>
</dd>
<dt><a name="item318">[318]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01360" title="Abstract">arXiv:2309.01360</a> [<a href="/pdf/2309.01360" title="Download PDF">pdf</a>, <a href="/ps/2309.01360" title="Download PostScript">ps</a>, <a href="/format/2309.01360" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Random Projections of Sparse Adjacency Matrices
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Qiu%2C+F">Frank Qiu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 21 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>; Machine Learning (cs.LG); Machine Learning (stat.ML)

</div>
<p class="mathjax">We analyze a random projection method for adjacency matrices, studying its
utility in representing sparse graphs. We show that these random projections
retain the functionality of their underlying adjacency matrices while having
extra properties that make them attractive as dynamic graph representations. In
particular, they can represent graphs of different sizes and vertex sets in the
same space, allowing for the aggregation and manipulation of graphs in a
unified manner. We also provide results on how the size of the projections need
to scale in order to preserve accurate graph operations, showing that the size
of the projections can scale linearly with the number of vertices while
accurately retaining first-order graph information. We conclude by
characterizing our random projection as a distance-preserving map of adjacency
matrices analogous to the usual Johnson-Lindenstrauss map.
</p>
</div>
</dd>
<dt><a name="item319">[319]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01361" title="Abstract">arXiv:2309.01361</a> [<a href="/pdf/2309.01361" title="Download PDF">pdf</a>, <a href="/format/2309.01361" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> High Frequency, High Accuracy Pointing onboard Nanosats using  Neuromorphic Event Sensing and Piezoelectric Actuation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Latif%2C+Y">Yasir Latif</a>, 
<a href="/search/cs?searchtype=author&query=Anastasiou%2C+P">Peter Anastasiou</a>, 
<a href="/search/cs?searchtype=author&query=Ng%2C+Y">Yonhon Ng</a>, 
<a href="/search/cs?searchtype=author&query=Prime%2C+Z">Zebb Prime</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+T">Tien-Fu Lu</a>, 
<a href="/search/cs?searchtype=author&query=Tetlow%2C+M">Matthew Tetlow</a>, 
<a href="/search/cs?searchtype=author&query=Mahony%2C+R">Robert Mahony</a>, 
<a href="/search/cs?searchtype=author&query=Chin%2C+T">Tat-Jun Chin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Emerging Technologies (cs.ET)</span>; Computer Vision and Pattern Recognition (cs.CV); Robotics (cs.RO)

</div>
<p class="mathjax">As satellites become smaller, the ability to maintain stable pointing
decreases as external forces acting on the satellite come into play. At the
same time, reaction wheels used in the attitude determination and control
system (ADCS) introduce high frequency jitter which can disrupt pointing
stability. For space domain awareness (SDA) tasks that track objects tens of
thousands of kilometres away, the pointing accuracy offered by current
nanosats, typically in the range of 10 to 100 arcseconds, is not sufficient. In
this work, we develop a novel payload that utilises a neuromorphic event sensor
(for high frequency and highly accurate relative attitude estimation) paired in
a closed loop with a piezoelectric stage (for active attitude corrections) to
provide highly stable sensor-specific pointing. Event sensors are especially
suited for space applications due to their desirable characteristics of low
power consumption, asynchronous operation, and high dynamic range. We use the
event sensor to first estimate a reference background star field from which
instantaneous relative attitude is estimated at high frequency. The
piezoelectric stage works in a closed control loop with the event sensor to
perform attitude corrections based on the discrepancy between the current and
desired attitude. Results in a controlled setting show that we can achieve a
pointing accuracy in the range of 1-5 arcseconds using our novel payload at an
operating frequency of up to 50Hz using a prototype built from
commercial-off-the-shelf components. Further details can be found at
https://ylatif.github.io/ultrafinestabilisation
</p>
</div>
</dd>
<dt><a name="item320">[320]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01365" title="Abstract">arXiv:2309.01365</a> [<a href="/pdf/2309.01365" title="Download PDF">pdf</a>, <a href="/format/2309.01365" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Refined Temporal Pyramidal Compression-and-Amplification Transformer for  3D Human Pose Estimation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Hanbing Li</a>, 
<a href="/search/cs?searchtype=author&query=Xiang%2C+W">Wangmeng Xiang</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+J">Jun-Yan He</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+Z">Zhi-Qi Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+B">Bin Luo</a>, 
<a href="/search/cs?searchtype=author&query=Geng%2C+Y">Yifeng Geng</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+X">Xuansong Xie</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages, 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Accurately estimating the 3D pose of humans in video sequences requires both
accuracy and a well-structured architecture. With the success of transformers,
we introduce the Refined Temporal Pyramidal Compression-and-Amplification
(RTPCA) transformer. Exploiting the temporal dimension, RTPCA extends
intra-block temporal modeling via its Temporal Pyramidal
Compression-and-Amplification (TPCA) structure and refines inter-block feature
interaction with a Cross-Layer Refinement (XLR) module. In particular, TPCA
block exploits a temporal pyramid paradigm, reinforcing key and value
representation capabilities and seamlessly extracting spatial semantics from
motion sequences. We stitch these TPCA blocks with XLR that promotes rich
semantic representation through continuous interaction of queries, keys, and
values. This strategy embodies early-stage information with current flows,
addressing typical deficits in detail and stability seen in other
transformer-based methods. We demonstrate the effectiveness of RTPCA by
achieving state-of-the-art results on Human3.6M, HumanEva-I, and MPI-INF-3DHP
benchmarks with minimal computational overhead. The source code is available at
https://github.com/hbing-l/RTPCA.
</p>
</div>
</dd>
<dt><a name="item321">[321]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01366" title="Abstract">arXiv:2309.01366</a> [<a href="/pdf/2309.01366" title="Download PDF">pdf</a>, <a href="/format/2309.01366" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Target-Guided Composed Image Retrieval
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wen%2C+H">Haokun Wen</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xian Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+X">Xuemeng Song</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+Y">Yinwei Wei</a>, 
<a href="/search/cs?searchtype=author&query=Nie%2C+L">Liqiang Nie</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> ACM Multimedia 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Multimedia (cs.MM)</span>

</div>
<p class="mathjax">Composed image retrieval (CIR) is a new and flexible image retrieval
paradigm, which can retrieve the target image for a multimodal query, including
a reference image and its corresponding modification text. Although existing
efforts have achieved compelling success, they overlook the conflict
relationship modeling between the reference image and the modification text for
improving the multimodal query composition and the adaptive matching degree
modeling for promoting the ranking of the candidate images that could present
different levels of matching degrees with the given query. To address these two
limitations, in this work, we propose a Target-Guided Composed Image Retrieval
network (TG-CIR). In particular, TG-CIR first extracts the unified global and
local attribute features for the reference/target image and the modification
text with the contrastive language-image pre-training model (CLIP) as the
backbone, where an orthogonal regularization is introduced to promote the
independence among the attribute features. Then TG-CIR designs a target-query
relationship-guided multimodal query composition module, comprising a
target-free student composition branch and a target-based teacher composition
branch, where the target-query relationship is injected into the teacher branch
for guiding the conflict relationship modeling of the student branch. Last,
apart from the conventional batch-based classification loss, TG-CIR
additionally introduces a batch-based target similarity-guided matching degree
regularization to promote the metric learning process. Extensive experiments on
three benchmark datasets demonstrate the superiority of our proposed method.
</p>
</div>
</dd>
<dt><a name="item322">[322]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01369" title="Abstract">arXiv:2309.01369</a> [<a href="/pdf/2309.01369" title="Download PDF">pdf</a>, <a href="/format/2309.01369" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Attention as Annotation: Generating Images and Pseudo-masks for Weakly  Supervised Semantic Segmentation with Diffusion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yoshihashi%2C+R">Ryota Yoshihashi</a>, 
<a href="/search/cs?searchtype=author&query=Otsuka%2C+Y">Yuya Otsuka</a>, 
<a href="/search/cs?searchtype=author&query=Doi%2C+K">Kenji Doi</a>, 
<a href="/search/cs?searchtype=author&query=Tanaka%2C+T">Tomohiro Tanaka</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Although recent advancements in diffusion models enabled high-fidelity and
diverse image generation, training of discriminative models largely depends on
collections of massive real images and their manual annotation. Here, we
present a training method for semantic segmentation that neither relies on real
images nor manual annotation. The proposed method {\it attn2mask} utilizes
images generated by a text-to-image diffusion model in combination with its
internal text-to-image cross-attention as supervisory pseudo-masks. Since the
text-to-image generator is trained with image-caption pairs but without
pixel-wise labels, attn2mask can be regarded as a weakly supervised
segmentation method overall. Experiments show that attn2mask achieves promising
results in PASCAL VOC for not using real training data for segmentation at all,
and it is also useful to scale up segmentation to a more-class scenario, i.e.,
ImageNet segmentation. It also shows adaptation ability with LoRA-based
fine-tuning, which enables the transfer to a distant domain i.e., Cityscapes.
</p>
</div>
</dd>
<dt><a name="item323">[323]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01370" title="Abstract">arXiv:2309.01370</a> [<a href="/pdf/2309.01370" title="Download PDF">pdf</a>, <a href="/format/2309.01370" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ReOnto: A Neuro-Symbolic Approach for Biomedical Relation Extraction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jain%2C+M">Monika Jain</a>, 
<a href="/search/cs?searchtype=author&query=Singh%2C+K">Kuldeep Singh</a>, 
<a href="/search/cs?searchtype=author&query=Mutharaju%2C+R">Raghava Mutharaju</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted in ECML 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Information Retrieval (cs.IR); Machine Learning (cs.LG)

</div>
<p class="mathjax">Relation Extraction (RE) is the task of extracting semantic relationships
between entities in a sentence and aligning them to relations defined in a
vocabulary, which is generally in the form of a Knowledge Graph (KG) or an
ontology. Various approaches have been proposed so far to address this task.
However, applying these techniques to biomedical text often yields
unsatisfactory results because it is hard to infer relations directly from
sentences due to the nature of the biomedical relations. To address these
issues, we present a novel technique called ReOnto, that makes use of neuro
symbolic knowledge for the RE task. ReOnto employs a graph neural network to
acquire the sentence representation and leverages publicly accessible
ontologies as prior knowledge to identify the sentential relation between two
entities. The approach involves extracting the relation path between the two
entities from the ontology. We evaluate the effect of using symbolic knowledge
from ontologies with graph neural networks. Experimental results on two public
biomedical datasets, BioRel and ADE, show that our method outperforms all the
baselines (approximately by 3\%).
</p>
</div>
</dd>
<dt><a name="item324">[324]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01371" title="Abstract">arXiv:2309.01371</a> [<a href="/pdf/2309.01371" title="Download PDF">pdf</a>, <a href="/format/2309.01371" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Survey for Graphic Design Intelligence
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+D">Danqing Huang</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+J">Jiaqi Guo</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+S">Shizhao Sun</a>, 
<a href="/search/cs?searchtype=author&query=Tian%2C+H">Hanling Tian</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+J">Jieru Lin</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+Z">Zheng Hu</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+C">Chin-Yew Lin</a>, 
<a href="/search/cs?searchtype=author&query=Lou%2C+J">Jian-Guang Lou</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+D">Dongmei Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 2 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">Graphic design is an effective language for visual communication. Using
complex composition of visual elements (e.g., shape, color, font) guided by
design principles and aesthetics, design helps produce more visually-appealing
content. The creation of a harmonious design requires carefully selecting and
combining different visual elements, which can be challenging and
time-consuming. To expedite the design process, emerging AI techniques have
been proposed to automatize tedious tasks and facilitate human creativity.
However, most current works only focus on specific tasks targeting at different
scenarios without a high-level abstraction. This paper aims to provide a
systematic overview of graphic design intelligence and summarize literature in
the taxonomy of representation, understanding and generation. Specifically we
consider related works for individual visual elements as well as the overall
design composition. Furthermore, we highlight some of the potential directions
for future explorations.
</p>
</div>
</dd>
<dt><a name="item325">[325]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01372" title="Abstract">arXiv:2309.01372</a> [<a href="/pdf/2309.01372" title="Download PDF">pdf</a>, <a href="/format/2309.01372" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DiverseMotion: Towards Diverse Human Motion Generation via Discrete  Diffusion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lou%2C+Y">Yunhong Lou</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+L">Linchao Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yaxiong Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xiaohan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yi Yang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 7 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">We present DiverseMotion, a new approach for synthesizing high-quality human
motions conditioned on textual descriptions while preserving motion
diversity.Despite the recent significant process in text-based human motion
generation,existing methods often prioritize fitting training motions at the
expense of action diversity. Consequently, striking a balance between motion
quality and diversity remains an unresolved challenge. This problem is
compounded by two key factors: 1) the lack of diversity in motion-caption pairs
in existing benchmarks and 2) the unilateral and biased semantic understanding
of the text prompt, focusing primarily on the verb component while neglecting
the nuanced distinctions indicated by other words.In response to the first
issue, we construct a large-scale Wild Motion-Caption dataset (WMC) to extend
the restricted action boundary of existing well-annotated datasets, enabling
the learning of diverse motions through a more extensive range of actions. To
this end, a motion BLIP is trained upon a pretrained vision-language model,
then we automatically generate diverse motion captions for the collected motion
sequences. As a result, we finally build a dataset comprising 8,888 motions
coupled with 141k text.To comprehensively understand the text command, we
propose a Hierarchical Semantic Aggregation (HSA) module to capture the
fine-grained semantics.Finally,we involve the above two designs into an
effective Motion Discrete Diffusion (MDD) framework to strike a balance between
motion quality and diversity. Extensive experiments on HumanML3D and KIT-ML
show that our DiverseMotion achieves the state-of-the-art motion quality and
competitive motion diversity. Dataset, code, and pretrained models will be
released to reproduce all of our results.
</p>
</div>
</dd>
<dt><a name="item326">[326]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01373" title="Abstract">arXiv:2309.01373</a> [<a href="/pdf/2309.01373" title="Download PDF">pdf</a>, <a href="/format/2309.01373" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PreprintResolver: Improving Citation Quality by Resolving Published  Versions of ArXiv Preprints using Literature Databases
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bloch%2C+L">Louise Bloch</a>, 
<a href="/search/cs?searchtype=author&query=R%C3%BCckert%2C+J">Johannes R&#xfc;ckert</a>, 
<a href="/search/cs?searchtype=author&query=Friedrich%2C+C+M">Christoph M. Friedrich</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted for International Conference on Theory and Practice of Digital Libraries (TPDL 2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Digital Libraries (cs.DL)</span>; Information Retrieval (cs.IR)

</div>
<p class="mathjax">The growing impact of preprint servers enables the rapid sharing of
time-sensitive research. Likewise, it is becoming increasingly difficult to
distinguish high-quality, peer-reviewed research from preprints. Although
preprints are often later published in peer-reviewed journals, this information
is often missing from preprint servers. To overcome this problem, the
PreprintResolver was developed, which uses four literature databases (DBLP,
SemanticScholar, OpenAlex, and CrossRef / CrossCite) to identify
preprint-publication pairs for the arXiv preprint server. The target audience
focuses on, but is not limited to inexperienced researchers and students,
especially from the field of computer science. The tool is based on a fuzzy
matching of author surnames, titles, and DOIs. Experiments were performed on a
sample of 1,000 arXiv-preprints from the research field of computer science and
without any publication information. With 77.94 %, computer science is highly
affected by missing publication information in arXiv. The results show that the
PreprintResolver was able to resolve 603 out of 1,000 (60.3 %) arXiv-preprints
from the research field of computer science and without any publication
information. All four literature databases contributed to the final result. In
a manual validation, a random sample of 100 resolved preprints was checked. For
all preprints, at least one result is plausible. For nine preprints, more than
one result was identified, three of which are partially invalid. In conclusion
the PreprintResolver is suitable for individual, manually reviewed requests,
but less suitable for bulk requests. The PreprintResolver tool
(https://preprintresolver.eu, Available from 2023-08-01) and source code
(https://gitlab.com/ippolis_wp3/preprint-resolver, Accessed: 2023-07-19) is
available online.
</p>
</div>
</dd>
<dt><a name="item327">[327]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01374" title="Abstract">arXiv:2309.01374</a> [<a href="/pdf/2309.01374" title="Download PDF">pdf</a>, <a href="/format/2309.01374" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ImmersiveNeRF: Hybrid Radiance Fields for Unbounded Immersive Light  Field Reconstruction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yu%2C+X">Xiaohang Yu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Haoxiang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+Y">Yuqi Han</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+L">Lei Yang</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+T">Tao Yu</a>, 
<a href="/search/cs?searchtype=author&query=Dai%2C+Q">Qionghai Dai</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">This paper proposes a hybrid radiance field representation for unbounded
immersive light field reconstruction which supports high-quality rendering and
aggressive view extrapolation. The key idea is to first formally separate the
foreground and the background and then adaptively balance learning of them
during the training process. To fulfill this goal, we represent the foreground
and background as two separate radiance fields with two different spatial
mapping strategies. We further propose an adaptive sampling strategy and a
segmentation regularizer for more clear segmentation and robust convergence.
Finally, we contribute a novel immersive light field dataset, named
THUImmersive, with the potential to achieve much larger space 6DoF immersive
rendering effects compared with existing datasets, by capturing multiple
neighboring viewpoints for the same scene, to stimulate the research and AR/VR
applications in the immersive light field domain. Extensive experiments
demonstrate the strong performance of our method for unbounded immersive light
field reconstruction.
</p>
</div>
</dd>
<dt><a name="item328">[328]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01377" title="Abstract">arXiv:2309.01377</a> [<a href="/pdf/2309.01377" title="Download PDF">pdf</a>, <a href="/format/2309.01377" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Memory augment is All You Need for image restoration
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X+F">Xiao Feng Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Gu%2C+C+C">Chao Chen Gu</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+S+Y">Shan Ying Zhu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Image restoration is a low-level vision task, most CNN methods are designed
as a black box, lacking transparency and internal aesthetics. Although some
methods combining traditional optimization algorithms with DNNs have been
proposed, they all have some limitations. In this paper, we propose a
three-granularity memory layer and contrast learning named MemoryNet,
specifically, dividing the samples into positive, negative, and actual three
samples for contrastive learning, where the memory layer is able to preserve
the deep features of the image and the contrastive learning converges the
learned features to balance. Experiments on Derain/Deshadow/Deblur task
demonstrate that these methods are effective in improving restoration
performance. In addition, this paper's model obtains significant PSNR, SSIM
gain on three datasets with different degradation types, which is a strong
proof that the recovered images are perceptually realistic. The source code of
MemoryNet can be obtained from https://github.com/zhangbaijin/MemoryNet
</p>
</div>
</dd>
<dt><a name="item329">[329]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01379" title="Abstract">arXiv:2309.01379</a> [<a href="/pdf/2309.01379" title="Download PDF">pdf</a>, <a href="/format/2309.01379" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MLGuard: Defend Your Machine Learning Model!
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wong%2C+S">Sheng Wong</a>, 
<a href="/search/cs?searchtype=author&query=Barnett%2C+S">Scott Barnett</a>, 
<a href="/search/cs?searchtype=author&query=Rivera-Villicana%2C+J">Jessica Rivera-Villicana</a>, 
<a href="/search/cs?searchtype=author&query=Simmons%2C+A">Anj Simmons</a>, 
<a href="/search/cs?searchtype=author&query=Abdelkader%2C+H">Hala Abdelkader</a>, 
<a href="/search/cs?searchtype=author&query=Schneider%2C+J">Jean-Guy Schneider</a>, 
<a href="/search/cs?searchtype=author&query=Vasa%2C+R">Rajesh Vasa</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted in SE4SafeML'23
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
<p class="mathjax">Machine Learning (ML) is used in critical highly regulated and high-stakes
fields such as finance, medicine, and transportation. The correctness of these
ML applications is important for human safety and economic benefit. Progress
has been made on improving ML testing and monitoring of ML. However, these
approaches do not provide i) pre/post conditions to handle uncertainty, ii)
defining corrective actions based on probabilistic outcomes, or iii) continual
verification during system operation. In this paper, we propose MLGuard, a new
approach to specify contracts for ML applications. Our approach consists of a)
an ML contract specification defining pre/post conditions, invariants, and
altering behaviours, b) generated validation models to determine the
probability of contract violation, and c) an ML wrapper generator to enforce
the contract and respond to violations. Our work is intended to provide the
overarching framework required for building ML applications and monitoring
their safety.
</p>
</div>
</dd>
<dt><a name="item330">[330]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01380" title="Abstract">arXiv:2309.01380</a> [<a href="/pdf/2309.01380" title="Download PDF">pdf</a>, <a href="/format/2309.01380" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Understanding Video Scenes through Text: Insights from Text-based Video  Question Answering
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jahagirdar%2C+S">Soumya Jahagirdar</a>, 
<a href="/search/cs?searchtype=author&query=Mathew%2C+M">Minesh Mathew</a>, 
<a href="/search/cs?searchtype=author&query=Karatzas%2C+D">Dimosthenis Karatzas</a>, 
<a href="/search/cs?searchtype=author&query=Jawahar%2C+C+V">C. V. Jawahar</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Researchers have extensively studied the field of vision and language,
discovering that both visual and textual content is crucial for understanding
scenes effectively. Particularly, comprehending text in videos holds great
significance, requiring both scene text understanding and temporal reasoning.
This paper focuses on exploring two recently introduced datasets, NewsVideoQA
and M4-ViteVQA, which aim to address video question answering based on textual
content. The NewsVideoQA dataset contains question-answer pairs related to the
text in news videos, while M4-ViteVQA comprises question-answer pairs from
diverse categories like vlogging, traveling, and shopping. We provide an
analysis of the formulation of these datasets on various levels, exploring the
degree of visual understanding and multi-frame comprehension required for
answering the questions. Additionally, the study includes experimentation with
BERT-QA, a text-only model, which demonstrates comparable performance to the
original methods on both datasets, indicating the shortcomings in the
formulation of these datasets. Furthermore, we also look into the domain
adaptation aspect by examining the effectiveness of training on M4-ViteVQA and
evaluating on NewsVideoQA and vice-versa, thereby shedding light on the
challenges and potential benefits of out-of-domain training.
</p>
</div>
</dd>
<dt><a name="item331">[331]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01381" title="Abstract">arXiv:2309.01381</a> [<a href="/pdf/2309.01381" title="Download PDF">pdf</a>, <a href="/format/2309.01381" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Classic algorithms are fair learners: Classification Analysis of natural  weather and wildfire occurrences
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gopal%2C+S">Senthilkumar Gopal</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Classic machine learning algorithms have been reviewed and studied
mathematically on its performance and properties in detail. This paper intends
to review the empirical functioning of widely used classical supervised
learning algorithms such as Decision Trees, Boosting, Support Vector Machines,
k-nearest Neighbors and a shallow Artificial Neural Network. The paper
evaluates these algorithms on a sparse tabular data for classification task and
observes the effect on specific hyperparameters on these algorithms when the
data is synthetically modified for higher noise. These perturbations were
introduced to observe these algorithms on their efficiency in generalizing for
sparse data and their utility of different parameters to improve classification
accuracy. The paper intends to show that these classic algorithms are fair
learners even for such limited data due to their inherent properties even for
noisy and sparse datasets.
</p>
</div>
</dd>
<dt><a name="item332">[332]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01383" title="Abstract">arXiv:2309.01383</a> [<a href="/pdf/2309.01383" title="Download PDF">pdf</a>, <a href="/format/2309.01383" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LoRA-like Calibration for Multimodal Deception Detection using ATSFace  Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hsiao%2C+S">Shun-Wen Hsiao</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+C">Cheng-Yuan Sun</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 9 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Recently, deception detection on human videos is an eye-catching techniques
and can serve lots applications. AI model in this domain demonstrates the high
accuracy, but AI tends to be a non-interpretable black box. We introduce an
attention-aware neural network addressing challenges inherent in video data and
deception dynamics. This model, through its continuous assessment of visual,
audio, and text features, pinpoints deceptive cues. We employ a multimodal
fusion strategy that enhances accuracy; our approach yields a 92\% accuracy
rate on a real-life trial dataset. Most important of all, the model indicates
the attention focus in the videos, providing valuable insights on deception
cues. Hence, our method adeptly detects deceit and elucidates the underlying
process. We further enriched our study with an experiment involving students
answering questions either truthfully or deceitfully, resulting in a new
dataset of 309 video clips, named ATSFace. Using this, we also introduced a
calibration method, which is inspired by Low-Rank Adaptation (LoRA), to refine
individual-based deception detection accuracy.
</p>
</div>
</dd>
<dt><a name="item333">[333]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01386" title="Abstract">arXiv:2309.01386</a> [<a href="/pdf/2309.01386" title="Download PDF">pdf</a>, <a href="/format/2309.01386" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SemProtector: A Unified Framework for Semantic Protection in Deep  Learning-based Semantic Communication Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xinghan Liu</a>, 
<a href="/search/cs?searchtype=author&query=Nan%2C+G">Guoshun Nan</a>, 
<a href="/search/cs?searchtype=author&query=Cui%2C+Q">Qimei Cui</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zeju Li</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+P">Peiyuan Liu</a>, 
<a href="/search/cs?searchtype=author&query=Xing%2C+Z">Zebin Xing</a>, 
<a href="/search/cs?searchtype=author&query=Mu%2C+H">Hanqing Mu</a>, 
<a href="/search/cs?searchtype=author&query=Tao%2C+X">Xiaofeng Tao</a>, 
<a href="/search/cs?searchtype=author&query=Quek%2C+T+Q+S">Tony Q.S. Quek</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by Communications Magazine
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">Recently proliferated semantic communications (SC) aim at effectively
transmitting the semantics conveyed by the source and accurately interpreting
the meaning at the destination. While such a paradigm holds the promise of
making wireless communications more intelligent, it also suffers from severe
semantic security issues, such as eavesdropping, privacy leaking, and spoofing,
due to the open nature of wireless channels and the fragility of neural
modules. Previous works focus more on the robustness of SC via offline
adversarial training of the whole system, while online semantic protection, a
more practical setting in the real world, is still largely under-explored. To
this end, we present SemProtector, a unified framework that aims to secure an
online SC system with three hot-pluggable semantic protection modules.
Specifically, these protection modules are able to encrypt semantics to be
transmitted by an encryption method, mitigate privacy risks from wireless
channels by a perturbation mechanism, and calibrate distorted semantics at the
destination by a semantic signature generation method. Our framework enables an
existing online SC system to dynamically assemble the above three pluggable
modules to meet customized semantic protection requirements, facilitating the
practical deployment in real-world SC systems. Experiments on two public
datasets show the effectiveness of our proposed SemProtector, offering some
insights of how we reach the goal of secrecy, privacy and integrity of an SC
system. Finally, we discuss some future directions for the semantic protection.
</p>
</div>
</dd>
<dt><a name="item334">[334]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01390" title="Abstract">arXiv:2309.01390</a> [<a href="/pdf/2309.01390" title="Download PDF">pdf</a>, <a href="/format/2309.01390" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Metric Learning for Projections Bias of Generalized Zero-shot Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+C">Chong Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+M">Mingyu Jin</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+Q">Qinkai Yu</a>, 
<a href="/search/cs?searchtype=author&query=Xue%2C+H">Haochen Xue</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+X">Xiaobo Jin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages, 2 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Generalized zero-shot learning models (GZSL) aim to recognize samples from
seen or unseen classes using only samples from seen classes as training data.
During inference, GZSL methods are often biased towards seen classes due to the
visibility of seen class samples during training. Most current GZSL methods try
to learn an accurate projection function (from visual space to semantic space)
to avoid bias and ensure the effectiveness of GZSL methods. However, during
inference, the computation of distance will be important when we classify the
projection of any sample into its nearest class since we may learn a biased
projection function in the model. In our work, we attempt to learn a
parameterized Mahalanobis distance within the framework of VAEGAN (Variational
Autoencoder \&amp; Generative Adversarial Networks), where the weight matrix
depends on the network's output. In particular, we improved the network
structure of VAEGAN to leverage the discriminative models of two branches to
separately predict the seen samples and the unseen samples generated by this
seen one. We proposed a new loss function with two branches to help us learn
the optimized Mahalanobis distance representation. Comprehensive evaluation
benchmarks on four datasets demonstrate the superiority of our method over the
state-of-the-art counterparts. Our codes are available at
https://anonymous.4open.science/r/111hxr.
</p>
</div>
</dd>
<dt><a name="item335">[335]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01391" title="Abstract">arXiv:2309.01391</a> [<a href="/pdf/2309.01391" title="Download PDF">pdf</a>, <a href="/format/2309.01391" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SSVOD: Semi-Supervised Video Object Detection with Sparse Annotations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mahmud%2C+T">Tanvir Mahmud</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+C">Chun-Hao Liu</a>, 
<a href="/search/cs?searchtype=author&query=Yaman%2C+B">Burhaneddin Yaman</a>, 
<a href="/search/cs?searchtype=author&query=Marculescu%2C+D">Diana Marculescu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Despite significant progress in semi-supervised learning for image object
detection, several key issues are yet to be addressed for video object
detection: (1) Achieving good performance for supervised video object detection
greatly depends on the availability of annotated frames. (2) Despite having
large inter-frame correlations in a video, collecting annotations for a large
number of frames per video is expensive, time-consuming, and often redundant.
(3) Existing semi-supervised techniques on static images can hardly exploit the
temporal motion dynamics inherently present in videos. In this paper, we
introduce SSVOD, an end-to-end semi-supervised video object detection framework
that exploits motion dynamics of videos to utilize large-scale unlabeled frames
with sparse annotations. To selectively assemble robust pseudo-labels across
groups of frames, we introduce \textit{flow-warped predictions} from nearby
frames for temporal-consistency estimation. In particular, we introduce
cross-IoU and cross-divergence based selection methods over a set of estimated
predictions to include robust pseudo-labels for bounding boxes and class
labels, respectively. To strike a balance between confirmation bias and
uncertainty noise in pseudo-labels, we propose confidence threshold based
combination of hard and soft pseudo-labels. Our method achieves significant
performance improvements over existing methods on ImageNet-VID, Epic-KITCHENS,
and YouTube-VIS datasets. Code and pre-trained models will be released.
</p>
</div>
</dd>
<dt><a name="item336">[336]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01392" title="Abstract">arXiv:2309.01392</a> [<a href="/pdf/2309.01392" title="Download PDF">pdf</a>, <a href="/ps/2309.01392" title="Download PostScript">ps</a>, <a href="/format/2309.01392" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Topological Ordering in Differentiable Bayesian Structure Learning with  Guaranteed Acyclicity Constraint
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tran%2C+Q">Quang-Duy Tran</a>, 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+P">Phuoc Nguyen</a>, 
<a href="/search/cs?searchtype=author&query=Duong%2C+B">Bao Duong</a>, 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+T">Thin Nguyen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted as a regular paper (9.37%) at the 23rd IEEE International Conference on Data Mining (ICDM 2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
<p class="mathjax">Score-based approaches in the structure learning task are thriving because of
their scalability. Continuous relaxation has been the key reason for this
advancement. Despite achieving promising outcomes, most of these methods are
still struggling to ensure that the graphs generated from the latent space are
acyclic by minimizing a defined score. There has also been another trend of
permutation-based approaches, which concern the search for the topological
ordering of the variables in the directed acyclic graph (DAG) in order to limit
the search space of the graph. In this study, we propose an alternative
approach for strictly constraining the acyclicty of the graphs with an
integration of the knowledge from the topological orderings. Our approach can
reduce inference complexity while ensuring the structures of the generated
graphs to be acyclic. Our empirical experiments with simulated and real-world
data show that our approach can outperform related Bayesian score-based
approaches.
</p>
</div>
</dd>
<dt><a name="item337">[337]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01395" title="Abstract">arXiv:2309.01395</a> [<a href="/pdf/2309.01395" title="Download PDF">pdf</a>, <a href="/format/2309.01395" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AVATAR: Robust Voice Search Engine Leveraging Autoregressive Document  Retrieval and Contrastive Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yi-Cheng Wang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+T">Tzu-Ting Yang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Hsin-Wei Wang</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+B">Bi-Cheng Yan</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+B">Berlin Chen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>

</div>
<p class="mathjax">Voice, as input, has progressively become popular on mobiles and seems to
transcend almost entirely text input. Through voice, the voice search (VS)
system can provide a more natural way to meet user's information needs.
However, errors from the automatic speech recognition (ASR) system can be
catastrophic to the VS system. Building on the recent advanced lightweight
autoregressive retrieval model, which has the potential to be deployed on
mobiles, leading to a more secure and personal VS assistant. This paper
presents a novel study of VS leveraging autoregressive retrieval and tackles
the crucial problems facing VS, viz. the performance drop caused by ASR noise,
via data augmentations and contrastive learning, showing how explicit and
implicit modeling the noise patterns can alleviate the problems. A series of
experiments conducted on the Open-Domain Question Answering (ODSQA) confirm our
approach's effectiveness and robustness in relation to some strong baseline
systems.
</p>
</div>
</dd>
<dt><a name="item338">[338]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01398" title="Abstract">arXiv:2309.01398</a> [<a href="/pdf/2309.01398" title="Download PDF">pdf</a>, <a href="/format/2309.01398" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Zero-shot information extraction from radiological reports using ChatGPT
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hu%2C+D">Danqing Hu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+B">Bing Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+X">Xiaofeng Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+X">Xudong Lu</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+N">Nan Wu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Electronic health records contain an enormous amount of valuable information,
but many are recorded in free text. Information extraction is the strategy to
transform the sequence of characters into structured data, which can be
employed for secondary analysis. However, the traditional information
extraction components, such as named entity recognition and relation
extraction, require annotated data to optimize the model parameters, which has
become one of the major bottlenecks in building information extraction systems.
With the large language models achieving good performances on various
downstream NLP tasks without parameter tuning, it becomes possible to use large
language models for zero-shot information extraction. In this study, we aim to
explore whether the most popular large language model, ChatGPT, can extract
useful information from the radiological reports. We first design the prompt
template for the interested information in the CT reports. Then, we generate
the prompts by combining the prompt template with the CT reports as the inputs
of ChatGPT to obtain the responses. A post-processing module is developed to
transform the responses into structured extraction results. We conducted the
experiments with 847 CT reports collected from Peking University Cancer
Hospital. The experimental results indicate that ChatGPT can achieve
competitive performances for some extraction tasks compared with the baseline
information extraction system, but some limitations need to be further
improved.
</p>
</div>
</dd>
<dt><a name="item339">[339]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01399" title="Abstract">arXiv:2309.01399</a> [<a href="/pdf/2309.01399" title="Download PDF">pdf</a>, <a href="/format/2309.01399" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Objcache: An Elastic Filesystem over External Persistent Storage for  Container Clusters
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yoshimura%2C+T">Takeshi Yoshimura</a>, 
<a href="/search/cs?searchtype=author&query=Chiba%2C+T">Tatsuhiro Chiba</a>, 
<a href="/search/cs?searchtype=author&query=Choochotkaew%2C+S">Sunyanan Choochotkaew</a>, 
<a href="/search/cs?searchtype=author&query=Seelam%2C+S">Seetharami Seelam</a>, 
<a href="/search/cs?searchtype=author&query=Wen%2C+H">Hui-fang Wen</a>, 
<a href="/search/cs?searchtype=author&query=Pfefferle%2C+J">Jonas Pfefferle</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>

</div>
<p class="mathjax">Container virtualization enables emerging AI workloads such as model serving,
highly parallelized training, machine learning pipelines, and so on, to be
easily scaled on demand on the elastic cloud infrastructure. Particularly, AI
workloads require persistent storage to store data such as training inputs,
models, and checkpoints. An external storage system like cloud object storage
is a common choice because of its elasticity and scalability. To mitigate
access latency to external storage, caching at a local filesystem is an
essential technique. However, building local caches on scaling clusters must
cope with explosive disk usage, redundant networking, and unexpected failures.
We propose objcache, an elastic filesystem over external storage. Objcache
introduces an internal transaction protocol over Raft logging to enable atomic
updates of distributed persistent states with consistent hashing. The proposed
transaction protocol can also manage inode dirtiness by maintaining the
consistency between the local cache and external storage. Objcache supports
scaling down to zero by automatically evicting dirty files to external storage.
Our evaluation reports that objcache speeded up model serving startup by 98.9%
compared to direct copies via S3 interfaces. Scaling up with dirty files
completed from 2 to 14 seconds with 1024 dirty files.
</p>
</div>
</dd>
<dt><a name="item340">[340]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01406" title="Abstract">arXiv:2309.01406</a> [<a href="/pdf/2309.01406" title="Download PDF">pdf</a>, <a href="/format/2309.01406" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning Residual Elastic Warps for Image Stitching under Dirichlet  Boundary Condition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kim%2C+M">Minsu Kim</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+Y">Yongjun Lee</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+W+K">Woo Kyoung Han</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+K+H">Kyong Hwan Jin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Trendy suggestions for learning-based elastic warps enable the deep image
stitchings to align images exposed to large parallax errors. Despite the
remarkable alignments, the methods struggle with occasional holes or
discontinuity between overlapping and non-overlapping regions of a target image
as the applied training strategy mostly focuses on overlap region alignment. As
a result, they require additional modules such as seam finder and image
inpainting for hiding discontinuity and filling holes, respectively. In this
work, we suggest Recurrent Elastic Warps (REwarp) that address the problem with
Dirichlet boundary condition and boost performances by residual learning for
recurrent misalign correction. Specifically, REwarp predicts a homography and a
Thin-plate Spline (TPS) under the boundary constraint for discontinuity and
hole-free image stitching. Our experiments show the favorable aligns and the
competitive computational costs of REwarp compared to the existing stitching
methods. Our source code is available at https://github.com/minshu-kim/REwarp.
</p>
</div>
</dd>
<dt><a name="item341">[341]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01408" title="Abstract">arXiv:2309.01408</a> [<a href="/pdf/2309.01408" title="Download PDF">pdf</a>, <a href="/format/2309.01408" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Leveraging Self-Supervised Vision Transformers for Neural Transfer  Function Design
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Engel%2C+D">Dominik Engel</a>, 
<a href="/search/cs?searchtype=author&query=Sick%2C+L">Leon Sick</a>, 
<a href="/search/cs?searchtype=author&query=Ropinski%2C+T">Timo Ropinski</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Graphics (cs.GR); Machine Learning (cs.LG)

</div>
<p class="mathjax">In volume rendering, transfer functions are used to classify structures of
interest, and to assign optical properties such as color and opacity. They are
commonly defined as 1D or 2D functions that map simple features to these
optical properties. As the process of designing a transfer function is
typically tedious and unintuitive, several approaches have been proposed for
their interactive specification. In this paper, we present a novel method to
define transfer functions for volume rendering by leveraging the feature
extraction capabilities of self-supervised pre-trained vision transformers. To
design a transfer function, users simply select the structures of interest in a
slice viewer, and our method automatically selects similar structures based on
the high-level features extracted by the neural network. Contrary to previous
learning-based transfer function approaches, our method does not require
training of models and allows for quick inference, enabling an interactive
exploration of the volume data. Our approach reduces the amount of necessary
annotations by interactively informing the user about the current
classification, so they can focus on annotating the structures of interest that
still require annotation. In practice, this allows users to design transfer
functions within seconds, instead of minutes. We compare our method to existing
learning-based approaches in terms of annotation and compute time, as well as
with respect to segmentation accuracy. Our accompanying video showcases the
interactivity and effectiveness of our method.
</p>
</div>
</dd>
<dt><a name="item342">[342]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01409" title="Abstract">arXiv:2309.01409</a> [<a href="/pdf/2309.01409" title="Download PDF">pdf</a>, <a href="/format/2309.01409" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Implicit Neural Image Stitching With Enhanced and Blended Feature  Reconstruction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kim%2C+M">Minsu Kim</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+J">Jaewon Lee</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+B">Byeonghun Lee</a>, 
<a href="/search/cs?searchtype=author&query=Im%2C+S">Sunghoon Im</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+K+H">Kyong Hwan Jin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Existing frameworks for image stitching often provide visually reasonable
stitchings. However, they suffer from blurry artifacts and disparities in
illumination, depth level, etc. Although the recent learning-based stitchings
relax such disparities, the required methods impose sacrifice of image
qualities failing to capture high-frequency details for stitched images. To
address the problem, we propose a novel approach, implicit Neural Image
Stitching (NIS) that extends arbitrary-scale super-resolution. Our method
estimates Fourier coefficients of images for quality-enhancing warps. Then, the
suggested model blends color mismatches and misalignment in the latent space
and decodes the features into RGB values of stitched images. Our experiments
show that our approach achieves improvement in resolving the low-definition
imaging of the previous deep image stitching with favorable accelerated
image-enhancing methods. Our source code is available at
https://github.com/minshu-kim/NIS.
</p>
</div>
</dd>
<dt><a name="item343">[343]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01413" title="Abstract">arXiv:2309.01413</a> [<a href="/pdf/2309.01413" title="Download PDF">pdf</a>, <a href="/format/2309.01413" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Hateful Messages: A Conversational Data Set of Hate Speech produced by  Adolescents on Discord
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fillies%2C+J">Jan Fillies</a>, 
<a href="/search/cs?searchtype=author&query=Peikert%2C+S">Silvio Peikert</a>, 
<a href="/search/cs?searchtype=author&query=Paschke%2C+A">Adrian Paschke</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">With the rise of social media, a rise of hateful content can be observed.
Even though the understanding and definitions of hate speech varies, platforms,
communities, and legislature all acknowledge the problem. Therefore,
adolescents are a new and active group of social media users. The majority of
adolescents experience or witness online hate speech. Research in the field of
automated hate speech classification has been on the rise and focuses on
aspects such as bias, generalizability, and performance. To increase
generalizability and performance, it is important to understand biases within
the data. This research addresses the bias of youth language within hate speech
classification and contributes by providing a modern and anonymized hate speech
youth language data set consisting of 88.395 annotated chat messages. The data
set consists of publicly available online messages from the chat platform
Discord. ~6,42% of the messages were classified by a self-developed annotation
schema as hate speech. For 35.553 messages, the user profiles provided age
annotations setting the average author age to under 20 years old.
</p>
</div>
</dd>
<dt><a name="item344">[344]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01418" title="Abstract">arXiv:2309.01418</a> [<a href="/pdf/2309.01418" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Social Factors in P2P Energy Trading Using Hedonic Games
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mitrea%2C+D">Dan Mitrea</a>, 
<a href="/search/cs?searchtype=author&query=Chifu%2C+V">Viorica Chifu</a>, 
<a href="/search/cs?searchtype=author&query=Cioara%2C+T">Tudor Cioara</a>, 
<a href="/search/cs?searchtype=author&query=Anghel%2C+I">Ionut Anghel</a>, 
<a href="/search/cs?searchtype=author&query=Pop%2C+C">Cristina Pop</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> to be submitted to journal
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>; Artificial Intelligence (cs.AI); Computer Science and Game Theory (cs.GT)

</div>
<p class="mathjax">Lately, the energy communities have gained a lot of attention as they have
the potential to significantly contribute to the resilience and flexibility of
the energy system, facilitating widespread integration of intermittent
renewable energy sources. Within these communities the prosumers can engage in
peer-to-peer trading, fostering local collaborations and increasing awareness
about energy usage and flexible consumption. However, even under these
favorable conditions, prosumer engagement levels remain low, requiring trading
mechanisms that are aligned with their social values and expectations. In this
paper, we introduce an innovative hedonic game coordination and cooperation
model for P2P energy trading among prosumers which considers the social
relationships within an energy community to create energy coalitions and
facilitate energy transactions among them. We defined a heuristic that
optimizes the prosumers coalitions, considering their social and energy price
preferences and balancing the energy demand and supply within the community. We
integrated the proposed hedonic game model into a state-of-the-art
blockchain-based P2P energy flexibility market and evaluated its performance
within an energy community of prosumers. The evaluation results on a
blockchain-based P2P energy flexibility market show the effectiveness in
considering social factors when creating coalitions, increasing the total
amount of energy transacted in a market session by 5% compared with other game
theory-based solutions. Finally, it shows the importance of the social
dimensions of P2P energy transactions, the positive social dynamics in the
energy community increasing the amount of energy transacted by more than 10%
while contributing to a more balanced energy demand and supply within the
community.
</p>
</div>
</dd>
<dt><a name="item345">[345]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01420" title="Abstract">arXiv:2309.01420</a> [<a href="/pdf/2309.01420" title="Download PDF">pdf</a>, <a href="/format/2309.01420" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Unified Pre-training with Pseudo Texts for Text-To-Image Person  Re-identification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shao%2C+Z">Zhiyin Shao</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xinyu Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Ding%2C+C">Changxing Ding</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jian Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jingdong Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> accepted by ICCV 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">The pre-training task is indispensable for the text-to-image person
re-identification (T2I-ReID) task. However, there are two underlying
inconsistencies between these two tasks that may impact the performance; i)
Data inconsistency. A large domain gap exists between the generic images/texts
used in public pre-trained models and the specific person data in the T2I-ReID
task. This gap is especially severe for texts, as general textual data are
usually unable to describe specific people in fine-grained detail. ii) Training
inconsistency. The processes of pre-training of images and texts are
independent, despite cross-modality learning being critical to T2I-ReID. To
address the above issues, we present a new unified pre-training pipeline
(UniPT) designed specifically for the T2I-ReID task. We first build a
large-scale text-labeled person dataset "LUPerson-T", in which pseudo-textual
descriptions of images are automatically generated by the CLIP paradigm using a
divide-conquer-combine strategy. Benefiting from this dataset, we then utilize
a simple vision-and-language pre-training framework to explicitly align the
feature space of the image and text modalities during pre-training. In this
way, the pre-training task and the T2I-ReID task are made consistent with each
other on both data and training levels. Without the need for any bells and
whistles, our UniPT achieves competitive Rank-1 accuracy of, ie, 68.50%,
60.09%, and 51.85% on CUHK-PEDES, ICFG-PEDES and RSTPReid, respectively. Both
the LUPerson-T dataset and code are available at
https;//github.com/ZhiyinShao-H/UniPT.
</p>
</div>
</dd>
<dt><a name="item346">[346]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01426" title="Abstract">arXiv:2309.01426</a> [<a href="/pdf/2309.01426" title="Download PDF">pdf</a>, <a href="/format/2309.01426" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Unified Framework for Guiding Generative AI with Wireless Perception  in Resource Constrained Mobile Edge Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jiacheng Wang</a>, 
<a href="/search/cs?searchtype=author&query=Du%2C+H">Hongyang Du</a>, 
<a href="/search/cs?searchtype=author&query=Niyato%2C+D">Dusit Niyato</a>, 
<a href="/search/cs?searchtype=author&query=Kang%2C+J">Jiawen Kang</a>, 
<a href="/search/cs?searchtype=author&query=Xiong%2C+Z">Zehui Xiong</a>, 
<a href="/search/cs?searchtype=author&query=Rajan%2C+D">Deepu Rajan</a>, 
<a href="/search/cs?searchtype=author&query=Mao%2C+S">Shiwen Mao</a>, 
<a href="/search/cs?searchtype=author&query=Xuemin">Xuemin</a> (Sherman)
<a href="/search/cs?searchtype=author&query=Shen">Shen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">With the significant advancements in artificial intelligence (AI)
technologies and powerful computational capabilities, generative AI (GAI) has
become a pivotal digital content generation technique for offering superior
digital services. However, directing GAI towards desired outputs still suffer
the inherent instability of the AI model. In this paper, we design a novel
framework that utilizes wireless perception to guide GAI (WiPe-GAI) for
providing digital content generation service, i.e., AI-generated content
(AIGC), in resource-constrained mobile edge networks. Specifically, we first
propose a new sequential multi-scale perception (SMSP) algorithm to predict
user skeleton based on the channel state information (CSI) extracted from
wireless signals. This prediction then guides GAI to provide users with AIGC,
such as virtual character generation. To ensure the efficient operation of the
proposed framework in resource constrained networks, we further design a
pricing-based incentive mechanism and introduce a diffusion model based
approach to generate an optimal pricing strategy for the service provisioning.
The strategy maximizes the user's utility while enhancing the participation of
the virtual service provider (VSP) in AIGC provision. The experimental results
demonstrate the effectiveness of the designed framework in terms of skeleton
prediction and optimal pricing strategy generation comparing with other
existing solutions.
</p>
</div>
</dd>
<dt><a name="item347">[347]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01428" title="Abstract">arXiv:2309.01428</a> [<a href="/pdf/2309.01428" title="Download PDF">pdf</a>, <a href="/format/2309.01428" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Collective Communication Patterns Using Time-Reversal Terahertz Links at  the Chip Scale
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rodr%C3%ADguez-Gal%C3%A1n%2C+F">F&#xe1;tima Rodr&#xed;guez-Gal&#xe1;n</a>, 
<a href="/search/cs?searchtype=author&query=Bandara%2C+A">Ama Bandara</a>, 
<a href="/search/cs?searchtype=author&query=de+Santana%2C+E+P">Elana Pereira de Santana</a>, 
<a href="/search/cs?searchtype=author&query=Bol%C3%ADvar%2C+P+H">Peter Haring Bol&#xed;var</a>, 
<a href="/search/cs?searchtype=author&query=Alarc%C3%B3n%2C+E">Eduard Alarc&#xf3;n</a>, 
<a href="/search/cs?searchtype=author&query=Abadal%2C+S">Sergi Abadal</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Hardware Architecture (cs.AR)</span>

</div>
<p class="mathjax">Wireless communications in the terahertz band have been recently proposed as
complement to conventional wired interconnects within computing packages. Such
environments are typically highly reverberant, hence showing long channel
impulse responses and severely limiting the achievable rates. Fortunately, this
communications scenario is static and can be pre-characterized, which opens the
door to techniques such as time reversal. Time reversal acts a spatial matched
filter and has a spatiotemporal focusing effect, which allows not only to
increase the achievable symbol rates, but also to create multiple spatial
channels. In this paper, the multi-user capability of time reversal is explored
in the context of wireless communications in the terahertz band within a
computing package. Full-wave simulations are carried out to validate the
approach, whereas modulation streams are simulated to evaluate the error rate
as a function of the transmitted power, symbol rate, and number of simultaneous
transmissions.
</p>
</div>
</dd>
<dt><a name="item348">[348]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01429" title="Abstract">arXiv:2309.01429</a> [<a href="/pdf/2309.01429" title="Download PDF">pdf</a>, <a href="/format/2309.01429" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Adapting Segment Anything Model for Change Detection in HR Remote  Sensing Images
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ding%2C+L">Lei Ding</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+K">Kun Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+D">Daifeng Peng</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+H">Hao Tang</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+H">Haitao Guo</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Vision Foundation Models (VFMs) such as the Segment Anything Model (SAM)
allow zero-shot or interactive segmentation of visual contents, thus they are
quickly applied in a variety of visual scenes. However, their direct use in
many Remote Sensing (RS) applications is often unsatisfactory due to the
special imaging characteristics of RS images. In this work, we aim to utilize
the strong visual recognition capabilities of VFMs to improve the change
detection of high-resolution Remote Sensing Images (RSIs). We employ the visual
encoder of FastSAM, an efficient variant of the SAM, to extract visual
representations in RS scenes. To adapt FastSAM to focus on some specific ground
objects in the RS scenes, we propose a convolutional adaptor to aggregate the
task-oriented change information. Moreover, to utilize the semantic
representations that are inherent to SAM features, we introduce a task-agnostic
semantic learning branch to model the semantic latent in bi-temporal RSIs. The
resulting method, SAMCD, obtains superior accuracy compared to the SOTA methods
and exhibits a sample-efficient learning ability that is comparable to
semi-supervised CD methods. To the best of our knowledge, this is the first
work that adapts VFMs for the CD of HR RSIs.
</p>
</div>
</dd>
<dt><a name="item349">[349]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01430" title="Abstract">arXiv:2309.01430</a> [<a href="/pdf/2309.01430" title="Download PDF">pdf</a>, <a href="/format/2309.01430" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DAT++: Spatially Dynamic Vision Transformer with Deformable Attention
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xia%2C+Z">Zhuofan Xia</a>, 
<a href="/search/cs?searchtype=author&query=Pan%2C+X">Xuran Pan</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+S">Shiji Song</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+L+E">Li Erran Li</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+G">Gao Huang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 17 pages, 6 figures, 11 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Transformers have shown superior performance on various vision tasks. Their
large receptive field endows Transformer models with higher representation
power than their CNN counterparts. Nevertheless, simply enlarging the receptive
field also raises several concerns. On the one hand, using dense attention in
ViT leads to excessive memory and computational cost, and features can be
influenced by irrelevant parts that are beyond the region of interests. On the
other hand, the handcrafted attention adopted in PVT or Swin Transformer is
data agnostic and may limit the ability to model long-range relations. To solve
this dilemma, we propose a novel deformable multi-head attention module, where
the positions of key and value pairs in self-attention are adaptively allocated
in a data-dependent way. This flexible scheme enables the proposed deformable
attention to dynamically focus on relevant regions while maintains the
representation power of global attention. On this basis, we present Deformable
Attention Transformer (DAT), a general vision backbone efficient and effective
for visual recognition. We further build an enhanced version DAT++. Extensive
experiments show that our DAT++ achieves state-of-the-art results on various
visual recognition benchmarks, with 85.9% ImageNet accuracy, 54.5 and 47.0
MS-COCO instance segmentation mAP, and 51.5 ADE20K semantic segmentation mIoU.
</p>
</div>
</dd>
<dt><a name="item350">[350]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01431" title="Abstract">arXiv:2309.01431</a> [<a href="/pdf/2309.01431" title="Download PDF">pdf</a>, <a href="/format/2309.01431" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Benchmarking Large Language Models in Retrieval-Augmented Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Jiawei Chen</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+H">Hongyu Lin</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+X">Xianpei Han</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+L">Le Sun</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Retrieval-Augmented Generation (RAG) is a promising approach for mitigating
the hallucination of large language models (LLMs). However, existing research
lacks rigorous evaluation of the impact of retrieval-augmented generation on
different large language models, which make it challenging to identify the
potential bottlenecks in the capabilities of RAG for different LLMs. In this
paper, we systematically investigate the impact of Retrieval-Augmented
Generation on large language models. We analyze the performance of different
large language models in 4 fundamental abilities required for RAG, including
noise robustness, negative rejection, information integration, and
counterfactual robustness. To this end, we establish Retrieval-Augmented
Generation Benchmark (RGB), a new corpus for RAG evaluation in both English and
Chinese. RGB divides the instances within the benchmark into 4 separate
testbeds based on the aforementioned fundamental abilities required to resolve
the case. Then we evaluate 6 representative LLMs on RGB to diagnose the
challenges of current LLMs when applying RAG. Evaluation reveals that while
LLMs exhibit a certain degree of noise robustness, they still struggle
significantly in terms of negative rejection, information integration, and
dealing with false information. The aforementioned assessment outcomes indicate
that there is still a considerable journey ahead to effectively apply RAG to
LLMs.
</p>
</div>
</dd>
<dt><a name="item351">[351]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01433" title="Abstract">arXiv:2309.01433</a> [<a href="/pdf/2309.01433" title="Download PDF">pdf</a>, <a href="/ps/2309.01433" title="Download PostScript">ps</a>, <a href="/format/2309.01433" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Lifting the Reasoning Level in Generic Weak Memory Verification  (Extended Version)
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bargmann%2C+L">Lara Bargmann</a>, 
<a href="/search/cs?searchtype=author&query=Wehrheim%2C+H">Heike Wehrheim</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>

</div>
<p class="mathjax">Weak memory models specify the semantics of concurrent programs on multi-core
architectures. Reasoning techniques for weak memory models are often
specialized to one fixed model and verification results are hence not
transferable to other memory models. A recent proposal of a generic
verification technique based on axioms on program behaviour expressed via
weakest preconditions aims at overcoming this specialization to dedicated
models. Due to the usage of weakest preconditions, reasoning however takes
place on a very low level requiring the application of numerous axioms for
deriving program properties, even for a single statement. In this paper, we
lift reasoning in this generic verification approach to a more abstract level.
Based on a view-based assertion language, we provide a number of novel proof
rules for directly reasoning on the level of program constructs. We prove
soundness of our proof rules and exemplify them on the write-to-read causality
(WRC) litmus test. A comparison to the axiom-based low-level proof reveals a
significant reduction in the number of required proof steps.
</p>
</div>
</dd>
<dt><a name="item352">[352]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01437" title="Abstract">arXiv:2309.01437</a> [<a href="/pdf/2309.01437" title="Download PDF">pdf</a>, <a href="/format/2309.01437" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SememeASR: Boosting Performance of End-to-End Speech Recognition against  Domain and Long-Tailed Data Shift with Sememe Semantic Knowledge
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhu%2C+J">Jiaxu Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+C">Changhe Song</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Z">Zhiyong Wu</a>, 
<a href="/search/cs?searchtype=author&query=Meng%2C+H">Helen Meng</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by INTERSPEECH 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Computation and Language (cs.CL); Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">Recently, excellent progress has been made in speech recognition. However,
pure data-driven approaches have struggled to solve the problem in
domain-mismatch and long-tailed data. Considering that knowledge-driven
approaches can help data-driven approaches alleviate their flaws, we introduce
sememe-based semantic knowledge information to speech recognition (SememeASR).
Sememe, according to the linguistic definition, is the minimum semantic unit in
a language and is able to represent the implicit semantic information behind
each word very well. Our experiments show that the introduction of sememe
information can improve the effectiveness of speech recognition. In addition,
our further experiments show that sememe knowledge can improve the model's
recognition of long-tailed data and enhance the model's domain generalization
ability.
</p>
</div>
</dd>
<dt><a name="item353">[353]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01439" title="Abstract">arXiv:2309.01439</a> [<a href="/pdf/2309.01439" title="Download PDF">pdf</a>, <a href="/format/2309.01439" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Large Separable Kernel Attention: Rethinking the Large Kernel Attention  Design in CNN
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lau%2C+K+W">Kin Wai Lau</a>, 
<a href="/search/cs?searchtype=author&query=Po%2C+L">Lai-Man Po</a>, 
<a href="/search/cs?searchtype=author&query=Rehman%2C+Y+A+U">Yasar Abbas Ur Rehman</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Visual Attention Networks (VAN) with Large Kernel Attention (LKA) modules
have been shown to provide remarkable performance, that surpasses Vision
Transformers (ViTs), on a range of vision-based tasks. However, the depth-wise
convolutional layer in these LKA modules incurs a quadratic increase in the
computational and memory footprints with increasing convolutional kernel size.
To mitigate these problems and to enable the use of extremely large
convolutional kernels in the attention modules of VAN, we propose a family of
Large Separable Kernel Attention modules, termed LSKA. LSKA decomposes the 2D
convolutional kernel of the depth-wise convolutional layer into cascaded
horizontal and vertical 1-D kernels. In contrast to the standard LKA design,
the proposed decomposition enables the direct use of the depth-wise
convolutional layer with large kernels in the attention module, without
requiring any extra blocks. We demonstrate that the proposed LSKA module in VAN
can achieve comparable performance with the standard LKA module and incur lower
computational complexity and memory footprints. We also find that the proposed
LSKA design biases the VAN more toward the shape of the object than the texture
with increasing kernel size. Additionally, we benchmark the robustness of the
LKA and LSKA in VAN, ViTs, and the recent ConvNeXt on the five corrupted
versions of the ImageNet dataset that are largely unexplored in the previous
works. Our extensive experimental results show that the proposed LSKA module in
VAN provides a significant reduction in computational complexity and memory
footprints with increasing kernel size while outperforming ViTs, ConvNeXt, and
providing similar performance compared to the LKA module in VAN on object
recognition, object detection, semantic segmentation, and robustness tests.
</p>
</div>
</dd>
<dt><a name="item354">[354]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01441" title="Abstract">arXiv:2309.01441</a> [<a href="/pdf/2309.01441" title="Download PDF">pdf</a>, <a href="/format/2309.01441" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> This Is a Local Domain: On Amassing Country-Code Top-Level Domains from  Public Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sommese%2C+R">Raffaele Sommese</a>, 
<a href="/search/cs?searchtype=author&query=van+Rijswijk-Deij%2C+R">Roland van Rijswijk-Deij</a>, 
<a href="/search/cs?searchtype=author&query=Jonker%2C+M">Mattijs Jonker</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages double-column, 4 figures; submitted to ACM SIGCOMM CCR
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>; Information Retrieval (cs.IR)

</div>
<p class="mathjax">Domain lists are a key ingredient for representative censuses of the Web.
Unfortunately, such censuses typically lack a view on domains under
country-code top-level domains (ccTLDs). This introduces unwanted bias: many
countries have a rich local Web that remains hidden if their ccTLDs are not
considered. The reason ccTLDs are rarely considered is that gaining access --
if possible at all -- is often laborious. To tackle this, we ask: what can we
learn about ccTLDs from public sources? We extract domain names under ccTLDs
from 6 years of public data from Certificate Transparency logs and Common
Crawl. We compare this against ground truth for 19 ccTLDs for which we have the
full DNS zone. We find that public data covers 43%-80% of these ccTLDs, and
that coverage grows over time. By also comparing port scan data we then show
that these public sources reveal a significant part of the Web presence under a
ccTLD. We conclude that in the absence of full access to ccTLDs, domain names
learned from public sources can be a good proxy when performing Web censuses.
</p>
</div>
</dd>
<dt><a name="item355">[355]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01445" title="Abstract">arXiv:2309.01445</a> [<a href="/pdf/2309.01445" title="Download PDF">pdf</a>, <a href="/format/2309.01445" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Why Change My Design: Explaining Poorly Constructed Visualization  Designs with Explorable Explanations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lo%2C+L+Y">Leo Yu-Ho Lo</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+Y">Yifan Cao</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+L">Leni Yang</a>, 
<a href="/search/cs?searchtype=author&query=Qu%2C+H">Huamin Qu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To be presented at IEEE VIS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">Although visualization tools are widely available and accessible, not
everyone knows the best practices and guidelines for creating accurate and
honest visual representations of data. Numerous books and articles have been
written to expose the misleading potential of poorly constructed charts and
teach people how to avoid being deceived by them or making their own mistakes.
These readings use various rhetorical devices to explain the concepts to their
readers. In our analysis of a collection of books, online materials, and a
design workshop, we identified six common explanation methods. To assess the
effectiveness of these methods, we conducted two crowdsourced studies (each
with N = 125) to evaluate their ability to teach and persuade people to make
design changes. In addition to these existing methods, we brought in the idea
of Explorable Explanations, which allows readers to experiment with different
chart settings and observe how the changes are reflected in the visualization.
While we did not find significant differences across explanation methods, the
results of our experiments indicate that, following the exposure to the
explanations, the participants showed improved proficiency in identifying
deceptive charts and were more receptive to proposed alterations of the
visualization design. We discovered that participants were willing to accept
more than 60% of the proposed adjustments in the persuasiveness assessment.
Nevertheless, we found no significant differences among different explanation
methods in convincing participants to accept the modifications.
</p>
</div>
</dd>
<dt><a name="item356">[356]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01446" title="Abstract">arXiv:2309.01446</a> [<a href="/pdf/2309.01446" title="Download PDF">pdf</a>, <a href="/format/2309.01446" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Open Sesame! Universal Black Box Jailbreaking of Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lapid%2C+R">Raz Lapid</a>, 
<a href="/search/cs?searchtype=author&query=Langberg%2C+R">Ron Langberg</a>, 
<a href="/search/cs?searchtype=author&query=Sipper%2C+M">Moshe Sipper</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Computer Vision and Pattern Recognition (cs.CV); Neural and Evolutionary Computing (cs.NE)

</div>
<p class="mathjax">Large language models (LLMs), designed to provide helpful and safe responses,
often rely on alignment techniques to align with user intent and social
guidelines. Unfortunately, this alignment can be exploited by malicious actors
seeking to manipulate an LLM's outputs for unintended purposes. In this paper
we introduce a novel approach that employs a genetic algorithm (GA) to
manipulate LLMs when model architecture and parameters are inaccessible. The GA
attack works by optimizing a universal adversarial prompt that -- when combined
with a user's query -- disrupts the attacked model's alignment, resulting in
unintended and potentially harmful outputs. Our novel approach systematically
reveals a model's limitations and vulnerabilities by uncovering instances where
its responses deviate from expected behavior. Through extensive experiments we
demonstrate the efficacy of our technique, thus contributing to the ongoing
discussion on responsible AI development by providing a diagnostic tool for
evaluating and enhancing alignment of LLMs with human intent. To our knowledge
this is the first automated universal black box jailbreak attack.
</p>
</div>
</dd>
<dt><a name="item357">[357]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01447" title="Abstract">arXiv:2309.01447</a> [<a href="/pdf/2309.01447" title="Download PDF">pdf</a>, <a href="/format/2309.01447" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Experimental method for perching flapping-wing aerial robots
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zufferey%2C+R">Raphael Zufferey</a>, 
<a href="/search/cs?searchtype=author&query=Feliu-Talegon%2C+D">Daniel Feliu-Talegon</a>, 
<a href="/search/cs?searchtype=author&query=Nekoo%2C+S+R">Saeed Rafee Nekoo</a>, 
<a href="/search/cs?searchtype=author&query=Acosta%2C+J">Jose-Angel Acosta</a>, 
<a href="/search/cs?searchtype=author&query=Ollero%2C+A">Anibal Ollero</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> IROS 2022 Workshop: Agile Robotics: Perception, Learning, Planning, and Control, 2022
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">In this work, we present an experimental setup and guide to enable the
perching of large flapping-wing robots. The combination of forward flight,
limited payload, and flight oscillations imposes challenging conditions for
localized perching. The described method details the different operations that
are concurrently performed within the 4 second perching flight. We validate
this experiment with a 700 g ornithopter and demonstrate the first autonomous
perching flight of a flapping-wing robot on a branch. This work paves the way
towards the application of flapping-wing robots for long-range missions, bird
observation, manipulation, and outdoor flight.
</p>
</div>
</dd>
<dt><a name="item358">[358]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01448" title="Abstract">arXiv:2309.01448</a> [<a href="/pdf/2309.01448" title="Download PDF">pdf</a>, <a href="/format/2309.01448" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Hundreds Guide Millions: Adaptive Offline Reinforcement Learning with  Expert Guidance
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+Q">Qisen Yang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Shenzhi Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Q">Qihang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+G">Gao Huang</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+S">Shiji Song</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Offline reinforcement learning (RL) optimizes the policy on a previously
collected dataset without any interactions with the environment, yet usually
suffers from the distributional shift problem. To mitigate this issue, a
typical solution is to impose a policy constraint on a policy improvement
objective. However, existing methods generally adopt a ``one-size-fits-all''
practice, i.e., keeping only a single improvement-constraint balance for all
the samples in a mini-batch or even the entire offline dataset. In this work,
we argue that different samples should be treated with different policy
constraint intensities. Based on this idea, a novel plug-in approach named
Guided Offline RL (GORL) is proposed. GORL employs a guiding network, along
with only a few expert demonstrations, to adaptively determine the relative
importance of the policy improvement and policy constraint for every sample. We
theoretically prove that the guidance provided by our method is rational and
near-optimal. Extensive experiments on various environments suggest that GORL
can be easily installed on most offline RL algorithms with statistically
significant performance improvements.
</p>
</div>
</dd>
<dt><a name="item359">[359]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01452" title="Abstract">arXiv:2309.01452</a> [<a href="/pdf/2309.01452" title="Download PDF">pdf</a>, <a href="/format/2309.01452" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Toward Defensive Letter Design
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kataoka%2C+R">Rentaro Kataoka</a>, 
<a href="/search/cs?searchtype=author&query=Kimura%2C+A">Akisato Kimura</a>, 
<a href="/search/cs?searchtype=author&query=Uchida%2C+S">Seiichi Uchida</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages, 8 figures, accepted at ACPR 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">A major approach for defending against adversarial attacks aims at
controlling only image classifiers to be more resilient, and it does not care
about visual objects, such as pandas and cars, in images. This means that
visual objects themselves cannot take any defensive actions, and they are still
vulnerable to adversarial attacks. In contrast, letters are artificial symbols,
and we can freely control their appearance unless losing their readability. In
other words, we can make the letters more defensive to the attacks. This paper
poses three research questions related to the adversarial vulnerability of
letter images: (1) How defensive are the letters against adversarial attacks?
(2) Can we estimate how defensive a given letter image is before attacks? (3)
Can we control the letter images to be more defensive against adversarial
attacks? For answering the first and second questions, we measure the
defensibility of letters by employing Iterative Fast Gradient Sign Method
(I-FGSM) and then build a deep regression model for estimating the
defensibility of each letter image. We also propose a two-step method based on
a generative adversarial network (GAN) for generating character images with
higher defensibility, which solves the third research question.
</p>
</div>
</dd>
<dt><a name="item360">[360]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01453" title="Abstract">arXiv:2309.01453</a> [<a href="/pdf/2309.01453" title="Download PDF">pdf</a>, <a href="/ps/2309.01453" title="Download PostScript">ps</a>, <a href="/format/2309.01453" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Interactive Graph Convolutional Filtering
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jin Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Lian%2C+D">Defu Lian</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+H">Hong Xie</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yawen Li</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+E">Enhong Chen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Interactive Recommender Systems (IRS) have been increasingly used in various
domains, including personalized article recommendation, social media, and
online advertising. However, IRS faces significant challenges in providing
accurate recommendations under limited observations, especially in the context
of interactive collaborative filtering. These problems are exacerbated by the
cold start problem and data sparsity problem. Existing Multi-Armed Bandit
methods, despite their carefully designed exploration strategies, often
struggle to provide satisfactory results in the early stages due to the lack of
interaction data. Furthermore, these methods are computationally intractable
when applied to non-linear models, limiting their applicability. To address
these challenges, we propose a novel method, the Interactive Graph
Convolutional Filtering model. Our proposed method extends interactive
collaborative filtering into the graph model to enhance the performance of
collaborative filtering between users and items. We incorporate variational
inference techniques to overcome the computational hurdles posed by non-linear
models. Furthermore, we employ Bayesian meta-learning methods to effectively
address the cold-start problem and derive theoretical regret bounds for our
proposed method, ensuring a robust performance guarantee. Extensive
experimental results on three real-world datasets validate our method and
demonstrate its superiority over existing baselines.
</p>
</div>
</dd>
<dt><a name="item361">[361]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01455" title="Abstract">arXiv:2309.01455</a> [<a href="/pdf/2309.01455" title="Download PDF">pdf</a>, <a href="/ps/2309.01455" title="Download PostScript">ps</a>, <a href="/format/2309.01455" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> NumHG: A Dataset for Number-Focused Headline Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+J">Jian-Tao Huang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+C">Chung-Chi Chen</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+H">Hen-Hsen Huang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+H">Hsin-Hsi Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> NumEval@SemEval-2024 Dataset
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Headline generation, a key task in abstractive summarization, strives to
condense a full-length article into a succinct, single line of text. Notably,
while contemporary encoder-decoder models excel based on the ROUGE metric, they
often falter when it comes to the precise generation of numerals in headlines.
We identify the lack of datasets providing fine-grained annotations for
accurate numeral generation as a major roadblock. To address this, we introduce
a new dataset, the NumHG, and provide over 27,000 annotated numeral-rich news
articles for detailed investigation. Further, we evaluate five well-performing
models from previous headline generation tasks using human evaluation in terms
of numerical accuracy, reasonableness, and readability. Our study reveals a
need for improvement in numerical accuracy, demonstrating the potential of the
NumHG dataset to drive progress in number-focused headline generation and
stimulate further discussions in numeral-focused text generation.
</p>
</div>
</dd>
<dt><a name="item362">[362]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01456" title="Abstract">arXiv:2309.01456</a> [<a href="/pdf/2309.01456" title="Download PDF">pdf</a>, <a href="/format/2309.01456" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LLM and Infrastructure as a Code use case
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chanus%2C+T">Thibault Chanus</a> (ENS Rennes), 
<a href="/search/cs?searchtype=author&query=Aubertin%2C+M">Michael Aubertin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> in French language
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Cloud computing and the evolution of management methodologies such as Lean
Management or Agile entail a profound transformation in both system
construction and maintenance approaches. These practices are encompassed within
the term "DevOps." This descriptive approach to an information system or
application, alongside the configuration of its constituent components, has
necessitated the development of descriptive languages paired with specialized
engines for automating systems administration tasks. Among these, the tandem of
Ansible (engine) and YAML (descriptive language) stands out as the two most
prevalent tools in the market, facing notable competition mainly from
Terraform. The current document presents an inquiry into a solution for
generating and managing Ansible YAML roles and playbooks, utilizing Generative
LLMs (Language Models) to translate human descriptions into code. Our efforts
are focused on identifying plausible directions and outlining the potential
industrial applications.
<br />Note: For the purpose of this experiment, we have opted against the use of
Ansible Lightspeed. This is due to its reliance on an IBM Watson model, for
which we have not found any publicly available references. Comprehensive
information regarding this remarkable technology can be found directly on our
partner RedHat's website,
https://www.redhat.com/en/about/press-releases/red-hat-introduces-ansible-lightspeed-ai-driven-it-automation
</p>
</div>
</dd>
<dt><a name="item363">[363]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01457" title="Abstract">arXiv:2309.01457</a> [<a href="/pdf/2309.01457" title="Download PDF">pdf</a>, <a href="/format/2309.01457" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the Consistency and Robustness of Saliency Explanations for Time  Series Classification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Balestra%2C+C">Chiara Balestra</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+B">Bin Li</a>, 
<a href="/search/cs?searchtype=author&query=M%C3%BCller%2C+E">Emmanuel M&#xfc;ller</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Interpretable machine learning and explainable artificial intelligence have
become essential in many applications. The trade-off between interpretability
and model performance is the traitor to developing intrinsic and model-agnostic
interpretation methods. Although model explanation approaches have achieved
significant success in vision and natural language domains, explaining time
series remains challenging. The complex pattern in the feature domain, coupled
with the additional temporal dimension, hinders efficient interpretation.
Saliency maps have been applied to interpret time series windows as images.
However, they are not naturally designed for sequential data, thus suffering
various issues.
<br />This paper extensively analyzes the consistency and robustness of saliency
maps for time series features and temporal attribution. Specifically, we
examine saliency explanations from both perturbation-based and gradient-based
explanation models in a time series classification task. Our experimental
results on five real-world datasets show that they all lack consistent and
robust performances to some extent. By drawing attention to the flawed saliency
explanation models, we motivate to develop consistent and robust explanations
for time series classification.
</p>
</div>
</dd>
<dt><a name="item364">[364]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01458" title="Abstract">arXiv:2309.01458</a> [<a href="/pdf/2309.01458" title="Download PDF">pdf</a>, <a href="/format/2309.01458" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Leveraging Reward Consistency for Interpretable Feature Discovery in  Reinforcement Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+Q">Qisen Yang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Huanqian Wang</a>, 
<a href="/search/cs?searchtype=author&query=Tong%2C+M">Mukun Tong</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+W">Wenjie Shi</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+G">Gao Huang</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+S">Shiji Song</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">The black-box nature of deep reinforcement learning (RL) hinders them from
real-world applications. Therefore, interpreting and explaining RL agents have
been active research topics in recent years. Existing methods for post-hoc
explanations usually adopt the action matching principle to enable an easy
understanding of vision-based RL agents. In this paper, it is argued that the
commonly used action matching principle is more like an explanation of deep
neural networks (DNNs) than the interpretation of RL agents. It may lead to
irrelevant or misplaced feature attribution when different DNNs' outputs lead
to the same rewards or different rewards result from the same outputs.
Therefore, we propose to consider rewards, the essential objective of RL
agents, as the essential objective of interpreting RL agents as well. To ensure
reward consistency during interpretable feature discovery, a novel framework
(RL interpreting RL, denoted as RL-in-RL) is proposed to solve the gradient
disconnection from actions to rewards. We verify and evaluate our method on the
Atari 2600 games as well as Duckietown, a challenging self-driving car
simulator environment. The results show that our method manages to keep reward
(or return) consistency and achieves high-quality feature attribution. Further,
a series of analytical experiments validate our assumption of the action
matching principle's limitations.
</p>
</div>
</dd>
<dt><a name="item365">[365]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01461" title="Abstract">arXiv:2309.01461</a> [<a href="/pdf/2309.01461" title="Download PDF">pdf</a>, <a href="/ps/2309.01461" title="Download PostScript">ps</a>, <a href="/format/2309.01461" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Joint vehicle state and parameters estimation via Twin-in-the-Loop  observers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Dett%C3%B9%2C+F">Federico Dett&#xf9;</a>, 
<a href="/search/eess?searchtype=author&query=Formentin%2C+S">Simone Formentin</a>, 
<a href="/search/eess?searchtype=author&query=Savaresi%2C+S+M">Sergio Matteo Savaresi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Preprint under review at Vehicle Systems Dynamics
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">Vehicular control systems are required to be both extremely reliable and
robust to different environmental conditions, e.g. load or tire-road friction.
In this paper, we extend a new paradigm for state estimation, called
Twin-in-the-Loop filtering (TiL-F), to the estimation of the unknown parameters
describing the vehicle operating conditions. In such an approach, a
digital-twin of the vehicle (usually already available to the car manufacturer)
is employed on-board as a plant replica within a closed-loop scheme, and the
observer gains are tuned purely from experimental data. The proposed approach
is validated against experimental data, showing to significantly outperform the
state-of-the-art solutions.
</p>
</div>
</dd>
<dt><a name="item366">[366]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01463" title="Abstract">arXiv:2309.01463</a> [<a href="/pdf/2309.01463" title="Download PDF">pdf</a>, <a href="/format/2309.01463" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Mutual Witness Proximity Drawings of Isomorphic Trees
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Haase%2C+C">Carolina Haase</a>, 
<a href="/search/cs?searchtype=author&query=Kindermann%2C+P">Philipp Kindermann</a>, 
<a href="/search/cs?searchtype=author&query=Lenhart%2C+W+J">William J. Lenhart</a>, 
<a href="/search/cs?searchtype=author&query=Liotta%2C+G">Giuseppe Liotta</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Appears in the Proceedings of the 31st International Symposium on Graph Drawing and Network Visualization (GD 2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Geometry (cs.CG)</span>

</div>
<p class="mathjax">A pair $\langle G_0, G_1 \rangle$ of graphs admits a mutual witness proximity
drawing $\langle \Gamma_0, \Gamma_1 \rangle$ when: (i) $\Gamma_i$ represents
$G_i$, and (ii) there is an edge $(u,v)$ in $\Gamma_i$ if and only if there is
no vertex $w$ in $\Gamma_{1-i}$ that is ``too close'' to both $u$ and $v$
($i=0,1$). In this paper, we consider infinitely many definitions of closeness
by adopting the $\beta$-proximity rule for any $\beta \in [1,\infty]$ and study
pairs of isomorphic trees that admit a mutual witness $\beta$-proximity
drawing. Specifically, we show that every two isomorphic trees admit a mutual
witness $\beta$-proximity drawing for any $\beta \in [1,\infty]$. The
constructive technique can be made ``robust'': For some tree pairs we can
suitably prune linearly many leaves from one of the two trees and still retain
their mutual witness $\beta$-proximity drawability. Notably, in the special
case of isomorphic caterpillars and $\beta=1$, we construct linearly separable
mutual witness Gabriel drawings.
</p>
</div>
</dd>
<dt><a name="item367">[367]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01466" title="Abstract">arXiv:2309.01466</a> [<a href="/pdf/2309.01466" title="Download PDF">pdf</a>, <a href="/ps/2309.01466" title="Download PostScript">ps</a>, <a href="/format/2309.01466" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Communication Lower Bounds for Cryptographic Broadcast Protocols
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Blum%2C+E">Erica Blum</a>, 
<a href="/search/cs?searchtype=author&query=Boyle%2C+E">Elette Boyle</a>, 
<a href="/search/cs?searchtype=author&query=Cohen%2C+R">Ran Cohen</a>, 
<a href="/search/cs?searchtype=author&query=Liu-Zhang%2C+C">Chen-Da Liu-Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> A preliminary version of this work appeared in DISC 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Distributed, Parallel, and Cluster Computing (cs.DC)

</div>
<p class="mathjax">Broadcast protocols enable a set of $n$ parties to agree on the input of a
designated sender, even facing attacks by malicious parties. In the
honest-majority setting, randomization and cryptography were harnessed to
achieve low-communication broadcast with sub-quadratic total communication and
balanced sub-linear cost per party. However, comparatively little is known in
the dishonest-majority setting. Here, the most communication-efficient
constructions are based on Dolev and Strong (SICOMP '83), and sub-quadratic
broadcast has not been achieved. On the other hand, the only nontrivial
$\omega(n)$ communication lower bounds are restricted to deterministic
protocols, or against strong adaptive adversaries that can perform "after the
fact" removal of messages.
<br />We provide new communication lower bounds in this space, which hold against
arbitrary cryptography and setup assumptions, as well as a simple protocol
showing near tightness of our first bound.
<br />1) We demonstrate a tradeoff between resiliency and communication for
protocols secure against $n-o(n)$ static corruptions. For example,
$\Omega(n\cdot {\sf polylog}(n))$ messages are needed when the number of honest
parties is $n/{\sf polylog}(n)$; $\Omega(n\sqrt{n})$ messages are needed for
$O(\sqrt{n})$ honest parties; and $\Omega(n^2)$ messages are needed for $O(1)$
honest parties.
<br />Complementarily, we demonstrate broadcast with $O(n\cdot{\sf polylog}(n))$
total communication facing any constant fraction of static corruptions.
<br />2) Our second bound considers $n/2 + k$ corruptions and a weakly adaptive
adversary that cannot remove messages "after the fact." We show that any
broadcast protocol within this setting can be attacked to force an arbitrary
party to send messages to $k$ other parties. This rules out, for example,
broadcast facing 51% corruptions in which all non-sender parties have sublinear
communication locality.
</p>
</div>
</dd>
<dt><a name="item368">[368]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01469" title="Abstract">arXiv:2309.01469</a> [<a href="/pdf/2309.01469" title="Download PDF">pdf</a>, <a href="/format/2309.01469" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Defect Detection in Synthetic Fibre Ropes using Detectron2 Framework
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rani%2C+A">Anju Rani</a>, 
<a href="/search/cs?searchtype=author&query=Arroyo%2C+D+O">Daniel O. Arroyo</a>, 
<a href="/search/cs?searchtype=author&query=Durdevic%2C+P">Petar Durdevic</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 7 figures, 4 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Fibre ropes with the latest technology have emerged as an appealing
alternative to steel ropes for offshore industries due to their lightweight and
high tensile strength. At the same time, frequent inspection of these ropes is
essential to ensure the proper functioning and safety of the entire system. The
development of deep learning (DL) models in condition monitoring (CM)
applications offers a simpler and more effective approach for defect detection
in synthetic fibre ropes (SFRs). The present paper investigates the performance
of Detectron2, a state-of-the-art library for defect detection and instance
segmentation. Detectron2 with Mask R-CNN architecture is used for segmenting
defects in SFRs. Mask R-CNN with various backbone configurations has been
trained and tested on an experimentally obtained dataset comprising 1,803
high-dimensional images containing seven damage classes (loop high, loop
medium, loop low, compression, core out, abrasion, and normal respectively) for
SFRs. By leveraging the capabilities of Detectron2, this study aims to develop
an automated and efficient method for detecting defects in SFRs, enhancing the
inspection process, and ensuring the safety of the fibre ropes.
</p>
</div>
</dd>
<dt><a name="item369">[369]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01472" title="Abstract">arXiv:2309.01472</a> [<a href="/pdf/2309.01472" title="Download PDF">pdf</a>, <a href="/format/2309.01472" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FinDiff: Diffusion Models for Financial Tabular Data Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sattarov%2C+T">Timur Sattarov</a>, 
<a href="/search/cs?searchtype=author&query=Schreyer%2C+M">Marco Schreyer</a>, 
<a href="/search/cs?searchtype=author&query=Borth%2C+D">Damian Borth</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages, 5 figures, 3 tables, preprint version, currently under review
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Statistical Finance (q-fin.ST)

</div>
<p class="mathjax">The sharing of microdata, such as fund holdings and derivative instruments,
by regulatory institutions presents a unique challenge due to strict data
confidentiality and privacy regulations. These challenges often hinder the
ability of both academics and practitioners to conduct collaborative research
effectively. The emergence of generative models, particularly diffusion models,
capable of synthesizing data mimicking the underlying distributions of
real-world data presents a compelling solution. This work introduces 'FinDiff',
a diffusion model designed to generate real-world financial tabular data for a
variety of regulatory downstream tasks, for example economic scenario modeling,
stress tests, and fraud detection. The model uses embedding encodings to model
mixed modality financial data, comprising both categorical and numeric
attributes. The performance of FinDiff in generating synthetic tabular
financial data is evaluated against state-of-the-art baseline models using
three real-world financial datasets (including two publicly available datasets
and one proprietary dataset). Empirical results demonstrate that FinDiff excels
in generating synthetic tabular financial data with high fidelity, privacy, and
utility.
</p>
</div>
</dd>
<dt><a name="item370">[370]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01479" title="Abstract">arXiv:2309.01479</a> [<a href="/pdf/2309.01479" title="Download PDF">pdf</a>, <a href="/format/2309.01479" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Parameter and Computation Efficient Transfer Learning for  Vision-Language Pre-trained Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+Q">Qiong Wu</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+W">Wei Yu</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Y">Yiyi Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+S">Shubin Huang</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+X">Xiaoshuai Sun</a>, 
<a href="/search/cs?searchtype=author&query=Ji%2C+R">Rongrong Ji</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">With ever increasing parameters and computation, vision-language pre-trained
(VLP) models exhibit prohibitive expenditure in downstream task adaption.
Recent endeavors mainly focus on parameter efficient transfer learning (PETL)
for VLP models by only updating a small number of parameters. However,
excessive computational overhead still plagues the application of VLPs. In this
paper, we aim at parameter and computation efficient transfer learning (PCETL)
for VLP models. In particular, PCETL not only needs to limit the number of
trainable parameters in VLP models, but also to reduce the computational
redundancy during inference, thus enabling a more efficient transfer. To
approach this target, we propose a novel dynamic architecture skipping (DAS)
approach towards effective PCETL. Instead of directly optimizing the intrinsic
architectures of VLP models, DAS first observes the significances of their
modules to downstream tasks via a reinforcement learning (RL) based process,
and then skips the redundant ones with lightweight networks, i.e., adapters,
according to the obtained rewards. In this case, the VLP model can well
maintain the scale of trainable parameters while speeding up its inference on
downstream tasks. To validate DAS, we apply it to two representative VLP
models, namely ViLT and METER, and conduct extensive experiments on a bunch of
VL tasks. The experimental results not only show the great advantages of DAS in
reducing computational complexity, e.g. -11.97% FLOPs of METER on VQA2.0, but
also confirm its competitiveness against existing PETL methods in terms of
parameter scale and performance. Our source code is given in our appendix.
</p>
</div>
</dd>
<dt><a name="item371">[371]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01480" title="Abstract">arXiv:2309.01480</a> [<a href="/pdf/2309.01480" title="Download PDF">pdf</a>, <a href="/format/2309.01480" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> BadSQA: Stealthy Backdoor Attacks Using Presence Events as Triggers in  Non-Intrusive Speech Quality Assessment
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ren%2C+Y">Ying Ren</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+K">Kailai Shen</a>, 
<a href="/search/cs?searchtype=author&query=Ye%2C+Z">Zhe Ye</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+D">Diqun Yan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages, 6 figures,conference
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Artificial Intelligence (cs.AI); Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">Non-Intrusive speech quality assessment (NISQA) has gained significant
attention for predicting the mean opinion score (MOS) of speech without
requiring the reference speech. In practical NISQA scenarios, untrusted
third-party resources are often employed during deep neural network training to
reduce costs. However, it would introduce a potential security vulnerability as
specially designed untrusted resources can launch backdoor attacks against
NISQA systems. Existing backdoor attacks primarily focus on classification
tasks and are not directly applicable to NISQA which is a regression task. In
this paper, we propose a novel backdoor attack on NISQA tasks, leveraging
presence events as triggers to achieving highly stealthy attacks. To evaluate
the effectiveness of our proposed approach, we conducted experiments on four
benchmark datasets and employed two state-of-the-art NISQA models. The results
demonstrate that the proposed backdoor attack achieved an average attack
success rate of up to 99% with a poisoning rate of only 3%.
</p>
</div>
</dd>
<dt><a name="item372">[372]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01483" title="Abstract">arXiv:2309.01483</a> [<a href="/pdf/2309.01483" title="Download PDF">pdf</a>, <a href="/format/2309.01483" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CA2: Class-Agnostic Adaptive Feature Adaptation for One-class  Classification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zilong Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Z">Zhibin Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Meng%2C+D">Deyu Meng</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xingwu Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+X">Xuefeng Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submit to AAAI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">One-class classification (OCC), i.e., identifying whether an example belongs
to the same distribution as the training data, is essential for deploying
machine learning models in the real world. Adapting the pre-trained features on
the target dataset has proven to be a promising paradigm for improving OCC
performance. Existing methods are constrained by assumptions about the number
of classes. This contradicts the real scenario where the number of classes is
unknown. In this work, we propose a simple class-agnostic adaptive feature
adaptation method (CA2). We generalize the center-based method to unknown
classes and optimize this objective based on the prior existing in the
pre-trained network, i.e., pre-trained features that belong to the same class
are adjacent. CA2 is validated to consistently improve OCC performance across a
spectrum of training data classes, spanning from 1 to 1024, outperforming
current state-of-the-art methods. Code is available at
https://github.com/zhangzilongc/CA2.
</p>
</div>
</dd>
<dt><a name="item373">[373]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01487" title="Abstract">arXiv:2309.01487</a> [<a href="/pdf/2309.01487" title="Download PDF">pdf</a>, <a href="/format/2309.01487" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GenSelfDiff-HIS: Generative Self-Supervision Using Diffusion for  Histopathological Image Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Purma%2C+V">Vishnuvardhan Purma</a>, 
<a href="/search/cs?searchtype=author&query=Srinath%2C+S">Suhas Srinath</a>, 
<a href="/search/cs?searchtype=author&query=Srirangarajan%2C+S">Seshan Srirangarajan</a>, 
<a href="/search/cs?searchtype=author&query=Kakkar%2C+A">Aanchal Kakkar</a>, 
<a href="/search/cs?searchtype=author&query=P%2C+P+A">Prathosh A.P</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Histopathological image segmentation is a laborious and time-intensive task,
often requiring analysis from experienced pathologists for accurate
examinations. To reduce this burden, supervised machine-learning approaches
have been adopted using large-scale annotated datasets for histopathological
image analysis. However, in several scenarios, the availability of large-scale
annotated data is a bottleneck while training such models. Self-supervised
learning (SSL) is an alternative paradigm that provides some respite by
constructing models utilizing only the unannotated data which is often
abundant. The basic idea of SSL is to train a network to perform one or many
pseudo or pretext tasks on unannotated data and use it subsequently as the
basis for a variety of downstream tasks. It is seen that the success of SSL
depends critically on the considered pretext task. While there have been many
efforts in designing pretext tasks for classification problems, there haven't
been many attempts on SSL for histopathological segmentation. Motivated by
this, we propose an SSL approach for segmenting histopathological images via
generative diffusion models in this paper. Our method is based on the
observation that diffusion models effectively solve an image-to-image
translation task akin to a segmentation task. Hence, we propose generative
diffusion as the pretext task for histopathological image segmentation. We also
propose a multi-loss function-based fine-tuning for the downstream task. We
validate our method using several metrics on two publically available datasets
along with a newly proposed head and neck (HN) cancer dataset containing
hematoxylin and eosin (H\&amp;E) stained images along with annotations. Codes will
be made public at
https://github.com/PurmaVishnuVardhanReddy/GenSelfDiff-HIS.git.
</p>
</div>
</dd>
<dt><a name="item374">[374]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01488" title="Abstract">arXiv:2309.01488</a> [<a href="/pdf/2309.01488" title="Download PDF">pdf</a>, <a href="/format/2309.01488" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the use of Mahalanobis distance for out-of-distribution detection  with neural networks for medical imaging
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Anthony%2C+H">Harry Anthony</a>, 
<a href="/search/cs?searchtype=author&query=Kamnitsas%2C+K">Konstantinos Kamnitsas</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted for the Uncertainty for Safe Utilization of Machine Learning in Medical Imaging (UNSURE 2023) workshop at the MICCAI 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Implementing neural networks for clinical use in medical applications
necessitates the ability for the network to detect when input data differs
significantly from the training data, with the aim of preventing unreliable
predictions. The community has developed several methods for
out-of-distribution (OOD) detection, within which distance-based approaches -
such as Mahalanobis distance - have shown potential. This paper challenges the
prevailing community understanding that there is an optimal layer, or
combination of layers, of a neural network for applying Mahalanobis distance
for detection of any OOD pattern. Using synthetic artefacts to emulate OOD
patterns, this paper shows the optimum layer to apply Mahalanobis distance
changes with the type of OOD pattern, showing there is no one-fits-all
solution. This paper also shows that separating this OOD detector into multiple
detectors at different depths of the network can enhance the robustness for
detecting different OOD patterns. These insights were validated on real-world
OOD tasks, training models on CheXpert chest X-rays with no support devices,
then using scans with unseen pacemakers (we manually labelled 50% of CheXpert
for this research) and unseen sex as OOD cases. The results inform
best-practices for the use of Mahalanobis distance for OOD detection. The
manually annotated pacemaker labels and the project's code are available at:
https://github.com/HarryAnthony/Mahalanobis-OOD-detection.
</p>
</div>
</dd>
<dt><a name="item375">[375]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01490" title="Abstract">arXiv:2309.01490</a> [<a href="/pdf/2309.01490" title="Download PDF">pdf</a>, <a href="/format/2309.01490" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Adaptive Maximum Power Transfer for Movable device in Wireless Power  Transfer system
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Jun-Kim%2C+D">Dong Jun-Kim</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10pages, 10 figures, 3 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">More and more applications are adopting the charging topology of wireless
power transmission. However, most wireless charging systems can not charge
mobile devices which are moving in position while charging. Currently, many
commercialized wireless charging systems adopt an inductive coupling method,
which has very short charging distances. In addition, the frequency of the two
coupled coils that produce maximum power transfer keeps varying, depending on
the coupling coefficient that relies on the separation between coils, and this
tendency becomes more severe when the coupling is strengthened at a close
charging distance by the phenomenon called frequency splitting. Therefore, the
existing wireless power transmission system using a fixed operating frequency
can not optimize power transmission for a fluctuating charging environment as
the coupling between coils changes, and charging efficiency is greatly reduced
by frequency splitting when charging at a very short distance. To solve this
problem, we proposed the method of estimating the RX side power and mutual
inductance using the information from the TX side such as input impedance
rather than using a direct communication link which adds more cost and
complexity. Also, we derived a mathematical model for the above estimation
method. To prove this mathematical model, the proposed wireless power
transmission system was implemented in a SIMULINK environment, and the system
model was validated through simulation. Also comparison between the adaptive
frequency tracking method and static impedance matching circuit is made by
analyzing simulation results.
</p>
</div>
</dd>
<dt><a name="item376">[376]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01494" title="Abstract">arXiv:2309.01494</a> [<a href="/pdf/2309.01494" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Productive Development of Scalable Network Functions with NFork
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yan%2C+L">Lei Yan</a> (1), 
<a href="/search/cs?searchtype=author&query=Pan%2C+Y">Yueyang Pan</a> (1), 
<a href="/search/cs?searchtype=author&query=Zhou%2C+D">Diyu Zhou</a> (1), 
<a href="/search/cs?searchtype=author&query=Kashyap%2C+S">Sanidhya Kashyap</a> (1), 
<a href="/search/cs?searchtype=author&query=Candea%2C+G">George Candea</a> (1) ((1) EPFL)
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 pages, 8 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>

</div>
<p class="mathjax">Despite decades of research, developing correct and scalable concurrent
programs is still challenging. Network functions (NFs) are not an exception.
This paper presents NFork, a system that helps NF domain experts to
productively develop concurrent NFs by abstracting away concurrency from
developers. The key scheme behind NFork's design is to exploit NF
characteristics to overcome the limitations of prior work on concurrency
programming. Developers write NFs as sequential programs, and during runtime,
NFork performs transparent parallelization by processing packets in different
cores. Exploiting NF characteristics, NFork leverages transactional memory and
develops efficient concurrent data structures to achieve scalability and
guarantee the absence of concurrency bugs.
<br />Since NFork manages concurrency, it further provides (i) a profiler that
reveals the root causes of scalability bottlenecks inherent to the NF's
semantics and (ii) actionable recipes for developers to mitigate these root
causes by relaxing the NF's semantics. We show that NFs developed with NFork
achieve competitive scalability with those in Cisco VPP [16], and NFork's
profiler and recipes can effectively aid developers in optimizing NF
scalability.
</p>
</div>
</dd>
<dt><a name="item377">[377]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01503" title="Abstract">arXiv:2309.01503</a> [<a href="/pdf/2309.01503" title="Download PDF">pdf</a>, <a href="/format/2309.01503" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Layer-wise training for self-supervised learning on graphs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pina%2C+O">Oscar Pina</a>, 
<a href="/search/cs?searchtype=author&query=Vilaplana%2C+V">Ver&#xf3;nica Vilaplana</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">End-to-end training of graph neural networks (GNN) on large graphs presents
several memory and computational challenges, and limits the application to
shallow architectures as depth exponentially increases the memory and space
complexities. In this manuscript, we propose Layer-wise Regularized Graph
Infomax, an algorithm to train GNNs layer by layer in a self-supervised manner.
We decouple the feature propagation and feature transformation carried out by
GNNs to learn node representations in order to derive a loss function based on
the prediction of future inputs. We evaluate the algorithm in inductive large
graphs and show similar performance to other end to end methods and a
substantially increased efficiency, which enables the training of more
sophisticated models in one single device. We also show that our algorithm
avoids the oversmoothing of the representations, another common challenge of
deep GNNs.
</p>
</div>
</dd>
<dt><a name="item378">[378]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01507" title="Abstract">arXiv:2309.01507</a> [<a href="/pdf/2309.01507" title="Download PDF">pdf</a>, <a href="/format/2309.01507" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Memory Efficient Optimizers with 4-bit States
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+B">Bingrui Li</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Jianfei Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+J">Jun Zhu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 36 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Optimizer states are a major source of memory consumption for training neural
networks, limiting the maximum trainable model within given memory budget.
Compressing the optimizer states from 32-bit floating points to lower bitwidth
is promising to reduce the training memory footprint, while the current lowest
achievable bitwidth is 8-bit. In this work, we push optimizer states bitwidth
down to 4-bit through a detailed empirical analysis of first and second order
momentums. Specifically, we find that momentums have complicated outlier
patterns, that current block-wise quantization cannot accurately approximate.
We use a smaller block size and propose to utilize both row-wise and
column-wise information for better quantization. We further identify a zero
point problem of quantizing the second-order momentum, and solve this problem
with a linear quantizer that excludes the zero point. Our 4-bit optimizer is
evaluated on a wide variety of benchmarks including natural language
understanding, machine translation, image classification, and instruction
tuning. On all the tasks our optimizers can achieve comparable accuracy with
their full-precision counterparts, while enjoying better memory efficiency.
</p>
</div>
</dd>
<dt><a name="item379">[379]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01512" title="Abstract">arXiv:2309.01512</a> [<a href="/pdf/2309.01512" title="Download PDF">pdf</a>, <a href="/format/2309.01512" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Neural Vector Fields: Generalizing Distance Vector Fields by Codebooks  and Zero-Curl Regularization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+X">Xianghui Yang</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+G">Guosheng Lin</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Z">Zhenghao Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+L">Luping Zhou</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Recent neural networks based surface reconstruction can be roughly divided
into two categories, one warping templates explicitly and the other
representing 3D surfaces implicitly. To enjoy the advantages of both, we
propose a novel 3D representation, Neural Vector Fields (NVF), which adopts the
explicit learning process to manipulate meshes and implicit unsigned distance
function (UDF) representation to break the barriers in resolution and topology.
This is achieved by directly predicting the displacements from surface queries
and modeling shapes as Vector Fields, rather than relying on network
differentiation to obtain direction fields as most existing UDF-based methods
do. In this way, our approach is capable of encoding both the distance and the
direction fields so that the calculation of direction fields is
differentiation-free, circumventing the non-trivial surface extraction step.
Furthermore, building upon NVFs, we propose to incorporate two types of shape
codebooks, \ie, NVFs (Lite or Ultra), to promote cross-category reconstruction
through encoding cross-object priors. Moreover, we propose a new regularization
based on analyzing the zero-curl property of NVFs, and implement this through
the fully differentiable framework of our NVF (ultra). We evaluate both NVFs on
four surface reconstruction scenarios, including watertight vs non-watertight
shapes, category-agnostic reconstruction vs category-unseen reconstruction,
category-specific, and cross-domain reconstruction.
</p>
</div>
</dd>
<dt><a name="item380">[380]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01515" title="Abstract">arXiv:2309.01515</a> [<a href="/pdf/2309.01515" title="Download PDF">pdf</a>, <a href="/format/2309.01515" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Federated cINN Clustering for Accurate Clustered Federated Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Y">Yuhao Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+M">Minjia Shi</a>, 
<a href="/search/cs?searchtype=author&query=Tian%2C+Y">Yuxin Tian</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yuanxi Li</a>, 
<a href="/search/cs?searchtype=author&query=Ye%2C+Q">Qing Ye</a>, 
<a href="/search/cs?searchtype=author&query=Lv%2C+J">Jiancheng Lv</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Federated Learning (FL) presents an innovative approach to privacy-preserving
distributed machine learning and enables efficient crowd intelligence on a
large scale. However, a significant challenge arises when coordinating FL with
crowd intelligence which diverse client groups possess disparate objectives due
to data heterogeneity or distinct tasks. To address this challenge, we propose
the Federated cINN Clustering Algorithm (FCCA) to robustly cluster clients into
different groups, avoiding mutual interference between clients with data
heterogeneity, and thereby enhancing the performance of the global model.
Specifically, FCCA utilizes a global encoder to transform each client's private
data into multivariate Gaussian distributions. It then employs a generative
model to learn encoded latent features through maximum likelihood estimation,
which eases optimization and avoids mode collapse. Finally, the central server
collects converged local models to approximate similarities between clients and
thus partition them into distinct clusters. Extensive experimental results
demonstrate FCCA's superiority over other state-of-the-art clustered federated
learning algorithms, evaluated on various models and datasets. These results
suggest that our approach has substantial potential to enhance the efficiency
and accuracy of real-world federated learning tasks.
</p>
</div>
</dd>
<dt><a name="item381">[381]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01516" title="Abstract">arXiv:2309.01516</a> [<a href="/pdf/2309.01516" title="Download PDF">pdf</a>, <a href="/format/2309.01516" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MultiWay-Adapater: Adapting large-scale multi-modal models for scalable  image-text retrieval
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Long%2C+Z">Zijun Long</a>, 
<a href="/search/cs?searchtype=author&query=Killick%2C+G">George Killick</a>, 
<a href="/search/cs?searchtype=author&query=McCreadie%2C+R">Richard McCreadie</a>, 
<a href="/search/cs?searchtype=author&query=Camarasa%2C+G+A">Gerardo Aragon Camarasa</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Multimedia (cs.MM)

</div>
<p class="mathjax">As the size of Large Multi-Modal Models (LMMs) increases consistently, the
adaptation of these pre-trained models to specialized tasks has become a
computationally and memory-intensive challenge. Traditional fine-tuning methods
require isolated, exhaustive retuning for each new task, limiting the models'
versatility. Moreover, current efficient adaptation techniques often overlook
modality alignment, focusing only on the knowledge extraction of new tasks. To
tackle these issues, we introduce Multiway-Adapter, an innovative framework
incorporating an 'Alignment Enhancer' to deepen modality alignment, enabling
high transferability without tuning pre-trained parameters. Our method adds
fewer than 1.25\% of additional parameters to LMMs, exemplified by the BEiT-3
model in our study. This leads to superior zero-shot image-text retrieval
performance compared to fully fine-tuned models, while achieving up to a 57\%
reduction in fine-tuning time. Our approach offers a resource-efficient and
effective adaptation pathway for LMMs, broadening their applicability. The
source code is publicly available at:
\url{https://github.com/longkukuhi/MultiWay-Adapter}.
</p>
</div>
</dd>
<dt><a name="item382">[382]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01519" title="Abstract">arXiv:2309.01519</a> [<a href="/pdf/2309.01519" title="Download PDF">pdf</a>, <a href="/format/2309.01519" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Hawkeye: Change-targeted Testing for Android Apps based on Deep  Reinforcement Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Peng%2C+C">Chao Peng</a>, 
<a href="/search/cs?searchtype=author&query=Lv%2C+Z">Zhengwei Lv</a>, 
<a href="/search/cs?searchtype=author&query=Fu%2C+J">Jiarong Fu</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+J">Jiayuan Liang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zhao Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Rajan%2C+A">Ajitha Rajan</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+P">Ping Yang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Android Apps are frequently updated to keep up with changing user, hardware,
and business demands. Ensuring the correctness of App updates through extensive
testing is crucial to avoid potential bugs reaching the end user. Existing
Android testing tools generate GUI events focussing on improving the test
coverage of the entire App rather than prioritising updates and its impacted
elements. Recent research has proposed change-focused testing but relies on
random exploration to exercise the updates and impacted GUI elements that is
ineffective and slow for large complex Apps with a huge input exploration
space. We propose directed testing of App updates with Hawkeye that is able to
prioritise executing GUI actions associated with code changes based on deep
reinforcement learning from historical exploration data. Our empirical
evaluation compares Hawkeye with state-of-the-art model-based and reinforcement
learning-based testing tools FastBot2 and ARES using 10 popular open-source and
1 commercial App. We find that Hawkeye is able to generate GUI event sequences
targeting changed functions more reliably than FastBot2 and ARES for the open
source Apps and the large commercial App. Hawkeye achieves comparable
performance on smaller open source Apps with a more tractable exploration
space. The industrial deployment of Hawkeye in the development pipeline also
shows that Hawkeye is ideal to perform smoke testing for merge requests of a
complicated commercial App.
</p>
</div>
</dd>
<dt><a name="item383">[383]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01522" title="Abstract">arXiv:2309.01522</a> [<a href="/pdf/2309.01522" title="Download PDF">pdf</a>, <a href="/format/2309.01522" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> What are Public Concerns about ChatGPT? A Novel Self-Supervised Neural  Topic Model Tells You
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+R">Rui Wang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xing Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yanan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+H">Haiping Huang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">The recently released artificial intelligence conversational agent, ChatGPT,
has gained significant attention in academia and real life. A multitude of
early ChatGPT users eagerly explore its capabilities and share their opinions
on it via social media. Both user queries and social media posts express public
concerns regarding this advanced dialogue system. To mine public concerns about
ChatGPT, a novel Self-Supervised neural Topic Model (SSTM), which formalizes
topic modeling as a representation learning procedure, is proposed in this
paper. Extensive experiments have been conducted on Twitter posts about ChatGPT
and queries asked by ChatGPT users. And experimental results demonstrate that
the proposed approach could extract higher quality public concerns with
improved interpretability and diversity, surpassing the performance of
state-of-the-art approaches.
</p>
</div>
</dd>
<dt><a name="item384">[384]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01523" title="Abstract">arXiv:2309.01523</a> [<a href="/pdf/2309.01523" title="Download PDF">pdf</a>, <a href="/format/2309.01523" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Blackbox Model Is All You Need to Breach Privacy: Smart Grid  Forecasting Models as a Use Case
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Aly%2C+H">Hussein Aly</a>, 
<a href="/search/cs?searchtype=author&query=Al-Ali%2C+A">Abdulaziz Al-Ali</a>, 
<a href="/search/cs?searchtype=author&query=Al-Ali%2C+A">Abdullah Al-Ali</a>, 
<a href="/search/cs?searchtype=author&query=Malluhi%2C+Q">Qutaibah Malluhi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Cryptography and Security (cs.CR)

</div>
<p class="mathjax">This paper investigates the potential privacy risks associated with
forecasting models, with specific emphasis on their application in the context
of smart grids. While machine learning and deep learning algorithms offer
valuable utility, concerns arise regarding their exposure of sensitive
information. Previous studies have focused on classification models,
overlooking risks associated with forecasting models. Deep learning based
forecasting models, such as Long Short Term Memory (LSTM), play a crucial role
in several applications including optimizing smart grid systems but also
introduce privacy risks. Our study analyzes the ability of forecasting models
to leak global properties and privacy threats in smart grid systems. We
demonstrate that a black box access to an LSTM model can reveal a significant
amount of information equivalent to having access to the data itself (with the
difference being as low as 1% in Area Under the ROC Curve). This highlights the
importance of protecting forecasting models at the same level as the data.
</p>
</div>
</dd>
<dt><a name="item385">[385]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01524" title="Abstract">arXiv:2309.01524</a> [<a href="/pdf/2309.01524" title="Download PDF">pdf</a>, <a href="/format/2309.01524" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Input Redundancy under Input and State Constraints (Extended version of  the submission accepted to Automatica)
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Tr%C3%A9gou%C3%ABt%2C+J">Jean-Fran&#xe7;ois Tr&#xe9;gou&#xeb;t</a>, 
<a href="/search/eess?searchtype=author&query=Kreiss%2C+J">J&#xe9;r&#xe9;mie Kreiss</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">For a given unconstrained dynamical system, input redundancy has been
recently redefined as the existence of distinct inputs producing identical
output for the same initial state. By directly referring to signals, this
definition readily applies to any input-to-output mapping. As an illustration
of this potentiality, this paper tackles the case where input and state
constraints are imposed on the system. This context is indeed of foremost
importance since input redundancy has been historically regarded as a way to
deal with input saturations. An example illustrating how constraints can
challenge redundancy is offered right at the outset. A more complex
phenomenology is highlighted. This motivates the enrichment of the existing
framework on redundancy. Then, a sufficient condition for redundancy to be
preserved when imposing constraints is offered in the most general context of
arbitrary constraints. It is shown that redundancy can be destroyed only when
input and state trajectories lie on the border of the set of constraints almost
all the time. Finally, those results are specialized and expanded under the
assumption that input and state constraints are linear.
</p>
</div>
</dd>
<dt><a name="item386">[386]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01525" title="Abstract">arXiv:2309.01525</a> [<a href="/pdf/2309.01525" title="Download PDF">pdf</a>, <a href="/format/2309.01525" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The History of Quantum Games
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Piispanen%2C+L">Laura Piispanen</a>, 
<a href="/search/cs?searchtype=author&query=Morrell%2C+E">Edward Morrell</a>, 
<a href="/search/cs?searchtype=author&query=Park%2C+S">Solip Park</a>, 
<a href="/search/cs?searchtype=author&query=Pfaffhauser%2C+M">Marcell Pfaffhauser</a>, 
<a href="/search/cs?searchtype=author&query=Kultima%2C+A">Annakaisa Kultima</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, from which 1.5 pages of references, 11 figures, one table, presented in the IEEE Conference on Games 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">General Literature (cs.GL)</span>; Quantum Physics (quant-ph)

</div>
<p class="mathjax">In this paper, we explore the historical development of playable quantum
physics related games (\textit{\textbf{quantum games}}). For the purpose of
this examination, we have collected over 260 quantum games ranging from
commercial games, applied and serious games, and games that have been developed
at quantum themed game jams and educational courses. We provide an overview of
the journey of quantum games across three dimensions: \textit{the perceivable
dimension of quantum physics, the dimension of scientific purposes, and the
dimension of quantum technologies}. We then further reflect on the definition
of quantum games and its implications. While motivations behind developing
quantum games have typically been educational or academic, themes related to
quantum physics have begun to be more broadly utilised across a range of
commercial games. In addition, as the availability of quantum computer hardware
has grown, entirely new variants of quantum games have emerged to take
advantage of these machines' inherent capabilities, \textit{quantum computer
games}
</p>
</div>
</dd>
<dt><a name="item387">[387]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01526" title="Abstract">arXiv:2309.01526</a> [<a href="/pdf/2309.01526" title="Download PDF">pdf</a>, <a href="/format/2309.01526" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Passing Heatmap Prediction Based on Transformer Model and Tracking Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pei%2C+Y">Yisheng Pei</a>, 
<a href="/search/cs?searchtype=author&query=De+Silva%2C+V">Varuna De Silva</a>, 
<a href="/search/cs?searchtype=author&query=Caine%2C+M">Mike Caine</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Although the data-driven analysis of football players' performance has been
developed for years, most research only focuses on the on-ball event including
shots and passes, while the off-ball movement remains a little-explored area in
this domain. Players' contributions to the whole match are evaluated unfairly,
those who have more chances to score goals earn more credit than others, while
the indirect and unnoticeable impact that comes from continuous movement has
been ignored. This research presents a novel deep-learning network architecture
which is capable to predict the potential end location of passes and how
players' movement before the pass affects the final outcome. Once analysed more
than 28,000 pass events, a robust prediction can be achieved with more than 0.7
Top-1 accuracy. And based on the prediction, a better understanding of the
pitch control and pass option could be reached to measure players' off-ball
movement contribution to defensive performance. Moreover, this model could
provide football analysts a better tool and metric to understand how players'
movement over time contributes to the game strategy and final victory.
</p>
</div>
</dd>
<dt><a name="item388">[388]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01528" title="Abstract">arXiv:2309.01528</a> [<a href="/pdf/2309.01528" title="Download PDF">pdf</a>, <a href="/format/2309.01528" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Recognition of Heat-Induced Food State Changes by Time-Series Use of  Vision-Language Model for Cooking Robot
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kanazawa%2C+N">Naoaki Kanazawa</a>, 
<a href="/search/cs?searchtype=author&query=Kawaharazuka%2C+K">Kento Kawaharazuka</a>, 
<a href="/search/cs?searchtype=author&query=Obinata%2C+Y">Yoshiki Obinata</a>, 
<a href="/search/cs?searchtype=author&query=Okada%2C+K">Kei Okada</a>, 
<a href="/search/cs?searchtype=author&query=Inaba%2C+M">Masayuki Inaba</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at IAS18-2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Cooking tasks are characterized by large changes in the state of the food,
which is one of the major challenges in robot execution of cooking tasks. In
particular, cooking using a stove to apply heat to the foodstuff causes many
special state changes that are not seen in other tasks, making it difficult to
design a recognizer. In this study, we propose a unified method for recognizing
changes in the cooking state of robots by using the vision-language model that
can discriminate open-vocabulary objects in a time-series manner. We collected
data on four typical state changes in cooking using a real robot and confirmed
the effectiveness of the proposed method. We also compared the conditions and
discussed the types of natural language prompts and the image regions that are
suitable for recognizing the state changes.
</p>
</div>
</dd>
<dt><a name="item389">[389]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01532" title="Abstract">arXiv:2309.01532</a> [<a href="/pdf/2309.01532" title="Download PDF">pdf</a>, <a href="/format/2309.01532" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Are We Using Autoencoders in a Wrong Way?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Martino%2C+G">Gabriele Martino</a>, 
<a href="/search/cs?searchtype=author&query=Moroni%2C+D">Davide Moroni</a>, 
<a href="/search/cs?searchtype=author&query=Martinelli%2C+M">Massimo Martinelli</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Autoencoders are certainly among the most studied and used Deep Learning
models: the idea behind them is to train a model in order to reconstruct the
same input data. The peculiarity of these models is to compress the information
through a bottleneck, creating what is called Latent Space. Autoencoders are
generally used for dimensionality reduction, anomaly detection and feature
extraction. These models have been extensively studied and updated, given their
high simplicity and power. Examples are (i) the Denoising Autoencoder, where
the model is trained to reconstruct an image from a noisy one; (ii) Sparse
Autoencoder, where the bottleneck is created by a regularization term in the
loss function; (iii) Variational Autoencoder, where the latent space is used to
generate new consistent data. In this article, we revisited the standard
training for the undercomplete Autoencoder modifying the shape of the latent
space without using any explicit regularization term in the loss function. We
forced the model to reconstruct not the same observation in input, but another
one sampled from the same class distribution. We also explored the behaviour of
the latent space in the case of reconstruction of a random sample from the
whole dataset.
</p>
</div>
</dd>
<dt><a name="item390">[390]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01538" title="Abstract">arXiv:2309.01538</a> [<a href="/pdf/2309.01538" title="Download PDF">pdf</a>, <a href="/format/2309.01538" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ChatRule: Mining Logical Rules with Large Language Models for Knowledge  Graph Reasoning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Luo%2C+L">Linhao Luo</a>, 
<a href="/search/cs?searchtype=author&query=Ju%2C+J">Jiaxin Ju</a>, 
<a href="/search/cs?searchtype=author&query=Xiong%2C+B">Bo Xiong</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yuan-Fang Li</a>, 
<a href="/search/cs?searchtype=author&query=Haffari%2C+G">Gholamreza Haffari</a>, 
<a href="/search/cs?searchtype=author&query=Pan%2C+S">Shirui Pan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages, 4 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computation and Language (cs.CL)

</div>
<p class="mathjax">Logical rules are essential for uncovering the logical connections between
relations, which could improve the reasoning performance and provide
interpretable results on knowledge graphs (KGs). Although there have been many
efforts to mine meaningful logical rules over KGs, existing methods suffer from
the computationally intensive searches over the rule space and a lack of
scalability for large-scale KGs. Besides, they often ignore the semantics of
relations which is crucial for uncovering logical connections. Recently, large
language models (LLMs) have shown impressive performance in the field of
natural language processing and various applications, owing to their emergent
ability and generalizability. In this paper, we propose a novel framework,
ChatRule, unleashing the power of large language models for mining logical
rules over knowledge graphs. Specifically, the framework is initiated with an
LLM-based rule generator, leveraging both the semantic and structural
information of KGs to prompt LLMs to generate logical rules. To refine the
generated rules, a rule ranking module estimates the rule quality by
incorporating facts from existing KGs. Last, a rule validator harnesses the
reasoning ability of LLMs to validate the logical correctness of ranked rules
through chain-of-thought reasoning. ChatRule is evaluated on four large-scale
KGs, w.r.t. different rule quality metrics and downstream tasks, showing the
effectiveness and scalability of our method.
</p>
</div>
</dd>
<dt><a name="item391">[391]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01539" title="Abstract">arXiv:2309.01539</a> [<a href="/pdf/2309.01539" title="Download PDF">pdf</a>, <a href="/format/2309.01539" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> TSTTC: A Large-Scale Dataset for Time-to-Contact Estimation in Driving  Scenarios
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shi%2C+Y">Yuheng Shi</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+Z">Zehao Huang</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+Y">Yan Yan</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+N">Naiyan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+X">Xiaojie Guo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 19 pages, 9 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Time-to-Contact (TTC) estimation is a critical task for assessing collision
risk and is widely used in various driver assistance and autonomous driving
systems. The past few decades have witnessed development of related theories
and algorithms. The prevalent learning-based methods call for a large-scale TTC
dataset in real-world scenarios. In this work, we present a large-scale object
oriented TTC dataset in the driving scene for promoting the TTC estimation by a
monocular camera. To collect valuable samples and make data with different TTC
values relatively balanced, we go through thousands of hours of driving data
and select over 200K sequences with a preset data distribution. To augment the
quantity of small TTC cases, we also generate clips using the latest Neural
rendering methods. Additionally, we provide several simple yet effective TTC
estimation baselines and evaluate them extensively on the proposed dataset to
demonstrate their effectiveness. The proposed dataset is publicly available at
https://open-dataset.tusen.ai/TSTTC.
</p>
</div>
</dd>
<dt><a name="item392">[392]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01551" title="Abstract">arXiv:2309.01551</a> [<a href="/pdf/2309.01551" title="Download PDF">pdf</a>, <a href="/format/2309.01551" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Is Your Learned Query Optimizer Behaving As You Expect? A Machine  Learning Perspective
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lehmann%2C+C">Claude Lehmann</a>, 
<a href="/search/cs?searchtype=author&query=Sulimov%2C+P">Pavel Sulimov</a>, 
<a href="/search/cs?searchtype=author&query=Stockinger%2C+K">Kurt Stockinger</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Databases (cs.DB)</span>

</div>
<p class="mathjax">The current boom of learned query optimizers (LQO) can be explained not only
by the general continuous improvement of deep learning (DL) methods but also by
the straightforward formulation of a query optimization problem (QOP) as a
machine learning (ML) one. The idea is often to replace dynamic programming
approaches, widespread for solving QOP, with more powerful methods such as
reinforcement learning. However, such a rapid "game change" in the field of QOP
could not pass without consequences - other parts of the ML pipeline, except
for predictive model development, have large improvement potential. For
instance, different LQOs introduce their own restrictions on training data
generation from queries, use an arbitrary train/validation approach, and
evaluate on a voluntary split of benchmark queries.
<br />In this paper, we attempt to standardize the ML pipeline for evaluating LQOs
by introducing a new end-to-end benchmarking framework. Additionally, we guide
the reader through each data science stage in the ML pipeline and provide novel
insights from the machine learning perspective, considering the specifics of
QOP. Finally, we perform a rigorous evaluation of existing LQOs, showing that
PostgreSQL outperforms these LQOs in almost all experiments depending on the
train/test splits.
</p>
</div>
</dd>
<dt><a name="item393">[393]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01552" title="Abstract">arXiv:2309.01552</a> [<a href="/pdf/2309.01552" title="Download PDF">pdf</a>, <a href="/format/2309.01552" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> OutRank: Speeding up AutoML-based Model Search for Large Sparse Data  sets with Cardinality-aware Feature Ranking
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=%C5%A0krlj%2C+B">Bla&#x17e; &#x160;krlj</a>, 
<a href="/search/cs?searchtype=author&query=Mramor%2C+B">Bla&#x17e; Mramor</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> accepted to RecSys2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">The design of modern recommender systems relies on understanding which parts
of the feature space are relevant for solving a given recommendation task.
However, real-world data sets in this domain are often characterized by their
large size, sparsity, and noise, making it challenging to identify meaningful
signals. Feature ranking represents an efficient branch of algorithms that can
help address these challenges by identifying the most informative features and
facilitating the automated search for more compact and better-performing models
(AutoML). We introduce OutRank, a system for versatile feature ranking and data
quality-related anomaly detection. OutRank was built with categorical data in
mind, utilizing a variant of mutual information that is normalized with regard
to the noise produced by features of the same cardinality. We further extend
the similarity measure by incorporating information on feature similarity and
combined relevance. The proposed approach's feasibility is demonstrated by
speeding up the state-of-the-art AutoML system on a synthetic data set with no
performance loss. Furthermore, we considered a real-life click-through-rate
prediction data set where it outperformed strong baselines such as random
forest-based approaches. The proposed approach enables exploration of up to
300% larger feature spaces compared to AutoML-only approaches, enabling faster
search for better models on off-the-shelf hardware.
</p>
</div>
</dd>
<dt><a name="item394">[394]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01556" title="Abstract">arXiv:2309.01556</a> [<a href="/pdf/2309.01556" title="Download PDF">pdf</a>, <a href="/format/2309.01556" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Loopless Algorithms to Generate Maximum Length Gray Cycles wrt.  k-Character Substitution
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=N%C3%A9raud%2C+J">Jean N&#xe9;raud</a> (LITIS, UNIROUEN)
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: text overlap with <a href="/abs/2108.13659">arXiv:2108.13659</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Discrete Mathematics (cs.DM)</span>; Combinatorics (math.CO)

</div>
<p class="mathjax">Given a binary word relation $\tau$ onto $A^*$ and a finite language
$X\subseteq A^*$, a $\tau$-Gray cycle over $X$ consists in a permutation
$\left(w_{[i]}\right)_{0\le i\le |X|-1}$ of $X$ such that each word $w_{[i]}$
is an image under $\tau$ of the previous word $w_{{[i-1]}}$. We define the
complexity measure $\lambda_{A,\tau}(n)$, equal to the largest cardinality of a
language $X$ having words of length at most $n$, and s.t. some $\tau$-Gray
cycle over $X$ exists. The present paper is concerned with $\tau=\sigma_k$, the
so-called $k$-character substitution, s.t. $(u,v)\in\sigma_k$ holds if, and
only if, the Hamming distance of $u$ and $v$ is $k$. We present loopless
(resp., constant amortized time) algorithms for computing specific maximum
length $$\sigma_k$-Gray cycles.
</p>
</div>
</dd>
<dt><a name="item395">[395]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01559" title="Abstract">arXiv:2309.01559</a> [<a href="/pdf/2309.01559" title="Download PDF">pdf</a>, <a href="/format/2309.01559" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Homomorphically encrypted gradient descent algorithms for quadratic  programming
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bertolace%2C+A">Andr&#xe9; Bertolace</a>, 
<a href="/search/cs?searchtype=author&query=Gatsis%2C+K">Konstantinos Gatsis</a>, 
<a href="/search/cs?searchtype=author&query=Margellos%2C+K">Kostas Margellos</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Systems and Control (eess.SY)

</div>
<p class="mathjax">In this paper, we evaluate the different fully homomorphic encryption
schemes, propose an implementation, and numerically analyze the applicability
of gradient descent algorithms to solve quadratic programming in a homomorphic
encryption setup. The limit on the multiplication depth of homomorphic
encryption circuits is a major challenge for iterative procedures such as
gradient descent algorithms. Our analysis not only quantifies these limitations
on prototype examples, thus serving as a benchmark for future investigations,
but also highlights additional trade-offs like the ones pertaining the choice
of gradient descent or accelerated gradient descent methods, opening the road
for the use of homomorphic encryption techniques in iterative procedures widely
used in optimization based control. In addition, we argue that, among the
available homomorphic encryption schemes, the one adopted in this work, namely
CKKS, is the only suitable scheme for implementing gradient descent algorithms.
The choice of the appropriate step size is crucial to the convergence of the
procedure. The paper shows firsthand the feasibility of homomorphically
encrypted gradient descent algorithms.
</p>
</div>
</dd>
<dt><a name="item396">[396]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01561" title="Abstract">arXiv:2309.01561</a> [<a href="/pdf/2309.01561" title="Download PDF">pdf</a>, <a href="/format/2309.01561" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Locality-Aware Hyperspectral Classification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhou%2C+F">Fangqin Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Kilickaya%2C+M">Mert Kilickaya</a>, 
<a href="/search/cs?searchtype=author&query=Vanschoren%2C+J">Joaquin Vanschoren</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> The paper is accepted at BMVC2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Hyperspectral image classification is gaining popularity for high-precision
vision tasks in remote sensing, thanks to their ability to capture visual
information available in a wide continuum of spectra. Researchers have been
working on automating Hyperspectral image classification, with recent efforts
leveraging Vision-Transformers. However, most research models only spectra
information and lacks attention to the locality (i.e., neighboring pixels),
which may be not sufficiently discriminative, resulting in performance
limitations. To address this, we present three contributions: i) We introduce
the Hyperspectral Locality-aware Image TransformEr (HyLITE), a vision
transformer that models both local and spectral information, ii) A novel
regularization function that promotes the integration of local-to-global
information, and iii) Our proposed approach outperforms competing baselines by
a significant margin, achieving up to 10% gains in accuracy. The trained models
and the code are available at HyLITE.
</p>
</div>
</dd>
<dt><a name="item397">[397]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01562" title="Abstract">arXiv:2309.01562</a> [<a href="/pdf/2309.01562" title="Download PDF">pdf</a>, <a href="/format/2309.01562" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the non-global linear stability and spurious fixed points of MPRK  schemes with negative RK parameters
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Izgin%2C+T">Thomas Izgin</a>, 
<a href="/search/math?searchtype=author&query=Kopecz%2C+S">Stefan Kopecz</a>, 
<a href="/search/math?searchtype=author&query=Meister%2C+A">Andreas Meister</a>, 
<a href="/search/math?searchtype=author&query=Schilling%2C+A">Amandine Schilling</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 19 pages, 3 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">Recently, a stability theory has been developed to study the linear stability
of modified Patankar--Runge--Kutta (MPRK) schemes. This stability theory
provides sufficient conditions for a fixed point of an MPRK scheme to be stable
as well as for the convergence of an MPRK scheme towards the steady state of
the corresponding initial value problem, whereas the main assumption is that
the initial value is sufficiently close to the steady state. Initially,
numerical experiments in several publications indicated that these linear
stability properties are not only local, but even global, as is the case for
general linear methods. Recently, however, it was discovered that the linear
stability of the MPDeC(8) scheme is indeed only local in nature. Our conjecture
is that this is a result of negative Runge--Kutta (RK) parameters of MPDeC(8)
and that linear stability is indeed global, if the RK parameters are
nonnegative. To support this conjecture, we examine the family of
MPRK22($\alpha$) methods with negative RK parameters and show that even among
these methods there are methods for which the stability properties are only
local. However, this local linear stability is not observed for
MPRK22($\alpha$) schemes with nonnegative Runge-Kutta parameters.
</p>
</div>
</dd>
<dt><a name="item398">[398]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01569" title="Abstract">arXiv:2309.01569</a> [<a href="/pdf/2309.01569" title="Download PDF">pdf</a>, <a href="/format/2309.01569" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Rail Crack Propagation Forecasting Using Multi-horizons RNNs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ouerk%2C+S+Y">Sara Yasmine Ouerk</a>, 
<a href="/search/cs?searchtype=author&query=Van%2C+O+V">Olivier Vo Van</a>, 
<a href="/search/cs?searchtype=author&query=Yagoubi%2C+M">Mouadh Yagoubi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">The prediction of rail crack length propagation plays a crucial role in the
maintenance and safety assessment of materials and structures. Traditional
methods rely on physical models and empirical equations such as Paris law,
which often have limitations in capturing the complex nature of crack growth.
In recent years, machine learning techniques, particularly Recurrent Neural
Networks (RNNs), have emerged as promising methods for time series forecasting.
They allow to model time series data, and to incorporate exogenous variables
into the model. The proposed approach involves collecting real data on the
French rail network that includes historical crack length measurements, along
with relevant exogenous factors that may influence crack growth. First, a
pre-processing phase was performed to prepare a consistent data set for
learning. Then, a suitable Bayesian multi-horizons recurrent architecture was
designed to model the crack propagation phenomenon. Obtained results show that
the Multi-horizons model outperforms state-of-the-art models such as LSTM and
GRU.
</p>
</div>
</dd>
<dt><a name="item399">[399]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01571" title="Abstract">arXiv:2309.01571</a> [<a href="/pdf/2309.01571" title="Download PDF">pdf</a>, <a href="/format/2309.01571" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Interplay Between High-Level Problems and The Process Instances That  Give Rise To Them
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bakullari%2C+B">Bianka Bakullari</a>, 
<a href="/search/cs?searchtype=author&query=van+Thoor%2C+J">Jules van Thoor</a>, 
<a href="/search/cs?searchtype=author&query=Fahland%2C+D">Dirk Fahland</a>, 
<a href="/search/cs?searchtype=author&query=van+der+Aalst%2C+W+M+P">Wil M.P. van der Aalst</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Databases (cs.DB)</span>; Software Engineering (cs.SE)

</div>
<p class="mathjax">Business processes may face a variety of problems due to the number of tasks
that need to be handled within short time periods, resources' workload and
working patterns, as well as bottlenecks. These problems may arise locally and
be short-lived, but as the process is forced to operate outside its standard
capacity, the effect on the underlying process instances can be costly. We use
the term high-level behavior to cover all process behavior which can not be
captured in terms of the individual process instances. %Whenever such behavior
emerges, we call the cases which are involved in it participating cases. The
natural question arises as to how the characteristics of cases relate to the
high-level behavior they give rise to. In this work, we first show how to
detect and correlate observations of high-level problems, as well as determine
the corresponding (non-)participating cases. Then we show how to assess the
connection between any case-level characteristic and any given detected
sequence of high-level problems. Applying our method on the event data of a
real loan application process revealed which specific combinations of delays,
batching and busy resources at which particular parts of the process correlate
with an application's duration and chance of a positive outcome.
</p>
</div>
</dd>
<dt><a name="item400">[400]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01574" title="Abstract">arXiv:2309.01574</a> [<a href="/pdf/2309.01574" title="Download PDF">pdf</a>, <a href="/format/2309.01574" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Raw Data Is All You Need: Virtual Axle Detector with Enhanced Receptive  Field
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Riedel%2C+H">Henik Riedel</a>, 
<a href="/search/cs?searchtype=author&query=Lorenzen%2C+R+S">Robert Steven Lorenzen</a>, 
<a href="/search/cs?searchtype=author&query=H%C3%BCbler%2C+C">Clemens H&#xfc;bler</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Rising maintenance costs of ageing infrastructure necessitate innovative
monitoring techniques. This paper presents a new approach for axle detection,
enabling real-time application of Bridge Weigh-In-Motion (BWIM) systems without
dedicated axle detectors. The proposed method adapts the Virtual Axle Detector
(VAD) model to handle raw acceleration data, which allows the receptive field
to be increased. The proposed Virtual Axle Detector with Enhanced Receptive
field (VADER) improves the \(F_1\) score by 73\% and spatial accuracy by 39\%,
while cutting computational and memory costs by 99\% compared to the
state-of-the-art VAD. VADER reaches a \(F_1\) score of 99.4\% and a spatial
error of 4.13~cm when using a representative training set and functional
sensors. We also introduce a novel receptive field (RF) rule for an object-size
driven design of Convolutional Neural Network (CNN) architectures. Based on
this rule, our results suggest that models using raw data could achieve better
performance than those using spectrograms, offering a compelling reason to
consider raw data as input.
</p>
</div>
</dd>
<dt><a name="item401">[401]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01575" title="Abstract">arXiv:2309.01575</a> [<a href="/pdf/2309.01575" title="Download PDF">pdf</a>, <a href="/format/2309.01575" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DiffHPE: Robust, Coherent 3D Human Pose Lifting with Diffusion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rommel%2C+C">C&#xe9;dric Rommel</a>, 
<a href="/search/cs?searchtype=author&query=Valle%2C+E">Eduardo Valle</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+M">Micka&#xeb;l Chen</a>, 
<a href="/search/cs?searchtype=author&query=Khalfaoui%2C+S">Souhaiel Khalfaoui</a>, 
<a href="/search/cs?searchtype=author&query=Marlet%2C+R">Renaud Marlet</a>, 
<a href="/search/cs?searchtype=author&query=Cord%2C+M">Matthieu Cord</a>, 
<a href="/search/cs?searchtype=author&query=P%C3%A9rez%2C+P">Patrick P&#xe9;rez</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to 2023 International Conference on Computer Vision Workshop (Analysis and Modeling of Faces and Gestures)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">We present an innovative approach to 3D Human Pose Estimation (3D-HPE) by
integrating cutting-edge diffusion models, which have revolutionized diverse
fields, but are relatively unexplored in 3D-HPE. We show that diffusion models
enhance the accuracy, robustness, and coherence of human pose estimations. We
introduce DiffHPE, a novel strategy for harnessing diffusion models in 3D-HPE,
and demonstrate its ability to refine standard supervised 3D-HPE. We also show
how diffusion models lead to more robust estimations in the face of occlusions,
and improve the time-coherence and the sagittal symmetry of predictions. Using
the Human\,3.6M dataset, we illustrate the effectiveness of our approach and
its superiority over existing models, even under adverse situations where the
occlusion patterns in training do not match those in inference. Our findings
indicate that while standalone diffusion models provide commendable
performance, their accuracy is even better in combination with supervised
models, opening exciting new avenues for 3D-HPE research.
</p>
</div>
</dd>
<dt><a name="item402">[402]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01576" title="Abstract">arXiv:2309.01576</a> [<a href="/pdf/2309.01576" title="Download PDF">pdf</a>, <a href="/format/2309.01576" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Comparative Analysis of Pretrained Language Models for Text-to-Speech
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Granero-Moya%2C+M">Marcel Granero-Moya</a>, 
<a href="/search/cs?searchtype=author&query=Karanasou%2C+P">Penny Karanasou</a>, 
<a href="/search/cs?searchtype=author&query=Karlapati%2C+S">Sri Karlapati</a>, 
<a href="/search/cs?searchtype=author&query=Schnell%2C+B">Bastian Schnell</a>, 
<a href="/search/cs?searchtype=author&query=Peinelt%2C+N">Nicole Peinelt</a>, 
<a href="/search/cs?searchtype=author&query=Moinet%2C+A">Alexis Moinet</a>, 
<a href="/search/cs?searchtype=author&query=Drugman%2C+T">Thomas Drugman</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted for presentation at the 12th ISCA Speech Synthesis Workshop (SSW) in Grenoble, France, from 26th to 28th August 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Sound (cs.SD); Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">State-of-the-art text-to-speech (TTS) systems have utilized pretrained
language models (PLMs) to enhance prosody and create more natural-sounding
speech. However, while PLMs have been extensively researched for natural
language understanding (NLU), their impact on TTS has been overlooked. In this
study, we aim to address this gap by conducting a comparative analysis of
different PLMs for two TTS tasks: prosody prediction and pause prediction.
Firstly, we trained a prosody prediction model using 15 different PLMs. Our
findings revealed a logarithmic relationship between model size and quality, as
well as significant performance differences between neutral and expressive
prosody. Secondly, we employed PLMs for pause prediction and found that the
task was less sensitive to small models. We also identified a strong
correlation between our empirical results and the GLUE scores obtained for
these language models. To the best of our knowledge, this is the first study of
its kind to investigate the impact of different PLMs on TTS.
</p>
</div>
</dd>
<dt><a name="item403">[403]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01582" title="Abstract">arXiv:2309.01582</a> [<a href="/pdf/2309.01582" title="Download PDF">pdf</a>, <a href="/format/2309.01582" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Improving Visual Quality and Transferability of Adversarial Attacks on  Face Recognition Simultaneously with Adversarial Restoration
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhou%2C+F">Fengfan Zhou</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Visual Quality and Transferability are the two key property of adversarial
face examples. However, few works consider to improve the key properties
simultaneously. To this end, we proposed a novel adversarial attack called
Adversarial Restoration (AdvRestore) that enhances the visual quality and the
transferability of adversarial face examples simultaneously by using a face
Restoration Latent Diffusion Model Prior. Specifically, we first train a face
Restoration Latent Diffusion Model (RLDM) for face restoration. Then, we use
RLDM to restore of the attacker image, in the process of restoration, we add
adversarial perturbations on the output feature of the UNet of RLDM. Combined
with the prior, the visual quality and tranferability of the crafted
adversarial face examples can be further improved. Experimental results
demonstrate the effectiveness of our proposed attack method.
</p>
</div>
</dd>
<dt><a name="item404">[404]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01585" title="Abstract">arXiv:2309.01585</a> [<a href="/pdf/2309.01585" title="Download PDF">pdf</a>, <a href="/format/2309.01585" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Incorporating Data Dependencies and Properties in Difference  Verification with Conditions (Technical Report)
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jakobs%2C+M">Marie-Christine Jakobs</a>, 
<a href="/search/cs?searchtype=author&query=Pollandt%2C+T">Tim Pollandt</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>; Programming Languages (cs.PL)

</div>
<p class="mathjax">Software changes frequently. To efficiently deal with such frequent changes,
software verification tools must be incremental. Most of today's approaches for
incremental verification consider one specific verification approach. One
exception is difference verification with conditions recently proposed by Beyer
et al. Its underlying idea is to determine an overapproximation of those
modified execution paths that may cause a new property violation, which does
not exist in the unchanged program, encode the determined paths into a
condition, and use the condition to restrict the verification to the analysis
of those determined paths. To determine the overapproximation, Beyer et al.
propose a syntax-based difference detector that adds any syntactical path of
the modified program that does not exist in the original program into the
overapproximation. This paper provides a second difference detector diffDP,
which computes a more precise overapproximation by taking data dependencies and
program properties into account when determining the overapproximation of those
modified execution paths that may cause a new property violation. Our
evaluation indeed shows that our more precise difference detector improves the
effectiveness and efficiency of difference verification with condition on
several tasks.
</p>
</div>
</dd>
<dt><a name="item405">[405]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01586" title="Abstract">arXiv:2309.01586</a> [<a href="/pdf/2309.01586" title="Download PDF">pdf</a>, <a href="/format/2309.01586" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Automatic Scam-Baiting Using ChatGPT
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bajaj%2C+P">Piyush Bajaj</a>, 
<a href="/search/cs?searchtype=author&query=Edwards%2C+M">Matthew Edwards</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Proceedings of the 7th International Workshop on Applications of AI, Cyber Security and Economics Data Analytics (ACE-2023) (in press)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">Automatic scam-baiting is an online fraud countermeasure that involves
automated systems responding to online fraudsters in order to waste their time
and deplete their resources, diverting attackers away from real potential
victims. Previous work has demonstrated that text generation systems are
capable of engaging with attackers as automatic scam-baiters, but the fluency
and coherence of generated text may be a limit to the effectiveness of such
systems.
<br />In this paper, we report on the results of a month-long experiment comparing
the effectiveness of two ChatGPT-based automatic scam-baiters to a control
measure. Within our results, with engagement from over 250 real email
fraudsters, we find that ChatGPT-based scam-baiters show a marked increase in
scammer response rate and conversation length relative to the control measure,
outperforming previous approaches. We discuss the implications of these results
and practical considerations for wider deployment of automatic scam-baiting.
</p>
</div>
</dd>
<dt><a name="item406">[406]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01587" title="Abstract">arXiv:2309.01587</a> [<a href="/pdf/2309.01587" title="Download PDF">pdf</a>, <a href="/format/2309.01587" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SATAY: A Streaming Architecture Toolflow for Accelerating YOLO Models on  FPGA Devices
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Montgomerie-Corcoran%2C+A">Alexander Montgomerie-Corcoran</a>, 
<a href="/search/cs?searchtype=author&query=Toupas%2C+P">Petros Toupas</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+Z">Zhewen Yu</a>, 
<a href="/search/cs?searchtype=author&query=Bouganis%2C+C">Christos-Savvas Bouganis</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Hardware Architecture (cs.AR)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
<p class="mathjax">AI has led to significant advancements in computer vision and image
processing tasks, enabling a wide range of applications in real-life scenarios,
from autonomous vehicles to medical imaging. Many of those applications require
efficient object detection algorithms and complementary real-time, low latency
hardware to perform inference of these algorithms. The YOLO family of models is
considered the most efficient for object detection, having only a single model
pass. Despite this, the complexity and size of YOLO models can be too
computationally demanding for current edge-based platforms. To address this, we
present SATAY: a Streaming Architecture Toolflow for Accelerating YOLO. This
work tackles the challenges of deploying stateof-the-art object detection
models onto FPGA devices for ultralow latency applications, enabling real-time,
edge-based object detection. We employ a streaming architecture design for our
YOLO accelerators, implementing the complete model on-chip in a deeply
pipelined fashion. These accelerators are generated using an automated
toolflow, and can target a range of suitable FPGA devices. We introduce novel
hardware components to support the operations of YOLO models in a dataflow
manner, and off-chip memory buffering to address the limited on-chip memory
resources. Our toolflow is able to generate accelerator designs which
demonstrate competitive performance and energy characteristics to GPU devices,
and which outperform current state-of-the-art FPGA accelerators.
</p>
</div>
</dd>
<dt><a name="item407">[407]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01590" title="Abstract">arXiv:2309.01590</a> [<a href="/pdf/2309.01590" title="Download PDF">pdf</a>, <a href="/format/2309.01590" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Probabilistic Precision and Recall Towards Reliable Evaluation of  Generative Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Park%2C+D">Dogyun Park</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+S">Suhyun Kim</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Assessing the fidelity and diversity of the generative model is a difficult
but important issue for technological advancement. So, recent papers have
introduced k-Nearest Neighbor ($k$NN) based precision-recall metrics to break
down the statistical distance into fidelity and diversity. While they provide
an intuitive method, we thoroughly analyze these metrics and identify
oversimplified assumptions and undesirable properties of kNN that result in
unreliable evaluation, such as susceptibility to outliers and insensitivity to
distributional changes. Thus, we propose novel metrics, P-precision and
P-recall (PP\&amp;PR), based on a probabilistic approach that address the problems.
Through extensive investigations on toy experiments and state-of-the-art
generative models, we show that our PP\&amp;PR provide more reliable estimates for
comparing fidelity and diversity than the existing metrics. The codes are
available at \url{https://github.com/kdst-team/Probablistic_precision_recall}.
</p>
</div>
</dd>
<dt><a name="item408">[408]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01593" title="Abstract">arXiv:2309.01593</a> [<a href="/pdf/2309.01593" title="Download PDF">pdf</a>, <a href="/format/2309.01593" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deep Learning Overloaded Vehicle Identification for Long Span Bridges  Based on Structural Health Monitoring Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yuqin Li</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jun Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhong%2C+S">Shengliang Zhong</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+L">Licheng Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+S">Shoubin Dong</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zejia Liu</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+L">Liqun Tang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computational Engineering, Finance, and Science (cs.CE)

</div>
<p class="mathjax">Overloaded vehicles bring great harm to transportation infrastructures. BWIM
(bridge weigh-in-motion) method for overloaded vehicle identification is
getting more popular because it can be implemented without interruption to the
traffic. However, its application is still limited because its effectiveness
largely depends on professional knowledge and extra information, and is
susceptible to occurrence of multiple vehicles. In this paper, a deep learning
based overloaded vehicle identification approach (DOVI) is proposed, with the
purpose of overloaded vehicle identification for long-span bridges by the use
of structural health monitoring data. The proposed DOVI model uses temporal
convolutional architectures to extract the spatial and temporal features of the
input sequence data, thus provides an end-to-end overloaded vehicle
identification solution which neither needs the influence line nor needs to
obtain velocity and wheelbase information in advance and can be applied under
the occurrence of multiple vehicles. Model evaluations are conducted on a
simply supported beam and a long-span cable-stayed bridge under random traffic
flow. Results demonstrate that the proposed deep-learning overloaded vehicle
identification approach has better effectiveness and robustness, compared with
other machine learning and deep learning approaches.
</p>
</div>
</dd>
<dt><a name="item409">[409]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01597" title="Abstract">arXiv:2309.01597</a> [<a href="/pdf/2309.01597" title="Download PDF">pdf</a>, <a href="/format/2309.01597" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Revealing the True Cost of Local Privacy: An Auditing Perspective
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Arcolezi%2C+H+H">H&#xe9;ber H. Arcolezi</a>, 
<a href="/search/cs?searchtype=author&query=Gambs%2C+S">S&#xe9;bastien Gambs</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted for poster presentation at TPDP
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">This paper introduces the LDP-Auditor framework for empirically estimating
the privacy loss of Locally Differentially Private (LDP) mechanisms. Several
factors influencing the privacy audit are explored, such as the impact of
different encoding and perturbation functions of eight state-of-the-art LDP
protocols. Furthermore, the influence of domain size as well as the theoretical
privacy loss parameter $\epsilon$ on local privacy estimation are also
examined. Overall, our LDP-Auditor framework and findings offer valuable
insights into the sources of randomness and information loss in LDP protocols,
contributing to a more realistic understanding of the local privacy loss.
Furthermore, we demonstrate the effectiveness of LDP-Auditor by successfully
identifying a bug in an LDP library.
</p>
</div>
</dd>
<dt><a name="item410">[410]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01598" title="Abstract">arXiv:2309.01598</a> [<a href="/pdf/2309.01598" title="Download PDF">pdf</a>, <a href="/ps/2309.01598" title="Download PostScript">ps</a>, <a href="/format/2309.01598" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exploring Diverse Coping Mechanisms in 2023: A Comprehensive Survey  Across Backgrounds and Cultures
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Paul%2C+A">Abhijit Paul</a>, 
<a href="/search/cs?searchtype=author&query=Majumder%2C+R">Rony Majumder</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>

</div>
<p class="mathjax">This study presents a pioneering investigation into the wide array of coping
mechanisms employed by individuals in the year 2023, with a focus on data
collected through the popular social media platform TikTok. Coping mechanisms
are essential strategies that people adopt to navigate the challenges and
stressors of everyday life, yet little research has been conducted on their
comprehensive compilation across different backgrounds, countries, and
experiences.
<br />Using TikTok as a data collection tool allowed us to access a diverse and
extensive pool of participants, representing various cultural, social, and
demographic backgrounds. Our study collates coping mechanisms reported by users
from different parts of the world, facilitating the identification of both
universal and culture-specific strategies.
<br />This research contributes to the existing literature by providing a holistic
view of coping mechanisms without being limited to specific fields or
populations. By analyzing the coping methods shared on TikTok, we reveal a
comprehensive list of strategies employed by people from diverse walks of life.
The findings of this study not only shed light on how individuals cope with
challenges in the modern era but also offer insights into the evolving coping
trends and the role of social media in disseminating coping strategies.
Understanding these coping mechanisms can have implications for mental health
professionals, practitioners, and policymakers seeking to provide support and
resources to individuals facing different stressors and hardships.
</p>
</div>
</dd>
<dt><a name="item411">[411]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01606" title="Abstract">arXiv:2309.01606</a> [<a href="/pdf/2309.01606" title="Download PDF">pdf</a>, <a href="/format/2309.01606" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Geo-Encoder: A Chunk-Argument Bi-Encoder Framework for Chinese  Geographic Re-Ranking
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cao%2C+Y">Yong Cao</a>, 
<a href="/search/cs?searchtype=author&query=Ding%2C+R">Ruixue Ding</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+B">Boli Chen</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xianzhi Li</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+M">Min Chen</a>, 
<a href="/search/cs?searchtype=author&query=Hershcovich%2C+D">Daniel Hershcovich</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+P">Pengjun Xie</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+F">Fei Huang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Chinese geographic re-ranking task aims to find the most relevant addresses
among retrieved candidates, which is crucial for location-related services such
as navigation maps. Unlike the general sentences, geographic contexts are
closely intertwined with geographical concepts, from general spans (e.g.,
province) to specific spans (e.g., road). Given this feature, we propose an
innovative framework, namely Geo-Encoder, to more effectively integrate Chinese
geographical semantics into re-ranking pipelines. Our methodology begins by
employing off-the-shelf tools to associate text with geographical spans,
treating them as chunking units. Then, we present a multi-task learning module
to simultaneously acquire an effective attention matrix that determines chunk
contributions to extra semantic representations. Furthermore, we put forth an
asynchronous update mechanism for the proposed addition task, aiming to guide
the model capable of effectively focusing on specific chunks. Experiments on
two distinct Chinese geographic re-ranking datasets, show that the Geo-Encoder
achieves significant improvements when compared to state-of-the-art baselines.
Notably, it leads to a substantial improvement in the Hit@1 score of MGEO-BERT,
increasing it by 6.22% from 62.76 to 68.98 on the GeoTES dataset.
</p>
</div>
</dd>
<dt><a name="item412">[412]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01610" title="Abstract">arXiv:2309.01610</a> [<a href="/pdf/2309.01610" title="Download PDF">pdf</a>, <a href="/format/2309.01610" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fair Ranking under Disparate Uncertainty
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rastogi%2C+R">Richa Rastogi</a>, 
<a href="/search/cs?searchtype=author&query=Joachims%2C+T">Thorsten Joachims</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> A version of this paper was accepted as Spotlight (Oral) at UAI workshop on Epistemic in AI, 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computers and Society (cs.CY); Information Retrieval (cs.IR)

</div>
<p class="mathjax">Ranking is a ubiquitous method for focusing the attention of human evaluators
on a manageable subset of options. Its use ranges from surfacing potentially
relevant products on an e-commerce site to prioritizing college applications
for human review. While ranking can make human evaluation far more effective by
focusing attention on the most promising options, we argue that it can
introduce unfairness if the uncertainty of the underlying relevance model
differs between groups of options. Unfortunately, such disparity in uncertainty
appears widespread, since the relevance estimates for minority groups tend to
have higher uncertainty due to a lack of data or appropriate features. To
overcome this fairness issue, we propose Equal-Opportunity Ranking (EOR) as a
new fairness criterion for ranking that provably corrects for the disparity in
uncertainty between groups. Furthermore, we present a practical algorithm for
computing EOR rankings in time $O(n \log(n))$ and prove its close approximation
guarantee to the globally optimal solution. In a comprehensive empirical
evaluation on synthetic data, a US Census dataset, and a real-world case study
of Amazon search queries, we find that the algorithm reliably guarantees EOR
fairness while providing effective rankings.
</p>
</div>
</dd>
<dt><a name="item413">[413]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01611" title="Abstract">arXiv:2309.01611</a> [<a href="/pdf/2309.01611" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Segmentation of 3D pore space from CT images using curvilinear skeleton:  application to numerical simulation of microbial decomposition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Monga%2C+O">Olivier Monga</a>, 
<a href="/search/cs?searchtype=author&query=Belghali%2C+Z">Zakaria Belghali</a>, 
<a href="/search/cs?searchtype=author&query=Klai%2C+M">Mouad Klai</a>, 
<a href="/search/cs?searchtype=author&query=Druoton%2C+L">Lucie Druoton</a>, 
<a href="/search/cs?searchtype=author&query=Michelucci%2C+D">Dominique Michelucci</a>, 
<a href="/search/cs?searchtype=author&query=Pot%2C+V">Valerie Pot</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> preprint, submitted to Computers &amp; Geosciences 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Recent advances in 3D X-ray Computed Tomographic (CT) sensors have stimulated
research efforts to unveil the extremely complex micro-scale processes that
control the activity of soil microorganisms. Voxel-based description (up to
hundreds millions voxels) of the pore space can be extracted, from grey level
3D CT scanner images, by means of simple image processing tools. Classical
methods for numerical simulation of biological dynamics using mesh of voxels,
such as Lattice Boltzmann Model (LBM), are too much time consuming. Thus, the
use of more compact and reliable geometrical representations of pore space can
drastically decrease the computational cost of the simulations. Several recent
works propose basic analytic volume primitives (e.g. spheres, generalized
cylinders, ellipsoids) to define a piece-wise approximation of pore space for
numerical simulation of draining, diffusion and microbial decomposition. Such
approaches work well but the drawback is that it generates approximation
errors. In the present work, we study another alternative where pore space is
described by means of geometrically relevant connected subsets of voxels
(regions) computed from the curvilinear skeleton. Indeed, many works use the
curvilinear skeleton (3D medial axis) for analyzing and partitioning 3D shapes
within various domains (medicine, material sciences, petroleum engineering,
etc.) but only a few ones in soil sciences. Within the context of soil
sciences, most studies dealing with 3D medial axis focus on the determination
of pore throats. Here, we segment pore space using curvilinear skeleton in
order to achieve numerical simulation of microbial decomposition (including
diffusion processes). We validate simulation outputs by comparison with other
methods using different pore space geometrical representations (balls, voxels).
</p>
</div>
</dd>
<dt><a name="item414">[414]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01612" title="Abstract">arXiv:2309.01612</a> [<a href="/pdf/2309.01612" title="Download PDF">pdf</a>, <a href="/format/2309.01612" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the Query Strategies for Efficient Online Active Distillation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Boldo%2C+M">Michele Boldo</a>, 
<a href="/search/cs?searchtype=author&query=Martini%2C+E">Enrico Martini</a>, 
<a href="/search/cs?searchtype=author&query=De+Marchi%2C+M">Mirco De Marchi</a>, 
<a href="/search/cs?searchtype=author&query=Aldegheri%2C+S">Stefano Aldegheri</a>, 
<a href="/search/cs?searchtype=author&query=Bombieri%2C+N">Nicola Bombieri</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Deep Learning (DL) requires lots of time and data, resulting in high
computational demands. Recently, researchers employ Active Learning (AL) and
online distillation to enhance training efficiency and real-time model
adaptation. This paper evaluates a set of query strategies to achieve the best
training results. It focuses on Human Pose Estimation (HPE) applications,
assessing the impact of selected frames during training using two approaches: a
classical offline method and a online evaluation through a continual learning
approach employing knowledge distillation, on a popular state-of-the-art HPE
dataset. The paper demonstrates the possibility of enabling training at the
edge lightweight models, adapting them effectively to new contexts in
real-time.
</p>
</div>
</dd>
<dt><a name="item415">[415]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01614" title="Abstract">arXiv:2309.01614</a> [<a href="/pdf/2309.01614" title="Download PDF">pdf</a>, <a href="/format/2309.01614" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Dropout Attacks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yuan%2C+A">Andrew Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Oprea%2C+A">Alina Oprea</a>, 
<a href="/search/cs?searchtype=author&query=Tan%2C+C">Cheng Tan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Cryptography and Security (cs.CR)

</div>
<p class="mathjax">Dropout is a common operator in deep learning, aiming to prevent overfitting
by randomly dropping neurons during training. This paper introduces a new
family of poisoning attacks against neural networks named DROPOUTATTACK.
DROPOUTATTACK attacks the dropout operator by manipulating the selection of
neurons to drop instead of selecting them uniformly at random. We design,
implement, and evaluate four DROPOUTATTACK variants that cover a broad range of
scenarios. These attacks can slow or stop training, destroy prediction accuracy
of target classes, and sabotage either precision or recall of a target class.
In our experiments of training a VGG-16 model on CIFAR-100, our attack can
reduce the precision of the victim class by 34.6% (from 81.7% to 47.1%) without
incurring any degradation in model accuracy
</p>
</div>
</dd>
<dt><a name="item416">[416]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01617" title="Abstract">arXiv:2309.01617</a> [<a href="/pdf/2309.01617" title="Download PDF">pdf</a>, <a href="/format/2309.01617" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DeViL: Decoding Vision features into Language
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dani%2C+M">Meghal Dani</a>, 
<a href="/search/cs?searchtype=author&query=Rio-Torto%2C+I">Isabel Rio-Torto</a>, 
<a href="/search/cs?searchtype=author&query=Alaniz%2C+S">Stephan Alaniz</a>, 
<a href="/search/cs?searchtype=author&query=Akata%2C+Z">Zeynep Akata</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at GCPR 2023 (Oral)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Post-hoc explanation methods have often been criticised for abstracting away
the decision-making process of deep neural networks. In this work, we would
like to provide natural language descriptions for what different layers of a
vision backbone have learned. Our DeViL method decodes vision features into
language, not only highlighting the attribution locations but also generating
textual descriptions of visual features at different layers of the network. We
train a transformer network to translate individual image features of any
vision layer into a prompt that a separate off-the-shelf language model decodes
into natural language. By employing dropout both per-layer and
per-spatial-location, our model can generalize training on image-text pairs to
generate localized explanations. As it uses a pre-trained language model, our
approach is fast to train, can be applied to any vision backbone, and produces
textual descriptions at different layers of the vision network. Moreover, DeViL
can create open-vocabulary attribution maps corresponding to words or phrases
even outside the training scope of the vision model. We demonstrate that DeViL
generates textual descriptions relevant to the image content on CC3M surpassing
previous lightweight captioning models and attribution maps uncovering the
learned concepts of the vision backbone. Finally, we show DeViL also
outperforms the current state-of-the-art on the neuron-wise descriptions of the
MILANNOTATIONS dataset. Code available at
https://github.com/ExplainableML/DeViL
</p>
</div>
</dd>
<dt><a name="item417">[417]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01618" title="Abstract">arXiv:2309.01618</a> [<a href="/pdf/2309.01618" title="Download PDF">pdf</a>, <a href="/format/2309.01618" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Critical Behavioral Traits Foster Peer Engagement in Online Mental  Health Communities
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Srivastava%2C+A">Aseem Srivastava</a>, 
<a href="/search/cs?searchtype=author&query=Gupta%2C+T">Tanya Gupta</a>, 
<a href="/search/cs?searchtype=author&query=Cerezo%2C+A">Alison Cerezo</a>, 
<a href="/search/cs?searchtype=author&query=Peregrine%2C+S">Sarah Peregrine</a> (Grin)
<a href="/search/cs?searchtype=author&query=Lord">Lord</a>, 
<a href="/search/cs?searchtype=author&query=Akhtar%2C+M+S">Md Shad Akhtar</a>, 
<a href="/search/cs?searchtype=author&query=Chakraborty%2C+T">Tanmoy Chakraborty</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Online Mental Health Communities (OMHCs), such as Reddit, have witnessed a
surge in popularity as go-to platforms for seeking information and support in
managing mental health needs. Platforms like Reddit offer immediate
interactions with peers, granting users a vital space for seeking mental health
assistance. However, the largely unregulated nature of these platforms
introduces intricate challenges for both users and society at large. This study
explores the factors that drive peer engagement within counseling threads,
aiming to enhance our understanding of this critical phenomenon. We introduce
BeCOPE, a novel behavior encoded Peer counseling dataset comprising over 10,118
posts and 58,279 comments sourced from 21 mental health-specific subreddits.
The dataset is annotated using three major fine-grained behavior labels: (a)
intent, (b) criticism, and (c) readability, along with the emotion labels. Our
analysis indicates the prominence of ``self-criticism'' as the most prevalent
form of criticism expressed by help-seekers, accounting for a significant 43%
of interactions. Intriguingly, we observe that individuals who explicitly
express their need for help are 18.01% more likely to receive assistance
compared to those who present ``surveys'' or engage in ``rants.'' Furthermore,
we highlight the pivotal role of well-articulated problem descriptions, showing
that superior readability effectively doubles the likelihood of receiving the
sought-after support. Our study emphasizes the essential role of OMHCs in
offering personalized guidance and unveils behavior-driven engagement patterns.
</p>
</div>
</dd>
<dt><a name="item418">[418]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01620" title="Abstract">arXiv:2309.01620</a> [<a href="/pdf/2309.01620" title="Download PDF">pdf</a>, <a href="/format/2309.01620" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Hindering Adversarial Attacks with Multiple Encrypted Patch Embeddings
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=MaungMaung%2C+A">AprilPyone MaungMaung</a>, 
<a href="/search/cs?searchtype=author&query=Echizen%2C+I">Isao Echizen</a>, 
<a href="/search/cs?searchtype=author&query=Kiya%2C+H">Hitoshi Kiya</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To appear in APSIPA ASC 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">In this paper, we propose a new key-based defense focusing on both efficiency
and robustness. Although the previous key-based defense seems effective in
defending against adversarial examples, carefully designed adaptive attacks can
bypass the previous defense, and it is difficult to train the previous defense
on large datasets like ImageNet. We build upon the previous defense with two
major improvements: (1) efficient training and (2) optional randomization. The
proposed defense utilizes one or more secret patch embeddings and classifier
heads with a pre-trained isotropic network. When more than one secret
embeddings are used, the proposed defense enables randomization on inference.
Experiments were carried out on the ImageNet dataset, and the proposed defense
was evaluated against an arsenal of state-of-the-art attacks, including
adaptive ones. The results show that the proposed defense achieves a high
robust accuracy and a comparable clean accuracy compared to the previous
key-based defense.
</p>
</div>
</dd>
<dt><a name="item419">[419]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01622" title="Abstract">arXiv:2309.01622</a> [<a href="/pdf/2309.01622" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Concepts is All You Need: A More Direct Path to AGI
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Voss%2C+P">Peter Voss</a>, 
<a href="/search/cs?searchtype=author&query=Jovanovic%2C+M">Mladjan Jovanovic</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
<p class="mathjax">Little demonstrable progress has been made toward AGI (Artificial General
Intelligence) since the term was coined some 20 years ago. In spite of the
fantastic breakthroughs in Statistical AI such as AlphaZero, ChatGPT, and
Stable Diffusion none of these projects have, or claim to have, a clear path to
AGI. In order to expedite the development of AGI it is crucial to understand
and identify the core requirements of human-like intelligence as it pertains to
AGI. From that one can distill which particular development steps are necessary
to achieve AGI, and which are a distraction. Such analysis highlights the need
for a Cognitive AI approach rather than the currently favored statistical and
generative efforts. More specifically it identifies the central role of
concepts in human-like cognition. Here we outline an architecture and
development plan, together with some preliminary results, that offers a much
more direct path to full Human-Level AI (HLAI)/ AGI.
</p>
</div>
</dd>
<dt><a name="item420">[420]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01624" title="Abstract">arXiv:2309.01624</a> [<a href="/pdf/2309.01624" title="Download PDF">pdf</a>, <a href="/format/2309.01624" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AGG-Net: Attention Guided Gated-convolutional Network for Depth Image  Completion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+D">Dongyue Chen</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+T">Tingxuan Huang</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+Z">Zhimin Song</a>, 
<a href="/search/cs?searchtype=author&query=Deng%2C+S">Shizhuo Deng</a>, 
<a href="/search/cs?searchtype=author&query=Jia%2C+T">Tong Jia</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages, 7 figures, ICCV2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Recently, stereo vision based on lightweight RGBD cameras has been widely
used in various fields. However, limited by the imaging principles, the
commonly used RGB-D cameras based on TOF, structured light, or binocular vision
acquire some invalid data inevitably, such as weak reflection, boundary
shadows, and artifacts, which may bring adverse impacts to the follow-up work.
In this paper, we propose a new model for depth image completion based on the
Attention Guided Gated-convolutional Network (AGG-Net), through which more
accurate and reliable depth images can be obtained from the raw depth maps and
the corresponding RGB images. Our model employs a UNet-like architecture which
consists of two parallel branches of depth and color features. In the encoding
stage, an Attention Guided Gated-Convolution (AG-GConv) module is proposed to
realize the fusion of depth and color features at different scales, which can
effectively reduce the negative impacts of invalid depth data on the
reconstruction. In the decoding stage, an Attention Guided Skip Connection
(AG-SC) module is presented to avoid introducing too many depth-irrelevant
features to the reconstruction. The experimental results demonstrate that our
method outperforms the state-of-the-art methods on the popular benchmarks
NYU-Depth V2, DIML, and SUN RGB-D.
</p>
</div>
</dd>
<dt><a name="item421">[421]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01625" title="Abstract">arXiv:2309.01625</a> [<a href="/pdf/2309.01625" title="Download PDF">pdf</a>, <a href="/format/2309.01625" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Information Flow Topology in Mixed Traffic: A Comparative Study between  &quot;Looking Ahead&quot; and &quot;Looking Behind&quot;
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Li%2C+S">Shuai Li</a>, 
<a href="/search/eess?searchtype=author&query=Zheng%2C+H">Haotian Zheng</a>, 
<a href="/search/eess?searchtype=author&query=Wang%2C+J">Jiawei Wang</a>, 
<a href="/search/eess?searchtype=author&query=Chen%2C+C">Chaoyi Chen</a>, 
<a href="/search/eess?searchtype=author&query=Xu%2C+Q">Qing Xu</a>, 
<a href="/search/eess?searchtype=author&query=Wang%2C+J">Jianqiang Wang</a>, 
<a href="/search/eess?searchtype=author&query=Li%2C+K">Keqiang Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This paper has been accepted by 26th IEEE International Conference on Intelligent Transportation Systems ITSC 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">The emergence of connected and automated vehicles (CAVs) promises smoother
traffic flow. In mixed traffic where human-driven vehicles (HDVs) also exist,
existing research mostly focuses on "looking ahead" (i.e., the CAVs receive
information from preceding vehicles) strategies for CAVs, while recent work
reveals that "looking behind" (i.e., the CAVs receive information from their
rear vehicles) strategies might provide more possibilities for CAV longitudinal
control. This paper presents a comparative study between these two types of
information flow topology (IFT) from the string stability perspective, with the
role of maximum platoon size (MPS) also under investigation. Precisely, we
provide a dynamical modeling framework for the mixed platoon under the
multi-predecessor-following (MPF) topology and the multi-successor-leading
(MSL) topology. Then, a unified method for string stability analysis is
presented, with explicit consideration of both IFT and MPS. Numerical results
suggest that MSL ("looking behind") outperforms MPF ("looking ahead" ) in
mitigating traffic perturbations. In addition, increasing MPS could further
improve string stability of mixed traffic flow.
</p>
</div>
</dd>
<dt><a name="item422">[422]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01627" title="Abstract">arXiv:2309.01627</a> [<a href="/pdf/2309.01627" title="Download PDF">pdf</a>, <a href="/format/2309.01627" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Cross-Consistent Deep Unfolding Network for Adaptive All-In-One Video  Restoration
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cheng%2C+Y">Yuanshuo Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Shao%2C+M">Mingwen Shao</a>, 
<a href="/search/cs?searchtype=author&query=Wan%2C+Y">Yecong Wan</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+L">Lixu Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zuo%2C+W">Wangmeng Zuo</a>, 
<a href="/search/cs?searchtype=author&query=Meng%2C+D">Deyu Meng</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 pages, 13 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Existing Video Restoration (VR) methods always necessitate the individual
deployment of models for each adverse weather to remove diverse adverse weather
degradations, lacking the capability for adaptive processing of degradations.
Such limitation amplifies the complexity and deployment costs in practical
applications. To overcome this deficiency, in this paper, we propose a
Cross-consistent Deep Unfolding Network (CDUN) for All-In-One VR, which enables
the employment of a single model to remove diverse degradations for the first
time. Specifically, the proposed CDUN accomplishes a novel iterative
optimization framework, capable of restoring frames corrupted by corresponding
degradations according to the degradation features given in advance. To empower
the framework for eliminating diverse degradations, we devise a Sequence-wise
Adaptive Degradation Estimator (SADE) to estimate degradation features for the
input corrupted video. By orchestrating these two cascading procedures, CDUN
achieves adaptive processing for diverse degradation. In addition, we introduce
a window-based inter-frame fusion strategy to utilize information from more
adjacent frames. This strategy involves the progressive stacking of temporal
windows in multiple iterations, effectively enlarging the temporal receptive
field and enabling each frame's restoration to leverage information from
distant frames. Extensive experiments demonstrate that the proposed method
achieves state-of-the-art performance in All-In-One VR.
</p>
</div>
</dd>
<dt><a name="item423">[423]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01632" title="Abstract">arXiv:2309.01632</a> [<a href="/pdf/2309.01632" title="Download PDF">pdf</a>, <a href="/format/2309.01632" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Representing Edge Flows on Graphs via Sparse Cell Complexes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hoppe%2C+J">Josef Hoppe</a>, 
<a href="/search/cs?searchtype=author&query=Schaub%2C+M+T">Michael T. Schaub</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages, 6 figures (plus appendix). For evaluation code, see <a href="https://anonymous.4open.science/r/edge-flow-repr-cell-complexes-11C5">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>; Machine Learning (cs.LG); Signal Processing (eess.SP)

</div>
<p class="mathjax">Obtaining sparse, interpretable representations of observable data is crucial
in many machine learning and signal processing tasks. For data representing
flows along the edges of a graph, an intuitively interpretable way to obtain
such representations is to lift the graph structure to a simplicial complex:
The eigenvectors of the associated Hodge-Laplacian, respectively the incidence
matrices of the corresponding simplicial complex then induce a Hodge
decomposition, which can be used to represent the observed data in terms of
gradient, curl, and harmonic flows. In this paper, we generalize this approach
to cellular complexes and introduce the cell inference optimization problem,
i.e., the problem of augmenting the observed graph by a set of cells, such that
the eigenvectors of the associated Hodge Laplacian provide a sparse,
interpretable representation of the observed edge flows on the graph. We show
that this problem is NP-hard and introduce an efficient approximation algorithm
for its solution. Experiments on real-world and synthetic data demonstrate that
our algorithm outperforms current state-of-the-art methods while being
computationally efficient.
</p>
</div>
</dd>
<dt><a name="item424">[424]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01633" title="Abstract">arXiv:2309.01633</a> [<a href="/pdf/2309.01633" title="Download PDF">pdf</a>, <a href="/format/2309.01633" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the Analysis and Synthesis of Wind Turbine Side-Side Tower Load  Control via Demodulation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Pamososuryo%2C+A+K">Atindriyo K. Pamososuryo</a>, 
<a href="/search/eess?searchtype=author&query=Mulders%2C+S+P">Sebastiaan P. Mulders</a>, 
<a href="/search/eess?searchtype=author&query=Ferrari%2C+R">Riccardo Ferrari</a>, 
<a href="/search/eess?searchtype=author&query=van+Wingerden%2C+J">Jan-Willem van Wingerden</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">As wind turbine power capacities continue to rise, taller and more flexible
tower designs are needed for support. These designs often have the tower's
natural frequency in the turbine's operating regime, increasing the risk of
resonance excitation and fatigue damage. Advanced load-reducing control methods
are needed to enable flexible tower designs that consider the complex dynamics
of flexible turbine towers during partial-load operation. This paper proposes a
novel modulation-demodulation control (MDC) strategy for side-side tower load
reduction driven by the varying speed of the turbine. The MDC method
demodulates the periodic content at the once-per-revolution (1P) frequency in
the tower motion measurements into two orthogonal channels. The proposed scheme
extends the conventional tower controller by augmentation of the MDC
contribution to the generator torque signal. A linear analysis framework into
the multivariable system in the demodulated domain reveals varying degrees of
coupling at different rotational speeds and a gain sign flip. As a solution, a
decoupling strategy has been developed, which simplifies the controller design
process and allows for a straightforward (but highly effective) diagonal linear
time-invariant controller design. The high-fidelity OpenFAST wind turbine
software evaluates the proposed controller scheme, demonstrating effective
reduction of the 1P periodic loading and the tower's natural frequency
excitation in the side-side tower motion.
</p>
</div>
</dd>
<dt><a name="item425">[425]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01636" title="Abstract">arXiv:2309.01636</a> [<a href="/pdf/2309.01636" title="Download PDF">pdf</a>, <a href="/format/2309.01636" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Finite element approximation for a delayed generalized Burgers-Huxley  equation with weakly singular kernels: Part I Well-posedness, Regularity and  Conforming approximation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Mahajan%2C+S">Sumit Mahajan</a>, 
<a href="/search/math?searchtype=author&query=Khan%2C+A">Arbaz Khan</a>, 
<a href="/search/math?searchtype=author&query=Mohan%2C+M+T">Manil T. Mohan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">The analysis of a delayed generalized Burgers-Huxley equation (a non-linear
advection-diffusion-reaction problem) with weakly singular kernels is carried
out in this work. Moreover, numerical approximations are performed using the
conforming finite element method (CFEM). The existence, uniqueness and
regularity results for the continuous problem have been discussed in detail
using the Faedo-Galerkin approximation technique. For the numerical studies, we
first propose a semi-discrete conforming finite element scheme for space
discretization and discuss its error estimates under minimal regularity
assumptions. We then employ a backward Euler discretization in time and CFEM in
space to obtain a fully-discrete approximation. Additionally, we derive a prior
error estimates for the fully-discrete approximated solution. Finally, we
present computational results that support the derived theoretical results.
</p>
</div>
</dd>
<dt><a name="item426">[426]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01640" title="Abstract">arXiv:2309.01640</a> [<a href="/pdf/2309.01640" title="Download PDF">pdf</a>, <a href="/format/2309.01640" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Corgi^2: A Hybrid Offline-Online Approach To Storage-Aware Data  Shuffling For SGD
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Livne%2C+E">Etay Livne</a>, 
<a href="/search/cs?searchtype=author&query=Kaplun%2C+G">Gal Kaplun</a>, 
<a href="/search/cs?searchtype=author&query=Shai%2C+E+M">Eran Malach Shai</a>, 
<a href="/search/cs?searchtype=author&query=Shalev-Schwatz">Shalev-Schwatz</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 19 pages, 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">When using Stochastic Gradient Descent (SGD) for training machine learning
models, it is often crucial to provide the model with examples sampled at
random from the dataset. However, for large datasets stored in the cloud,
random access to individual examples is often costly and inefficient. A recent
work \cite{corgi}, proposed an online shuffling algorithm called CorgiPile,
which greatly improves efficiency of data access, at the cost some performance
loss, which is particularly apparent for large datasets stored in homogeneous
shards (e.g., video datasets). In this paper, we introduce a novel two-step
partial data shuffling strategy for SGD which combines an offline iteration of
the CorgiPile method with a subsequent online iteration. Our approach enjoys
the best of both worlds: it performs similarly to SGD with random access (even
for homogenous data) without compromising the data access efficiency of
CorgiPile. We provide a comprehensive theoretical analysis of the convergence
properties of our method and demonstrate its practical advantages through
experimental results.
</p>
</div>
</dd>
<dt><a name="item427">[427]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01645" title="Abstract">arXiv:2309.01645</a> [<a href="/pdf/2309.01645" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exploring the effectiveness of ChatGPT-based feedback compared with  teacher feedback and self-feedback: Evidence from Chinese to English  translation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cao%2C+S">Siyi Cao</a>, 
<a href="/search/cs?searchtype=author&query=Zhong%2C+L">Linping Zhong</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">ChatGPT,a cutting-edge AI-powered Chatbot,can quickly generate responses on
given commands. While it was reported that ChatGPT had the capacity to deliver
useful feedback, it is still unclear about its effectiveness compared with
conventional feedback approaches,such as teacher feedback (TF) and
self-feedback (SF). To address this issue, this study compared the revised
Chinese to English translation texts produced by Chinese Master of Translation
and Interpretation (MTI) students,who learned English as a Second/Foreign
Language (ESL/EFL), based on three feedback types (i.e., ChatGPT-based
feedback, TF and SF). The data was analyzed using BLEU score to gauge the
overall translation quality as well as Coh-Metrix to examine linguistic
features across three dimensions: lexicon, syntax, and cohesion.The findings
revealed that TF- and SF-guided translation texts surpassed those with
ChatGPT-based feedback, as indicated by the BLEU score. In terms of linguistic
features,ChatGPT-based feedback demonstrated superiority, particularly in
enhancing lexical capability and referential cohesion in the translation texts.
However, TF and SF proved more effective in developing syntax-related skills,as
it addressed instances of incorrect usage of the passive voice. These diverse
outcomes indicate ChatGPT's potential as a supplementary resource,
complementing traditional teacher-led methods in translation practice.
</p>
</div>
</dd>
<dt><a name="item428">[428]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01646" title="Abstract">arXiv:2309.01646</a> [<a href="/pdf/2309.01646" title="Download PDF">pdf</a>, <a href="/format/2309.01646" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ReLoc-PDR: Visual Relocalization Enhanced Pedestrian Dead Reckoning via  Graph Optimization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+Z">Zongyang Chen</a>, 
<a href="/search/cs?searchtype=author&query=Pan%2C+X">Xianfei Pan</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+C">Changhao Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages, 14 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Accurately and reliably positioning pedestrians in satellite-denied
conditions remains a significant challenge. Pedestrian dead reckoning (PDR) is
commonly employed to estimate pedestrian location using low-cost inertial
sensor. However, PDR is susceptible to drift due to sensor noise, incorrect
step detection, and inaccurate stride length estimation. This work proposes
ReLoc-PDR, a fusion framework combining PDR and visual relocalization using
graph optimization. ReLoc-PDR leverages time-correlated visual observations and
learned descriptors to achieve robust positioning in visually-degraded
environments. A graph optimization-based fusion mechanism with the Tukey kernel
effectively corrects cumulative errors and mitigates the impact of abnormal
visual observations. Real-world experiments demonstrate that our ReLoc-PDR
surpasses representative methods in accuracy and robustness, achieving accurte
and robust pedestrian positioning results using only a smartphone in
challenging environments such as less-textured corridors and dark nighttime
scenarios.
</p>
</div>
</dd>
<dt><a name="item429">[429]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01647" title="Abstract">arXiv:2309.01647</a> [<a href="/pdf/2309.01647" title="Download PDF">pdf</a>, <a href="/format/2309.01647" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Robust Velocity and Position Estimation of Opponents for  Autonomous Racing Using Low-Power Radar
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ronco%2C+A">Andrea Ronco</a>, 
<a href="/search/cs?searchtype=author&query=Baumann%2C+N">Nicolas Baumann</a>, 
<a href="/search/cs?searchtype=author&query=Giordano%2C+M">Marco Giordano</a>, 
<a href="/search/cs?searchtype=author&query=Magno%2C+M">Michele Magno</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Signal Processing (eess.SP); Systems and Control (eess.SY)

</div>
<p class="mathjax">This paper presents the design and development of an intelligent subsystem
that includes a novel low-power radar sensor integrated into an autonomous
racing perception pipeline to robustly estimate the position and velocity of
dynamic obstacles. The proposed system, based on the Infineon BGT60TR13D radar,
is evaluated in a real-world scenario with scaled race cars. The paper explores
the benefits and limitations of using such a sensor subsystem and draws
conclusions based on field-collected data. The results demonstrate a tracking
error up to 0.21 +- 0.29 m in distance estimation and 0.39 +- 0.19 m/s in
velocity estimation, despite the power consumption in the range of 10s of
milliwatts. The presented system provides complementary information to other
sensors such as LiDAR and camera, and can be used in a wide range of
applications beyond autonomous racing.
</p>
</div>
</dd>
<dt><a name="item430">[430]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01655" title="Abstract">arXiv:2309.01655</a> [<a href="/pdf/2309.01655" title="Download PDF">pdf</a>, <a href="/format/2309.01655" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Rate-Splitting and Sum-DoF for the $K$-User MISO Broadcast Channel with  Mixed CSIT and Order-$(K-1)$ Messages
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zheng%2C+S">Shuo Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+T">Tong Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jingfu Li</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Shuai Wang</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+W">Weijie Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+G">Gaojie Chen</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+R">Rui Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This work has been accepted by VTC2023-Fall
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>

</div>
<p class="mathjax">In this paper, we propose a rate-splitting design and characterize the
sum-degrees-of-freedom (DoF) for the $K$-user multiple-input-single-output
(MISO) broadcast channel with mixed channel state information at the
transmitter (CSIT) and order-$(K-1)$ messages, where mixed CSIT refers to the
delayed and imperfect-current CSIT, and order-$(K-1)$ message refers to the
message desired by $K-1$ users simultaneously. In particular, for the sum-DoF
lower bound, we propose a rate-splitting scheme embedding with retrospective
interference alignment. In addition, we propose a matching sum-DoF upper bound
via genie signalings and extremal inequality. Opposed to existing works for
$K=2$, our results show that the sum-DoF is saturated with CSIT quality when
CSIT quality thresholds are satisfied for $K&gt;2$.
</p>
</div>
</dd>
<dt><a name="item431">[431]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01656" title="Abstract">arXiv:2309.01656</a> [<a href="/pdf/2309.01656" title="Download PDF">pdf</a>, <a href="/format/2309.01656" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Building Footprint Extraction in Dense Areas using Super Resolution and  Frame Field Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+V">Vuong Nguyen</a>, 
<a href="/search/cs?searchtype=author&query=Ho%2C+A">Anh Ho</a>, 
<a href="/search/cs?searchtype=author&query=Vu%2C+D">Duc-Anh Vu</a>, 
<a href="/search/cs?searchtype=author&query=Anh%2C+N+T+N">Nguyen Thi Ngoc Anh</a>, 
<a href="/search/cs?searchtype=author&query=Thang%2C+T+N">Tran Ngoc Thang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at The 12th International Conference on Awareness Science and Technology
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Despite notable results on standard aerial datasets, current
state-of-the-arts fail to produce accurate building footprints in dense areas
due to challenging properties posed by these areas and limited data
availability. In this paper, we propose a framework to address such issues in
polygonal building extraction. First, super resolution is employed to enhance
the spatial resolution of aerial image, allowing for finer details to be
captured. This enhanced imagery serves as input to a multitask learning module,
which consists of a segmentation head and a frame field learning head to
effectively handle the irregular building structures. Our model is supervised
by adaptive loss weighting, enabling extraction of sharp edges and fine-grained
polygons which is difficult due to overlapping buildings and low data quality.
Extensive experiments on a slum area in India that mimics a dense area
demonstrate that our proposed approach significantly outperforms the current
state-of-the-art methods by a large margin.
</p>
</div>
</dd>
<dt><a name="item432">[432]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01659" title="Abstract">arXiv:2309.01659</a> [<a href="/pdf/2309.01659" title="Download PDF">pdf</a>, <a href="/format/2309.01659" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Evolving linguistic divergence on polarizing social media
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Karjus%2C+A">Andres Karjus</a>, 
<a href="/search/cs?searchtype=author&query=Cuskley%2C+C">Christine Cuskley</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>; Computation and Language (cs.CL)

</div>
<p class="mathjax">Language change is influenced by many factors, but often starts from
synchronic variation, where multiple linguistic patterns or forms coexist, or
where different speech communities use language in increasingly different ways.
Besides regional or economic reasons, communities may form and segregate based
on political alignment. The latter, referred to as political polarization, is
of growing societal concern across the world. Here we map and quantify
linguistic divergence across the partisan left-right divide in the United
States, using social media data. We develop a general methodology to delineate
(social) media users by their political preference, based on which (potentially
biased) news media accounts they do and do not follow on a given platform. Our
data consists of 1.5M short posts by 10k users (about 20M words) from the
social media platform Twitter (now "X"). Delineating this sample involved
mining the platform for the lists of followers (n=422M) of 72 large news media
accounts. We quantify divergence in topics of conversation and word
frequencies, messaging sentiment, and lexical semantics of words and emoji. We
find signs of linguistic divergence across all these aspects, especially in
topics and themes of conversation, in line with previous research. While US
American English remains largely intelligible within its large speech
community, our findings point at areas where miscommunication may eventually
arise given ongoing polarization and therefore potential linguistic divergence.
Our methodology - combining data mining, lexicostatistics, machine learning,
large language models and a systematic human annotation approach - is largely
language and platform agnostic. In other words, while we focus here on US
political divides and US English, the same approach is applicable to other
countries, languages, and social media platforms.
</p>
</div>
</dd>
<dt><a name="item433">[433]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01660" title="Abstract">arXiv:2309.01660</a> [<a href="/pdf/2309.01660" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Unveiling Theory of Mind in Large Language Models: A Parallel to Single  Neurons in the Human Brain
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jamali%2C+M">Mohsen Jamali</a>, 
<a href="/search/cs?searchtype=author&query=Williams%2C+Z+M">Ziv M. Williams</a>, 
<a href="/search/cs?searchtype=author&query=Cai%2C+J">Jing Cai</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">With their recent development, large language models (LLMs) have been found
to exhibit a certain level of Theory of Mind (ToM), a complex cognitive
capacity that is related to our conscious mind and that allows us to infer
another's beliefs and perspective. While human ToM capabilities are believed to
derive from the neural activity of a broadly interconnected brain network,
including that of dorsal medial prefrontal cortex (dmPFC) neurons, the precise
processes underlying LLM's capacity for ToM or their similarities with that of
humans remains largely unknown. In this study, we drew inspiration from the
dmPFC neurons subserving human ToM and employed a similar methodology to
examine whether LLMs exhibit comparable characteristics. Surprisingly, our
analysis revealed a striking resemblance between the two, as hidden embeddings
(artificial neurons) within LLMs started to exhibit significant responsiveness
to either true- or false-belief trials, suggesting their ability to represent
another's perspective. These artificial embedding responses were closely
correlated with the LLMs' performance during the ToM tasks, a property that was
dependent on the size of the models. Further, the other's beliefs could be
accurately decoded using the entire embeddings, indicating the presence of the
embeddings' ToM capability at the population level. Together, our findings
revealed an emergent property of LLMs' embeddings that modified their
activities in response to ToM features, offering initial evidence of a parallel
between the artificial model and neurons in the human brain.
</p>
</div>
</dd>
<dt><a name="item434">[434]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01662" title="Abstract">arXiv:2309.01662</a> [<a href="/pdf/2309.01662" title="Download PDF">pdf</a>, <a href="/ps/2309.01662" title="Download PostScript">ps</a>, <a href="/format/2309.01662" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Persistent Memory based Stateful Serverless Computing for Big  Data Applications
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yuze Li</a>, 
<a href="/search/cs?searchtype=author&query=Assogba%2C+K">Kevin Assogba</a>, 
<a href="/search/cs?searchtype=author&query=Tripathy%2C+A">Abhijit Tripathy</a>, 
<a href="/search/cs?searchtype=author&query=Arif%2C+M">Moiz Arif</a>, 
<a href="/search/cs?searchtype=author&query=Rafique%2C+M+M">M. Mustafa Rafique</a>, 
<a href="/search/cs?searchtype=author&query=Butt%2C+A+R">Ali R. Butt</a>, 
<a href="/search/cs?searchtype=author&query=Nikolopoulos%2C+D">Dimitrios Nikolopoulos</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>; Performance (cs.PF)

</div>
<p class="mathjax">The Function-as-a-service (FaaS) computing model has recently seen
significant growth especially for highly scalable, event-driven applications.
The easy-to-deploy and cost-efficient fine-grained billing of FaaS is highly
attractive to big data applications. However, the stateless nature of
serverless platforms poses major challenges when supporting stateful I/O
intensive workloads such as a lack of native support for stateful execution,
state sharing, and inter-function communication. In this paper, we explore the
feasibility of performing stateful big data analytics on serverless platforms
and improving I/O throughput of functions by using modern storage technologies
such as Intel Optane DC Persistent Memory (PMEM). To this end, we propose
Marvel, an end-to-end architecture built on top of the popular serverless
platform, Apache OpenWhisk and Apache Hadoop. Marvel makes two main
contributions: (1) enable stateful function execution on OpenWhisk by
maintaining state information in an in-memory caching layer; and (2) provide
access to PMEM backed HDFS storage for faster I/O performance. Our evaluation
shows that Marvel reduces the overall execution time of big data applications
by up to 86.6% compared to current MapReduce implementations on AWS Lambda.
</p>
</div>
</dd>
<dt><a name="item435">[435]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01664" title="Abstract">arXiv:2309.01664</a> [<a href="/pdf/2309.01664" title="Download PDF">pdf</a>, <a href="/ps/2309.01664" title="Download PostScript">ps</a>, <a href="/format/2309.01664" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fine-grained Affective Processing Capabilities Emerging from Large  Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Broekens%2C+J">Joost Broekens</a>, 
<a href="/search/cs?searchtype=author&query=Hilpert%2C+B">Bernhard Hilpert</a>, 
<a href="/search/cs?searchtype=author&query=Verberne%2C+S">Suzan Verberne</a>, 
<a href="/search/cs?searchtype=author&query=Baraka%2C+K">Kim Baraka</a>, 
<a href="/search/cs?searchtype=author&query=Gebhard%2C+P">Patrick Gebhard</a>, 
<a href="/search/cs?searchtype=author&query=Plaat%2C+A">Aske Plaat</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Human-Computer Interaction (cs.HC)

</div>
<p class="mathjax">Large language models, in particular generative pre-trained transformers
(GPTs), show impressive results on a wide variety of language-related tasks. In
this paper, we explore ChatGPT's zero-shot ability to perform affective
computing tasks using prompting alone. We show that ChatGPT a) performs
meaningful sentiment analysis in the Valence, Arousal and Dominance dimensions,
b) has meaningful emotion representations in terms of emotion categories and
these affective dimensions, and c) can perform basic appraisal-based emotion
elicitation of situations based on a prompt-based computational implementation
of the OCC appraisal model. These findings are highly relevant: First, they
show that the ability to solve complex affect processing tasks emerges from
language-based token prediction trained on extensive data sets. Second, they
show the potential of large language models for simulating, processing and
analyzing human emotions, which has important implications for various
applications such as sentiment analysis, socially interactive agents, and
social robotics.
</p>
</div>
</dd>
<dt><a name="item436">[436]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01667" title="Abstract">arXiv:2309.01667</a> [<a href="/pdf/2309.01667" title="Download PDF">pdf</a>, <a href="/format/2309.01667" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Pisces: Private and Compliable Cryptocurrency Exchange
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Ya-nan Li</a> (1), 
<a href="/search/cs?searchtype=author&query=Qiu%2C+T">Tian Qiu</a> (1), 
<a href="/search/cs?searchtype=author&query=Tang%2C+Q">Qiang Tang</a> (1) ((1) The University of Sydney)
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 27 pages, 8 figures, 2 tables. To be published in NDSS'24. This is the full version of the conference paper
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">Cryptocurrency exchange platforms such as Coinbase, Binance, enable users to
purchase and sell cryptocurrencies conveniently just like trading
stocks/commodities. However, because of the nature of blockchain, when a user
withdraws coins (i.e., transfers coins to an external on-chain account), all
future transactions can be learned by the platform. This is in sharp contrast
to conventional stock exchange where all external activities of users are
always hidden from the platform. Since the platform knows highly sensitive user
private information such as passport number, bank information etc, linking all
(on-chain) transactions raises a serious privacy concern about the potential
disastrous data breach in those cryptocurrency exchange platforms.
<br />In this paper, we propose a cryptocurrency exchange that restores user
anonymity for the first time. To our surprise, the seemingly well-studied
privacy/anonymity problem has several new challenges in this setting. Since the
public blockchain and internal transaction activities naturally provide many
non-trivial leakages to the platform, internal privacy is not only useful in
the usual sense but also becomes necessary for regaining the basic anonymity of
user transactions. We also ensure that the user cannot double spend, and the
user has to properly report accumulated profit for tax purposes, even in the
private setting. We give a careful modeling and efficient construction of the
system that achieves constant computation and communication overhead (with only
simple cryptographic tools and rigorous security analysis); we also implement
our system and evaluate its practical performance.
</p>
</div>
</dd>
<dt><a name="item437">[437]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01669" title="Abstract">arXiv:2309.01669</a> [<a href="/pdf/2309.01669" title="Download PDF">pdf</a>, <a href="/format/2309.01669" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Donkii: Can Annotation Error Detection Methods Find Errors in  Instruction-Tuning Datasets?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Weber-Genzel%2C+L">Leon Weber-Genzel</a>, 
<a href="/search/cs?searchtype=author&query=Litschko%2C+R">Robert Litschko</a>, 
<a href="/search/cs?searchtype=author&query=Artemova%2C+E">Ekaterina Artemova</a>, 
<a href="/search/cs?searchtype=author&query=Plank%2C+B">Barbara Plank</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Instruction-tuning has become an integral part of training pipelines for
Large Language Models (LLMs) and has been shown to yield strong performance
gains. In an orthogonal line of research, Annotation Error Detection (AED) has
emerged as a tool for detecting quality issues of gold-standard labels. But so
far, the application of AED methods is limited to discriminative settings. It
is an open question how well AED methods generalize to generative settings
which are becoming widespread via generative LLMs. In this work, we present a
first and new benchmark for AED on instruction-tuning data: Donkii. It
encompasses three instruction-tuning datasets enriched with annotations by
experts and semi-automatic methods. We find that all three datasets contain
clear-cut errors that sometimes directly propagate into instruction-tuned LLMs.
We propose four AED baselines for the generative setting and evaluate them
comprehensively on the newly introduced dataset. Our results demonstrate that
choosing the right AED method and model size is indeed crucial, thereby
deriving practical recommendations. To gain insights, we provide a first
case-study to examine how the quality of the instruction-tuning datasets
influences downstream performance.
</p>
</div>
</dd>
<dt><a name="item438">[438]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01671" title="Abstract">arXiv:2309.01671</a> [<a href="/pdf/2309.01671" title="Download PDF">pdf</a>, <a href="/format/2309.01671" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Simple Pipeline for Orthogonal Graph Drawing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hegemann%2C+T">Tim Hegemann</a>, 
<a href="/search/cs?searchtype=author&query=Wolff%2C+A">Alexander Wolff</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Appears in the Proceedings of the 31st International Symposium on Graph Drawing and Network Visualization (GD 2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Geometry (cs.CG)</span>

</div>
<p class="mathjax">Orthogonal graph drawing has many applications, e.g., for laying out UML
diagrams or cableplans. In this paper, we present a new pipeline that draws
multigraphs orthogonally, using few bends, few crossings, and small area. Our
pipeline computes an initial graph layout, then removes overlaps between the
rectangular nodes, routes the edges, orders the edges, and nudges them, that
is, moves edge segments in order to balance the inter-edge distances. Our
pipeline is flexible and integrates well with existing approaches. Our main
contribution is (i) an effective edge-nudging algorithm that is based on linear
programming, (ii) a selection of simple algorithms that together produce
competitive results, and (iii) an extensive experimental comparison of our
pipeline with existing approaches using standard benchmark sets and metrics.
</p>
</div>
</dd>
<dt><a name="item439">[439]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01674" title="Abstract">arXiv:2309.01674</a> [<a href="/pdf/2309.01674" title="Download PDF">pdf</a>, <a href="/format/2309.01674" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Prompt me a Dataset: An investigation of text-image prompting for  historical image dataset creation using foundation models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=El-Hajj%2C+H">Hassan El-Hajj</a>, 
<a href="/search/cs?searchtype=author&query=Valleriani%2C+M">Matteo Valleriani</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 3 figures, Accepted in ICIAP2023, AI4DH workshop
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Digital Libraries (cs.DL)

</div>
<p class="mathjax">In this paper, we present a pipeline for image extraction from historical
documents using foundation models, and evaluate text-image prompts and their
effectiveness on humanities datasets of varying levels of complexity. The
motivation for this approach stems from the high interest of historians in
visual elements printed alongside historical texts on the one hand, and from
the relative lack of well-annotated datasets within the humanities when
compared to other domains. We propose a sequential approach that relies on
GroundDINO and Meta's Segment-Anything-Model (SAM) to retrieve a significant
portion of visual data from historical documents that can then be used for
downstream development tasks and dataset creation, as well as evaluate the
effect of different linguistic prompts on the resulting detections.
</p>
</div>
</dd>
<dt><a name="item440">[440]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01679" title="Abstract">arXiv:2309.01679</a> [<a href="/pdf/2309.01679" title="Download PDF">pdf</a>, <a href="/ps/2309.01679" title="Download PostScript">ps</a>, <a href="/format/2309.01679" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Stochastic Model Predictive Control for Networked Systems with Random  Delays and Packet Losses in All Channels
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Palmisano%2C+M">Marijan Palmisano</a>, 
<a href="/search/eess?searchtype=author&query=Steinberger%2C+M">Martin Steinberger</a>, 
<a href="/search/eess?searchtype=author&query=Horn%2C+M">Martin Horn</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">A stochastic Model Predictive Control strategy for control systems with
communication networks between the sensor node and the controller and between
the controller and the actuator node is proposed. Data packets are subject to
random delays and packet loss is possible; acknowledgments for received packets
are not provided. The expected value of a quadratic cost is minimized subject
to linear constraints; the set of all initial states for which the resulting
optimization problem is guaranteed to be feasible is provided. The state vector
of the controlled plant is shown to converge to zero with probability one.
</p>
</div>
</dd>
<dt><a name="item441">[441]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01681" title="Abstract">arXiv:2309.01681</a> [<a href="/pdf/2309.01681" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Serverless Computing for Scientific Applications
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Malawski%2C+M">Maciej Malawski</a>, 
<a href="/search/cs?searchtype=author&query=Balis%2C+B">Bartosz Balis</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> in IEEE Internet Computing, vol. 26, no. 4, pp. 53-58, 1 July-Aug.
  2022
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>

</div>
<p class="mathjax">Serverless computing has become an important model in cloud computing and
influenced the design of many applications. Here, we provide our perspective on
how the recent landscape of serverless computing for scientific applications
looks like. We discuss the advantages and problems with serverless computing
for scientific applications, and based on the analysis of existing solutions
and approaches, we propose a science-oriented architecture for a serverless
computing framework that is based on the existing designs. Finally, we provide
an outlook of current trends and future directions.
</p>
</div>
</dd>
<dt><a name="item442">[442]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01682" title="Abstract">arXiv:2309.01682</a> [<a href="/pdf/2309.01682" title="Download PDF">pdf</a>, <a href="/format/2309.01682" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Prior Knowledge Guided Network for Video Anomaly Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Deng%2C+Z">Zhewen Deng</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+D">Dongyue Chen</a>, 
<a href="/search/cs?searchtype=author&query=Deng%2C+S">Shizhuo Deng</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, 4 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Video Anomaly Detection (VAD) involves detecting anomalous events in videos,
presenting a significant and intricate task within intelligent video
surveillance. Existing studies often concentrate solely on features acquired
from limited normal data, disregarding the latent prior knowledge present in
extensive natural image datasets. To address this constraint, we propose a
Prior Knowledge Guided Network(PKG-Net) for the VAD task. First, an
auto-encoder network is incorporated into a teacher-student architecture to
learn two designated proxy tasks: future frame prediction and teacher network
imitation, which can provide better generalization ability on unknown samples.
Second, knowledge distillation on proper feature blocks is also proposed to
increase the multi-scale detection ability of the model. In addition,
prediction error and teacher-student feature inconsistency are combined to
evaluate anomaly scores of inference samples more comprehensively. Experimental
results on three public benchmarks validate the effectiveness and accuracy of
our method, which surpasses recent state-of-the-arts.
</p>
</div>
</dd>
<dt><a name="item443">[443]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01684" title="Abstract">arXiv:2309.01684</a> [<a href="/pdf/2309.01684" title="Download PDF">pdf</a>, <a href="/format/2309.01684" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CRUISE-Screening: Living Literature Reviews Toolbox
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kusa%2C+W">Wojciech Kusa</a>, 
<a href="/search/cs?searchtype=author&query=Knoth%2C+P">Petr Knoth</a>, 
<a href="/search/cs?searchtype=author&query=Hanbury%2C+A">Allan Hanbury</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Paper accepted at CIKM 2023. The arXiv version has an extra section about limitations in the Appendix that is not present in the ACM version
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Computation and Language (cs.CL); Digital Libraries (cs.DL)

</div>
<p class="mathjax">Keeping up with research and finding related work is still a time-consuming
task for academics. Researchers sift through thousands of studies to identify a
few relevant ones. Automation techniques can help by increasing the efficiency
and effectiveness of this task. To this end, we developed CRUISE-Screening, a
web-based application for conducting living literature reviews - a type of
literature review that is continuously updated to reflect the latest research
in a particular field. CRUISE-Screening is connected to several search engines
via an API, which allows for updating the search results periodically.
Moreover, it can facilitate the process of screening for relevant publications
by using text classification and question answering models. CRUISE-Screening
can be used both by researchers conducting literature reviews and by those
working on automating the citation screening process to validate their
algorithms. The application is open-source:
https://github.com/ProjectDoSSIER/cruise-screening, and a demo is available
under this URL: https://citation-screening.ec.tuwien.ac.at. We discuss the
limitations of our tool in Appendix A.
</p>
</div>
</dd>
<dt><a name="item444">[444]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01686" title="Abstract">arXiv:2309.01686</a> [<a href="/pdf/2309.01686" title="Download PDF">pdf</a>, <a href="/format/2309.01686" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MathAttack: Attacking Large Language Models Towards Math Solving Ability
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Z">Zihao Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Q">Qiufeng Wang</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+M">Mingyu Jin</a>, 
<a href="/search/cs?searchtype=author&query=Yao%2C+J">Jie Yao</a>, 
<a href="/search/cs?searchtype=author&query=Ye%2C+J">Jianan Ye</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+W">Wei Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+W">Wei Wang</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+X">Xiaowei Huang</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+K">Kaizhu Huang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages, 6 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">With the boom of Large Language Models (LLMs), the research of solving Math
Word Problem (MWP) has recently made great progress. However, there are few
studies to examine the security of LLMs in math solving ability. Instead of
attacking prompts in the use of LLMs, we propose a MathAttack model to attack
MWP samples which are closer to the essence of security in solving math
problems. Compared to traditional text adversarial attack, it is essential to
preserve the mathematical logic of original MWPs during the attacking. To this
end, we propose logical entity recognition to identify logical entries which
are then frozen. Subsequently, the remaining text are attacked by adopting a
word-level attacker. Furthermore, we propose a new dataset RobustMath to
evaluate the robustness of LLMs in math solving ability. Extensive experiments
on our RobustMath and two another math benchmark datasets GSM8K and MultiAirth
show that MathAttack could effectively attack the math solving ability of LLMs.
In the experiments, we observe that (1) Our adversarial samples from
higher-accuracy LLMs are also effective for attacking LLMs with lower accuracy
(e.g., transfer from larger to smaller-size LLMs, or from few-shot to zero-shot
prompts); (2) Complex MWPs (such as more solving steps, longer text, more
numbers) are more vulnerable to attack; (3) We can improve the robustness of
LLMs by using our adversarial samples in few-shot prompts. Finally, we hope our
practice and observation can serve as an important attempt towards enhancing
the robustness of LLMs in math solving ability. We will release our code and
dataset.
</p>
</div>
</dd>
<dt><a name="item445">[445]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01689" title="Abstract">arXiv:2309.01689</a> [<a href="/pdf/2309.01689" title="Download PDF">pdf</a>, <a href="/format/2309.01689" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Motion Cueing Algorithm for Effective Motion Perception: A  frequency-splitting MPC Approach
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jain%2C+V">Vishrut Jain</a>, 
<a href="/search/cs?searchtype=author&query=Lazcano%2C+A">Andrea Lazcano</a>, 
<a href="/search/cs?searchtype=author&query=Happee%2C+R">Riender Happee</a>, 
<a href="/search/cs?searchtype=author&query=Shyrokau%2C+B">Barys Shyrokau</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 10 figures, 3 tables, conference (DSC 2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Optimization and Control (math.OC)

</div>
<p class="mathjax">Model predictive control (MPC) is a promising technique for motion cueing in
driving simulators, but its high computation time limits widespread real-time
application. This paper proposes a hybrid algorithm that combines filter-based
and MPC-based techniques to improve specific force tracking while reducing
computation time. The proposed algorithm divides the reference acceleration
into low-frequency and high-frequency components. The high-frequency component
serves as a reference for translational motion to avoid workspace limit
violations, while the low-frequency component is for tilt coordination. The
total acceleration serves as a reference for combined specific force with the
highest priority to enable compensation of deviations from its reference
values. The algorithm uses constraints in the MPC formulation to account for
workspace limits and workspace management is applied. The investigated
scenarios were a step signal, a multi-sine wave and a recorded real-drive
slalom maneuver. Based on the conducted simulations, the algorithm produces
approximately 15% smaller root means squared error (RMSE) for the step signal
compared to the state-of-the-art. Around 16% improvement is observed when the
real-drive scenario is used as the simulation scenario, and for the multi-sine
wave, 90% improvement is observed. At higher prediction horizons the algorithm
matches the performance of a state-of-the-art MPC-based motion cueing
algorithm. Finally, for all prediction horizons, the frequency-splitting
algorithm produced faster results. The pre-generated references reduce the
required prediction horizon and computational complexity while improving
tracking performance. Hence, the proposed frequency-splitting algorithm
outperforms state-of-the-art MPC-based algorithm and offers promise for
real-time application in driving simulators.
</p>
</div>
</dd>
<dt><a name="item446">[446]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01692" title="Abstract">arXiv:2309.01692</a> [<a href="/pdf/2309.01692" title="Download PDF">pdf</a>, <a href="/format/2309.01692" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Mask-Attention-Free Transformer for 3D Instance Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lai%2C+X">Xin Lai</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+Y">Yuhui Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Chu%2C+R">Ruihang Chu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yukang Chen</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+H">Han Hu</a>, 
<a href="/search/cs?searchtype=author&query=Jia%2C+J">Jiaya Jia</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to ICCV 2023. Code and models are available at <a href="https://github.com/dvlab-research/Mask-Attention-Free-Transformer">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Recently, transformer-based methods have dominated 3D instance segmentation,
where mask attention is commonly involved. Specifically, object queries are
guided by the initial instance masks in the first cross-attention, and then
iteratively refine themselves in a similar manner. However, we observe that the
mask-attention pipeline usually leads to slow convergence due to low-recall
initial instance masks. Therefore, we abandon the mask attention design and
resort to an auxiliary center regression task instead. Through center
regression, we effectively overcome the low-recall issue and perform
cross-attention by imposing positional prior. To reach this goal, we develop a
series of position-aware designs. First, we learn a spatial distribution of 3D
locations as the initial position queries. They spread over the 3D space
densely, and thus can easily capture the objects in a scene with a high recall.
Moreover, we present relative position encoding for the cross-attention and
iterative refinement for more accurate position queries. Experiments show that
our approach converges 4x faster than existing work, sets a new state of the
art on ScanNetv2 3D instance segmentation benchmark, and also demonstrates
superior performance across various datasets. Code and models are available at
https://github.com/dvlab-research/Mask-Attention-Free-Transformer.
</p>
</div>
</dd>
<dt><a name="item447">[447]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01694" title="Abstract">arXiv:2309.01694</a> [<a href="/pdf/2309.01694" title="Download PDF">pdf</a>, <a href="/format/2309.01694" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> No Data Augmentation? Alternative Regularizations for Effective Training  on Small Datasets
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Brigato%2C+L">Lorenzo Brigato</a>, 
<a href="/search/cs?searchtype=author&query=Mougiakakou%2C+S">Stavroula Mougiakakou</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 4th Visual Inductive Priors for Data-Efficient Deep Learning Workshop, ICCVW 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Solving image classification tasks given small training datasets remains an
open challenge for modern computer vision. Aggressive data augmentation and
generative models are among the most straightforward approaches to overcoming
the lack of data. However, the first fails to be agnostic to varying image
domains, while the latter requires additional compute and careful design. In
this work, we study alternative regularization strategies to push the limits of
supervised learning on small image classification datasets. In particular,
along with the model size and training schedule scaling, we employ a heuristic
to select (semi) optimal learning rate and weight decay couples via the norm of
model parameters. By training on only 1% of the original CIFAR-10 training set
(i.e., 50 images per class) and testing on ciFAIR-10, a variant of the original
CIFAR without duplicated images, we reach a test accuracy of 66.5%, on par with
the best state-of-the-art methods.
</p>
</div>
</dd>
<dt><a name="item448">[448]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01697" title="Abstract">arXiv:2309.01697</a> [<a href="/pdf/2309.01697" title="Download PDF">pdf</a>, <a href="/format/2309.01697" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Physics-Informed Polynomial Chaos Expansions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nov%C3%A1k%2C+L">Luk&#xe1;&#x161; Nov&#xe1;k</a>, 
<a href="/search/cs?searchtype=author&query=Sharma%2C+H">Himanshu Sharma</a>, 
<a href="/search/cs?searchtype=author&query=Shields%2C+M+D">Michael D. Shields</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Data Analysis, Statistics and Probability (physics.data-an)

</div>
<p class="mathjax">Surrogate modeling of costly mathematical models representing physical
systems is challenging since it is typically not possible to create a large
experimental design. Thus, it is beneficial to constrain the approximation to
adhere to the known physics of the model. This paper presents a novel
methodology for the construction of physics-informed polynomial chaos
expansions (PCE) that combines the conventional experimental design with
additional constraints from the physics of the model. Physical constraints
investigated in this paper are represented by a set of differential equations
and specified boundary conditions. A computationally efficient means for
construction of physically constrained PCE is proposed and compared to standard
sparse PCE. It is shown that the proposed algorithms lead to superior accuracy
of the approximation and does not add significant computational burden.
Although the main purpose of the proposed method lies in combining data and
physical constraints, we show that physically constrained PCEs can be
constructed from differential equations and boundary conditions alone without
requiring evaluations of the original model. We further show that the
constrained PCEs can be easily applied for uncertainty quantification through
analytical post-processing of a reduced PCE filtering out the influence of all
deterministic space-time variables. Several deterministic examples of
increasing complexity are provided and the proposed method is applied for
uncertainty quantification.
</p>
</div>
</dd>
<dt><a name="item449">[449]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01698" title="Abstract">arXiv:2309.01698</a> [<a href="/pdf/2309.01698" title="Download PDF">pdf</a>, <a href="/ps/2309.01698" title="Download PostScript">ps</a>, <a href="/format/2309.01698" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Robust Online Classification: From Estimation to Denoising
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+C">Changlong Wu</a>, 
<a href="/search/cs?searchtype=author&query=Grama%2C+A">Ananth Grama</a>, 
<a href="/search/cs?searchtype=author&query=Szpankowski%2C+W">Wojciech Szpankowski</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">We study online classification in the presence of noisy labels. The noise
mechanism is modeled by a general kernel that specifies, for any feature-label
pair, a (known) set of distributions over noisy labels. At each time step, an
adversary selects an unknown distribution from the distribution set specified
by the kernel based on the actual feature-label pair, and generates the noisy
label from the selected distribution. The learner then makes a prediction based
on the actual features and noisy labels observed thus far, and incurs loss $1$
if the prediction differs from the underlying truth (and $0$ otherwise). The
prediction quality is quantified through minimax risk, which computes the
cumulative loss over a finite horizon $T$. We show that for a wide range of
natural noise kernels, adversarially selected features, and finite class of
labeling functions, minimax risk can be upper bounded independent of the time
horizon and logarithmic in the size of labeling function class. We then extend
these results to inifinite classes and stochastically generated features via
the concept of stochastic sequential covering. Our results extend and encompass
findings of Ben-David et al. (2009) through substantial generality, and provide
intuitive understanding through a novel reduction to online conditional
distribution estimation.
</p>
</div>
</dd>
<dt><a name="item450">[450]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01700" title="Abstract">arXiv:2309.01700</a> [<a href="/pdf/2309.01700" title="Download PDF">pdf</a>, <a href="/format/2309.01700" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ControlMat: A Controlled Generative Approach to Material Capture
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Vecchio%2C+G">Giuseppe Vecchio</a>, 
<a href="/search/cs?searchtype=author&query=Martin%2C+R">Rosalie Martin</a>, 
<a href="/search/cs?searchtype=author&query=Roullier%2C+A">Arthur Roullier</a>, 
<a href="/search/cs?searchtype=author&query=Kaiser%2C+A">Adrien Kaiser</a>, 
<a href="/search/cs?searchtype=author&query=Rouffet%2C+R">Romain Rouffet</a>, 
<a href="/search/cs?searchtype=author&query=Deschaintre%2C+V">Valentin Deschaintre</a>, 
<a href="/search/cs?searchtype=author&query=Boubekeur%2C+T">Tamy Boubekeur</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Graphics (cs.GR)

</div>
<p class="mathjax">Material reconstruction from a photograph is a key component of 3D content
creation democratization. We propose to formulate this ill-posed problem as a
controlled synthesis one, leveraging the recent progress in generative deep
networks. We present ControlMat, a method which, given a single photograph with
uncontrolled illumination as input, conditions a diffusion model to generate
plausible, tileable, high-resolution physically-based digital materials. We
carefully analyze the behavior of diffusion models for multi-channel outputs,
adapt the sampling process to fuse multi-scale information and introduce rolled
diffusion to enable both tileability and patched diffusion for high-resolution
outputs. Our generative approach further permits exploration of a variety of
materials which could correspond to the input image, mitigating the unknown
lighting conditions. We show that our approach outperforms recent inference and
latent-space-optimization methods, and carefully validate our diffusion process
design choices. Supplemental materials and additional details are available at:
https://gvecchio.com/controlmat/.
</p>
</div>
</dd>
<dt><a name="item451">[451]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01706" title="Abstract">arXiv:2309.01706</a> [<a href="/pdf/2309.01706" title="Download PDF">pdf</a>, <a href="/format/2309.01706" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the Robustness of Post-hoc GNN Explainers to Label Noise
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhong%2C+Z">Zhiqiang Zhong</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+Y">Yangqianzi Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Mottin%2C+D">Davide Mottin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Proposed as a solution to the inherent black-box limitations of graph neural
networks (GNNs), post-hoc GNN explainers aim to provide precise and insightful
explanations of the behaviours exhibited by trained GNNs. Despite their recent
notable advancements in academic and industrial contexts, the robustness of
post-hoc GNN explainers remains unexplored when confronted with label noise. To
bridge this gap, we conduct a systematic empirical investigation to evaluate
the efficacy of diverse post-hoc GNN explainers under varying degrees of label
noise. Our results reveal several key insights: Firstly, post-hoc GNN
explainers are susceptible to label perturbations. Secondly, even minor levels
of label noise, inconsequential to GNN performance, harm the quality of
generated explanations substantially. Lastly, we engage in a discourse
regarding the progressive recovery of explanation effectiveness with escalating
noise levels.
</p>
</div>
</dd>
<dt><a name="item452">[452]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01715" title="Abstract">arXiv:2309.01715</a> [<a href="/pdf/2309.01715" title="Download PDF">pdf</a>, <a href="/format/2309.01715" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Prompting or Fine-tuning? A Comparative Study of Large Language Models  for Taxonomy Construction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+B">Boqi Chen</a>, 
<a href="/search/cs?searchtype=author&query=Yi%2C+F">Fandi Yi</a>, 
<a href="/search/cs?searchtype=author&query=Varr%C3%B3%2C+D">D&#xe1;niel Varr&#xf3;</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by MDE Intelligence 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Taxonomies represent hierarchical relations between entities, frequently
applied in various software modeling and natural language processing (NLP)
activities. They are typically subject to a set of structural constraints
restricting their content. However, manual taxonomy construction can be
time-consuming, incomplete, and costly to maintain. Recent studies of large
language models (LLMs) have demonstrated that appropriate user inputs (called
prompting) can effectively guide LLMs, such as GPT-3, in diverse NLP tasks
without explicit (re-)training. However, existing approaches for automated
taxonomy construction typically involve fine-tuning a language model by
adjusting model parameters. In this paper, we present a general framework for
taxonomy construction that takes into account structural constraints. We
subsequently conduct a systematic comparison between the prompting and
fine-tuning approaches performed on a hypernym taxonomy and a novel computer
science taxonomy dataset. Our result reveals the following: (1) Even without
explicit training on the dataset, the prompting approach outperforms
fine-tuning-based approaches. Moreover, the performance gap between prompting
and fine-tuning widens when the training dataset is small. However, (2)
taxonomies generated by the fine-tuning approach can be easily post-processed
to satisfy all the constraints, whereas handling violations of the taxonomies
produced by the prompting approach can be challenging. These evaluation
findings provide guidance on selecting the appropriate method for taxonomy
construction and highlight potential enhancements for both approaches.
</p>
</div>
</dd>
<dt><a name="item453">[453]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01717" title="Abstract">arXiv:2309.01717</a> [<a href="/pdf/2309.01717" title="Download PDF">pdf</a>, <a href="/format/2309.01717" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Interdisciplinary Fairness in Imbalanced Research Proposal Topic  Inference: A Hierarchical Transformer-based Method with Selective  Interpolation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xiao%2C+M">Meng Xiao</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+M">Min Wu</a>, 
<a href="/search/cs?searchtype=author&query=Qiao%2C+Z">Ziyue Qiao</a>, 
<a href="/search/cs?searchtype=author&query=Fu%2C+Y">Yanjie Fu</a>, 
<a href="/search/cs?searchtype=author&query=Ning%2C+Z">Zhiyuan Ning</a>, 
<a href="/search/cs?searchtype=author&query=Du%2C+Y">Yi Du</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Y">Yuanchun Zhou</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 19 pages, Under review. arXiv admin note: text overlap with <a href="/abs/2209.13912">arXiv:2209.13912</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">The objective of topic inference in research proposals aims to obtain the
most suitable disciplinary division from the discipline system defined by a
funding agency. The agency will subsequently find appropriate peer review
experts from their database based on this division. Automated topic inference
can reduce human errors caused by manual topic filling, bridge the knowledge
gap between funding agencies and project applicants, and improve system
efficiency. Existing methods focus on modeling this as a hierarchical
multi-label classification problem, using generative models to iteratively
infer the most appropriate topic information. However, these methods overlook
the gap in scale between interdisciplinary research proposals and
non-interdisciplinary ones, leading to an unjust phenomenon where the automated
inference system categorizes interdisciplinary proposals as
non-interdisciplinary, causing unfairness during the expert assignment. How can
we address this data imbalance issue under a complex discipline system and
hence resolve this unfairness? In this paper, we implement a topic label
inference system based on a Transformer encoder-decoder architecture.
Furthermore, we utilize interpolation techniques to create a series of
pseudo-interdisciplinary proposals from non-interdisciplinary ones during
training based on non-parametric indicators such as cross-topic probabilities
and topic occurrence probabilities. This approach aims to reduce the bias of
the system during model training. Finally, we conduct extensive experiments on
a real-world dataset to verify the effectiveness of the proposed method. The
experimental results demonstrate that our training strategy can significantly
mitigate the unfairness generated in the topic inference task.
</p>
</div>
</dd>
<dt><a name="item454">[454]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01723" title="Abstract">arXiv:2309.01723</a> [<a href="/pdf/2309.01723" title="Download PDF">pdf</a>, <a href="/format/2309.01723" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SAF-IS: a Spatial Annotation Free Framework for Instance Segmentation of  Surgical Tools
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sestini%2C+L">Luca Sestini</a>, 
<a href="/search/cs?searchtype=author&query=Rosa%2C+B">Benoit Rosa</a>, 
<a href="/search/cs?searchtype=author&query=De+Momi%2C+E">Elena De Momi</a>, 
<a href="/search/cs?searchtype=author&query=Ferrigno%2C+G">Giancarlo Ferrigno</a>, 
<a href="/search/cs?searchtype=author&query=Padoy%2C+N">Nicolas Padoy</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Instance segmentation of surgical instruments is a long-standing research
problem, crucial for the development of many applications for computer-assisted
surgery. This problem is commonly tackled via fully-supervised training of deep
learning models, requiring expensive pixel-level annotations to train. In this
work, we develop a framework for instance segmentation not relying on spatial
annotations for training. Instead, our solution only requires binary tool
masks, obtainable using recent unsupervised approaches, and binary tool
presence labels, freely obtainable in robot-assisted surgery. Based on the
binary mask information, our solution learns to extract individual tool
instances from single frames, and to encode each instance into a compact vector
representation, capturing its semantic features. Such representations guide the
automatic selection of a tiny number of instances (8 only in our experiments),
displayed to a human operator for tool-type labelling. The gathered information
is finally used to match each training instance with a binary tool presence
label, providing an effective supervision signal to train a tool instance
classifier. We validate our framework on the EndoVis 2017 and 2018 segmentation
datasets. We provide results using binary masks obtained either by manual
annotation or as predictions of an unsupervised binary segmentation model. The
latter solution yields an instance segmentation approach completely free from
spatial annotations, outperforming several state-of-the-art fully-supervised
segmentation approaches.
</p>
</div>
</dd>
<dt><a name="item455">[455]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01728" title="Abstract">arXiv:2309.01728</a> [<a href="/pdf/2309.01728" title="Download PDF">pdf</a>, <a href="/format/2309.01728" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Generative-based Fusion Mechanism for Multi-Modal Tracking
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tang%2C+Z">Zhangyong Tang</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+T">Tianyang Xu</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+X">Xuefeng Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+X">Xiao-Jun Wu</a>, 
<a href="/search/cs?searchtype=author&query=Kittler%2C+J">Josef Kittler</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 figures, 8 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Generative models (GMs) have received increasing research interest for their
remarkable capacity to achieve comprehensive understanding. However, their
potential application in the domain of multi-modal tracking has remained
relatively unexplored. In this context, we seek to uncover the potential of
harnessing generative techniques to address the critical challenge, information
fusion, in multi-modal tracking. In this paper, we delve into two prominent GM
techniques, namely, Conditional Generative Adversarial Networks (CGANs) and
Diffusion Models (DMs). Different from the standard fusion process where the
features from each modality are directly fed into the fusion block, we
condition these multi-modal features with random noise in the GM framework,
effectively transforming the original training samples into harder instances.
This design excels at extracting discriminative clues from the features,
enhancing the ultimate tracking performance. To quantitatively gauge the
effectiveness of our approach, we conduct extensive experiments across two
multi-modal tracking tasks, three baseline methods, and three challenging
benchmarks. The experimental results demonstrate that the proposed
generative-based fusion mechanism achieves state-of-the-art performance,
setting new records on LasHeR and RGBD1K.
</p>
</div>
</dd>
<dt><a name="item456">[456]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01729" title="Abstract">arXiv:2309.01729</a> [<a href="/pdf/2309.01729" title="Download PDF">pdf</a>, <a href="/format/2309.01729" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Softmax Bias Correction for Quantized Generative Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pandey%2C+N+P">Nilesh Prasad Pandey</a>, 
<a href="/search/cs?searchtype=author&query=Fournarakis%2C+M">Marios Fournarakis</a>, 
<a href="/search/cs?searchtype=author&query=Patel%2C+C">Chirag Patel</a>, 
<a href="/search/cs?searchtype=author&query=Nagel%2C+M">Markus Nagel</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Post-training quantization (PTQ) is the go-to compression technique for large
generative models, such as stable diffusion or large language models. PTQ
methods commonly keep the softmax activation in higher precision as it has been
shown to be very sensitive to quantization noise. However, this can lead to a
significant runtime and power overhead during inference on resource-constraint
edge devices. In this work, we investigate the source of the softmax
sensitivity to quantization and show that the quantization operation leads to a
large bias in the softmax output, causing accuracy degradation. To overcome
this issue, we propose an offline bias correction technique that improves the
quantizability of softmax without additional compute during deployment, as it
can be readily absorbed into the quantization parameters. We demonstrate the
effectiveness of our method on stable diffusion v1.5 and 125M-size OPT language
model, achieving significant accuracy improvement for 8-bit quantized softmax.
</p>
</div>
</dd>
<dt><a name="item457">[457]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01730" title="Abstract">arXiv:2309.01730</a> [<a href="/pdf/2309.01730" title="Download PDF">pdf</a>, <a href="/format/2309.01730" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Adaptive Resource Allocation for Virtualized Base Stations in O-RAN with  Online Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kalntis%2C+M">Michail Kalntis</a>, 
<a href="/search/cs?searchtype=author&query=Iosifidis%2C+G">George Iosifidis</a>, 
<a href="/search/cs?searchtype=author&query=Kuipers%2C+F+A">Fernando A. Kuipers</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Open Radio Access Network systems, with their virtualized base stations
(vBSs), offer operators the benefits of increased flexibility, reduced costs,
vendor diversity, and interoperability. Optimizing the allocation of resources
in a vBS is challenging since it requires knowledge of the environment, (i.e.,
"external'' information), such as traffic demands and channel quality, which is
difficult to acquire precisely over short intervals of a few seconds. To tackle
this problem, we propose an online learning algorithm that balances the
effective throughput and vBS energy consumption, even under unforeseeable and
"challenging'' environments; for instance, non-stationary or adversarial
traffic demands. We also develop a meta-learning scheme, which leverages the
power of other algorithmic approaches, tailored for more "easy'' environments,
and dynamically chooses the best performing one, thus enhancing the overall
system's versatility and effectiveness. We prove the proposed solutions achieve
sub-linear regret, providing zero average optimality gap even in challenging
environments. The performance of the algorithms is evaluated with real-world
data and various trace-driven evaluations, indicating savings of up to 64.5% in
the power consumption of a vBS compared with state-of-the-art benchmarks.
</p>
</div>
</dd>
<dt><a name="item458">[458]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01731" title="Abstract">arXiv:2309.01731</a> [<a href="/pdf/2309.01731" title="Download PDF">pdf</a>, <a href="/format/2309.01731" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Intranasal Chemosensory Lateralization Through the Multi-electrode  Transcutaneous Electrical Nasal Bridge Stimulation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Matsui%2C+A">Ayari Matsui</a>, 
<a href="/search/cs?searchtype=author&query=Amemiya%2C+T">Tomohiro Amemiya</a>, 
<a href="/search/cs?searchtype=author&query=Narumi%2C+T">Takuji Narumi</a>, 
<a href="/search/cs?searchtype=author&query=Aoyama%2C+K">Kazuma Aoyama</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Biological Physics (physics.bio-ph)

</div>
<p class="mathjax">Numerous studies have been conducted on display techniques for intranasal
chemosensory perception. However, a limited number of studies have focused on
the presentation of sensory spatial information. To artificially produce
intranasal chemosensory spatial perception, we focused on a technique to induce
intranasal chemosensation by transcutaneous electrical stimulation between the
nasal bridge and the back of the neck. Whether this technique stimulates the
trigeminal nerve or the olfactory nerve remains debatable; if this method
stimulates the trigeminal nerve, the differences in the amount of stimulation
to the left and right trigeminal branches would evoke lateralization of
intranasal chemosensory perception. Therefore, we propose a novel method to
lateralize intranasal chemosensation by selectively stimulating the left or
right trigeminal nerve branches through the shifting of an electrode on the
nasal bridge to the left or right. Finite element simulations reveal that
electrical stimulation applied between the electrodes on the left/right nasal
bridge and the back of the neck results in the construction of a high current
density area on the left/right branch of the trigeminal nerve. The results of
two psychophysical experiments reveal that intranasal chemosensation can be
lateralized by using the proposed method. The results of our experiment also
suggest that lateralization is not the result of electrically induced tactile
sensation of the skin surface but rather due to the distribution of stimuli to
the trigeminal nerves. To the best of our knowledge, this study is the first
successful lateralization of intranasal chemosensation that utilizes an
easy-to-apply method without involving nostril blocking.
</p>
</div>
</dd>
<dt><a name="item459">[459]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01734" title="Abstract">arXiv:2309.01734</a> [<a href="/pdf/2309.01734" title="Download PDF">pdf</a>, <a href="/format/2309.01734" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Hybrid data driven/thermal simulation model for comfort assessment
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Barbedienne%2C+R">Romain Barbedienne</a>, 
<a href="/search/cs?searchtype=author&query=Ouerk%2C+S+Y">Sara Yasmine Ouerk</a>, 
<a href="/search/cs?searchtype=author&query=Yagoubi%2C+M">Mouadh Yagoubi</a>, 
<a href="/search/cs?searchtype=author&query=Bouia%2C+H">Hassan Bouia</a>, 
<a href="/search/cs?searchtype=author&query=Kaemmerlen%2C+A">Aurelie Kaemmerlen</a>, 
<a href="/search/cs?searchtype=author&query=Charrier%2C+B">Benoit Charrier</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Machine learning models improve the speed and quality of physical models.
However, they require a large amount of data, which is often difficult and
costly to acquire. Predicting thermal comfort, for example, requires a
controlled environment, with participants presenting various characteristics
(age, gender, ...). This paper proposes a method for hybridizing real data with
simulated data for thermal comfort prediction. The simulations are performed
using Modelica Language. A benchmarking study is realized to compare different
machine learning methods. Obtained results look promising with an F1 score of
0.999 obtained using the random forest model.
</p>
</div>
</dd>
<dt><a name="item460">[460]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01736" title="Abstract">arXiv:2309.01736</a> [<a href="/pdf/2309.01736" title="Download PDF">pdf</a>, <a href="/ps/2309.01736" title="Download PostScript">ps</a>, <a href="/format/2309.01736" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Understanding and Optimizing Serverless Workloads in CXL-Enabled Tiered  Memory
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yuze Li</a>, 
<a href="/search/cs?searchtype=author&query=Yao%2C+S">Shunyu Yao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>

</div>
<p class="mathjax">Recent Serverless workloads tend to be largescaled/CPU-memory intensive, such
as DL, graph applications, that require dynamic memory-to-compute resources
provisioning.
<br />Meanwhile, recent solutions seek to design page management strategies for
multi-tiered memory systems, to efficiently run heavy workloads. Compute
Express Link (CXL) is an ideal platform for serverless workloads runtime that
offers a holistic memory namespace thanks to its cache coherent feature and
large memory capacity. However, naively offloading Serverless applications to
CXL brings substantial latencies.
<br />In this work, we first quantify CXL impacts on various Serverless
applications. Second, we argue the opportunity of provisioning DRAM and CXL in
a fine-grained, application-specific manner to Serverless workloads, by
creating a shim layer to identify, and naively place hot regions to DRAM, while
leaving cold/warm regions to CXL. Based on the observation, we finally propose
the prototype of Porter, a middleware in-between modern Serverless architecture
and CXL-enabled tiered memory system, to efficiently utilize memory resources,
while saving costs.
</p>
</div>
</dd>
<dt><a name="item461">[461]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01745" title="Abstract">arXiv:2309.01745</a> [<a href="/pdf/2309.01745" title="Download PDF">pdf</a>, <a href="/format/2309.01745" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Turbulent Flow Simulation using Autoregressive Conditional Diffusion  Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kohl%2C+G">Georg Kohl</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+L">Li-Wei Chen</a>, 
<a href="/search/cs?searchtype=author&query=Thuerey%2C+N">Nils Thuerey</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Source code available at <a href="https://github.com/tum-pbs/autoreg-pde-diffusion">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Fluid Dynamics (physics.flu-dyn)

</div>
<p class="mathjax">Simulating turbulent flows is crucial for a wide range of applications, and
machine learning-based solvers are gaining increasing relevance. However,
achieving stability when generalizing to longer rollout horizons remains a
persistent challenge for learned PDE solvers. We address this challenge by
introducing a fully data-driven fluid solver that utilizes an autoregressive
rollout based on conditional diffusion models. We show that this approach
offers clear advantages in terms of rollout stability compared to other learned
baselines. Remarkably, these improvements in stability are achieved without
compromising the quality of generated samples, and our model successfully
generalizes to flow parameters beyond the training regime. Additionally, the
probabilistic nature of the diffusion approach allows for inferring predictions
that align with the statistics of the underlying physics. We quantitatively and
qualitatively evaluate the performance of our method on a range of challenging
scenarios, including incompressible and transonic flows, as well as isotropic
turbulence.
</p>
</div>
</dd>
<dt><a name="item462">[462]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01754" title="Abstract">arXiv:2309.01754</a> [<a href="/pdf/2309.01754" title="Download PDF">pdf</a>, <a href="/format/2309.01754" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the success probability of the quantum algorithm for the short DLP
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Eker%C3%A5%2C+M">Martin Eker&#xe5;</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Quantum Physics (quant-ph)

</div>
<p class="mathjax">Eker{\aa} and H{\aa}stad have introduced a variation of Shor's algorithm for
the discrete logarithm problem (DLP). Unlike Shor's original algorithm,
Eker{\aa}-H{\aa}stad's algorithm solves the short DLP in groups of unknown
order. In this work, we prove a lower bound on the probability of
Eker{\aa}-H{\aa}stad's algorithm recovering the short logarithm $d$ in a single
run. By our bound, the success probability can easily be pushed as high as $1 -
10^{-10}$ for any short $d$. A key to achieving such a high success probability
is to efficiently perform a limited search in the classical post-processing by
leveraging meet-in-the-middle techniques. Asymptotically, in the limit as the
bit length $m$ of $d$ tends to infinity, the success probability tends to one
if the limits on the search space are parameterized in $m$. Our results are
directly applicable to Diffie-Hellman in safe-prime groups with short
exponents, and to RSA via a reduction from the RSA integer factoring problem
(IFP) to the short DLP.
</p>
</div>
</dd>
<dt><a name="item463">[463]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01759" title="Abstract">arXiv:2309.01759</a> [<a href="/pdf/2309.01759" title="Download PDF">pdf</a>, <a href="/ps/2309.01759" title="Download PostScript">ps</a>, <a href="/format/2309.01759" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Extremal Growth of Multiple Toeplitz Operators and Implications for  Numerical Stability of Approximation Schemes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Rastogi%2C+Y">Yash Rastogi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Functional Analysis (math.FA)

</div>
<p class="mathjax">We relate the power bound and a resolvent condition of Kreiss-Ritt type and
characterize the extremal growth of two families of products of three Toeplitz
operators on the Hardy space that contain infinitely many points in their
spectra. Since these operators do not fall into a well-understood class, we
analyze them through explicit techniques based on properties of Toeplitz
operators and the structure of the Hardy space. Our methods apply mutatis
mutandis to operators of the form $T_{g(z)}^{-1}T_{f(z)}T_{g(z)}$ where $f(z)$
is a polynomial in $z$ and $\bar{z}$ and $g(z)$ is a polynomial in $z$. This
collection of operators arises in the numerical solution of the Cauchy problem
for linear ordinary, partial, and delay differential equations that are
frequently used as models for processes in the sciences and engineering. Our
results provide a framework for the stability analysis of existing numerical
methods for new classes of linear differential equations as well as the
development of novel approximation schemes.
</p>
</div>
</dd>
<dt><a name="item464">[464]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01763" title="Abstract">arXiv:2309.01763</a> [<a href="/pdf/2309.01763" title="Download PDF">pdf</a>, <a href="/ps/2309.01763" title="Download PostScript">ps</a>, <a href="/format/2309.01763" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Visualizing the Weird and the Eerie
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Brehmer%2C+M">Matthew Brehmer</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Proceedings of alt.VIS 2023 (<a href="https://altvis.github.io/">this https URL</a>), an IEEE VIS Workshop on Monday, October 23 in Melbourne, Australia
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">In this brief essay, I reflect on how Mark Fisher's definitions of the weird
and the eerie could be applied in communicative data visualization. I ask how
visualization designers might elicit these two impressions when a viewer is
engaging with multimodal representations of data. I argue that there are
situations in which viewers should feel uncertain or suspicious of unseen
forces that account for the presence or absence of audiovisual patterns.
Finally, I conclude that the ability to appreciate the weird and the eerie in
data is particularly important at this moment in history, one marked by
significant ecological and economic disruption.
</p>
</div>
</dd>
<dt><a name="item465">[465]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01765" title="Abstract">arXiv:2309.01765</a> [<a href="/pdf/2309.01765" title="Download PDF">pdf</a>, <a href="/format/2309.01765" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> BLiSS: Bootstrapped Linear Shape Space
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Muralikrishnan%2C+S">Sanjeev Muralikrishnan</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+C+P">Chun-Hao Paul Huang</a>, 
<a href="/search/cs?searchtype=author&query=Ceylan%2C+D">Duygu Ceylan</a>, 
<a href="/search/cs?searchtype=author&query=Mitra%2C+N+J">Niloy J. Mitra</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 10 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Morphable models are fundamental to numerous human-centered processes as they
offer a simple yet expressive shape space. Creating such morphable models,
however, is both tedious and expensive. The main challenge is establishing
dense correspondences across raw scans that capture sufficient shape variation.
This is often addressed using a mix of significant manual intervention and
non-rigid registration. We observe that creating a shape space and solving for
dense correspondence are tightly coupled -- while dense correspondence is
needed to build shape spaces, an expressive shape space provides a reduced
dimensional space to regularize the search. We introduce BLiSS, a method to
solve both progressively. Starting from a small set of manually registered
scans to bootstrap the process, we enrich the shape space and then use that to
get new unregistered scans into correspondence automatically. The critical
component of BLiSS is a non-linear deformation model that captures details
missed by the low-dimensional shape space, thus allowing progressive enrichment
of the space.
</p>
</div>
</dd>
<dt><a name="item466">[466]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01770" title="Abstract">arXiv:2309.01770</a> [<a href="/pdf/2309.01770" title="Download PDF">pdf</a>, <a href="/format/2309.01770" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> StyleAdapter: A Single-Pass LoRA-Free Model for Stylized Image  Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zhouxia Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xintao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+L">Liangbin Xie</a>, 
<a href="/search/cs?searchtype=author&query=Qi%2C+Z">Zhongang Qi</a>, 
<a href="/search/cs?searchtype=author&query=Shan%2C+Y">Ying Shan</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+W">Wenping Wang</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+P">Ping Luo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> AIGC
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">This paper presents a LoRA-free method for stylized image generation that
takes a text prompt and style reference images as inputs and produces an output
image in a single pass. Unlike existing methods that rely on training a
separate LoRA for each style, our method can adapt to various styles with a
unified model. However, this poses two challenges: 1) the prompt loses
controllability over the generated content, and 2) the output image inherits
both the semantic and style features of the style reference image, compromising
its content fidelity. To address these challenges, we introduce StyleAdapter, a
model that comprises two components: a two-path cross-attention module (TPCA)
and three decoupling strategies. These components enable our model to process
the prompt and style reference features separately and reduce the strong
coupling between the semantic and style information in the style references.
StyleAdapter can generate high-quality images that match the content of the
prompts and adopt the style of the references (even for unseen styles) in a
single pass, which is more flexible and efficient than previous methods.
Experiments have been conducted to demonstrate the superiority of our method
over previous works.
</p>
</div>
</dd>
<dt><a name="item467">[467]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01771" title="Abstract">arXiv:2309.01771</a> [<a href="/pdf/2309.01771" title="Download PDF">pdf</a>, <a href="/format/2309.01771" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ADC/DAC-Free Analog Acceleration of Deep Neural Networks with Frequency  Transformation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Darabi%2C+N">Nastaran Darabi</a>, 
<a href="/search/cs?searchtype=author&query=Hashem%2C+M+B">Maeesha Binte Hashem</a>, 
<a href="/search/cs?searchtype=author&query=Pan%2C+H">Hongyi Pan</a>, 
<a href="/search/cs?searchtype=author&query=Cetin%2C+A">Ahmet Cetin</a>, 
<a href="/search/cs?searchtype=author&query=Gomes%2C+W">Wilfred Gomes</a>, 
<a href="/search/cs?searchtype=author&query=Trivedi%2C+A+R">Amit Ranjan Trivedi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Hardware Architecture (cs.AR)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">The edge processing of deep neural networks (DNNs) is becoming increasingly
important due to its ability to extract valuable information directly at the
data source to minimize latency and energy consumption. Frequency-domain model
compression, such as with the Walsh-Hadamard transform (WHT), has been
identified as an efficient alternative. However, the benefits of
frequency-domain processing are often offset by the increased
multiply-accumulate (MAC) operations required. This paper proposes a novel
approach to an energy-efficient acceleration of frequency-domain neural
networks by utilizing analog-domain frequency-based tensor transformations. Our
approach offers unique opportunities to enhance computational efficiency,
resulting in several high-level advantages, including array micro-architecture
with parallelism, ADC/DAC-free analog computations, and increased output
sparsity. Our approach achieves more compact cells by eliminating the need for
trainable parameters in the transformation matrix. Moreover, our novel array
micro-architecture enables adaptive stitching of cells column-wise and
row-wise, thereby facilitating perfect parallelism in computations.
Additionally, our scheme enables ADC/DAC-free computations by training against
highly quantized matrix-vector products, leveraging the parameter-free nature
of matrix multiplications. Another crucial aspect of our design is its ability
to handle signed-bit processing for frequency-based transformations. This leads
to increased output sparsity and reduced digitization workload. On a
16$\times$16 crossbars, for 8-bit input processing, the proposed approach
achieves the energy efficiency of 1602 tera operations per second per Watt
(TOPS/W) without early termination strategy and 5311 TOPS/W with early
termination strategy at VDD = 0.8 V.
</p>
</div>
</dd>
<dt><a name="item468">[468]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01775" title="Abstract">arXiv:2309.01775</a> [<a href="/pdf/2309.01775" title="Download PDF">pdf</a>, <a href="/format/2309.01775" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Gated recurrent neural networks discover attention
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zucchet%2C+N">Nicolas Zucchet</a>, 
<a href="/search/cs?searchtype=author&query=Kobayashi%2C+S">Seijin Kobayashi</a>, 
<a href="/search/cs?searchtype=author&query=Akram%2C+Y">Yassir Akram</a>, 
<a href="/search/cs?searchtype=author&query=von+Oswald%2C+J">Johannes von Oswald</a>, 
<a href="/search/cs?searchtype=author&query=Larcher%2C+M">Maxime Larcher</a>, 
<a href="/search/cs?searchtype=author&query=Steger%2C+A">Angelika Steger</a>, 
<a href="/search/cs?searchtype=author&query=Sacramento%2C+J">Jo&#xe3;o Sacramento</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Neural and Evolutionary Computing (cs.NE)

</div>
<p class="mathjax">Recent architectural developments have enabled recurrent neural networks
(RNNs) to reach and even surpass the performance of Transformers on certain
sequence modeling tasks. These modern RNNs feature a prominent design pattern:
linear recurrent layers interconnected by feedforward paths with multiplicative
gating. Here, we show how RNNs equipped with these two design elements can
exactly implement (linear) self-attention, the main building block of
Transformers. By reverse-engineering a set of trained RNNs, we find that
gradient descent in practice discovers our construction. In particular, we
examine RNNs trained to solve simple in-context learning tasks on which
Transformers are known to excel and find that gradient descent instills in our
RNNs the same attention-based in-context learning algorithm used by
Transformers. Our findings highlight the importance of multiplicative
interactions in neural networks and suggest that certain RNNs might be
unexpectedly implementing attention under the hood.
</p>
</div>
</dd>
<dt><a name="item469">[469]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01778" title="Abstract">arXiv:2309.01778</a> [<a href="/pdf/2309.01778" title="Download PDF">pdf</a>, <a href="/format/2309.01778" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CONFIDERAI: a novel CONFormal Interpretable-by-Design score function  forExplainable and Reliable Artificial Intelligence
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Carlevaro%2C+A">Alberto Carlevaro</a>, 
<a href="/search/cs?searchtype=author&query=Narteni%2C+S">Sara Narteni</a>, 
<a href="/search/cs?searchtype=author&query=Dabbene%2C+F">Fabrizio Dabbene</a>, 
<a href="/search/cs?searchtype=author&query=Muselli%2C+M">Marco Muselli</a>, 
<a href="/search/cs?searchtype=author&query=Mongelli%2C+M">Maurizio Mongelli</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 7 figures, 1 algorithm, international journal
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
<p class="mathjax">Everyday life is increasingly influenced by artificial intelligence, and
there is no question that machine learning algorithms must be designed to be
reliable and trustworthy for everyone. Specifically, computer scientists
consider an artificial intelligence system safe and trustworthy if it fulfills
five pillars: explainability, robustness, transparency, fairness, and privacy.
In addition to these five, we propose a sixth fundamental aspect: conformity,
that is, the probabilistic assurance that the system will behave as the machine
learner expects. In this paper, we propose a methodology to link conformal
prediction with explainable machine learning by defining CONFIDERAI, a new
score function for rule-based models that leverages both rules predictive
ability and points geometrical position within rules boundaries. We also
address the problem of defining regions in the feature space where conformal
guarantees are satisfied by exploiting techniques to control the number of
non-conformal samples in conformal regions based on support vector data
description (SVDD). The overall methodology is tested with promising results on
benchmark and real datasets, such as DNS tunneling detection or cardiovascular
disease prediction.
</p>
</div>
</dd>
<dt><a name="item470">[470]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01779" title="Abstract">arXiv:2309.01779</a> [<a href="/pdf/2309.01779" title="Download PDF">pdf</a>, <a href="/format/2309.01779" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DRAG: Divergence-based Adaptive Aggregation in Federated learning on  Non-IID Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhu%2C+F">Feng Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jingjing Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+S">Shengyun Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xin Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Information Theory (cs.IT)

</div>
<p class="mathjax">Local stochastic gradient descent (SGD) is a fundamental approach in
achieving communication efficiency in Federated Learning (FL) by allowing
individual workers to perform local updates. However, the presence of
heterogeneous data distributions across working nodes causes each worker to
update its local model towards a local optimum, leading to the phenomenon known
as ``client-drift" and resulting in slowed convergence. To address this issue,
previous works have explored methods that either introduce communication
overhead or suffer from unsteady performance. In this work, we introduce a
novel metric called ``degree of divergence," quantifying the angle between the
local gradient and the global reference direction. Leveraging this metric, we
propose the divergence-based adaptive aggregation (DRAG) algorithm, which
dynamically ``drags" the received local updates toward the reference direction
in each round without requiring extra communication overhead. Furthermore, we
establish a rigorous convergence analysis for DRAG, proving its ability to
achieve a sublinear convergence rate. Compelling experimental results are
presented to illustrate DRAG's superior performance compared to
state-of-the-art algorithms in effectively managing the client-drift
phenomenon. Additionally, DRAG exhibits remarkable resilience against certain
Byzantine attacks. By securely sharing a small sample of the client's data with
the FL server, DRAG effectively counters these attacks, as demonstrated through
comprehensive experiments.
</p>
</div>
</dd>
<dt><a name="item471">[471]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01780" title="Abstract">arXiv:2309.01780</a> [<a href="/pdf/2309.01780" title="Download PDF">pdf</a>, <a href="/format/2309.01780" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Measuring, Interpreting, and Improving Fairness of Algorithms using  Causal Inference and Randomized Experiments
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Enouen%2C+J">James Enouen</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+T">Tianshu Sun</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yan Liu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computers and Society (cs.CY); Methodology (stat.ME)

</div>
<p class="mathjax">Algorithm fairness has become a central problem for the broad adoption of
artificial intelligence. Although the past decade has witnessed an explosion of
excellent work studying algorithm biases, achieving fairness in real-world AI
production systems has remained a challenging task. Most existing works fail to
excel in practical applications since either they have conflicting measurement
techniques and/ or heavy assumptions, or require code-access of the production
models, whereas real systems demand an easy-to-implement measurement framework
and a systematic way to correct the detected sources of bias.
<br />In this paper, we leverage recent advances in causal inference and
interpretable machine learning to present an algorithm-agnostic framework
(MIIF) to Measure, Interpret, and Improve the Fairness of an algorithmic
decision. We measure the algorithm bias using randomized experiments, which
enables the simultaneous measurement of disparate treatment, disparate impact,
and economic value. Furthermore, using modern interpretability techniques, we
develop an explainable machine learning model which accurately interprets and
distills the beliefs of a blackbox algorithm. Altogether, these techniques
create a simple and powerful toolset for studying algorithm fairness,
especially for understanding the cost of fairness in practical applications
like e-commerce and targeted advertising, where industry A/B testing is already
abundant.
</p>
</div>
</dd>
<dt><a name="item472">[472]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01782" title="Abstract">arXiv:2309.01782</a> [<a href="/pdf/2309.01782" title="Download PDF">pdf</a>, <a href="/format/2309.01782" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> 3D View Prediction Models of the Dorsal Visual Stream
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sarch%2C+G">Gabriel Sarch</a>, 
<a href="/search/cs?searchtype=author&query=Tung%2C+H+F">Hsiao-Yu Fish Tung</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+A">Aria Wang</a>, 
<a href="/search/cs?searchtype=author&query=Prince%2C+J">Jacob Prince</a>, 
<a href="/search/cs?searchtype=author&query=Tarr%2C+M">Michael Tarr</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 2023 Conference on Cognitive Computational Neuroscience
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Neurons and Cognition (q-bio.NC)

</div>
<p class="mathjax">Deep neural network representations align well with brain activity in the
ventral visual stream. However, the primate visual system has a distinct dorsal
processing stream with different functional properties. To test if a model
trained to perceive 3D scene geometry aligns better with neural responses in
dorsal visual areas, we trained a self-supervised geometry-aware recurrent
neural network (GRNN) to predict novel camera views using a 3D feature memory.
We compared GRNN to self-supervised baseline models that have been shown to
align well with ventral regions using the large-scale fMRI Natural Scenes
Dataset (NSD). We found that while the baseline models accounted better for
ventral brain regions, GRNN accounted for a greater proportion of variance in
dorsal brain regions. Our findings demonstrate the potential for using
task-relevant models to probe representational differences across visual
streams.
</p>
</div>
</dd>
<dt><a name="item473">[473]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01783" title="Abstract">arXiv:2309.01783</a> [<a href="/pdf/2309.01783" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Survival Prediction from Imbalance colorectal cancer dataset using  hybrid sampling methods and tree-based classifiers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Soleimani%2C+S">Sadegh Soleimani</a>, 
<a href="/search/cs?searchtype=author&query=Bahrami%2C+M">Mahsa Bahrami</a>, 
<a href="/search/cs?searchtype=author&query=Vali%2C+M">Mansour Vali</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 19 Pages, 6 Figures, 4 Tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Background and Objective: Colorectal cancer is a high mortality cancer.
Clinical data analysis plays a crucial role in predicting the survival of
colorectal cancer patients, enabling clinicians to make informed treatment
decisions. However, utilizing clinical data can be challenging, especially when
dealing with imbalanced outcomes. This paper focuses on developing algorithms
to predict 1-, 3-, and 5-year survival of colorectal cancer patients using
clinical datasets, with particular emphasis on the highly imbalanced 1-year
survival prediction task. To address this issue, we propose a method that
creates a pipeline of some of standard balancing techniques to increase the
true positive rate. Evaluation is conducted on a colorectal cancer dataset from
the SEER database. Methods: The pre-processing step consists of removing
records with missing values and merging categories. The minority class of
1-year and 3-year survival tasks consists of 10% and 20% of the data,
respectively. Edited Nearest Neighbor, Repeated edited nearest neighbor (RENN),
Synthetic Minority Over-sampling Techniques (SMOTE), and pipelines of SMOTE and
RENN approaches were used and compared for balancing the data with tree-based
classifiers. Decision Trees, Random Forest, Extra Tree, eXtreme Gradient
Boosting, and Light Gradient Boosting (LGBM) are used in this article. Method.
Results: The performance evaluation utilizes a 5-fold cross-validation
approach. In the case of highly imbalanced datasets (1-year), our proposed
method with LGBM outperforms other sampling methods with the sensitivity of
72.30%. For the task of imbalance (3-year survival), the combination of RENN
and LGBM achieves a sensitivity of 80.81%, indicating that our proposed method
works best for highly imbalanced datasets. Conclusions: Our proposed method
significantly improves mortality prediction for the minority class of
colorectal cancer patients.
</p>
</div>
</dd>
<dt><a name="item474">[474]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01784" title="Abstract">arXiv:2309.01784</a> [<a href="/pdf/2309.01784" title="Download PDF">pdf</a>, <a href="/format/2309.01784" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ATMS: Algorithmic Trading-Guided Market Simulation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wei%2C+S">Song Wei</a>, 
<a href="/search/cs?searchtype=author&query=Coletta%2C+A">Andrea Coletta</a>, 
<a href="/search/cs?searchtype=author&query=Vyetrenko%2C+S">Svitlana Vyetrenko</a>, 
<a href="/search/cs?searchtype=author&query=Balch%2C+T">Tucker Balch</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Trading and Market Microstructure (q-fin.TR); Applications (stat.AP)

</div>
<p class="mathjax">The effective construction of an Algorithmic Trading (AT) strategy often
relies on market simulators, which remains challenging due to existing methods'
inability to adapt to the sequential and dynamic nature of trading activities.
This work fills this gap by proposing a metric to quantify market discrepancy.
This metric measures the difference between a causal effect from underlying
market unique characteristics and it is evaluated through the interaction
between the AT agent and the market. Most importantly, we introduce Algorithmic
Trading-guided Market Simulation (ATMS) by optimizing our proposed metric.
Inspired by SeqGAN, ATMS formulates the simulator as a stochastic policy in
reinforcement learning (RL) to account for the sequential nature of trading.
Moreover, ATMS utilizes the policy gradient update to bypass differentiating
the proposed metric, which involves non-differentiable operations such as order
deletion from the market. Through extensive experiments on semi-real market
data, we demonstrate the effectiveness of our metric and show that ATMS
generates market data with improved similarity to reality compared to the
state-of-the-art conditional Wasserstein Generative Adversarial Network (cWGAN)
approach. Furthermore, ATMS produces market data with more balanced BUY and
SELL volumes, mitigating the bias of the cWGAN baseline approach, where a
simple strategy can exploit the BUY/SELL imbalance for profit.
</p>
</div>
</dd>
<dt><a name="item475">[475]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01786" title="Abstract">arXiv:2309.01786</a> [<a href="/pdf/2309.01786" title="Download PDF">pdf</a>, <a href="/format/2309.01786" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Safe and Robust Watermark Injection with a Single OoD Image
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yu%2C+S">Shuyang Yu</a>, 
<a href="/search/cs?searchtype=author&query=Hong%2C+J">Junyuan Hong</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Haobo Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Haotao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zhangyang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+J">Jiayu Zhou</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Training a high-performance deep neural network requires large amounts of
data and computational resources. Protecting the intellectual property (IP) and
commercial ownership of a deep model is challenging yet increasingly crucial. A
major stream of watermarking strategies implants verifiable backdoor triggers
by poisoning training samples, but these are often unrealistic due to data
privacy and safety concerns and are vulnerable to minor model changes such as
fine-tuning. To overcome these challenges, we propose a safe and robust
backdoor-based watermark injection technique that leverages the diverse
knowledge from a single out-of-distribution (OoD) image, which serves as a
secret key for IP verification. The independence of training data makes it
agnostic to third-party promises of IP security. We induce robustness via
random perturbation of model parameters during watermark injection to defend
against common watermark removal attacks, including fine-tuning, pruning, and
model extraction. Our experimental results demonstrate that the proposed
watermarking approach is not only time- and sample-efficient without training
data, but also robust against the watermark removal attacks above.
</p>
</div>
</dd>
<dt><a name="item476">[476]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01788" title="Abstract">arXiv:2309.01788</a> [<a href="/pdf/2309.01788" title="Download PDF">pdf</a>, <a href="/format/2309.01788" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Hierarchical Grammar-Induced Geometry for Data-Efficient Molecular  Property Prediction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Guo%2C+M">Minghao Guo</a>, 
<a href="/search/cs?searchtype=author&query=Thost%2C+V">Veronika Thost</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+S+W">Samuel W Song</a>, 
<a href="/search/cs?searchtype=author&query=Balachandran%2C+A">Adithya Balachandran</a>, 
<a href="/search/cs?searchtype=author&query=Das%2C+P">Payel Das</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Jie Chen</a>, 
<a href="/search/cs?searchtype=author&query=Matusik%2C+W">Wojciech Matusik</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 22 pages, 10 figures; ICML 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Quantitative Methods (q-bio.QM)

</div>
<p class="mathjax">The prediction of molecular properties is a crucial task in the field of
material and drug discovery. The potential benefits of using deep learning
techniques are reflected in the wealth of recent literature. Still, these
techniques are faced with a common challenge in practice: Labeled data are
limited by the cost of manual extraction from literature and laborious
experimentation. In this work, we propose a data-efficient property predictor
by utilizing a learnable hierarchical molecular grammar that can generate
molecules from grammar production rules. Such a grammar induces an explicit
geometry of the space of molecular graphs, which provides an informative prior
on molecular structural similarity. The property prediction is performed using
graph neural diffusion over the grammar-induced geometry. On both small and
large datasets, our evaluation shows that this approach outperforms a wide
spectrum of baselines, including supervised and pre-trained graph neural
networks. We include a detailed ablation study and further analysis of our
solution, showing its effectiveness in cases with extremely limited data. Code
is available at https://github.com/gmh14/Geo-DEG.
</p>
</div>
</dd>
<dt><a name="item477">[477]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01793" title="Abstract">arXiv:2309.01793</a> [<a href="/pdf/2309.01793" title="Download PDF">pdf</a>, <a href="/format/2309.01793" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Neural-Singular-Hessian: Implicit Neural Representation of Unoriented  Point Clouds by Enforcing Singular Hessian
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zixiong Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yunxiao Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+R">Rui Xu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+F">Fan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+P">Pengshuai Wang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+S">Shuangmin Chen</a>, 
<a href="/search/cs?searchtype=author&query=Xin%2C+S">Shiqing Xin</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+W">Wenping Wang</a>, 
<a href="/search/cs?searchtype=author&query=Tu%2C+C">Changhe Tu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Graphics (cs.GR)

</div>
<p class="mathjax">Neural implicit representation is a promising approach for reconstructing
surfaces from point clouds. Existing methods combine various regularization
terms, such as the Eikonal and Laplacian energy terms, to enforce the learned
neural function to possess the properties of a Signed Distance Function (SDF).
However, inferring the actual topology and geometry of the underlying surface
from poor-quality unoriented point clouds remains challenging. In accordance
with Differential Geometry, the Hessian of the SDF is singular for points
within the differential thin-shell space surrounding the surface. Our approach
enforces the Hessian of the neural implicit function to have a zero determinant
for points near the surface. This technique aligns the gradients for a
near-surface point and its on-surface projection point, producing a rough but
faithful shape within just a few iterations. By annealing the weight of the
singular-Hessian term, our approach ultimately produces a high-fidelity
reconstruction result. Extensive experimental results demonstrate that our
approach effectively suppresses ghost geometry and recovers details from
unoriented point clouds with better expressiveness than existing fitting-based
methods.
</p>
</div>
</dd>
<dt><a name="item478">[478]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01795" title="Abstract">arXiv:2309.01795</a> [<a href="/pdf/2309.01795" title="Download PDF">pdf</a>, <a href="/format/2309.01795" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Composite federated learning with heterogeneous data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jiaojiao Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+J">Jiang Hu</a>, 
<a href="/search/cs?searchtype=author&query=Johansson%2C+M">Mikael Johansson</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Distributed, Parallel, and Cluster Computing (cs.DC); Optimization and Control (math.OC)

</div>
<p class="mathjax">We propose a novel algorithm for solving the composite Federated Learning
(FL) problem. This algorithm manages non-smooth regularization by strategically
decoupling the proximal operator and communication, and addresses client drift
without any assumptions about data similarity. Moreover, each worker uses local
updates to reduce the communication frequency with the server and transmits
only a $d$-dimensional vector per communication round. We prove that our
algorithm converges linearly to a neighborhood of the optimal solution and
demonstrate the superiority of our algorithm over state-of-the-art methods in
numerical experiments.
</p>
</div>
</dd>
<dt><a name="item479">[479]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01796" title="Abstract">arXiv:2309.01796</a> [<a href="/pdf/2309.01796" title="Download PDF">pdf</a>, <a href="/ps/2309.01796" title="Download PostScript">ps</a>, <a href="/format/2309.01796" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Asymmetric matrix sensing by gradient descent with small random  initialization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wind%2C+J+S">Johan S. Wind</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Optimization and Control (math.OC); Machine Learning (stat.ML)

</div>
<p class="mathjax">We study matrix sensing, which is the problem of reconstructing a low-rank
matrix from a few linear measurements. It can be formulated as an
overparameterized regression problem, which can be solved by factorized
gradient descent when starting from a small random initialization.
<br />Linear neural networks, and in particular matrix sensing by factorized
gradient descent, serve as prototypical models of non-convex problems in modern
machine learning, where complex phenomena can be disentangled and studied in
detail. Much research has been devoted to studying special cases of asymmetric
matrix sensing, such as asymmetric matrix factorization and symmetric positive
semi-definite matrix sensing.
<br />Our key contribution is introducing a continuous differential equation that
we call the $\textit{perturbed gradient flow}$. We prove that the perturbed
gradient flow converges quickly to the true target matrix whenever the
perturbation is sufficiently bounded. The dynamics of gradient descent for
matrix sensing can be reduced to this formulation, yielding a novel proof of
asymmetric matrix sensing with factorized gradient descent. Compared to
directly analyzing the dynamics of gradient descent, the continuous formulation
allows bounding key quantities by considering their derivatives, often
simplifying the proofs. We believe the general proof technique may prove useful
in other settings as well.
</p>
</div>
</dd>
<dt><a name="item480">[480]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01797" title="Abstract">arXiv:2309.01797</a> [<a href="/pdf/2309.01797" title="Download PDF">pdf</a>, <a href="/format/2309.01797" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Accuracy and Consistency of Space-based Vegetation Height Maps for  Forest Dynamics in Alpine Terrain
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jiang%2C+Y">Yuchang Jiang</a>, 
<a href="/search/cs?searchtype=author&query=R%C3%BCetschi%2C+M">Marius R&#xfc;etschi</a>, 
<a href="/search/cs?searchtype=author&query=Garnot%2C+V+S+F">Vivien Sainte Fare Garnot</a>, 
<a href="/search/cs?searchtype=author&query=Marty%2C+M">Mauro Marty</a>, 
<a href="/search/cs?searchtype=author&query=Schindler%2C+K">Konrad Schindler</a>, 
<a href="/search/cs?searchtype=author&query=Ginzler%2C+C">Christian Ginzler</a>, 
<a href="/search/cs?searchtype=author&query=Wegner%2C+J+D">Jan D. Wegner</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Image and Video Processing (eess.IV)

</div>
<p class="mathjax">Monitoring and understanding forest dynamics is essential for environmental
conservation and management. This is why the Swiss National Forest Inventory
(NFI) provides countrywide vegetation height maps at a spatial resolution of
0.5 m. Its long update time of 6 years, however, limits the temporal analysis
of forest dynamics. This can be improved by using spaceborne remote sensing and
deep learning to generate large-scale vegetation height maps in a
cost-effective way. In this paper, we present an in-depth analysis of these
methods for operational application in Switzerland. We generate annual,
countrywide vegetation height maps at a 10-meter ground sampling distance for
the years 2017 to 2020 based on Sentinel-2 satellite imagery. In comparison to
previous works, we conduct a large-scale and detailed stratified analysis
against a precise Airborne Laser Scanning reference dataset. This stratified
analysis reveals a close relationship between the model accuracy and the
topology, especially slope and aspect. We assess the potential of deep
learning-derived height maps for change detection and find that these maps can
indicate changes as small as 250 $m^2$. Larger-scale changes caused by a winter
storm are detected with an F1-score of 0.77. Our results demonstrate that
vegetation height maps computed from satellite imagery with deep learning are a
valuable, complementary, cost-effective source of evidence to increase the
temporal resolution for national forest assessments.
</p>
</div>
</dd>
<dt><a name="item481">[481]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01798" title="Abstract">arXiv:2309.01798</a> [<a href="/pdf/2309.01798" title="Download PDF">pdf</a>, <a href="/format/2309.01798" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> New Qubit Codes from Multidimensional Circulant Graphs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Seneviratne%2C+P">Padmapani Seneviratne</a>, 
<a href="/search/cs?searchtype=author&query=Cuff%2C+H">Hannah Cuff</a>, 
<a href="/search/cs?searchtype=author&query=Koletsos%2C+A">Alexandra Koletsos</a>, 
<a href="/search/cs?searchtype=author&query=Seekamp%2C+K">Kerry Seekamp</a>, 
<a href="/search/cs?searchtype=author&query=Thnanopavarn%2C+A">Adrian Thnanopavarn</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>

</div>
<p class="mathjax">Two new qubit stabilizer codes with parameters $[77, 0, 19]_2$ and $[90, 0,
22]_2$ are constructed for the first time by employing additive symplectic
self-dual $\F_4$ codes from multidimensional circulant (MDC) graphs. We
completely classify MDC graph codes for lengths $4\le n \le 40$ and show that
many optimal $\dsb{\ell, 0, d}$ qubit codes can be obtained from the MDC
construction. Moreover, we prove that adjacency matrices of MDC graphs have
nested block circulant structure and determine isomorphism properties of MDC
graphs.
</p>
</div>
</dd>
<dt><a name="item482">[482]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01800" title="Abstract">arXiv:2309.01800</a> [<a href="/pdf/2309.01800" title="Download PDF">pdf</a>, <a href="/ps/2309.01800" title="Download PostScript">ps</a>, <a href="/format/2309.01800" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Tight Bounds on List-Decodable and List-Recoverable Zero-Rate Codes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Resch%2C+N">Nicolas Resch</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+C">Chen Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yihan Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Abstract shortened to meet the arXiv requirement
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Computational Complexity (cs.CC); Combinatorics (math.CO)

</div>
<p class="mathjax">In this work, we consider the list-decodability and list-recoverability of
codes in the zero-rate regime. Briefly, a code $\mathcal{C} \subseteq [q]^n$ is
$(p,\ell,L)$-list-recoverable if for all tuples of input lists
$(Y_1,\dots,Y_n)$ with each $Y_i \subseteq [q]$ and $|Y_i|=\ell$ the number of
codewords $c \in \mathcal{C}$ such that $c_i \notin Y_i$ for at most $pn$
choices of $i \in [n]$ is less than $L$; list-decoding is the special case of
$\ell=1$. In recent work by Resch, Yuan and Zhang~(ICALP~2023) the zero-rate
threshold for list-recovery was determined for all parameters: that is, the
work explicitly computes $p_*:=p_*(q,\ell,L)$ with the property that for all
$\epsilon&gt;0$ (a) there exist infinite families positive-rate
$(p_*-\epsilon,\ell,L)$-list-recoverable codes, and (b) any
$(p_*+\epsilon,\ell,L)$-list-recoverable code has rate $0$. In fact, in the
latter case the code has constant size, independent on $n$. However, the
constant size in their work is quite large in $1/\epsilon$, at least
$|\mathcal{C}|\geq (\frac{1}{\epsilon})^{O(q^L)}$.
<br />Our contribution in this work is to show that for all choices of $q,\ell$ and
$L$ with $q \geq 3$, any $(p_*+\epsilon,\ell,L)$-list-recoverable code must
have size $O_{q,\ell,L}(1/\epsilon)$, and furthermore this upper bound is
complemented by a matching lower bound $\Omega_{q,\ell,L}(1/\epsilon)$. This
greatly generalizes work by Alon, Bukh and Polyanskiy~(IEEE Trans.\ Inf.\
Theory~2018) which focused only on the case of binary alphabet (and thus
necessarily only list-decoding). We remark that we can in fact recover the same
result for $q=2$ and even $L$, as obtained by Alon, Bukh and Polyanskiy: we
thus strictly generalize their work.
</p>
</div>
</dd>
<dt><a name="item483">[483]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01805" title="Abstract">arXiv:2309.01805</a> [<a href="/pdf/2309.01805" title="Download PDF">pdf</a>, <a href="/format/2309.01805" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> From Kubernetes to Knactor: A State-Centric Rethink of Service  Integration
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fu%2C+S">Silvery Fu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Hong Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Teoh%2C+R">Ryan Teoh</a>, 
<a href="/search/cs?searchtype=author&query=Priadka%2C+T">Taras Priadka</a>, 
<a href="/search/cs?searchtype=author&query=Ratnasamy%2C+S">Sylvia Ratnasamy</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>; Software Engineering (cs.SE)

</div>
<p class="mathjax">Microservices are increasingly used in modern applications, leading to a
growing need for effective service integration solutions. However, we argue
that traditional API-centric integration mechanisms (e.g., RPC, REST, and
Pub/Sub) hamper the modularity of microservices. These mechanisms introduce
rigid code-level coupling, scatter integration logic, and hinder visibility
into cross-service state exchanges. Ultimately, these limitations complicate
the maintenance and evolution of microservice-based applications. In response,
we propose a rethinking of service integration and present Knactor, a new
state-centric integration framework to restore the modularity that
microservices were intended to offer. Knactor decouples service integration
from service development, allowing integration to be implemented as explicit
state exchanges among multiple services. Our initial case study suggests that
Knactor simplifies service integration and creates new opportunities for
optimizations.
</p>
</div>
</dd>
<dt><a name="item484">[484]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01806" title="Abstract">arXiv:2309.01806</a> [<a href="/pdf/2309.01806" title="Download PDF">pdf</a>, <a href="/format/2309.01806" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Focusing and Calibration of Large Scale Network Sensors using GraphBLAS  Anonymized Hypersparse Matrices
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kepner%2C+J">Jeremy Kepner</a>, 
<a href="/search/cs?searchtype=author&query=Jones%2C+M">Michael Jones</a>, 
<a href="/search/cs?searchtype=author&query=Dykstra%2C+P">Phil Dykstra</a>, 
<a href="/search/cs?searchtype=author&query=Byun%2C+C">Chansup Byun</a>, 
<a href="/search/cs?searchtype=author&query=Davis%2C+T">Timothy Davis</a>, 
<a href="/search/cs?searchtype=author&query=Jananthan%2C+H">Hayden Jananthan</a>, 
<a href="/search/cs?searchtype=author&query=Arcand%2C+W">William Arcand</a>, 
<a href="/search/cs?searchtype=author&query=Bestor%2C+D">David Bestor</a>, 
<a href="/search/cs?searchtype=author&query=Bergeron%2C+W">William Bergeron</a>, 
<a href="/search/cs?searchtype=author&query=Gadepally%2C+V">Vijay Gadepally</a>, 
<a href="/search/cs?searchtype=author&query=Houle%2C+M">Micheal Houle</a>, 
<a href="/search/cs?searchtype=author&query=Hubbell%2C+M">Matthew Hubbell</a>, 
<a href="/search/cs?searchtype=author&query=Klein%2C+A">Anna Klein</a>, 
<a href="/search/cs?searchtype=author&query=Milechin%2C+L">Lauren Milechin</a>, 
<a href="/search/cs?searchtype=author&query=Morales%2C+G">Guillermo Morales</a>, 
<a href="/search/cs?searchtype=author&query=Mullen%2C+J">Julie Mullen</a>, 
<a href="/search/cs?searchtype=author&query=Patel%2C+R">Ritesh Patel</a>, 
<a href="/search/cs?searchtype=author&query=Pentland%2C+A">Alex Pentland</a>, 
<a href="/search/cs?searchtype=author&query=Pisharody%2C+S">Sandeep Pisharody</a>, 
<a href="/search/cs?searchtype=author&query=Prout%2C+A">Andrew Prout</a>, 
<a href="/search/cs?searchtype=author&query=Reuther%2C+A">Albert Reuther</a>, 
<a href="/search/cs?searchtype=author&query=Rosa%2C+A">Antonio Rosa</a>, 
<a href="/search/cs?searchtype=author&query=Samsi%2C+S">Siddharth Samsi</a>, 
<a href="/search/cs?searchtype=author&query=Trigg%2C+T">Tyler Trigg</a>, 
<a href="/search/cs?searchtype=author&query=Yee%2C+C">Charles Yee</a>, 
<a href="/search/cs?searchtype=author&query=Michaleas%2C+P">Peter Michaleas</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to IEEE HPEC, 9 pages, 12 figures, 1 table, 63 references, 2 appendices
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>; Social and Information Networks (cs.SI); Probability (math.PR)

</div>
<p class="mathjax">Defending community-owned cyber space requires community-based efforts.
Large-scale network observations that uphold the highest regard for privacy are
key to protecting our shared cyberspace. Deployment of the necessary network
sensors requires careful sensor placement, focusing, and calibration with
significant volumes of network observations. This paper demonstrates novel
focusing and calibration procedures on a multi-billion packet dataset using
high-performance GraphBLAS anonymized hypersparse matrices. The run-time
performance on a real-world data set confirms previously observed real-time
processing rates for high-bandwidth links while achieving significant data
compression. The output of the analysis demonstrates the effectiveness of these
procedures at focusing the traffic matrix and revealing the underlying stable
heavy-tail statistical distributions that are necessary for anomaly detection.
A simple model of the corresponding probability of detection ($p_{\rm d}$) and
probability of false alarm ($p_{\rm fa}$) for these distributions highlights
the criticality of network sensor focusing and calibration. Once a sensor is
properly focused and calibrated it is then in a position to carry out two of
the central tenets of good cybersecurity: (1) continuous observation of the
network and (2) minimizing unbrokered network connections.
</p>
</div>
</dd>
<dt><a name="item485">[485]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01807" title="Abstract">arXiv:2309.01807</a> [<a href="/pdf/2309.01807" title="Download PDF">pdf</a>, <a href="/format/2309.01807" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Marginalized Importance Sampling for Off-Environment Policy Evaluation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Katdare%2C+P">Pulkit Katdare</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+N">Nan Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Driggs-Campbell%2C+K">Katherine Driggs-Campbell</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Robotics (cs.RO)

</div>
<p class="mathjax">Reinforcement Learning (RL) methods are typically sample-inefficient, making
it challenging to train and deploy RL-policies in real world robots. Even a
robust policy trained in simulation, requires a real-world deployment to assess
their performance. This paper proposes a new approach to evaluate the
real-world performance of agent policies without deploying them in the real
world. The proposed approach incorporates a simulator along with real-world
offline data to evaluate the performance of any policy using the framework of
Marginalized Importance Sampling (MIS). Existing MIS methods face two
challenges: (1) large density ratios that deviate from a reasonable range and
(2) indirect supervision, where the ratio needs to be inferred indirectly, thus
exacerbating estimation error. Our approach addresses these challenges by
introducing the target policy's occupancy in the simulator as an intermediate
variable and learning the density ratio as the product of two terms that can be
learned separately. The first term is learned with direct supervision and the
second term has a small magnitude, thus making it easier to run. We analyze the
sample complexity as well as error propagation of our two step-procedure.
Furthermore, we empirically evaluate our approach on Sim2Sim environments such
as Cartpole, Reacher and Half-Cheetah. Our results show that our method
generalizes well across a variety of Sim2Sim gap, target policies and offline
data collection policies. We also demonstrate the performance of our algorithm
on a Sim2Real task of validating the performance of a 7 DOF robotic arm using
offline data along with a gazebo based arm simulator.
</p>
</div>
</dd>
<dt><a name="item486">[486]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01808" title="Abstract">arXiv:2309.01808</a> [<a href="/pdf/2309.01808" title="Download PDF">pdf</a>, <a href="/format/2309.01808" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DiscoverPath: A Knowledge Refinement and Retrieval System for  Interdisciplinarity on Biomedical Research
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chuang%2C+Y">Yu-Neng Chuang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+G">Guanchu Wang</a>, 
<a href="/search/cs?searchtype=author&query=Chang%2C+C">Chia-Yuan Chang</a>, 
<a href="/search/cs?searchtype=author&query=Lai%2C+K">Kwei-Herng Lai</a>, 
<a href="/search/cs?searchtype=author&query=Zha%2C+D">Daochen Zha</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+R">Ruixiang Tang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+F">Fan Yang</a>, 
<a href="/search/cs?searchtype=author&query=Reyes%2C+A+C">Alfredo Costilla Reyes</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+K">Kaixiong Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+X">Xiaoqian Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+X">Xia Hu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">The exponential growth in scholarly publications necessitates advanced tools
for efficient article retrieval, especially in interdisciplinary fields where
diverse terminologies are used to describe similar research. Traditional
keyword-based search engines often fall short in assisting users who may not be
familiar with specific terminologies. To address this, we present a knowledge
graph-based paper search engine for biomedical research to enhance the user
experience in discovering relevant queries and articles. The system, dubbed
DiscoverPath, employs Named Entity Recognition (NER) and part-of-speech (POS)
tagging to extract terminologies and relationships from article abstracts to
create a KG. To reduce information overload, DiscoverPath presents users with a
focused subgraph containing the queried entity and its neighboring nodes and
incorporates a query recommendation system, enabling users to iteratively
refine their queries. The system is equipped with an accessible Graphical User
Interface that provides an intuitive visualization of the KG, query
recommendations, and detailed article information, enabling efficient article
retrieval, thus fostering interdisciplinary knowledge exploration. DiscoverPath
is open-sourced at https://github.com/ynchuang/DiscoverPath.
</p>
</div>
</dd>
<dt><a name="item487">[487]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01809" title="Abstract">arXiv:2309.01809</a> [<a href="/pdf/2309.01809" title="Download PDF">pdf</a>, <a href="/format/2309.01809" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Are Emergent Abilities in Large Language Models just In-Context  Learning?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lu%2C+S">Sheng Lu</a>, 
<a href="/search/cs?searchtype=author&query=Bigoulaeva%2C+I">Irina Bigoulaeva</a>, 
<a href="/search/cs?searchtype=author&query=Sachdeva%2C+R">Rachneet Sachdeva</a>, 
<a href="/search/cs?searchtype=author&query=Madabushi%2C+H+T">Harish Tayyar Madabushi</a>, 
<a href="/search/cs?searchtype=author&query=Gurevych%2C+I">Iryna Gurevych</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Code available at <a href="https://github.com/UKPLab/on-emergence">this https URL</a> and data available at <a href="https://tudatalib.ulb.tu-darmstadt.de/handle/tudatalib/3931">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Large language models have exhibited emergent abilities, demonstrating
exceptional performance across diverse tasks for which they were not explicitly
trained, including those that require complex reasoning abilities. The
emergence of such abilities carries profound implications for the future
direction of research in NLP, especially as the deployment of such models
becomes more prevalent. However, one key challenge is that the evaluation of
these abilities is often confounded by competencies that arise in models
through alternative prompting techniques, such as in-context learning and
instruction following, which also emerge as the models are scaled up. In this
study, we provide the first comprehensive examination of these emergent
abilities while accounting for various potentially biasing factors that can
influence the evaluation of models. We conduct rigorous tests on a set of 18
models, encompassing a parameter range from 60 million to 175 billion
parameters, across a comprehensive set of 22 tasks. Through an extensive series
of over 1,000 experiments, we provide compelling evidence that emergent
abilities can primarily be ascribed to in-context learning. We find no evidence
for the emergence of reasoning abilities, thus providing valuable insights into
the underlying mechanisms driving the observed abilities and thus alleviating
safety concerns regarding their use.
</p>
</div>
</dd>
<dt><a name="item488">[488]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01811" title="Abstract">arXiv:2309.01811</a> [<a href="/pdf/2309.01811" title="Download PDF">pdf</a>, <a href="/format/2309.01811" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Instant Continual Learning of Neural Radiance Fields
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Po%2C+R">Ryan Po</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+Z">Zhengyang Dong</a>, 
<a href="/search/cs?searchtype=author&query=Bergman%2C+A+W">Alexander W. Bergman</a>, 
<a href="/search/cs?searchtype=author&query=Wetzstein%2C+G">Gordon Wetzstein</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> For project page
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Neural radiance fields (NeRFs) have emerged as an effective method for
novel-view synthesis and 3D scene reconstruction. However, conventional
training methods require access to all training views during scene
optimization. This assumption may be prohibitive in continual learning
scenarios, where new data is acquired in a sequential manner and a continuous
update of the NeRF is desired, as in automotive or remote sensing applications.
When naively trained in such a continual setting, traditional scene
representation frameworks suffer from catastrophic forgetting, where previously
learned knowledge is corrupted after training on new data. Prior works in
alleviating forgetting with NeRFs suffer from low reconstruction quality and
high latency, making them impractical for real-world application. We propose a
continual learning framework for training NeRFs that leverages replay-based
methods combined with a hybrid explicit--implicit scene representation. Our
method outperforms previous methods in reconstruction quality when trained in a
continual setting, while having the additional benefit of being an order of
magnitude faster.
</p>
</div>
</dd>
<dt><a name="item489">[489]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01812" title="Abstract">arXiv:2309.01812</a> [<a href="/pdf/2309.01812" title="Download PDF">pdf</a>, <a href="/format/2309.01812" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Into the Single Cell Multiverse: an End-to-End Dataset for Procedural  Knowledge Extraction in Biomedical Texts
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dannenfelser%2C+R">Ruth Dannenfelser</a>, 
<a href="/search/cs?searchtype=author&query=Zhong%2C+J">Jeffrey Zhong</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+R">Ran Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Yao%2C+V">Vicky Yao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to NeurIPS 2023 Datasets and Benchmarks Track
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Many of the most commonly explored natural language processing (NLP)
information extraction tasks can be thought of as evaluations of declarative
knowledge, or fact-based information extraction. Procedural knowledge
extraction, i.e., breaking down a described process into a series of steps, has
received much less attention, perhaps in part due to the lack of structured
datasets that capture the knowledge extraction process from end-to-end. To
address this unmet need, we present FlaMB\'e (Flow annotations for Multiverse
Biological entities), a collection of expert-curated datasets across a series
of complementary tasks that capture procedural knowledge in biomedical texts.
This dataset is inspired by the observation that one ubiquitous source of
procedural knowledge that is described as unstructured text is within academic
papers describing their methodology. The workflows annotated in FlaMB\'e are
from texts in the burgeoning field of single cell research, a research area
that has become notorious for the number of software tools and complexity of
workflows used. Additionally, FlaMB\'e provides, to our knowledge, the largest
manually curated named entity recognition (NER) and disambiguation (NED)
datasets for tissue/cell type, a fundamental biological entity that is critical
for knowledge extraction in the biomedical research domain. Beyond providing a
valuable dataset to enable further development of NLP models for procedural
knowledge extraction, automating the process of workflow mining also has
important implications for advancing reproducibility in biomedical research.
</p>
</div>
</dd>
<dt><a name="item490">[490]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01813" title="Abstract">arXiv:2309.01813</a> [<a href="/pdf/2309.01813" title="Download PDF">pdf</a>, <a href="/format/2309.01813" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Inverse Dynamics Trajectory Optimization for Contact-Implicit Model  Predictive Control
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kurtz%2C+V">Vince Kurtz</a>, 
<a href="/search/cs?searchtype=author&query=Castro%2C+A">Alejandro Castro</a>, 
<a href="/search/cs?searchtype=author&query=%C3%96nol%2C+A+%C3%96">Aykut &#xd6;zg&#xfc;n &#xd6;nol</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+H">Hai Lin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Robots must make and break contact to interact with the world and perform
useful tasks. However, planning and control through contact remains a
formidable challenge. In this work, we achieve real-time contact-implicit model
predictive control with a surprisingly simple method: inverse dynamics
trajectory optimization. While trajectory optimization with inverse dynamics is
not new, we introduce a series of incremental innovations that collectively
enable fast model predictive control on a variety of challenging manipulation
and locomotion tasks. We implement these innovations in an open-source solver,
and present a variety of simulation examples to support the effectiveness of
the proposed approach. Additionally, we demonstrate contact-implicit model
predictive control on hardware at over 100 Hz for a 20 degree-of-freedom
bi-manual manipulation task.
</p>
</div>
</dd>
<dt><a name="item491">[491]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01814" title="Abstract">arXiv:2309.01814</a> [<a href="/pdf/2309.01814" title="Download PDF">pdf</a>, <a href="/ps/2309.01814" title="Download PostScript">ps</a>, <a href="/format/2309.01814" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Data-Driven Computation of Robust Invariant Sets and Gain-Scheduled  Controllers for Linear Parameter-Varying Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Mejari%2C+M">Manas Mejari</a>, 
<a href="/search/eess?searchtype=author&query=Gupta%2C+A">Ankit Gupta</a>, 
<a href="/search/eess?searchtype=author&query=Piga%2C+D">Dario Piga</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, 4 figures. arXiv admin note: substantial text overlap with <a href="/abs/2303.18154">arXiv:2303.18154</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">We present a direct data-driven approach to synthesize robust control
invariant (RCI) sets and their associated gain-scheduled feedback control laws
for linear parameter-varying (LPV) systems subjected to bounded disturbances.
The proposed method utilizes a single state-input-scheduling trajectory to
compute polytopic RCI sets, without requiring a model of the system. The
problem is formulated in terms of a set of sufficient data-based LMI conditions
that are then combined in a semi-definite program to maximize the volume of the
RCI set, while respecting the state and input constraints. We demonstrate
through a numerical example that the proposed approach can generate RCI sets
with a relatively small number of data samples when the data satisfies certain
excitation conditions.
</p>
</div>
</dd>
<dt><a name="item492">[492]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01816" title="Abstract">arXiv:2309.01816</a> [<a href="/pdf/2309.01816" title="Download PDF">pdf</a>, <a href="/format/2309.01816" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Computation and Communication Efficient Federated Learning over Wireless  Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xiaonan Liu</a>, 
<a href="/search/cs?searchtype=author&query=Ratnarajah%2C+T">Tharmalingam Ratnarajah</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: text overlap with <a href="/abs/2305.09042">arXiv:2305.09042</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Networking and Internet Architecture (cs.NI)

</div>
<p class="mathjax">Federated learning (FL) allows model training from local data by edge devices
while preserving data privacy. However, the learning accuracy decreases due to
the heterogeneity of devices data, and the computation and communication
latency increase when updating large scale learning models on devices with
limited computational capability and wireless resources. To overcome these
challenges, we consider a novel FL framework with partial model pruning and
personalization. This framework splits the learning model into a global part
with model pruning shared with all devices to learn data representations and a
personalized part to be fine tuned for a specific device, which adapts the
model size during FL to reduce both computation and communication overhead and
minimize the overall training time, and increases the learning accuracy for the
device with non independent and identically distributed (non IID) data. Then,
the computation and communication latency and the convergence analysis of the
proposed FL framework are mathematically analyzed. Based on the convergence
analysis, an optimization problem is formulated to maximize the convergence
rate under a latency threshold by jointly optimizing the pruning ratio and
wireless resource allocation. By decoupling the optimization problem and
deploying Karush Kuhn Tucker (KKT) conditions, we derive the closed form
solutions of pruning ratio and wireless resource allocation. Finally,
experimental results demonstrate that the proposed FL framework achieves a
remarkable reduction of approximately 50 percents computation and communication
latency compared with the scheme only with model personalization.
</p>
</div>
</dd>
<dt><a name="item493">[493]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01822" title="Abstract">arXiv:2309.01822</a> [<a href="/pdf/2309.01822" title="Download PDF">pdf</a>, <a href="/format/2309.01822" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Systematic Review on Reproducibility in Child-Robot Interaction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Spitale%2C+M">Micol Spitale</a>, 
<a href="/search/cs?searchtype=author&query=Stower%2C+R">Rebecca Stower</a>, 
<a href="/search/cs?searchtype=author&query=Yadollahi%2C+E">Elmira Yadollahi</a>, 
<a href="/search/cs?searchtype=author&query=Parreira%2C+M+T">Maria Teresa Parreira</a>, 
<a href="/search/cs?searchtype=author&query=Abbasi%2C+N+I">Nida Itrat Abbasi</a>, 
<a href="/search/cs?searchtype=author&query=Leite%2C+I">Iolanda Leite</a>, 
<a href="/search/cs?searchtype=author&query=Gunes%2C+H">Hatice Gunes</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Robotics (cs.RO)

</div>
<p class="mathjax">Research reproducibility - i.e., rerunning analyses on original data to
replicate the results - is paramount for guaranteeing scientific validity.
However, reproducibility is often very challenging, especially in research
fields where multi-disciplinary teams are involved, such as child-robot
interaction (CRI). This paper presents a systematic review of the last three
years (2020-2022) of research in CRI under the lens of reproducibility, by
analysing the field for transparency in reporting. Across a total of 325
studies, we found deficiencies in reporting demographics (e.g. age of
participants), study design and implementation (e.g. length of interactions),
and open data (e.g. maintaining an active code repository). From this analysis,
we distill a set of guidelines and provide a checklist to systematically report
CRI studies to help and guide research to improve reproducibility in CRI and
beyond.
</p>
</div>
</dd>
<dt><a name="item494">[494]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01824" title="Abstract">arXiv:2309.01824</a> [<a href="/pdf/2309.01824" title="Download PDF">pdf</a>, <a href="/format/2309.01824" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the fly Deep Neural Network Optimization Control for Low-Power  Computer Vision
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kaur%2C+I">Ishmeet Kaur</a>, 
<a href="/search/cs?searchtype=author&query=Jadhav%2C+A+J">Adwaita Janardhan Jadhav</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Processing visual data on mobile devices has many applications, e.g.,
emergency response and tracking. State-of-the-art computer vision techniques
rely on large Deep Neural Networks (DNNs) that are usually too power-hungry to
be deployed on resource-constrained edge devices. Many techniques improve the
efficiency of DNNs by using sparsity or quantization. However, the accuracy and
efficiency of these techniques cannot be adapted for diverse edge applications
with different hardware constraints and accuracy requirements. This paper
presents a novel technique to allow DNNs to adapt their accuracy and energy
consumption during run-time, without the need for any re-training. Our
technique called AdaptiveActivation introduces a hyper-parameter that controls
the output range of the DNNs' activation function to dynamically adjust the
sparsity and precision in the DNN. AdaptiveActivation can be applied to any
existing pre-trained DNN to improve their deployability in diverse edge
environments. We conduct experiments on popular edge devices and show that the
accuracy is within 1.5% of the baseline. We also show that our approach
requires 10%--38% less memory than the baseline techniques leading to more
accuracy-efficiency tradeoff options
</p>
</div>
</dd>
<dt><a name="item495">[495]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01825" title="Abstract">arXiv:2309.01825</a> [<a href="/pdf/2309.01825" title="Download PDF">pdf</a>, <a href="/format/2309.01825" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LoopTune: Optimizing Tensor Computations with Reinforcement Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Grubisic%2C+D">Dejan Grubisic</a>, 
<a href="/search/cs?searchtype=author&query=Wasti%2C+B">Bram Wasti</a>, 
<a href="/search/cs?searchtype=author&query=Cummins%2C+C">Chris Cummins</a>, 
<a href="/search/cs?searchtype=author&query=Mellor-Crummey%2C+J">John Mellor-Crummey</a>, 
<a href="/search/cs?searchtype=author&query=Zlateski%2C+A">Aleksandar Zlateski</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Programming Languages (cs.PL)

</div>
<p class="mathjax">Advanced compiler technology is crucial for enabling machine learning
applications to run on novel hardware, but traditional compilers fail to
deliver performance, popular auto-tuners have long search times and
expert-optimized libraries introduce unsustainable costs. To address this, we
developed LoopTune, a deep reinforcement learning compiler that optimizes
tensor computations in deep learning models for the CPU. LoopTune optimizes
tensor traversal order while using the ultra-fast lightweight code generator
LoopNest to perform hardware-specific optimizations. With a novel graph-based
representation and action space, LoopTune speeds up LoopNest by 3.2x,
generating an order of magnitude faster code than TVM, 2.8x faster than
MetaSchedule, and 1.08x faster than AutoTVM, consistently performing at the
level of the hand-tuned library Numpy. Moreover, LoopTune tunes code in order
of seconds.
</p>
</div>
</dd>
<dt><a name="item496">[496]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01826" title="Abstract">arXiv:2309.01826</a> [<a href="/pdf/2309.01826" title="Download PDF">pdf</a>, <a href="/format/2309.01826" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> One Wide Feedforward is All You Need
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pires%2C+T+P">Telmo Pessoa Pires</a>, 
<a href="/search/cs?searchtype=author&query=Lopes%2C+A+V">Ant&#xf3;nio V. Lopes</a>, 
<a href="/search/cs?searchtype=author&query=Assogba%2C+Y">Yannick Assogba</a>, 
<a href="/search/cs?searchtype=author&query=Setiawan%2C+H">Hendra Setiawan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">The Transformer architecture has two main non-embedding components: Attention
and the Feed Forward Network (FFN). Attention captures interdependencies
between words regardless of their position, while the FFN non-linearly
transforms each input token independently. In this work we explore the role of
the FFN, and find that despite taking up a significant fraction of the model's
parameters, it is highly redundant. Concretely, we are able to substantially
reduce the number of parameters with only a modest drop in accuracy by removing
the FFN on the decoder layers and sharing a single FFN across the encoder.
Finally we scale this architecture back to its original size by increasing the
hidden dimension of the shared FFN, achieving substantial gains in both
accuracy and latency with respect to the original Transformer Big.
</p>
</div>
</dd>
<dt><a name="item497">[497]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01828" title="Abstract">arXiv:2309.01828</a> [<a href="/pdf/2309.01828" title="Download PDF">pdf</a>, <a href="/format/2309.01828" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Secure and Efficient Federated Learning in LEO Constellations using  Decentralized Key Generation and On-Orbit Model Aggregation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Elmahallawy%2C+M">Mohamed Elmahallawy</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+T">Tie Luo</a>, 
<a href="/search/cs?searchtype=author&query=Ibrahem%2C+M+I">Mohamed I. Ibrahem</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Satellite technologies have advanced drastically in recent years, leading to
a heated interest in launching small satellites into low Earth orbit (LEOs) to
collect massive data such as satellite imagery. Downloading these data to a
ground station (GS) to perform centralized learning to build an AI model is not
practical due to the limited and expensive bandwidth. Federated learning (FL)
offers a potential solution but will incur a very large convergence delay due
to the highly sporadic and irregular connectivity between LEO satellites and
GS. In addition, there are significant security and privacy risks where
eavesdroppers or curious servers/satellites may infer raw data from satellites'
model parameters transmitted over insecure communication channels. To address
these issues, this paper proposes FedSecure, a secure FL approach designed for
LEO constellations, which consists of two novel components: (1) decentralized
key generation that protects satellite data privacy using a functional
encryption scheme, and (2) on-orbit model forwarding and aggregation that
generates a partial global model per orbit to minimize the idle waiting time
for invisible satellites to enter the visible zone of the GS. Our analysis and
results show that FedSecure preserves the privacy of each satellite's data
against eavesdroppers, a curious server, or curious satellites. It is
lightweight with significantly lower communication and computation overheads
than other privacy-preserving FL aggregation approaches. It also reduces
convergence delay drastically from days to only a few hours, yet achieving high
accuracy of up to 85.35% using realistic satellite images.
</p>
</div>
</dd>
<dt><a name="item498">[498]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01834" title="Abstract">arXiv:2309.01834</a> [<a href="/pdf/2309.01834" title="Download PDF">pdf</a>, <a href="/format/2309.01834" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Mitigation of stop-and-go traffic waves with intelligent vehicles at low  market penetration rates
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Mart%C3%ADnez%2C+I">Irene Mart&#xed;nez</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">Stop-and-go traffic patterns sometimes manifest on roadways without any
discernible congestion triggers. Such a phenomenon has been observed on
homogeneous ring roads without lane changes. With the development of vehicle
technology and measurement sensors, multiple researchers have focused on
studying the influence of automated vehicles on traffic. In particular, there
is a focus on the design of string-stable adaptive cruise control (ACC)
strategies to dampen stop-and-go waves. However, there is no systematic
comparison among different strategies nor a quantitative analysis of the
oscillation reduction at low market penetration rates (MPRs). This paper
proposes a framework to evaluate the impact of low MPRs across multiple ACC
strategies. Then, through Monte Carlo simulations, our findings indicate that
multi-vehicle anticipation technology yields nearly equivalent benefits in
mitigating stop-and-go patterns compared to full vehicular connectivity, even
at a modest MPR of 1\%. In contrast, partial connectivity among vehicles only
eliminates stop-and-go waves if the MPR is larger.
</p>
</div>
</dd>
<dt><a name="item499">[499]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01837" title="Abstract">arXiv:2309.01837</a> [<a href="/pdf/2309.01837" title="Download PDF">pdf</a>, <a href="/format/2309.01837" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Delegating Data Collection in Decentralized Machine Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ananthakrishnan%2C+N">Nivasini Ananthakrishnan</a>, 
<a href="/search/cs?searchtype=author&query=Bates%2C+S">Stephen Bates</a>, 
<a href="/search/cs?searchtype=author&query=Jordan%2C+M+I">Michael I. Jordan</a>, 
<a href="/search/cs?searchtype=author&query=Haghtalab%2C+N">Nika Haghtalab</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
<p class="mathjax">Motivated by the emergence of decentralized machine learning ecosystems, we
study the delegation of data collection. Taking the field of contract theory as
our starting point, we design optimal and near-optimal contracts that deal with
two fundamental machine learning challenges: lack of certainty in the
assessment of model quality and lack of knowledge regarding the optimal
performance of any model. We show that lack of certainty can be dealt with via
simple linear contracts that achieve 1-1/e fraction of the first-best utility,
even if the principal has a small test set. Furthermore, we give sufficient
conditions on the size of the principal's test set that achieves a vanishing
additive approximation to the optimal utility. To address the lack of a priori
knowledge regarding the optimal performance, we give a convex program that can
adaptively and efficiently compute the optimal contract.
</p>
</div>
</dd>
<dt><a name="item500">[500]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01838" title="Abstract">arXiv:2309.01838</a> [<a href="/pdf/2309.01838" title="Download PDF">pdf</a>, <a href="/format/2309.01838" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Efficient Defense Against Model Stealing Attacks on Convolutional Neural  Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Khaled%2C+K">Kacem Khaled</a>, 
<a href="/search/cs?searchtype=author&query=Dhaouadi%2C+M">Mouna Dhaouadi</a>, 
<a href="/search/cs?searchtype=author&query=de+Magalh%C3%A3es%2C+F+G">Felipe Gohring de Magalh&#xe3;es</a>, 
<a href="/search/cs?searchtype=author&query=Nicolescu%2C+G">Gabriela Nicolescu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted for publication at 2023 International Conference on Machine Learning and Applications (ICMLA)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Cryptography and Security (cs.CR)

</div>
<p class="mathjax">Model stealing attacks have become a serious concern for deep learning
models, where an attacker can steal a trained model by querying its black-box
API. This can lead to intellectual property theft and other security and
privacy risks. The current state-of-the-art defenses against model stealing
attacks suggest adding perturbations to the prediction probabilities. However,
they suffer from heavy computations and make impracticable assumptions about
the adversary. They often require the training of auxiliary models. This can be
time-consuming and resource-intensive which hinders the deployment of these
defenses in real-world applications. In this paper, we propose a simple yet
effective and efficient defense alternative. We introduce a heuristic approach
to perturb the output probabilities. The proposed defense can be easily
integrated into models without additional training. We show that our defense is
effective in defending against three state-of-the-art stealing attacks. We
evaluate our approach on large and quantized (i.e., compressed) Convolutional
Neural Networks (CNNs) trained on several vision datasets. Our technique
outperforms the state-of-the-art defenses with a $\times37$ faster inference
latency without requiring any additional model and with a low impact on the
model's performance. We validate that our defense is also effective for
quantized CNNs targeting edge devices.
</p>
</div>
</dd>
<dt><a name="item501">[501]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01839" title="Abstract">arXiv:2309.01839</a> [<a href="/pdf/2309.01839" title="Download PDF">pdf</a>, <a href="/format/2309.01839" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Designing a Security System Administration Course for Cybersecurity with  a Companion Project
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zuo%2C+F">Fei Zuo</a>, 
<a href="/search/cs?searchtype=author&query=Rhee%2C+J">Junghwan Rhee</a>, 
<a href="/search/cs?searchtype=author&query=Park%2C+M">Myungah Park</a>, 
<a href="/search/cs?searchtype=author&query=Qian%2C+G">Gang Qian</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by the 37th Annual CCSC: Southeastern Conference
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">In the past few years, an incident response-oriented cybersecurity program
has been constructed at University of Central Oklahoma. As a core course in the
newly-established curricula, Secure System Administration focuses on the
essential knowledge and skill set for system administration. To enrich students
with hands-on experience, we also develop a companion coursework project, named
PowerGrader. In this paper, we present the course structure as well as the
companion project design. Additionally, we survey the pertinent criterion and
curriculum requirements from the widely recognized accreditation units. By this
means, we demonstrate the importance of a secure system administration course
within the context of cybersecurity education
</p>
</div>
</dd>
<dt><a name="item502">[502]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01842" title="Abstract">arXiv:2309.01842</a> [<a href="/pdf/2309.01842" title="Download PDF">pdf</a>, <a href="/format/2309.01842" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> StereoFlowGAN: Co-training for Stereo and Flow with Unsupervised Domain  Adaptation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xiong%2C+Z">Zhexiao Xiong</a>, 
<a href="/search/cs?searchtype=author&query=Qiao%2C+F">Feng Qiao</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yu Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Jacobs%2C+N">Nathan Jacobs</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by BMVC 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">We introduce a novel training strategy for stereo matching and optical flow
estimation that utilizes image-to-image translation between synthetic and real
image domains. Our approach enables the training of models that excel in real
image scenarios while relying solely on ground-truth information from synthetic
images. To facilitate task-agnostic domain adaptation and the training of
task-specific components, we introduce a bidirectional feature warping module
that handles both left-right and forward-backward directions. Experimental
results show competitive performance over previous domain translation-based
methods, which substantiate the efficacy of our proposed framework, effectively
leveraging the benefits of unsupervised domain adaptation, stereo matching, and
optical flow estimation.
</p>
</div>
</dd>
<dt><a name="item503">[503]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01848" title="Abstract">arXiv:2309.01848</a> [<a href="/pdf/2309.01848" title="Download PDF">pdf</a>, <a href="/format/2309.01848" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Human-Centric Metaverse Enabled by Brain-Computer Interface: A Survey
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhu%2C+H+Y">Howe Yuan Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Hieu%2C+N+Q">Nguyen Quang Hieu</a>, 
<a href="/search/cs?searchtype=author&query=Hoang%2C+D+T">Dinh Thai Hoang</a>, 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+D+N">Diep N. Nguyen</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+C">Chin-Teng Lin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">The growing interest in the Metaverse has generated momentum for members of
academia and industry to innovate toward realizing the Metaverse world. The
Metaverse is a unique, continuous, and shared virtual world where humans embody
a digital form within an online platform. Through a digital avatar, Metaverse
users should have a perceptual presence within the environment and can interact
and control the virtual world around them. Thus, a human-centric design is a
crucial element of the Metaverse. The human users are not only the central
entity but also the source of multi-sensory data that can be used to enrich the
Metaverse ecosystem. In this survey, we study the potential applications of
Brain-Computer Interface (BCI) technologies that can enhance the experience of
Metaverse users. By directly communicating with the human brain, the most
complex organ in the human body, BCI technologies hold the potential for the
most intuitive human-machine system operating at the speed of thought. BCI
technologies can enable various innovative applications for the Metaverse
through this neural pathway, such as user cognitive state monitoring, digital
avatar control, virtual interactions, and imagined speech communications. This
survey first outlines the fundamental background of the Metaverse and BCI
technologies. We then discuss the current challenges of the Metaverse that can
potentially be addressed by BCI, such as motion sickness when users experience
virtual environments or the negative emotional states of users in immersive
virtual applications. After that, we propose and discuss a new research
direction called Human Digital Twin, in which digital twins can create an
intelligent and interactable avatar from the user's brain signals. We also
present the challenges and potential solutions in synchronizing and
communicating between virtual and physical entities in the Metaverse.
</p>
</div>
</dd>
<dt><a name="item504">[504]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01850" title="Abstract">arXiv:2309.01850</a> [<a href="/pdf/2309.01850" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Uncertainty in AI: Evaluating Deep Neural Networks on  Out-of-Distribution Images
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Idowu%2C+J">Jamiu Idowu</a>, 
<a href="/search/cs?searchtype=author&query=Almasoud%2C+A">Ahmed Almasoud</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">As AI models are increasingly deployed in critical applications, ensuring the
consistent performance of models when exposed to unusual situations such as
out-of-distribution (OOD) or perturbed data, is important. Therefore, this
paper investigates the uncertainty of various deep neural networks, including
ResNet-50, VGG16, DenseNet121, AlexNet, and GoogleNet, when dealing with such
data. Our approach includes three experiments. First, we used the pretrained
models to classify OOD images generated via DALL-E to assess their performance.
Second, we built an ensemble from the models' predictions using probabilistic
averaging for consensus due to its advantages over plurality or majority
voting. The ensemble's uncertainty was quantified using average probabilities,
variance, and entropy metrics. Our results showed that while ResNet-50 was the
most accurate single model for OOD images, the ensemble performed even better,
correctly classifying all images. Third, we tested model robustness by adding
perturbations (filters, rotations, etc.) to new epistemic images from DALL-E or
real-world captures. ResNet-50 was chosen for this being the best performing
model. While it classified 4 out of 5 unperturbed images correctly, it
misclassified all of them post-perturbation, indicating a significant
vulnerability. These misclassifications, which are clear to human observers,
highlight AI models' limitations. Using saliency maps, we identified regions of
the images that the model considered important for their decisions.
</p>
</div>
</dd>
<dt><a name="item505">[505]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01852" title="Abstract">arXiv:2309.01852</a> [<a href="/pdf/2309.01852" title="Download PDF">pdf</a>, <a href="/ps/2309.01852" title="Download PostScript">ps</a>, <a href="/format/2309.01852" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Local Certification of Majority Dynamics
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Maldonado%2C+D">Diego Maldonado</a>, 
<a href="/search/cs?searchtype=author&query=Montealegre%2C+P">Pedro Montealegre</a>, 
<a href="/search/cs?searchtype=author&query=R%C3%ADos-Wilson%2C+M">Mart&#xed;n R&#xed;os-Wilson</a>, 
<a href="/search/cs?searchtype=author&query=Theyssier%2C+G">Guillaume Theyssier</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>

</div>
<p class="mathjax">In majority voting dynamics, a group of $n$ agents in a social network are
asked for their preferred candidate in a future election between two possible
choices. At each time step, a new poll is taken, and each agent adjusts their
vote according to the majority opinion of their network neighbors. After $T$
time steps, the candidate with the majority of votes is the leading contender
in the election. In general, it is very hard to predict who will be the leading
candidate after a large number of time-steps.
<br />We study, from the perspective of local certification, the problem of
predicting the leading candidate after a certain number of time-steps, which we
call Election-Prediction. We show that in graphs with sub-exponential growth
Election-Prediction admits a proof labeling scheme of size $\mathcal{O}(\log
n)$. We also find non-trivial upper bounds for graphs with a bounded degree, in
which the size of the certificates are sub-linear in $n$.
<br />Furthermore, we explore lower bounds for the unrestricted case, showing that
locally checkable proofs for Election-Prediction on arbitrary $n$-node graphs
have certificates on $\Omega(n)$ bits. Finally, we show that our upper bounds
are tight even for graphs of constant growth.
</p>
</div>
</dd>
<dt><a name="item506">[506]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01853" title="Abstract">arXiv:2309.01853</a> [<a href="/pdf/2309.01853" title="Download PDF">pdf</a>, <a href="/format/2309.01853" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Interactive Design and Optics-Based Visualization of Arbitrary  Non-Euclidean Kaleidoscopic Orbifolds
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zheng%2C+J">Jinta Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+E">Eugene Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yue Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> IEEE VIS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Graphics (cs.GR)</span>

</div>
<p class="mathjax">Orbifolds are a modern mathematical concept that arises in the research of
hyperbolic geometry with applications in computer graphics and visualization.
In this paper, we make use of rooms with mirrors as the visual metaphor for
orbifolds. Given any arbitrary two-dimensional kaleidoscopic orbifold, we
provide an algorithm to construct a Euclidean, spherical, or hyperbolic polygon
to match the orbifold. This polygon is then used to create a room for which the
polygon serves as the floor and the ceiling. With our system that implements
M\"obius transformations, the user can interactively edit the scene and see the
reflections of the edited objects. To correctly visualize non-Euclidean
orbifolds, we adapt the rendering algorithms to account for the geodesics in
these spaces, which light rays follow. Our interactive orbifold design system
allows the user to create arbitrary two-dimensional kaleidoscopic orbifolds. In
addition, our mirror-based orbifold visualization approach has the potential of
helping our users gain insight on the orbifold, including its orbifold notation
as well as its universal cover, which can also be the spherical space and the
hyperbolic space.
</p>
</div>
</dd>
<dt><a name="item507">[507]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01854" title="Abstract">arXiv:2309.01854</a> [<a href="/pdf/2309.01854" title="Download PDF">pdf</a>, <a href="/ps/2309.01854" title="Download PostScript">ps</a>, <a href="/format/2309.01854" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Dynamical Stability of Threshold Networks over Undirected Signed Graphs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Goles%2C+E">Eric Goles</a>, 
<a href="/search/cs?searchtype=author&query=Montealegre%2C+P">Pedro Montealegre</a>, 
<a href="/search/cs?searchtype=author&query=R%C3%ADos-Wilson%2C+M">Mart&#xed;n R&#xed;os-Wilson</a>, 
<a href="/search/cs?searchtype=author&query=Sen%C3%A9%2C+S">Sylvain Sen&#xe9;</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Discrete Mathematics (cs.DM)</span>

</div>
<p class="mathjax">In this paper we study the dynamic behavior of threshold networks on
undirected signed graphs. While much attention has been given to the
convergence and long-term behavior of this model, an open question remains: How
does the underlying graph structure influence network dynamics? While similar
papers have been carried out for threshold networks (as well as for other
networks) these have largely focused on unsigned networks. However, the signed
graph model finds applications in various real-world domains like gene
regulation and social networks.
<br />By studying a graph parameter that we call "stability index," we search to
establish a connection between the structure and the dynamics of threshold
network. Interestingly, this parameter is related to the concepts of
frustration and balance in signed graphs. We show that graphs that present
negative stability index exhibit stable dynamics, meaning that the dynamics
converges to fixed points regardless of threshold parameters. Conversely, if at
least one subgraph has positive stability index, oscillations in long term
behavior may appear. Finally, we generalize the analysis to network dynamics
under periodic update schemes and we explore the case in which the stability
index is positive for some subgraph finding that attractors with
superpolynomial period on the size of the network may appear.
</p>
</div>
</dd>
<dt><a name="item508">[508]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01855" title="Abstract">arXiv:2309.01855</a> [<a href="/pdf/2309.01855" title="Download PDF">pdf</a>, <a href="/format/2309.01855" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SMPLitex: A Generative Model and Dataset for 3D Human Texture Estimation  from Single Image
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Casas%2C+D">Dan Casas</a>, 
<a href="/search/cs?searchtype=author&query=Trinidad%2C+M+C">Marc Comino Trinidad</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at BMVC 2023. Project website: <a href="https://dancasas.github.io/projects/SMPLitex">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Graphics (cs.GR)

</div>
<p class="mathjax">We propose SMPLitex, a method for estimating and manipulating the complete 3D
appearance of humans captured from a single image. SMPLitex builds upon the
recently proposed generative models for 2D images, and extends their use to the
3D domain through pixel-to-surface correspondences computed on the input image.
To this end, we first train a generative model for complete 3D human
appearance, and then fit it into the input image by conditioning the generative
model to the visible parts of the subject. Furthermore, we propose a new
dataset of high-quality human textures built by sampling SMPLitex conditioned
on subject descriptions and images. We quantitatively and qualitatively
evaluate our method in 3 publicly available datasets, demonstrating that
SMPLitex significantly outperforms existing methods for human texture
estimation while allowing for a wider variety of tasks such as editing,
synthesis, and manipulation
</p>
</div>
</dd>
<dt><a name="item509">[509]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01858" title="Abstract">arXiv:2309.01858</a> [<a href="/pdf/2309.01858" title="Download PDF">pdf</a>, <a href="/format/2309.01858" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Universal Image Embeddings: A Large-Scale Dataset and Challenge  for Generic Image Representations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ypsilantis%2C+N">Nikolaos-Antonios Ypsilantis</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+K">Kaifeng Chen</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+B">Bingyi Cao</a>, 
<a href="/search/cs?searchtype=author&query=Lipovsk%C3%BD%2C+M">M&#xe1;rio Lipovsk&#xfd;</a>, 
<a href="/search/cs?searchtype=author&query=Dogan-Sch%C3%B6nberger%2C+P">Pelin Dogan-Sch&#xf6;nberger</a>, 
<a href="/search/cs?searchtype=author&query=Makosa%2C+G">Grzegorz Makosa</a>, 
<a href="/search/cs?searchtype=author&query=Bluntschli%2C+B">Boris Bluntschli</a>, 
<a href="/search/cs?searchtype=author&query=Seyedhosseini%2C+M">Mojtaba Seyedhosseini</a>, 
<a href="/search/cs?searchtype=author&query=Chum%2C+O">Ond&#x159;ej Chum</a>, 
<a href="/search/cs?searchtype=author&query=Araujo%2C+A">Andr&#xe9; Araujo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ICCV 2023 Accepted
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Fine-grained and instance-level recognition methods are commonly trained and
evaluated on specific domains, in a model per domain scenario. Such an
approach, however, is impractical in real large-scale applications. In this
work, we address the problem of universal image embedding, where a single
universal model is trained and used in multiple domains. First, we leverage
existing domain-specific datasets to carefully construct a new large-scale
public benchmark for the evaluation of universal image embeddings, with 241k
query images, 1.4M index images and 2.8M training images across 8 different
domains and 349k classes. We define suitable metrics, training and evaluation
protocols to foster future research in this area. Second, we provide a
comprehensive experimental evaluation on the new dataset, demonstrating that
existing approaches and simplistic extensions lead to worse performance than an
assembly of models trained for each domain separately. Finally, we conducted a
public research competition on this topic, leveraging industrial datasets,
which attracted the participation of more than 1k teams worldwide. This
exercise generated many interesting research ideas and findings which we
present in detail. Project webpage: https://cmp.felk.cvut.cz/univ_emb/
</p>
</div>
</dd>
<dt><a name="item510">[510]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01859" title="Abstract">arXiv:2309.01859</a> [<a href="/pdf/2309.01859" title="Download PDF">pdf</a>, <a href="/format/2309.01859" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> NLLB-CLIP -- train performant multilingual image retrieval model on a  budget
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Visheratin%2C+A">Alexander Visheratin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Today, the exponential rise of large models developed by academic and
industrial institutions with the help of massive computing resources raises the
question of whether someone without access to such resources can make a
valuable scientific contribution. To explore this, we tried to solve the
challenging task of multilingual image retrieval having a limited budget of
$1,000. As a result, we present NLLB-CLIP - CLIP model with a text encoder from
the NLLB model. To train the model, we used an automatically created dataset of
106,246 good-quality images with captions in 201 languages derived from the
LAION COCO dataset. We trained multiple models using image and text encoders of
various sizes and kept different parts of the model frozen during the training.
We thoroughly analyzed the trained models using existing evaluation datasets
and newly created XTD200 and Flickr30k-200 datasets. We show that NLLB-CLIP is
comparable in quality to state-of-the-art models and significantly outperforms
them on low-resource languages.
</p>
</div>
</dd>
<dt><a name="item511">[511]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01860" title="Abstract">arXiv:2309.01860</a> [<a href="/pdf/2309.01860" title="Download PDF">pdf</a>, <a href="/format/2309.01860" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Attention-Driven Multi-Modal Fusion: Enhancing Sign Language Recognition  and Translation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hakim%2C+Z+I+A">Zaber Ibn Abdul Hakim</a>, 
<a href="/search/cs?searchtype=author&query=Swargo%2C+R+M">Rasman Mubtasim Swargo</a>, 
<a href="/search/cs?searchtype=author&query=Adnan%2C+M+A">Muhammad Abdullah Adnan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Computation and Language (cs.CL); Machine Learning (cs.LG)

</div>
<p class="mathjax">In this paper, we devise a mechanism for the addition of multi-modal
information with an existing pipeline for continuous sign language recognition
and translation. In our procedure, we have incorporated optical flow
information with RGB images to enrich the features with movement-related
information. This work studies the feasibility of such modality inclusion using
a cross-modal encoder. The plugin we have used is very lightweight and doesn't
need to include a separate feature extractor for the new modality in an
end-to-end manner. We have applied the changes in both sign language
recognition and translation, improving the result in each case. We have
evaluated the performance on the RWTH-PHOENIX-2014 dataset for sign language
recognition and the RWTH-PHOENIX-2014T dataset for translation. On the
recognition task, our approach reduced the WER by 0.9, and on the translation
task, our approach increased most of the BLEU scores by ~0.6 on the test set.
</p>
</div>
</dd>
<dt><a name="item512">[512]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01861" title="Abstract">arXiv:2309.01861</a> [<a href="/pdf/2309.01861" title="Download PDF">pdf</a>, <a href="/format/2309.01861" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FlexRDZ: Autonomous Mobility Management for Radio Dynamic Zones
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gottipati%2C+A">Aashish Gottipati</a>, 
<a href="/search/cs?searchtype=author&query=Van+der+Merwe%2C+J">Jacobus Van der Merwe</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">FlexRDZ is an online, autonomous manager for radio dynamic zones (RDZ) that
seeks to enable the safe operation of RDZs through real-time control of
deployed test transmitters. FlexRDZ leverages Hierarchical Task Networks and
digital twin modeling to plan and resolve RDZ violations in near real-time. We
prototype FlexRDZ with GTPyhop and the Terrain Integrated Rough Earth Model
(TIREM). We deploy and evaluate FlexRDZ within a simulated version of the Salt
Lake City POWDER testbed, a potential urban RDZ environment. Our simulations
show that FlexRDZ enables up to a 20 dBm reduction in mobile interference and a
significant reduction in the total power of leaked transmissions while
preserving the overall communication capabilities and uptime of test
transmitters. To our knowledge, FlexRDZ is the first autonomous system for RDZ
management.
</p>
</div>
</dd>
<dt><a name="item513">[513]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01863" title="Abstract">arXiv:2309.01863</a> [<a href="/pdf/2309.01863" title="Download PDF">pdf</a>, <a href="/format/2309.01863" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Global Topology of 3D Symmetric Tensor Fields
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hung%2C+S">Shih-Hsuan Hung</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yue Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+E">Eugene Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> IEEE VIS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Graphics (cs.GR)</span>

</div>
<p class="mathjax">There have been recent advances in the analysis and visualization of 3D
symmetric tensor fields, with a focus on the robust extraction of tensor field
topology. However, topological features such as degenerate curves and neutral
surfaces do not live in isolation. Instead, they intriguingly interact with
each other. In this paper, we introduce the notion of {\em topological graph}
for 3D symmetric tensor fields to facilitate global topological analysis of
such fields. The nodes of the graph include degenerate curves and regions
bounded by neutral surfaces in the domain. The edges in the graph denote the
adjacency information between the regions and degenerate curves. In addition,
we observe that a degenerate curve can be a loop and even a knot and that two
degenerate curves (whether in the same region or not) can form a link. We
provide a definition and theoretical analysis of individual degenerate curves
in order to help understand why knots and links may occur. Moreover, we
differentiate between wedges and trisectors, thus making the analysis more
detailed about degenerate curves. We incorporate this information into the
topological graph. Such a graph can not only reveal the global structure in a
3D symmetric tensor field but also allow two symmetric tensor fields to be
compared. We demonstrate our approach by applying it to solid mechanics and
material science data sets.
</p>
</div>
</dd>
<dt><a name="item514">[514]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01866" title="Abstract">arXiv:2309.01866</a> [<a href="/pdf/2309.01866" title="Download PDF">pdf</a>, <a href="/format/2309.01866" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Efficient Query-Based Attack against ML-Based Android Malware Detection  under Zero Knowledge Setting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=He%2C+P">Ping He</a>, 
<a href="/search/cs?searchtype=author&query=Xia%2C+Y">Yifan Xia</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xuhong Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Ji%2C+S">Shouling Ji</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To Appear in the ACM Conference on Computer and Communications Security, November, 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Software Engineering (cs.SE)

</div>
<p class="mathjax">The widespread adoption of the Android operating system has made malicious
Android applications an appealing target for attackers. Machine learning-based
(ML-based) Android malware detection (AMD) methods are crucial in addressing
this problem; however, their vulnerability to adversarial examples raises
concerns. Current attacks against ML-based AMD methods demonstrate remarkable
performance but rely on strong assumptions that may not be realistic in
real-world scenarios, e.g., the knowledge requirements about feature space,
model parameters, and training dataset. To address this limitation, we
introduce AdvDroidZero, an efficient query-based attack framework against
ML-based AMD methods that operates under the zero knowledge setting. Our
extensive evaluation shows that AdvDroidZero is effective against various
mainstream ML-based AMD methods, in particular, state-of-the-art such methods
and real-world antivirus solutions.
</p>
</div>
</dd>
<dt><a name="item515">[515]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01867" title="Abstract">arXiv:2309.01867</a> [<a href="/pdf/2309.01867" title="Download PDF">pdf</a>, <a href="/format/2309.01867" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Variable Time Step Method of DAHLQUIST, LINIGER and NEVANLINNA (DLN) for  a Corrected Smagorinsky Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Siddiqua%2C+F">Farjana Siddiqua</a>, 
<a href="/search/math?searchtype=author&query=Pei%2C+W">Wenlong Pei</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">Turbulent flows strain resources, both memory and CPU speed. The DLN method
has greater accuracy and allows larger time steps, requiring less memory and
fewer FLOPS. The DLN method can also be implemented adaptively. The classical
Smagorinsky model, as an effective way to approximate a (resolved) mean
velocity, has recently been corrected to represent a flow of energy from
unresolved fluctuations to the (resolved) mean velocity. In this paper, we
apply a family of second-order, G-stable time-stepping methods proposed by
Dahlquist, Liniger, and Nevanlinna (the DLN method) to one corrected
Smagorinsky model and provide the detailed numerical analysis of the stability
and consistency. We prove that the numerical solutions under any arbitrary time
step sequences are unconditionally stable in the long term and converge at
second order. We also provide error estimate under certain time step condition.
Numerical tests are given to confirm the rate of convergence and also to show
that the adaptive DLN algorithm helps to control numerical dissipation so that
backscatter is visible.
</p>
</div>
</dd>
<dt><a name="item516">[516]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01868" title="Abstract">arXiv:2309.01868</a> [<a href="/pdf/2309.01868" title="Download PDF">pdf</a>, <a href="/format/2309.01868" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the Planning, Search, and Memorization Capabilities of Large Language  Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yunhao Yang</a>, 
<a href="/search/cs?searchtype=author&query=Tomar%2C+A">Anshul Tomar</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, 2 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">The rapid advancement of large language models, such as the Generative
Pre-trained Transformer (GPT) series, has had significant implications across
various disciplines. In this study, we investigate the potential of the
state-of-the-art large language model (GPT-4) for planning tasks. We explore
its effectiveness in multiple planning subfields, highlighting both its
strengths and limitations. Through a comprehensive examination, we identify
areas where large language models excel in solving planning problems and reveal
the constraints that limit their applicability. Our empirical analysis focuses
on GPT-4's performance in planning domain extraction, graph search path
planning, and adversarial planning. We then propose a way of fine-tuning a
domain-specific large language model to improve its Chain of Thought (CoT)
capabilities for the above-mentioned tasks. The results provide valuable
insights into the potential applications of large language models in the
planning domain and pave the way for future research to overcome their
limitations and expand their capabilities.
</p>
</div>
</dd>
<dt><a name="item517">[517]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01875" title="Abstract">arXiv:2309.01875</a> [<a href="/pdf/2309.01875" title="Download PDF">pdf</a>, <a href="/format/2309.01875" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Gradient Domain Diffusion Models for Image Synthesis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gong%2C+Y">Yuanhao Gong</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG); Multimedia (cs.MM); Performance (cs.PF); Image and Video Processing (eess.IV)

</div>
<p class="mathjax">Diffusion models are getting popular in generative image and video synthesis.
However, due to the diffusion process, they require a large number of steps to
converge. To tackle this issue, in this paper, we propose to perform the
diffusion process in the gradient domain, where the convergence becomes faster.
There are two reasons. First, thanks to the Poisson equation, the gradient
domain is mathematically equivalent to the original image domain. Therefore,
each diffusion step in the image domain has a unique corresponding gradient
domain representation. Second, the gradient domain is much sparser than the
image domain. As a result, gradient domain diffusion models converge faster.
Several numerical experiments confirm that the gradient domain diffusion models
are more efficient than the original diffusion models. The proposed method can
be applied in a wide range of applications such as image processing, computer
vision and machine learning tasks.
</p>
</div>
</dd>
<dt><a name="item518">[518]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01881" title="Abstract">arXiv:2309.01881</a> [<a href="/pdf/2309.01881" title="Download PDF">pdf</a>, <a href="/ps/2309.01881" title="Download PostScript">ps</a>, <a href="/format/2309.01881" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> In-depth analysis of S-boxes over binary finite fields concerning their  differential and Feistel boomerang differential uniformities
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Man%2C+Y">Yuying Man</a>, 
<a href="/search/cs?searchtype=author&query=Mesnager%2C+S">Sihem Mesnager</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+N">Nian Li</a>, 
<a href="/search/cs?searchtype=author&query=Zeng%2C+X">Xiangyong Zeng</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+X">Xiaohu Tang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>

</div>
<p class="mathjax">Substitution boxes (S-boxes) play a significant role in ensuring the
resistance of block ciphers against various attacks. The Difference
Distribution Table (DDT), the Feistel Boomerang Connectivity Table (FBCT), the
Feistel Boomerang Difference Table (FBDT) and the Feistel Boomerang Extended
Table (FBET) of a given S-box are crucial tools to analyze its security
concerning specific attacks. However, the results on them are rare. In this
paper, we investigate the properties of the power function
$F(x):=x^{2^{m+1}-1}$ over the finite field $\gf_{2^n}$ of order $2^n$ where
$n=2m$ or $n=2m+1$ ($m$ stands for a positive integer). As a consequence, by
carrying out certain finer manipulations of solving specific equations over
$\gf_{2^n}$, we give explicit values of all entries of the DDT, the FBCT, the
FBDT and the FBET of the investigated power functions. From the theoretical
point of view, our study pushes further former investigations on differential
and Feistel boomerang differential uniformities for a novel power function $F$.
From a cryptographic point of view, when considering Feistel block cipher
involving $F$, our in-depth analysis helps select $F$ resistant to differential
attacks, Feistel differential attacks and Feistel boomerang attacks,
respectively.
</p>
</div>
</dd>
<dt><a name="item519">[519]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01884" title="Abstract">arXiv:2309.01884</a> [<a href="/pdf/2309.01884" title="Download PDF">pdf</a>, <a href="/format/2309.01884" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Task Generalization with Stability Guarantees via Elastic Dynamical  System Motion Policies
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+T">Tianyu Li</a>, 
<a href="/search/cs?searchtype=author&query=Figueroa%2C+N">Nadia Figueroa</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to CoRL 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Machine Learning (cs.LG); Systems and Control (eess.SY)

</div>
<p class="mathjax">Dynamical System (DS) based Learning from Demonstration (LfD) allows learning
of reactive motion policies with stability and convergence guarantees from a
few trajectories. Yet, current DS learning techniques lack the flexibility to
generalize to new task instances as they ignore explicit task parameters that
inherently change the underlying trajectories. In this work, we propose
Elastic-DS, a novel DS learning, and generalization approach that embeds task
parameters into the Gaussian Mixture Model (GMM) based Linear Parameter Varying
(LPV) DS formulation. Central to our approach is the Elastic-GMM, a GMM
constrained to SE(3) task-relevant frames. Given a new task instance/context,
the Elastic-GMM is transformed with Laplacian Editing and used to re-estimate
the LPV-DS policy. Elastic-DS is compositional in nature and can be used to
construct flexible multi-step tasks. We showcase its strength on a myriad of
simulated and real-robot experiments while preserving desirable
control-theoretic guarantees. Supplementary videos can be found at
https://sites.google.com/view/elastic-ds
</p>
</div>
</dd>
<dt><a name="item520">[520]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01897" title="Abstract">arXiv:2309.01897</a> [<a href="/pdf/2309.01897" title="Download PDF">pdf</a>, <a href="/format/2309.01897" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Inferring Actual Treatment Pathways from Patient Records
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wilkins-Caruana%2C+A">Adrian Wilkins-Caruana</a>, 
<a href="/search/cs?searchtype=author&query=Bandara%2C+M">Madhushi Bandara</a>, 
<a href="/search/cs?searchtype=author&query=Musial%2C+K">Katarzyna Musial</a>, 
<a href="/search/cs?searchtype=author&query=Catchpoole%2C+D">Daniel Catchpoole</a>, 
<a href="/search/cs?searchtype=author&query=Kennedy%2C+P+J">Paul J. Kennedy</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Treatment pathways are step-by-step plans outlining the recommended medical
care for specific diseases; they get revised when different treatments are
found to improve patient outcomes. Examining health records is an important
part of this revision process, but inferring patients' actual treatments from
health data is challenging due to complex event-coding schemes and the absence
of pathway-related annotations. This study aims to infer the actual treatment
steps for a particular patient group from administrative health records (AHR) -
a common form of tabular healthcare data - and address several technique- and
methodology-based gaps in treatment pathway-inference research. We introduce
Defrag, a method for examining AHRs to infer the real-world treatment steps for
a particular patient group. Defrag learns the semantic and temporal meaning of
healthcare event sequences, allowing it to reliably infer treatment steps from
complex healthcare data. To our knowledge, Defrag is the first
pathway-inference method to utilise a neural network (NN), an approach made
possible by a novel, self-supervised learning objective. We also developed a
testing and validation framework for pathway inference, which we use to
characterise and evaluate Defrag's pathway inference ability and compare
against baselines. We demonstrate Defrag's effectiveness by identifying
best-practice pathway fragments for breast cancer, lung cancer, and melanoma in
public healthcare records. Additionally, we use synthetic data experiments to
demonstrate the characteristics of the Defrag method, and to compare Defrag to
several baselines where it significantly outperforms non-NN-based methods.
Defrag significantly outperforms several existing pathway-inference methods and
offers an innovative and effective approach for inferring treatment pathways
from AHRs. Open-source code is provided to encourage further research in this
area.
</p>
</div>
</dd>
<dt><a name="item521">[521]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01898" title="Abstract">arXiv:2309.01898</a> [<a href="/pdf/2309.01898" title="Download PDF">pdf</a>, <a href="/format/2309.01898" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Safe Legged Locomotion using Collision Cone Control Barrier Functions  (C3BFs)
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tayal%2C+M">Manan Tayal</a>, 
<a href="/search/cs?searchtype=author&query=Kolathaya%2C+S">Shishir Kolathaya</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 Pages, 5 Figures. arXiv admin note: text overlap with <a href="/abs/2303.15871">arXiv:2303.15871</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Systems and Control (eess.SY)

</div>
<p class="mathjax">Legged robots exhibit significant potential across diverse applications,
including but not limited to hazardous environment search and rescue missions
and the exploration of unexplored regions both on Earth and in outer space.
However, the successful navigation of these robots in dynamic environments
heavily hinges on the implementation of efficient collision avoidance
techniques. In this research paper, we employ Collision Cone Control Barrier
Functions (C3BF) to ensure the secure movement of legged robots within
environments featuring a wide array of static and dynamic obstacles. We
introduce the Quadratic Program (QP) formulation of C3BF, referred to as
C3BF-QP, which serves as a protective filter layer atop a reference controller
to ensure the robots' safety during operation. The effectiveness of this
approach is illustrated through simulations conducted on PyBullet.
</p>
</div>
</dd>
<dt><a name="item522">[522]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01899" title="Abstract">arXiv:2309.01899</a> [<a href="/pdf/2309.01899" title="Download PDF">pdf</a>, <a href="/format/2309.01899" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Unsupervised Skin Lesion Segmentation via Structural Entropy  Minimization on Multi-Scale Superpixel Graphs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zeng%2C+G">Guangjie Zeng</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+H">Hao Peng</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+A">Angsheng Li</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zhiwei Liu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+C">Chunyang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+P+S">Philip S. Yu</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+L">Lifang He</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 8 figures, conference. Accepted by IEEE ICDM 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Skin lesion segmentation is a fundamental task in dermoscopic image analysis.
The complex features of pixels in the lesion region impede the lesion
segmentation accuracy, and existing deep learning-based methods often lack
interpretability to this problem. In this work, we propose a novel unsupervised
Skin Lesion sEgmentation framework based on structural entropy and isolation
forest outlier Detection, namely SLED. Specifically, skin lesions are segmented
by minimizing the structural entropy of a superpixel graph constructed from the
dermoscopic image. Then, we characterize the consistency of healthy skin
features and devise a novel multi-scale segmentation mechanism by outlier
detection, which enhances the segmentation accuracy by leveraging the
superpixel features from multiple scales. We conduct experiments on four skin
lesion benchmarks and compare SLED with nine representative unsupervised
segmentation methods. Experimental results demonstrate the superiority of the
proposed framework. Additionally, some case studies are analyzed to demonstrate
the effectiveness of SLED.
</p>
</div>
</dd>
<dt><a name="item523">[523]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01901" title="Abstract">arXiv:2309.01901</a> [<a href="/pdf/2309.01901" title="Download PDF">pdf</a>, <a href="/format/2309.01901" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards General and Efficient Online Tuning for Spark
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yang Li</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+H">Huaijun Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+Y">Yu Shen</a>, 
<a href="/search/cs?searchtype=author&query=Fang%2C+Y">Yide Fang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+X">Xiaofeng Yang</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+D">Danqing Huang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xinyi Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+W">Wentao Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+C">Ce Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+P">Peng Chen</a>, 
<a href="/search/cs?searchtype=author&query=Cui%2C+B">Bin Cui</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Proceedings of the VLDB Endowment 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">The distributed data analytic system -- Spark is a common choice for
processing massive volumes of heterogeneous data, while it is challenging to
tune its parameters to achieve high performance. Recent studies try to employ
auto-tuning techniques to solve this problem but suffer from three issues:
limited functionality, high overhead, and inefficient search.
<br />In this paper, we present a general and efficient Spark tuning framework that
can deal with the three issues simultaneously. First, we introduce a
generalized tuning formulation, which can support multiple tuning goals and
constraints conveniently, and a Bayesian optimization (BO) based solution to
solve this generalized optimization problem. Second, to avoid high overhead
from additional offline evaluations in existing methods, we propose to tune
parameters along with the actual periodic executions of each job (i.e., online
evaluations). To ensure safety during online job executions, we design a safe
configuration acquisition method that models the safe region. Finally, three
innovative techniques are leveraged to further accelerate the search process:
adaptive sub-space generation, approximate gradient descent, and meta-learning
method.
<br />We have implemented this framework as an independent cloud service, and
applied it to the data platform in Tencent. The empirical results on both
public benchmarks and large-scale production tasks demonstrate its superiority
in terms of practicality, generality, and efficiency. Notably, this service
saves an average of 57.00% memory cost and 34.93% CPU cost on 25K in-production
tasks within 20 iterations, respectively.
</p>
</div>
</dd>
<dt><a name="item524">[524]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01902" title="Abstract">arXiv:2309.01902</a> [<a href="/pdf/2309.01902" title="Download PDF">pdf</a>, <a href="/ps/2309.01902" title="Download PostScript">ps</a>, <a href="/format/2309.01902" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A $5$-approximation Algorithm for the Traveling Tournament Problem
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhao%2C+J">Jingyang Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Xiao%2C+M">Mingyu Xiao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>

</div>
<p class="mathjax">The Traveling Tournament Problem (TTP-$k$) is a well-known benchmark problem
in tournament timetabling, which asks us to design a double round-robin
schedule such that the total traveling distance of all $n$ teams is minimized
under the constraints that each pair of teams plays one game in each other's
home venue, and each team plays at most $k$-consecutive home games or away
games. Westphal and Noparlik (Ann. Oper. Res. 218(1):347-360, 2014) claimed a
$5.875$-approximation algorithm for all $k\geq 4$ and $n\geq 6$. However, there
were both flaws in the construction of the schedule and in the analysis. In
this paper, we show that there is a $5$-approximation algorithm for all $k$ and
$n$. Furthermore, if $k \geq n/2$, the approximation ratio can be improved to
$4$.
</p>
</div>
</dd>
<dt><a name="item525">[525]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01903" title="Abstract">arXiv:2309.01903</a> [<a href="/pdf/2309.01903" title="Download PDF">pdf</a>, <a href="/format/2309.01903" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Robust Plant Disease Diagnosis with Hard-sample Re-mining  Strategy
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cap%2C+Q+H">Quan Huu Cap</a>, 
<a href="/search/cs?searchtype=author&query=Fukuda%2C+A">Atsushi Fukuda</a>, 
<a href="/search/cs?searchtype=author&query=Kagiwada%2C+S">Satoshi Kagiwada</a>, 
<a href="/search/cs?searchtype=author&query=Uga%2C+H">Hiroyuki Uga</a>, 
<a href="/search/cs?searchtype=author&query=Iwasaki%2C+N">Nobusuke Iwasaki</a>, 
<a href="/search/cs?searchtype=author&query=Iyatomi%2C+H">Hitoshi Iyatomi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">With rich annotation information, object detection-based automated plant
disease diagnosis systems (e.g., YOLO-based systems) often provide advantages
over classification-based systems (e.g., EfficientNet-based), such as the
ability to detect disease locations and superior classification performance.
One drawback of these detection systems is dealing with unannotated healthy
data with no real symptoms present. In practice, healthy plant data appear to
be very similar to many disease data. Thus, those models often produce
mis-detected boxes on healthy images. In addition, labeling new data for
detection models is typically time-consuming. Hard-sample mining (HSM) is a
common technique for re-training a model by using the mis-detected boxes as new
training samples. However, blindly selecting an arbitrary amount of hard-sample
for re-training will result in the degradation of diagnostic performance for
other diseases due to the high similarity between disease and healthy data. In
this paper, we propose a simple but effective training strategy called
hard-sample re-mining (HSReM), which is designed to enhance the diagnostic
performance of healthy data and simultaneously improve the performance of
disease data by strategically selecting hard-sample training images at an
appropriate level. Experiments based on two practical in-field eight-class
cucumber and ten-class tomato datasets (42.7K and 35.6K images) show that our
HSReM training strategy leads to a substantial improvement in the overall
diagnostic performance on large-scale unseen data. Specifically, the object
detection model trained using the HSReM strategy not only achieved superior
results as compared to the classification-based state-of-the-art
EfficientNetV2-Large model and the original object detection model, but also
outperformed the model using the HSM strategy.
</p>
</div>
</dd>
<dt><a name="item526">[526]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01904" title="Abstract">arXiv:2309.01904</a> [<a href="/pdf/2309.01904" title="Download PDF">pdf</a>, <a href="/format/2309.01904" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Improving Drone Imagery For Computer Vision/Machine Learning in  Wilderness Search and Rescue
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Murphy%2C+R">Robin Murphy</a>, 
<a href="/search/cs?searchtype=author&query=Manzini%2C+T">Thomas Manzini</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages, 4 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">This paper describes gaps in acquisition of drone imagery that impair the use
with computer vision/machine learning (CV/ML) models and makes five
recommendations to maximize image suitability for CV/ML post-processing. It
describes a notional work process for the use of drones in wilderness search
and rescue incidents. The large volume of data from the wide area search phase
offers the greatest opportunity for CV/ML techniques because of the large
number of images that would otherwise have to be manually inspected. The 2023
Wu-Murad search in Japan, one of the largest missing person searches conducted
in that area, serves as a case study. Although drone teams conducting wide area
searches may not know in advance if the data they collect is going to be used
for CV/ML post-processing, there are data collection procedures that can
improve the search in general with automated collection software. If the drone
teams do expect to use CV/ML, then they can exploit knowledge about the model
to further optimize flights.
</p>
</div>
</dd>
<dt><a name="item527">[527]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01906" title="Abstract">arXiv:2309.01906</a> [<a href="/pdf/2309.01906" title="Download PDF">pdf</a>, <a href="/format/2309.01906" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Generalizing Hierarchical Parallelism
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kruse%2C+M">Michael Kruse</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> IWOMP'23 preprint
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Programming Languages (cs.PL)</span>

</div>
<p class="mathjax">Since the days of OpenMP 1.0 computer hardware has become more complex,
typically by specializing compute units for coarse- and fine-grained
parallelism in incrementally deeper hierarchies of parallelism. Newer versions
of OpenMP reacted by introducing new mechanisms for querying or controlling its
individual levels, each time adding another concept such as places, teams, and
progress groups. In this paper we propose going back to the roots of OpenMP in
the form of nested parallelism for a simpler model and more flexible handling
of arbitrary deep hardware hierarchies.
</p>
</div>
</dd>
<dt><a name="item528">[528]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01907" title="Abstract">arXiv:2309.01907</a> [<a href="/pdf/2309.01907" title="Download PDF">pdf</a>, <a href="/format/2309.01907" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SyntheWorld: A Large-Scale Synthetic Dataset for Land Cover Mapping and  Building Change Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Song%2C+J">Jian Song</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+H">Hongruixuan Chen</a>, 
<a href="/search/cs?searchtype=author&query=Yokoya%2C+N">Naoto Yokoya</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by WACV 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Human-Computer Interaction (cs.HC)

</div>
<p class="mathjax">Synthetic datasets, recognized for their cost effectiveness, play a pivotal
role in advancing computer vision tasks and techniques. However, when it comes
to remote sensing image processing, the creation of synthetic datasets becomes
challenging due to the demand for larger-scale and more diverse 3D models. This
complexity is compounded by the difficulties associated with real remote
sensing datasets, including limited data acquisition and high annotation costs,
which amplifies the need for high-quality synthetic alternatives. To address
this, we present SyntheWorld, a synthetic dataset unparalleled in quality,
diversity, and scale. It includes 40,000 images with submeter-level pixels and
fine-grained land cover annotations of eight categories, and it also provides
40,000 pairs of bitemporal image pairs with building change annotations for
building change detection task. We conduct experiments on multiple benchmark
remote sensing datasets to verify the effectiveness of SyntheWorld and to
investigate the conditions under which our synthetic data yield advantages. We
will release SyntheWorld to facilitate remote sensing image processing
research.
</p>
</div>
</dd>
<dt><a name="item529">[529]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01908" title="Abstract">arXiv:2309.01908</a> [<a href="/pdf/2309.01908" title="Download PDF">pdf</a>, <a href="/format/2309.01908" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Bound-preserving discontinuous Galerkin methods for compressible  two-phase flows in porous media
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Joshaghani%2C+M+S">M. S. Joshaghani</a>, 
<a href="/search/math?searchtype=author&query=Riviere%2C+B">B. Riviere</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 21 pages and 17 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">This paper presents a numerical study of immiscible, compressible two-phase
flows in porous media, that takes into account heterogeneity, gravity,
anisotropy, and injection/production wells. We formulate a fully implicit
stable discontinuous Galerkin solver for this system that is accurate, that
respects the maximum principle for the approximation of saturation, and that is
locally mass conservative. To completely eliminate the overshoot and undershoot
phenomena, we construct a flux limiter that produces bound-preserving
elementwise average of the saturation. The addition of a slope limiter allows
to recover a pointwise bound-preserving discrete saturation. Numerical results
show that both maximum principle and monotonicity of the solution are
satisfied. The proposed flux limiter does not impact the local mass error and
the number of nonlinear solver iterations.
</p>
</div>
</dd>
<dt><a name="item530">[530]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01909" title="Abstract">arXiv:2309.01909</a> [<a href="/pdf/2309.01909" title="Download PDF">pdf</a>, <a href="/format/2309.01909" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Survey on Physics Informed Reinforcement Learning: Review and Open  Problems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Banerjee%2C+C">Chayan Banerjee</a>, 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+K">Kien Nguyen</a>, 
<a href="/search/cs?searchtype=author&query=Fookes%2C+C">Clinton Fookes</a>, 
<a href="/search/cs?searchtype=author&query=Raissi%2C+M">Maziar Raissi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Systems and Control (eess.SY)

</div>
<p class="mathjax">The inclusion of physical information in machine learning frameworks has
revolutionized many application areas. This involves enhancing the learning
process by incorporating physical constraints and adhering to physical laws. In
this work we explore their utility for reinforcement learning applications. We
present a thorough review of the literature on incorporating physics
information, as known as physics priors, in reinforcement learning approaches,
commonly referred to as physics-informed reinforcement learning (PIRL). We
introduce a novel taxonomy with the reinforcement learning pipeline as the
backbone to classify existing works, compare and contrast them, and derive
crucial insights. Existing works are analyzed with regard to the
representation/ form of the governing physics modeled for integration, their
specific contribution to the typical reinforcement learning architecture, and
their connection to the underlying reinforcement learning pipeline stages. We
also identify core learning architectures and physics incorporation biases
(i.e., observational, inductive and learning) of existing PIRL approaches and
use them to further categorize the works for better understanding and
adaptation. By providing a comprehensive perspective on the implementation of
the physics-informed capability, the taxonomy presents a cohesive approach to
PIRL. It identifies the areas where this approach has been applied, as well as
the gaps and opportunities that exist. Additionally, the taxonomy sheds light
on unresolved issues and challenges, which can guide future research. This
nascent field holds great potential for enhancing reinforcement learning
algorithms by increasing their physical plausibility, precision, data
efficiency, and applicability in real-world scenarios.
</p>
</div>
</dd>
<dt><a name="item531">[531]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01916" title="Abstract">arXiv:2309.01916</a> [<a href="/pdf/2309.01916" title="Download PDF">pdf</a>, <a href="/format/2309.01916" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Realistic Volume Rendering with Environment-Synced Illumination in Mixed  Reality
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cheng%2C+H">Haojie Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+C">Chunxiao Xu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+X">Xujing Chen</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Z">Zhenxin Chen</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jiajun Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+L">Lingxiao Zhao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages, 6 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Graphics (cs.GR)</span>

</div>
<p class="mathjax">Interactive volume visualization using a mixed reality (MR) system helps
provide users with an intuitive spatial perception of volumetric data. Due to
sophisticated requirements of user interaction and vision when using MR
head-mounted display (HMD) devices, the conflict between the realisticness and
efficiency of direct volume rendering (DVR) is yet to be resolved. In this
paper, a new MR visualization framework that supports interactive realistic DVR
is proposed. An efficient illumination estimation method is used to identify
the high dynamic range (HDR) environment illumination captured using a panorama
camera. To improve the visual quality of Monte Carlo-based DVR, a new
spatio-temporal denoising algorithm is designed. Based on a reprojection
strategy, it makes full use of temporal coherence between adjacent frames and
spatial coherence between the two screens of an HMD to optimize MR rendering
quality. Several MR development modules are also developed for related devices
to efficiently and stably display the DVR results in an MR HMD. Experimental
results demonstrate that our framework can better support immersive and
intuitive user perception during MR viewing than existing MR solutions.
</p>
</div>
</dd>
<dt><a name="item532">[532]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01918" title="Abstract">arXiv:2309.01918</a> [<a href="/pdf/2309.01918" title="Download PDF">pdf</a>, <a href="/format/2309.01918" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> RoboAgent: Generalization and Efficiency in Robot Manipulation via  Semantic Augmentations and Action Chunking
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bharadhwaj%2C+H">Homanga Bharadhwaj</a>, 
<a href="/search/cs?searchtype=author&query=Vakil%2C+J">Jay Vakil</a>, 
<a href="/search/cs?searchtype=author&query=Sharma%2C+M">Mohit Sharma</a>, 
<a href="/search/cs?searchtype=author&query=Gupta%2C+A">Abhinav Gupta</a>, 
<a href="/search/cs?searchtype=author&query=Tulsiani%2C+S">Shubham Tulsiani</a>, 
<a href="/search/cs?searchtype=author&query=Kumar%2C+V">Vikash Kumar</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">The grand aim of having a single robot that can manipulate arbitrary objects
in diverse settings is at odds with the paucity of robotics datasets. Acquiring
and growing such datasets is strenuous due to manual efforts, operational
costs, and safety challenges. A path toward such an universal agent would
require a structured framework capable of wide generalization but trained
within a reasonable data budget. In this paper, we develop an efficient system
(RoboAgent) for training universal agents capable of multi-task manipulation
skills using (a) semantic augmentations that can rapidly multiply existing
datasets and (b) action representations that can extract performant policies
with small yet diverse multi-modal datasets without overfitting. In addition,
reliable task conditioning and an expressive policy architecture enable our
agent to exhibit a diverse repertoire of skills in novel situations specified
using language commands. Using merely 7500 demonstrations, we are able to train
a single agent capable of 12 unique skills, and demonstrate its generalization
over 38 tasks spread across common daily activities in diverse kitchen scenes.
On average, RoboAgent outperforms prior methods by over 40% in unseen
situations while being more sample efficient and being amenable to capability
improvements and extensions through fine-tuning. Videos at
https://robopen.github.io/
</p>
</div>
</dd>
<dt><a name="item533">[533]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01919" title="Abstract">arXiv:2309.01919</a> [<a href="/pdf/2309.01919" title="Download PDF">pdf</a>, <a href="/format/2309.01919" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Understanding of Deepfake Videos in the Wild
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cho%2C+B">Beomsang Cho</a>, 
<a href="/search/cs?searchtype=author&query=Le%2C+B+M">Binh M. Le</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+J">Jiwon Kim</a>, 
<a href="/search/cs?searchtype=author&query=Woo%2C+S">Simon Woo</a>, 
<a href="/search/cs?searchtype=author&query=Tariq%2C+S">Shahroz Tariq</a>, 
<a href="/search/cs?searchtype=author&query=Abuadbba%2C+A">Alsharif Abuadbba</a>, 
<a href="/search/cs?searchtype=author&query=Moore%2C+K">Kristen Moore</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> 32nd ACM International Conference on Information &amp; Knowledge
  Management (CIKM), UK, 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>

</div>
<p class="mathjax">Deepfakes have become a growing concern in recent years, prompting
researchers to develop benchmark datasets and detection algorithms to tackle
the issue. However, existing datasets suffer from significant drawbacks that
hamper their effectiveness. Notably, these datasets fail to encompass the
latest deepfake videos produced by state-of-the-art methods that are being
shared across various platforms. This limitation impedes the ability to keep
pace with the rapid evolution of generative AI techniques employed in
real-world deepfake production. Our contributions in this IRB-approved study
are to bridge this knowledge gap from current real-world deepfakes by providing
in-depth analysis. We first present the largest and most diverse and recent
deepfake dataset (RWDF-23) collected from the wild to date, consisting of 2,000
deepfake videos collected from 4 platforms targeting 4 different languages span
created from 21 countries: Reddit, YouTube, TikTok, and Bilibili. By expanding
the dataset's scope beyond the previous research, we capture a broader range of
real-world deepfake content, reflecting the ever-evolving landscape of online
platforms. Also, we conduct a comprehensive analysis encompassing various
aspects of deepfakes, including creators, manipulation strategies, purposes,
and real-world content production methods. This allows us to gain valuable
insights into the nuances and characteristics of deepfakes in different
contexts. Lastly, in addition to the video content, we also collect viewer
comments and interactions, enabling us to explore the engagements of internet
users with deepfake content. By considering this rich contextual information,
we aim to provide a holistic understanding of the {evolving} deepfake
phenomenon and its impact on online platforms.
</p>
</div>
</dd>
<dt><a name="item534">[534]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01920" title="Abstract">arXiv:2309.01920</a> [<a href="/pdf/2309.01920" title="Download PDF">pdf</a>, <a href="/format/2309.01920" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Dual Auction Mechanism for Transaction Forwarding and Validation in  Complex Wireless Blockchain Network
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+W">Weiyi Wang</a>, 
<a href="/search/cs?searchtype=author&query=Jiao%2C+Y">Yutao Jiao</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Jin Chen</a>, 
<a href="/search/cs?searchtype=author&query=Dai%2C+W">Wenting Dai</a>, 
<a href="/search/cs?searchtype=author&query=Kang%2C+J">Jiawen Kang</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+Y">Yuhua Xu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>; Computer Science and Game Theory (cs.GT)

</div>
<p class="mathjax">In traditional blockchain networks, transaction fees are only allocated to
full nodes (i.e., miners) regardless of the contribution of forwarding
behaviors of light nodes. However, the lack of forwarding incentive reduces the
willingness of light nodes to relay transactions, especially in the
energy-constrained Mobile Ad Hoc Network (MANET). This paper proposes a novel
dual auction mechanism to allocate transaction fees for forwarding and
validation behaviors in the wireless blockchain network. The dual auction
mechanism consists of two auction models: the forwarding auction and the
validation auction. In the forwarding auction, forwarding nodes use Generalized
First Price (GFP) auction to choose transactions to forward. Besides,
forwarding nodes adjust the forwarding probability through a no-regret
algorithm to improve efficiency. In the validation auction, full nodes select
transactions using Vickrey-Clarke-Grove (VCG) mechanism to construct the block.
We prove that the designed dual auction mechanism is Incentive Compatibility
(IC), Individual Rationality (IR), and Computational Efficiency (CE).
Especially, we derive the upper bound of the social welfare difference between
the social optimal auction and our proposed one. Extensive simulation results
demonstrate that the proposed dual auction mechanism decreases energy and
spectrum resource consumption and effectively improves social welfare without
sacrificing the throughput and the security of the wireless blockchain network.
</p>
</div>
</dd>
<dt><a name="item535">[535]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01921" title="Abstract">arXiv:2309.01921</a> [<a href="/pdf/2309.01921" title="Download PDF">pdf</a>, <a href="/format/2309.01921" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Causal Scoring Medical Image Explanations: A Case Study On Ex-vivo  Kidney Stone Images
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Villegas-Jimenez%2C+A">Armando Villegas-Jimenez</a>, 
<a href="/search/cs?searchtype=author&query=Flores-Araiza%2C+D">Daniel Flores-Araiza</a>, 
<a href="/search/cs?searchtype=author&query=Lopez-Tiro%2C+F">Francisco Lopez-Tiro</a>, 
<a href="/search/cs?searchtype=author&query=Daul%2C+G+O+a+C">Gilberto Ochoa-Ruiz andand Christian Daul</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">On the promise that if human users know the cause of an output, it would
enable them to grasp the process responsible for the output, and hence provide
understanding, many explainable methods have been proposed to indicate the
cause for the output of a model based on its input. Nonetheless, little has
been reported on quantitative measurements of such causal relationships between
the inputs, the explanations, and the outputs of a model, leaving the
assessment to the user, independent of his level of expertise in the subject.
To address this situation, we explore a technique for measuring the causal
relationship between the features from the area of the object of interest in
the images of a class and the output of a classifier. Our experiments indicate
improvement in the causal relationships measured when the area of the object of
interest per class is indicated by a mask from an explainable method than when
it is indicated by human annotators. Hence the chosen name of Causal
Explanation Score (CaES)
</p>
</div>
</dd>
<dt><a name="item536">[536]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01922" title="Abstract">arXiv:2309.01922</a> [<a href="/pdf/2309.01922" title="Download PDF">pdf</a>, <a href="/ps/2309.01922" title="Download PostScript">ps</a>, <a href="/format/2309.01922" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Regret Analysis of Policy Gradient Algorithm for Infinite Horizon  Average Reward Markov Decision Processes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bai%2C+Q">Qinbo Bai</a>, 
<a href="/search/cs?searchtype=author&query=Mondal%2C+W+U">Washim Uddin Mondal</a>, 
<a href="/search/cs?searchtype=author&query=Aggarwal%2C+V">Vaneet Aggarwal</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">In this paper, we consider an infinite horizon average reward Markov Decision
Process (MDP). Distinguishing itself from existing works within this context,
our approach harnesses the power of the general policy gradient-based
algorithm, liberating it from the constraints of assuming a linear MDP
structure. We propose a policy gradient-based algorithm and show its global
convergence property. We then prove that the proposed algorithm has
$\tilde{\mathcal{O}}({T}^{3/4})$ regret. Remarkably, this paper marks a
pioneering effort by presenting the first exploration into regret-bound
computation for the general parameterized policy gradient algorithm in the
context of average reward scenarios.
</p>
</div>
</dd>
<dt><a name="item537">[537]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01925" title="Abstract">arXiv:2309.01925</a> [<a href="/pdf/2309.01925" title="Download PDF">pdf</a>, <a href="/format/2309.01925" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DR-Pose: A Two-stage Deformation-and-Registration Pipeline for  Category-level 6D Object Pose Estimation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhou%2C+L">Lei Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zhiyang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Gan%2C+R">Runze Gan</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Haozhe Wang</a>, 
<a href="/search/cs?searchtype=author&query=Ang%2C+M+H">Marcelo H. Ang Jr</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Camera-ready version accepted to IROS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Robotics (cs.RO)

</div>
<p class="mathjax">Category-level object pose estimation involves estimating the 6D pose and the
3D metric size of objects from predetermined categories. While recent
approaches take categorical shape prior information as reference to improve
pose estimation accuracy, the single-stage network design and training manner
lead to sub-optimal performance since there are two distinct tasks in the
pipeline. In this paper, the advantage of two-stage pipeline over single-stage
design is discussed. To this end, we propose a two-stage deformation-and
registration pipeline called DR-Pose, which consists of completion-aided
deformation stage and scaled registration stage. The first stage uses a point
cloud completion method to generate unseen parts of target object, guiding
subsequent deformation on the shape prior. In the second stage, a novel
registration network is designed to extract pose-sensitive features and predict
the representation of object partial point cloud in canonical space based on
the deformation results from the first stage. DR-Pose produces superior results
to the state-of-the-art shape prior-based methods on both CAMERA25 and REAL275
benchmarks. Codes are available at https://github.com/Zray26/DR-Pose.git.
</p>
</div>
</dd>
<dt><a name="item538">[538]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01930" title="Abstract">arXiv:2309.01930</a> [<a href="/pdf/2309.01930" title="Download PDF">pdf</a>, <a href="/ps/2309.01930" title="Download PostScript">ps</a>, <a href="/format/2309.01930" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Superconvergence of a nonconforming brick element for the quad-curl  problem
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Zhou%2C+X">Xinchen Zhou</a>, 
<a href="/search/math?searchtype=author&query=Meng%2C+Z">Zhaoliang Meng</a>, 
<a href="/search/math?searchtype=author&query=Niu%2C+H">Hexin Niu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">This short note shows the superconvergence of an
$H(\mathrm{grad}\,\mathrm{curl})$-nonconforming brick element very recently
introduced in [17] for the quad-curl problem. The supercloseness is based on
proper modifications for both the interpolation and the discrete formulation,
leading to an $O(h^2)$ superclose order in the discrete
$H(\mathrm{grad}\,\mathrm{curl})$ norm. Moreover, we propose a suitable
postprocessing method to ensure the global superconvergence. Numerical results
verify our theory.
</p>
</div>
</dd>
<dt><a name="item539">[539]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01933" title="Abstract">arXiv:2309.01933</a> [<a href="/pdf/2309.01933" title="Download PDF">pdf</a>, <a href="/format/2309.01933" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Provably safe systems: the only path to controllable AGI
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tegmark%2C+M">Max Tegmark</a> (MIT), 
<a href="/search/cs?searchtype=author&query=Omohundro%2C+S">Steve Omohundro</a> (Beneficial AI Research)
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 17 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">We describe a path to humanity safely thriving with powerful Artificial
General Intelligences (AGIs) by building them to provably satisfy
human-specified requirements. We argue that this will soon be technically
feasible using advanced AI for formal verification and mechanistic
interpretability. We further argue that it is the only path which guarantees
safe controlled AGI. We end with a list of challenge problems whose solution
would contribute to this positive outcome and invite readers to join in this
work.
</p>
</div>
</dd>
<dt><a name="item540">[540]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01940" title="Abstract">arXiv:2309.01940</a> [<a href="/pdf/2309.01940" title="Download PDF">pdf</a>, <a href="/format/2309.01940" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CodeApex: A Bilingual Programming Evaluation Benchmark for Large  Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fu%2C+L">Lingyue Fu</a>, 
<a href="/search/cs?searchtype=author&query=Chai%2C+H">Huacan Chai</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+S">Shuang Luo</a>, 
<a href="/search/cs?searchtype=author&query=Du%2C+K">Kounianhua Du</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+W">Weiming Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Fan%2C+L">Longteng Fan</a>, 
<a href="/search/cs?searchtype=author&query=Lei%2C+J">Jiayi Lei</a>, 
<a href="/search/cs?searchtype=author&query=Rui%2C+R">Renting Rui</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+J">Jianghao Lin</a>, 
<a href="/search/cs?searchtype=author&query=Fang%2C+Y">Yuchen Fang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yifan Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jingkuan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Qi%2C+S">Siyuan Qi</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+K">Kangning Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+W">Weinan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+Y">Yong Yu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 20 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">With the emergence of Large Language Models (LLMs), there has been a
significant improvement in the programming capabilities of models, attracting
growing attention from researchers. We propose CodeApex, a bilingual benchmark
dataset focusing on the programming comprehension and code generation abilities
of LLMs. CodeApex comprises three types of multiple-choice questions:
conceptual understanding, commonsense reasoning, and multi-hop reasoning,
designed to evaluate LLMs on programming comprehension tasks. Additionally,
CodeApex utilizes algorithmic questions and corresponding test cases to assess
the code quality generated by LLMs. We evaluate 14 state-of-the-art LLMs,
including both general-purpose and specialized models. GPT exhibits the best
programming capabilities, achieving approximate accuracies of 50% and 56% on
the two tasks, respectively. There is still significant room for improvement in
programming tasks. We hope that CodeApex can serve as a reference for
evaluating the coding capabilities of LLMs, further promoting their development
and growth. Datasets are released at
\url{https://github.com/APEXLAB/CodeApex.git}. CodeApex submission website is
\url{https://apex.sjtu.edu.cn/codeapex/}.
</p>
</div>
</dd>
<dt><a name="item541">[541]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01943" title="Abstract">arXiv:2309.01943</a> [<a href="/pdf/2309.01943" title="Download PDF">pdf</a>, <a href="/format/2309.01943" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Extract-and-Adaptation Network for 3D Interacting Hand Mesh Recovery
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Park%2C+J">JoonKyu Park</a>, 
<a href="/search/cs?searchtype=author&query=Jung%2C+D+S">Daniel Sungho Jung</a>, 
<a href="/search/cs?searchtype=author&query=Moon%2C+G">Gyeongsik Moon</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+K+M">Kyoung Mu Lee</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at ICCVW 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Understanding how two hands interact with each other is a key component of
accurate 3D interacting hand mesh recovery. However, recent Transformer-based
methods struggle to learn the interaction between two hands as they directly
utilize two hand features as input tokens, which results in distant token
problem. The distant token problem represents that input tokens are in
heterogeneous spaces, leading Transformer to fail in capturing correlation
between input tokens. Previous Transformer-based methods suffer from the
problem especially when poses of two hands are very different as they project
features from a backbone to separate left and right hand-dedicated features. We
present EANet, extract-and-adaptation network, with EABlock, the main component
of our network. Rather than directly utilizing two hand features as input
tokens, our EABlock utilizes two complementary types of novel tokens, SimToken
and JoinToken, as input tokens. Our two novel tokens are from a combination of
separated two hand features; hence, it is much more robust to the distant token
problem. Using the two type of tokens, our EABlock effectively extracts
interaction feature and adapts it to each hand. The proposed EANet achieves the
state-of-the-art performance on 3D interacting hands benchmarks. The codes are
available at https://github.com/jkpark0825/EANet.
</p>
</div>
</dd>
<dt><a name="item542">[542]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01945" title="Abstract">arXiv:2309.01945</a> [<a href="/pdf/2309.01945" title="Download PDF">pdf</a>, <a href="/format/2309.01945" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> OHQ: On-chip Hardware-aware Quantization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+W">Wei Huang</a>, 
<a href="/search/cs?searchtype=author&query=Qin%2C+H">Haotong Qin</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yangdong Liu</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+J">Jingzhuo Liang</a>, 
<a href="/search/cs?searchtype=author&query=Ding%2C+Y">Yifu Ding</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Ying Li</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xianglong Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 6 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Hardware Architecture (cs.AR)

</div>
<p class="mathjax">Quantization emerges as one of the most promising approaches for deploying
advanced deep models on resource-constrained hardware. Mixed-precision
quantization leverages multiple bit-width architectures to unleash the accuracy
and efficiency potential of quantized models. However, existing mixed-precision
quantization suffers exhaustive search space that causes immense computational
overhead. The quantization process thus relies on separate high-performance
devices rather than locally, which also leads to a significant gap between the
considered hardware metrics and the real deployment.In this paper, we propose
an On-chip Hardware-aware Quantization (OHQ) framework that performs
hardware-aware mixed-precision quantization without accessing online devices.
First, we construct the On-chip Quantization Awareness (OQA) pipeline, enabling
perceive the actual efficiency metrics of the quantization operator on the
hardware.Second, we propose Mask-guided Quantization Estimation (MQE) technique
to efficiently estimate the accuracy metrics of operators under the constraints
of on-chip-level computing power.By synthesizing network and hardware insights
through linear programming, we obtain optimized bit-width configurations.
Notably, the quantization process occurs on-chip entirely without any
additional computing devices and data access. We demonstrate accelerated
inference after quantization for various architectures and compression ratios,
achieving 70% and 73% accuracy for ResNet-18 and MobileNetV3, respectively. OHQ
improves latency by 15~30% compared to INT8 on deployment.
</p>
</div>
</dd>
<dt><a name="item543">[543]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01947" title="Abstract">arXiv:2309.01947</a> [<a href="/pdf/2309.01947" title="Download PDF">pdf</a>, <a href="/format/2309.01947" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> TODM: Train Once Deploy Many Efficient Supernet-Based RNN-T Compression  For On-device ASR Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shangguan%2C+Y">Yuan Shangguan</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+H">Haichuan Yang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+D">Danni Li</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+C">Chunyang Wu</a>, 
<a href="/search/cs?searchtype=author&query=Fathullah%2C+Y">Yassir Fathullah</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+D">Dilin Wang</a>, 
<a href="/search/cs?searchtype=author&query=Dalmia%2C+A">Ayushi Dalmia</a>, 
<a href="/search/cs?searchtype=author&query=Krishnamoorthi%2C+R">Raghuraman Krishnamoorthi</a>, 
<a href="/search/cs?searchtype=author&query=Kalinli%2C+O">Ozlem Kalinli</a>, 
<a href="/search/cs?searchtype=author&query=Jia%2C+J">Junteng Jia</a>, 
<a href="/search/cs?searchtype=author&query=Mahadeokar%2C+J">Jay Mahadeokar</a>, 
<a href="/search/cs?searchtype=author&query=Lei%2C+X">Xin Lei</a>, 
<a href="/search/cs?searchtype=author&query=Seltzer%2C+M">Mike Seltzer</a>, 
<a href="/search/cs?searchtype=author&query=Chandra%2C+V">Vikas Chandra</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Meta AI; Submitted to ICASSP 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Machine Learning (cs.LG); Sound (cs.SD); Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">Automatic Speech Recognition (ASR) models need to be optimized for specific
hardware before they can be deployed on devices. This can be done by tuning the
model's hyperparameters or exploring variations in its architecture.
Re-training and re-validating models after making these changes can be a
resource-intensive task. This paper presents TODM (Train Once Deploy Many), a
new approach to efficiently train many sizes of hardware-friendly on-device ASR
models with comparable GPU-hours to that of a single training job. TODM
leverages insights from prior work on Supernet, where Recurrent Neural Network
Transducer (RNN-T) models share weights within a Supernet. It reduces layer
sizes and widths of the Supernet to obtain subnetworks, making them smaller
models suitable for all hardware types. We introduce a novel combination of
three techniques to improve the outcomes of the TODM Supernet: adaptive
dropouts, an in-place Alpha-divergence knowledge distillation, and the use of
ScaledAdam optimizer. We validate our approach by comparing Supernet-trained
versus individually tuned Multi-Head State Space Model (MH-SSM) RNN-T using
LibriSpeech. Results demonstrate that our TODM Supernet either matches or
surpasses the performance of manually tuned models by up to a relative of 3%
better in word error rate (WER), while efficiently keeping the cost of training
many models at a small constant.
</p>
</div>
</dd>
<dt><a name="item544">[544]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01948" title="Abstract">arXiv:2309.01948</a> [<a href="/pdf/2309.01948" title="Download PDF">pdf</a>, <a href="/format/2309.01948" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Automatic Diary Generation System including Information on Joint  Experiences between Humans and Robots
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ichikura%2C+A">Aiko Ichikura</a>, 
<a href="/search/cs?searchtype=author&query=Kawaharazuka%2C+K">Kento Kawaharazuka</a>, 
<a href="/search/cs?searchtype=author&query=Obinata%2C+Y">Yoshiki Obinata</a>, 
<a href="/search/cs?searchtype=author&query=Shinjo%2C+K">Koki Shinjo</a>, 
<a href="/search/cs?searchtype=author&query=Okada%2C+K">Kei Okada</a>, 
<a href="/search/cs?searchtype=author&query=Inaba%2C+M">Masayuki Inaba</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 5 figures, IAS-18
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">In this study, we propose an automatic diary generation system that uses
information from past joint experiences with the aim of increasing the
favorability for robots through shared experiences between humans and robots.
For the verbalization of the robot's memory, the system applies a large-scale
language model, which is a rapidly developing field. Since this model does not
have memories of experiences, it generates a diary by receiving information
from joint experiences. As an experiment, a robot and a human went for a walk
and generated a diary with interaction and dialogue history. The proposed diary
achieved high scores in comfort and performance in the evaluation of the
robot's impression. In the survey of diaries giving more favorable impressions,
diaries with information on joint experiences were selected higher than diaries
without such information, because diaries with information on joint experiences
showed more cooperation between the robot and the human and more intimacy from
the robot.
</p>
</div>
</dd>
<dt><a name="item545">[545]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01949" title="Abstract">arXiv:2309.01949</a> [<a href="/pdf/2309.01949" title="Download PDF">pdf</a>, <a href="/format/2309.01949" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Efficient Bayesian Computational Imaging with a Surrogate Score-Based  Prior
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Feng%2C+B+T">Berthy T. Feng</a>, 
<a href="/search/cs?searchtype=author&query=Bouman%2C+K+L">Katherine L. Bouman</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">We propose a surrogate function for efficient use of score-based priors for
Bayesian inverse imaging. Recent work turned score-based diffusion models into
probabilistic priors for solving ill-posed imaging problems by appealing to an
ODE-based log-probability function. However, evaluating this function is
computationally inefficient and inhibits posterior estimation of
high-dimensional images. Our proposed surrogate prior is based on the evidence
lower-bound of a score-based diffusion model. We demonstrate the surrogate
prior on variational inference for efficient approximate posterior sampling of
large images. Compared to the exact prior in previous work, our surrogate prior
accelerates optimization of the variational image distribution by at least two
orders of magnitude. We also find that our principled approach achieves
higher-fidelity images than non-Bayesian baselines that involve
hyperparameter-tuning at inference. Our work establishes a practical path
forward for using score-based diffusion models as general-purpose priors for
imaging.
</p>
</div>
</dd>
<dt><a name="item546">[546]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01950" title="Abstract">arXiv:2309.01950</a> [<a href="/pdf/2309.01950" title="Download PDF">pdf</a>, <a href="/format/2309.01950" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> RADIO: Reference-Agnostic Dubbing Video Synthesis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lee%2C+D">Dongyeun Lee</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+C">Chaewon Kim</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+S">Sangjoon Yu</a>, 
<a href="/search/cs?searchtype=author&query=Yoo%2C+J">Jaejun Yoo</a>, 
<a href="/search/cs?searchtype=author&query=Park%2C+G">Gyeong-Moon Park</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Under review
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Sound (cs.SD); Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">One of the most challenging problems in audio-driven talking head generation
is achieving high-fidelity detail while ensuring precise synchronization. Given
only a single reference image, extracting meaningful identity attributes
becomes even more challenging, often causing the network to mirror the facial
and lip structures too closely. To address these issues, we introduce RADIO, a
framework engineered to yield high-quality dubbed videos regardless of the pose
or expression in reference images. The key is to modulate the decoder layers
using latent space composed of audio and reference features. Additionally, we
incorporate ViT blocks into the decoder to emphasize high-fidelity details,
especially in the lip region. Our experimental results demonstrate that RADIO
displays high synchronization without the loss of fidelity. Especially in harsh
scenarios where the reference frame deviates significantly from the ground
truth, our method outperforms state-of-the-art methods, highlighting its
robustness. Pre-trained model and codes will be made public after the review.
</p>
</div>
</dd>
<dt><a name="item547">[547]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01951" title="Abstract">arXiv:2309.01951</a> [<a href="/pdf/2309.01951" title="Download PDF">pdf</a>, <a href="/format/2309.01951" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A method for Selecting Scenes and Emotion-based Descriptions for a  Robot&#x27;s Diary
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ichikura%2C+A">Aiko Ichikura</a>, 
<a href="/search/cs?searchtype=author&query=Kawaharazuka%2C+K">Kento Kawaharazuka</a>, 
<a href="/search/cs?searchtype=author&query=Obinata%2C+Y">Yoshiki Obinata</a>, 
<a href="/search/cs?searchtype=author&query=Okada%2C+K">Kei Okada</a>, 
<a href="/search/cs?searchtype=author&query=Inaba%2C+M">Masayuki Inaba</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages, 5 figures, ROMAN 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">In this study, we examined scene selection methods and emotion-based
descriptions for a robot's daily diary. We proposed a scene selection method
and an emotion description method that take into account semantic and affective
information, and created several types of diaries. Experiments were conducted
to examine the change in sentiment values and preference of each diary, and it
was found that the robot's feelings and impressions changed more from date to
date when scenes were selected using the affective captions. Furthermore, we
found that the robot's emotion generally improves the preference of the robot's
diary regardless of the scene it describes. However, presenting negative or
mixed emotions at once may decrease the preference of the diary or reduce the
robot's robot-likeness, and thus the method of presenting emotions still needs
further investigation.
</p>
</div>
</dd>
<dt><a name="item548">[548]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01952" title="Abstract">arXiv:2309.01952</a> [<a href="/pdf/2309.01952" title="Download PDF">pdf</a>, <a href="/format/2309.01952" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deep Imitation Learning for Humanoid Loco-manipulation through Human  Teleoperation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Seo%2C+M">Mingyo Seo</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+S">Steve Han</a>, 
<a href="/search/cs?searchtype=author&query=Sim%2C+K">Kyutae Sim</a>, 
<a href="/search/cs?searchtype=author&query=Bang%2C+S+H">Seung Hyeon Bang</a>, 
<a href="/search/cs?searchtype=author&query=Gonzalez%2C+C">Carlos Gonzalez</a>, 
<a href="/search/cs?searchtype=author&query=Sentis%2C+L">Luis Sentis</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+Y">Yuke Zhu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to Humanoids 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">We tackle the problem of developing humanoid loco-manipulation skills with
deep imitation learning. The difficulty of collecting task demonstrations and
training policies for humanoids with a high degree of freedom presents
substantial challenges. We introduce TRILL, a data-efficient framework for
training humanoid loco-manipulation policies from human demonstrations. In this
framework, we collect human demonstration data through an intuitive Virtual
Reality (VR) interface. We employ the whole-body control formulation to
transform task-space commands by human operators into the robot's joint-torque
actuation while stabilizing its dynamics. By employing high-level action
abstractions tailored for humanoid loco-manipulation, our method can
efficiently learn complex sensorimotor skills. We demonstrate the effectiveness
of TRILL in simulation and on a real-world robot for performing various
loco-manipulation tasks. Videos and additional materials can be found on the
project page: https://ut-austin-rpl.github.io/TRILL.
</p>
</div>
</dd>
<dt><a name="item549">[549]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01953" title="Abstract">arXiv:2309.01953</a> [<a href="/pdf/2309.01953" title="Download PDF">pdf</a>, <a href="/format/2309.01953" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Bilevel Scheduled Sampling for Dialogue Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jiawen Liu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+K">Kan Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, 4 figures, Natural Language Processing and Chinese Computing(NLPCC 2023) accepted
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Exposure bias poses a common challenge in numerous natural language
processing tasks, particularly in the dialog generation. In response to this
issue, researchers have devised various techniques, among which scheduled
sampling has proven to be an effective method for mitigating exposure bias.
However, the existing state-of-the-art scheduled sampling methods solely
consider the current sampling words' quality for threshold truncation sampling,
which overlooks the importance of sentence-level information and the method of
threshold truncation warrants further discussion. In this paper, we propose a
bilevel scheduled sampling model that takes the sentence-level information into
account and incorporates it with word-level quality. To enhance sampling
diversity and improve the model's adaptability, we propose a smooth function
that maps the combined result of sentence-level and word-level information to
an appropriate range, and employ probabilistic sampling based on the mapped
values instead of threshold truncation. Experiments conducted on the
DailyDialog and PersonaChat datasets demonstrate the effectiveness of our
proposed methods, which significantly alleviate the exposure bias problem and
outperform state-of-the-art scheduled sampling methods.
</p>
</div>
</dd>
<dt><a name="item550">[550]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01954" title="Abstract">arXiv:2309.01954</a> [<a href="/pdf/2309.01954" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Electro-Chemo-Mechanical Modeling of Multiscale Active Materials for  Next-Generation Energy Storage: Opportunities and Challenges
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Datta%2C+D">Dibakar Datta</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 33 pages, 17 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Engineering, Finance, and Science (cs.CE)</span>

</div>
<p class="mathjax">The recent geopolitical crisis resulted in a gas price surge. Although
lithium-ion batteries represent the best available rechargeable battery
technology, a significant energy and power density gap exists between LIBs and
petrol/gasoline. The battery electrodes comprise a mixture of active materials
particles, conductive carbon, and binder additives deposited onto a current
collector. Although this basic design has persisted for decades, the active
material particle's desired size scale is debated. Traditionally,
microparticles have been used in batteries. Advances in nanotechnology have
spurred interest in deploying nanoparticles as active materials. However,
despite many efforts in nano, industries still primarily use 'old'
microparticles. Most importantly, the battery industry is unlikely to replace
microstructures with nanometer-sized analogs. This poses an important question:
Is there a place for nanostructure in battery design due to irreplaceable
microstructure? The way forward lies in multiscale active materials, microscale
structures with built-in nanoscale features, such as microparticles assembled
from nanoscale building blocks or patterned with engineered or natural
nanopores. Although experimental strides have been made in developing such
materials, computational progress in this domain remains limited and, in some
cases, negligible. However, the fields hold immense computational potential,
presenting a multitude of opportunities. This perspective highlights the
existing gaps in modeling multiscale active materials and delineates various
open challenges in the realm of electro-chemo-mechanical modeling. By doing so,
it aims to inspire computational research within this field and promote
synergistic collaborative efforts between computational and experimental
researchers.
</p>
</div>
</dd>
<dt><a name="item551">[551]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01955" title="Abstract">arXiv:2309.01955</a> [<a href="/pdf/2309.01955" title="Download PDF">pdf</a>, <a href="/format/2309.01955" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Survey on Interpretable Cross-modal Reasoning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xue%2C+D">Dizhan Xue</a>, 
<a href="/search/cs?searchtype=author&query=Qian%2C+S">Shengsheng Qian</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Z">Zuyi Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+C">Changsheng Xu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Multimedia (cs.MM)

</div>
<p class="mathjax">In recent years, cross-modal reasoning (CMR), the process of understanding
and reasoning across different modalities, has emerged as a pivotal area with
applications spanning from multimedia analysis to healthcare diagnostics. As
the deployment of AI systems becomes more ubiquitous, the demand for
transparency and comprehensibility in these systems' decision-making processes
has intensified. This survey delves into the realm of interpretable cross-modal
reasoning (I-CMR), where the objective is not only to achieve high predictive
performance but also to provide human-understandable explanations for the
results. This survey presents a comprehensive overview of the typical methods
with a three-level taxonomy for I-CMR. Furthermore, this survey reviews the
existing CMR datasets with annotations for explanations. Finally, this survey
summarizes the challenges for I-CMR and discusses potential future directions.
In conclusion, this survey aims to catalyze the progress of this emerging
research area by providing researchers with a panoramic and comprehensive
perspective, illuminating the state of the art and discerning the
opportunities.
</p>
</div>
</dd>
<dt><a name="item552">[552]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01957" title="Abstract">arXiv:2309.01957</a> [<a href="/pdf/2309.01957" title="Download PDF">pdf</a>, <a href="/format/2309.01957" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Automatic Data Transformation Using Large Language Model An Experimental  Study on Building Energy Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sharma%2C+A">Ankita Sharma</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xuanmao Li</a>, 
<a href="/search/cs?searchtype=author&query=Guan%2C+H">Hong Guan</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+G">Guoxin Sun</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+L">Liang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+L">Lanjun Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+K">Kesheng Wu</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+L">Lei Cao</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+E">Erkang Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Sim%2C+A">Alexander Sim</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+T">Teresa Wu</a>, 
<a href="/search/cs?searchtype=author&query=Zou%2C+J">Jia Zou</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 7 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Databases (cs.DB)</span>

</div>
<p class="mathjax">Existing approaches to automatic data transformation are insufficient to meet
the requirements in many real-world scenarios, such as the building sector.
First, there is no convenient interface for domain experts to provide domain
knowledge easily. Second, they require significant training data collection
overheads. Third, the accuracy suffers from complicated schema changes. To
bridge this gap, we present a novel approach that leverages the unique
capabilities of large language models (LLMs) in coding, complex reasoning, and
zero-shot learning to generate SQL code that transforms the source datasets
into the target datasets. We demonstrate the viability of this approach by
designing an LLM-based framework, termed SQLMorpher, which comprises a prompt
generator that integrates the initial prompt with optional domain knowledge and
historical patterns in external databases. It also implements an iterative
prompt optimization mechanism that automatically improves the prompt based on
flaw detection. The key contributions of this work include (1) pioneering an
end-to-end LLM-based solution for data transformation, (2) developing a
benchmark dataset of 105 real-world building energy data transformation
problems, and (3) conducting an extensive empirical evaluation where our
approach achieved 96% accuracy in all 105 problems. SQLMorpher demonstrates the
effectiveness of utilizing LLMs in complex, domain-specific challenges,
highlighting the potential of their potential to drive sustainable solutions.
</p>
</div>
</dd>
<dt><a name="item553">[553]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01958" title="Abstract">arXiv:2309.01958</a> [<a href="/pdf/2309.01958" title="Download PDF">pdf</a>, <a href="/format/2309.01958" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Empowering Low-Light Image Enhancer through Customized Learnable Priors
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zheng%2C+N">Naishan Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+M">Man Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+Y">Yanmeng Dong</a>, 
<a href="/search/cs?searchtype=author&query=Rui%2C+X">Xiangyu Rui</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+J">Jie Huang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+C">Chongyi Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+F">Feng Zhao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by ICCV 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Image and Video Processing (eess.IV)

</div>
<p class="mathjax">Deep neural networks have achieved remarkable progress in enhancing low-light
images by improving their brightness and eliminating noise. However, most
existing methods construct end-to-end mapping networks heuristically,
neglecting the intrinsic prior of image enhancement task and lacking
transparency and interpretability. Although some unfolding solutions have been
proposed to relieve these issues, they rely on proximal operator networks that
deliver ambiguous and implicit priors. In this work, we propose a paradigm for
low-light image enhancement that explores the potential of customized learnable
priors to improve the transparency of the deep unfolding paradigm. Motivated by
the powerful feature representation capability of Masked Autoencoder (MAE), we
customize MAE-based illumination and noise priors and redevelop them from two
perspectives: 1) \textbf{structure flow}: we train the MAE from a normal-light
image to its illumination properties and then embed it into the proximal
operator design of the unfolding architecture; and m2) \textbf{optimization
flow}: we train MAE from a normal-light image to its gradient representation
and then employ it as a regularization term to constrain noise in the model
output. These designs improve the interpretability and representation
capability of the model.Extensive experiments on multiple low-light image
enhancement datasets demonstrate the superiority of our proposed paradigm over
state-of-the-art methods. Code is available at
https://github.com/zheng980629/CUE.
</p>
</div>
</dd>
<dt><a name="item554">[554]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01961" title="Abstract">arXiv:2309.01961</a> [<a href="/pdf/2309.01961" title="Download PDF">pdf</a>, <a href="/format/2309.01961" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> NICE 2023 Zero-shot Image Captioning Challenge
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kim%2C+T">Taehoon Kim</a>, 
<a href="/search/cs?searchtype=author&query=Ahn%2C+P">Pyunghwan Ahn</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+S">Sangyun Kim</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+S">Sihaeng Lee</a>, 
<a href="/search/cs?searchtype=author&query=Marsden%2C+M">Mark Marsden</a>, 
<a href="/search/cs?searchtype=author&query=Sala%2C+A">Alessandra Sala</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+S+H">Seung Hwan Kim</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+H">Honglak Lee</a>, 
<a href="/search/cs?searchtype=author&query=Bae%2C+K">Kyounghoon Bae</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+B">Bohyung Han</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+K+M">Kyoung Mu Lee</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+X">Xiangyu Wu</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+Y">Yi Gao</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Hailiang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yang Yang</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+W">Weili Guo</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+J">Jianfeng Lu</a>, 
<a href="/search/cs?searchtype=author&query=Oh%2C+Y">Youngtaek Oh</a>, 
<a href="/search/cs?searchtype=author&query=Cho%2C+J+W">Jae Won Cho</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+D">Dong-jin Kim</a>, 
<a href="/search/cs?searchtype=author&query=Kweon%2C+I+S">In So Kweon</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+J">Junmo Kim</a>, 
<a href="/search/cs?searchtype=author&query=Kang%2C+W">Wooyoung Kang</a>, 
<a href="/search/cs?searchtype=author&query=Jhoo%2C+W+Y">Won Young Jhoo</a>, 
<a href="/search/cs?searchtype=author&query=Roh%2C+B">Byungseok Roh</a>, 
<a href="/search/cs?searchtype=author&query=Mun%2C+J">Jonghwan Mun</a>, 
<a href="/search/cs?searchtype=author&query=Oh%2C+S">Solgil Oh</a>, 
<a href="/search/cs?searchtype=author&query=Ak%2C+K+E">Kenan Emir Ak</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+G">Gwang-Gook Lee</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+Y">Yan Xu</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+M">Mingwei Shen</a>, 
<a href="/search/cs?searchtype=author&query=Hwang%2C+K">Kyomin Hwang</a>, 
<a href="/search/cs?searchtype=author&query=Shin%2C+W">Wonsik Shin</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+K">Kamin Lee</a>, 
<a href="/search/cs?searchtype=author&query=Park%2C+W">Wonhark Park</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+D">Dongkwan Lee</a>, 
<a href="/search/cs?searchtype=author&query=Kwak%2C+N">Nojun Kwak</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yujin Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yimu Wang</a>, 
<a href="/search/cs?searchtype=author&query=Gu%2C+T">Tiancheng Gu</a>, 
<a href="/search/cs?searchtype=author&query=Lv%2C+X">Xingchang Lv</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+M">Mingmao Sun</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Tech report
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">In this report, we introduce NICE
project\footnote{\url{https://nice.lgresearch.ai/}} and share the results and
outcomes of NICE challenge 2023. This project is designed to challenge the
computer vision community to develop robust image captioning models that
advance the state-of-the-art both in terms of accuracy and fairness. Through
the challenge, the image captioning models were tested using a new evaluation
dataset that includes a large variety of visual concepts from many domains.
There was no specific training data provided for the challenge, and therefore
the challenge entries were required to adapt to new types of image descriptions
that had not been seen during training. This report includes information on the
newly proposed NICE dataset, evaluation methods, challenge results, and
technical details of top-ranking entries. We expect that the outcomes of the
challenge will contribute to the improvement of AI models on various
vision-language tasks.
</p>
</div>
</dd>
<dt><a name="item555">[555]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01963" title="Abstract">arXiv:2309.01963</a> [<a href="/pdf/2309.01963" title="Download PDF">pdf</a>, <a href="/format/2309.01963" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Generalized Simple Regenerating Codes: Trading Sub-packetization and  Fault Tolerance
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jiang%2C+Z">Zhengyi Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+H">Hao Shi</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+Z">Zhongyi Huang</a>, 
<a href="/search/cs?searchtype=author&query=Bai%2C+B">Bo Bai</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+G">Gong Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Hou%2C+H">Hanxu Hou</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>

</div>
<p class="mathjax">Maximum distance separable (MDS) codes have the optimal trade-off between
storage efficiency and fault tolerance, which are widely used in distributed
storage systems. As typical non-MDS codes, simple regenerating codes (SRCs) can
achieve both smaller repair bandwidth and smaller repair locality than
traditional MDS codes in repairing single-node erasure.
<br />In this paper, we propose {\em generalized simple regenerating codes} (GSRCs)
that can support much more parameters than that of SRCs. We show that there is
a trade-off between sub-packetization and fault tolerance in our GSRCs, and
SRCs achieve a special point of the trade-off of GSRCs. We show that the fault
tolerance of our GSRCs increases when the sub-packetization increases linearly.
We also show that our GSRCs can locally repair any singe-symbol erasure and any
single-node erasure, and the repair bandwidth of our GSRCs is smaller than that
of the existing related codes.
</p>
</div>
</dd>
<dt><a name="item556">[556]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01964" title="Abstract">arXiv:2309.01964</a> [<a href="/pdf/2309.01964" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Gender Inequalities: Women Researchers Require More Knowledge in  Specific and Experimental Topics
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tang%2C+S">Shiqi Tang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+D">Dongyi Wang</a>, 
<a href="/search/cs?searchtype=author&query=Hou%2C+J">Jianhua Hou</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>

</div>
<p class="mathjax">Gender inequalities in science have long been observed globally. Studies have
demonstrated it through survey data or published literature, focusing on the
interests of subjects or authors; few, however, examined the manifestation of
gender inequalities on researchers' knowledge status. This study analyzes the
relationship between regional and gender identities, topics, and knowledge
status while revealing the female labor division in science and scientific
research using online Q&amp;A from researchers. We find that gender inequalities
are merged with both regional-specific characteristics and global common
patterns. Women's field and topic distribution within fields are influenced by
regions, yet the prevalent topics are consistent in all regions. Women are more
involved in specific topics, particularly topics about experiments with weaker
levels of knowledge and they are of less assistance. To promote inequality in
science, the scientific community should pay more attention to reducing the
knowledge gap and encourage women to work on unexplored topics and areas.
</p>
</div>
</dd>
<dt><a name="item557">[557]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01966" title="Abstract">arXiv:2309.01966</a> [<a href="/pdf/2309.01966" title="Download PDF">pdf</a>, <a href="/format/2309.01966" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AdaPlus: Integrating Nesterov Momentum and Precise Stepsize Adjustment  on AdamW Basis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Guan%2C+L">Lei Guan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">This paper proposes an efficient optimizer called AdaPlus which integrates
Nesterov momentum and precise stepsize adjustment on AdamW basis. AdaPlus
combines the advantages of AdamW, Nadam, and AdaBelief and, in particular, does
not introduce any extra hyper-parameters. We perform extensive experimental
evaluations on three machine learning tasks to validate the effectiveness of
AdaPlus. The experiment results validate that AdaPlus (i) is the best adaptive
method which performs most comparable with (even slightly better than) SGD with
momentum on image classification tasks and (ii) outperforms other
state-of-the-art optimizers on language modeling tasks and illustrates the
highest stability when training GANs. The experiment code of AdaPlus is
available at: https://github.com/guanleics/AdaPlus.
</p>
</div>
</dd>
<dt><a name="item558">[558]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01970" title="Abstract">arXiv:2309.01970</a> [<a href="/pdf/2309.01970" title="Download PDF">pdf</a>, <a href="/format/2309.01970" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Priority Queue Formulation of Agent-Based Bathtub Model for Network Trip  Flows in the Relative Space
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Martinez%2C+I">Irene Martinez</a>, 
<a href="/search/eess?searchtype=author&query=Jin%2C+W">Wen-long Jin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">Agent-based models have been extensively used to simulate the behavior of
travelers in transportation systems because they allow for realistic and
versatile modeling of interactions. However, traditional agent-based models
suffer from high computational costs and rely on tracking physical locations,
raising privacy concerns. This paper proposes an efficient formulation for the
agent-based bathtub model (AB2M) in the relative space, where each agent's
trajectory is represented by a time series of the remaining distance to its
destination. The AB2M can be understood as a microscopic model that tracks
individual trips' initiation, progression, and completion and is an exact
numerical solution of the bathtub model for generic (time-dependent) trip
distance distributions. The model can be solved for a deterministic set of
trips with a given demand pattern (defined by the start time of each trip and
its distance), or it can be used to run Monte Carlo simulations to capture the
average behavior and variation stochastic demand patterns, described by
probabilistic distributions of trip distances and departure times. To enhance
the computational efficiency, we introduce a priority queue formulation,
eliminating the need to update trip positions at each time step and allowing us
to run large-scale scenarios with millions of individual trips in seconds. We
systematically explore the scaling properties and discuss the introduction of
biases and numerical errors. The systematic exploration of scaling properties
of the modeling of individual agents in the relative space with the AB2M
further enhances its applicability to large-scale transportation systems and
opens up opportunities for studying travel time reliability, scheduling, and
mode choices.
</p>
</div>
</dd>
<dt><a name="item559">[559]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01971" title="Abstract">arXiv:2309.01971</a> [<a href="/pdf/2309.01971" title="Download PDF">pdf</a>, <a href="/format/2309.01971" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> VFFINDER: A Graph-based Approach for Automated Silent Vulnerability-Fix  Identification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+S">Son Nguyen</a>, 
<a href="/search/cs?searchtype=author&query=Vu%2C+T+T">Thanh Trong Vu</a>, 
<a href="/search/cs?searchtype=author&query=Vo%2C+H+D">Hieu Dinh Vo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by IEEE KSE 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
<p class="mathjax">The increasing reliance of software projects on third-party libraries has
raised concerns about the security of these libraries due to hidden
vulnerabilities. Managing these vulnerabilities is challenging due to the time
gap between fixes and public disclosures. Moreover, a significant portion of
open-source projects silently fix vulnerabilities without disclosure, impacting
vulnerability management. Existing tools like OWASP heavily rely on public
disclosures, hindering their effectiveness in detecting unknown
vulnerabilities. To tackle this problem, automated identification of
vulnerability-fixing commits has emerged. However, identifying silent
vulnerability fixes remains challenging. This paper presents VFFINDER, a novel
graph-based approach for automated silent vulnerability fix identification.
VFFINDER captures structural changes using Abstract Syntax Trees (ASTs) and
represents them in annotated ASTs. VFFINDER distinguishes vulnerability-fixing
commits from non-fixing ones using attention-based graph neural network models
to extract structural features. We conducted experiments to evaluate VFFINDER
on a dataset of 36K+ fixing and non-fixing commits in 507 real-world C/C++
projects. Our results show that VFFINDER significantly improves the
state-of-the-art methods by 39-83% in Precision, 19-148% in Recall, and 30-109%
in F1. Especially, VFFINDER speeds up the silent fix identification process by
up to 47% with the same review effort of 5% compared to the existing
approaches.
</p>
</div>
</dd>
<dt><a name="item560">[560]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01973" title="Abstract">arXiv:2309.01973</a> [<a href="/pdf/2309.01973" title="Download PDF">pdf</a>, <a href="/format/2309.01973" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Linear Regression using Heterogeneous Data Batches
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jain%2C+A">Ayush Jain</a>, 
<a href="/search/cs?searchtype=author&query=Sen%2C+R">Rajat Sen</a>, 
<a href="/search/cs?searchtype=author&query=Kong%2C+W">Weihao Kong</a>, 
<a href="/search/cs?searchtype=author&query=Das%2C+A">Abhimanyu Das</a>, 
<a href="/search/cs?searchtype=author&query=Orlitsky%2C+A">Alon Orlitsky</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Information Theory (cs.IT); Machine Learning (stat.ML)

</div>
<p class="mathjax">In many learning applications, data are collected from multiple sources, each
providing a \emph{batch} of samples that by itself is insufficient to learn its
input-output relationship. A common approach assumes that the sources fall in
one of several unknown subgroups, each with an unknown input distribution and
input-output relationship. We consider one of this setup's most fundamental and
important manifestations where the output is a noisy linear combination of the
inputs, and there are $k$ subgroups, each with its own regression vector. Prior
work~\cite{kong2020meta} showed that with abundant small-batches, the
regression vectors can be learned with only few, $\tilde\Omega( k^{3/2})$,
batches of medium-size with $\tilde\Omega(\sqrt k)$ samples each. However, the
paper requires that the input distribution for all $k$ subgroups be isotropic
Gaussian, and states that removing this assumption is an ``interesting and
challenging problem". We propose a novel gradient-based algorithm that improves
on the existing results in several ways. It extends the applicability of the
algorithm by: (1) allowing the subgroups' underlying input distributions to be
different, unknown, and heavy-tailed; (2) recovering all subgroups followed by
a significant proportion of batches even for infinite $k$; (3) removing the
separation requirement between the regression vectors; (4) reducing the number
of batches and allowing smaller batch sizes.
</p>
</div>
</dd>
<dt><a name="item561">[561]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01978" title="Abstract">arXiv:2309.01978</a> [<a href="/pdf/2309.01978" title="Download PDF">pdf</a>, <a href="/format/2309.01978" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An LSTM-Based Predictive Monitoring Method for Data with Time-varying  Variability
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Qiu%2C+J">Jiaqi Qiu</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+Y">Yu Lin</a>, 
<a href="/search/cs?searchtype=author&query=Zwetsloot%2C+I">Inez Zwetsloot</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 19 pages, 9 figures, 6 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Methodology (stat.ME)

</div>
<p class="mathjax">The recurrent neural network and its variants have shown great success in
processing sequences in recent years. However, this deep neural network has not
aroused much attention in anomaly detection through predictively process
monitoring. Furthermore, the traditional statistic models work on assumptions
and hypothesis tests, while neural network (NN) models do not need that many
assumptions. This flexibility enables NN models to work efficiently on data
with time-varying variability, a common inherent aspect of data in practice.
This paper explores the ability of the recurrent neural network structure to
monitor processes and proposes a control chart based on long short-term memory
(LSTM) prediction intervals for data with time-varying variability. The
simulation studies provide empirical evidence that the proposed model
outperforms other NN-based predictive monitoring methods for mean shift
detection. The proposed method is also applied to time series sensor data,
which confirms that the proposed method is an effective technique for detecting
abnormalities.
</p>
</div>
</dd>
<dt><a name="item562">[562]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01981" title="Abstract">arXiv:2309.01981</a> [<a href="/pdf/2309.01981" title="Download PDF">pdf</a>, <a href="/format/2309.01981" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Graph-Based Interaction-Aware Multimodal 2D Vehicle Trajectory  Prediction using Diffusion Graph Convolutional Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+K">Keshu Wu</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Y">Yang Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+H">Haotian Shi</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xiaopeng Li</a>, 
<a href="/search/cs?searchtype=author&query=Ran%2C+B">Bin Ran</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI); Graphics (cs.GR)

</div>
<p class="mathjax">Predicting vehicle trajectories is crucial for ensuring automated vehicle
operation efficiency and safety, particularly on congested multi-lane highways.
In such dynamic environments, a vehicle's motion is determined by its
historical behaviors as well as interactions with surrounding vehicles. These
intricate interactions arise from unpredictable motion patterns, leading to a
wide range of driving behaviors that warrant in-depth investigation. This study
presents the Graph-based Interaction-aware Multi-modal Trajectory Prediction
(GIMTP) framework, designed to probabilistically predict future vehicle
trajectories by effectively capturing these interactions. Within this
framework, vehicles' motions are conceptualized as nodes in a time-varying
graph, and the traffic interactions are represented by a dynamic adjacency
matrix. To holistically capture both spatial and temporal dependencies embedded
in this dynamic adjacency matrix, the methodology incorporates the Diffusion
Graph Convolutional Network (DGCN), thereby providing a graph embedding of both
historical states and future states. Furthermore, we employ a driving
intention-specific feature fusion, enabling the adaptive integration of
historical and future embeddings for enhanced intention recognition and
trajectory prediction. This model gives two-dimensional predictions for each
mode of longitudinal and lateral driving behaviors and offers probabilistic
future paths with corresponding probabilities, addressing the challenges of
complex vehicle interactions and multi-modality of driving behaviors.
Validation using real-world trajectory datasets demonstrates the efficiency and
potential.
</p>
</div>
</dd>
<dt><a name="item563">[563]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01983" title="Abstract">arXiv:2309.01983</a> [<a href="/pdf/2309.01983" title="Download PDF">pdf</a>, <a href="/ps/2309.01983" title="Download PostScript">ps</a>, <a href="/format/2309.01983" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Quaternary Conjucyclic Codes with an Application to EAQEC Codes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hossain%2C+M+A">Md Ajaharul Hossain</a>, 
<a href="/search/cs?searchtype=author&query=Bandi%2C+R">Ramakrishna Bandi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Rings and Algebras (math.RA)

</div>
<p class="mathjax">Conjucyclic codes are part of a family of codes that includes cyclic,
constacyclic, and quasi-cyclic codes, among others. Despite their importance in
quantum error correction, they have not received much attention in the
literature. This paper focuses on additive conjucyclic (ACC) codes over
$\mathbb{F}_4$ and investigates their properties. Specifically, we derive the
duals of ACC codes using a trace inner product and obtain the trace hull and
its dimension. Also, establish a necessary and sufficient condition for an
additive code to have a complementary dual (ACD). Additionally, we identify a
necessary condition for an additive conjucyclic complementary pair of codes
over $\mathbb{F}_4$. Furthermore, we show that the trace code of an ACC code is
cyclic and provide a condition for the trace code of an ACC code to be LCD. To
demonstrate the practical application of our findings, we construct some good
entanglement-assisted quantum error-correcting (EAQEC) codes using the trace
code of ACC codes.
</p>
</div>
</dd>
<dt><a name="item564">[564]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01985" title="Abstract">arXiv:2309.01985</a> [<a href="/pdf/2309.01985" title="Download PDF">pdf</a>, <a href="/ps/2309.01985" title="Download PostScript">ps</a>, <a href="/format/2309.01985" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The $\ell$-intersection Pairs of Constacyclic and Conjucyclic Codes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hossain%2C+M+A">Md Ajaharul Hossain</a>, 
<a href="/search/cs?searchtype=author&query=Bandi%2C+R">Ramakrishna Bandi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Rings and Algebras (math.RA)

</div>
<p class="mathjax">A pair of linear codes whose intersection is of dimension $\ell$, where
$\ell$ is a non-negetive integer, is called an $\ell$-intersection pair of
codes. This paper focuses on studying $\ell$-intersection pairs of
$\lambda_i$-constacyclic, $i=1,2,$ and conjucyclic codes. We first characterize
an $\ell$-intersection pair of $\lambda_i$-constacyclic codes. A formula for
$\ell$ has been established in terms of the degrees of the generator
polynomials of $\lambda_i$-constacyclic codes. This allows obtaining a
condition for $\ell$-linear complementary pairs (LPC) of constacyclic codes.
Later, we introduce and characterize the $\ell$-intersection pair of
conjucyclic codes over $\mathbb{F}_{q^2}$. The first observation in the process
is that there are no non-trivial linear conjucyclic codes over finite fields.
So focus on the characterization of additive conjucyclic (ACC) codes. We show
that the largest $\mathbb{F}_q$-subcode of an ACC code over $\mathbb{F}_{q^2}$
is cyclic and obtain its generating polynomial. This enables us to find the
size of an ACC code. Furthermore, we discuss the trace code of an ACC code and
show that it is cyclic. Finally, we determine $\ell$-intersection pairs of
trace codes of ACC codes over $\mathbb{F}_4$.
</p>
</div>
</dd>
<dt><a name="item565">[565]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01987" title="Abstract">arXiv:2309.01987</a> [<a href="/pdf/2309.01987" title="Download PDF">pdf</a>, <a href="/format/2309.01987" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Load Shifting Versus Manual Frequency Reserve: Which One is More  Appealing to Flexible Loads?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Gade%2C+P+A+V">Peter A. V. Gade</a>, 
<a href="/search/eess?searchtype=author&query=Skj%C3%B8tskift%2C+T">Trygve Skj&#xf8;tskift</a>, 
<a href="/search/eess?searchtype=author&query=Ziras%2C+C">Charalampos Ziras</a>, 
<a href="/search/eess?searchtype=author&query=Bindner%2C+H+W">Henrik W. Bindner</a>, 
<a href="/search/eess?searchtype=author&query=Kazempour%2C+J">Jalal Kazempour</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">This paper investigates how a thermostatically controlled load can deliver
flexibility either in form of manual frequency restoration reserves (mFRR) or
load shifting, and which one is financially more appealing to such a load. A
supermarket freezer is considered as a representative flexible load, and a
grey-box model describing its temperature dynamics is developed using real data
from a supermarket in Denmark. Taking into account price and activation
uncertainties, a two-stage stochastic mixed-integer linear program is
formulated to maximize the flexibility value from the freezer. For practical
reasons, we propose a linear policy to determine regulating power bids, and
then linearize the mFRR activation conditions through the McCormick relaxation
approach. For computational ease, we develop a decomposition technique,
splitting the problem to a set of smaller subproblems, one per scenario.
Examined on an out-of-sample simulation based on real Danish spot and balancing
market prices in 2022, load shifting shows to be more profitable than mFRR
provision, but is also more consequential for temperature deviations in the
freezer.
</p>
</div>
</dd>
<dt><a name="item566">[566]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01988" title="Abstract">arXiv:2309.01988</a> [<a href="/pdf/2309.01988" title="Download PDF">pdf</a>, <a href="/format/2309.01988" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> sasdim: self-adaptive noise scaling diffusion model for spatial time  series imputation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+S">Shunyang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Senzhang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Tan%2C+X">Xianzhen Tan</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+R">Ruochen Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jian Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jianxin Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Spatial time series imputation is critically important to many real
applications such as intelligent transportation and air quality monitoring.
Although recent transformer and diffusion model based approaches have achieved
significant performance gains compared with conventional statistic based
methods, spatial time series imputation still remains as a challenging issue
due to the complex spatio-temporal dependencies and the noise uncertainty of
the spatial time series data. Especially, recent diffusion process based models
may introduce random noise to the imputations, and thus cause negative impact
on the model performance. To this end, we propose a self-adaptive noise scaling
diffusion model named SaSDim to more effectively perform spatial time series
imputation. Specially, we propose a new loss function that can scale the noise
to the similar intensity, and propose the across spatial-temporal global
convolution module to more effectively capture the dynamic spatial-temporal
dependencies. Extensive experiments conducted on three real world datasets
verify the effectiveness of SaSDim by comparison with current state-of-the-art
baselines.
</p>
</div>
</dd>
<dt><a name="item567">[567]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01990" title="Abstract">arXiv:2309.01990</a> [<a href="/pdf/2309.01990" title="Download PDF">pdf</a>, <a href="/format/2309.01990" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Dynamic distance-based pricing scheme for high-occupancy-toll lanes  along a freeway corridor
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Mart%C3%ADnez%2C+I">Irene Mart&#xed;nez</a>, 
<a href="/search/eess?searchtype=author&query=Jin%2C+W">Wen-Long Jin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">Single-occupancy vehicles (SOVs) are charged to use the highoccupancy-toll
(HOT) lanes, while high-occupancy-vehicles (HOVs) can drive in them at no cost.
The pricing scheme for HOT lanes has been extensively studied at local
bottlenecks or at the network level through computationally expensive
simulations. However, the HOT lane pricing study on a freeway corridor with
multiple origins and destinations as well as multiple interacting bottlenecks
is a challenging problem for which no analytical results are available. In this
paper, we attempt to fill the gap by proposing to study the traffic dynamics in
the corridor based on the relative space paradigm. In this new paradigm, the
interaction of multiple bottlenecks and trips can be captured with Vickrey's
bathtub model by a simple ordinary differential equation. We consider three
types of lane choice behavior and analyze their properties. Then, we propose a
distance-based dynamic pricing scheme based on a linear combination of
I-controllers. This closed-loop controller is independent of the model and
feeds back the travel time difference between HOT lanes and general-purpose
lanes. Given the mathematical tractability of the system model, we analytically
study the performance of the proposed closed-loop control under constant demand
and show the existence and stability of the optimal equilibrium. Finally, we
verify the results with numerical simulations considering a typical peak period
demand pattern. In the future, we are interested in extending this work and
testing the performance of the proposed linear combination of I-controllers for
other traffic flow models.
</p>
</div>
</dd>
<dt><a name="item568">[568]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01994" title="Abstract">arXiv:2309.01994</a> [<a href="/pdf/2309.01994" title="Download PDF">pdf</a>, <a href="/format/2309.01994" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Cloud Control of Connected Vehicle under Bi-directional Time-varying  delay: An Application of Predictor-observer Structured Controller
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Pan%2C+J">Ji-An Pan</a>, 
<a href="/search/eess?searchtype=author&query=Xu%2C+Q">Qing Xu</a>, 
<a href="/search/eess?searchtype=author&query=Li%2C+K">Keqiang Li</a>, 
<a href="/search/eess?searchtype=author&query=Yang%2C+C">Chunying Yang</a>, 
<a href="/search/eess?searchtype=author&query=Wang%2C+J">Jianqiang Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">This article is devoted to addressing the cloud control of connected
vehicles, specifically focusing on analyzing the effect of bi-directional
communication-induced delays. To mitigate the adverse effects of such delays, a
novel predictor-observer structured controller is proposed which compensate for
both measurable output delays and unmeasurable, yet bounded, input delays
simultaneously. The study begins by novelly constructing an equivalent
delay-free inter-connected system model that incorporates the
Predictor-Observer controller, considering certain delay boundaries and model
uncertainties. Subsequently, a stability analysis is conducted to assess the
system's robustness under these conditions. Next, the connected vehicle lateral
control scenario is built which contain high-fidelity vehicle dynamic model.
The results demonstrate the controller's ability to accurately predict the
system states, even under time-varying bi-directional delays. Finally, the
proposed method is deployed in a real connected vehicle lateral control system.
Comparative tests with a conventional linear feedback controller showcase
significantly improved control performance under dominant bi-directional delay
conditions, affirming the superiority of the proposed method against the delay.
</p>
</div>
</dd>
<dt><a name="item569">[569]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01997" title="Abstract">arXiv:2309.01997</a> [<a href="/pdf/2309.01997" title="Download PDF">pdf</a>, <a href="/format/2309.01997" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Topologies for Error-Detecting Variable-Length Codes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=N%C3%A9raud%2C+J">Jean N&#xe9;raud</a> (LITIS, UNIROUEN)
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: text overlap with <a href="/abs/2208.14681">arXiv:2208.14681</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Discrete Mathematics (cs.DM)</span>

</div>
<p class="mathjax">Given a finite alphabet $A$, a quasi-metric $d$ over $A^*$, and a
non-negative integer $k$, we introduce the relation $\tau_{d,k}\subseteq
A^*\times A^*$ such that $(x,y)\in\tau_{d,k}$ holds whenever $d(x,y)\le k$. The
error detection capability of variable-length codes is expressed in term of
conditions over $\tau_{d,k}$. With respect to the prefix metric, the factor
one, and any quasi-metric associated with some free monoid (anti-)automorphism,
we prove that one can decide whether a given regular variable-length code
satisfies any of those error detection constraints.
</p>
</div>
</dd>
<dt><a name="item570">[570]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.02000" title="Abstract">arXiv:2309.02000</a> [<a href="/pdf/2309.02000" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the peer review reports: It&#x27;s not the size that matters ... really?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Maddi%2C+A">Abdelghani Maddi</a> (GEMASS), 
<a href="/search/cs?searchtype=author&query=Miotti%2C+E+L">Egidio Luis Miotti</a> (CEPN)
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 19th International Conference of the International Society for Scientometrics and Informetrics, Jul 2023, Bloomington (Indiana), United States
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Digital Libraries (cs.DL)</span>

</div>
<p class="mathjax">Scientometers and sociologists of science have spilled much ink on the topic
of peer review over the past twenty years, given its primordial role in a
context marked by the exponential growth of scientific production and the
proliferation of predatory journals. Although the topic is addressed under
different prisms, few studies have empirically analyzed to what extent it can
affect the quality of publications. Here we study the link between the length
of reviewers' reports and the citations received by publications. To do this,
we used data from the Publons database (58,093 peer review reports). We have
adjusted this sample to match the WoS database structure. Our regression
results show that peer review positively affects the quality of publications.
In other words, the more indepth (longer) the referees' reports are, the
greater the publication improvements will be, resulting in an increase in
citations received. This result is important from both the point of view of
reviewers and that of journal's chiefseditors. Even if it is not a remunerated
activity, it is important that it be more valued at least within the framework
of research evaluation exercises, given its positive impact on science.
</p>
</div>
</dd>
<dt><a name="item571">[571]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.02001" title="Abstract">arXiv:2309.02001</a> [<a href="/pdf/2309.02001" title="Download PDF">pdf</a>, <a href="/format/2309.02001" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Analyzing domain shift when using additional data for the MICCAI KiTS23  Challenge
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Stoica%2C+G">George Stoica</a>, 
<a href="/search/cs?searchtype=author&query=Breaban%2C+M">Mihaela Breaban</a>, 
<a href="/search/cs?searchtype=author&query=Barbu%2C+V">Vlad Barbu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This preprint has not undergone peer review or any post-submission improvements or corrections. The Version of Record of this contribution is published in [TODO], and is available online at <a href="https://doi.org/">this https URL</a>[TODO]
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Using additional training data is known to improve the results, especially
for medical image 3D segmentation where there is a lack of training material
and the model needs to generalize well from few available data. However, the
new data could have been acquired using other instruments and preprocessed such
its distribution is significantly different from the original training data.
Therefore, we study techniques which ameliorate domain shift during training so
that the additional data becomes better usable for preprocessing and training
together with the original data. Our results show that transforming the
additional data using histogram matching has better results than using simple
normalization.
</p>
</div>
</dd>
<dt><a name="item572">[572]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.02004" title="Abstract">arXiv:2309.02004</a> [<a href="/pdf/2309.02004" title="Download PDF">pdf</a>, <a href="/format/2309.02004" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Efficient Reduced Magnetic Vector Potential Formulation for the Magnetic  Field Simulation of Superconducting Magnets
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=D%27Angelo%2C+L+A+M">Laura A. M. D&#x27;Angelo</a>, 
<a href="/search/cs?searchtype=author&query=Moll%2C+D">Dominik Moll</a>, 
<a href="/search/cs?searchtype=author&query=De+Gersem%2C+H">Herbert De Gersem</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages, 8 figures, to be published in IEEE Transactions on Magnetics
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Engineering, Finance, and Science (cs.CE)</span>

</div>
<p class="mathjax">The major advantage of reduced magnetic vector potential formulations (RMVPs)
is that complicated coil structures do not need to be resolved by a
computational mesh. Instead, they are modeled by thin wires, whose source field
is included into the simulation model along Biot-Savart's law. Such an approach
has already been successfully employed in ROXIE for the simulation of
superconducting Large Hadron Collider magnets at CERN. This work presents an
updated RMVP approach, which significantly outperforms the original method. The
updated formulation is postulated, implemented, verified, compared to the
original formulation, and applied for the simulation of a quadrupole magnet.
The promising results of this work encourage further investigation towards an
updated simulation framework for next-generation accelerator magnets.
</p>
</div>
</dd>
<dt><a name="item573">[573]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.02005" title="Abstract">arXiv:2309.02005</a> [<a href="/pdf/2309.02005" title="Download PDF">pdf</a>, <a href="/format/2309.02005" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Aggregating Correlated Estimations with (Almost) no Training
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Delemazure%2C+T">Theo Delemazure</a> (LAMSADE), 
<a href="/search/cs?searchtype=author&query=Durand%2C+F">Fran&#xe7;ois Durand</a> (CREM, LINCS), 
<a href="/search/cs?searchtype=author&query=Mathieu%2C+F">Fabien Mathieu</a> (LINCS)
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> 26th European Conference on Artificial Intelligence (ECAI 2023),
  Sep 2023, Krak{\'o}w, Poland
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Multiagent Systems (cs.MA); Optimization and Control (math.OC)

</div>
<p class="mathjax">Many decision problems cannot be solved exactly and use several estimation
algorithms that assign scores to the different available options. The
estimation errors can have various correlations, from low (e.g. between two
very different approaches) to high (e.g. when using a given algorithm with
different hyperparameters). Most aggregation rules would suffer from this
diversity of correlations. In this article, we propose different aggregation
rules that take correlations into account, and we compare them to naive rules
in various experiments based on synthetic data. Our results show that when
sufficient information is known about the correlations between errors, a
maximum likelihood aggregation should be preferred. Otherwise, typically with
limited training data, we recommend a method that we call Embedded Voting (EV).
</p>
</div>
</dd>
<dt><a name="item574">[574]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.02009" title="Abstract">arXiv:2309.02009</a> [<a href="/pdf/2309.02009" title="Download PDF">pdf</a>, <a href="/ps/2309.02009" title="Download PostScript">ps</a>, <a href="/format/2309.02009" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Belief revision and incongruity: is it a joke?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=de+Saint+Cyr+-+Bannay%2C+F+D">Florence Dupin de Saint Cyr - Bannay</a> (IRIT-ADRIA), 
<a href="/search/cs?searchtype=author&query=Prade%2C+H">Henri Prade</a> (IRIT-ADRIA)
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> A special paper on/in humor/honor for/of Philippe Besnard
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Journal of Applied Non-Classical Logics, In press, Special issue
  in honour of Philippe Besnard, pp.1-28
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
<p class="mathjax">Incongruity often makes people laugh. You have to be smart to say stupid
things. It requires to be even smarter for understanding them. This paper is a
shameless attempt to formalize this intelligent behavior in the case of an
agent listening to a joke. All this is a matter of revision of beliefs,
surprise and violation of norms.
</p>
</div>
</dd>
<dt><a name="item575">[575]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.02010" title="Abstract">arXiv:2309.02010</a> [<a href="/pdf/2309.02010" title="Download PDF">pdf</a>, <a href="/format/2309.02010" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Establishing a real-time traffic alarm in the city of Valencia with Deep  Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Folgado%2C+M">Miguel Folgado</a>, 
<a href="/search/cs?searchtype=author&query=Sanz%2C+V">Veronica Sanz</a>, 
<a href="/search/cs?searchtype=author&query=Hirn%2C+J">Johannes Hirn</a>, 
<a href="/search/cs?searchtype=author&query=Lorenzo-Saez%2C+E">Edgar Lorenzo-Saez</a>, 
<a href="/search/cs?searchtype=author&query=Urchueguia%2C+J">Javier Urchueguia</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 13 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Urban traffic emissions represent a significant concern due to their
detrimental impacts on both public health and the environment. Consequently,
decision-makers have flagged their reduction as a crucial goal. In this study,
we first analyze the correlation between traffic flux and pollution in the city
of Valencia, Spain. Our results demonstrate that traffic has a significant
impact on the levels of certain pollutants (especially $\text{NO}_\text{x}$).
Secondly, we develop an alarm system to predict if a street is likely to
experience unusually high traffic in the next 30 minutes, using an independent
three-tier level for each street. To make the predictions, we use traffic data
updated every 10 minutes and Long Short-Term Memory (LSTM) neural networks. We
trained the LSTM using traffic data from 2018, and tested it using traffic data
from 2019.
</p>
</div>
</dd>
<dt><a name="item576">[576]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.02011" title="Abstract">arXiv:2309.02011</a> [<a href="/pdf/2309.02011" title="Download PDF">pdf</a>, <a href="/format/2309.02011" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Representation Learning Dynamics of Self-Supervised Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Esser%2C+P">Pascal Esser</a>, 
<a href="/search/cs?searchtype=author&query=Mukherjee%2C+S">Satyaki Mukherjee</a>, 
<a href="/search/cs?searchtype=author&query=Ghoshdastidar%2C+D">Debarghya Ghoshdastidar</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Self-Supervised Learning (SSL) is an important paradigm for learning
representations from unlabelled data, and SSL with neural networks has been
highly successful in practice. However current theoretical analysis of SSL is
mostly restricted to generalisation error bounds. In contrast, learning
dynamics often provide a precise characterisation of the behaviour of neural
networks based models but, so far, are mainly known in supervised settings. In
this paper, we study the learning dynamics of SSL models, specifically
representations obtained by minimising contrastive and non-contrastive losses.
We show that a naive extension of the dymanics of multivariate regression to
SSL leads to learning trivial scalar representations that demonstrates
dimension collapse in SSL. Consequently, we formulate SSL objectives with
orthogonality constraints on the weights, and derive the exact (network width
independent) learning dynamics of the SSL models trained using gradient descent
on the Grassmannian manifold. We also argue that the infinite width
approximation of SSL models significantly deviate from the neural tangent
kernel approximations of supervised models. We numerically illustrate the
validity of our theoretical findings, and discuss how the presented results
provide a framework for further theoretical analysis of contrastive and
non-contrastive SSL.
</p>
</div>
</dd>
<dt><a name="item577">[577]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.02012" title="Abstract">arXiv:2309.02012</a> [<a href="/pdf/2309.02012" title="Download PDF">pdf</a>, <a href="/format/2309.02012" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> iLoRE: Dynamic Graph Representation with Instant Long-term Modeling and  Re-occurrence Preservation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+S">Siwei Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Xiong%2C+Y">Yun Xiong</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yao Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+X">Xixi Wu</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+Y">Yiheng Sun</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jiawei Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Social and Information Networks (cs.SI)

</div>
<p class="mathjax">Continuous-time dynamic graph modeling is a crucial task for many real-world
applications, such as financial risk management and fraud detection. Though
existing dynamic graph modeling methods have achieved satisfactory results,
they still suffer from three key limitations, hindering their scalability and
further applicability. i) Indiscriminate updating. For incoming edges, existing
methods would indiscriminately deal with them, which may lead to more time
consumption and unexpected noisy information. ii) Ineffective node-wise
long-term modeling. They heavily rely on recurrent neural networks (RNNs) as a
backbone, which has been demonstrated to be incapable of fully capturing
node-wise long-term dependencies in event sequences. iii) Neglect of
re-occurrence patterns. Dynamic graphs involve the repeated occurrence of
neighbors that indicates their importance, which is disappointedly neglected by
existing methods. In this paper, we present iLoRE, a novel dynamic graph
modeling method with instant node-wise Long-term modeling and Re-occurrence
preservation. To overcome the indiscriminate updating issue, we introduce the
Adaptive Short-term Updater module that will automatically discard the useless
or noisy edges, ensuring iLoRE's effectiveness and instant ability. We further
propose the Long-term Updater to realize more effective node-wise long-term
modeling, where we innovatively propose the Identity Attention mechanism to
empower a Transformer-based updater, bypassing the limited effectiveness of
typical RNN-dominated designs. Finally, the crucial re-occurrence patterns are
also encoded into a graph module for informative representation learning, which
will further improve the expressiveness of our method. Our experimental results
on real-world datasets demonstrate the effectiveness of our iLoRE for dynamic
graph modeling.
</p>
</div>
</dd>
<dt><a name="item578">[578]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.02017" title="Abstract">arXiv:2309.02017</a> [<a href="/pdf/2309.02017" title="Download PDF">pdf</a>, <a href="/ps/2309.02017" title="Download PostScript">ps</a>, <a href="/format/2309.02017" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Index and Core of a Relation. With Applications to the Axiomatics of  Relation Algebra
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Backhouse%2C+R">Roland Backhouse</a> (University of Nottingham, UK), 
<a href="/search/cs?searchtype=author&query=Voermans%2C+E">Ed Voermans</a> (Independent Researcher)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>

</div>
<p class="mathjax">We introduce the general notions of an index and a core of a relation. We
postulate a limited form of the axiom of choice -- specifically that all
partial equivalence relations have an index -- and explore the consequences of
adding the axiom to standard axiom systems for point-free reasoning. Examples
of the theorems we prove are that a core/index of a difunction is a bijection,
and that the so-called ``all or nothing'' axiom used to facilitate pointwise
reasoning is derivable from our axiom of choice.
</p>
</div>
</dd>
<dt><a name="item579">[579]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.02019" title="Abstract">arXiv:2309.02019</a> [<a href="/pdf/2309.02019" title="Download PDF">pdf</a>, <a href="/format/2309.02019" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Parsing Fortran-77 with proprietary extensions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sow%2C+Y">Younoussa Sow</a>, 
<a href="/search/cs?searchtype=author&query=Safina%2C+L">Larisa Safina</a>, 
<a href="/search/cs?searchtype=author&query=Brault%2C+L">L&#xe9;andre Brault</a>, 
<a href="/search/cs?searchtype=author&query=Diouf%2C+P+I">Papa Ibou Diouf</a>, 
<a href="/search/cs?searchtype=author&query=Ducasse%2C+S">St&#xe9;phane Ducasse</a>, 
<a href="/search/cs?searchtype=author&query=Anquetil%2C+N">Nicolas Anquetil</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at ICSME'23 Industrial track
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
<p class="mathjax">Far from the latest innovations in software development, many organizations
still rely on old code written in "obsolete" programming languages. Because
this source code is old and proven it often contributes significantly to the
continuing success of these organizations. Yet to keep the applications
relevant and running in an evolving environment, they sometimes need to be
updated or migrated to new languages or new platforms. One difficulty of
working with these "veteran languages" is being able to parse the source code
to build a representation of it. Parsing can also allow modern software
development tools and IDEs to offer better support to these veteran languages.
We initiated a project between our group and the Framatome company to help
migrate old Fortran-77 with proprietary extensions (called Esope) into more
modern Fortran. In this paper, we explain how we parsed the Esope language with
a combination of island grammar and regular parser to build an abstract syntax
tree of the code.
</p>
</div>
</dd>
<dt><a name="item580">[580]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.02022" title="Abstract">arXiv:2309.02022</a> [<a href="/pdf/2309.02022" title="Download PDF">pdf</a>, <a href="/format/2309.02022" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Dynamic Early Exiting Predictive Coding Neural Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zniber%2C+A">Alaa Zniber</a>, 
<a href="/search/cs?searchtype=author&query=Karrakchou%2C+O">Ouassim Karrakchou</a>, 
<a href="/search/cs?searchtype=author&query=Ghogho%2C+M">Mounir Ghogho</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Internet of Things (IoT) sensors are nowadays heavily utilized in various
real-world applications ranging from wearables to smart buildings passing by
agrotechnology and health monitoring. With the huge amounts of data generated
by these tiny devices, Deep Learning (DL) models have been extensively used to
enhance them with intelligent processing. However, with the urge for smaller
and more accurate devices, DL models became too heavy to deploy. It is thus
necessary to incorporate the hardware's limited resources in the design
process. Therefore, inspired by the human brain known for its efficiency and
low power consumption, we propose a shallow bidirectional network based on
predictive coding theory and dynamic early exiting for halting further
computations when a performance threshold is surpassed. We achieve comparable
accuracy to VGG-16 in image classification on CIFAR-10 with fewer parameters
and less computational complexity.
</p>
</div>
</dd>
<dt><a name="item581">[581]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.02024" title="Abstract">arXiv:2309.02024</a> [<a href="/pdf/2309.02024" title="Download PDF">pdf</a>, <a href="/ps/2309.02024" title="Download PostScript">ps</a>, <a href="/format/2309.02024" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Unification Algorithm for Second-Order Linear Terms
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dowek%2C+G">Gilles Dowek</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>

</div>
<p class="mathjax">We give an algorithm for the class of second order unification problems in
which second order variables have at most one occurrence.
</p>
</div>
</dd>
<dt><a name="item582">[582]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.02025" title="Abstract">arXiv:2309.02025</a> [<a href="/pdf/2309.02025" title="Download PDF">pdf</a>, <a href="/format/2309.02025" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> RDGSL: Dynamic Graph Representation Learning with Structure Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+S">Siwei Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Xiong%2C+Y">Yun Xiong</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yao Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+Y">Yiheng Sun</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+X">Xi Chen</a>, 
<a href="/search/cs?searchtype=author&query=Jiao%2C+Y">Yizhu Jiao</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+Y">Yangyong Zhu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Temporal Graph Networks (TGNs) have shown remarkable performance in learning
representation for continuous-time dynamic graphs. However, real-world dynamic
graphs typically contain diverse and intricate noise. Noise can significantly
degrade the quality of representation generation, impeding the effectiveness of
TGNs in downstream tasks. Though structure learning is widely applied to
mitigate noise in static graphs, its adaptation to dynamic graph settings poses
two significant challenges. i) Noise dynamics. Existing structure learning
methods are ill-equipped to address the temporal aspect of noise, hampering
their effectiveness in such dynamic and ever-changing noise patterns. ii) More
severe noise. Noise may be introduced along with multiple interactions between
two nodes, leading to the re-pollution of these nodes and consequently causing
more severe noise compared to static graphs. In this paper, we present RDGSL, a
representation learning method in continuous-time dynamic graphs. Meanwhile, we
propose dynamic graph structure learning, a novel supervisory signal that
empowers RDGSL with the ability to effectively combat noise in dynamic graphs.
To address the noise dynamics issue, we introduce the Dynamic Graph Filter,
where we innovatively propose a dynamic noise function that dynamically
captures both current and historical noise, enabling us to assess the temporal
aspect of noise and generate a denoised graph. We further propose the Temporal
Embedding Learner to tackle the challenge of more severe noise, which utilizes
an attention mechanism to selectively turn a blind eye to noisy edges and hence
focus on normal edges, enhancing the expressiveness for representation
generation that remains resilient to noise. Our method demonstrates robustness
towards downstream tasks, resulting in up to 5.1% absolute AUC improvement in
evolving classification versus the second-best baseline.
</p>
</div>
</dd>
<dt><a name="item583">[583]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.02026" title="Abstract">arXiv:2309.02026</a> [<a href="/pdf/2309.02026" title="Download PDF">pdf</a>, <a href="/format/2309.02026" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AutonomROS: A ReconROS-based Autonomonous Driving Unit
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lienen%2C+C">Christian Lienen</a>, 
<a href="/search/cs?searchtype=author&query=Brede%2C+M">Mathis Brede</a>, 
<a href="/search/cs?searchtype=author&query=Karger%2C+D">Daniel Karger</a>, 
<a href="/search/cs?searchtype=author&query=Koch%2C+K">Kevin Koch</a>, 
<a href="/search/cs?searchtype=author&query=Logan%2C+D">Dalisha Logan</a>, 
<a href="/search/cs?searchtype=author&query=Mazur%2C+J">Janet Mazur</a>, 
<a href="/search/cs?searchtype=author&query=Nowosad%2C+A+P">Alexander Philipp Nowosad</a>, 
<a href="/search/cs?searchtype=author&query=Schnelle%2C+A">Alexander Schnelle</a>, 
<a href="/search/cs?searchtype=author&query=Waizy%2C+M">Mohness Waizy</a>, 
<a href="/search/cs?searchtype=author&query=Platzner%2C+M">Marco Platzner</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Autonomous driving has become an important research area in recent years, and
the corresponding system creates an enormous demand for computations.
Heterogeneous computing platforms such as systems-on-chip that combine CPUs
with reprogrammable hardware offer both computational performance and
flexibility and are thus interesting targets for autonomous driving
architectures. The de-facto software architecture standard in robotics,
including autonomous driving systems, is ROS 2. ReconROS is a framework for
creating robotics applications that extends ROS 2 with the possibility of
mapping compute-intense functions to hardware.
<br />This paper presents AutonomROS, an autonomous driving unit based on the
ReconROS framework. AutonomROS serves as a blueprint for a larger robotics
application developed with ReconROS and demonstrates its suitability and
extendability. The application integrates the ROS 2 package Navigation 2 with
custom-developed software and hardware-accelerated functions for point cloud
generation, obstacle detection, and lane detection. In addition, we detail a
new communication middleware for shared memory communication between software
and hardware functions. We evaluate AutonomROS and show the advantage of
hardware acceleration and the new communication middleware for improving
turnaround times, achievable frame rates, and, most importantly, reducing CPU
load.
</p>
</div>
</dd>
<dt><a name="item584">[584]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.02027" title="Abstract">arXiv:2309.02027</a> [<a href="/pdf/2309.02027" title="Download PDF">pdf</a>, <a href="/ps/2309.02027" title="Download PostScript">ps</a>, <a href="/format/2309.02027" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Granger Causal Inference in Multivariate Hawkes Processes by Minimum  Message Length
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hlavackova-Schindler%2C+K">Katerina Hlavackova-Schindler</a>, 
<a href="/search/cs?searchtype=author&query=Melnykova%2C+A">Anna Melnykova</a>, 
<a href="/search/cs?searchtype=author&query=Tubikanec%2C+I">Irene Tubikanec</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 23 pages, 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Multivariate Hawkes processes (MHPs) are versatile probabilistic tools used
to model various real-life phenomena: earthquakes, operations on stock markets,
neuronal activity, virus propagation and many others. In this paper, we focus
on MHPs with exponential decay kernels and estimate connectivity graphs, which
represent the Granger causal relations between their components. We approach
this inference problem by proposing an optimization criterion and model
selection algorithm based on the minimum message length (MML) principle. MML
compares Granger causal models using the Occam's razor principle in the
following way: even when models have a comparable goodness-of-fit to the
observed data, the one generating the most concise explanation of the data is
preferred. While most of the state-of-art methods using lasso-type penalization
tend to overfitting in scenarios with short time horizons, the proposed
MML-based method achieves high F1 scores in these settings. We conduct a
numerical study comparing the proposed algorithm to other related classical and
state-of-art methods, where we achieve the highest F1 scores in specific sparse
graph settings. We illustrate the proposed method also on G7 sovereign bond
data and obtain causal connections, which are in agreement with the expert
knowledge available in the literature.
</p>
</div>
</dd>
<dt><a name="item585">[585]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.02028" title="Abstract">arXiv:2309.02028</a> [<a href="/pdf/2309.02028" title="Download PDF">pdf</a>, <a href="/format/2309.02028" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Non-Parametric Representation Learning with Kernels
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Esser%2C+P">Pascal Esser</a>, 
<a href="/search/cs?searchtype=author&query=Fleissner%2C+M">Maximilian Fleissner</a>, 
<a href="/search/cs?searchtype=author&query=Ghoshdastidar%2C+D">Debarghya Ghoshdastidar</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Unsupervised and self-supervised representation learning has become popular
in recent years for learning useful features from unlabelled data.
Representation learning has been mostly developed in the neural network
literature, and other models for representation learning are surprisingly
unexplored. In this work, we introduce and analyze several kernel-based
representation learning approaches: Firstly, we define two kernel
Self-Supervised Learning (SSL) models using contrastive loss functions and
secondly, a Kernel Autoencoder (AE) model based on the idea of embedding and
reconstructing data. We argue that the classical representer theorems for
supervised kernel machines are not always applicable for (self-supervised)
representation learning, and present new representer theorems, which show that
the representations learned by our kernel models can be expressed in terms of
kernel matrices. We further derive generalisation error bounds for
representation learning with kernel SSL and AE, and empirically evaluate the
performance of these methods in both small data regimes as well as in
comparison with neural network based models.
</p>
</div>
</dd>
<dt><a name="item586">[586]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.02029" title="Abstract">arXiv:2309.02029</a> [<a href="/pdf/2309.02029" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Impact of Artificial Intelligence on the Evolution of Digital  Education: A Comparative Study of OpenAI Text Generation Tools including  ChatGPT, Bing Chat, Bard, and Ernie
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Motlagh%2C+N+Y">Negin Yazdani Motlagh</a>, 
<a href="/search/cs?searchtype=author&query=Khajavi%2C+M">Matin Khajavi</a>, 
<a href="/search/cs?searchtype=author&query=Sharifi%2C+A">Abbas Sharifi</a>, 
<a href="/search/cs?searchtype=author&query=Ahmadi%2C+M">Mohsen Ahmadi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">In the digital era, the integration of artificial intelligence (AI) in
education has ushered in transformative changes, redefining teaching
methodologies, curriculum planning, and student engagement. This review paper
delves deep into the rapidly evolving landscape of digital education by
contrasting the capabilities and impact of OpenAI's pioneering text generation
tools like Bing Chat, Bard, Ernie with a keen focus on the novel ChatGPT.
Grounded in a typology that views education through the lenses of system,
process, and result, the paper navigates the multifaceted applications of AI.
From decentralizing global education and personalizing curriculums to digitally
documenting competence-based outcomes, AI stands at the forefront of
educational modernization. Highlighting ChatGPT's meteoric rise to one million
users in just five days, the study underscores its role in democratizing
education, fostering autodidacticism, and magnifying student engagement.
However, with such transformative power comes the potential for misuse, as
text-generation tools can inadvertently challenge academic integrity. By
juxtaposing the promise and pitfalls of AI in education, this paper advocates
for a harmonized synergy between AI tools and the educational community,
emphasizing the urgent need for ethical guidelines, pedagogical adaptations,
and strategic collaborations.
</p>
</div>
</dd>
<dt><a name="item587">[587]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.02031" title="Abstract">arXiv:2309.02031</a> [<a href="/pdf/2309.02031" title="Download PDF">pdf</a>, <a href="/format/2309.02031" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A survey on efficient vision transformers: algorithms, techniques, and  performance benchmarking
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Papa%2C+L">Lorenzo Papa</a>, 
<a href="/search/cs?searchtype=author&query=Russo%2C+P">Paolo Russo</a>, 
<a href="/search/cs?searchtype=author&query=Amerini%2C+I">Irene Amerini</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+L">Luping Zhou</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Vision Transformer (ViT) architectures are becoming increasingly popular and
widely employed to tackle computer vision applications. Their main feature is
the capacity to extract global information through the self-attention
mechanism, outperforming earlier convolutional neural networks. However, ViT
deployment and performance have grown steadily with their size, number of
trainable parameters, and operations. Furthermore, self-attention's
computational and memory cost quadratically increases with the image
resolution. Generally speaking, it is challenging to employ these architectures
in real-world applications due to many hardware and environmental restrictions,
such as processing and computational capabilities. Therefore, this survey
investigates the most efficient methodologies to ensure sub-optimal estimation
performances. More in detail, four efficient categories will be analyzed:
compact architecture, pruning, knowledge distillation, and quantization
strategies. Moreover, a new metric called Efficient Error Rate has been
introduced in order to normalize and compare models' features that affect
hardware devices at inference time, such as the number of parameters, bits,
FLOPs, and model size. Summarizing, this paper firstly mathematically defines
the strategies used to make Vision Transformer efficient, describes and
discusses state-of-the-art methodologies, and analyzes their performances over
different application scenarios. Toward the end of this paper, we also discuss
open challenges and promising research directions.
</p>
</div>
</dd>
<dt><a name="item588">[588]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.02033" title="Abstract">arXiv:2309.02033</a> [<a href="/pdf/2309.02033" title="Download PDF">pdf</a>, <a href="/format/2309.02033" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Data-Juicer: A One-Stop Data Processing System for Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+D">Daoyuan Chen</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+Y">Yilun Huang</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+Z">Zhijian Ma</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+H">Hesen Chen</a>, 
<a href="/search/cs?searchtype=author&query=Pan%2C+X">Xuchen Pan</a>, 
<a href="/search/cs?searchtype=author&query=Ge%2C+C">Ce Ge</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+D">Dawei Gao</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+Y">Yuexiang Xie</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zhaoyang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+J">Jinyang Gao</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yaliang Li</a>, 
<a href="/search/cs?searchtype=author&query=Ding%2C+B">Bolin Ding</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+J">Jingren Zhou</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Under continuous maintenance and updating; The system, refined data recipes, and demos are at <a href="https://github.com/alibaba/data-juicer">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Databases (cs.DB); Distributed, Parallel, and Cluster Computing (cs.DC)

</div>
<p class="mathjax">The immense evolution in Large Language Models (LLMs) has underscored the
importance of massive, diverse, and high-quality data. Despite this, existing
open-source tools for LLM data processing remain limited and mostly tailored to
specific datasets, with an emphasis on the reproducibility of released data
over adaptability and usability, inhibiting potential applications. In
response, we propose a one-stop, powerful yet flexible and user-friendly LLM
data processing system named Data-Juicer. Our system offers over 50 built-in
versatile operators and pluggable tools, which synergize modularity,
composability, and extensibility dedicated to diverse LLM data processing
needs. By incorporating visualized and automatic evaluation capabilities,
Data-Juicer enables a timely feedback loop to accelerate data processing and
gain data insights. To enhance usability, Data-Juicer provides out-of-the-box
components for users with various backgrounds, and fruitful data recipes for
LLM pre-training and post-tuning usages. Further, we employ multi-facet system
optimization and seamlessly integrate Data-Juicer with both LLM and distributed
computing ecosystems, to enable efficient and scalable data processing.
Empirical validation of the generated data recipes reveals considerable
improvements in LLaMA performance for various pre-training and post-tuning
cases, demonstrating up to 7.45% relative improvement of averaged score across
16 LLM benchmarks and 16.25% higher win rate using pair-wise GPT-4 evaluation.
The system's efficiency and scalability are also validated, supported by up to
88.7% reduction in single-machine processing time, 77.1% and 73.1% less memory
and CPU usage respectively, and 7.91x processing acceleration when utilizing
distributed computing ecosystems. Our system, data recipes, and multiple
tutorial demos are released, calling for broader research centered on LLM data.
</p>
</div>
</dd>
<dt><a name="item589">[589]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.02040" title="Abstract">arXiv:2309.02040</a> [<a href="/pdf/2309.02040" title="Download PDF">pdf</a>, <a href="/format/2309.02040" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Diffusion Generative Inverse Design
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Vlastelica%2C+M">Marin Vlastelica</a>, 
<a href="/search/cs?searchtype=author&query=L%C3%B3pez-Guevara%2C+T">Tatiana L&#xf3;pez-Guevara</a>, 
<a href="/search/cs?searchtype=author&query=Allen%2C+K">Kelsey Allen</a>, 
<a href="/search/cs?searchtype=author&query=Battaglia%2C+P">Peter Battaglia</a>, 
<a href="/search/cs?searchtype=author&query=Doucet%2C+A">Arnaud Doucet</a>, 
<a href="/search/cs?searchtype=author&query=Stachenfeld%2C+K">Kimberley Stachenfeld</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ICML workshop on Structured Probabilistic Inference &amp; Generative Modeling
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Inverse design refers to the problem of optimizing the input of an objective
function in order to enact a target outcome. For many real-world engineering
problems, the objective function takes the form of a simulator that predicts
how the system state will evolve over time, and the design challenge is to
optimize the initial conditions that lead to a target outcome. Recent
developments in learned simulation have shown that graph neural networks (GNNs)
can be used for accurate, efficient, differentiable estimation of simulator
dynamics, and support high-quality design optimization with gradient- or
sampling-based optimization procedures. However, optimizing designs from
scratch requires many expensive model queries, and these procedures exhibit
basic failures on either non-convex or high-dimensional problems.In this work,
we show how denoising diffusion models (DDMs) can be used to solve inverse
design problems efficiently and propose a particle sampling algorithm for
further improving their efficiency. We perform experiments on a number of fluid
dynamics design challenges, and find that our approach substantially reduces
the number of calls to the simulator compared to standard techniques.
</p>
</div>
</dd>
<dt><a name="item590">[590]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.02041" title="Abstract">arXiv:2309.02041</a> [<a href="/pdf/2309.02041" title="Download PDF">pdf</a>, <a href="/format/2309.02041" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning Cross-Modal Affinity for Referring Video Object Segmentation  Targeting Limited Samples
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+G">Guanghui Li</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+M">Mingqi Gao</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+H">Heng Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhen%2C+X">Xiantong Zhen</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+F">Feng Zheng</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by ICCV2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Referring video object segmentation (RVOS), as a supervised learning task,
relies on sufficient annotated data for a given scene. However, in more
realistic scenarios, only minimal annotations are available for a new scene,
which poses significant challenges to existing RVOS methods. With this in mind,
we propose a simple yet effective model with a newly designed cross-modal
affinity (CMA) module based on a Transformer architecture. The CMA module
builds multimodal affinity with a few samples, thus quickly learning new
semantic information, and enabling the model to adapt to different scenarios.
Since the proposed method targets limited samples for new scenes, we generalize
the problem as - few-shot referring video object segmentation (FS-RVOS). To
foster research in this direction, we build up a new FS-RVOS benchmark based on
currently available datasets. The benchmark covers a wide range and includes
multiple situations, which can maximally simulate real-world scenarios.
Extensive experiments show that our model adapts well to different scenarios
with only a few samples, reaching state-of-the-art performance on the
benchmark. On Mini-Ref-YouTube-VOS, our model achieves an average performance
of 53.1 J and 54.8 F, which are 10% better than the baselines. Furthermore, we
show impressive results of 77.7 J and 74.8 F on Mini-Ref-SAIL-VOS, which are
significantly better than the baselines. Code is publicly available at
https://github.com/hengliusky/Few_shot_RVOS.
</p>
</div>
</dd>
<dt><a name="item591">[591]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.02042" title="Abstract">arXiv:2309.02042</a> [<a href="/pdf/2309.02042" title="Download PDF">pdf</a>, <a href="/format/2309.02042" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Bayesian experimental design for linear elasticity
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Eberle-Blick%2C+S">Sarah Eberle-Blick</a>, 
<a href="/search/math?searchtype=author&query=Hyv%C3%B6nen%2C+N">Nuutti Hyv&#xf6;nen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 23 pages, 11 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">This work considers Bayesian experimental design for the inverse boundary
value problem of linear elasticity in a two-dimensional setting. The aim is to
optimize the positions of compactly supported pressure activations on the
boundary of the examined body in order to maximize the value of the resulting
boundary deformations as data for the inverse problem of reconstructing the
Lam\'e parameters inside the object. We resort to a linearized measurement
model and adopt the framework of Bayesian experimental design, under the
assumption that the prior and measurement noise distributions are mutually
independent Gaussians. This enables the use of the standard Bayesian
A-optimality criterion for deducing optimal positions for the pressure
activations. The (second) derivatives of the boundary measurements with respect
to the Lam\'e parameters and the positions of the boundary pressure activations
are deduced to allow minimizing the corresponding objective function, i.e., the
trace of the covariance matrix of the posterior distribution, by a
gradient-based optimization algorithm. Two-dimensional numerical experiments
are performed to demonstrate the functionality of our approach.
</p>
</div>
</dd>
<dt><a name="item592">[592]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.02043" title="Abstract">arXiv:2309.02043</a> [<a href="/pdf/2309.02043" title="Download PDF">pdf</a>, <a href="/format/2309.02043" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Decomposed Guided Dynamic Filters for Efficient RGB-Guided Depth  Completion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yufei Wang</a>, 
<a href="/search/cs?searchtype=author&query=Mao%2C+Y">Yuxin Mao</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Q">Qi Liu</a>, 
<a href="/search/cs?searchtype=author&query=Dai%2C+Y">Yuchao Dai</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">RGB-guided depth completion aims at predicting dense depth maps from sparse
depth measurements and corresponding RGB images, where how to effectively and
efficiently exploit the multi-modal information is a key issue. Guided dynamic
filters, which generate spatially-variant depth-wise separable convolutional
filters from RGB features to guide depth features, have been proven to be
effective in this task. However, the dynamically generated filters require
massive model parameters, computational costs and memory footprints when the
number of feature channels is large. In this paper, we propose to decompose the
guided dynamic filters into a spatially-shared component multiplied by
content-adaptive adaptors at each spatial location. Based on the proposed idea,
we introduce two decomposition schemes A and B, which decompose the filters by
splitting the filter structure and using spatial-wise attention, respectively.
The decomposed filters not only maintain the favorable properties of guided
dynamic filters as being content-dependent and spatially-variant, but also
reduce model parameters and hardware costs, as the learned adaptors are
decoupled with the number of feature channels. Extensive experimental results
demonstrate that the methods using our schemes outperform state-of-the-art
methods on the KITTI dataset, and rank 1st and 2nd on the KITTI benchmark at
the time of submission. Meanwhile, they also achieve comparable performance on
the NYUv2 dataset. In addition, our proposed methods are general and could be
employed as plug-and-play feature fusion blocks in other multi-modal fusion
tasks such as RGB-D salient object detection.
</p>
</div>
</dd>
<dt><a name="item593">[593]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.02045" title="Abstract">arXiv:2309.02045</a> [<a href="/pdf/2309.02045" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Enhance Multi-domain Sentiment Analysis of Review Texts through  Prompting Strategies
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yajing Wang</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+Z">Zongwei Luo</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Large Language Models (LLMs) have made significant strides in both scientific
research and practical applications. Existing studies have demonstrated the
state-of-the-art (SOTA) performance of LLMs in various natural language
processing tasks. However, the question of how to further enhance LLMs'
performance in specific task using prompting strategies remains a pivotal
concern. This paper explores the enhancement of LLMs' performance in sentiment
analysis through the application of prompting strategies. We formulate the
process of prompting for sentiment analysis tasks and introduce two novel
strategies tailored for sentiment analysis: RolePlaying (RP) prompting and
Chain-of-thought (CoT) prompting. Specifically, we also propose the RP-CoT
prompting strategy which is a combination of RP prompting and CoT prompting. We
conduct comparative experiments on three distinct domain datasets to evaluate
the effectiveness of the proposed sentiment analysis strategies. The results
demonstrate that the adoption of the proposed prompting strategies leads to a
increasing enhancement in sentiment analysis accuracy. Further, the CoT
prompting strategy exhibits a notable impact on implicit sentiment analysis,
with the RP-CoT prompting strategy delivering the most superior performance
among all strategies.
</p>
</div>
</dd>
<dt><a name="item594">[594]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.02046" title="Abstract">arXiv:2309.02046</a> [<a href="/pdf/2309.02046" title="Download PDF">pdf</a>, <a href="/format/2309.02046" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Fast and Provable Algorithm for Sparse Phase Retrieval
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cai%2C+J">Jian-Feng Cai</a>, 
<a href="/search/cs?searchtype=author&query=Long%2C+Y">Yu Long</a>, 
<a href="/search/cs?searchtype=author&query=Wen%2C+R">Ruixue Wen</a>, 
<a href="/search/cs?searchtype=author&query=Ying%2C+J">Jiaxi Ying</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Optimization and Control (math.OC)

</div>
<p class="mathjax">We study the sparse phase retrieval problem, which aims to recover a sparse
signal from a limited number of phaseless measurements. Existing algorithms for
sparse phase retrieval primarily rely on first-order methods with linear
convergence rate. In this paper, we propose an efficient second-order algorithm
based on Newton projection, which maintains the same per-iteration
computational complexity as popular first-order methods. The proposed algorithm
is theoretically guaranteed to converge to the ground truth (up to a global
sign) at a quadratic convergence rate after at most $O\big(\log (\Vert
\mathbf{x}^{\natural} \, \Vert /x_{\min}^{\natural})\big)$ iterations, provided
a sample complexity of $O(s^2\log n)$, where $\mathbf{x}^{\natural} \in
\mathbb{R}^n$ represents an $s$-sparse ground truth signal. Numerical
experiments demonstrate that our algorithm not only outperforms
state-of-the-art methods in terms of achieving a significantly faster
convergence rate, but also excels in attaining a higher success rate for exact
signal recovery from noise-free measurements and providing enhanced signal
reconstruction in noisy scenarios.
</p>
</div>
</dd>
<dt><a name="item595">[595]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.02048" title="Abstract">arXiv:2309.02048</a> [<a href="/pdf/2309.02048" title="Download PDF">pdf</a>, <a href="/format/2309.02048" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Probabilistic Self-supervised Learning via Scoring Rules Minimization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Vahidi%2C+A">Amirhossein Vahidi</a>, 
<a href="/search/cs?searchtype=author&query=Scho%C3%9Fer%2C+S">Simon Scho&#xdf;er</a>, 
<a href="/search/cs?searchtype=author&query=Wimmer%2C+L">Lisa Wimmer</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yawei Li</a>, 
<a href="/search/cs?searchtype=author&query=Bischl%2C+B">Bernd Bischl</a>, 
<a href="/search/cs?searchtype=author&query=H%C3%BCllermeier%2C+E">Eyke H&#xfc;llermeier</a>, 
<a href="/search/cs?searchtype=author&query=Rezaei%2C+M">Mina Rezaei</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
<p class="mathjax">In this paper, we propose a novel probabilistic self-supervised learning via
Scoring Rule Minimization (ProSMIN), which leverages the power of probabilistic
models to enhance representation quality and mitigate collapsing
representations. Our proposed approach involves two neural networks; the online
network and the target network, which collaborate and learn the diverse
distribution of representations from each other through knowledge distillation.
By presenting the input samples in two augmented formats, the online network is
trained to predict the target network representation of the same sample under a
different augmented view. The two networks are trained via our new loss
function based on proper scoring rules. We provide a theoretical justification
for ProSMIN's convergence, demonstrating the strict propriety of its modified
scoring rule. This insight validates the method's optimization process and
contributes to its robustness and effectiveness in improving representation
quality. We evaluate our probabilistic model on various downstream tasks, such
as in-distribution generalization, out-of-distribution detection, dataset
corruption, low-shot learning, and transfer learning. Our method achieves
superior accuracy and calibration, surpassing the self-supervised baseline in a
wide range of experiments on large-scale datasets like ImageNet-O and
ImageNet-C, ProSMIN demonstrates its scalability and real-world applicability.
</p>
</div>
</dd>
<dt><a name="item596">[596]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.02049" title="Abstract">arXiv:2309.02049</a> [<a href="/pdf/2309.02049" title="Download PDF">pdf</a>, <a href="/format/2309.02049" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Diffusion-based 3D Object Detection with Random Boxes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhou%2C+X">Xin Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Hou%2C+J">Jinghua Hou</a>, 
<a href="/search/cs?searchtype=author&query=Yao%2C+T">Tingting Yao</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+D">Dingkang Liang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zhe Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zou%2C+Z">Zhikang Zou</a>, 
<a href="/search/cs?searchtype=author&query=Ye%2C+X">Xiaoqing Ye</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+J">Jianwei Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Bai%2C+X">Xiang Bai</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by PRCV 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">3D object detection is an essential task for achieving autonomous driving.
Existing anchor-based detection methods rely on empirical heuristics setting of
anchors, which makes the algorithms lack elegance. In recent years, we have
witnessed the rise of several generative models, among which diffusion models
show great potential for learning the transformation of two distributions. Our
proposed Diff3Det migrates the diffusion model to proposal generation for 3D
object detection by considering the detection boxes as generative targets.
During training, the object boxes diffuse from the ground truth boxes to the
Gaussian distribution, and the decoder learns to reverse this noise process. In
the inference stage, the model progressively refines a set of random boxes to
the prediction results. We provide detailed experiments on the KITTI benchmark
and achieve promising performance compared to classical anchor-based 3D
detection methods.
</p>
</div>
</dd>
<dt><a name="item597">[597]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.02050" title="Abstract">arXiv:2309.02050</a> [<a href="/pdf/2309.02050" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Model-agnostic network inference enhancement from noisy measurements via  curriculum learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+K">Kai Wu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yuanyuan Li</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jing Liu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Noise is a pervasive element within real-world measurement data,
significantly undermining the performance of network inference models. However,
the quest for a comprehensive enhancement framework capable of bolstering noise
resistance across a diverse array of network inference models has remained
elusive. Here, we present an elegant and efficient framework tailored to
amplify the capabilities of network inference models in the presence of noise.
Leveraging curriculum learning, we mitigate the deleterious impact of noisy
samples on network inference models. Our proposed framework is model-agnostic,
seamlessly integrable into a plethora of model-based and model-free network
inference methods. Notably, we utilize one model-based and three model-free
network inference methods as the foundation. Extensive experimentation across
various synthetic and real-world networks, encapsulating diverse nonlinear
dynamic processes, showcases substantial performance augmentation under varied
noise types, particularly thriving in scenarios enriched with clean samples.
This framework's adeptness in fortifying both model-free and model-based
network inference methodologies paves the avenue towards a comprehensive and
unified enhancement framework, encompassing the entire spectrum of network
inference models. Available Code: https://github.com/xiaoyuans/MANIE.
</p>
</div>
</dd>
<dt><a name="item598">[598]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.02052" title="Abstract">arXiv:2309.02052</a> [<a href="/pdf/2309.02052" title="Download PDF">pdf</a>, <a href="/ps/2309.02052" title="Download PostScript">ps</a>, <a href="/format/2309.02052" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Individual and Multistakeholder Fairness in Tourism Recommender  Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Banerjee%2C+A">Ashmi Banerjee</a>, 
<a href="/search/cs?searchtype=author&query=Banik%2C+P">Paromita Banik</a>, 
<a href="/search/cs?searchtype=author&query=W%C3%B6rndl%2C+W">Wolfgang W&#xf6;rndl</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Position Paper for FAcctRec 2023 at RecSys 2023
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Frontiers in Big Data 2023, Volume 6, 1168692
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Human-Computer Interaction (cs.HC)

</div>
<p class="mathjax">This position paper summarizes our published review on individual and
multistakeholder fairness in Tourism Recommender Systems (TRS). Recently, there
has been growing attention to fairness considerations in recommender systems
(RS). It has been acknowledged in research that fairness in RS is often closely
tied to the presence of multiple stakeholders, such as end users, item
providers, and platforms, as it raises concerns for the fair treatment of all
parties involved. Hence, fairness in RS is a multi-faceted concept that
requires consideration of the perspectives and needs of the different
stakeholders to ensure fair outcomes for them. However, there may often be
instances where achieving the goals of one stakeholder could conflict with
those of another, resulting in trade-offs.
<br />In this paper, we emphasized addressing the unique challenges of ensuring
fairness in RS within the tourism domain. We aimed to discuss potential
strategies for mitigating the aforementioned challenges and examine the
applicability of solutions from other domains to tackle fairness issues in
tourism. By exploring cross-domain approaches and strategies for incorporating
S-Fairness, we can uncover valuable insights and determine how these solutions
can be adapted and implemented effectively in the context of tourism to enhance
fairness in RS.
</p>
</div>
</dd>
<dt><a name="item599">[599]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.02054" title="Abstract">arXiv:2309.02054</a> [<a href="/pdf/2309.02054" title="Download PDF">pdf</a>, <a href="/format/2309.02054" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An Adaptive Spatial-Temporal Local Feature Difference Method for  Infrared Small-moving Target Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Y">Yongkang Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+C">Chuang Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yuan Li</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Shuaishuai Wang</a>, 
<a href="/search/cs?searchtype=author&query=Lan%2C+Z">Zihan Lan</a>, 
<a href="/search/cs?searchtype=author&query=Qiao%2C+Y">Yuanyuan Qiao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Detecting small moving targets accurately in infrared (IR) image sequences is
a significant challenge. To address this problem, we propose a novel method
called spatial-temporal local feature difference (STLFD) with adaptive
background suppression (ABS). Our approach utilizes filters in the spatial and
temporal domains and performs pixel-level ABS on the output to enhance the
contrast between the target and the background. The proposed method comprises
three steps. First, we obtain three temporal frame images based on the current
frame image and extract two feature maps using the designed spatial domain and
temporal domain filters. Next, we fuse the information of the spatial domain
and temporal domain to produce the spatial-temporal feature maps and suppress
noise using our pixel-level ABS module. Finally, we obtain the segmented binary
map by applying a threshold. Our experimental results demonstrate that the
proposed method outperforms existing state-of-the-art methods for infrared
small-moving target detection.
</p>
</div>
</dd>
<dt><a name="item600">[600]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.02055" title="Abstract">arXiv:2309.02055</a> [<a href="/pdf/2309.02055" title="Download PDF">pdf</a>, <a href="/format/2309.02055" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> No-Regret Caching with Noisy Request Estimates
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mazziane%2C+Y+B">Younes Ben Mazziane</a>, 
<a href="/search/cs?searchtype=author&query=Faticanti%2C+F">Francescomaria Faticanti</a>, 
<a href="/search/cs?searchtype=author&query=Neglia%2C+G">Giovanni Neglia</a>, 
<a href="/search/cs?searchtype=author&query=Alouf%2C+S">Sara Alouf</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Networking and Internet Architecture (cs.NI); Performance (cs.PF)

</div>
<p class="mathjax">Online learning algorithms have been successfully used to design caching
policies with regret guarantees. Existing algorithms assume that the cache
knows the exact request sequence, but this may not be feasible in high load
and/or memory-constrained scenarios, where the cache may have access only to
sampled requests or to approximate requests' counters. In this paper, we
propose the Noisy-Follow-the-Perturbed-Leader (NFPL) algorithm, a variant of
the classic Follow-the-Perturbed-Leader (FPL) when request estimates are noisy,
and we show that the proposed solution has sublinear regret under specific
conditions on the requests estimator. The experimental evaluation compares the
proposed solution against classic caching policies and validates the proposed
approach under both synthetic and real request traces.
</p>
</div>
</dd>
<dt><a name="item601">[601]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.02057" title="Abstract">arXiv:2309.02057</a> [<a href="/pdf/2309.02057" title="Download PDF">pdf</a>, <a href="/format/2309.02057" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Robust Recommender System: A Survey and Future Directions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+K">Kaike Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+Q">Qi Cao</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+F">Fei Sun</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Y">Yunfan Wu</a>, 
<a href="/search/cs?searchtype=author&query=Tao%2C+S">Shuchang Tao</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+H">Huawei Shen</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+X">Xueqi Cheng</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>

</div>
<p class="mathjax">With the rapid growth of information, recommender systems have become
integral for providing personalized suggestions and overcoming information
overload. However, their practical deployment often encounters "dirty" data,
where noise or malicious information can lead to abnormal recommendations.
Research on improving recommender systems' robustness against such dirty data
has thus gained significant attention. This survey provides a comprehensive
review of recent work on recommender systems' robustness. We first present a
taxonomy to organize current techniques for withstanding malicious attacks and
natural noise. We then explore state-of-the-art methods in each category,
including fraudster detection, adversarial training, certifiable robust
training against malicious attacks, and regularization, purification,
self-supervised learning against natural noise. Additionally, we summarize
evaluation metrics and common datasets used to assess robustness. We discuss
robustness across varying recommendation scenarios and its interplay with other
properties like accuracy, interpretability, privacy, and fairness. Finally, we
delve into open issues and future research directions in this emerging field.
Our goal is to equip readers with a holistic understanding of robust
recommender systems and spotlight pathways for future research and development.
</p>
</div>
</dd>
<dt><a name="item602">[602]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.02058" title="Abstract">arXiv:2309.02058</a> [<a href="/pdf/2309.02058" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> How Can AI be Distributed in the Computing Continuum? Introducing the  Neural Pub/Sub Paradigm
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lov%C3%A9n%2C+L">Lauri Lov&#xe9;n</a>, 
<a href="/search/cs?searchtype=author&query=Morabito%2C+R">Roberto Morabito</a>, 
<a href="/search/cs?searchtype=author&query=Kumar%2C+A">Abhishek Kumar</a>, 
<a href="/search/cs?searchtype=author&query=Pirttikangas%2C+S">Susanna Pirttikangas</a>, 
<a href="/search/cs?searchtype=author&query=Riekki%2C+J">Jukka Riekki</a>, 
<a href="/search/cs?searchtype=author&query=Tarkoma%2C+S">Sasu Tarkoma</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>

</div>
<p class="mathjax">This paper proposes the neural publish/subscribe paradigm, a novel approach
to orchestrating AI workflows in large-scale distributed AI systems in the
computing continuum. Traditional centralized broker methodologies are
increasingly struggling with managing the data surge resulting from the
proliferation of 5G systems, connected devices, and ultra-reliable
applications. Moreover, the advent of AI-powered applications, particularly
those leveraging advanced neural network architectures, necessitates a new
approach to orchestrate and schedule AI processes within the computing
continuum. In response, the neural pub/sub paradigm aims to overcome these
limitations by efficiently managing training, fine-tuning and inference
workflows, improving distributed computation, facilitating dynamic resource
allocation, and enhancing system resilience across the computing continuum. We
explore this new paradigm through various design patterns, use cases, and
discuss open research questions for further exploration.
</p>
</div>
</dd>
<dt><a name="item603">[603]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.02061" title="Abstract">arXiv:2309.02061</a> [<a href="/pdf/2309.02061" title="Download PDF">pdf</a>, <a href="/format/2309.02061" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Scenario-Aware Hierarchical Dynamic Network for Multi-Scenario  Recommendation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gao%2C+J">Jingtong Gao</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+B">Bo Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+M">Menghui Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+X">Xiangyu Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xiaopeng Li</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yuhao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yichao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+H">Huifeng Guo</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+R">Ruiming Tang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>

</div>
<p class="mathjax">Click-Through Rate (CTR) prediction is a fundamental technique in
recommendation and advertising systems. Recent studies have shown that
implementing multi-scenario recommendations contributes to strengthening
information sharing and improving overall performance. However, existing
multi-scenario models only consider coarse-grained explicit scenario modeling
that depends on pre-defined scenario identification from manual prior rules,
which is biased and sub-optimal. To address these limitations, we propose a
Scenario-Aware Hierarchical Dynamic Network for Multi-Scenario Recommendations
(HierRec), which perceives implicit patterns adaptively and conducts explicit
and implicit scenario modeling jointly. In particular, HierRec designs a basic
scenario-oriented module based on the dynamic weight to capture
scenario-specific information. Then the hierarchical explicit and implicit
scenario-aware modules are proposed to model hybrid-grained scenario
information. The multi-head implicit modeling design contributes to perceiving
distinctive patterns from different perspectives. Our experiments on two public
datasets and real-world industrial applications on a mainstream online
advertising platform demonstrate that our HierRec outperforms existing models
significantly.
</p>
</div>
</dd>
<dt><a name="item604">[604]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.02064" title="Abstract">arXiv:2309.02064</a> [<a href="/pdf/2309.02064" title="Download PDF">pdf</a>, <a href="/format/2309.02064" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MvFS: Multi-view Feature Selection for Recommender System
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lee%2C+Y">Youngjune Lee</a>, 
<a href="/search/cs?searchtype=author&query=Jeong%2C+Y">Yeongjong Jeong</a>, 
<a href="/search/cs?searchtype=author&query=Park%2C+K">Keunchan Park</a>, 
<a href="/search/cs?searchtype=author&query=Kang%2C+S">SeongKu Kang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> CIKM 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Feature selection, which is a technique to select key features in recommender
systems, has received increasing research attention. Recently, Adaptive Feature
Selection (AdaFS) has shown remarkable performance by adaptively selecting
features for each data instance, considering that the importance of a given
feature field can vary significantly across data. However, this method still
has limitations in that its selection process could be easily biased to major
features that frequently occur. To address these problems, we propose
Multi-view Feature Selection (MvFS), which selects informative features for
each instance more effectively. Most importantly, MvFS employs a multi-view
network consisting of multiple sub-networks, each of which learns to measure
the feature importance of a part of data with different feature patterns. By
doing so, MvFS promotes a more balanced feature selection process mitigating
the bias problem towards dominant patterns. Moreover, MvFS adopts an effective
importance score modeling strategy which is applied independently to each field
without incurring dependency among features. Experimental results on real-world
datasets demonstrate the effectiveness of MvFS compared to state-of-the-art
baselines.
</p>
</div>
</dd>
<dt><a name="item605">[605]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.02065" title="Abstract">arXiv:2309.02065</a> [<a href="/pdf/2309.02065" title="Download PDF">pdf</a>, <a href="/format/2309.02065" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Efficiency is Not Enough: A Critical Perspective of Environmentally  Sustainable AI
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wright%2C+D">Dustin Wright</a>, 
<a href="/search/cs?searchtype=author&query=Igel%2C+C">Christian Igel</a>, 
<a href="/search/cs?searchtype=author&query=Samuel%2C+G">Gabrielle Samuel</a>, 
<a href="/search/cs?searchtype=author&query=Selvan%2C+R">Raghavendra Selvan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 24 pages; 6 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computers and Society (cs.CY); Machine Learning (stat.ML)

</div>
<p class="mathjax">Artificial Intelligence (AI) is currently spearheaded by machine learning
(ML) methods such as deep learning (DL) which have accelerated progress on many
tasks thought to be out of reach of AI. These ML methods can often be compute
hungry, energy intensive, and result in significant carbon emissions, a known
driver of anthropogenic climate change. Additionally, the platforms on which ML
systems run are associated with environmental impacts including and beyond
carbon emissions. The solution lionized by both industry and the ML community
to improve the environmental sustainability of ML is to increase the efficiency
with which ML systems operate in terms of both compute and energy consumption.
In this perspective, we argue that efficiency alone is not enough to make ML as
a technology environmentally sustainable. We do so by presenting three high
level discrepancies between the effect of efficiency on the environmental
sustainability of ML when considering the many variables which it interacts
with. In doing so, we comprehensively demonstrate, at multiple levels of
granularity both technical and non-technical reasons, why efficiency is not
enough to fully remedy the environmental impacts of ML. Based on this, we
present and argue for systems thinking as a viable path towards improving the
environmental sustainability of ML holistically.
</p>
</div>
</dd>
<dt><a name="item606">[606]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.02067" title="Abstract">arXiv:2309.02067</a> [<a href="/pdf/2309.02067" title="Download PDF">pdf</a>, <a href="/format/2309.02067" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Histograms of Points, Orientations, and Dynamics of Orientations  Features for Hindi Online Handwritten Character Recognition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sharma%2C+A">Anand Sharma</a> (MIET, Meerut), 
<a href="/search/cs?searchtype=author&query=Ramakrishnan%2C+A+G">A. G. Ramakrishnan</a> (IISc, Bengaluru)
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 21 pages, 12 jpg figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">A set of features independent of character stroke direction and order
variations is proposed for online handwritten character recognition. A method
is developed that maps features like co-ordinates of points, orientations of
strokes at points, and dynamics of orientations of strokes at points spatially
as a function of co-ordinate values of the points and computes histograms of
these features from different regions in the spatial map.
<br />Different features like spatio-temporal, discrete Fourier transform, discrete
cosine transform, discrete wavelet transform, spatial, and histograms of
oriented gradients used in other studies for training classifiers for character
recognition are considered. The classifier chosen for classification
performance comparison, when trained with different features, is support vector
machines (SVM).
<br />The character datasets used for training and testing the classifiers consist
of online handwritten samples of 96 different Hindi characters. There are 12832
and 2821 samples in training and testing datasets, respectively.
<br />SVM classifiers trained with the proposed features has the highest
classification accuracy of 92.9\% when compared to the performances of SVM
classifiers trained with the other features and tested on the same testing
dataset. Therefore, the proposed features have better character discriminative
capability than the other features considered for comparison.
</p>
</div>
</dd>
<dt><a name="item607">[607]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.02077" title="Abstract">arXiv:2309.02077</a> [<a href="/pdf/2309.02077" title="Download PDF">pdf</a>, <a href="/format/2309.02077" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An Automatic Evaluation Framework for Multi-turn Medical Consultations  Capabilities of Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liao%2C+Y">Yusheng Liao</a>, 
<a href="/search/cs?searchtype=author&query=Meng%2C+Y">Yutong Meng</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+H">Hongcheng Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yanfeng Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yu Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 9figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Large language models (LLMs) have achieved significant success in interacting
with human. However, recent studies have revealed that these models often
suffer from hallucinations, leading to overly confident but incorrect
judgments. This limits their application in the medical domain, where tasks
require the utmost accuracy. This paper introduces an automated evaluation
framework that assesses the practical capabilities of LLMs as virtual doctors
during multi-turn consultations. Consultation tasks are designed to require
LLMs to be aware of what they do not know, to inquire about missing medical
information from patients, and to ultimately make diagnoses. To evaluate the
performance of LLMs for these tasks, a benchmark is proposed by reformulating
medical multiple-choice questions from the United States Medical Licensing
Examinations (USMLE), and comprehensive evaluation metrics are developed and
evaluated on three constructed test sets. A medical consultation training set
is further constructed to improve the consultation ability of LLMs. The results
of the experiments show that fine-tuning with the training set can alleviate
hallucinations and improve LLMs' performance on the proposed benchmark.
Extensive experiments and ablation studies are conducted to validate the
effectiveness and robustness of the proposed framework.
</p>
</div>
</dd>
<dt><a name="item608">[608]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.02079" title="Abstract">arXiv:2309.02079</a> [<a href="/pdf/2309.02079" title="Download PDF">pdf</a>, <a href="/format/2309.02079" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Investigating the Impact of a Dual Musical Brain-Computer Interface on  Interpersonal Synchrony: A Pilot Study
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Vrins%2C+A">Anita Vrins</a>, 
<a href="/search/cs?searchtype=author&query=Pruss%2C+E">Ethel Pruss</a>, 
<a href="/search/cs?searchtype=author&query=Ceccato%2C+C">Caterina Ceccato</a>, 
<a href="/search/cs?searchtype=author&query=Prinsen%2C+J">Jos Prinsen</a>, 
<a href="/search/cs?searchtype=author&query=Alimardani%2C+M">Maryam Alimardani</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages, 4 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">This study looked into how effective a Musical Brain-Computer Interface
(MBCI) can be in providing feedback about synchrony between two people. Using a
double EEG setup, we compared two types of musical feedback; one that adapted
in real-time based on the inter-brain synchrony between participants
(Neuroadaptive condition), and another music that was randomly generated
(Random condition). We evaluated how these two conditions were perceived by 8
dyads (n = 16) and whether the generated music could influence the perceived
connection and EEG synchrony between them. The findings indicated that
Neuroadaptive musical feedback could potentially boost synchrony levels between
people compared to Random feedback, as seen by a significant increase in EEG
phase-locking values. Additionally, the real-time measurement of synchrony was
successfully validated and musical neurofeedback was generally well-received by
the participants. However, more research is needed for conclusive results due
to the small sample size. This study is a stepping stone towards creating music
that can audibly reflect the level of synchrony between individuals.
</p>
</div>
</dd>
<dt><a name="item609">[609]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.02080" title="Abstract">arXiv:2309.02080</a> [<a href="/pdf/2309.02080" title="Download PDF">pdf</a>, <a href="/ps/2309.02080" title="Download PostScript">ps</a>, <a href="/format/2309.02080" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Optimization tools for Twin-in-the-Loop vehicle control design: analysis  and yaw-rate tracking case study
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Dett%C3%B9%2C+F">Federico Dett&#xf9;</a>, 
<a href="/search/eess?searchtype=author&query=Formentin%2C+S">Simone Formentin</a>, 
<a href="/search/eess?searchtype=author&query=Varisco%2C+S">Stefano Varisco</a>, 
<a href="/search/eess?searchtype=author&query=Savaresi%2C+S+M">Sergio Matteo Savaresi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Preprint submitted to European Journal of Control
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">Given the urgent need of simplifying the end-of-line tuning of complex
vehicle dynamics controllers, the Twin-in-the-Loop Control (TiL-C) approach was
recently proposed in the automotive field. In TiL-C, a digital twin is run
on-board to compute a nominal control action in run-time and an additional
block C_delta is used to compensate for the mismatch between the simulator and
the real vehicle. As the digital twin is assumed to be the best replica
available of the real plant, the key issue in TiL-C becomes the tuning of the
compensator, which must be performed relying on data only. In this paper, we
investigate the use of different black-box optimization techniques for the
calibration of C_delta. More specifically, we compare the originally proposed
Bayesian Optimization (BO) approach with the recently developed Set Membership
Global Optimization (SMGO) and Virtual Reference Feedback Tuning (VRFT), a
one-shot direct data-driven design method. The analysis will be carried out
within a professional multibody simulation environment on a novel TiL-C
application case study -- the yaw-rate tracking problem -- so as to further
prove the TiL-C effctiveness on a challenging problem. Simulations will show
that the VRFT approach is capable of providing a well tuned controller after a
single iteration, while 10 to 15 iterations are necessary for refining it with
global optimizers. Also, SMGO is shown to significantly reduce the
computational effort required by BO.
</p>
</div>
</dd>
<dt><a name="item610">[610]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.02083" title="Abstract">arXiv:2309.02083</a> [<a href="/pdf/2309.02083" title="Download PDF">pdf</a>, <a href="/format/2309.02083" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the Age of Information of Processor Sharing Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gandarias%2C+B">Be&#xf1;at Gandarias</a>, 
<a href="/search/cs?searchtype=author&query=Doncel%2C+J">Josu Doncel</a>, 
<a href="/search/cs?searchtype=author&query=Assaad%2C+M">Mohamad Assaad</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Performance (cs.PF); Probability (math.PR)

</div>
<p class="mathjax">In this paper, we examine the Age of Information (AoI) of a source sending
status updates to a monitor through a queue operating under the Processor
Sharing (PS) discipline. In the PS queueing discipline, all the updates are
served simultaneously and, therefore, none of of the jobs wait in the queue to
get service. While AoI has been well studied for various queuing models and
policies, less attention has been given so far to the PS discipline. We first
consider the M/M/1/2 queue with and without preemption and provide closed-form
expressions for the average AoI in this case. We overcome the challenges of
deriving the AoI expression by employing the Stochastic Hybrid Systems (SHS)
tool. We then extend the analysis to the M/M/1 queue with one and two sources
and provide numerical results for these cases. Our results show that PS can
outperform the M/M/1/1* queue in some cases.
</p>
</div>
</dd>
<dt><a name="item611">[611]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.02084" title="Abstract">arXiv:2309.02084</a> [<a href="/pdf/2309.02084" title="Download PDF">pdf</a>, <a href="/format/2309.02084" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An Efficient Approach to Unsupervised Out-of-Distribution Detection with  Variational Autoencoders
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zeng%2C+Z">Zezhen Zeng</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+B">Bin Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">This paper is concerned with deep generative models (DGMs) for unsupervised
out-of-distribution (OOD) detection. In particular, we focus on vanilla
Variational Autoencoders (VAE) that use a standard normal prior distribution
for the latent variables. These models have a smaller model size, enabling
faster training and inference, making them well-suited for resource-limited
applications compared to more complex DGMs. We propose a novel OOD score called
Error Reduction (ER) specifically designed for vanilla VAE. ER incorporate the
idea of reconstructing image inputs from their lossy counterparts and takes
into account the Kolmogorov complexity of the images. Experimental results on
diverse datasets demonstrate the superiority of our approach over baseline
methods. Our code is available at: https://github.com/ZJLAB-AMMI/VAE4OOD.
</p>
</div>
</dd>
<dt><a name="item612">[612]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.02088" title="Abstract">arXiv:2309.02088</a> [<a href="/pdf/2309.02088" title="Download PDF">pdf</a>, <a href="/format/2309.02088" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Dual Adversarial Alignment for Realistic Support-Query Shift Few-shot  Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jiang%2C+S">Siyang Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Fang%2C+R">Rui Fang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+H">Hsi-Wen Chen</a>, 
<a href="/search/cs?searchtype=author&query=Ding%2C+W">Wei Ding</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+M">Ming-Syan Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Best student paper in PAKDD 2022
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Support-query shift few-shot learning aims to classify unseen examples (query
set) to labeled data (support set) based on the learned embedding in a
low-dimensional space under a distribution shift between the support set and
the query set. However, in real-world scenarios the shifts are usually unknown
and varied, making it difficult to estimate in advance. Therefore, in this
paper, we propose a novel but more difficult challenge, RSQS, focusing on
Realistic Support-Query Shift few-shot learning. The key feature of RSQS is
that the individual samples in a meta-task are subjected to multiple
distribution shifts in each meta-task. In addition, we propose a unified
adversarial feature alignment method called DUal adversarial ALignment
framework (DuaL) to relieve RSQS from two aspects, i.e., inter-domain bias and
intra-domain variance. On the one hand, for the inter-domain bias, we corrupt
the original data in advance and use the synthesized perturbed inputs to train
the repairer network by minimizing distance in the feature level. On the other
hand, for intra-domain variance, we proposed a generator network to synthesize
hard, i.e., less similar, examples from the support set in a self-supervised
manner and introduce regularized optimal transportation to derive a smooth
optimal transportation plan. Lastly, a benchmark of RSQS is built with several
state-of-the-art baselines among three datasets (CIFAR100, mini-ImageNet, and
Tiered-Imagenet). Experiment results show that DuaL significantly outperforms
the state-of-the-art methods in our benchmark.
</p>
</div>
</dd>
<dt><a name="item613">[613]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.02091" title="Abstract">arXiv:2309.02091</a> [<a href="/pdf/2309.02091" title="Download PDF">pdf</a>, <a href="/format/2309.02091" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DeNISE: Deep Networks for Improved Segmentation Edges
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jyhne%2C+S+R">Sander Riis&#xf8;en Jyhne</a>, 
<a href="/search/cs?searchtype=author&query=Andersen%2C+P">Per-Arne Andersen</a>, 
<a href="/search/cs?searchtype=author&query=Goodwin%2C+M">Morten Goodwin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">This paper presents Deep Networks for Improved Segmentation Edges (DeNISE), a
novel data enhancement technique using edge detection and segmentation models
to improve the boundary quality of segmentation masks. DeNISE utilizes the
inherent differences in two sequential deep neural architectures to improve the
accuracy of the predicted segmentation edge. DeNISE applies to all types of
neural networks and is not trained end-to-end, allowing rapid experiments to
discover which models complement each other. We test and apply DeNISE for
building segmentation in aerial images. Aerial images are known for difficult
conditions as they have a low resolution with optical noise, such as
reflections, shadows, and visual obstructions. Overall the paper demonstrates
the potential for DeNISE. Using the technique, we improve the baseline results
with a building IoU of 78.9%.
</p>
</div>
</dd>
<dt><a name="item614">[614]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.02092" title="Abstract">arXiv:2309.02092</a> [<a href="/pdf/2309.02092" title="Download PDF">pdf</a>, <a href="/format/2309.02092" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Bridging Emotion Role Labeling and Appraisal-based Emotion Analysis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Klinger%2C+R">Roman Klinger</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> under review for <a href="https://bigpictureworkshop.com/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">The term emotion analysis in text subsumes various natural language
processing tasks which have in common the goal to enable computers to
understand emotions. Most popular is emotion classification in which one or
multiple emotions are assigned to a predefined textual unit. While such setting
is appropriate to identify the reader's or author's emotion, emotion role
labeling adds the perspective of mentioned entities and extracts text spans
that correspond to the emotion cause. The underlying emotion theories agree on
one important point; that an emotion is caused by some internal or external
event and comprises several subcomponents, including the subjective feeling and
a cognitive evaluation. We therefore argue that emotions and events are related
in two ways. (1) Emotions are events; and this perspective is the fundament in
NLP for emotion role labeling. (2) Emotions are caused by events; a perspective
that is made explicit with research how to incorporate psychological appraisal
theories in NLP models to interpret events. These two research directions, role
labeling and (event-focused) emotion classification, have by and large been
tackled separately. We contributed to both directions with the projects SEAT
(Structured Multi-Domain Emotion Analysis from Text) and CEAT (Computational
Event Evaluation based on Appraisal Theories for Emotion Analysis), both funded
by the German Research Foundation. In this paper, we consolidate the findings
and point out open research questions.
</p>
</div>
</dd>
<dt><a name="item615">[615]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.02094" title="Abstract">arXiv:2309.02094</a> [<a href="/pdf/2309.02094" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> TensorBank:Tensor Lakehouse for Foundation Model Training
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kienzler%2C+R">Romeo Kienzler</a>, 
<a href="/search/cs?searchtype=author&query=Blumenstiel%2C+B">Benedikt Blumenstiel</a>, 
<a href="/search/cs?searchtype=author&query=Nagy%2C+Z+A">Zoltan Arnold Nagy</a>, 
<a href="/search/cs?searchtype=author&query=Mukkavilli%2C+S+K">S. Karthik Mukkavilli</a>, 
<a href="/search/cs?searchtype=author&query=Schmude%2C+J">Johannes Schmude</a>, 
<a href="/search/cs?searchtype=author&query=Freitag%2C+M">Marcus Freitag</a>, 
<a href="/search/cs?searchtype=author&query=Behrendt%2C+M">Michael Behrendt</a>, 
<a href="/search/cs?searchtype=author&query=Civitarese%2C+D+S">Daniel Salles Civitarese</a>, 
<a href="/search/cs?searchtype=author&query=Hamann%2C+H">Hendrik Hamann</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Databases (cs.DB); Information Retrieval (cs.IR)

</div>
<p class="mathjax">Storing and streaming high dimensional data for foundation model training
became a critical requirement with the rise of foundation models beyond natural
language. In this paper we introduce TensorBank, a petabyte scale tensor
lakehouse capable of streaming tensors from Cloud Object Store (COS) to GPU
memory at wire speed based on complex relational queries. We use Hierarchical
Statistical Indices (HSI) for query acceleration. Our architecture allows to
directly address tensors on block level using HTTP range reads. Once in GPU
memory, data can be transformed using PyTorch transforms. We provide a generic
PyTorch dataset type with a corresponding dataset factory translating
relational queries and requested transformations as an instance. By making use
of the HSI, irrelevant blocks can be skipped without reading them as those
indices contain statistics on their content at different hierarchical
resolution levels. This is an opinionated architecture powered by open
standards and making heavy use of open-source technology. Although, hardened
for production use using geospatial-temporal data, this architecture
generalizes to other use case like computer vision, computational neuroscience,
biological sequence analysis and more.
</p>
</div>
</dd>
<dt><a name="item616">[616]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.02099" title="Abstract">arXiv:2309.02099</a> [<a href="/pdf/2309.02099" title="Download PDF">pdf</a>, <a href="/format/2309.02099" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Diverse and Consistent Typography Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shimoda%2C+W">Wataru Shimoda</a>, 
<a href="/search/cs?searchtype=author&query=Haraguchi%2C+D">Daichi Haraguchi</a>, 
<a href="/search/cs?searchtype=author&query=Uchida%2C+S">Seiichi Uchida</a>, 
<a href="/search/cs?searchtype=author&query=Yamaguchi%2C+K">Kota Yamaguchi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Multimedia (cs.MM)

</div>
<p class="mathjax">In this work, we consider the typography generation task that aims at
producing diverse typographic styling for the given graphic document. We
formulate typography generation as a fine-grained attribute generation for
multiple text elements and build an autoregressive model to generate diverse
typography that matches the input design context. We further propose a simple
yet effective sampling approach that respects the consistency and distinction
principle of typography so that generated examples share consistent typographic
styling across text elements. Our empirical study shows that our model
successfully generates diverse typographic designs while preserving a
consistent typographic structure.
</p>
</div>
</dd>
<dt><a name="item617">[617]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.02102" title="Abstract">arXiv:2309.02102</a> [<a href="/pdf/2309.02102" title="Download PDF">pdf</a>, <a href="/format/2309.02102" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Iterative Superquadric Recomposition of 3D Objects from Multiple Views
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Alaniz%2C+S">Stephan Alaniz</a>, 
<a href="/search/cs?searchtype=author&query=Mancini%2C+M">Massimiliano Mancini</a>, 
<a href="/search/cs?searchtype=author&query=Akata%2C+Z">Zeynep Akata</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at ICCV 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Humans are good at recomposing novel objects, i.e. they can identify
commonalities between unknown objects from general structure to finer detail,
an ability difficult to replicate by machines. We propose a framework, ISCO, to
recompose an object using 3D superquadrics as semantic parts directly from 2D
views without training a model that uses 3D supervision. To achieve this, we
optimize the superquadric parameters that compose a specific instance of the
object, comparing its rendered 3D view and 2D image silhouette. Our ISCO
framework iteratively adds new superquadrics wherever the reconstruction error
is high, abstracting first coarse regions and then finer details of the target
object. With this simple coarse-to-fine inductive bias, ISCO provides
consistent superquadrics for related object parts, despite not having any
semantic supervision. Since ISCO does not train any neural network, it is also
inherently robust to out-of-distribution objects. Experiments show that,
compared to recent single instance superquadrics reconstruction approaches,
ISCO provides consistently more accurate 3D reconstructions, even from images
in the wild. Code available at https://github.com/ExplainableML/ISCO .
</p>
</div>
</dd>
<dt><a name="item618">[618]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.02105" title="Abstract">arXiv:2309.02105</a> [<a href="/pdf/2309.02105" title="Download PDF">pdf</a>, <a href="/format/2309.02105" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Improving Query-Focused Meeting Summarization with Query-Relevant  Knowledge
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yu%2C+T">Tiezheng Yu</a>, 
<a href="/search/cs?searchtype=author&query=Ji%2C+Z">Ziwei Ji</a>, 
<a href="/search/cs?searchtype=author&query=Fung%2C+P">Pascale Fung</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> AACL 2023 Findings
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Query-Focused Meeting Summarization (QFMS) aims to generate a summary of a
given meeting transcript conditioned upon a query. The main challenges for QFMS
are the long input text length and sparse query-relevant information in the
meeting transcript. In this paper, we propose a knowledge-enhanced two-stage
framework called Knowledge-Aware Summarizer (KAS) to tackle the challenges. In
the first stage, we introduce knowledge-aware scores to improve the
query-relevant segment extraction. In the second stage, we incorporate
query-relevant knowledge in the summary generation. Experimental results on the
QMSum dataset show that our approach achieves state-of-the-art performance.
Further analysis proves the competency of our methods in generating relevant
and faithful summaries.
</p>
</div>
</dd>
<dt><a name="item619">[619]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.02106" title="Abstract">arXiv:2309.02106</a> [<a href="/pdf/2309.02106" title="Download PDF">pdf</a>, <a href="/format/2309.02106" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Leveraging Label Information for Multimodal Emotion Recognition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+P">Peiying Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zeng%2C+S">Sunlu Zeng</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Junqing Chen</a>, 
<a href="/search/cs?searchtype=author&query=Fan%2C+L">Lu Fan</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+M">Meng Chen</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Y">Youzheng Wu</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+X">Xiaodong He</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by Interspeech 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">Multimodal emotion recognition (MER) aims to detect the emotional status of a
given expression by combining the speech and text information. Intuitively,
label information should be capable of helping the model locate the salient
tokens/frames relevant to the specific emotion, which finally facilitates the
MER task. Inspired by this, we propose a novel approach for MER by leveraging
label information. Specifically, we first obtain the representative label
embeddings for both text and speech modalities, then learn the label-enhanced
text/speech representations for each utterance via label-token and label-frame
interactions. Finally, we devise a novel label-guided attentive fusion module
to fuse the label-aware text and speech representations for emotion
classification. Extensive experiments were conducted on the public IEMOCAP
dataset, and experimental results demonstrate that our proposed approach
outperforms existing baselines and achieves new state-of-the-art performance.
</p>
</div>
</dd>
<dt><a name="item620">[620]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.02111" title="Abstract">arXiv:2309.02111</a> [<a href="/pdf/2309.02111" title="Download PDF">pdf</a>, <a href="/format/2309.02111" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> HW/SW Codesign for Robust and Efficient Binarized SNNs by Capacitor  Minimization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yayla%2C+M">Mikail Yayla</a>, 
<a href="/search/cs?searchtype=author&query=Thomann%2C+S">Simon Thomann</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+M">Ming-Liang Wei</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+C">Chia-Lin Yang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Jian-Jia Chen</a>, 
<a href="/search/cs?searchtype=author&query=Amrouch%2C+H">Hussam Amrouch</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages, 9 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Hardware Architecture (cs.AR)</span>; Emerging Technologies (cs.ET)

</div>
<p class="mathjax">Using accelerators based on analog computing is an efficient way to process
the immensely large workloads in Neural Networks (NNs). One example of an
analog computing scheme for NNs is Integrate-and-Fire (IF) Spiking Neural
Networks (SNNs). However, to achieve high inference accuracy in IF-SNNs, the
analog hardware needs to represent current-based multiply-accumulate (MAC)
levels as spike times, for which a large membrane capacitor needs to be charged
for a certain amount of time. A large capacitor results in high energy use,
considerable area cost, and long latency, constituting one of the major
bottlenecks in analog IF-SNN implementations. In this work, we propose a HW/SW
Codesign method, called CapMin, for capacitor size minimization in analog
computing IF-SNNs. CapMin minimizes the capacitor size by reducing the number
of spike times needed for accurate operation of the HW, based on the absolute
frequency of MAC level occurrences in the SW. To increase the operation of
IF-SNNs to current variation, we propose the method CapMin-V, which trades
capacitor size for protection based on the reduced capacitor size found in
CapMin. In our experiments, CapMin achieves more than a 14$\times$ reduction in
capacitor size over the state of the art, while CapMin-V achieves increased
variation tolerance in the IF-SNN operation, requiring only a small increase in
capacitor size.
</p>
</div>
</dd>
<dt><a name="item621">[621]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.02119" title="Abstract">arXiv:2309.02119</a> [<a href="/pdf/2309.02119" title="Download PDF">pdf</a>, <a href="/format/2309.02119" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Hierarchical Masked 3D Diffusion Model for Video Outpainting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fan%2C+F">Fanda Fan</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+C">Chaoxu Guo</a>, 
<a href="/search/cs?searchtype=author&query=Gong%2C+L">Litong Gong</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+B">Biao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Ge%2C+T">Tiezheng Ge</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+Y">Yuning Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+C">Chunjie Luo</a>, 
<a href="/search/cs?searchtype=author&query=Zhan%2C+J">Jianfeng Zhan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ACM MM 2023 accepted
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Video outpainting aims to adequately complete missing areas at the edges of
video frames. Compared to image outpainting, it presents an additional
challenge as the model should maintain the temporal consistency of the filled
area. In this paper, we introduce a masked 3D diffusion model for video
outpainting. We use the technique of mask modeling to train the 3D diffusion
model. This allows us to use multiple guide frames to connect the results of
multiple video clip inferences, thus ensuring temporal consistency and reducing
jitter between adjacent frames. Meanwhile, we extract the global frames of the
video as prompts and guide the model to obtain information other than the
current video clip using cross-attention. We also introduce a hybrid
coarse-to-fine inference pipeline to alleviate the artifact accumulation
problem. The existing coarse-to-fine pipeline only uses the infilling strategy,
which brings degradation because the time interval of the sparse frames is too
large. Our pipeline benefits from bidirectional learning of the mask modeling
and thus can employ a hybrid strategy of infilling and interpolation when
generating sparse frames. Experiments show that our method achieves
state-of-the-art results in video outpainting tasks. More results are provided
at our https://fanfanda.github.io/M3DDM/.
</p>
</div>
</dd>
<dt><a name="item622">[622]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.02120" title="Abstract">arXiv:2309.02120</a> [<a href="/pdf/2309.02120" title="Download PDF">pdf</a>, <a href="/format/2309.02120" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multi-label affordance mapping from egocentric vision
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mur-Labadia%2C+L">Lorenzo Mur-Labadia</a>, 
<a href="/search/cs?searchtype=author&query=Guerrero%2C+J+J">Jose J. Guerrero</a>, 
<a href="/search/cs?searchtype=author&query=Martinez-Cantin%2C+R">Ruben Martinez-Cantin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> International Conference on Computer Vision (ICCV) 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Accurate affordance detection and segmentation with pixel precision is an
important piece in many complex systems based on interactions, such as robots
and assitive devices. We present a new approach to affordance perception which
enables accurate multi-label segmentation. Our approach can be used to
automatically extract grounded affordances from first person videos of
interactions using a 3D map of the environment providing pixel level precision
for the affordance location. We use this method to build the largest and most
complete dataset on affordances based on the EPIC-Kitchen dataset, EPIC-Aff,
which provides interaction-grounded, multi-label, metric and spatial affordance
annotations. Then, we propose a new approach to affordance segmentation based
on multi-label detection which enables multiple affordances to co-exists in the
same space, for example if they are associated with the same object. We present
several strategies of multi-label detection using several segmentation
architectures. The experimental results highlight the importance of the
multi-label detection. Finally, we show how our metric representation can be
exploited for build a map of interaction hotspots in spatial action-centric
zones and use that representation to perform a task-oriented navigation.
</p>
</div>
</dd>
<dt><a name="item623">[623]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.02124" title="Abstract">arXiv:2309.02124</a> [<a href="/pdf/2309.02124" title="Download PDF">pdf</a>, <a href="/format/2309.02124" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exploiting Spatial-temporal Data for Sleep Stage Classification via  Hypergraph Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yuze Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Z">Ziming Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+T">Tiehua Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+K">Kang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+X">Xin Chen</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+X">Xiaowei Huang</a>, 
<a href="/search/cs?searchtype=author&query=Yin%2C+J">Jun Yin</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+Z">Zhishu Shen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">Sleep stage classification is crucial for detecting patients' health
conditions. Existing models, which mainly use Convolutional Neural Networks
(CNN) for modelling Euclidean data and Graph Convolution Networks (GNN) for
modelling non-Euclidean data, are unable to consider the heterogeneity and
interactivity of multimodal data as well as the spatial-temporal correlation
simultaneously, which hinders a further improvement of classification
performance. In this paper, we propose a dynamic learning framework STHL, which
introduces hypergraph to encode spatial-temporal data for sleep stage
classification. Hypergraphs can construct multi-modal/multi-type data instead
of using simple pairwise between two subjects. STHL creates spatial and
temporal hyperedges separately to build node correlations, then it conducts
type-specific hypergraph learning process to encode the attributes into the
embedding space. Extensive experiments show that our proposed STHL outperforms
the state-of-the-art models in sleep stage classification tasks.
</p>
</div>
</dd>
<dt><a name="item624">[624]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.02130" title="Abstract">arXiv:2309.02130</a> [<a href="/pdf/2309.02130" title="Download PDF">pdf</a>, <a href="/ps/2309.02130" title="Download PostScript">ps</a>, <a href="/format/2309.02130" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Simple Asymmetric Momentum Make SGD Greatest Again
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+G">Gongyue Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+D">Dinghuang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+S">Shuwen Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+D">Donghan Liu</a>, 
<a href="/search/cs?searchtype=author&query=Toptan%2C+C+M">Carrie M. Toptan</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+H">Honghai Liu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">We propose the simplest SGD enhanced method ever, Loss-Controlled Asymmetric
Momentum(LCAM), aimed directly at the Saddle Point problem. Compared to the
traditional SGD with Momentum, there's no increase in computational demand, yet
it outperforms all current optimizers. We use the concepts of weight
conjugation and traction effect to explain this phenomenon. We designed
experiments to rapidly reduce the learning rate at specified epochs to trap
parameters more easily at saddle points. We selected WRN28-10 as the test
network and chose cifar10 and cifar100 as test datasets, an identical group to
the original paper of WRN and Cosine Annealing Scheduling(CAS). We compared the
ability to bypass saddle points of Asymmetric Momentum with different
priorities. Finally, using WRN28-10 on Cifar100, we achieved a peak average
test accuracy of 80.78\% around 120 epoch. For comparison, the original WRN
paper reported 80.75\%, while CAS was at 80.42\%, all at 200 epoch. This means
that while potentially increasing accuracy, we use nearly half convergence
time. Our demonstration code is available at\\
https://github.com/hakumaicc/Asymmetric-Momentum-LCAM
</p>
</div>
</dd>
<dt><a name="item625">[625]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.02133" title="Abstract">arXiv:2309.02133</a> [<a href="/pdf/2309.02133" title="Download PDF">pdf</a>, <a href="/format/2309.02133" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Evaluating Methods for Ground-Truth-Free Foreign Accent Conversion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+W">Wen-Chin Huang</a>, 
<a href="/search/cs?searchtype=author&query=Toda%2C+T">Tomoki Toda</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to the 2023 Asia Pacific Signal and Information Processing Association Annual Summit and Conference (APSIPA ASC). Demo page: <a href="https://unilight.github.io/Publication-Demos/publications/fac-evaluate.">this https URL</a> Code: <a href="https://github.com/unilight/seq2seq-vc">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Computation and Language (cs.CL); Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">Foreign accent conversion (FAC) is a special application of voice conversion
(VC) which aims to convert the accented speech of a non-native speaker to a
native-sounding speech with the same speaker identity. FAC is difficult since
the native speech from the desired non-native speaker to be used as the
training target is impossible to collect. In this work, we evaluate three
recently proposed methods for ground-truth-free FAC, where all of them aim to
harness the power of sequence-to-sequence (seq2seq) and non-parallel VC models
to properly convert the accent and control the speaker identity. Our
experimental evaluation results show that no single method was significantly
better than the others in all evaluation axes, which is in contrast to
conclusions drawn in previous studies. We also explain the effectiveness of
these methods with the training input and output of the seq2seq model and
examine the design choice of the non-parallel VC model, and show that
intelligibility measures such as word error rates do not correlate well with
subjective accentedness. Finally, our implementation is open-sourced to promote
reproducible research and help future researchers improve upon the compared
systems.
</p>
</div>
</dd>
<dt><a name="item626">[626]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.02136" title="Abstract">arXiv:2309.02136</a> [<a href="/pdf/2309.02136" title="Download PDF">pdf</a>, <a href="/format/2309.02136" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exploring the Intersection of Complex Aesthetics and Generative AI for  Promoting Cultural Creativity in Rural China after the Post-Pandemic Era
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Guo%2C+M">Mengyao Guo</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xiaolin Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhuang%2C+Y">Yuan Zhuang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Jing Chen</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+P">Pengfei Wang</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+Z">Ze Gao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by 2023 the 1st International Conference on AI-generated Content (AIGC2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>; Artificial Intelligence (cs.AI); Multimedia (cs.MM)

</div>
<p class="mathjax">This paper explores using generative AI and aesthetics to promote cultural
creativity in rural China amidst COVID-19's impact. Through literature reviews,
case studies, surveys, and text analysis, it examines art and technology
applications in rural contexts and identifies key challenges. The study finds
artworks often fail to resonate locally, while reliance on external artists
limits sustainability. Hence, nurturing grassroots "artist villagers" through
AI is proposed. Our approach involves training machine learning on subjective
aesthetics to generate culturally relevant content. Interactive AI media can
also boost tourism while preserving heritage. This pioneering research puts
forth original perspectives on the intersection of AI and aesthetics to
invigorate rural culture. It advocates holistic integration of technology and
emphasizes AI's potential as a creative enabler versus replacement. Ultimately,
it lays the groundwork for further exploration of leveraging AI innovations to
empower rural communities. This timely study contributes to growing interest in
emerging technologies to address critical issues facing rural China.
</p>
</div>
</dd>
<dt><a name="item627">[627]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.02137" title="Abstract">arXiv:2309.02137</a> [<a href="/pdf/2309.02137" title="Download PDF">pdf</a>, <a href="/format/2309.02137" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Connectivity and interference in device-to-device networks in  Poisson-Voronoi cities
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Keeler%2C+H+P">H. P. Keeler</a>, 
<a href="/search/cs?searchtype=author&query=B%C5%82aszczyszyn%2C+B">B. B&#x142;aszczyszyn</a>, 
<a href="/search/cs?searchtype=author&query=Cal%2C+E">E. Cal</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>

</div>
<p class="mathjax">To study the overall connectivity in device-to-device networks in cities, we
incorporate a signal-to-interference-plus-noise connectivity model into a
Poisson-Voronoi tessellation model representing the streets of a city. Relays
are located at crossroads (or street intersections), whereas (user) devices are
scattered along streets. Between any two adjacent relays, we assume data can be
transmitted either directly between the relays or through users, given they
share a common street. Our simulation results reveal that the network
connectivity is ensured when the density of users (on the streets) exceeds a
certain critical value. But then the network connectivity disappears when the
user density exceeds a second critical value. The intuition is that for longer
streets, where direct relay-to-relay communication is not possible, users are
needed to transmit data between relays, but with too many users the
interference becomes too strong, eventually reducing the overall network
connectivity. This observation on the user density evokes previous results
based on another wireless network model, where transmitter-receivers were
scattered across the plane. This effect disappears when interference is removed
from the model, giving a variation of the classic Gilbert model and recalling
the lesson that neglecting interference in such network models can give overly
optimistic results. For physically reasonable model parameters, we show that
crowded streets (with more than six users on a typical street) lead to a sudden
drop in connectivity. We also give numerical results outlining a relationship
between the user density and the strength of any interference reduction
techniques.
</p>
</div>
</dd>
<dt><a name="item628">[628]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.02138" title="Abstract">arXiv:2309.02138</a> [<a href="/pdf/2309.02138" title="Download PDF">pdf</a>, <a href="/format/2309.02138" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Generalized Simplicial Attention Neural Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Battiloro%2C+C">Claudio Battiloro</a>, 
<a href="/search/cs?searchtype=author&query=Testa%2C+L">Lucia Testa</a>, 
<a href="/search/cs?searchtype=author&query=Giusti%2C+L">Lorenzo Giusti</a>, 
<a href="/search/cs?searchtype=author&query=Sardellitti%2C+S">Stefania Sardellitti</a>, 
<a href="/search/cs?searchtype=author&query=Di+Lorenzo%2C+P">Paolo Di Lorenzo</a>, 
<a href="/search/cs?searchtype=author&query=Barbarossa%2C+S">Sergio Barbarossa</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: text overlap with <a href="/abs/2203.07485">arXiv:2203.07485</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Algebraic Topology (math.AT)

</div>
<p class="mathjax">The aim of this work is to introduce Generalized Simplicial Attention Neural
Networks (GSANs), i.e., novel neural architectures designed to process data
defined on simplicial complexes using masked self-attentional layers. Hinging
on topological signal processing principles, we devise a series of
self-attention schemes capable of processing data components defined at
different simplicial orders, such as nodes, edges, triangles, and beyond. These
schemes learn how to weight the neighborhoods of the given topological domain
in a task-oriented fashion, leveraging the interplay among simplices of
different orders through the Dirac operator and its Dirac decomposition. We
also theoretically establish that GSANs are permutation equivariant and
simplicial-aware. Finally, we illustrate how our approach compares favorably
with other methods when applied to several (inductive and transductive) tasks
such as trajectory prediction, missing data imputation, graph classification,
and simplex prediction.
</p>
</div>
</dd>
<dt><a name="item629">[629]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.02139" title="Abstract">arXiv:2309.02139</a> [<a href="/pdf/2309.02139" title="Download PDF">pdf</a>, <a href="/format/2309.02139" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Self-Supervised Pre-Training Boosts Semantic Scene Segmentation on LiDAR  data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Car%C3%B3s%2C+M">Mariona Car&#xf3;s</a>, 
<a href="/search/cs?searchtype=author&query=Just%2C+A">Ariadna Just</a>, 
<a href="/search/cs?searchtype=author&query=Segu%C3%AD%2C+S">Santi Segu&#xed;</a>, 
<a href="/search/cs?searchtype=author&query=Vitri%C3%A0%2C+J">Jordi Vitri&#xe0;</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> International conference Machine Vision Applications 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Airborne LiDAR systems have the capability to capture the Earth's surface by
generating extensive point cloud data comprised of points mainly defined by 3D
coordinates. However, labeling such points for supervised learning tasks is
time-consuming. As a result, there is a need to investigate techniques that can
learn from unlabeled data to significantly reduce the number of annotated
samples. In this work, we propose to train a self-supervised encoder with
Barlow Twins and use it as a pre-trained network in the task of semantic scene
segmentation. The experimental results demonstrate that our unsupervised
pre-training boosts performance once fine-tuned on the supervised task,
especially for under-represented categories.
</p>
</div>
</dd>
<dt><a name="item630">[630]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.02142" title="Abstract">arXiv:2309.02142</a> [<a href="/pdf/2309.02142" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Who are the users of ChatGPT? Implications for the digital divide from  web tracking data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kacperski%2C+C">Celina Kacperski</a>, 
<a href="/search/cs?searchtype=author&query=Ulloa%2C+R">Roberto Ulloa</a>, 
<a href="/search/cs?searchtype=author&query=Bonnay%2C+D">Denis Bonnay</a>, 
<a href="/search/cs?searchtype=author&query=Kulshrestha%2C+J">Juhi Kulshrestha</a>, 
<a href="/search/cs?searchtype=author&query=Selb%2C+P">Peter Selb</a>, 
<a href="/search/cs?searchtype=author&query=Spitz%2C+A">Andreas Spitz</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>

</div>
<p class="mathjax">A major challenge of our time is reducing disparities in access to and
effective use of digital technologies, with recent discussions highlighting the
role of AI in exacerbating the digital divide. We examine user characteristics
that predict usage of the AI-powered conversational agent ChatGPT. We combine
web tracking and survey data of N=1068 German citizens to investigate
differences in activity (usage, visits and duration on chat.openai.com). We
examine socio-demographics commonly associated with the digital divide and
explore further socio-political attributes identified via stability selection
in Lasso regressions. We confirm lower age and more education to affect ChatGPT
usage, but not gender and income. We find full-time employment and more
children to be barriers to ChatGPT activity. Rural residence, writing and
social media activities, as well as more political knowledge, were positively
associated with ChatGPT activity. Our research informs efforts to address
digital disparities and promote digital literacy among underserved populations.
</p>
</div>
</dd>
<dt><a name="item631">[631]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.02144" title="Abstract">arXiv:2309.02144</a> [<a href="/pdf/2309.02144" title="Download PDF">pdf</a>, <a href="/format/2309.02144" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Making Large Language Models Better Reasoners with Alignment
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+P">Peiyi Wang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+L">Lei Li</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+L">Liang Chen</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+F">Feifan Song</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+B">Binghuai Lin</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+Y">Yunbo Cao</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+T">Tianyu Liu</a>, 
<a href="/search/cs?searchtype=author&query=Sui%2C+Z">Zhifang Sui</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Large Language Models; Reasoning; Alignment
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Reasoning is a cognitive process of using evidence to reach a sound
conclusion. The reasoning capability is essential for large language models
(LLMs) to serve as the brain of the artificial general intelligence agent.
Recent studies reveal that fine-tuning LLMs on data with the chain of thought
(COT) reasoning process can significantly enhance their reasoning capabilities.
However, we find that the fine-tuned LLMs suffer from an \textit{Assessment
Misalignment} problem, i.e., they frequently assign higher scores to subpar
COTs, leading to potential limitations in their reasoning abilities. To address
this problem, we introduce an \textit{Alignment Fine-Tuning (AFT)} paradigm,
which involves three steps: 1) fine-tuning LLMs with COT training data; 2)
generating multiple COT responses for each question, and categorizing them into
positive and negative ones based on whether they achieve the correct answer; 3)
calibrating the scores of positive and negative responses given by LLMs with a
novel constraint alignment loss. Specifically, the constraint alignment loss
has two objectives: a) Alignment, which guarantees that positive scores surpass
negative scores to encourage answers with high-quality COTs; b) Constraint,
which keeps the negative scores confined to a reasonable range to prevent the
model degradation. Beyond just the binary positive and negative feedback, the
constraint alignment loss can be seamlessly adapted to the ranking situations
when ranking feedback is accessible. Furthermore, we also delve deeply into
recent ranking-based alignment methods, such as DPO, RRHF, and PRO, and
discover that the constraint, which has been overlooked by these approaches, is
also crucial for their performance. Extensive experiments on four reasoning
benchmarks with both binary and ranking feedback demonstrate the effectiveness
of AFT.
</p>
</div>
</dd>
<dt><a name="item632">[632]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.02145" title="Abstract">arXiv:2309.02145</a> [<a href="/pdf/2309.02145" title="Download PDF">pdf</a>, <a href="/format/2309.02145" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Bring the Noise: Introducing Noise Robustness to Pretrained Automatic  Speech Recognition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Eickhoff%2C+P">Patrick Eickhoff</a>, 
<a href="/search/cs?searchtype=author&query=M%C3%B6ller%2C+M">Matthias M&#xf6;ller</a>, 
<a href="/search/cs?searchtype=author&query=Rosin%2C+T+P">Theresa Pekarek Rosin</a>, 
<a href="/search/cs?searchtype=author&query=Twiefel%2C+J">Johannes Twiefel</a>, 
<a href="/search/cs?searchtype=author&query=Wermter%2C+S">Stefan Wermter</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted and accepted for ICANN 2023 (32nd International Conference on Artificial Neural Networks)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Sound (cs.SD); Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">In recent research, in the domain of speech processing, large End-to-End
(E2E) systems for Automatic Speech Recognition (ASR) have reported
state-of-the-art performance on various benchmarks. These systems intrinsically
learn how to handle and remove noise conditions from speech. Previous research
has shown, that it is possible to extract the denoising capabilities of these
models into a preprocessor network, which can be used as a frontend for
downstream ASR models. However, the proposed methods were limited to specific
fully convolutional architectures. In this work, we propose a novel method to
extract the denoising capabilities, that can be applied to any encoder-decoder
architecture. We propose the Cleancoder preprocessor architecture that extracts
hidden activations from the Conformer ASR model and feeds them to a decoder to
predict denoised spectrograms. We train our pre-processor on the Noisy Speech
Database (NSD) to reconstruct denoised spectrograms from noisy inputs. Then, we
evaluate our model as a frontend to a pretrained Conformer ASR model as well as
a frontend to train smaller Conformer ASR models from scratch. We show that the
Cleancoder is able to filter noise from speech and that it improves the total
Word Error Rate (WER) of the downstream model in noisy conditions for both
applications.
</p>
</div>
</dd>
<dt><a name="item633">[633]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.02150" title="Abstract">arXiv:2309.02150</a> [<a href="/pdf/2309.02150" title="Download PDF">pdf</a>, <a href="/format/2309.02150" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Domain Adaptation for Satellite-Borne Hyperspectral Cloud Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Du%2C+A">Andrew Du</a>, 
<a href="/search/cs?searchtype=author&query=Doan%2C+A">Anh-Dzung Doan</a>, 
<a href="/search/cs?searchtype=author&query=Law%2C+Y+W">Yee Wei Law</a>, 
<a href="/search/cs?searchtype=author&query=Chin%2C+T">Tat-Jun Chin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">The advent of satellite-borne machine learning hardware accelerators has
enabled the on-board processing of payload data using machine learning
techniques such as convolutional neural networks (CNN). A notable example is
using a CNN to detect the presence of clouds in hyperspectral data captured on
Earth observation (EO) missions, whereby only clear sky data is downlinked to
conserve bandwidth. However, prior to deployment, new missions that employ new
sensors will not have enough representative datasets to train a CNN model,
while a model trained solely on data from previous missions will underperform
when deployed to process the data on the new missions. This underperformance
stems from the domain gap, i.e., differences in the underlying distributions of
the data generated by the different sensors in previous and future missions. In
this paper, we address the domain gap problem in the context of on-board
hyperspectral cloud detection. Our main contributions lie in formulating new
domain adaptation tasks that are motivated by a concrete EO mission, developing
a novel algorithm for bandwidth-efficient supervised domain adaptation, and
demonstrating test-time adaptation algorithms on space deployable neural
network accelerators. Our contributions enable minimal data transmission to be
invoked (e.g., only 1% of the weights in ResNet50) to achieve domain
adaptation, thereby allowing more sophisticated CNN models to be deployed and
updated on satellites without being hampered by domain gap and bandwidth
limitations.
</p>
</div>
</dd>
<dt><a name="item634">[634]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.02155" title="Abstract">arXiv:2309.02155</a> [<a href="/pdf/2309.02155" title="Download PDF">pdf</a>, <a href="/format/2309.02155" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> S3C: Semi-Supervised VQA Natural Language Explanation via Self-Critical  Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Suo%2C+W">Wei Suo</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+M">Mengyang Sun</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+W">Weisong Liu</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+Y">Yiqi Gao</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+P">Peng Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yanning Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Q">Qi Wu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> CVPR2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">VQA Natural Language Explanation (VQA-NLE) task aims to explain the
decision-making process of VQA models in natural language. Unlike traditional
attention or gradient analysis, free-text rationales can be easier to
understand and gain users' trust. Existing methods mostly use post-hoc or
self-rationalization models to obtain a plausible explanation. However, these
frameworks are bottlenecked by the following challenges: 1) the reasoning
process cannot be faithfully responded to and suffer from the problem of
logical inconsistency. 2) Human-annotated explanations are expensive and
time-consuming to collect. In this paper, we propose a new Semi-Supervised
VQA-NLE via Self-Critical Learning (S3C), which evaluates the candidate
explanations by answering rewards to improve the logical consistency between
answers and rationales. With a semi-supervised learning framework, the S3C can
benefit from a tremendous amount of samples without human-annotated
explanations. A large number of automatic measures and human evaluations all
show the effectiveness of our method. Meanwhile, the framework achieves a new
state-of-the-art performance on the two VQA-NLE datasets.
</p>
</div>
</dd>
<dt><a name="item635">[635]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.02156" title="Abstract">arXiv:2309.02156</a> [<a href="/pdf/2309.02156" title="Download PDF">pdf</a>, <a href="/ps/2309.02156" title="Download PostScript">ps</a>, <a href="/format/2309.02156" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Subspace Acceleration for a Sequence of Linear Systems and Application  to Plasma Simulation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Guido%2C+M">Margherita Guido</a>, 
<a href="/search/math?searchtype=author&query=Kressner%2C+D">Daniel Kressner</a>, 
<a href="/search/math?searchtype=author&query=Ricci%2C+P">Paolo Ricci</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Plasma Physics (physics.plasm-ph)

</div>
<p class="mathjax">We present an acceleration method for sequences of large-scale linear
systems, such as the ones arising from the numerical solution of time-dependent
partial differential equations coupled with algebraic constraints. We discuss
different approaches to leverage the subspace containing the history of
solutions computed at previous time steps in order to generate a good initial
guess for the iterative solver. In particular, we propose a novel combination
of reduced-order projection with randomized linear algebra techniques, which
drastically reduces the number of iterations needed for convergence. We analyze
the accuracy of the initial guess produced by the reduced-order projection when
the coefficients of the linear system depend analytically on time. Extending
extrapolation results by Demanet and Townsend to a vector-valued setting, we
show that the accuracy improves rapidly as the size of the history increases, a
theoretical result confirmed by our numerical observations. In particular, we
apply the developed method to the simulation of plasma turbulence in the
boundary of a fusion device, showing that the time needed for solving the
linear systems is significantly reduced.
</p>
</div>
</dd>
<dt><a name="item636">[636]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.02157" title="Abstract">arXiv:2309.02157</a> [<a href="/pdf/2309.02157" title="Download PDF">pdf</a>, <a href="/format/2309.02157" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Model-based Offline Policy Optimization with Adversarial Network
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+J">Junming Yang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+X">Xingguo Chen</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Shengyuan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+B">Bolei Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by 26th European Conference on Artificial Intelligence ECAI 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Model-based offline reinforcement learning (RL), which builds a supervised
transition model with logging dataset to avoid costly interactions with the
online environment, has been a promising approach for offline policy
optimization. As the discrepancy between the logging data and online
environment may result in a distributional shift problem, many prior works have
studied how to build robust transition models conservatively and estimate the
model uncertainty accurately. However, the over-conservatism can limit the
exploration of the agent, and the uncertainty estimates may be unreliable. In
this work, we propose a novel Model-based Offline policy optimization framework
with Adversarial Network (MOAN). The key idea is to use adversarial learning to
build a transition model with better generalization, where an adversary is
introduced to distinguish between in-distribution and out-of-distribution
samples. Moreover, the adversary can naturally provide a quantification of the
model's uncertainty with theoretical guarantees. Extensive experiments showed
that our approach outperforms existing state-of-the-art baselines on widely
studied offline RL benchmarks. It can also generate diverse in-distribution
samples, and quantify the uncertainty more accurately.
</p>
</div>
</dd>
<dt><a name="item637">[637]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.02158" title="Abstract">arXiv:2309.02158</a> [<a href="/pdf/2309.02158" title="Download PDF">pdf</a>, <a href="/format/2309.02158" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Traffic Light Recognition using Convolutional Neural Networks: A Survey
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pavlitska%2C+S">Svetlana Pavlitska</a>, 
<a href="/search/cs?searchtype=author&query=Lambing%2C+N">Nico Lambing</a>, 
<a href="/search/cs?searchtype=author&query=Bangaru%2C+A+K">Ashok Kumar Bangaru</a>, 
<a href="/search/cs?searchtype=author&query=Z%C3%B6llner%2C+J+M">J. Marius Z&#xf6;llner</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted for publication at ITSC2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Robotics (cs.RO)

</div>
<p class="mathjax">Real-time traffic light recognition is essential for autonomous driving. Yet,
a cohesive overview of the underlying model architectures for this task is
currently missing. In this work, we conduct a comprehensive survey and analysis
of traffic light recognition methods that use convolutional neural networks
(CNNs). We focus on two essential aspects: datasets and CNN architectures.
Based on an underlying architecture, we cluster methods into three major
groups: (1) modifications of generic object detectors which compensate for
specific task characteristics, (2) multi-stage approaches involving both
rule-based and CNN components, and (3) task-specific single-stage methods. We
describe the most important works in each cluster, discuss the usage of the
datasets, and identify research gaps.
</p>
</div>
</dd>
<dt><a name="item638">[638]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.02159" title="Abstract">arXiv:2309.02159</a> [<a href="/pdf/2309.02159" title="Download PDF">pdf</a>, <a href="/format/2309.02159" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Adversarial Implications of Variable-Time Inference
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Biton%2C+D">Dudi Biton</a>, 
<a href="/search/cs?searchtype=author&query=Misra%2C+A">Aditi Misra</a>, 
<a href="/search/cs?searchtype=author&query=Levy%2C+E">Efrat Levy</a>, 
<a href="/search/cs?searchtype=author&query=Kotak%2C+J">Jaidip Kotak</a>, 
<a href="/search/cs?searchtype=author&query=Bitton%2C+R">Ron Bitton</a>, 
<a href="/search/cs?searchtype=author&query=Schuster%2C+R">Roei Schuster</a>, 
<a href="/search/cs?searchtype=author&query=Papernot%2C+N">Nicolas Papernot</a>, 
<a href="/search/cs?searchtype=author&query=Elovici%2C+Y">Yuval Elovici</a>, 
<a href="/search/cs?searchtype=author&query=Nassi%2C+B">Ben Nassi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Machine learning (ML) models are known to be vulnerable to a number of
attacks that target the integrity of their predictions or the privacy of their
training data. To carry out these attacks, a black-box adversary must typically
possess the ability to query the model and observe its outputs (e.g., labels).
In this work, we demonstrate, for the first time, the ability to enhance such
decision-based attacks. To accomplish this, we present an approach that
exploits a novel side channel in which the adversary simply measures the
execution time of the algorithm used to post-process the predictions of the ML
model under attack. The leakage of inference-state elements into algorithmic
timing side channels has never been studied before, and we have found that it
can contain rich information that facilitates superior timing attacks that
significantly outperform attacks based solely on label outputs. In a case
study, we investigate leakage from the non-maximum suppression (NMS) algorithm,
which plays a crucial role in the operation of object detectors. In our
examination of the timing side-channel vulnerabilities associated with this
algorithm, we identified the potential to enhance decision-based attacks. We
demonstrate attacks against the YOLOv3 detector, leveraging the timing leakage
to successfully evade object detection using adversarial examples, and perform
dataset inference. Our experiments show that our adversarial examples exhibit
superior perturbation quality compared to a decision-based attack. In addition,
we present a new threat model in which dataset inference based solely on timing
leakage is performed. To address the timing leakage vulnerability inherent in
the NMS algorithm, we explore the potential and limitations of implementing
constant-time inference passes as a mitigation strategy.
</p>
</div>
</dd>
<dt><a name="item639">[639]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.02160" title="Abstract">arXiv:2309.02160</a> [<a href="/pdf/2309.02160" title="Download PDF">pdf</a>, <a href="/format/2309.02160" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Bias Propagation in Federated Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chang%2C+H">Hongyan Chang</a>, 
<a href="/search/cs?searchtype=author&query=Shokri%2C+R">Reza Shokri</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> The Eleventh International Conference on Learning Representations,
  2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computers and Society (cs.CY); Machine Learning (stat.ML)

</div>
<p class="mathjax">We show that participating in federated learning can be detrimental to group
fairness. In fact, the bias of a few parties against under-represented groups
(identified by sensitive attributes such as gender or race) can propagate
through the network to all the parties in the network. We analyze and explain
bias propagation in federated learning on naturally partitioned real-world
datasets. Our analysis reveals that biased parties unintentionally yet
stealthily encode their bias in a small number of model parameters, and
throughout the training, they steadily increase the dependence of the global
model on sensitive attributes. What is important to highlight is that the
experienced bias in federated learning is higher than what parties would
otherwise encounter in centralized training with a model trained on the union
of all their data. This indicates that the bias is due to the algorithm. Our
work calls for auditing group fairness in federated learning and designing
learning algorithms that are robust to bias propagation.
</p>
</div>
</dd>
<dt><a name="item640">[640]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.02162" title="Abstract">arXiv:2309.02162</a> [<a href="/pdf/2309.02162" title="Download PDF">pdf</a>, <a href="/format/2309.02162" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Advancing Text-to-GLOSS Neural Translation Using a Novel Hyper-parameter  Optimization Technique
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ouargani%2C+Y">Younes Ouargani</a>, 
<a href="/search/cs?searchtype=author&query=Khattabi%2C+N+E">Noussaima El Khattabi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">In this paper, we investigate the use of transformers for Neural Machine
Translation of text-to-GLOSS for Deaf and Hard-of-Hearing communication. Due to
the scarcity of available data and limited resources for text-to-GLOSS
translation, we treat the problem as a low-resource language task. We use our
novel hyper-parameter exploration technique to explore a variety of
architectural parameters and build an optimal transformer-based architecture
specifically tailored for text-to-GLOSS translation. The study aims to improve
the accuracy and fluency of Neural Machine Translation generated GLOSS. This is
achieved by examining various architectural parameters including layer count,
attention heads, embedding dimension, dropout, and label smoothing to identify
the optimal architecture for improving text-to-GLOSS translation performance.
The experiments conducted on the PHOENIX14T dataset reveal that the optimal
transformer architecture outperforms previous work on the same dataset. The
best model reaches a ROUGE (Recall-Oriented Understudy for Gisting Evaluation)
score of 55.18% and a BLEU-1 (BiLingual Evaluation Understudy 1) score of
63.6%, outperforming state-of-the-art results on the BLEU1 and ROUGE score by
8.42 and 0.63 respectively.
</p>
</div>
</dd>
<dt><a name="item641">[641]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.02165" title="Abstract">arXiv:2309.02165</a> [<a href="/pdf/2309.02165" title="Download PDF">pdf</a>, <a href="/format/2309.02165" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PCFGaze: Physics-Consistent Feature for Appearance-based Gaze Estimation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bao%2C+Y">Yiwei Bao</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+F">Feng Lu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Although recent deep learning based gaze estimation approaches have achieved
much improvement, we still know little about how gaze features are connected to
the physics of gaze. In this paper, we try to answer this question by analyzing
the gaze feature manifold. Our analysis revealed the insight that the geodesic
distance between gaze features is consistent with the gaze differences between
samples. According to this finding, we construct the Physics- Consistent
Feature (PCF) in an analytical way, which connects gaze feature to the physical
definition of gaze. We further propose the PCFGaze framework that directly
optimizes gaze feature space by the guidance of PCF. Experimental results
demonstrate that the proposed framework alleviates the overfitting problem and
significantly improves cross-domain gaze estimation accuracy without extra
training data. The insight of gaze feature has the potential to benefit other
regression tasks with physical meanings.
</p>
</div>
</dd>
<dt><a name="item642">[642]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.02168" title="Abstract">arXiv:2309.02168</a> [<a href="/pdf/2309.02168" title="Download PDF">pdf</a>, <a href="/format/2309.02168" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Impact of SAR-ADC Mismatch on Quantized Massive MU-MIMO Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Guichemerre%2C+J">J&#xe9;r&#xe9;my Guichemerre</a>, 
<a href="/search/cs?searchtype=author&query=Studer%2C+C">Christoph Studer</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To be presented at Asilomar Conference on Signals, Systems, and Computers 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">Low-resolution analog-to-digital converters (ADCs) in massive multi-user (MU)
multiple-input multiple-output (MIMO) wireless systems can significantly reduce
the power, cost, and interconnect data rates of infrastructure basestations.
Thus, recent research on the theory and algorithm sides has extensively focused
on such architectures, but with idealistic quantization models. However,
real-world ADCs do not behave like ideal quantizers, and are affected by
fabrication mismatches. We analyze the impact of capacitor-array mismatches in
successive approximation register (SAR) ADCs, which are widely used in wireless
systems. We use Bussgang's decomposition to model the effects of such
mismatches, and we analyze their impact on the performance of a single ADC. We
then simulate a massive MU-MIMO system to demonstrate that capacitor mismatches
should not be ignored, even in basestations that use low-resolution SAR ADCs.
</p>
</div>
</dd>
<dt><a name="item643">[643]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.02169" title="Abstract">arXiv:2309.02169</a> [<a href="/pdf/2309.02169" title="Download PDF">pdf</a>, <a href="/format/2309.02169" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Dual Relation Alignment for Composed Image Retrieval
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jiang%2C+X">Xintong Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yaxiong Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Y">Yujiao Wu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+M">Meng Wang</a>, 
<a href="/search/cs?searchtype=author&query=Qian%2C+X">Xueming Qian</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Composed image retrieval, a task involving the search for a target image
using a reference image and a complementary text as the query, has witnessed
significant advancements owing to the progress made in cross-modal modeling.
Unlike the general image-text retrieval problem with only one alignment
relation, i.e., image-text, we argue for the existence of two types of
relations in composed image retrieval. The explicit relation pertains to the
reference image &amp; complementary text-target image, which is commonly exploited
by existing methods. Besides this intuitive relation, the observations during
our practice have uncovered another implicit yet crucial relation, i.e.,
reference image &amp; target image-complementary text, since we found that the
complementary text can be inferred by studying the relation between the target
image and the reference image. Regrettably, existing methods largely focus on
leveraging the explicit relation to learn their networks, while overlooking the
implicit relation. In response to this weakness, We propose a new framework for
composed image retrieval, termed dual relation alignment, which integrates both
explicit and implicit relations to fully exploit the correlations among the
triplets. Specifically, we design a vision compositor to fuse reference image
and target image at first, then the resulted representation will serve two
roles: (1) counterpart for semantic alignment with the complementary text and
(2) compensation for the complementary text to boost the explicit relation
modeling, thereby implant the implicit relation into the alignment learning.
Our method is evaluated on two popular datasets, CIRR and FashionIQ, through
extensive experiments. The results confirm the effectiveness of our
dual-relation learning in substantially enhancing composed image retrieval
performance.
</p>
</div>
</dd>
<dt><a name="item644">[644]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.02171" title="Abstract">arXiv:2309.02171</a> [<a href="/pdf/2309.02171" title="Download PDF">pdf</a>, <a href="/format/2309.02171" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Wideband MIMO Channel Model for Aerial Intelligent Reflecting  Surface-Assisted Wireless Communications
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+S">Shaoyi Liu</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+N">Nan Ma</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yaning Chen</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+K">Ke Peng</a>, 
<a href="/search/cs?searchtype=author&query=Xue%2C+D">Dongsheng Xue</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages, 7 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">Compared to traditional intelligent reflecting surfaces(IRS), aerial IRS
(AIRS) has unique advantages, such as more flexible deployment and wider
service coverage. However, modeling AIRS in the channel presents new challenges
due to their mobility. In this paper, a three-dimensional (3D) wideband channel
model for AIRS and IRS joint-assisted multiple-input multiple-output (MIMO)
communication system is proposed, where considering the rotational degrees of
freedom in three directions and the motion angles of AIRS in space. Based on
the proposed model, the channel impulse response (CIR), correlation function,
and channel capacity are derived, and several feasible joint phase shifts
schemes for AIRS and IRS units are proposed. Simulation results show that the
proposed model can capture the channel characteristics accurately, and the
proposed phase shifts methods can effectively improve the channel statistical
characteristics and increase the system capacity. Additionally, we observe that
in certain scenarios, the paths involving the IRS and the line-of-sight (LoS)
paths exhibit similar characteristics. These findings provide valuable insights
for the future development of intelligent communication systems.
</p>
</div>
</dd>
<dt><a name="item645">[645]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.02172" title="Abstract">arXiv:2309.02172</a> [<a href="/pdf/2309.02172" title="Download PDF">pdf</a>, <a href="/format/2309.02172" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Orchestration in the Cloud-to-Things Compute Continuum: Taxonomy, Survey  and Future Directions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ullah%2C+A">Amjad Ullah</a>, 
<a href="/search/cs?searchtype=author&query=Kiss%2C+T">Tamas Kiss</a>, 
<a href="/search/cs?searchtype=author&query=Kov%C3%A1cs%2C+J">J&#xf3;zsef Kov&#xe1;cs</a>, 
<a href="/search/cs?searchtype=author&query=Tusa%2C+F">Francesco Tusa</a>, 
<a href="/search/cs?searchtype=author&query=Deslauriers%2C+J">James Deslauriers</a>, 
<a href="/search/cs?searchtype=author&query=Dagdeviren%2C+H">Huseyin Dagdeviren</a>, 
<a href="/search/cs?searchtype=author&query=Arjun%2C+R">Resmi Arjun</a>, 
<a href="/search/cs?searchtype=author&query=Hamzeh%2C+H">Hamed Hamzeh</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Journal of Cloud Computing Pages: 27
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>

</div>
<p class="mathjax">IoT systems are becoming an essential part of our environment. Smart cities,
smart manufacturing, augmented reality, and self-driving cars are just some
examples of the wide range of domains, where the applicability of such systems
has been increasing rapidly. These IoT use cases often require simultaneous
access to geographically distributed arrays of sensors, and heterogeneous
remote, local as well as multi-cloud computational resources. This gives birth
to the extended Cloud-to-Things computing paradigm. The emergence of this new
paradigm raised the quintessential need to extend the orchestration
requirements i.e., the automated deployment and run-time management) of
applications from the centralised cloud-only environment to the entire spectrum
of resources in the Cloud-to-Things continuum. In order to cope with this
requirement, in the last few years, there has been a lot of attention to the
development of orchestration systems in both industry and academic
environments. This paper is an attempt to gather the research conducted in the
orchestration for the Cloud-to-Things continuum landscape and to propose a
detailed taxonomy, which is then used to critically review the landscape of
existing research work. We finally discuss the key challenges that require
further attention and also present a conceptual framework based on the
conducted analysis.
</p>
</div>
</dd>
<dt><a name="item646">[646]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.02173" title="Abstract">arXiv:2309.02173</a> [<a href="/pdf/2309.02173" title="Download PDF">pdf</a>, <a href="/ps/2309.02173" title="Download PostScript">ps</a>, <a href="/format/2309.02173" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Blockchain-assisted Twin Migration for Vehicular Metaverses: A Game  Theory Approach
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhong%2C+Y">Yue Zhong</a>, 
<a href="/search/cs?searchtype=author&query=Wen%2C+J">Jinbo Wen</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Junhong Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Kang%2C+J">Jiawen Kang</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+Y">Yuna Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+Y">Yanyu Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Tong%2C+Y">Yongju Tong</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Transactions on Emerging Telecommunications Technologies (ISSN: 2161-3915)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>

</div>
<p class="mathjax">As the fusion of automotive industry and metaverse, vehicular metaverses
establish a bridge between the physical space and virtual space, providing
intelligent transportation services through the integration of various
technologies, such as extended reality and real-time rendering technologies, to
offer immersive metaverse services for Vehicular Metaverse Users (VMUs). In
vehicular metaverses, VMUs update vehicle twins (VTs) deployed in RoadSide
Units (RSUs) to obtain metaverse services. However, due to the mobility of
vehicles and the limited service coverage of RSUs, VT migration is necessary to
ensure continuous immersive experiences for VMUs. This process requires RSUs to
contribute resources for enabling efficient migration, which leads to a
resource trading problem between RSUs and VMUs. Moreover, a single RSU cannot
support large-scale VT migration. To this end, we propose a blockchain-assisted
game approach framework for reliable VT migration in vehicular metaverses.
Based on the subject logic model, we first calculate the reputation values of
RSUs considering the freshness of interaction between RSUs and VMUs. Then, a
coalition game based on the reputation values of RSUs is formulated, and RSU
coalitions are formed to jointly provide bandwidth resources for reliable and
large-scale VT migration. Subsequently, the RSU coalition with the highest
utility is selected. Finally, to incentivize VMUs to participate in VT
migration, we propose a Stackelberg model between the selected coalition and
VMUs. Numerical results demonstrate the reliability and effectiveness of the
proposed schemes.
</p>
</div>
</dd>
<dt><a name="item647">[647]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.02175" title="Abstract">arXiv:2309.02175</a> [<a href="/pdf/2309.02175" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Collaboration Conundrum: Synchrony-Cooperation Trade-off
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=David-Barrett%2C+T">Tamas David-Barrett</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 21 pages, 7 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>; Physics and Society (physics.soc-ph)

</div>
<p class="mathjax">In large groups, every collaborative act requires balancing two pressures:
the need to achieve behavioural synchrony and the need to keep free riding to a
minimum. This paper introduces a model of collaboration that requires both
synchronisation on a social network and costly cooperation. The results show
that coordination slows, and cooperativeness increases with the social
network`s local integratedness, measured by the clustering coefficient. That
is, in a large-group collaboration, achieving behavioural synchrony and
strategic cooperation are in opposition to each other. The optimal clustering
coefficient has no natural state in our species, and is determined by the
ecological environment, the group`s technology set, and the group`s size. This
opens the space for social technologies that solve this optimisation problem by
generating optimal social network structures.
</p>
</div>
</dd>
<dt><a name="item648">[648]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.02177" title="Abstract">arXiv:2309.02177</a> [<a href="/pdf/2309.02177" title="Download PDF">pdf</a>, <a href="/ps/2309.02177" title="Download PostScript">ps</a>, <a href="/format/2309.02177" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Quantitative Method to Determine What Collisions Are Reasonably  Foreseeable and Preventable
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=de+Gelder%2C+E">Erwin de Gelder</a>, 
<a href="/search/cs?searchtype=author&query=Camp%2C+O+O+d">Olaf Op den Camp</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 25 pages, 9 figures, 2 tables
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Safety Science, Volume 167, 2023, 106233
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">The development of Automated Driving Systems (ADSs) has made significant
progress in the last years. To enable the deployment of Automated Vehicles
(AVs) equipped with such ADSs, regulations concerning the approval of these
systems need to be established. In 2021, the World Forum for Harmonization of
Vehicle Regulations has approved a new United Nations regulation concerning the
approval of Automated Lane Keeping Systems (ALKSs). An important aspect of this
regulation is that "the activated system shall not cause any collisions that
are reasonably foreseeable and preventable." The phrasing of "reasonably
foreseeable and preventable" might be subjected to different interpretations
and, therefore, this might result in disagreements among AV developers and the
authorities that are requested to approve AVs.
<br />The objective of this work is to propose a method for quantifying what is
"reasonably foreseeable and preventable". The proposed method considers the
Operational Design Domain (ODD) of the system and can be applied to any ODD.
Having a quantitative method for determining what is reasonably foreseeable and
preventable provides developers, authorities, and the users of ADSs a better
understanding of the residual risks to be expected when deploying these systems
in real traffic.
<br />Using our proposed method, we can estimate what collisions are reasonably
foreseeable and preventable. This will help in setting requirements regarding
the safety of ADSs and can lead to stronger justification for design decisions
and test coverage for developing ADSs.
</p>
</div>
</dd>
<dt><a name="item649">[649]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.02182" title="Abstract">arXiv:2309.02182</a> [<a href="/pdf/2309.02182" title="Download PDF">pdf</a>, <a href="/format/2309.02182" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Using a Nearest-Neighbour, BERT-Based Approach for Scalable Clone  Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chochlov%2C+M">Muslim Chochlov</a> (1), 
<a href="/search/cs?searchtype=author&query=Ahmed%2C+G+A">Gul Aftab Ahmed</a> (2), 
<a href="/search/cs?searchtype=author&query=Patten%2C+J+V">James Vincent Patten</a> (1), 
<a href="/search/cs?searchtype=author&query=Lu%2C+G">Guoxian Lu</a> (3), 
<a href="/search/cs?searchtype=author&query=Hou%2C+W">Wei Hou</a> (4), 
<a href="/search/cs?searchtype=author&query=Gregg%2C+D">David Gregg</a> (2), 
<a href="/search/cs?searchtype=author&query=Buckley%2C+J">Jim Buckley</a> (1) ((1) Deptment of Computer Science and Information Systems, University of Limerick, Ireland, (2) Deptment of Computer Science, Trinity College Dublin, Ireland, (3) WN Digital IPD and Trustworthiness Enabling, Huawei Technologies Co., Ltd., Shanghai, China, (4) Huawei Vulnerability Management Center, Huawei Technologies Co., Ltd., Shenzhen, Guangdong, China)
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 2 figures, 38th IEEE International Conference on Software Maintenance and Evolution
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
<p class="mathjax">Code clones can detrimentally impact software maintenance and manually
detecting them in very large codebases is impractical. Additionally, automated
approaches find detection of Type 3 and Type 4 (inexact) clones very
challenging. While the most recent artificial deep neural networks (for example
BERT-based artificial neural networks) seem to be highly effective in detecting
such clones, their pairwise comparison of every code pair in the target
system(s) is inefficient and scales poorly on large codebases.
<br />We therefore introduce SSCD, a BERT-based clone detection approach that
targets high recall of Type 3 and Type 4 clones at scale (in line with our
industrial partner's requirements). It does so by computing a representative
embedding for each code fragment and finding similar fragments using a nearest
neighbour search. SSCD thus avoids the pairwise-comparison bottleneck of other
Neural Network approaches while also using parallel, GPU-accelerated search to
tackle scalability.
<br />This paper details the approach and an empirical assessment towards
configuring and evaluating that approach in industrial setting. The
configuration analysis suggests that shorter input lengths and text-only based
neural network models demonstrate better efficiency in SSCD, while only
slightly decreasing effectiveness. The evaluation results suggest that SSCD is
more effective than state-of-the-art approaches like SAGA and SourcererCC. It
is also highly efficient: in its optimal setting, SSCD effectively locates
clones in the entire 320 million LOC BigCloneBench (a standard clone detection
benchmark) in just under three hours.
</p>
</div>
</dd>
<dt><a name="item650">[650]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.02184" title="Abstract">arXiv:2309.02184</a> [<a href="/pdf/2309.02184" title="Download PDF">pdf</a>, <a href="/format/2309.02184" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Integral equation methods for acoustic scattering by fractals
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Caetano%2C+A+M">A. M. Caetano</a>, 
<a href="/search/math?searchtype=author&query=Chandler-Wilde%2C+S+N">S. N. Chandler-Wilde</a>, 
<a href="/search/math?searchtype=author&query=Claeys%2C+X">X. Claeys</a>, 
<a href="/search/math?searchtype=author&query=Gibbs%2C+A">A. Gibbs</a>, 
<a href="/search/math?searchtype=author&query=Hewett%2C+D+P">D. P. Hewett</a>, 
<a href="/search/math?searchtype=author&query=Moiola%2C+A">A. Moiola</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">We study sound-soft time-harmonic acoustic scattering by general scatterers,
including fractal scatterers, in 2D and 3D space. For an arbitrary compact
scatterer $\Gamma$ we reformulate the Dirichlet boundary value problem for the
Helmholtz equation as a first kind integral equation (IE) on $\Gamma$ involving
the Newton potential. The IE is well-posed, except possibly at a countable set
of frequencies, and reduces to existing single-layer boundary IEs when $\Gamma$
is the boundary of a bounded Lipschitz open set, a screen, or a multi-screen.
When $\Gamma$ is uniformly of $d$-dimensional Hausdorff dimension in a sense we
make precise (a $d$-set), the operator in our equation is an integral operator
on $\Gamma$ with respect to $d$-dimensional Hausdorff measure, with kernel the
Helmholtz fundamental solution, and we propose a piecewise-constant Galerkin
discretization of the IE, which converges in the limit of vanishing mesh width.
When $\Gamma$ is the fractal attractor of an iterated function system of
contracting similarities we prove convergence rates under assumptions on
$\Gamma$ and the IE solution, and describe a fully discrete implementation
using recently proposed quadrature rules for singular integrals on fractals. We
present numerical results for a range of examples and make our software
available as a Julia code.
</p>
</div>
</dd>
<dt><a name="item651">[651]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.02185" title="Abstract">arXiv:2309.02185</a> [<a href="/pdf/2309.02185" title="Download PDF">pdf</a>, <a href="/format/2309.02185" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> BEVTrack: A Simple Baseline for Point Cloud Tracking in Bird&#x27;s-Eye-View
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yuxiang Yang</a>, 
<a href="/search/cs?searchtype=author&query=Deng%2C+Y">Yingqi Deng</a>, 
<a href="/search/cs?searchtype=author&query=Nie%2C+J">Jiahao Nie</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jing Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Technical report. Work in progress. The code will be released at <a href="https://github.com/xmm-prio/BEVTrack">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">3D single object tracking (SOT) in point clouds is still a challenging
problem due to appearance variation, distractors, and high sparsity of point
clouds. Notably, in autonomous driving scenarios, the target object typically
maintains spatial adjacency across consecutive frames, predominantly moving
horizontally. This spatial continuity offers valuable prior knowledge for
target localization. However, existing trackers, which often employ point-wise
representations, struggle to efficiently utilize this knowledge owing to the
irregular format of such representations. Consequently, they require elaborate
designs and solving multiple subtasks to establish spatial correspondence. In
this paper, we introduce BEVTrack, a simple yet strong baseline framework for
3D SOT. After converting consecutive point clouds into the common
Bird's-Eye-View representation, BEVTrack inherently encodes spatial proximity
and adeptly captures motion cues for tracking via a simple element-wise
operation and convolutional layers. Additionally, to better deal with objects
having diverse sizes and moving patterns, BEVTrack directly learns the
underlying motion distribution rather than making a fixed Laplacian or Gaussian
assumption as in previous works. Without bells and whistles, BEVTrack achieves
state-of-the-art performance on KITTI and NuScenes datasets while maintaining a
high inference speed of 122 FPS. The code will be released at
https://github.com/xmm-prio/BEVTrack.
</p>
</div>
</dd>
<dt><a name="item652">[652]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.02186" title="Abstract">arXiv:2309.02186</a> [<a href="/pdf/2309.02186" title="Download PDF">pdf</a>, <a href="/format/2309.02186" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AniPortraitGAN: Animatable 3D Portrait Generation from 2D Image  Collections
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+Y">Yue Wu</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+S">Sicheng Xu</a>, 
<a href="/search/cs?searchtype=author&query=Xiang%2C+J">Jianfeng Xiang</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+F">Fangyun Wei</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Q">Qifeng Chen</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+J">Jiaolong Yang</a>, 
<a href="/search/cs?searchtype=author&query=Tong%2C+X">Xin Tong</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> SIGGRAPH Asia 2023. Project Page: <a href="https://yuewuhkust.github.io/AniPortraitGAN/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Graphics (cs.GR)

</div>
<p class="mathjax">Previous animatable 3D-aware GANs for human generation have primarily focused
on either the human head or full body. However, head-only videos are relatively
uncommon in real life, and full body generation typically does not deal with
facial expression control and still has challenges in generating high-quality
results. Towards applicable video avatars, we present an animatable 3D-aware
GAN that generates portrait images with controllable facial expression, head
pose, and shoulder movements. It is a generative model trained on unstructured
2D image collections without using 3D or video data. For the new task, we base
our method on the generative radiance manifold representation and equip it with
learnable facial and head-shoulder deformations. A dual-camera rendering and
adversarial learning scheme is proposed to improve the quality of the generated
faces, which is critical for portrait images. A pose deformation processing
network is developed to generate plausible deformations for challenging regions
such as long hair. Experiments show that our method, trained on unstructured 2D
images, can generate diverse and high-quality 3D portraits with desired control
over different properties.
</p>
</div>
</dd>
<dt><a name="item653">[653]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.02188" title="Abstract">arXiv:2309.02188</a> [<a href="/pdf/2309.02188" title="Download PDF">pdf</a>, <a href="/format/2309.02188" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Incorporating Dictionaries into a Neural Network Architecture to Extract  COVID-19 Medical Concepts From Social Media
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hasan%2C+A">Abul Hasan</a>, 
<a href="/search/cs?searchtype=author&query=Levene%2C+M">Mark Levene</a>, 
<a href="/search/cs?searchtype=author&query=Weston%2C+D">David Weston</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Social and Information Networks (cs.SI)

</div>
<p class="mathjax">We investigate the potential benefit of incorporating dictionary information
into a neural network architecture for natural language processing. In
particular, we make use of this architecture to extract several concepts
related to COVID-19 from an on-line medical forum. We use a sample from the
forum to manually curate one dictionary for each concept. In addition, we use
MetaMap, which is a tool for extracting biomedical concepts, to identify a
small number of semantic concepts. For a supervised concept extraction task on
the forum data, our best model achieved a macro $F_1$ score of 90\%. A major
difficulty in medical concept extraction is obtaining labelled data from which
to build supervised models. We investigate the utility of our models to
transfer to data derived from a different source in two ways. First for
producing labels via weak learning and second to perform concept extraction.
The dataset we use in this case comprises COVID-19 related tweets and we
achieve an $F_1$ score 81\% for symptom concept extraction trained on weakly
labelled data. The utility of our dictionaries is compared with a COVID-19
symptom dictionary that was constructed directly from Twitter. Further
experiments that incorporate BERT and a COVID-19 version of BERTweet
demonstrate that the dictionaries provide a commensurate result. Our results
show that incorporating small domain dictionaries to deep learning models can
improve concept extraction tasks. Moreover, models built using dictionaries
generalize well and are transferable to different datasets on a similar task.
</p>
</div>
</dd>
<dt><a name="item654">[654]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.02189" title="Abstract">arXiv:2309.02189</a> [<a href="/pdf/2309.02189" title="Download PDF">pdf</a>, <a href="/format/2309.02189" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Leveraging BERT Language Models for Multi-Lingual ESG Issue  Identification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pontes%2C+E+L">Elvys Linhares Pontes</a>, 
<a href="/search/cs?searchtype=author&query=Benjannet%2C+M">Mohamed Benjannet</a>, 
<a href="/search/cs?searchtype=author&query=Ming%2C+L+K">Lam Kim Ming</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Environmental, Social, and Governance (ESG) has been used as a metric to
measure the negative impacts and enhance positive outcomes of companies in
areas such as the environment, society, and governance. Recently, investors
have increasingly recognized the significance of ESG criteria in their
investment choices, leading businesses to integrate ESG principles into their
operations and strategies. The Multi-Lingual ESG Issue Identification (ML-ESG)
shared task encompasses the classification of news documents into 35 distinct
ESG issue labels. In this study, we explored multiple strategies harnessing
BERT language models to achieve accurate classification of news documents
across these labels. Our analysis revealed that the RoBERTa classifier emerged
as one of the most successful approaches, securing the second-place position
for the English test dataset, and sharing the fifth-place position for the
French test dataset. Furthermore, our SVM-based binary model tailored for the
Chinese language exhibited exceptional performance, earning the second-place
rank on the test dataset.
</p>
</div>
</dd>
<dt><a name="item655">[655]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.02190" title="Abstract">arXiv:2309.02190</a> [<a href="/pdf/2309.02190" title="Download PDF">pdf</a>, <a href="/format/2309.02190" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exchanging-based Multimodal Fusion with Transformer
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhu%2C+R">Renyu Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+C">Chengcheng Han</a>, 
<a href="/search/cs?searchtype=author&query=Qian%2C+Y">Yong Qian</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+Q">Qiushi Sun</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xiang Li</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+M">Ming Gao</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+X">Xuezhi Cao</a>, 
<a href="/search/cs?searchtype=author&query=Xian%2C+Y">Yunsen Xian</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">We study the problem of multimodal fusion in this paper. Recent
exchanging-based methods have been proposed for vision-vision fusion, which aim
to exchange embeddings learned from one modality to the other. However, most of
them project inputs of multimodalities into different low-dimensional spaces
and cannot be applied to the sequential input data. To solve these issues, in
this paper, we propose a novel exchanging-based multimodal fusion model MuSE
for text-vision fusion based on Transformer. We first use two encoders to
separately map multimodal inputs into different low-dimensional spaces. Then we
employ two decoders to regularize the embeddings and pull them into the same
space. The two decoders capture the correlations between texts and images with
the image captioning task and the text-to-image generation task, respectively.
Further, based on the regularized embeddings, we present CrossTransformer,
which uses two Transformer encoders with shared parameters as the backbone
model to exchange knowledge between multimodalities. Specifically,
CrossTransformer first learns the global contextual information of the inputs
in the shallow layers. After that, it performs inter-modal exchange by
selecting a proportion of tokens in one modality and replacing their embeddings
with the average of embeddings in the other modality. We conduct extensive
experiments to evaluate the performance of MuSE on the Multimodal Named Entity
Recognition task and the Multimodal Sentiment Analysis task. Our results show
the superiority of MuSE against other competitors. Our code and data are
provided at https://github.com/RecklessRonan/MuSE.
</p>
</div>
</dd>
<dt><a name="item656">[656]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.02193" title="Abstract">arXiv:2309.02193</a> [<a href="/pdf/2309.02193" title="Download PDF">pdf</a>, <a href="/format/2309.02193" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Personalized Federated Deep Reinforcement Learning-based Trajectory  Optimization for Multi-UAV Assisted Edge Computing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Song%2C+Z">Zhengrong Song</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+C">Chuan Ma</a>, 
<a href="/search/cs?searchtype=author&query=Ding%2C+M">Ming Ding</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+H+H">Howard H. Yang</a>, 
<a href="/search/cs?searchtype=author&query=Qian%2C+Y">Yuwen Qian</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+X">Xiangwei Zhou</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Multiagent Systems (cs.MA)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">In the era of 5G mobile communication, there has been a significant surge in
research focused on unmanned aerial vehicles (UAVs) and mobile edge computing
technology. UAVs can serve as intelligent servers in edge computing
environments, optimizing their flight trajectories to maximize communication
system throughput. Deep reinforcement learning (DRL)-based trajectory
optimization algorithms may suffer from poor training performance due to
intricate terrain features and inadequate training data. To overcome this
limitation, some studies have proposed leveraging federated learning (FL) to
mitigate the data isolation problem and expedite convergence. Nevertheless, the
efficacy of global FL models can be negatively impacted by the high
heterogeneity of local data, which could potentially impede the training
process and even compromise the performance of local agents. This work proposes
a novel solution to address these challenges, namely personalized federated
deep reinforcement learning (PF-DRL), for multi-UAV trajectory optimization.
PF-DRL aims to develop individualized models for each agent to address the data
scarcity issue and mitigate the negative impact of data heterogeneity.
Simulation results demonstrate that the proposed algorithm achieves superior
training performance with faster convergence rates, and improves service
quality compared to other DRL-based approaches.
</p>
</div>
</dd>
<dt><a name="item657">[657]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.02197" title="Abstract">arXiv:2309.02197</a> [<a href="/pdf/2309.02197" title="Download PDF">pdf</a>, <a href="/format/2309.02197" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Delving into Ipsilateral Mammogram Assessment under Multi-View Network
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Truong%2C+T+N+T">Thai Ngoc Toan Truong</a>, 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+T">Thanh-Huy Nguyen</a>, 
<a href="/search/cs?searchtype=author&query=Lam%2C+B+T">Ba Thinh Lam</a>, 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+V+M+D">Vu Minh Duy Nguyen</a>, 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+H+P">Hong Phuc Nguyen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">In many recent years, multi-view mammogram analysis has been focused widely
on AI-based cancer assessment. In this work, we aim to explore diverse fusion
strategies (average and concatenate) and examine the model's learning behavior
with varying individuals and fusion pathways, involving Coarse Layer and Fine
Layer. The Ipsilateral Multi-View Network, comprising five fusion types (Pre,
Early, Middle, Last, and Post Fusion) in ResNet-18, is employed. Notably, the
Middle Fusion emerges as the most balanced and effective approach, enhancing
deep-learning models' generalization performance by +5.29\% (concatenate) and
+5.9\% (average) in VinDr-Mammo dataset and +2.03\% (concatenate) and +3\%
(average) in CMMD dataset on macro F1-Score. The paper emphasizes the crucial
role of layer assignment in multi-view network extraction with various
strategies.
</p>
</div>
</dd>
<dt><a name="item658">[658]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.02200" title="Abstract">arXiv:2309.02200</a> [<a href="/pdf/2309.02200" title="Download PDF">pdf</a>, <a href="/format/2309.02200" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Run for Cover: Dominating Set via Mobile Agents
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chand%2C+P+K">Prabhat Kumar Chand</a>, 
<a href="/search/cs?searchtype=author&query=Molla%2C+A+R">Anisur Rahaman Molla</a>, 
<a href="/search/cs?searchtype=author&query=Sivasubramaniam%2C+S">Sumathi Sivasubramaniam</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>

</div>
<p class="mathjax">Research involving computing with mobile agents is a fast-growing field,
given the advancement of technology in automated systems, e.g., robots, drones,
self-driving cars, etc. Therefore, it is pressing to focus on solving classical
network problems using mobile agents. In this paper, we study one such problem
-- finding small dominating sets of a graph $G$ using mobile agents. Dominating
set is interesting in the field of mobile agents as it opens up a way for
solving various robotic problems, e.g., guarding, covering, facility location,
transport routing, etc. In this paper, we first present two algorithms for
computing a {\em minimal dominating set}: (i) an $O(m)$ time algorithm if the
robots start from a single node (i.e., gathered initially), (ii) an
$O(\ell\Delta\log(\lambda)+n\ell+m)$ time algorithm, if the robots start from
multiple nodes (i.e., positioned arbitrarily), where $m$ is the number of edges
and $\Delta$ is the maximum degree of $G$, $\ell$ is the number of clusters of
the robot initially and $\lambda$ is the maximum ID-length of the robots. Then
we present a $\ln (\Delta)$ approximation algorithm for the {\em minimum}
dominating set which takes $O(n\Delta\log (\lambda))$ rounds.
</p>
</div>
</dd>
<dt><a name="item659">[659]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.02206" title="Abstract">arXiv:2309.02206</a> [<a href="/pdf/2309.02206" title="Download PDF">pdf</a>, <a href="/format/2309.02206" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Language Models for Novelty Detection in System Call Traces
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fournier%2C+Q">Quentin Fournier</a>, 
<a href="/search/cs?searchtype=author&query=Aloise%2C+D">Daniel Aloise</a>, 
<a href="/search/cs?searchtype=author&query=Costa%2C+L+R">Leandro R. Costa</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 7 figures, 3 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Operating Systems (cs.OS); Software Engineering (cs.SE)

</div>
<p class="mathjax">Due to the complexity of modern computer systems, novel and unexpected
behaviors frequently occur. Such deviations are either normal occurrences, such
as software updates and new user activities, or abnormalities, such as
misconfigurations, latency issues, intrusions, and software bugs. Regardless,
novel behaviors are of great interest to developers, and there is a genuine
need for efficient and effective methods to detect them. Nowadays, researchers
consider system calls to be the most fine-grained and accurate source of
information to investigate the behavior of computer systems. Accordingly, this
paper introduces a novelty detection methodology that relies on a probability
distribution over sequences of system calls, which can be seen as a language
model. Language models estimate the likelihood of sequences, and since
novelties deviate from previously observed behaviors by definition, they would
be unlikely under the model. Following the success of neural networks for
language models, three architectures are evaluated in this work: the widespread
LSTM, the state-of-the-art Transformer, and the lower-complexity Longformer.
However, large neural networks typically require an enormous amount of data to
be trained effectively, and to the best of our knowledge, no massive modern
datasets of kernel traces are publicly available. This paper addresses this
limitation by introducing a new open-source dataset of kernel traces comprising
over 2 million web requests with seven distinct behaviors. The proposed
methodology requires minimal expert hand-crafting and achieves an F-score and
AuROC greater than 95% on most novelties while being data- and task-agnostic.
The source code and trained models are publicly available on GitHub while the
datasets are available on Zenodo.
</p>
</div>
</dd>
<dt><a name="item660">[660]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.02208" title="Abstract">arXiv:2309.02208</a> [<a href="/pdf/2309.02208" title="Download PDF">pdf</a>, <a href="/ps/2309.02208" title="Download PostScript">ps</a>, <a href="/format/2309.02208" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Convergent finite difference schemes for stochastic transport equations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Fjordholm%2C+U+S">Ulrik S. Fjordholm</a>, 
<a href="/search/math?searchtype=author&query=Karlsen%2C+K+H">Kenneth H. Karlsen</a>, 
<a href="/search/math?searchtype=author&query=Pang%2C+P+H+C">Peter H.C. Pang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Analysis of PDEs (math.AP)

</div>
<p class="mathjax">We present difference schemes for stochastic transport equations with
low-regularity velocity fields. We establish $L^2$ stability and convergence of
the difference approximations under conditions that are less strict than those
required for deterministic transport equations. The $L^2$ estimate, crucial for
the analysis, is obtained through a discrete duality argument and a
comprehensive examination of a class of backward parabolic difference schemes.
</p>
</div>
</dd>
<dt><a name="item661">[661]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.02210" title="Abstract">arXiv:2309.02210</a> [<a href="/pdf/2309.02210" title="Download PDF">pdf</a>, <a href="/format/2309.02210" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Continual Cross-Dataset Adaptation in Road Surface Classification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cudrano%2C+P">Paolo Cudrano</a>, 
<a href="/search/cs?searchtype=author&query=Bellusci%2C+M">Matteo Bellusci</a>, 
<a href="/search/cs?searchtype=author&query=Macino%2C+G">Giuseppe Macino</a>, 
<a href="/search/cs?searchtype=author&query=Matteucci%2C+M">Matteo Matteucci</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To be published in Proceedings of 26th IEEE International Conference on Intelligent Transportation Systems (ITSC 2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Accurate road surface classification is crucial for autonomous vehicles (AVs)
to optimize driving conditions, enhance safety, and enable advanced road
mapping. However, deep learning models for road surface classification suffer
from poor generalization when tested on unseen datasets. To update these models
with new information, also the original training dataset must be taken into
account, in order to avoid catastrophic forgetting. This is, however,
inefficient if not impossible, e.g., when the data is collected in streams or
large amounts. To overcome this limitation and enable fast and efficient
cross-dataset adaptation, we propose to employ continual learning finetuning
methods designed to retain past knowledge while adapting to new data, thus
effectively avoiding forgetting. Experimental results demonstrate the
superiority of this approach over naive finetuning, achieving performance close
to fresh retraining. While solving this known problem, we also provide a
general description of how the same technique can be adopted in other AV
scenarios. We highlight the potential computational and economic benefits that
a continual-based adaptation can bring to the AV industry, while also reducing
greenhouse emissions due to unnecessary joint retraining.
</p>
</div>
</dd>
<dt><a name="item662">[662]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.02214" title="Abstract">arXiv:2309.02214</a> [<a href="/pdf/2309.02214" title="Download PDF">pdf</a>, <a href="/format/2309.02214" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Improving equilibrium propagation without weight symmetry through  Jacobian homeostasis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Laborieux%2C+A">Axel Laborieux</a>, 
<a href="/search/cs?searchtype=author&query=Zenke%2C+F">Friedemann Zenke</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Neural and Evolutionary Computing (cs.NE)

</div>
<p class="mathjax">Equilibrium propagation (EP) is a compelling alternative to the
backpropagation of error algorithm (BP) for computing gradients of neural
networks on biological or analog neuromorphic substrates. Still, the algorithm
requires weight symmetry and infinitesimal equilibrium perturbations, i.e.,
nudges, to estimate unbiased gradients efficiently. Both requirements are
challenging to implement in physical systems. Yet, whether and how weight
asymmetry affects its applicability is unknown because, in practice, it may be
masked by biases introduced through the finite nudge. To address this question,
we study generalized EP, which can be formulated without weight symmetry, and
analytically isolate the two sources of bias. For complex-differentiable
non-symmetric networks, we show that the finite nudge does not pose a problem,
as exact derivatives can still be estimated via a Cauchy integral. In contrast,
weight asymmetry introduces bias resulting in low task performance due to poor
alignment of EP's neuronal error vectors compared to BP. To mitigate this
issue, we present a new homeostatic objective that directly penalizes
functional asymmetries of the Jacobian at the network's fixed point. This
homeostatic objective dramatically improves the network's ability to solve
complex tasks such as ImageNet 32x32. Our results lay the theoretical
groundwork for studying and mitigating the adverse effects of imperfections of
physical networks on learning algorithms that rely on the substrate's
relaxation dynamics.
</p>
</div>
</dd>
<dt><a name="item663">[663]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.02217" title="Abstract">arXiv:2309.02217</a> [<a href="/pdf/2309.02217" title="Download PDF">pdf</a>, <a href="/format/2309.02217" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Advanced Underwater Image Restoration in Complex Illumination Conditions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Song%2C+Y">Yifan Song</a>, 
<a href="/search/cs?searchtype=author&query=She%2C+M">Mengkun She</a>, 
<a href="/search/cs?searchtype=author&query=K%C3%B6ser%2C+K">Kevin K&#xf6;ser</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Image and Video Processing (eess.IV)

</div>
<p class="mathjax">Underwater image restoration has been a challenging problem for decades since
the advent of underwater photography. Most solutions focus on shallow water
scenarios, where the scene is uniformly illuminated by the sunlight. However,
the vast majority of uncharted underwater terrain is located beyond 200 meters
depth where natural light is scarce and artificial illumination is needed. In
such cases, light sources co-moving with the camera, dynamically change the
scene appearance, which make shallow water restoration methods inadequate. In
particular for multi-light source systems (composed of dozens of LEDs
nowadays), calibrating each light is time-consuming, error-prone and tedious,
and we observe that only the integrated illumination within the viewing volume
of the camera is critical, rather than the individual light sources. The key
idea of this paper is therefore to exploit the appearance changes of objects or
the seafloor, when traversing the viewing frustum of the camera. Through new
constraints assuming Lambertian surfaces, corresponding image pixels constrain
the light field in front of the camera, and for each voxel a signal factor and
a backscatter value are stored in a volumetric grid that can be used for very
efficient image restoration of camera-light platforms, which facilitates
consistently texturing large 3D models and maps that would otherwise be
dominated by lighting and medium artifacts. To validate the effectiveness of
our approach, we conducted extensive experiments on simulated and real-world
datasets. The results of these experiments demonstrate the robustness of our
approach in restoring the true albedo of objects, while mitigating the
influence of lighting and medium effects. Furthermore, we demonstrate our
approach can be readily extended to other scenarios, including in-air imaging
with artificial illumination or other similar cases.
</p>
</div>
</dd>
<dt><a name="item664">[664]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.02218" title="Abstract">arXiv:2309.02218</a> [<a href="/pdf/2309.02218" title="Download PDF">pdf</a>, <a href="/format/2309.02218" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Robustness and Generalizability of Deepfake Detection: A Study with  Diffusion Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Song%2C+H">Haixu Song</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+S">Shiyu Huang</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+Y">Yinpeng Dong</a>, 
<a href="/search/cs?searchtype=author&query=Tu%2C+W">Wei-Wei Tu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">The rise of deepfake images, especially of well-known personalities, poses a
serious threat to the dissemination of authentic information. To tackle this,
we present a thorough investigation into how deepfakes are produced and how
they can be identified. The cornerstone of our research is a rich collection of
artificial celebrity faces, titled DeepFakeFace (DFF). We crafted the DFF
dataset using advanced diffusion models and have shared it with the community
through online platforms. This data serves as a robust foundation to train and
test algorithms designed to spot deepfakes. We carried out a thorough review of
the DFF dataset and suggest two evaluation methods to gauge the strength and
adaptability of deepfake recognition tools. The first method tests whether an
algorithm trained on one type of fake images can recognize those produced by
other methods. The second evaluates the algorithm's performance with imperfect
images, like those that are blurry, of low quality, or compressed. Given varied
results across deepfake methods and image changes, our findings stress the need
for better deepfake detectors. Our DFF dataset and tests aim to boost the
development of more effective tools against deepfakes.
</p>
</div>
</dd>
<dt><a name="item665">[665]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.02221" title="Abstract">arXiv:2309.02221</a> [<a href="/pdf/2309.02221" title="Download PDF">pdf</a>, <a href="/ps/2309.02221" title="Download PostScript">ps</a>, <a href="/format/2309.02221" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Improving students&#x27; code correctness and test completeness by informal  specifications
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Broeders%2C+A">Arno Broeders</a>, 
<a href="/search/cs?searchtype=author&query=Hermans%2C+R">Ruud Hermans</a>, 
<a href="/search/cs?searchtype=author&query=Stuurman%2C+S">Sylvia Stuurman</a>, 
<a href="/search/cs?searchtype=author&query=Bijlsma%2C+L">Lex Bijlsma</a>, 
<a href="/search/cs?searchtype=author&query=Passier%2C+H">Harrie Passier</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
<p class="mathjax">The quality of software produced by students is often poor. How to teach
students to develop good quality software has long been a topic in computer
science education and research. We must conclude that we still do not have a
good answer to this question. Specifications are necessary to determine the
correctness of software, to develop error-free software and to write complete
tests. Several attempts have been made to teach students to write
specifications before writing code. So far, that has not proven to be very
successful: Students do not like to write a specification and do not see the
benefits of writing specifications. In this paper we focus on the use of
informal specifications. Instead of teaching students how to write
specifications, we teach them how to use informal specifications to develop
correct software. The results were surprising: the number of errors in software
and the completeness of tests both improved considerably and, most importantly,
students really appreciate the specifications. We think that if students
appreciate specification, we have a key to teach them how to specify and to
appreciate its value.
</p>
</div>
</dd>
<dt><a name="item666">[666]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.02223" title="Abstract">arXiv:2309.02223</a> [<a href="/pdf/2309.02223" title="Download PDF">pdf</a>, <a href="/format/2309.02223" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Worst-Case Complexity of Symmetric Strategy Improvement
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=van+Dijk%2C+T">Tom van Dijk</a>, 
<a href="/search/cs?searchtype=author&query=Loho%2C+G">Georg Loho</a>, 
<a href="/search/cs?searchtype=author&query=Maat%2C+M">Matthew Maat</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>

</div>
<p class="mathjax">Symmetric strategy improvement is an algorithm introduced by Schewe et al.
(ICALP 2015) that can be used to solve two-player games on directed graphs such
as parity games and mean payoff games. In contrast to the usual well-known
strategy improvement algorithm, it iterates over strategies of both players
simultaneously. The symmetric version solves the known worst-case examples for
strategy improvement quickly, however its worst-case complexity remained open.
<br />We present a class of worst-case examples for symmetric strategy improvement
on which this symmetric version also takes exponentially many steps.
Remarkably, our examples exhibit this behaviour for any choice of improvement
rule, which is in contrast to classical strategy improvement where hard
instances are usually hand-crafted for a specific improvement rule. We present
a generalized version of symmetric strategy iteration depending less rigidly on
the interplay of the strategies of both players. However, it turns out it has
the same shortcomings.
</p>
</div>
</dd>
<dt><a name="item667">[667]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.02224" title="Abstract">arXiv:2309.02224</a> [<a href="/pdf/2309.02224" title="Download PDF">pdf</a>, <a href="/format/2309.02224" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Dense Object Grounding in 3D Scenes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+W">Wencan Huang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+D">Daizong Liu</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+W">Wei Hu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ACM MM 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Localizing objects in 3D scenes according to the semantics of a given natural
language is a fundamental yet important task in the field of multimedia
understanding, which benefits various real-world applications such as robotics
and autonomous driving. However, the majority of existing 3D object grounding
methods are restricted to a single-sentence input describing an individual
object, which cannot comprehend and reason more contextualized descriptions of
multiple objects in more practical 3D cases. To this end, we introduce a new
challenging task, called 3D Dense Object Grounding (3D DOG), to jointly
localize multiple objects described in a more complicated paragraph rather than
a single sentence. Instead of naively localizing each sentence-guided object
independently, we found that dense objects described in the same paragraph are
often semantically related and spatially located in a focused region of the 3D
scene. To explore such semantic and spatial relationships of densely referred
objects for more accurate localization, we propose a novel Stacked Transformer
based framework for 3D DOG, named 3DOGSFormer. Specifically, we first devise a
contextual query-driven local transformer decoder to generate initial grounding
proposals for each target object. Then, we employ a proposal-guided global
transformer decoder that exploits the local object features to learn their
correlation for further refining initial grounding proposals. Extensive
experiments on three challenging benchmarks (Nr3D, Sr3D, and ScanRefer) show
that our proposed 3DOGSFormer outperforms state-of-the-art 3D single-object
grounding methods and their dense-object variants by significant margins.
</p>
</div>
</dd>
<dt><a name="item668">[668]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.02228" title="Abstract">arXiv:2309.02228</a> [<a href="/pdf/2309.02228" title="Download PDF">pdf</a>, <a href="/format/2309.02228" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Algebraic Temporal Blocking for Sparse Iterative Solvers on Multi-Core  CPUs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Alappat%2C+C">Christie Alappat</a>, 
<a href="/search/math?searchtype=author&query=Thies%2C+J">Jonas Thies</a>, 
<a href="/search/math?searchtype=author&query=Hager%2C+G">Georg Hager</a>, 
<a href="/search/math?searchtype=author&query=Fehske%2C+H">Holger Fehske</a>, 
<a href="/search/math?searchtype=author&query=Wellein%2C+G">Gerhard Wellein</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 25 pages, 11 figures, 3 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Distributed, Parallel, and Cluster Computing (cs.DC)

</div>
<p class="mathjax">Sparse linear iterative solvers are essential for many large-scale
simulations. Much of the runtime of these solvers is often spent in the
implicit evaluation of matrix polynomials via a sequence of sparse
matrix-vector products. A variety of approaches has been proposed to make these
polynomial evaluations explicit (i.e., fix the coefficients), e.g., polynomial
preconditioners or s-step Krylov methods. Furthermore, it is nowadays a popular
practice to approximate triangular solves by a matrix polynomial to increase
parallelism. Such algorithms allow to evaluate the polynomial using a so-called
matrix power kernel (MPK), which computes the product between a power of a
sparse matrix A and a dense vector x, or a related operation. Recently we have
shown that using the level-based formulation of sparse matrix-vector
multiplications in the Recursive Algebraic Coloring Engine (RACE) framework we
can perform temporal cache blocking of MPK to increase its performance. In this
work, we demonstrate the application of this cache-blocking optimization in
sparse iterative solvers.
<br />By integrating the RACE library into the Trilinos framework, we demonstrate
the speedups achieved in preconditioned) s-step GMRES, polynomial
preconditioners, and algebraic multigrid (AMG). For MPK-dominated algorithms we
achieve speedups of up to 3x on modern multi-core compute nodes. For algorithms
with moderate contributions from subspace orthogonalization, the gain reduces
significantly, which is often caused by the insufficient quality of the
orthogonalization routines. Finally, we showcase the application of
RACE-accelerated solvers in a real-world wind turbine simulation (Nalu-Wind)
and highlight the new opportunities and perspectives opened up by RACE as a
cache-blocking technique for MPK-enabled sparse solvers.
</p>
</div>
</dd>
<dt><a name="item669">[669]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.02230" title="Abstract">arXiv:2309.02230</a> [<a href="/pdf/2309.02230" title="Download PDF">pdf</a>, <a href="/format/2309.02230" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DCP-Net: A Distributed Collaborative Perception Network for Remote  Sensing Semantic Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zhechao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+P">Peirui Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Duan%2C+S">Shujing Duan</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+K">Kaiqiang Chen</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zhirui Wang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xinming Li</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+X">Xian Sun</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Onboard intelligent processing is widely applied in emergency tasks in the
field of remote sensing. However, it is predominantly confined to an individual
platform with a limited observation range as well as susceptibility to
interference, resulting in limited accuracy. Considering the current state of
multi-platform collaborative observation, this article innovatively presents a
distributed collaborative perception network called DCP-Net. Firstly, the
proposed DCP-Net helps members to enhance perception performance by integrating
features from other platforms. Secondly, a self-mutual information match module
is proposed to identify collaboration opportunities and select suitable
partners, prioritizing critical collaborative features and reducing redundant
transmission cost. Thirdly, a related feature fusion module is designed to
address the misalignment between local and collaborative features, improving
the quality of fused features for the downstream task. We conduct extensive
experiments and visualization analyses using three semantic segmentation
datasets, including Potsdam, iSAID and DFC23. The results demonstrate that
DCP-Net outperforms the existing methods comprehensively, improving mIoU by
2.61%~16.89% at the highest collaboration efficiency, which promotes the
performance to a state-of-the-art level.
</p>
</div>
</dd>
<dt><a name="item670">[670]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.02232" title="Abstract">arXiv:2309.02232</a> [<a href="/pdf/2309.02232" title="Download PDF">pdf</a>, <a href="/format/2309.02232" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FSD: An Initial Chinese Dataset for Fake Song Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xie%2C+Y">Yuankun Xie</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+J">Jingjing Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+X">Xiaolin Lu</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+Z">Zhenghao Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yuxin Yang</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+H">Haonan Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Ye%2C+L">Long Ye</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to ICASSP 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Artificial Intelligence (cs.AI); Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">Singing voice synthesis and singing voice conversion have significantly
advanced, revolutionizing musical experiences. However, the rise of "Deepfake
Songs" generated by these technologies raises concerns about authenticity.
Unlike Audio DeepFake Detection (ADD), the field of song deepfake detection
lacks specialized datasets or methods for song authenticity verification. In
this paper, we initially construct a Chinese Fake Song Detection (FSD) dataset
to investigate the field of song deepfake detection. The fake songs in the FSD
dataset are generated by five state-of-the-art singing voice synthesis and
singing voice conversion methods. Our initial experiments on FSD revealed the
ineffectiveness of existing speech-trained ADD models for the task of Song
DeepFake Detection. Thus, we employ the FSD dataset for the training of ADD
models. We subsequently evaluate these models under two scenarios: one with the
original songs and another with separated vocal tracks. Experiment results show
that song-trained ADD models exhibit an approximate 38.58% reduction in average
equal error rate compared to speech-trained ADD models on the FSD test set.
</p>
</div>
</dd>
<dt><a name="item671">[671]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.02233" title="Abstract">arXiv:2309.02233</a> [<a href="/pdf/2309.02233" title="Download PDF">pdf</a>, <a href="/ps/2309.02233" title="Download PostScript">ps</a>, <a href="/format/2309.02233" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Augmenting Black-box LLMs with Medical Textbooks for Clinical Question  Answering
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yubo Wang</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+X">Xueguang Ma</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+W">Wenhu Chen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Large-scale language models (LLMs), such as ChatGPT, are capable of
generating human-like responses for various downstream tasks, such as
task-oriented dialogues and question answering. However, applying LLMs to
medical domains remains challenging due to their inability to leverage
domain-specific knowledge. In this study, we present the Large-scale Language
Models Augmented with Medical Textbooks (LLM-AMT), which integrates
authoritative medical textbooks as the cornerstone of its design, enhancing its
proficiency in the specialized domain through plug-and-play modules, comprised
of a Hybrid Textbook Retriever, supplemented by the Query Augmenter and the LLM
Reader. Experimental evaluation on three open-domain medical question-answering
tasks reveals a substantial enhancement in both the professionalism and
accuracy of the LLM responses when utilizing LLM-AMT, exhibiting an improvement
ranging from 11.4% to 13.2%. Despite being 100 times smaller, we found that
medical textbooks as the retrieval corpus serves as a more valuable external
knowledge source than Wikipedia in the medical domain. Our experiments show
that textbook augmentation results in a performance improvement ranging from
9.7% to 12.2% over Wikipedia augmentation.
</p>
</div>
</dd>
<dt><a name="item672">[672]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.02235" title="Abstract">arXiv:2309.02235</a> [<a href="/pdf/2309.02235" title="Download PDF">pdf</a>, <a href="/format/2309.02235" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Experimental Evaluation of Air-to-Ground VHF Band Communication for UAV  Relays
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Galkin%2C+B">Boris Galkin</a>, 
<a href="/search/cs?searchtype=author&query=Ho%2C+L">Lester Ho</a>, 
<a href="/search/cs?searchtype=author&query=Lyons%2C+K">Ken Lyons</a>, 
<a href="/search/cs?searchtype=author&query=Celik%2C+G">Gokhan Celik</a>, 
<a href="/search/cs?searchtype=author&query=Claussen%2C+H">Holger Claussen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Pre-print of paper presented at the Workshop on Integrating UAVs into 5G and Beyond at IEEE International Conference on Communications 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>

</div>
<p class="mathjax">Unmanned Aerial Vehicles (UAVs) are a disruptive technology that is
transforming a range of industries. Because they operate in the sky, UAVs are
able to take advantage of strong Line-of-Sight (LoS) channels for radio
propagation, allowing them to communicate over much larger distances than
equivalent hardware located at ground level. This has attracted the attention
of organisations such as the Irish Defence Forces (DF), with whom we are
developing a UAV-based radio relay system as part of the MISTRAL project. This
relay system will support digital Very High Frequency (VHF) band communication
between ground personnel, while they are deployed on missions. In this paper we
report on the initial set of experimental measurements which were carried out
to verify the feasibility of VHF signal relaying via UAV. In our experiments, a
UAV carrying a lightweight Software-Defined Radio (SDR) receiver is positioned
at a height of 500 meters above ground, while two 5W transmitters travel in
vehicles on the ground. The SDR receiver measures the received signal power,
while the Global Positioning System (GPS) coordinates of the vehicles are
logged. This is combined to measure the signal pathloss over distance. Our
results show that the signal is received successfully at distances of over 50
kilometers away. While the signals still appear to suffer from a degree of
obstacle blockage and multipath effects, these communication ranges are a
substantial improvement over the ground communication baseline, and validate
the use of UAVs to support wide area emergency communication.
</p>
</div>
</dd>
<dt><a name="item673">[673]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.02236" title="Abstract">arXiv:2309.02236</a> [<a href="/pdf/2309.02236" title="Download PDF">pdf</a>, <a href="/format/2309.02236" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Distributionally Robust Model-based Reinforcement Learning with Large  State Spaces
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ramesh%2C+S+S">Shyam Sundhar Ramesh</a>, 
<a href="/search/cs?searchtype=author&query=Sessa%2C+P+G">Pier Giuseppe Sessa</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+Y">Yifan Hu</a>, 
<a href="/search/cs?searchtype=author&query=Krause%2C+A">Andreas Krause</a>, 
<a href="/search/cs?searchtype=author&query=Bogunovic%2C+I">Ilija Bogunovic</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Machine Learning (stat.ML)

</div>
<p class="mathjax">Three major challenges in reinforcement learning are the complex dynamical
systems with large state spaces, the costly data acquisition processes, and the
deviation of real-world dynamics from the training environment deployment. To
overcome these issues, we study distributionally robust Markov decision
processes with continuous state spaces under the widely used Kullback-Leibler,
chi-square, and total variation uncertainty sets. We propose a model-based
approach that utilizes Gaussian Processes and the maximum variance reduction
algorithm to efficiently learn multi-output nominal transition dynamics,
leveraging access to a generative model (i.e., simulator). We further
demonstrate the statistical sample complexity of the proposed method for
different uncertainty sets. These complexity bounds are independent of the
number of states and extend beyond linear dynamics, ensuring the effectiveness
of our approach in identifying near-optimal distributionally-robust policies.
The proposed method can be further combined with other model-free
distributionally robust reinforcement learning methods to obtain a near-optimal
robust policy. Experimental results demonstrate the robustness of our algorithm
to distributional shifts and its superior performance in terms of the number of
samples needed.
</p>
</div>
</dd>
<dt><a name="item674">[674]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.02237" title="Abstract">arXiv:2309.02237</a> [<a href="/pdf/2309.02237" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Sample Size in Natural Language Processing within Healthcare Research
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chaturvedi%2C+J">Jaya Chaturvedi</a>, 
<a href="/search/cs?searchtype=author&query=Shamsutdinova%2C+D">Diana Shamsutdinova</a>, 
<a href="/search/cs?searchtype=author&query=Zimmer%2C+F">Felix Zimmer</a>, 
<a href="/search/cs?searchtype=author&query=Velupillai%2C+S">Sumithra Velupillai</a>, 
<a href="/search/cs?searchtype=author&query=Stahl%2C+D">Daniel Stahl</a>, 
<a href="/search/cs?searchtype=author&query=Stewart%2C+R">Robert Stewart</a>, 
<a href="/search/cs?searchtype=author&query=Roberts%2C+A">Angus Roberts</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to Journal of Biomedical Informatics
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Sample size calculation is an essential step in most data-based disciplines.
Large enough samples ensure representativeness of the population and determine
the precision of estimates. This is true for most quantitative studies,
including those that employ machine learning methods, such as natural language
processing, where free-text is used to generate predictions and classify
instances of text. Within the healthcare domain, the lack of sufficient corpora
of previously collected data can be a limiting factor when determining sample
sizes for new studies. This paper tries to address the issue by making
recommendations on sample sizes for text classification tasks in the healthcare
domain.
<br />Models trained on the MIMIC-III database of critical care records from Beth
Israel Deaconess Medical Center were used to classify documents as having or
not having Unspecified Essential Hypertension, the most common diagnosis code
in the database. Simulations were performed using various classifiers on
different sample sizes and class proportions. This was repeated for a
comparatively less common diagnosis code within the database of diabetes
mellitus without mention of complication.
<br />Smaller sample sizes resulted in better results when using a K-nearest
neighbours classifier, whereas larger sample sizes provided better results with
support vector machines and BERT models. Overall, a sample size larger than
1000 was sufficient to provide decent performance metrics.
<br />The simulations conducted within this study provide guidelines that can be
used as recommendations for selecting appropriate sample sizes and class
proportions, and for predicting expected performance, when building classifiers
for textual healthcare data. The methodology used here can be modified for
sample size estimates calculations with other datasets.
</p>
</div>
</dd>
<dt><a name="item675">[675]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.02240" title="Abstract">arXiv:2309.02240</a> [<a href="/pdf/2309.02240" title="Download PDF">pdf</a>, <a href="/format/2309.02240" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Dialog Action-Aware Transformer for Dialog Policy Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Huimin Wang</a>, 
<a href="/search/cs?searchtype=author&query=Kwan%2C+W">Wai-Chung Kwan</a>, 
<a href="/search/cs?searchtype=author&query=Wong%2C+K">Kam-Fai Wong</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To be appeared in SIGdial 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Recent works usually address Dialog policy learning DPL by training a
reinforcement learning (RL) agent to determine the best dialog action. However,
existing works on deep RL require a large volume of agent-user interactions to
achieve acceptable performance. In this paper, we propose to make full use of
the plain text knowledge from the pre-trained language model to accelerate the
RL agent's learning speed. Specifically, we design a dialog action-aware
transformer encoder (DaTrans), which integrates a new fine-tuning procedure
named masked last action task to encourage DaTrans to be dialog-aware and
distils action-specific features. Then, DaTrans is further optimized in an RL
setting with ongoing interactions and evolves through exploration in the dialog
action space toward maximizing long-term accumulated rewards. The effectiveness
and efficiency of the proposed model are demonstrated with both simulator
evaluation and human evaluation.
</p>
</div>
</dd>
<dt><a name="item676">[676]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.02243" title="Abstract">arXiv:2309.02243</a> [<a href="/pdf/2309.02243" title="Download PDF">pdf</a>, <a href="/format/2309.02243" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Self-Similarity-Based and Novelty-based loss for music structure  analysis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Peeters%2C+G">Geoffroy Peeters</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Machine Learning (cs.LG); Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">Music Structure Analysis (MSA) is the task aiming at identifying musical
segments that compose a music track and possibly label them based on their
similarity. In this paper we propose a supervised approach for the task of
music boundary detection. In our approach we simultaneously learn features and
convolution kernels. For this we jointly optimize -- a loss based on the
Self-Similarity-Matrix (SSM) obtained with the learned features, denoted by
SSM-loss, and -- a loss based on the novelty score obtained applying the
learned kernels to the estimated SSM, denoted by novelty-loss. We also
demonstrate that relative feature learning, through self-attention, is
beneficial for the task of MSA. Finally, we compare the performances of our
approach to previously proposed approaches on the standard RWC-Pop, and various
subsets of SALAMI.
</p>
</div>
</dd>
<dt><a name="item677">[677]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.02244" title="Abstract">arXiv:2309.02244</a> [<a href="/pdf/2309.02244" title="Download PDF">pdf</a>, <a href="/format/2309.02244" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Augmenting Chest X-ray Datasets with Non-Expert Annotations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Damgaard%2C+C">Cathrine Damgaard</a>, 
<a href="/search/cs?searchtype=author&query=Eriksen%2C+T+N">Trine Naja Eriksen</a>, 
<a href="/search/cs?searchtype=author&query=Juodelyte%2C+D">Dovile Juodelyte</a>, 
<a href="/search/cs?searchtype=author&query=Cheplygina%2C+V">Veronika Cheplygina</a>, 
<a href="/search/cs?searchtype=author&query=Jim%C3%A9nez-S%C3%A1nchez%2C+A">Amelia Jim&#xe9;nez-S&#xe1;nchez</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">The advancement of machine learning algorithms in medical image analysis
requires the expansion of training datasets. A popular and cost-effective
approach is automated annotation extraction from free-text medical reports,
primarily due to the high costs associated with expert clinicians annotating
chest X-ray images. However, it has been shown that the resulting datasets are
susceptible to biases and shortcuts. Another strategy to increase the size of a
dataset is crowdsourcing, a widely adopted practice in general computer vision
with some success in medical image analysis. In a similar vein to
crowdsourcing, we enhance two publicly available chest X-ray datasets by
incorporating non-expert annotations. However, instead of using diagnostic
labels, we annotate shortcuts in the form of tubes. We collect 3.5k chest drain
annotations for CXR14, and 1k annotations for 4 different tube types in
PadChest. We train a chest drain detector with the non-expert annotations that
generalizes well to expert labels. Moreover, we compare our annotations to
those provided by experts and show "moderate" to "almost perfect" agreement.
Finally, we present a pathology agreement study to raise awareness about ground
truth annotations. We make our annotations and code available.
</p>
</div>
</dd>
<dt><a name="item678">[678]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.02247" title="Abstract">arXiv:2309.02247</a> [<a href="/pdf/2309.02247" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Second International Workshop on Adaptive Cyber Defense, 2023
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+L">Li Li</a>, 
<a href="/search/cs?searchtype=author&query=Rami%2C+J+S+E">Jean-Pierre S. El Rami</a>, 
<a href="/search/cs?searchtype=author&query=Kerr%2C+R">Ryan Kerr</a>, 
<a href="/search/cs?searchtype=author&query=Taylor%2C+A">Adrian Taylor</a>, 
<a href="/search/cs?searchtype=author&query=Vandenberghe%2C+G">Grant Vandenberghe</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Presented at 2nd International Workshop on Adaptive Cyber Defense, 2023 (<a href="/abs/2308.09520">arXiv:2308.09520</a>)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">Recently, reinforcement and deep reinforcement learning (RL/DRL) have been
applied to develop autonomous agents for cyber network operations(CyOps), where
the agents are trained in a representative environment using RL and
particularly DRL algorithms. The training environment must simulate CyOps with
high fidelity, which the agent aims to learn and accomplish. A good simulator
is hard to achieve due to the extreme complexity of the cyber environment. The
trained agent must also be generalizable to network variations because
operational cyber networks change constantly. The red agent case is taken to
discuss these two issues in this work. We elaborate on their essential
requirements and potential solution options, illustrated by some preliminary
experimentations in a Cyber Gym for Intelligent Learning (CyGIL) testbed.
</p>
</div>
</dd>
<dt><a name="item679">[679]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.02248" title="Abstract">arXiv:2309.02248</a> [<a href="/pdf/2309.02248" title="Download PDF">pdf</a>, <a href="/format/2309.02248" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Encoding Seasonal Climate Predictions for Demand Forecasting with  Modular Neural Network
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Marvaniya%2C+S">Smit Marvaniya</a>, 
<a href="/search/cs?searchtype=author&query=Singh%2C+J">Jitendra Singh</a>, 
<a href="/search/cs?searchtype=author&query=Galichet%2C+N">Nicolas Galichet</a>, 
<a href="/search/cs?searchtype=author&query=Otieno%2C+F+O">Fred Ochieng Otieno</a>, 
<a href="/search/cs?searchtype=author&query=De+Mel%2C+G">Geeth De Mel</a>, 
<a href="/search/cs?searchtype=author&query=Weldemariam%2C+K">Kommy Weldemariam</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 15 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Current time-series forecasting problems use short-term weather attributes as
exogenous inputs. However, in specific time-series forecasting solutions (e.g.,
demand prediction in the supply chain), seasonal climate predictions are
crucial to improve its resilience. Representing mid to long-term seasonal
climate forecasts is challenging as seasonal climate predictions are uncertain,
and encoding spatio-temporal relationship of climate forecasts with demand is
complex.
<br />We propose a novel modeling framework that efficiently encodes seasonal
climate predictions to provide robust and reliable time-series forecasting for
supply chain functions. The encoding framework enables effective learning of
latent representations -- be it uncertain seasonal climate prediction or other
time-series data (e.g., buyer patterns) -- via a modular neural network
architecture. Our extensive experiments indicate that learning such
representations to model seasonal climate forecast results in an error
reduction of approximately 13\% to 17\% across multiple real-world data sets
compared to existing demand forecasting methods.
</p>
</div>
</dd>
<dt><a name="item680">[680]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.02250" title="Abstract">arXiv:2309.02250</a> [<a href="/pdf/2309.02250" title="Download PDF">pdf</a>, <a href="/format/2309.02250" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> RoBoSS: A Robust, Bounded, Sparse, and Smooth Loss Function for  Supervised Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Akhtar%2C+M">Mushir Akhtar</a>, 
<a href="/search/cs?searchtype=author&query=Tanveer%2C+M">M. Tanveer</a>, 
<a href="/search/cs?searchtype=author&query=Arshad%2C+M">Mohd. Arshad</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">In the domain of machine learning algorithms, the significance of the loss
function is paramount, especially in supervised learning tasks. It serves as a
fundamental pillar that profoundly influences the behavior and efficacy of
supervised learning algorithms. Traditional loss functions, while widely used,
often struggle to handle noisy and high-dimensional data, impede model
interpretability, and lead to slow convergence during training. In this paper,
we address the aforementioned constraints by proposing a novel robust, bounded,
sparse, and smooth (RoBoSS) loss function for supervised learning. Further, we
incorporate the RoBoSS loss function within the framework of support vector
machine (SVM) and introduce a new robust algorithm named
$\mathcal{L}_{rbss}$-SVM. For the theoretical analysis, the
classification-calibrated property and generalization ability are also
presented. These investigations are crucial for gaining deeper insights into
the performance of the RoBoSS loss function in the classification tasks and its
potential to generalize well to unseen data. To empirically demonstrate the
effectiveness of the proposed $\mathcal{L}_{rbss}$-SVM, we evaluate it on $88$
real-world UCI and KEEL datasets from diverse domains. Additionally, to
exemplify the effectiveness of the proposed $\mathcal{L}_{rbss}$-SVM within the
biomedical realm, we evaluated it on two medical datasets: the
electroencephalogram (EEG) signal dataset and the breast cancer (BreaKHis)
dataset. The numerical results substantiate the superiority of the proposed
$\mathcal{L}_{rbss}$-SVM model, both in terms of its remarkable generalization
performance and its efficiency in training time.
</p>
</div>
</dd>
<dt><a name="item681">[681]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.02251" title="Abstract">arXiv:2309.02251</a> [<a href="/pdf/2309.02251" title="Download PDF">pdf</a>, <a href="/format/2309.02251" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> STGIN: Spatial-Temporal Graph Interaction Network for Large-scale POI  Recommendation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+S">Shaohua Liu</a>, 
<a href="/search/cs?searchtype=author&query=Qi%2C+Y">Yu Qi</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+G">Gen Li</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+M">Mingjian Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+T">Teng Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+J">Jia Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Lei%2C+J">Jun Lei</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> accepted by CIKM 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>

</div>
<p class="mathjax">In Location-Based Services, Point-Of-Interest(POI) recommendation plays a
crucial role in both user experience and business opportunities. Graph neural
networks have been proven effective in providing personalized POI
recommendation services. However, there are still two critical challenges.
First, existing graph models attempt to capture users' diversified interests
through a unified graph, which limits their ability to express interests in
various spatial-temporal contexts. Second, the efficiency limitations of graph
construction and graph sampling in large-scale systems make it difficult to
adapt quickly to new real-time interests. To tackle the above challenges, we
propose a novel Spatial-Temporal Graph Interaction Network. Specifically, we
construct subgraphs of spatial, temporal, spatial-temporal, and global views
respectively to precisely characterize the user's interests in various
contexts. In addition, we design an industry-friendly framework to track the
user's latest interests. Extensive experiments on the real-world dataset show
that our method outperforms state-of-the-art models. This work has been
successfully deployed in a large e-commerce platform, delivering a 1.1% CTR and
6.3% RPM improvement.
</p>
</div>
</dd>
<dt><a name="item682">[682]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.02253" title="Abstract">arXiv:2309.02253</a> [<a href="/pdf/2309.02253" title="Download PDF">pdf</a>, <a href="/ps/2309.02253" title="Download PostScript">ps</a>, <a href="/format/2309.02253" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MA-VAE: Multi-head Attention-based Variational Autoencoder Approach for  Anomaly Detection in Multivariate Time-series Applied to Automotive Endurance  Powertrain Testing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Correia%2C+L">Lucas Correia</a>, 
<a href="/search/cs?searchtype=author&query=Goos%2C+J">Jan-Christoph Goos</a>, 
<a href="/search/cs?searchtype=author&query=Klein%2C+P">Philipp Klein</a>, 
<a href="/search/cs?searchtype=author&query=B%C3%A4ck%2C+T">Thomas B&#xe4;ck</a>, 
<a href="/search/cs?searchtype=author&query=Kononova%2C+A+V">Anna V. Kononova</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted in NCTA2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Systems and Control (eess.SY)

</div>
<p class="mathjax">A clear need for automatic anomaly detection applied to automotive testing
has emerged as more and more attention is paid to the data recorded and manual
evaluation by humans reaches its capacity. Such real-world data is massive,
diverse, multivariate and temporal in nature, therefore requiring modelling of
the testee behaviour. We propose a variational autoencoder with multi-head
attention (MA-VAE), which, when trained on unlabelled data, not only provides
very few false positives but also manages to detect the majority of the
anomalies presented. In addition to that, the approach offers a novel way to
avoid the bypass phenomenon, an undesirable behaviour investigated in
literature. Lastly, the approach also introduces a new method to remap
individual windows to a continuous time series. The results are presented in
the context of a real-world industrial data set and several experiments are
undertaken to further investigate certain aspects of the proposed model. When
configured properly, it is 9% of the time wrong when an anomaly is flagged and
discovers 67% of the anomalies present. Also, MA-VAE has the potential to
perform well with only a fraction of the training and validation subset,
however, to extract it, a more sophisticated threshold estimation method is
required.
</p>
</div>
</dd>
<dt><a name="item683">[683]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.02255" title="Abstract">arXiv:2309.02255</a> [<a href="/pdf/2309.02255" title="Download PDF">pdf</a>, <a href="/format/2309.02255" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MAFIA: Protecting the Microarchitecture of Embedded Systems Against  Fault Injection Attacks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chamelot%2C+T">Thomas Chamelot</a>, 
<a href="/search/cs?searchtype=author&query=Courouss%C3%A9%2C+D">Damien Courouss&#xe9;</a>, 
<a href="/search/cs?searchtype=author&query=Heydemann%2C+K">Karine Heydemann</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> published by IEEE TCAD
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> IEEE TCAD (2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">Fault injection attacks represent an effective threat to embedded systems.
Recently, Laurent et al. have reported that fault injection attacks can
leverage faults inside the microarchitecture. However, state-of-the-art
counter-measures, hardwareonly or with hardware support, do not consider the
integrity of microarchitecture control signals that are the target of these
faults.
<br />We present MAFIA, a microarchitecture protection against fault injection
attacks. MAFIA ensures integrity of pipeline control signals through a
signature-based mechanism, and ensures fine-grained control-flow integrity with
a complete indirect branch support and code authenticity. We analyse the
security properties of two different implementations with different
security/overhead trade-offs: one with a CBC-MAC/Prince signature function, and
another one with a CRC32. We present our implementation of MAFIA in a RISC-V
processor, supported by a dedicated compiler toolchain based on LLVM/Clang. We
report a hardware area overhead of 23.8 % and 6.5 % for the CBC-MAC/Prince and
CRC32 respectively. The average code size and execution time overheads are 29.4
% and 18.4 % respectively for the CRC32 implementation and are 50 % and 39 %
for the CBC-MAC/Prince.
</p>
</div>
</dd>
<dt><a name="item684">[684]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.02257" title="Abstract">arXiv:2309.02257</a> [<a href="/pdf/2309.02257" title="Download PDF">pdf</a>, <a href="/ps/2309.02257" title="Download PostScript">ps</a>, <a href="/format/2309.02257" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Designing Interfaces for Human-Computer Communication: An On-Going  Collection of Considerations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Glassman%2C+E+L">Elena L. Glassman</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">While we do not always use words, communicating what we want to an AI is a
conversation -- with ourselves as well as with it, a recurring loop with
optional steps depending on the complexity of the situation and our request.
Any given conversation of this type may include: (a) the human forming an
intent, (b) the human expressing that intent as a command or utterance, (c) the
AI performing one or more rounds of inference on that command to resolve
ambiguities and/or requesting clarifications from the human, (d) the AI showing
the inferred meaning of the command and/or its execution on current and future
situations or data, (e) the human hopefully correctly recognizing whether the
AI's interpretation actually aligns with their intent. In the process, they may
(f) update their model of the AI's capabilities and characteristics, (g) update
their model of the situations in which the AI is executing its interpretation
of their intent, (h) confirm or refine their intent, and (i) revise their
expression of their intent to the AI, where the loop repeats until the human is
satisfied. With these critical cognitive and computational steps within this
back-and-forth laid out as a framework, it is easier to anticipate where
communication can fail, and design algorithms and interfaces that ameliorate
those failure points.
</p>
</div>
</dd>
<dt><a name="item685">[685]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.02258" title="Abstract">arXiv:2309.02258</a> [<a href="/pdf/2309.02258" title="Download PDF">pdf</a>, <a href="/format/2309.02258" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On 3-Coloring Circle Graphs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bachmann%2C+P">Patricia Bachmann</a>, 
<a href="/search/cs?searchtype=author&query=Rutter%2C+I">Ignaz Rutter</a>, 
<a href="/search/cs?searchtype=author&query=Stumpf%2C+P">Peter Stumpf</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Appears in the Proceedings of the 31st International Symposium on Graph Drawing and Network Visualization (GD 2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Discrete Mathematics (cs.DM)</span>; Data Structures and Algorithms (cs.DS)

</div>
<p class="mathjax">Given a graph $G$ with a fixed vertex order $\prec$, one obtains a circle
graph $H$ whose vertices are the edges of $G$ and where two such edges are
adjacent if and only if their endpoints are pairwise distinct and alternate in
$\prec$. Therefore, the problem of determining whether $G$ has a $k$-page book
embedding with spine order $\prec$ is equivalent to deciding whether $H$ can be
colored with $k$ colors. Finding a $k$-coloring for a circle graph is known to
be NP-complete for $k \geq 4$ and trivial for $k \leq 2$. For $k = 3$, Unger
(1992) claims an efficient algorithm that finds a 3-coloring in $O(n \log n)$
time, if it exists. Given a circle graph $H$, Unger's algorithm (1) constructs
a 3-\textsc{Sat} formula $\Phi$ that is satisfiable if and only if $H$ admits a
3-coloring and (2) solves $\Phi$ by a backtracking strategy that relies on the
structure imposed by the circle graph. However, the extended abstract misses
several details and Unger refers to his PhD thesis (in German) for details. In
this paper we argue that Unger's algorithm for 3-coloring circle graphs is not
correct and that 3-coloring circle graphs should be considered as an open
problem. We show that step (1) of Unger's algorithm is incorrect by exhibiting
a circle graph whose formula $\Phi$ is satisfiable but that is not 3-colorable.
We further show that Unger's backtracking strategy for solving $\Phi$ in step
(2) may produce incorrect results and give empirical evidence that it exhibits
a runtime behaviour that is not consistent with the claimed running time.
</p>
</div>
</dd>
<dt><a name="item686">[686]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.02259" title="Abstract">arXiv:2309.02259</a> [<a href="/pdf/2309.02259" title="Download PDF">pdf</a>, <a href="/ps/2309.02259" title="Download PostScript">ps</a>, <a href="/format/2309.02259" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Design of a New CIM-DCSK-Based Ambient Backscatter Communication System
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+R">Ruipeng Yang</a>, 
<a href="/search/cs?searchtype=author&query=Fang%2C+Y">Yi Fang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+P">Pingping Chen</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+H">Huan Ma</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">To improve the data rate in differential chaos shift keying (DCSK) based
ambient backscatter communication (AmBC) system, we propose a new AmBC system
based on code index modulation (CIM), referred to as CIM-DCSK-AmBC system. In
the proposed system, the CIM-DCSK signal transmitted in the direct link is used
as the radio frequency source of the backscatter link. The signal format in the
backscatter link is designed to increase the data rate as well as eliminate the
interference of the direct link signal. As such, the direct link signal and the
backscatter link signal can be received and demodulated simultaneously.
Moreover, we derive and validate the theoretical bit error rate (BER)
expressions of the CIM-DCSK-AmBC system over multipath Rayleigh fading
channels. Regarding the short reference DCSK-based AmBC (SR-DCSK-AmBC) system
as a benchmark system, numerical results reveal that the CIM-DCSK-AmBC system
can achieve better BER performance in the direct link and higher throughput in
the backscatter link than the benchmark system.
</p>
</div>
</dd>
<dt><a name="item687">[687]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.02264" title="Abstract">arXiv:2309.02264</a> [<a href="/pdf/2309.02264" title="Download PDF">pdf</a>, <a href="/ps/2309.02264" title="Download PostScript">ps</a>, <a href="/format/2309.02264" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fairness Optimization of RSMA for Uplink Communication based on  Intelligent Reflecting Surface
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+S">Shanshan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+W">Wen Chen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">In this paper, we propose a rate-splitting multiple access (RSMA) scheme for
uplink wireless communication systems with intelligent reflecting surface (IRS)
aided. In the considered model, IRS is adopted to overcome power attenuation
caused by path loss. We construct a max-min fairness optimization problem to
obtain the resource allocation, including the receive beamforming at the base
station (BS) and phase-shift beamforming at IRS. We also introduce a successive
group decoding (SGD) algorithm at the receiver, which trades off the fairness
and complexity of decoding. In the simulation, the results show that the
proposed scheme has superiority in improving the fairness of uplink
communication.
</p>
</div>
</dd>
<dt><a name="item688">[688]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.02269" title="Abstract">arXiv:2309.02269</a> [<a href="/pdf/2309.02269" title="Download PDF">pdf</a>, <a href="/format/2309.02269" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Online hitting set of $d$-dimensional fat objects
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Alefkhani%2C+S">Shanli Alefkhani</a>, 
<a href="/search/cs?searchtype=author&query=Khodaveisi%2C+N">Nima Khodaveisi</a>, 
<a href="/search/cs?searchtype=author&query=Mari%2C+M">Mathieu Mari</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>; Computational Geometry (cs.CG)

</div>
<p class="mathjax">We consider an online version of the geometric minimum hitting set problem
that can be described as a game between an adversary and an algorithm. For some
integers $d$ and $N$, let $P$ be the set of points in $(0, N)^d$ with integral
coordinates, and let $\mathcal{O}$ be a family of subsets of $P$, called
objects. Both $P$ and $\mathcal{O}$ are known in advance by the algorithm and
by the adversary. Then, the adversary gives some objects one by one, and the
algorithm has to maintain a valid hitting set for these objects using points
from $P$, with an immediate and irrevocable decision. We measure the
performance of the algorithm by its competitive ratio, that is the ratio
between the number of points used by the algorithm and the offline minimum
hitting set for the sub-sequence of objects chosen by the adversary.
<br />We present a simple deterministic online algorithm with competitive ratio
$((4\alpha+1)^{2d}\log N)$ when objects correspond to a family of $\alpha$-fat
objects. Informally, $\alpha$-fatness measures how cube-like is an object. We
show that no algorithm can achieve a better ratio when $\alpha$ and $d$ are
fixed constants. In particular, our algorithm works for two-dimensional disks
and $d$-cubes which answers two open questions from related previous papers in
the special case where the set of points corresponds to all the points of
integral coordinates with a fixed $d$-cube.
</p>
</div>
</dd>
<dt><a name="item689">[689]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.02270" title="Abstract">arXiv:2309.02270</a> [<a href="/pdf/2309.02270" title="Download PDF">pdf</a>, <a href="/format/2309.02270" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SAM-Deblur: Let Segment Anything Boost Image Deblurring
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+S">Siwei Li</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+M">Mingxuan Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yating Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+S">Shu Chen</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Haoxiang Li</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+H">Hong Chen</a>, 
<a href="/search/cs?searchtype=author&query=Dou%2C+Z">Zifei Dou</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Under review
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Image deblurring is a critical task in the field of image restoration, aiming
to eliminate blurring artifacts. However, the challenge of addressing
non-uniform blurring leads to an ill-posed problem, which limits the
generalization performance of existing deblurring models. To solve the problem,
we propose a framework SAM-Deblur, integrating prior knowledge from the Segment
Anything Model (SAM) into the deblurring task for the first time. In
particular, SAM-Deblur is divided into three stages. First, We preprocess the
blurred images, obtain image masks via SAM, and propose a mask dropout method
for training to enhance model robustness. Then, to fully leverage the
structural priors generated by SAM, we propose a Mask Average Pooling (MAP)
unit specifically designed to average SAM-generated segmented areas, serving as
a plug-and-play component which can be seamlessly integrated into existing
deblurring networks. Finally, we feed the fused features generated by the MAP
Unit into the deblurring model to obtain a sharp image. Experimental results on
the RealBlurJ, ReloBlur, and REDS datasets reveal that incorporating our
methods improves NAFNet's PSNR by 0.05, 0.96, and 7.03, respectively. Code will
be available at \href{https://github.com/HPLQAQ/SAM-Deblur}{SAM-Deblur}.
</p>
</div>
</dd>
<dt><a name="item690">[690]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.02272" title="Abstract">arXiv:2309.02272</a> [<a href="/pdf/2309.02272" title="Download PDF">pdf</a>, <a href="/format/2309.02272" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Graph-Based Automatic Feature Selection for Multi-Class Classification  via Mean Simplified Silhouette
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Levin%2C+D">David Levin</a>, 
<a href="/search/cs?searchtype=author&query=Singer%2C+G">Gonen Singer</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 4 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">This paper introduces a novel graph-based filter method for automatic feature
selection (abbreviated as GB-AFS) for multi-class classification tasks. The
method determines the minimum combination of features required to sustain
prediction performance while maintaining complementary discriminating abilities
between different classes. It does not require any user-defined parameters such
as the number of features to select. The methodology employs the
Jeffries-Matusita (JM) distance in conjunction with t-distributed Stochastic
Neighbor Embedding (t-SNE) to generate a low-dimensional space reflecting how
effectively each feature can differentiate between each pair of classes. The
minimum number of features is selected using our newly developed Mean
Simplified Silhouette (abbreviated as MSS) index, designed to evaluate the
clustering results for the feature selection task. Experimental results on
public data sets demonstrate the superior performance of the proposed GB-AFS
over other filter-based techniques and automatic feature selection approaches.
Moreover, the proposed algorithm maintained the accuracy achieved when
utilizing all features, while using only $7\%$ to $30\%$ of the features.
Consequently, this resulted in a reduction of the time needed for
classifications, from $15\%$ to $70\%$.
</p>
</div>
</dd>
<dt><a name="item691">[691]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.02273" title="Abstract">arXiv:2309.02273</a> [<a href="/pdf/2309.02273" title="Download PDF">pdf</a>, <a href="/format/2309.02273" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Computing Hive Plots: A Combinatorial Framework
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=N%C3%B6llenburg%2C+M">Martin N&#xf6;llenburg</a>, 
<a href="/search/cs?searchtype=author&query=Wallinger%2C+M">Markus Wallinger</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Appears in the Proceedings of the 31st International Symposium on Graph Drawing and Network Visualization (GD 2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Geometry (cs.CG)</span>; Human-Computer Interaction (cs.HC)

</div>
<p class="mathjax">Hive plots are a graph visualization style placing vertices on a set of
radial axes emanating from a common center and drawing edges as smooth curves
connecting their respective endpoints. In previous work on hive plots,
assignment to an axis and vertex positions on each axis were determined based
on selected vertex attributes and the order of axes was prespecified. Here, we
present a new framework focusing on combinatorial aspects of these drawings to
extend the original hive plot idea and optimize visual properties such as the
total edge length and the number of edge crossings in the resulting hive plots.
Our framework comprises three steps: (1) partition the vertices into multiple
groups, each corresponding to an axis of the hive plot; (2) optimize the cyclic
axis order to bring more strongly connected groups near each other; (3)
optimize the vertex ordering on each axis to minimize edge crossings. Each of
the three steps is related to a well-studied, but NP-complete computational
problem. We combine and adapt suitable algorithmic approaches, implement them
as an instantiation of our framework and show in a case study how it can be
applied in a practical setting. Furthermore, we conduct computational
experiments to gain further insights regarding algorithmic choices of the
framework. The code of the implementation and a prototype web application can
be found on OSF.
</p>
</div>
</dd>
<dt><a name="item692">[692]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.02274" title="Abstract">arXiv:2309.02274</a> [<a href="/pdf/2309.02274" title="Download PDF">pdf</a>, <a href="/format/2309.02274" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Comparison of Residual-based Methods on Fault Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Hsu%2C+C">Chi-Ching Hsu</a>, 
<a href="/search/eess?searchtype=author&query=Frusque%2C+G">Gaetan Frusque</a>, 
<a href="/search/eess?searchtype=author&query=Fink%2C+O">Olga Fink</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, submitted to the 15th Annual Conference of the Prognostics and Health Management Society
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">An important initial step in fault detection for complex industrial systems
is gaining an understanding of their health condition. Subsequently, continuous
monitoring of this health condition becomes crucial to observe its evolution,
track changes over time, and isolate faults. As faults are typically rare
occurrences, it is essential to perform this monitoring in an unsupervised
manner. Various approaches have been proposed not only to detect faults in an
unsupervised manner but also to distinguish between different potential fault
types. In this study, we perform a comprehensive comparison between two
residual-based approaches: autoencoders, and the input-output models that
establish a mapping between operating conditions and sensor readings. We
explore the sensor-wise residuals and aggregated residuals for the entire
system in both methods. The performance evaluation focuses on three tasks:
health indicator construction, fault detection, and health indicator
interpretation. To perform the comparison, we utilize the Commercial Modular
Aero-Propulsion System Simulation (C-MAPSS) dynamical model, specifically a
subset of the turbofan engine dataset containing three different fault types.
All models are trained exclusively on healthy data. Fault detection is achieved
by applying a threshold that is determined based on the healthy condition. The
detection results reveal that both models are capable of detecting faults with
an average delay of around 20 cycles and maintain a low false positive rate.
While the fault detection performance is similar for both models, the
input-output model provides better interpretability regarding potential fault
types and the possible faulty components.
</p>
</div>
</dd>
<dt><a name="item693">[693]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.02281" title="Abstract">arXiv:2309.02281</a> [<a href="/pdf/2309.02281" title="Download PDF">pdf</a>, <a href="/ps/2309.02281" title="Download PostScript">ps</a>, <a href="/format/2309.02281" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> s-ID: Causal Effect Identification in a Sub-Population
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Abouei%2C+A+M">Amir Mohammad Abouei</a>, 
<a href="/search/cs?searchtype=author&query=Mokhtarian%2C+E">Ehsan Mokhtarian</a>, 
<a href="/search/cs?searchtype=author&query=Kiyavash%2C+N">Negar Kiyavash</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 22 pages, 14 figures, 1 table
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Methodology (stat.ME)

</div>
<p class="mathjax">Causal inference in a sub-population involves identifying the causal effect
of an intervention on a specific subgroup within a larger population. However,
ignoring the subtleties introduced by sub-populations can either lead to
erroneous inference or limit the applicability of existing methods. We
introduce and advocate for a causal inference problem in sub-populations
(henceforth called s-ID), in which we merely have access to observational data
of the targeted sub-population (as opposed to the entire population). Existing
inference problems in sub-populations operate on the premise that the given
data distributions originate from the entire population, thus, cannot tackle
the s-ID problem. To address this gap, we provide necessary and sufficient
conditions that must hold in the causal graph for a causal effect in a
sub-population to be identifiable from the observational distribution of that
sub-population. Given these conditions, we present a sound and complete
algorithm for the s-ID problem.
</p>
</div>
</dd>
<dt><a name="item694">[694]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.02286" title="Abstract">arXiv:2309.02286</a> [<a href="/pdf/2309.02286" title="Download PDF">pdf</a>, <a href="/format/2309.02286" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Haystack: A Panoptic Scene Graph Dataset to Evaluate Rare Predicate  Classes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lorenz%2C+J">Julian Lorenz</a>, 
<a href="/search/cs?searchtype=author&query=Barthel%2C+F">Florian Barthel</a>, 
<a href="/search/cs?searchtype=author&query=Kienzle%2C+D">Daniel Kienzle</a>, 
<a href="/search/cs?searchtype=author&query=Lienhart%2C+R">Rainer Lienhart</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Current scene graph datasets suffer from strong long-tail distributions of
their predicate classes. Due to a very low number of some predicate classes in
the test sets, no reliable metrics can be retrieved for the rarest classes. We
construct a new panoptic scene graph dataset and a set of metrics that are
designed as a benchmark for the predictive performance especially on rare
predicate classes. To construct the new dataset, we propose a model-assisted
annotation pipeline that efficiently finds rare predicate classes that are
hidden in a large set of images like needles in a haystack.
<br />Contrary to prior scene graph datasets, Haystack contains explicit negative
annotations, i.e. annotations that a given relation does not have a certain
predicate class. Negative annotations are helpful especially in the field of
scene graph generation and open up a whole new set of possibilities to improve
current scene graph generation models.
<br />Haystack is 100% compatible with existing panoptic scene graph datasets and
can easily be integrated with existing evaluation pipelines. Our dataset and
code can be found here: https://lorjul.github.io/haystack/. It includes
annotation files and simple to use scripts and utilities, to help with
integrating our dataset in existing work.
</p>
</div>
</dd>
<dt><a name="item695">[695]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.02287" title="Abstract">arXiv:2309.02287</a> [<a href="/pdf/2309.02287" title="Download PDF">pdf</a>, <a href="/format/2309.02287" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Optimal Observation-Intervention Trade-Off in Optimisation Problems with  Causal Structure
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hammar%2C+K">Kim Hammar</a>, 
<a href="/search/cs?searchtype=author&query=Dhir%2C+N">Neil Dhir</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
<p class="mathjax">We consider the problem of optimising an expensive-to-evaluate grey-box
objective function, within a finite budget, where known side-information exists
in the form of the causal structure between the design variables. Standard
black-box optimisation ignores the causal structure, often making it
inefficient and expensive. The few existing methods that consider the causal
structure are myopic and do not fully accommodate the observation-intervention
trade-off that emerges when estimating causal effects. In this paper, we show
that the observation-intervention trade-off can be formulated as a non-myopic
optimal stopping problem which permits an efficient solution. We give
theoretical results detailing the structure of the optimal stopping times and
demonstrate the generality of our approach by showing that it can be integrated
with existing causal Bayesian optimisation algorithms. Experimental results
show that our formulation can enhance existing algorithms on real and synthetic
benchmarks.
</p>
</div>
</dd>
<dt><a name="item696">[696]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.02289" title="Abstract">arXiv:2309.02289</a> [<a href="/pdf/2309.02289" title="Download PDF">pdf</a>, <a href="/format/2309.02289" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A well-conditioned combined field integral equation for electromagnetic  scattering
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Le%2C+V+C">Van Chien Le</a>, 
<a href="/search/math?searchtype=author&query=Cools%2C+K">Kristof Cools</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">This paper aims to address two issues of integral equations for the
scattering of time-harmonic electromagnetic waves by a perfect electric
conductor with Lipschitz continuous boundary: resonant instability and dense
discretization breakdown. The remedy to resonant instability is a combined
field integral equation, and dense discretization breakdown is eliminated by
means of operator preconditioning. The exterior traces of single and double
layer potentials are complemented by their interior counterparts of a pure
imaginary wave number. We derive the corresponding variational formulation in
the natural trace space for electromagnetic fields and establish its
well-posedness for all wave numbers. A Galerkin discretization scheme is
employed using conforming edge boundary elements on dual meshes, which produces
well-conditioned discrete linear systems of the variational formulation. Some
numerical results are also provided to support the numerical analysis.
</p>
</div>
</dd>
<dt><a name="item697">[697]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.02290" title="Abstract">arXiv:2309.02290</a> [<a href="/pdf/2309.02290" title="Download PDF">pdf</a>, <a href="/format/2309.02290" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ATM: Action Temporality Modeling for Video Question Answering
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Junwen Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+J">Jie Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Kong%2C+Y">Yu Kong</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Despite significant progress in video question answering (VideoQA), existing
methods fall short of questions that require causal/temporal reasoning across
frames. This can be attributed to imprecise motion representations. We
introduce Action Temporality Modeling (ATM) for temporality reasoning via
three-fold uniqueness: (1) rethinking the optical flow and realizing that
optical flow is effective in capturing the long horizon temporality reasoning;
(2) training the visual-text embedding by contrastive learning in an
action-centric manner, leading to better action representations in both vision
and text modalities; and (3) preventing the model from answering the question
given the shuffled video in the fine-tuning stage, to avoid spurious
correlation between appearance and motion and hence ensure faithful temporality
reasoning. In the experiments, we show that ATM outperforms previous approaches
in terms of the accuracy on multiple VideoQAs and exhibits better true
temporality reasoning ability.
</p>
</div>
</dd>
<dt><a name="item698">[698]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.02297" title="Abstract">arXiv:2309.02297</a> [<a href="/pdf/2309.02297" title="Download PDF">pdf</a>, <a href="/ps/2309.02297" title="Download PostScript">ps</a>, <a href="/format/2309.02297" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Smoothening block rewards: How much should miners pay for mining pools?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cortes-Cubero%2C+A">Axel Cortes-Cubero</a>, 
<a href="/search/cs?searchtype=author&query=Madrigal-Cianci%2C+J+P">Juan P. Madrigal-Cianci</a>, 
<a href="/search/cs?searchtype=author&query=Karra%2C+K">Kiran Karra</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zixuan Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 15 pages, 1 figure
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">The rewards a blockchain miner earns vary with time. Most of the time is
spent mining without receiving any rewards, and only occasionally the miner
wins a block and earns a reward. Mining pools smoothen the stochastic flow of
rewards, and in the ideal case, provide a steady flow of rewards over time.
Smooth block rewards allow miners to choose an optimal mining power growth
strategy that will result in a higher reward yield for a given investment. We
quantify the economic advantage for a given miner of having smooth rewards, and
use this to define a maximum percentage of rewards that a miner should be
willing to pay for the mining pool services.
</p>
</div>
</dd>
<dt><a name="item699">[699]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.02301" title="Abstract">arXiv:2309.02301</a> [<a href="/pdf/2309.02301" title="Download PDF">pdf</a>, <a href="/format/2309.02301" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CIEM: Contrastive Instruction Evaluation Method for Better Instruction  Tuning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hu%2C+H">Hongyu Hu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jiyuan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+M">Minyi Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+Z">Zhenbang Sun</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Nowadays, the research on Large Vision-Language Models (LVLMs) has been
significantly promoted thanks to the success of Large Language Models (LLM).
Nevertheless, these Vision-Language Models (VLMs) are suffering from the
drawback of hallucination -- due to insufficient understanding of vision and
language modalities, VLMs may generate incorrect perception information when
doing downstream applications, for example, captioning a non-existent entity.
To address the hallucination phenomenon, on the one hand, we introduce a
Contrastive Instruction Evaluation Method (CIEM), which is an automatic
pipeline that leverages an annotated image-text dataset coupled with an LLM to
generate factual/contrastive question-answer pairs for the evaluation of the
hallucination of VLMs. On the other hand, based on CIEM, we further propose a
new instruction tuning method called CIT (the abbreviation of Contrastive
Instruction Tuning) to alleviate the hallucination of VLMs by automatically
producing high-quality factual/contrastive question-answer pairs and
corresponding justifications for model tuning. Through extensive experiments on
CIEM and CIT, we pinpoint the hallucination issues commonly present in existing
VLMs, the disability of the current instruction-tuning dataset to handle the
hallucination phenomenon and the superiority of CIT-tuned VLMs over both CIEM
and public datasets.
</p>
</div>
</dd>
<dt><a name="item700">[700]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.02304" title="Abstract">arXiv:2309.02304</a> [<a href="/pdf/2309.02304" title="Download PDF">pdf</a>, <a href="/format/2309.02304" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Graph Self-Contrast Representation Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+M">Minjie Chen</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+Y">Yao Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Ye Wang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xiang Li</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+M">Ming Gao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ICDM 2023(Regular)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Graphics (cs.GR)

</div>
<p class="mathjax">Graph contrastive learning (GCL) has recently emerged as a promising approach
for graph representation learning. Some existing methods adopt the 1-vs-K
scheme to construct one positive and K negative samples for each graph, but it
is difficult to set K. For those methods that do not use negative samples, it
is often necessary to add additional strategies to avoid model collapse, which
could only alleviate the problem to some extent. All these drawbacks will
undoubtedly have an adverse impact on the generalizability and efficiency of
the model. In this paper, to address these issues, we propose a novel graph
self-contrast framework GraphSC, which only uses one positive and one negative
sample, and chooses triplet loss as the objective. Specifically, self-contrast
has two implications. First, GraphSC generates both positive and negative views
of a graph sample from the graph itself via graph augmentation functions of
various intensities, and use them for self-contrast. Second, GraphSC uses
Hilbert-Schmidt Independence Criterion (HSIC) to factorize the representations
into multiple factors and proposes a masked self-contrast mechanism to better
separate positive and negative samples. Further, Since the triplet loss only
optimizes the relative distance between the anchor and its positive/negative
samples, it is difficult to ensure the absolute distance between the anchor and
positive sample. Therefore, we explicitly reduced the absolute distance between
the anchor and positive sample to accelerate convergence. Finally, we conduct
extensive experiments to evaluate the performance of GraphSC against 19 other
state-of-the-art methods in both unsupervised and transfer learning settings.
</p>
</div>
</dd>
<dt><a name="item701">[701]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.02311" title="Abstract">arXiv:2309.02311</a> [<a href="/pdf/2309.02311" title="Download PDF">pdf</a>, <a href="/format/2309.02311" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Weigh Your Own Words: Improving Hate Speech Counter Narrative Generation  via Attention Regularization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bonaldi%2C+H">Helena Bonaldi</a>, 
<a href="/search/cs?searchtype=author&query=Attanasio%2C+G">Giuseppe Attanasio</a>, 
<a href="/search/cs?searchtype=author&query=Nozza%2C+D">Debora Nozza</a>, 
<a href="/search/cs?searchtype=author&query=Guerini%2C+M">Marco Guerini</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To appear at CS4OA workshop (INLG-SIGDial)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Recent computational approaches for combating online hate speech involve the
automatic generation of counter narratives by adapting Pretrained
Transformer-based Language Models (PLMs) with human-curated data. This process,
however, can produce in-domain overfitting, resulting in models generating
acceptable narratives only for hatred similar to training data, with little
portability to other targets or to real-world toxic language. This paper
introduces novel attention regularization methodologies to improve the
generalization capabilities of PLMs for counter narratives generation.
Overfitting to training-specific terms is then discouraged, resulting in more
diverse and richer narratives. We experiment with two attention-based
regularization techniques on a benchmark English dataset. Regularized models
produce better counter narratives than state-of-the-art approaches in most
cases, both in terms of automatic metrics and human evaluation, especially when
hateful targets are not present in the training data. This work paves the way
for better and more flexible counter-speech generation models, a task for which
datasets are highly challenging to produce.
</p>
</div>
</dd>
<dt><a name="item702">[702]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.02317" title="Abstract">arXiv:2309.02317</a> [<a href="/pdf/2309.02317" title="Download PDF">pdf</a>, <a href="/format/2309.02317" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A study on the impact of pre-trained model on Just-In-Time defect  prediction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Guo%2C+Y">Yuxiang Guo</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+X">Xiaopeng Gao</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zhenyu Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Chan%2C+W+K">W.K.Chan</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+B">Bo Jiang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Previous researchers conducting Just-In-Time (JIT) defect prediction tasks
have primarily focused on the performance of individual pre-trained models,
without exploring the relationship between different pre-trained models as
backbones. In this study, we build six models: RoBERTaJIT, CodeBERTJIT,
BARTJIT, PLBARTJIT, GPT2JIT, and CodeGPTJIT, each with a distinct pre-trained
model as its backbone. We systematically explore the differences and
connections between these models. Specifically, we investigate the performance
of the models when using Commit code and Commit message as inputs, as well as
the relationship between training efficiency and model distribution among these
six models. Additionally, we conduct an ablation experiment to explore the
sensitivity of each model to inputs. Furthermore, we investigate how the models
perform in zero-shot and few-shot scenarios. Our findings indicate that each
model based on different backbones shows improvements, and when the backbone's
pre-training model is similar, the training resources that need to be consumed
are much more closer. We also observe that Commit code plays a significant role
in defect detection, and different pre-trained models demonstrate better defect
detection ability with a balanced dataset under few-shot scenarios. These
results provide new insights for optimizing JIT defect prediction tasks using
pre-trained models and highlight the factors that require more attention when
constructing such models. Additionally, CodeGPTJIT and GPT2JIT achieved better
performance than DeepJIT and CC2Vec on the two datasets respectively under 2000
training samples. These findings emphasize the effectiveness of
transformer-based pre-trained models in JIT defect prediction tasks, especially
in scenarios with limited training data.
</p>
</div>
</dd>
<dt><a name="item703">[703]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.02318" title="Abstract">arXiv:2309.02318</a> [<a href="/pdf/2309.02318" title="Download PDF">pdf</a>, <a href="/format/2309.02318" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> TiAVox: Time-aware Attenuation Voxels for Sparse-view 4D DSA  Reconstruction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Z">Zhenghong Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+H">Huangxuan Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Fang%2C+J">Jiemin Fang</a>, 
<a href="/search/cs?searchtype=author&query=Xiang%2C+D">Dongqiao Xiang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+L">Lei Chen</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+L">Lingxia Wu</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+F">Feihong Wu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+W">Wenyu Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+C">Chuansheng Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xinggang Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 8 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Image and Video Processing (eess.IV)

</div>
<p class="mathjax">Four-dimensional Digital Subtraction Angiography (4D DSA) plays a critical
role in the diagnosis of many medical diseases, such as Arteriovenous
Malformations (AVM) and Arteriovenous Fistulas (AVF). Despite its significant
application value, the reconstruction of 4D DSA demands numerous views to
effectively model the intricate vessels and radiocontrast flow, thereby
implying a significant radiation dose. To address this high radiation issue, we
propose a Time-aware Attenuation Voxel (TiAVox) approach for sparse-view 4D DSA
reconstruction, which paves the way for high-quality 4D imaging. Additionally,
2D and 3D DSA imaging results can be generated from the reconstructed 4D DSA
images. TiAVox introduces 4D attenuation voxel grids, which reflect attenuation
properties from both spatial and temporal dimensions. It is optimized by
minimizing discrepancies between the rendered images and sparse 2D DSA images.
Without any neural network involved, TiAVox enjoys specific physical
interpretability. The parameters of each learnable voxel represent the
attenuation coefficients. We validated the TiAVox approach on both clinical and
simulated datasets, achieving a 31.23 Peak Signal-to-Noise Ratio (PSNR) for
novel view synthesis using only 30 views on the clinically sourced dataset,
whereas traditional Feldkamp-Davis-Kress methods required 133 views. Similarly,
with merely 10 views from the synthetic dataset, TiAVox yielded a PSNR of 34.32
for novel view synthesis and 41.40 for 3D reconstruction. We also executed
ablation studies to corroborate the essential components of TiAVox. The code
will be publically available.
</p>
</div>
</dd>
<dt><a name="item704">[704]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.02322" title="Abstract">arXiv:2309.02322</a> [<a href="/pdf/2309.02322" title="Download PDF">pdf</a>, <a href="/format/2309.02322" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fairness of Exposure in Dynamic Recommendation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mansoury%2C+M">Masoud Mansoury</a>, 
<a href="/search/cs?searchtype=author&query=Mobasher%2C+B">Bamshad Mobasher</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>

</div>
<p class="mathjax">Exposure bias is a well-known issue in recommender systems where the exposure
is not fairly distributed among items in the recommendation results. This is
especially problematic when bias is amplified over time as a few items (e.g.,
popular ones) are repeatedly over-represented in recommendation lists and
users' interactions with those items will amplify bias towards those items over
time resulting in a feedback loop. This issue has been extensively studied in
the literature in static recommendation environment where a single round of
recommendation result is processed to improve the exposure fairness. However,
less work has been done on addressing exposure bias in a dynamic recommendation
setting where the system is operating over time, the recommendation model and
the input data are dynamically updated with ongoing user feedback on
recommended items at each round. In this paper, we study exposure bias in a
dynamic recommendation setting. Our goal is to show that existing bias
mitigation methods that are designed to operate in a static recommendation
setting are unable to satisfy fairness of exposure for items in long run. In
particular, we empirically study one of these methods and show that repeatedly
applying this method fails to fairly distribute exposure among items in long
run. To address this limitation, we show how this method can be adapted to
effectively operate in a dynamic recommendation setting and achieve exposure
fairness for items in long run. Experiments on a real-world dataset confirm
that our solution is superior in achieving long-term exposure fairness for the
items while maintaining the recommendation accuracy.
</p>
</div>
</dd>
<dt><a name="item705">[705]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.02324" title="Abstract">arXiv:2309.02324</a> [<a href="/pdf/2309.02324" title="Download PDF">pdf</a>, <a href="/format/2309.02324" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Accurate Solution of the Nonlinear Schr&#xf6;dinger Equation via  Conservative Multiple-Relaxation ImEx Methods
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Biswas%2C+A">Abhijit Biswas</a>, 
<a href="/search/math?searchtype=author&query=Ketcheson%2C+D+I">David I. Ketcheson</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">The nonlinear Schr\"{o}dinger (NLS) equation possesses an infinite hierarchy
of conserved densities and the numerical preservation of some of these
quantities is critical for accurate long-time simulations, particularly for
multi-soliton solutions. We propose an essentially explicit discretization that
conserves one or two of these conserved quantities by combining higher-order
Implicit-Explicit (ImEx) Runge-Kutta time integrators with the relaxation
technique and adaptive step size control. We show through numerical tests that
our mass-conserving method is much more efficient and accurate than the
widely-used 2nd-order time-splitting pseudospectral approach. Compared to
higher-order operator splitting, it gives similar results in general and
significantly better results near the semi-classical limit. Furthermore, for
some problems adaptive time stepping provides a dramatic reduction in cost
without sacrificing accuracy. We also propose a full discretization that
conserves both mass and energy by using a conservative finite element spatial
discretization and multiple relaxation in time. Our results suggest that this
method provides a qualitative improvement in long-time error growth for
multi-soliton solutions.
</p>
</div>
</dd>
<dt><a name="item706">[706]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.02326" title="Abstract">arXiv:2309.02326</a> [<a href="/pdf/2309.02326" title="Download PDF">pdf</a>, <a href="/format/2309.02326" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Revisiting File Context for Source Code Summarization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bansal%2C+A">Aakash Bansal</a>, 
<a href="/search/cs?searchtype=author&query=Su%2C+C">Chia-Yi Su</a>, 
<a href="/search/cs?searchtype=author&query=McMillan%2C+C">Collin McMillan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 27 pages + references, Under peer review
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Source code summarization is the task of writing natural language
descriptions of source code. A typical use case is generating short summaries
of subroutines for use in API documentation. The heart of almost all current
research into code summarization is the encoder-decoder neural architecture,
and the encoder input is almost always a single subroutine or other short code
snippet. The problem with this setup is that the information needed to describe
the code is often not present in the code itself -- that information often
resides in other nearby code. In this paper, we revisit the idea of ``file
context'' for code summarization. File context is the idea of encoding select
information from other subroutines in the same file. We propose a novel
modification of the Transformer architecture that is purpose-built to encode
file context and demonstrate its improvement over several baselines. We find
that file context helps on a subset of challenging examples where traditional
approaches struggle.
</p>
</div>
</dd>
<dt><a name="item707">[707]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.02328" title="Abstract">arXiv:2309.02328</a> [<a href="/pdf/2309.02328" title="Download PDF">pdf</a>, <a href="/format/2309.02328" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Neurosymbolic Meta-Reinforcement Lookahead Learning Achieves Safe  Self-Driving in Non-Stationary Environments
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lei%2C+H">Haozhe Lei</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+Q">Quanyan Zhu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI); Systems and Control (eess.SY); Machine Learning (stat.ML)

</div>
<p class="mathjax">In the area of learning-driven artificial intelligence advancement, the
integration of machine learning (ML) into self-driving (SD) technology stands
as an impressive engineering feat. Yet, in real-world applications outside the
confines of controlled laboratory scenarios, the deployment of self-driving
technology assumes a life-critical role, necessitating heightened attention
from researchers towards both safety and efficiency. To illustrate, when a
self-driving model encounters an unfamiliar environment in real-time execution,
the focus must not solely revolve around enhancing its anticipated performance;
equal consideration must be given to ensuring its execution or real-time
adaptation maintains a requisite level of safety. This study introduces an
algorithm for online meta-reinforcement learning, employing lookahead symbolic
constraints based on \emph{Neurosymbolic Meta-Reinforcement Lookahead Learning}
(NUMERLA). NUMERLA proposes a lookahead updating mechanism that harmonizes the
efficiency of online adaptations with the overarching goal of ensuring
long-term safety. Experimental results demonstrate NUMERLA confers the
self-driving agent with the capacity for real-time adaptability, leading to
safe and self-adaptive driving under non-stationary urban human-vehicle
interaction scenarios.
</p>
</div>
</dd>
<dt><a name="item708">[708]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.02334" title="Abstract">arXiv:2309.02334</a> [<a href="/pdf/2309.02334" title="Download PDF">pdf</a>, <a href="/format/2309.02334" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PolyLUT: Learning Piecewise Polynomials for Ultra-Low Latency FPGA  LUT-based Inference
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Andronic%2C+M">Marta Andronic</a>, 
<a href="/search/cs?searchtype=author&query=Constantinides%2C+G+A">George A. Constantinides</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Hardware Architecture (cs.AR); Machine Learning (stat.ML)

</div>
<p class="mathjax">Field-programmable gate arrays (FPGAs) are widely used to implement deep
learning inference. Standard deep neural network inference involves the
computation of interleaved linear maps and nonlinear activation functions.
Prior work for ultra-low latency implementations has hardcoded the combination
of linear maps and nonlinear activations inside FPGA lookup tables (LUTs). Our
work is motivated by the idea that the LUTs in an FPGA can be used to implement
a much greater variety of functions than this. In this paper, we propose a
novel approach to training neural networks for FPGA deployment using
multivariate polynomials as the basic building block. Our method takes
advantage of the flexibility offered by the soft logic, hiding the polynomial
evaluation inside the LUTs with zero overhead. We show that by using polynomial
building blocks, we can achieve the same accuracy using considerably fewer
layers of soft logic than by using linear functions, leading to significant
latency and area improvements. We demonstrate the effectiveness of this
approach in three tasks: network intrusion detection, jet identification at the
CERN Large Hadron Collider, and handwritten digit recognition using the MNIST
dataset.
</p>
</div>
</dd>
<dt><a name="item709">[709]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.02340" title="Abstract">arXiv:2309.02340</a> [<a href="/pdf/2309.02340" title="Download PDF">pdf</a>, <a href="/format/2309.02340" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Generating Infinite-Resolution Texture using GANs with Patch-by-Patch  Paradigm
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Abdellatif%2C+A">Alhasan Abdellatif</a>, 
<a href="/search/cs?searchtype=author&query=Elsheikh%2C+A+H">Ahmed H. Elsheikh</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Image and Video Processing (eess.IV)

</div>
<p class="mathjax">In this paper, we introduce a novel approach for generating texture images of
infinite resolutions using Generative Adversarial Networks (GANs) based on a
patch-by-patch paradigm. Existing texture synthesis techniques often rely on
generating a large-scale texture using a one-forward pass to the generating
model, this limits the scalability and flexibility of the generated images. In
contrast, the proposed approach trains GANs models on a single texture image to
generate relatively small patches that are locally correlated and can be
seamlessly concatenated to form a larger image while using a constant GPU
memory footprint. Our method learns the local texture structure and is able to
generate arbitrary-size textures, while also maintaining coherence and
diversity. The proposed method relies on local padding in the generator to
ensure consistency between patches and utilizes spatial stochastic modulation
to allow for local variations and diversity within the large-scale image.
Experimental results demonstrate superior scalability compared to existing
approaches while maintaining visual coherence of generated textures.
</p>
</div>
</dd>
<dt><a name="item710">[710]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.02351" title="Abstract">arXiv:2309.02351</a> [<a href="/pdf/2309.02351" title="Download PDF">pdf</a>, <a href="/format/2309.02351" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exact Inference for Continuous-Time Gaussian Process Dynamics
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ensinger%2C+K">Katharina Ensinger</a>, 
<a href="/search/cs?searchtype=author&query=Tagliapietra%2C+N">Nicholas Tagliapietra</a>, 
<a href="/search/cs?searchtype=author&query=Ziesche%2C+S">Sebastian Ziesche</a>, 
<a href="/search/cs?searchtype=author&query=Trimpe%2C+S">Sebastian Trimpe</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
<p class="mathjax">Physical systems can often be described via a continuous-time dynamical
system. In practice, the true system is often unknown and has to be learned
from measurement data. Since data is typically collected in discrete time, e.g.
by sensors, most methods in Gaussian process (GP) dynamics model learning are
trained on one-step ahead predictions. This can become problematic in several
scenarios, e.g. if measurements are provided at irregularly-sampled time steps
or physical system properties have to be conserved. Thus, we aim for a GP model
of the true continuous-time dynamics. Higher-order numerical integrators
provide the necessary tools to address this problem by discretizing the
dynamics function with arbitrary accuracy. Many higher-order integrators
require dynamics evaluations at intermediate time steps making exact GP
inference intractable. In previous work, this problem is often tackled by
approximating the GP posterior with variational inference. However, exact GP
inference is preferable in many scenarios, e.g. due to its mathematical
guarantees. In order to make direct inference tractable, we propose to leverage
multistep and Taylor integrators. We demonstrate how to derive flexible
inference schemes for these types of integrators. Further, we derive tailored
sampling schemes that allow to draw consistent dynamics functions from the
learned posterior. This is crucial to sample consistent predictions from the
dynamics model. We demonstrate empirically and theoretically that our approach
yields an accurate representation of the continuous-time system.
</p>
</div>
</dd>
<dt><a name="item711">[711]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.02354" title="Abstract">arXiv:2309.02354</a> [<a href="/pdf/2309.02354" title="Download PDF">pdf</a>, <a href="/format/2309.02354" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Lightweight and Transferable Design for Robust LEGO Manipulation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+R">Ruixuan Liu</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+Y">Yifan Sun</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+C">Changliu Liu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Machine Learning (cs.LG); Neural and Evolutionary Computing (cs.NE)

</div>
<p class="mathjax">LEGO is a well-known platform for prototyping pixelized objects. However,
robotic LEGO prototyping (i.e. manipulating LEGO bricks) is challenging due to
the tight connections and accuracy requirement. This paper investigates safe
and efficient robotic LEGO manipulation. In particular, this paper reduces the
complexity of the manipulation by hardware-software co-design. An end-of-arm
tool (EOAT) is designed, which reduces the problem dimension and allows large
industrial robots to easily manipulate LEGO bricks. In addition, this paper
uses evolution strategy to safely optimize the robot motion for LEGO
manipulation. Experiments demonstrate that the EOAT performs reliably in
manipulating LEGO bricks and the learning framework can effectively and safely
improve the manipulation performance to a 100\% success rate. The co-design is
deployed to multiple robots (i.e. FANUC LR-mate 200id/7L and Yaskawa GP4) to
demonstrate its generalizability and transferability. In the end, we show that
the proposed solution enables sustainable robotic LEGO prototyping, in which
the robot can repeatedly assemble and disassemble different prototypes.
</p>
</div>
</dd>
<dt><a name="item712">[712]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.02356" title="Abstract">arXiv:2309.02356</a> [<a href="/pdf/2309.02356" title="Download PDF">pdf</a>, <a href="/format/2309.02356" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> STEP -- Towards Structured Scene-Text Spotting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Garcia-Bordils%2C+S">Sergi Garcia-Bordils</a>, 
<a href="/search/cs?searchtype=author&query=Karatzas%2C+D">Dimosthenis Karatzas</a>, 
<a href="/search/cs?searchtype=author&query=Rusi%C3%B1ol%2C+M">Mar&#xe7;al Rusi&#xf1;ol</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 15 pages, 11 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">We introduce the structured scene-text spotting task, which requires a
scene-text OCR system to spot text in the wild according to a query regular
expression. Contrary to generic scene text OCR, structured scene-text spotting
seeks to dynamically condition both scene text detection and recognition on
user-provided regular expressions. To tackle this task, we propose the
Structured TExt sPotter (STEP), a model that exploits the provided text
structure to guide the OCR process. STEP is able to deal with regular
expressions that contain spaces and it is not bound to detection at the
word-level granularity. Our approach enables accurate zero-shot structured text
spotting in a wide variety of real-world reading scenarios and is solely
trained on publicly available data. To demonstrate the effectiveness of our
approach, we introduce a new challenging test dataset that contains several
types of out-of-vocabulary structured text, reflecting important reading
applications of fields such as prices, dates, serial numbers, license plates
etc. We demonstrate that STEP can provide specialised OCR performance on demand
in all tested scenarios.
</p>
</div>
</dd>
<dt><a name="item713">[713]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.02367" title="Abstract">arXiv:2309.02367</a> [<a href="/pdf/2309.02367" title="Download PDF">pdf</a>, <a href="/ps/2309.02367" title="Download PostScript">ps</a>, <a href="/format/2309.02367" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Minimal modal logics, constructive modal logics and their relations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dalmonte%2C+T">Tiziano Dalmonte</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>

</div>
<p class="mathjax">We present a family of minimal modal logics (namely, modal logics based on
minimal propositional logic) corresponding each to a different classical modal
logic. The minimal modal logics are defined based on their classical
counterparts in two distinct ways: (1) via embedding into fusions of classical
modal logics through a natural extension of the G\"odel-Johansson translation
of minimal logic into modal logic S4; (2) via extension to modal logics of the
multi- vs. single-succedent correspondence of sequent calculi for classical and
minimal logic. We show that, despite being mutually independent, the two
methods turn out to be equivalent for a wide class of modal systems. Moreover,
we compare the resulting minimal version of K with the constructive modal logic
CK studied in the literature, displaying tight relations among the two systems.
Based on these relations, we also define a constructive correspondent for each
minimal system, thus obtaining a family of constructive modal logics which
includes CK as well as other constructive modal logics studied in the
literature.
</p>
</div>
</dd>
<dt><a name="item714">[714]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.02373" title="Abstract">arXiv:2309.02373</a> [<a href="/pdf/2309.02373" title="Download PDF">pdf</a>, <a href="/format/2309.02373" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> nanoT5: A PyTorch Framework for Pre-training and Fine-tuning T5-style  Models with Limited Resources
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nawrot%2C+P">Piotr Nawrot</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">State-of-the-art language models like T5 have revolutionized the NLP
landscape, but their computational demands hinder a large portion of the
research community. To address this challenge, we present nanoT5, a
specially-optimized PyTorch framework for efficient pre-training and
fine-tuning of T5 models. Drawing on insights from optimizer differences and
prioritizing efficiency, nanoT5 allows a T5-Base model to be pre-trained on a
single GPU in just 16 hours, without any loss in performance. With the
introduction of this open-source framework, we hope to widen the accessibility
to language modelling research and cater to the community's demand for more
user-friendly T5 (Encoder-Decoder) implementations. Our contributions,
including configurations, codebase, software/hardware insights, and pre-trained
models, are available to the public, aiming to strike a balance between
research accessibility and resource constraints in NLP.
</p>
</div>
</dd>
<dt><a name="item715">[715]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.02383" title="Abstract">arXiv:2309.02383</a> [<a href="/pdf/2309.02383" title="Download PDF">pdf</a>, <a href="/format/2309.02383" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> From Curves to Words and Back Again: Geometric Computation of  Minimum-Area Homotopy
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chang%2C+H">Hsien-Chih Chang</a>, 
<a href="/search/cs?searchtype=author&query=Fasy%2C+B+T">Brittany Terese Fasy</a>, 
<a href="/search/cs?searchtype=author&query=McCoy%2C+B">Bradley McCoy</a>, 
<a href="/search/cs?searchtype=author&query=Millman%2C+D+L">David L. Millman</a>, 
<a href="/search/cs?searchtype=author&query=Wenk%2C+C">Carola Wenk</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 27 pages, 16 figures
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Proc. 18th Algorithms and Data Structures Symposium. 605-619, 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Geometry (cs.CG)</span>; Geometric Topology (math.GT)

</div>
<p class="mathjax">Let $\gamma$ be a generic closed curve in the plane. Samuel Blank, in his
1967 Ph.D. thesis, determined if $\gamma$ is self-overlapping by geometrically
constructing a combinatorial word from $\gamma$. More recently, Zipei Nie, in
an unpublished manuscript, computed the minimum homotopy area of $\gamma$ by
constructing a combinatorial word algebraically. We provide a unified framework
for working with both words and determine the settings under which Blank's word
and Nie's word are equivalent. Using this equivalence, we give a new geometric
proof for the correctness of Nie's algorithm. Unlike previous work, our proof
is constructive which allows us to naturally compute the actual homotopy that
realizes the minimum area. Furthermore, we contribute to the theory of
self-overlapping curves by providing the first polynomial-time algorithm to
compute a self-overlapping decomposition of any closed curve $\gamma$ with
minimum area.
</p>
</div>
</dd>
<dt><a name="item716">[716]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.02384" title="Abstract">arXiv:2309.02384</a> [<a href="/pdf/2309.02384" title="Download PDF">pdf</a>, <a href="/format/2309.02384" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Parameter Dependent Robust Control Invariant Sets for LPV Systems with  Bounded Parameter Variation Rate
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Mulagaleti%2C+S+K">Sampath Kumar Mulagaleti</a>, 
<a href="/search/eess?searchtype=author&query=Mejari%2C+M">Manas Mejari</a>, 
<a href="/search/eess?searchtype=author&query=Bemporad%2C+A">Alberto Bemporad</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 6 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">Real-time measurements of the scheduling parameter of linear
parameter-varying (LPV) systems enables the synthesis of robust control
invariant (RCI) sets and parameter dependent controllers inducing invariance.
We present a method to synthesize parameter-dependent robust control invariant
(PD-RCI) sets for LPV systems with bounded parameter variation, in which
invariance is induced using PD-vertex control laws. The PD-RCI sets are
parameterized as configuration-constrained polytopes that admit a joint
parameterization of their facets and vertices. The proposed sets and associated
control laws are computed by solving a single semidefinite programing (SDP)
problem. Through numerical examples, we demonstrate that the proposed method
outperforms state-of-the-art methods for synthesizing PD-RCI sets, both with
respect to conservativeness and computational load.
</p>
</div>
</dd>
<dt><a name="item717">[717]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.02385" title="Abstract">arXiv:2309.02385</a> [<a href="/pdf/2309.02385" title="Download PDF">pdf</a>, <a href="/format/2309.02385" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Hybrid Design of Multiplicative Watermarking for Defense Against  Malicious Parameter Identification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Zhang%2C+J">Jiaxuan Zhang</a>, 
<a href="/search/eess?searchtype=author&query=Gallo%2C+A+J">Alexander J. Gallo</a>, 
<a href="/search/eess?searchtype=author&query=Ferrari%2C+R+M+G">Riccardo M. G. Ferrari</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, first submission to the 62nd IEEE Conference on Decision and Control
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Cryptography and Security (cs.CR); Multimedia (cs.MM)

</div>
<p class="mathjax">Watermarking is a promising active diagnosis technique for detection of
highly sophisticated attacks, but is vulnerable to malicious agents that use
eavesdropped data to identify and then remove or replicate the watermark. In
this work, we propose a hybrid multiplicative watermarking (HMWM) scheme, where
the watermark parameters are periodically updated, following the dynamics of
the unobservable states of specifically designed piecewise affine (PWA) hybrid
systems. We provide a theoretical analysis of the effects of this scheme on the
closed-loop performance, and prove that stability properties are preserved.
Additionally, we show that the proposed approach makes it difficult for an
eavesdropper to reconstruct the watermarking parameters, both in terms of the
associated computational complexity and from a systems theoretic perspective.
</p>
</div>
</dd>
<dt><a name="item718">[718]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.02388" title="Abstract">arXiv:2309.02388</a> [<a href="/pdf/2309.02388" title="Download PDF">pdf</a>, <a href="/format/2309.02388" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A stochastic LATIN method for stochastic and parameterized elastoplastic  analysis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Zheng%2C+Z">Zhibao Zheng</a>, 
<a href="/search/math?searchtype=author&query=N%C3%A9ron%2C+D">David N&#xe9;ron</a>, 
<a href="/search/math?searchtype=author&query=Nackenhorst%2C+U">Udo Nackenhorst</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">The LATIN method has been developed and successfully applied to a variety of
deterministic problems, but few work has been developed for nonlinear
stochastic problems. This paper presents a stochastic LATIN method to solve
stochastic and/or parameterized elastoplastic problems. To this end, the
stochastic solution is decoupled into spatial, temporal and stochastic spaces,
and approximated by the sum of a set of products of triplets of spatial
functions, temporal functions and random variables. Each triplet is then
calculated in a greedy way using a stochastic LATIN iteration. The high
efficiency of the proposed method relies on two aspects: The nonlinearity is
efficiently handled by inheriting advantages of the classical LATIN method, and
the randomness and/or parameters are effectively treated by a sample-based
approximation of stochastic spaces. Further, the proposed method is not
sensitive to the stochastic and/or parametric dimensions of inputs due to the
sample description of stochastic spaces. It can thus be applied to
high-dimensional stochastic and parameterized problems. Four numerical examples
demonstrate the promising performance of the proposed stochastic LATIN method.
</p>
</div>
</dd>
<dt><a name="item719">[719]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.02389" title="Abstract">arXiv:2309.02389</a> [<a href="/pdf/2309.02389" title="Download PDF">pdf</a>, <a href="/format/2309.02389" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Contextual Predictive Mutation Testing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jain%2C+K">Kush Jain</a>, 
<a href="/search/cs?searchtype=author&query=Alon%2C+U">Uri Alon</a>, 
<a href="/search/cs?searchtype=author&query=Groce%2C+A">Alex Groce</a>, 
<a href="/search/cs?searchtype=author&query=Goues%2C+C+L">Claire Le Goues</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
<p class="mathjax">Mutation testing is a powerful technique for assessing and improving test
suite quality that artificially introduces bugs and checks whether the test
suites catch them. However, it is also computationally expensive and thus does
not scale to large systems and projects. One promising recent approach to
tackling this scalability problem uses machine learning to predict whether the
tests will detect the synthetic bugs, without actually running those tests.
However, existing predictive mutation testing approaches still misclassify 33%
of detection outcomes on a randomly sampled set of mutant-test suite pairs. We
introduce MutationBERT, an approach for predictive mutation testing that
simultaneously encodes the source method mutation and test method, capturing
key context in the input representation. Thanks to its higher precision,
MutationBERT saves 33% of the time spent by a prior approach on
checking/verifying live mutants. MutationBERT, also outperforms the
state-of-the-art in both same project and cross project settings, with
meaningful improvements in precision, recall, and F1 score. We validate our
input representation, and aggregation approaches for lifting predictions from
the test matrix level to the test suite level, finding similar improvements in
performance. MutationBERT not only enhances the state-of-the-art in predictive
mutation testing, but also presents practical benefits for real-world
applications, both in saving developer time and finding hard to detect mutants.
</p>
</div>
</dd>
<dt><a name="item720">[720]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.02390" title="Abstract">arXiv:2309.02390</a> [<a href="/pdf/2309.02390" title="Download PDF">pdf</a>, <a href="/format/2309.02390" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Explaining grokking through circuit efficiency
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Varma%2C+V">Vikrant Varma</a>, 
<a href="/search/cs?searchtype=author&query=Shah%2C+R">Rohin Shah</a>, 
<a href="/search/cs?searchtype=author&query=Kenton%2C+Z">Zachary Kenton</a>, 
<a href="/search/cs?searchtype=author&query=Kram%C3%A1r%2C+J">J&#xe1;nos Kram&#xe1;r</a>, 
<a href="/search/cs?searchtype=author&query=Kumar%2C+R">Ramana Kumar</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">One of the most surprising puzzles in neural network generalisation is
grokking: a network with perfect training accuracy but poor generalisation
will, upon further training, transition to perfect generalisation. We propose
that grokking occurs when the task admits a generalising solution and a
memorising solution, where the generalising solution is slower to learn but
more efficient, producing larger logits with the same parameter norm. We
hypothesise that memorising circuits become more inefficient with larger
training datasets while generalising circuits do not, suggesting there is a
critical dataset size at which memorisation and generalisation are equally
efficient. We make and confirm four novel predictions about grokking, providing
significant evidence in favour of our explanation. Most strikingly, we
demonstrate two novel and surprising behaviours: ungrokking, in which a network
regresses from perfect to low test accuracy, and semi-grokking, in which a
network shows delayed generalisation to partial rather than perfect test
accuracy.
</p>
</div>
</dd>
<dt><a name="item721">[721]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.02391" title="Abstract">arXiv:2309.02391</a> [<a href="/pdf/2309.02391" title="Download PDF">pdf</a>, <a href="/format/2309.02391" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Empirical Review of Smart Contract and DeFi Security: Vulnerability  Detection and Automated Repair
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Qian%2C+P">Peng Qian</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+R">Rui Cao</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+W">Wenqing Li</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+M">Ming Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+L">Lun Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Eskil">Eskil</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Jianhai Chen</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+Q">Qinming He</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This paper is submitted to the journal of Expert Systems with Applications (ESWA) for review
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Software Engineering (cs.SE)

</div>
<p class="mathjax">Decentralized Finance (DeFi) is emerging as a peer-to-peer financial
ecosystem, enabling participants to trade products on a permissionless
blockchain. Built on blockchain and smart contracts, the DeFi ecosystem has
experienced explosive growth in recent years. Unfortunately, smart contracts
hold a massive amount of value, making them an attractive target for attacks.
So far, attacks against smart contracts and DeFi protocols have resulted in
billions of dollars in financial losses, severely threatening the security of
the entire DeFi ecosystem. Researchers have proposed various security tools for
smart contracts and DeFi protocols as countermeasures. However, a comprehensive
investigation of these efforts is still lacking, leaving a crucial gap in our
understanding of how to enhance the security posture of the smart contract and
DeFi landscape.
<br />To fill the gap, this paper reviews the progress made in the field of smart
contract and DeFi security from the perspective of both vulnerability detection
and automated repair. First, we analyze the DeFi smart contract security issues
and challenges. Specifically, we lucubrate various DeFi attack incidents and
summarize the attacks into six categories. Then, we present an empirical study
of 42 state-of-the-art techniques that can detect smart contract and DeFi
vulnerabilities. In particular, we evaluate the effectiveness of traditional
smart contract bug detection tools in analyzing complex DeFi protocols.
Additionally, we investigate 8 existing automated repair tools for smart
contracts and DeFi protocols, providing insight into their advantages and
disadvantages. To make this work useful for as wide of an audience as possible,
we also identify several open issues and challenges in the DeFi ecosystem that
should be addressed in the future.
</p>
</div>
</dd>
<dt><a name="item722">[722]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.02394" title="Abstract">arXiv:2309.02394</a> [<a href="/pdf/2309.02394" title="Download PDF">pdf</a>, <a href="/format/2309.02394" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Magnetic Navigation using Attitude-Invariant Magnetic Field Information  for Loop Closure Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pavlasek%2C+N">Natalia Pavlasek</a>, 
<a href="/search/cs?searchtype=author&query=Cossette%2C+C+C">Charles Champagne Cossette</a>, 
<a href="/search/cs?searchtype=author&query=Roy-Guay%2C+D">David Roy-Guay</a>, 
<a href="/search/cs?searchtype=author&query=Forbes%2C+J+R">James Richard Forbes</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Indoor magnetic fields are a combination of Earth's magnetic field and
disruptions induced by ferromagnetic objects, such as steel structural
components in buildings. As a result of these disruptions, pervasive in indoor
spaces, magnetic field data is often omitted from navigation algorithms in
indoor environments. This paper leverages the spatially-varying disruptions to
Earth's magnetic field to extract positional information for use in indoor
navigation algorithms. The algorithm uses a rate gyro and an array of four
magnetometers to estimate the robot's pose. Additionally, the magnetometer
array is used to compute attitude-invariant measurements associated with the
magnetic field and its gradient. These measurements are used to detect loop
closure points. Experimental results indicate that the proposed approach can
estimate the pose of a ground robot in an indoor environment within meter
accuracy.
</p>
</div>
</dd>
<dt><a name="item723">[723]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.02395" title="Abstract">arXiv:2309.02395</a> [<a href="/pdf/2309.02395" title="Download PDF">pdf</a>, <a href="/ps/2309.02395" title="Download PostScript">ps</a>, <a href="/format/2309.02395" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Mind the Gap: The Difference Between Coverage and Mutation Score Can  Guide Testing Efforts
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jain%2C+K">Kush Jain</a>, 
<a href="/search/cs?searchtype=author&query=Kalburgi%2C+G+T">Goutamkumar Tulajappa Kalburgi</a>, 
<a href="/search/cs?searchtype=author&query=Goues%2C+C+L">Claire Le Goues</a>, 
<a href="/search/cs?searchtype=author&query=Groce%2C+A">Alex Groce</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
<p class="mathjax">An "adequate" test suite should effectively find all inconsistencies between
a system's requirements/specifications and its implementation. Practitioners
frequently use code coverage to approximate adequacy, while academics argue
that mutation score may better approximate true (oracular) adequacy coverage.
High code coverage is increasingly attainable even on large systems via
automatic test generation, including fuzzing. In light of all of these options
for measuring and improving testing effort, how should a QA engineer spend
their time? We propose a new framework for reasoning about the extent, limits,
and nature of a given testing effort based on an idea we call the oracle gap,
or the difference between source code coverage and mutation score for a given
software element. We conduct (1) a large-scale observational study of the
oracle gap across popular Maven projects, (2) a study that varies testing and
oracle quality across several of those projects and (3) a small-scale
observational study of highly critical, well-tested code across comparable
blockchain projects. We show that the oracle gap surfaces important information
about the extent and quality of a test effort beyond either adequacy metric
alone. In particular, it provides a way for practitioners to identify source
files where it is likely a weak oracle tests important code.
</p>
</div>
</dd>
<dt><a name="item724">[724]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.02396" title="Abstract">arXiv:2309.02396</a> [<a href="/pdf/2309.02396" title="Download PDF">pdf</a>, <a href="/format/2309.02396" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Black-Box Attacks against Signed Graph Analysis via Balance Poisoning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhou%2C+J">Jialong Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Lai%2C+Y">Yuni Lai</a>, 
<a href="/search/cs?searchtype=author&query=Ren%2C+J">Jian Ren</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+K">Kai Zhou</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Social and Information Networks (cs.SI)

</div>
<p class="mathjax">Signed graphs are well-suited for modeling social networks as they capture
both positive and negative relationships. Signed graph neural networks (SGNNs)
are commonly employed to predict link signs (i.e., positive and negative) in
such graphs due to their ability to handle the unique structure of signed
graphs. However, real-world signed graphs are vulnerable to malicious attacks
by manipulating edge relationships, and existing adversarial graph attack
methods do not consider the specific structure of signed graphs. SGNNs often
incorporate balance theory to effectively model the positive and negative
links. Surprisingly, we find that the balance theory that they rely on can
ironically be exploited as a black-box attack. In this paper, we propose a
novel black-box attack called balance-attack that aims to decrease the balance
degree of the signed graphs. We present an efficient heuristic algorithm to
solve this NP-hard optimization problem. We conduct extensive experiments on
five popular SGNN models and four real-world datasets to demonstrate the
effectiveness and wide applicability of our proposed attack method. By
addressing these challenges, our research contributes to a better understanding
of the limitations and resilience of robust models when facing attacks on
SGNNs. This work contributes to enhancing the security and reliability of
signed graph analysis in social network modeling. Our PyTorch implementation of
the attack is publicly available on GitHub:
https://github.com/JialongZhou666/Balance-Attack.git.
</p>
</div>
</dd>
<dt><a name="item725">[725]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.02399" title="Abstract">arXiv:2309.02399</a> [<a href="/pdf/2309.02399" title="Download PDF">pdf</a>, <a href="/format/2309.02399" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Batik-plays-Mozart Corpus: Linking Performance to Score to  Musicological Annotations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hu%2C+P">Patricia Hu</a>, 
<a href="/search/cs?searchtype=author&query=Widmer%2C+G">Gerhard Widmer</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To be published in the Proceedings of the International Society for Music Information Retrieval Conference (ISMIR)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Digital Libraries (cs.DL); Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">We present the Batik-plays-Mozart Corpus, a piano performance dataset
combining professional Mozart piano sonata performances with expert-labelled
scores at a note-precise level. The performances originate from a recording by
Viennese pianist Roland Batik on a computer-monitored B\"osendorfer grand
piano, and are available both as MIDI files and audio recordings. They have
been precisely aligned, note by note, with a current standard edition of the
corresponding scores (the New Mozart Edition) in such a way that they can
further be connected to the musicological annotations (harmony, cadences,
phrases) on these scores that were recently published by Hentschel et al.
(2021).
<br />The result is a high-quality, high-precision corpus mapping scores and
musical structure annotations to precise note-level professional performance
information. As the first of its kind, it can serve as a valuable resource for
studying various facets of expressive performance and their relationship with
structural aspects. In the paper, we outline the curation process of the
alignment and conduct two exploratory experiments to demonstrate its usefulness
in analyzing expressive performance.
</p>
</div>
</dd>
<dt><a name="item726">[726]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.02401" title="Abstract">arXiv:2309.02401</a> [<a href="/pdf/2309.02401" title="Download PDF">pdf</a>, <a href="/format/2309.02401" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Prototype-based Dataset Comparison
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=van+Noord%2C+N">Nanne van Noord</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To be presented at ICCV 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Multimedia (cs.MM)

</div>
<p class="mathjax">Dataset summarisation is a fruitful approach to dataset inspection. However,
when applied to a single dataset the discovery of visual concepts is restricted
to those most prominent. We argue that a comparative approach can expand upon
this paradigm to enable richer forms of dataset inspection that go beyond the
most prominent concepts. To enable dataset comparison we present a module that
learns concept-level prototypes across datasets. We leverage self-supervised
learning to discover these prototypes without supervision, and we demonstrate
the benefits of our approach in two case-studies. Our findings show that
dataset comparison extends dataset inspection and we hope to encourage more
works in this direction. Code and usage instructions available at
https://github.com/Nanne/ProtoSim
</p>
</div>
</dd>
<dt><a name="item727">[727]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.02402" title="Abstract">arXiv:2309.02402</a> [<a href="/pdf/2309.02402" title="Download PDF">pdf</a>, <a href="/format/2309.02402" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Breaking Barriers to Creative Expression: Co-Designing and Implementing  an Accessible Text-to-Image Interface
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Taheri%2C+A">Atieh Taheri</a> (1), 
<a href="/search/cs?searchtype=author&query=Izadi%2C+M">Mohammad Izadi</a> (2), 
<a href="/search/cs?searchtype=author&query=Shriram%2C+G">Gururaj Shriram</a> (2), 
<a href="/search/cs?searchtype=author&query=Rostamzadeh%2C+N">Negar Rostamzadeh</a> (2), 
<a href="/search/cs?searchtype=author&query=Kane%2C+S">Shaun Kane</a> (2) ((1) University of California, Santa Barbara, (2) Google LLC)
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 2 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">Text-to-image generation models have grown in popularity due to their ability
to produce high-quality images from a text prompt. One use for this technology
is to enable the creation of more accessible art creation software. In this
paper, we document the development of an alternative user interface that
reduces the typing effort needed to enter image prompts by providing
suggestions from a large language model, developed through iterative design and
testing within the project team. The results of this testing demonstrate how
generative text models can support the accessibility of text-to-image models,
enabling users with a range of abilities to create visual art.
</p>
</div>
</dd>
<dt><a name="item728">[728]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.02403" title="Abstract">arXiv:2309.02403</a> [<a href="/pdf/2309.02403" title="Download PDF">pdf</a>, <a href="/format/2309.02403" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Substitution-based Semantic Change Detection using Contextual Embeddings
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Card%2C+D">Dallas Card</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> In Proceedings of the 61st Annual Meeting of the Association for
  Computational Linguistics (Volume 2: Short Papers) 2013
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Measuring semantic change has thus far remained a task where methods using
contextual embeddings have struggled to improve upon simpler techniques relying
only on static word vectors. Moreover, many of the previously proposed
approaches suffer from downsides related to scalability and ease of
interpretation. We present a simplified approach to measuring semantic change
using contextual embeddings, relying only on the most probable substitutes for
masked terms. Not only is this approach directly interpretable, it is also far
more efficient in terms of storage, achieves superior average performance
across the most frequently cited datasets for this task, and allows for more
nuanced investigation of change than is possible with static word vectors.
</p>
</div>
</dd>
<dt><a name="item729">[729]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.02404" title="Abstract">arXiv:2309.02404</a> [<a href="/pdf/2309.02404" title="Download PDF">pdf</a>, <a href="/format/2309.02404" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Voice Morphing: Two Identities in One Voice
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pani%2C+S+K">Sushanta K. Pani</a>, 
<a href="/search/cs?searchtype=author&query=Chowdhury%2C+A">Anurag Chowdhury</a>, 
<a href="/search/cs?searchtype=author&query=Sandler%2C+M">Morgan Sandler</a>, 
<a href="/search/cs?searchtype=author&query=Ross%2C+A">Arun Ross</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted oral paper at BIOSIG 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Computer Vision and Pattern Recognition (cs.CV); Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">In a biometric system, each biometric sample or template is typically
associated with a single identity. However, recent research has demonstrated
the possibility of generating "morph" biometric samples that can successfully
match more than a single identity. Morph attacks are now recognized as a
potential security threat to biometric systems. However, most morph attacks
have been studied on biometric modalities operating in the image domain, such
as face, fingerprint, and iris. In this preliminary work, we introduce Voice
Identity Morphing (VIM) - a voice-based morph attack that can synthesize speech
samples that impersonate the voice characteristics of a pair of individuals.
Our experiments evaluate the vulnerabilities of two popular speaker recognition
systems, ECAPA-TDNN and x-vector, to VIM, with a success rate (MMPMR) of over
80% at a false match rate of 1% on the Librispeech dataset.
</p>
</div>
</dd>
<dt><a name="item730">[730]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.02405" title="Abstract">arXiv:2309.02405</a> [<a href="/pdf/2309.02405" title="Download PDF">pdf</a>, <a href="/format/2309.02405" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Generating Realistic Images from In-the-wild Sounds
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lee%2C+T">Taegyeong Lee</a>, 
<a href="/search/cs?searchtype=author&query=Kang%2C+J">Jeonghun Kang</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+H">Hyeonyu Kim</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+T">Taehwan Kim</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to ICCV 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Sound (cs.SD); Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">Representing wild sounds as images is an important but challenging task due
to the lack of paired datasets between sound and images and the significant
differences in the characteristics of these two modalities. Previous studies
have focused on generating images from sound in limited categories or music. In
this paper, we propose a novel approach to generate images from in-the-wild
sounds. First, we convert sound into text using audio captioning. Second, we
propose audio attention and sentence attention to represent the rich
characteristics of sound and visualize the sound. Lastly, we propose a direct
sound optimization with CLIPscore and AudioCLIP and generate images with a
diffusion-based model. In experiments, it shows that our model is able to
generate high quality images from wild sounds and outperforms baselines in both
quantitative and qualitative evaluations on wild audio datasets.
</p>
</div>
</dd>
<dt><a name="item731">[731]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.02406" title="Abstract">arXiv:2309.02406</a> [<a href="/pdf/2309.02406" title="Download PDF">pdf</a>, <a href="/format/2309.02406" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Investment-based optimisation of energy storage design parameters in a  grid-connected hybrid renewable energy system
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Farah%2C+S">Sleiman Farah</a>, 
<a href="/search/eess?searchtype=author&query=Andresen%2C+G+B">Gorm Bruun Andresen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Optimization and Control (math.OC)

</div>
<p class="mathjax">Grid-connected hybrid renewable power systems with energy storage can reduce
the intermittency of renewable power supply. However, emerging energy storage
technologies need improvement to compete with lithium-ion batteries and reduce
the cost of energy. Identifying and optimizing the the most valuable
improvement path of these technologies is challenging due to the non-linearity
of the energy system model when considering parameters as independent
variables. To overcome this, a novel investment-based optimization method is
proposed. The method involves linear optimization of the hybrid renewable
energy system and subsequent investment optimization, accounting for
diminishing improvements per investment. Applied to thermal energy, pumped
thermal energy, molten salt, and adiabatic compressed air energy storage
technologies, the results show that enhancing discharge efficiency is most
valuable for all technologies. Reducing discharge capacity costs and energy
storage capacity cost can also become important. Charge capacity cost and
charge efficiency are found to be of lesser significance. The study provides
detailed improvement pathways for each technology under various operational
conditions, assisting developers in resource allocation. Overall, the
investment-based optimization method and findings contribute to enhancing the
competitiveness of emerging energy storage technologies and reducing reliance
on batteries in renewable energy systems.
</p>
</div>
</dd>
<dt><a name="item732">[732]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.02411" title="Abstract">arXiv:2309.02411</a> [<a href="/pdf/2309.02411" title="Download PDF">pdf</a>, <a href="/format/2309.02411" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Delta-LoRA: Fine-Tuning High-Rank Parameters with the Delta of Low-Rank  Matrices
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zi%2C+B">Bojia Zi</a>, 
<a href="/search/cs?searchtype=author&query=Qi%2C+X">Xianbiao Qi</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+L">Lingzhi Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jianan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wong%2C+K">Kam-Fai Wong</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+L">Lei Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">In this paper, we present Delta-LoRA, which is a novel parameter-efficient
approach to fine-tune large language models (LLMs). In contrast to LoRA and
other low-rank adaptation methods such as AdaLoRA, Delta-LoRA not only updates
the low-rank matrices $\bA$ and $\bB$, but also propagate the learning to the
pre-trained weights $\bW$ via updates utilizing the delta of the product of two
low-rank matrices ($\bA^{(t+1)}\bB^{(t+1)} - \bA^{(t)}\bB^{(t)}$). Such a
strategy effectively addresses the limitation that the incremental update of
low-rank matrices is inadequate for learning representations capable for
downstream tasks. Moreover, as the update of $\bW$ does not need to compute the
gradients of $\bW$ and store their momentums, Delta-LoRA shares comparable
memory requirements and computational costs with LoRA. Extensive experiments
show that Delta-LoRA significantly outperforms existing low-rank adaptation
methods. We further support these results with comprehensive analyses that
underscore the effectiveness of Delta-LoRA.
</p>
</div>
</dd>
<dt><a name="item733">[733]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.02420" title="Abstract">arXiv:2309.02420</a> [<a href="/pdf/2309.02420" title="Download PDF">pdf</a>, <a href="/format/2309.02420" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Doppelgangers: Learning to Disambiguate Images of Similar Structures
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cai%2C+R">Ruojin Cai</a>, 
<a href="/search/cs?searchtype=author&query=Tung%2C+J">Joseph Tung</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Q">Qianqian Wang</a>, 
<a href="/search/cs?searchtype=author&query=Averbuch-Elor%2C+H">Hadar Averbuch-Elor</a>, 
<a href="/search/cs?searchtype=author&query=Hariharan%2C+B">Bharath Hariharan</a>, 
<a href="/search/cs?searchtype=author&query=Snavely%2C+N">Noah Snavely</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Published in ICCV 2023 (Oral); Project page: <a href="http://doppelgangers-3d.github.io/">this http URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">We consider the visual disambiguation task of determining whether a pair of
visually similar images depict the same or distinct 3D surfaces (e.g., the same
or opposite sides of a symmetric building). Illusory image matches, where two
images observe distinct but visually similar 3D surfaces, can be challenging
for humans to differentiate, and can also lead 3D reconstruction algorithms to
produce erroneous results. We propose a learning-based approach to visual
disambiguation, formulating it as a binary classification task on image pairs.
To that end, we introduce a new dataset for this problem, Doppelgangers, which
includes image pairs of similar structures with ground truth labels. We also
design a network architecture that takes the spatial distribution of local
keypoints and matches as input, allowing for better reasoning about both local
and global cues. Our evaluation shows that our method can distinguish illusory
matches in difficult cases, and can be integrated into SfM pipelines to produce
correct, disambiguated 3D reconstructions. See our project page for our code,
datasets, and more results: <a href="http://doppelgangers-3d.github.io/.">this http URL</a>
</p>
</div>
</dd>
<dt><a name="item734">[734]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.02423" title="Abstract">arXiv:2309.02423</a> [<a href="/pdf/2309.02423" title="Download PDF">pdf</a>, <a href="/format/2309.02423" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> EgoPCA: A New Framework for Egocentric Hand-Object Interaction  Understanding
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+Y">Yue Xu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yong-Lu Li</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+Z">Zhemin Huang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+M+X">Michael Xu Liu</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+C">Cewu Lu</a>, 
<a href="/search/cs?searchtype=author&query=Tai%2C+Y">Yu-Wing Tai</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+C">Chi-Keung Tang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ICCV 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">With the surge in attention to Egocentric Hand-Object Interaction (Ego-HOI),
large-scale datasets such as Ego4D and EPIC-KITCHENS have been proposed.
However, most current research is built on resources derived from third-person
video action recognition. This inherent domain gap between first- and
third-person action videos, which have not been adequately addressed before,
makes current Ego-HOI suboptimal. This paper rethinks and proposes a new
framework as an infrastructure to advance Ego-HOI recognition by Probing,
Curation and Adaption (EgoPCA). We contribute comprehensive pre-train sets,
balanced test sets and a new baseline, which are complete with a
training-finetuning strategy. With our new framework, we not only achieve
state-of-the-art performance on Ego-HOI benchmarks but also build several new
and effective mechanisms and settings to advance further research. We believe
our data and the findings will pave a new way for Ego-HOI understanding. Code
and data are available at https://mvig-rhos.com/ego_pca
</p>
</div>
</dd>
<dt><a name="item735">[735]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.02425" title="Abstract">arXiv:2309.02425</a> [<a href="/pdf/2309.02425" title="Download PDF">pdf</a>, <a href="/ps/2309.02425" title="Download PostScript">ps</a>, <a href="/format/2309.02425" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the Minimax Regret in Online Ranking with Top-k Feedback
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+M">Mingyuan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Tewari%2C+A">Ambuj Tewari</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
<p class="mathjax">In online ranking, a learning algorithm sequentially ranks a set of items and
receives feedback on its ranking in the form of relevance scores. Since
obtaining relevance scores typically involves human annotation, it is of great
interest to consider a partial feedback setting where feedback is restricted to
the top-$k$ items in the rankings. Chaudhuri and Tewari [2017] developed a
framework to analyze online ranking algorithms with top $k$ feedback. A key
element in their work was the use of techniques from partial monitoring. In
this paper, we further investigate online ranking with top $k$ feedback and
solve some open problems posed by Chaudhuri and Tewari [2017]. We provide a
full characterization of minimax regret rates with the top $k$ feedback model
for all $k$ and for the following ranking performance measures: Pairwise Loss,
Discounted Cumulative Gain, and Precision@n. In addition, we give an efficient
algorithm that achieves the minimax regret rate for Precision@n.
</p>
</div>
</dd>
<dt><a name="item736">[736]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.02427" title="Abstract">arXiv:2309.02427</a> [<a href="/pdf/2309.02427" title="Download PDF">pdf</a>, <a href="/format/2309.02427" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Cognitive Architectures for Language Agents
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sumers%2C+T">Theodore Sumers</a>, 
<a href="/search/cs?searchtype=author&query=Yao%2C+S">Shunyu Yao</a>, 
<a href="/search/cs?searchtype=author&query=Narasimhan%2C+K">Karthik Narasimhan</a>, 
<a href="/search/cs?searchtype=author&query=Griffiths%2C+T+L">Thomas L. Griffiths</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 pages of main content, 10 pages of references, 5 figures. Equal contribution among the first two authors, order decided by coin flip. A CoALA-based repo of recent work on language agents: <a href="https://github.com/ysymyth/awesome-language-agents">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computation and Language (cs.CL); Machine Learning (cs.LG); Symbolic Computation (cs.SC)

</div>
<p class="mathjax">Recent efforts have incorporated large language models (LLMs) with external
resources (e.g., the Internet) or internal control flows (e.g., prompt
chaining) for tasks requiring grounding or reasoning. However, these efforts
have largely been piecemeal, lacking a systematic framework for constructing a
fully-fledged language agent. To address this challenge, we draw on the rich
history of agent design in symbolic artificial intelligence to develop a
blueprint for a new wave of cognitive language agents. We first show that LLMs
have many of the same properties as production systems, and recent efforts to
improve their grounding or reasoning mirror the development of cognitive
architectures built around production systems. We then propose Cognitive
Architectures for Language Agents (CoALA), a conceptual framework to
systematize diverse methods for LLM-based reasoning, grounding, learning, and
decision making as instantiations of language agents in the framework. Finally,
we use the CoALA framework to highlight gaps and propose actionable directions
toward more capable language agents in the future.
</p>
</div>
</dd>
<dt><a name="item737">[737]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.02428" title="Abstract">arXiv:2309.02428</a> [<a href="/pdf/2309.02428" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Tensorization: Creating and Utilising Multidimensional Datasets for  Multiway Analysis and Tensorised Deep Neural Networks -- Python Tutorial and  Survey
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Helal%2C+M">Manal Helal</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 29 pages, 8 figures, 3 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">As the size and complexity of data continue to increase, the need for
efficient and effective analysis methods becomes ever more crucial.
Tensorization, the process of converting 2-dimensional datasets into
multidimensional structures, has emerged as a promising approach for multiway
analysis methods. This paper explores the steps involved in tensorization,
multidimensional data sources, various multiway analysis methods employed, and
the benefits of these approaches. A small example of Blind Source Separation
(BSS) is presented comparing 2-dimensional algorithms and a multiway algorithm
in Python. Results indicate that multiway analysis is more expressive.
Additionally, tensorization techniques aid in compressing deep learning models
by reducing the number of required parameters while enhancing the expression of
relationships across dimensions. A survey of the multi-away analysis methods
and integration with various Deep Neural Networks models is presented using
case studies in different domains.
</p>
</div>
</dd>
<dt><a name="item738">[738]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.02429" title="Abstract">arXiv:2309.02429</a> [<a href="/pdf/2309.02429" title="Download PDF">pdf</a>, <a href="/format/2309.02429" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Building a Winning Team: Selecting Source Model Ensembles using a  Submodular Transferability Estimation Approach
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=B%2C+V+K">Vimal K B</a>, 
<a href="/search/cs?searchtype=author&query=Bachu%2C+S">Saketh Bachu</a>, 
<a href="/search/cs?searchtype=author&query=Garg%2C+T">Tanmay Garg</a>, 
<a href="/search/cs?searchtype=author&query=Narasimhan%2C+N+L">Niveditha Lakshmi Narasimhan</a>, 
<a href="/search/cs?searchtype=author&query=Konuru%2C+R">Raghavan Konuru</a>, 
<a href="/search/cs?searchtype=author&query=Balasubramanian%2C+V+N">Vineeth N Balasubramanian</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To appear at ICCV 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Estimating the transferability of publicly available pretrained models to a
target task has assumed an important place for transfer learning tasks in
recent years. Existing efforts propose metrics that allow a user to choose one
model from a pool of pre-trained models without having to fine-tune each model
individually and identify one explicitly. With the growth in the number of
available pre-trained models and the popularity of model ensembles, it also
becomes essential to study the transferability of multiple-source models for a
given target task. The few existing efforts study transferability in such
multi-source ensemble settings using just the outputs of the classification
layer and neglect possible domain or task mismatch. Moreover, they overlook the
most important factor while selecting the source models, viz., the cohesiveness
factor between them, which can impact the performance and confidence in the
prediction of the ensemble. To address these gaps, we propose a novel Optimal
tranSport-based suBmOdular tRaNsferability metric (OSBORN) to estimate the
transferability of an ensemble of models to a downstream task. OSBORN
collectively accounts for image domain difference, task difference, and
cohesiveness of models in the ensemble to provide reliable estimates of
transferability. We gauge the performance of OSBORN on both image
classification and semantic segmentation tasks. Our setup includes 28 source
datasets, 11 target datasets, 5 model architectures, and 2 pre-training
methods. We benchmark our method against current state-of-the-art metrics
MS-LEEP and E-LEEP, and outperform them consistently using the proposed
approach.
</p>
</div>
</dd>
<dt><a name="item739">[739]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.02434" title="Abstract">arXiv:2309.02434</a> [<a href="/pdf/2309.02434" title="Download PDF">pdf</a>, <a href="/format/2309.02434" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ReliTalk: Relightable Talking Portrait Generation from a Single Video
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Qiu%2C+H">Haonan Qiu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Z">Zhaoxi Chen</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+Y">Yuming Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+H">Hang Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Fan%2C+X">Xiangyu Fan</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+L">Lei Yang</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+W">Wayne Wu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Ziwei Liu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Graphics (cs.GR)

</div>
<p class="mathjax">Recent years have witnessed great progress in creating vivid audio-driven
portraits from monocular videos. However, how to seamlessly adapt the created
video avatars to other scenarios with different backgrounds and lighting
conditions remains unsolved. On the other hand, existing relighting studies
mostly rely on dynamically lighted or multi-view data, which are too expensive
for creating video portraits. To bridge this gap, we propose ReliTalk, a novel
framework for relightable audio-driven talking portrait generation from
monocular videos. Our key insight is to decompose the portrait's reflectance
from implicitly learned audio-driven facial normals and images. Specifically,
we involve 3D facial priors derived from audio features to predict delicate
normal maps through implicit functions. These initially predicted normals then
take a crucial part in reflectance decomposition by dynamically estimating the
lighting condition of the given video. Moreover, the stereoscopic face
representation is refined using the identity-consistent loss under simulated
multiple lighting conditions, addressing the ill-posed problem caused by
limited views available from a single monocular video. Extensive experiments
validate the superiority of our proposed framework on both real and synthetic
datasets. Our code is released in https://github.com/arthur-qiu/ReliTalk.
</p>
</div>
</dd>
<dt><a name="item740">[740]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.02435" title="Abstract">arXiv:2309.02435</a> [<a href="/pdf/2309.02435" title="Download PDF">pdf</a>, <a href="/format/2309.02435" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Efficient RL via Disentangled Environment and Agent Representations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gmelin%2C+K">Kevin Gmelin</a>, 
<a href="/search/cs?searchtype=author&query=Bahl%2C+S">Shikhar Bahl</a>, 
<a href="/search/cs?searchtype=author&query=Mendonca%2C+R">Russell Mendonca</a>, 
<a href="/search/cs?searchtype=author&query=Pathak%2C+D">Deepak Pathak</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ICML 2023. Website at <a href="https://sear-rl.github.io/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV); Neural and Evolutionary Computing (cs.NE); Robotics (cs.RO)

</div>
<p class="mathjax">Agents that are aware of the separation between themselves and their
environments can leverage this understanding to form effective representations
of visual input. We propose an approach for learning such structured
representations for RL algorithms, using visual knowledge of the agent, such as
its shape or mask, which is often inexpensive to obtain. This is incorporated
into the RL objective using a simple auxiliary loss. We show that our method,
Structured Environment-Agent Representations, outperforms state-of-the-art
model-free approaches over 18 different challenging visual simulation
environments spanning 5 different robots. Website at https://sear-rl.github.io/
</p>
</div>
</dd>
<dt><a name="item741">[741]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.02436" title="Abstract">arXiv:2309.02436</a> [<a href="/pdf/2309.02436" title="Download PDF">pdf</a>, <a href="/format/2309.02436" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GO-SLAM: Global Optimization for Consistent 3D Instant Reconstruction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Youmin Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Tosi%2C+F">Fabio Tosi</a>, 
<a href="/search/cs?searchtype=author&query=Mattoccia%2C+S">Stefano Mattoccia</a>, 
<a href="/search/cs?searchtype=author&query=Poggi%2C+M">Matteo Poggi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ICCV 2023. Code: <a href="https://github.com/youmi-zym/GO-SLAM">this https URL</a> - Project Page: <a href="https://youmi-zym.github.io/projects/GO-SLAM/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Robotics (cs.RO)

</div>
<p class="mathjax">Neural implicit representations have recently demonstrated compelling results
on dense Simultaneous Localization And Mapping (SLAM) but suffer from the
accumulation of errors in camera tracking and distortion in the reconstruction.
Purposely, we present GO-SLAM, a deep-learning-based dense visual SLAM
framework globally optimizing poses and 3D reconstruction in real-time. Robust
pose estimation is at its core, supported by efficient loop closing and online
full bundle adjustment, which optimize per frame by utilizing the learned
global geometry of the complete history of input frames. Simultaneously, we
update the implicit and continuous surface representation on-the-fly to ensure
global consistency of 3D reconstruction. Results on various synthetic and
real-world datasets demonstrate that GO-SLAM outperforms state-of-the-art
approaches at tracking robustness and reconstruction accuracy. Furthermore,
GO-SLAM is versatile and can run with monocular, stereo, and RGB-D input.
</p>
</div>
</dd>
</dl>
<h3>Cross-lists for Wed,  6 Sep 23</h3>
<dl>
<dt><a name="item742">[742]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.00475" title="Abstract">arXiv:2309.00475</a> (cross-list from math.GR) [<a href="/pdf/2309.00475" title="Download PDF">pdf</a>, <a href="/ps/2309.00475" title="Download PostScript">ps</a>, <a href="/format/2309.00475" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Effective equation solving, constraints and growth in virtually abelian  groups
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Ciobanu%2C+L">Laura Ciobanu</a>, 
<a href="/search/math?searchtype=author&query=Evetts%2C+A">Alex Evetts</a>, 
<a href="/search/math?searchtype=author&query=Levine%2C+A">Alex Levine</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 28 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Group Theory (math.GR)</span>; Discrete Mathematics (cs.DM); Formal Languages and Automata Theory (cs.FL)

</div>
<p class="mathjax">In this paper we study the satisfiability and solutions of group equations
when combinatorial, algebraic and language-theoretic constraints are imposed on
the solutions. We show that the solutions to equations with length,
lexicographic order, abelianisation or context-free constraints added, can be
effectively produced in finitely generated virtually abelian groups. Crucially,
we translate each of the constraints above into a rational set in an effective
way, and so reduce each problem to solving equations with rational constraints,
which is decidable and well understood in virtually abelian groups. A byproduct
of our results is that the growth series of a virtually abelian group, with
respect to any generating set and any weight, is effectively computable. This
series is known to be rational by a result of Benson, but his proof is
non-constructive.
</p>
</div>
</dd>
<dt><a name="item743">[743]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.00618" title="Abstract">arXiv:2309.00618</a> (cross-list from q-fin.TR) [<a href="/pdf/2309.00618" title="Download PDF">pdf</a>, <a href="/format/2309.00618" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Short-Term Stock Price Forecasting using exogenous variables and Machine  Learning Algorithms
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-fin?searchtype=author&query=Wong%2C+A">Albert Wong</a>, 
<a href="/search/q-fin?searchtype=author&query=Whang%2C+S">Steven Whang</a>, 
<a href="/search/q-fin?searchtype=author&query=Sagre%2C+E">Emilio Sagre</a>, 
<a href="/search/q-fin?searchtype=author&query=Sachin%2C+N">Niha Sachin</a>, 
<a href="/search/q-fin?searchtype=author&query=Dutra%2C+G">Gustavo Dutra</a>, 
<a href="/search/q-fin?searchtype=author&query=Lim%2C+Y">Yew-Wei Lim</a>, 
<a href="/search/q-fin?searchtype=author&query=Hains%2C+G">Gaetan Hains</a>, 
<a href="/search/q-fin?searchtype=author&query=Khmelevsky%2C+Y">Youry Khmelevsky</a>, 
<a href="/search/q-fin?searchtype=author&query=Zhang%2C+F">Frank Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Trading and Market Microstructure (q-fin.TR)</span>; Computational Engineering, Finance, and Science (cs.CE); Machine Learning (cs.LG)

</div>
<p class="mathjax">Creating accurate predictions in the stock market has always been a
significant challenge in finance. With the rise of machine learning as the next
level in the forecasting area, this research paper compares four machine
learning models and their accuracy in forecasting three well-known stocks
traded in the NYSE in the short term from March 2020 to May 2022. We deploy,
develop, and tune XGBoost, Random Forest, Multi-layer Perceptron, and Support
Vector Regression models. We report the models that produce the highest
accuracies from our evaluation metrics: RMSE, MAPE, MTT, and MPE. Using a
training data set of 240 trading days, we find that XGBoost gives the highest
accuracy despite running longer (up to 10 seconds). Results from this study may
improve by further tuning the individual parameters or introducing more
exogenous variables.
</p>
</div>
</dd>
<dt><a name="item744">[744]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.00621" title="Abstract">arXiv:2309.00621</a> (cross-list from physics.ed-ph) [<a href="/pdf/2309.00621" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Calculation of Kinetic and Static Friction Coefficient and Friction  Graph Analysis Using Arduino
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Coban%2C+A">Atakan Coban</a>, 
<a href="/search/physics?searchtype=author&query=Boyac%C4%B1%2C+S">Seher Boyac&#x131;</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 4 paper, published article
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Physics Education, 2021
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Physics Education (physics.ed-ph)</span>; Robotics (cs.RO)

</div>
<p class="mathjax">In this study, with the help of the Arduino UNO and Load-cell force sensor, a
simple experimental material has been developed to calculate kinetic and static
friction coefficients and analyse the friction force in detail. The system with
a force sensor mounted on it is placed on the plane. With the help of the rope
attached to the force sensor, a force, whose magnitude increased over time, was
applied on the sensor. After the force applied was large enough to move the
system, the force was applied to move the system at a constant speed. Since the
net force acting on the system is zero while the system is stationary and
moving with a constant speed, in these cases the magnitudes of force read
through the sensor are equal to the static and kinetic friction forces acting
on the object. Using these static and kinetic friction forces values, the
maximum value of the static friction coefficient and the kinetic friction
coefficient were calculated as 0.484 and 0.313, respectively.
</p>
</div>
</dd>
<dt><a name="item745">[745]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.00626" title="Abstract">arXiv:2309.00626</a> (cross-list from q-fin.TR) [<a href="/pdf/2309.00626" title="Download PDF">pdf</a>, <a href="/format/2309.00626" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An Ensemble Method of Deep Reinforcement Learning for Automated  Cryptocurrency Trading
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-fin?searchtype=author&query=Wang%2C+S">Shuyang Wang</a>, 
<a href="/search/q-fin?searchtype=author&query=Klabjan%2C+D">Diego Klabjan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Trading and Market Microstructure (q-fin.TR)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">We propose an ensemble method to improve the generalization performance of
trading strategies trained by deep reinforcement learning algorithms in a
highly stochastic environment of intraday cryptocurrency portfolio trading. We
adopt a model selection method that evaluates on multiple validation periods,
and propose a novel mixture distribution policy to effectively ensemble the
selected models. We provide a distributional view of the out-of-sample
performance on granular test periods to demonstrate the robustness of the
strategies in evolving market conditions, and retrain the models periodically
to address non-stationarity of financial data. Our proposed ensemble method
improves the out-of-sample performance compared with the benchmarks of a deep
reinforcement learning strategy and a passive investment strategy.
</p>
</div>
</dd>
<dt><a name="item746">[746]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.00627" title="Abstract">arXiv:2309.00627</a> (cross-list from q-bio.NC) [<a href="/pdf/2309.00627" title="Download PDF">pdf</a>, <a href="/format/2309.00627" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Through their eyes: multi-subject Brain Decoding with simple alignment  techniques
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-bio?searchtype=author&query=Ferrante%2C+M">Matteo Ferrante</a>, 
<a href="/search/q-bio?searchtype=author&query=Boccato%2C+T">Tommaso Boccato</a>, 
<a href="/search/q-bio?searchtype=author&query=Toschi%2C+N">Nicola Toschi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neurons and Cognition (q-bio.NC)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Previous brain decoding research primarily involves single-subject studies,
reconstructing stimuli via fMRI activity from the same subject. Our study aims
to introduce a generalization technique for cross-subject brain decoding,
facilitated by exploring data alignment methods. We utilized the NSD dataset, a
comprehensive 7T fMRI vision experiment involving multiple subjects exposed to
9841 images, 982 of which were viewed by all. Our approach involved training a
decoding model on one subject, aligning others' data to this space, and testing
the decoding on the second subject. We compared ridge regression, hyper
alignment, and anatomical alignment techniques for fMRI data alignment. We
established that cross-subject brain decoding is feasible, even using around
10% of the total data, or 982 common images, with comparable performance to
single-subject decoding. Ridge regression was the best method for functional
alignment. Through subject alignment, we achieved superior brain decoding and a
potential 90% reduction in scan time. This could pave the way for more
efficient experiments and further advancements in the field, typically
requiring an exorbitant 20-hour scan time per subject.
</p>
</div>
</dd>
<dt><a name="item747">[747]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.00629" title="Abstract">arXiv:2309.00629</a> (cross-list from q-fin.GN) [<a href="/pdf/2309.00629" title="Download PDF">pdf</a>, <a href="/format/2309.00629" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Quantifying MEV On Layer 2 Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-fin?searchtype=author&query=Bagourd%2C+A">Arthur Bagourd</a>, 
<a href="/search/q-fin?searchtype=author&query=Francois%2C+L+G">Luca Georges Francois</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">General Finance (q-fin.GN)</span>; Computer Science and Game Theory (cs.GT)

</div>
<p class="mathjax">This paper addresses the lack of research on quantifying Maximal Extractable
Value (MEV) on Ethereum Layer 2 networks (L2s). Our findings reveal a
substantial amount of MEV to be extracted on L2s, particularly on Polygon, with
a lower bound of $213 million surpassing previous estimates. We observe that
the majority of detected MEV on L2s consists of arbitrage opportunities, as
liquidations are rare. These results emphasize the need for continuous
monitoring and analysis of MEV on L2s, promoting informed decision-making for
network selection and highlighting the associated risks.
</p>
</div>
</dd>
<dt><a name="item748">[748]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.00630" title="Abstract">arXiv:2309.00630</a> (cross-list from q-fin.TR) [<a href="/pdf/2309.00630" title="Download PDF">pdf</a>, <a href="/format/2309.00630" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Commodities Trading through Deep Policy Gradient Methods
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-fin?searchtype=author&query=Hanetho%2C+J">Jonas Hanetho</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: substantial text overlap with <a href="/abs/2308.01910">arXiv:2308.01910</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Trading and Market Microstructure (q-fin.TR)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Algorithmic trading has gained attention due to its potential for generating
superior returns. This paper investigates the effectiveness of deep
reinforcement learning (DRL) methods in algorithmic commodities trading. It
formulates the commodities trading problem as a continuous, discrete-time
stochastic dynamical system. The proposed system employs a novel
time-discretization scheme that adapts to market volatility, enhancing the
statistical properties of subsampled financial time series. To optimize
transaction-cost- and risk-sensitive trading agents, two policy gradient
algorithms, namely actor-based and actor-critic-based approaches, are
introduced. These agents utilize CNNs and LSTMs as parametric function
approximators to map historical price observations to market
positions.Backtesting on front-month natural gas futures demonstrates that DRL
models increase the Sharpe ratio by $83\%$ compared to the buy-and-hold
baseline. Additionally, the risk profile of the agents can be customized
through a hyperparameter that regulates risk sensitivity in the reward function
during the optimization process. The actor-based models outperform the
actor-critic-based models, while the CNN-based models show a slight performance
advantage over the LSTM-based models.
</p>
</div>
</dd>
<dt><a name="item749">[749]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.00638" title="Abstract">arXiv:2309.00638</a> (cross-list from q-fin.TR) [<a href="/pdf/2309.00638" title="Download PDF">pdf</a>, <a href="/format/2309.00638" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Generative AI for End-to-End Limit Order Book Modelling: A Token-Level  Autoregressive Generative Model of Message Flow Using a Deep State Space  Network
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-fin?searchtype=author&query=Nagy%2C+P">Peer Nagy</a>, 
<a href="/search/q-fin?searchtype=author&query=Frey%2C+S">Sascha Frey</a>, 
<a href="/search/q-fin?searchtype=author&query=Sapora%2C+S">Silvia Sapora</a>, 
<a href="/search/q-fin?searchtype=author&query=Li%2C+K">Kang Li</a>, 
<a href="/search/q-fin?searchtype=author&query=Calinescu%2C+A">Anisoara Calinescu</a>, 
<a href="/search/q-fin?searchtype=author&query=Zohren%2C+S">Stefan Zohren</a>, 
<a href="/search/q-fin?searchtype=author&query=Foerster%2C+J">Jakob Foerster</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Trading and Market Microstructure (q-fin.TR)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Computational Finance (q-fin.CP)

</div>
<p class="mathjax">Developing a generative model of realistic order flow in financial markets is
a challenging open problem, with numerous applications for market participants.
Addressing this, we propose the first end-to-end autoregressive generative
model that generates tokenized limit order book (LOB) messages. These messages
are interpreted by a Jax-LOB simulator, which updates the LOB state. To handle
long sequences efficiently, the model employs simplified structured state-space
layers to process sequences of order book states and tokenized messages. Using
LOBSTER data of NASDAQ equity LOBs, we develop a custom tokenizer for message
data, converting groups of successive digits to tokens, similar to tokenization
in large language models. Out-of-sample results show promising performance in
approximating the data distribution, as evidenced by low model perplexity.
Furthermore, the mid-price returns calculated from the generated order flow
exhibit a significant correlation with the data, indicating impressive
conditional forecast performance. Due to the granularity of generated data, and
the accuracy of the model, it offers new application areas for future work
beyond forecasting, e.g. acting as a world model in high-frequency financial
reinforcement learning applications. Overall, our results invite the use and
extension of the model in the direction of autoregressive large financial
models for the generation of high-frequency financial data and we commit to
open-sourcing our code to facilitate future research.
</p>
</div>
</dd>
<dt><a name="item750">[750]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.00644" title="Abstract">arXiv:2309.00644</a> (cross-list from math.OC) [<a href="/pdf/2309.00644" title="Download PDF">pdf</a>, <a href="/format/2309.00644" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Ten New Benchmarks for Optimization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Yang%2C+X">Xin-She Yang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages, 6 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Artificial Intelligence (cs.AI); Neural and Evolutionary Computing (cs.NE)

</div>
<p class="mathjax">Benchmarks are used for testing new optimization algorithms and their
variants to evaluate their performance. Most existing benchmarks are smooth
functions. This chapter introduces ten new benchmarks with different
properties, including noise, discontinuity, parameter estimation and unknown
paths.
</p>
</div>
</dd>
<dt><a name="item751">[751]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.00645" title="Abstract">arXiv:2309.00645</a> (cross-list from stat.ML) [<a href="/pdf/2309.00645" title="Download PDF">pdf</a>, <a href="/format/2309.00645" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Minimal Assumptions for Optimal Serology Classification: Theory and  Implications for Multidimensional Settings and Impure Training Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Patrone%2C+P+N">Paul N. Patrone</a>, 
<a href="/search/stat?searchtype=author&query=Binder%2C+R+A">Raquel A. Binder</a>, 
<a href="/search/stat?searchtype=author&query=Forconi%2C+C+S">Catherine S. Forconi</a>, 
<a href="/search/stat?searchtype=author&query=Moormann%2C+A+M">Ann M. Moormann</a>, 
<a href="/search/stat?searchtype=author&query=Kearsley%2C+A+J">Anthony J. Kearsley</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG); Probability (math.PR)

</div>
<p class="mathjax">Minimizing error in prevalence estimates and diagnostic classifiers remains a
challenging task in serology. In theory, these problems can be reduced to
modeling class-conditional probability densities (PDFs) of measurement
outcomes, which control all downstream analyses. However, this task quickly
succumbs to the curse of dimensionality, even for assay outputs with only a few
dimensions (e.g. target antigens). To address this problem, we propose a
technique that uses empirical training data to classify samples and estimate
prevalence in arbitrary dimension without direct access to the conditional
PDFs. We motivate this method via a lemma that relates relative conditional
probabilities to minimum-error classification boundaries. This leads us to
formulate an optimization problem that: (i) embeds the data in a parameterized,
curved space; (ii) classifies samples based on their position relative to a
coordinate axis; and (iii) subsequently optimizes the space by minimizing the
empirical classification error of pure training data, for which the classes are
known. Interestingly, the solution to this problem requires use of a
homotopy-type method to stabilize the optimization. We then extend the analysis
to the case of impure training data, for which the classes are unknown. We find
that two impure datasets suffice for both prevalence estimation and
classification, provided they satisfy a linear independence property. Lastly,
we discuss how our analysis unifies discriminative and generative learning
techniques in a common framework based on ideas from set and measure theory.
Throughout, we validate our methods in the context of synthetic data and a
research-use SARS-CoV-2 enzyme-linked immunosorbent (ELISA) assay.
</p>
</div>
</dd>
<dt><a name="item752">[752]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.00646" title="Abstract">arXiv:2309.00646</a> (cross-list from q-bio.NC) [<a href="/pdf/2309.00646" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Intelligence as a Measure of Consciousness
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-bio?searchtype=author&query=%C5%A0evo%2C+I">Igor &#x160;evo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neurons and Cognition (q-bio.NC)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Evaluating artificial systems for signs of consciousness is increasingly
becoming a pressing concern, and a rigorous psychometric measurement framework
may be of crucial importance in evaluating large language models in this
regard. Most prominent theories of consciousness, both scientific and
metaphysical, argue for different kinds of information coupling as a necessary
component of human-like consciousness. By comparing information coupling in
human and animal brains, human cognitive development, emergent abilities, and
mental representation development to analogous phenomena in large language
models, I argue that psychometric measures of intelligence, such as the
g-factor or IQ, indirectly approximate the extent of conscious experience.
<br />Based on a broader source of both scientific and metaphysical theories of
consciousness, I argue that all systems possess a degree of consciousness
ascertainable psychometrically and that psychometric measures of intelligence
may be used to gauge relative similarities of conscious experiences across
disparate systems, be they artificial or human.
</p>
</div>
</dd>
<dt><a name="item753">[753]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.00647" title="Abstract">arXiv:2309.00647</a> (cross-list from eess.AS) [<a href="/pdf/2309.00647" title="Download PDF">pdf</a>, <a href="/format/2309.00647" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Improving Small Footprint Few-shot Keyword Spotting with Supervision on  Auxiliary Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Yang%2C+S">Seunghan Yang</a>, 
<a href="/search/eess?searchtype=author&query=Kim%2C+B">Byeonggeun Kim</a>, 
<a href="/search/eess?searchtype=author&query=Shim%2C+K">Kyuhong Shim</a>, 
<a href="/search/eess?searchtype=author&query=Chang%2C+S">Simyung Chang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Interspeech 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Machine Learning (cs.LG); Sound (cs.SD)

</div>
<p class="mathjax">Few-shot keyword spotting (FS-KWS) models usually require large-scale
annotated datasets to generalize to unseen target keywords. However, existing
KWS datasets are limited in scale and gathering keyword-like labeled data is
costly undertaking. To mitigate this issue, we propose a framework that uses
easily collectible, unlabeled reading speech data as an auxiliary source.
Self-supervised learning has been widely adopted for learning representations
from unlabeled data; however, it is known to be suitable for large models with
enough capacity and is not practical for training a small footprint FS-KWS
model. Instead, we automatically annotate and filter the data to construct a
keyword-like dataset, LibriWord, enabling supervision on auxiliary data. We
then adopt multi-task learning that helps the model to enhance the
representation power from out-of-domain auxiliary data. Our method notably
improves the performance over competitive methods in the FS-KWS benchmark.
</p>
</div>
</dd>
<dt><a name="item754">[754]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.00708" title="Abstract">arXiv:2309.00708</a> (cross-list from math.QA) [<a href="/pdf/2309.00708" title="Download PDF">pdf</a>, <a href="/ps/2309.00708" title="Download PostScript">ps</a>, <a href="/format/2309.00708" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> From finite state automata to tangle cobordisms: a TQFT journey from one  to four dimensions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Im%2C+M+S">Mee Seong Im</a>, 
<a href="/search/math?searchtype=author&query=Khovanov%2C+M">Mikhail Khovanov</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 40 pages, many figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Algebra (math.QA)</span>; Formal Languages and Automata Theory (cs.FL); Mathematical Physics (math-ph); Category Theory (math.CT); Representation Theory (math.RT)

</div>
<p class="mathjax">This is a brief introduction to link homology theories that categorify
Reshetikhin--Turaev $\mathsf{SL}(N)$-quantum link invariants. A recently
discovered surprising connection between finite state automata and Boolean
TQFTs in dimension one is explained as a warm-up.
</p>
</div>
</dd>
<dt><a name="item755">[755]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.00727" title="Abstract">arXiv:2309.00727</a> (cross-list from eess.IV) [<a href="/pdf/2309.00727" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deep learning in medical image registration: introduction and survey
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Hammoudeh%2C+A">Ahmad Hammoudeh</a>, 
<a href="/search/eess?searchtype=author&query=Dupont%2C+S">St&#xe9;phane Dupont</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
<p class="mathjax">Image registration (IR) is a process that deforms images to align them with
respect to a reference space, making it easier for medical practitioners to
examine various medical images in a standardized reference frame, such as
having the same rotation and scale. This document introduces image registration
using a simple numeric example. It provides a definition of image registration
along with a space-oriented symbolic representation. This review covers various
aspects of image transformations, including affine, deformable, invertible, and
bidirectional transformations, as well as medical image registration algorithms
such as Voxelmorph, Demons, SyN, Iterative Closest Point, and SynthMorph. It
also explores atlas-based registration and multistage image registration
techniques, including coarse-fine and pyramid approaches. Furthermore, this
survey paper discusses medical image registration taxonomies, datasets,
evaluation measures, such as correlation-based metrics, segmentation-based
metrics, processing time, and model size. It also explores applications in
image-guided surgery, motion tracking, and tumor diagnosis. Finally, the
document addresses future research directions, including the further
development of transformers.
</p>
</div>
</dd>
<dt><a name="item756">[756]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.00730" title="Abstract">arXiv:2309.00730</a> (cross-list from astro-ph.EP) [<a href="/pdf/2309.00730" title="Download PDF">pdf</a>, <a href="/format/2309.00730" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Tempestas ex machina: A review of machine learning methods for wavefront  control
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/astro-ph?searchtype=author&query=Fowler%2C+J">J. Fowler</a>, 
<a href="/search/astro-ph?searchtype=author&query=Landman%2C+R">Rico Landman</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> SPIE Proceeding: 2023 / 12680-15
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Earth and Planetary Astrophysics (astro-ph.EP)</span>; Instrumentation and Methods for Astrophysics (astro-ph.IM); Machine Learning (cs.LG); Optics (physics.optics)

</div>
<p class="mathjax">As we look to the next generation of adaptive optics systems, now is the time
to develop and explore the technologies that will allow us to image rocky
Earth-like planets; wavefront control algorithms are not only a crucial
component of these systems, but can benefit our adaptive optics systems without
requiring increased detector speed and sensitivity or more effective and
efficient deformable mirrors. To date, most observatories run the workhorse of
their wavefront control as a classic integral controller, which estimates a
correction from wavefront sensor residuals, and attempts to apply that
correction as fast as possible in closed-loop. An integrator of this nature
fails to address temporal lag errors that evolve over scales faster than the
correction time, as well as vibrations or dynamic errors within the system that
are not encapsulated in the wavefront sensor residuals; these errors impact
high contrast imaging systems with complex coronagraphs. With the rise in
popularity of machine learning, many are investigating applying modern machine
learning methods to wavefront control. Furthermore, many linear implementations
of machine learning methods (under varying aliases) have been in development
for wavefront control for the last 30-odd years. With this work we define
machine learning in its simplest terms, explore the most common machine
learning methods applied in the context of this problem, and present a review
of the literature concerning novel machine learning approaches to wavefront
control.
</p>
</div>
</dd>
<dt><a name="item757">[757]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.00736" title="Abstract">arXiv:2309.00736</a> (cross-list from stat.ML) [<a href="/pdf/2309.00736" title="Download PDF">pdf</a>, <a href="/ps/2309.00736" title="Download PostScript">ps</a>, <a href="/format/2309.00736" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Prediction Error Estimation in Random Forests
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Krupkin%2C+I">Ian Krupkin</a>, 
<a href="/search/stat?searchtype=author&query=Hardin%2C+J">Johanna Hardin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">In this paper, error estimates of classification Random Forests are
quantitatively assessed. Based on the initial theoretical framework built by
Bates et al. (2023), the true error rate and expected error rate are
theoretically and empirically investigated in the context of a variety of error
estimation methods common to Random Forests. We show that in the classification
case, Random Forests' estimates of prediction error is closer on average to the
true error rate instead of the average prediction error. This is opposite the
findings of Bates et al. (2023) which were given for logistic regression. We
further show that this result holds across different error estimation
strategies such as cross-validation, bagging, and data splitting.
</p>
</div>
</dd>
<dt><a name="item758">[758]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.00767" title="Abstract">arXiv:2309.00767</a> (cross-list from physics.comp-ph) [<a href="/pdf/2309.00767" title="Download PDF">pdf</a>, <a href="/format/2309.00767" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Physics-informed machine learning of the correlation functions in bulk  fluids
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Chen%2C+W">Wenqian Chen</a>, 
<a href="/search/physics?searchtype=author&query=Gao%2C+P">Peiyuan Gao</a>, 
<a href="/search/physics?searchtype=author&query=Stinis%2C+P">Panos Stinis</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Physics (physics.comp-ph)</span>; Machine Learning (cs.LG); Chemical Physics (physics.chem-ph); Fluid Dynamics (physics.flu-dyn)

</div>
<p class="mathjax">The Ornstein-Zernike (OZ) equation is the fundamental equation for pair
correlation function computations in the modern integral equation theory for
liquids. In this work, machine learning models, notably physics-informed neural
networks and physics-informed neural operator networks, are explored to solve
the OZ equation. The physics-informed machine learning models demonstrate great
accuracy and high efficiency in solving the forward and inverse OZ problems of
various bulk fluids. The results highlight the significant potential of
physics-informed machine learning for applications in thermodynamic state
theory.
</p>
</div>
</dd>
<dt><a name="item759">[759]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.00769" title="Abstract">arXiv:2309.00769</a> (cross-list from eess.IV) [<a href="/pdf/2309.00769" title="Download PDF">pdf</a>, <a href="/format/2309.00769" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Full Reference Video Quality Assessment for Machine Learning-Based Video  Codecs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Majeedi%2C+A">Abrar Majeedi</a>, 
<a href="/search/eess?searchtype=author&query=Naderi%2C+B">Babak Naderi</a>, 
<a href="/search/eess?searchtype=author&query=Hosseinkashi%2C+Y">Yasaman Hosseinkashi</a>, 
<a href="/search/eess?searchtype=author&query=Cho%2C+J">Juhee Cho</a>, 
<a href="/search/eess?searchtype=author&query=Martinez%2C+R+A">Ruben Alvarez Martinez</a>, 
<a href="/search/eess?searchtype=author&query=Cutler%2C+R">Ross Cutler</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Machine learning-based video codecs have made significant progress in the
past few years. A critical area in the development of ML-based video codecs is
an accurate evaluation metric that does not require an expensive and slow
subjective test. We show that existing evaluation metrics that were designed
and trained on DSP-based video codecs are not highly correlated to subjective
opinion when used with ML video codecs due to the video artifacts being quite
different between ML and video codecs. We provide a new dataset of ML video
codec videos that have been accurately labeled for quality. We also propose a
new full reference video quality assessment (FRVQA) model that achieves a
Pearson Correlation Coefficient (PCC) of 0.99 and a Spearman's Rank Correlation
Coefficient (SRCC) of 0.99 at the model level. We make the dataset and FRVQA
model open source to help accelerate research in ML video codecs, and so that
others can further improve the FRVQA model.
</p>
</div>
</dd>
<dt><a name="item760">[760]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.00771" title="Abstract">arXiv:2309.00771</a> (cross-list from stat.ML) [<a href="/pdf/2309.00771" title="Download PDF">pdf</a>, <a href="/ps/2309.00771" title="Download PostScript">ps</a>, <a href="/format/2309.00771" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Non-Asymptotic Bounds for Adversarial Excess Risk under Misspecified  Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Liu%2C+C">Changyu Liu</a>, 
<a href="/search/stat?searchtype=author&query=Jiao%2C+Y">Yuling Jiao</a>, 
<a href="/search/stat?searchtype=author&query=Wang%2C+J">Junhui Wang</a>, 
<a href="/search/stat?searchtype=author&query=Huang%2C+J">Jian Huang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 27 pages, 3 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">We propose a general approach to evaluating the performance of robust
estimators based on adversarial losses under misspecified models. We first show
that adversarial risk is equivalent to the risk induced by a distributional
adversarial attack under certain smoothness conditions. This ensures that the
adversarial training procedure is well-defined. To evaluate the generalization
performance of the adversarial estimator, we study the adversarial excess risk.
Our proposed analysis method includes investigations on both generalization
error and approximation error. We then establish non-asymptotic upper bounds
for the adversarial excess risk associated with Lipschitz loss functions. In
addition, we apply our general results to adversarial training for
classification and regression problems. For the quadratic loss in nonparametric
regression, we show that the adversarial excess risk bound can be improved over
those for a general loss.
</p>
</div>
</dd>
<dt><a name="item761">[761]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.00805" title="Abstract">arXiv:2309.00805</a> (cross-list from econ.EM) [<a href="/pdf/2309.00805" title="Download PDF">pdf</a>, <a href="/format/2309.00805" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fairness Implications of Heterogeneous Treatment Effect Estimation with  Machine Learning Methods in Policy-making
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/econ?searchtype=author&query=Rehill%2C+P">Patrick Rehill</a>, 
<a href="/search/econ?searchtype=author&query=Biddle%2C+N">Nicholas Biddle</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, 1 figure
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Econometrics (econ.EM)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Causal machine learning methods which flexibly generate heterogeneous
treatment effect estimates could be very useful tools for governments trying to
make and implement policy. However, as the critical artificial intelligence
literature has shown, governments must be very careful of unintended
consequences when using machine learning models. One way to try and protect
against unintended bad outcomes is with AI Fairness methods which seek to
create machine learning models where sensitive variables like race or gender do
not influence outcomes. In this paper we argue that standard AI Fairness
approaches developed for predictive machine learning are not suitable for all
causal machine learning applications because causal machine learning generally
(at least so far) uses modelling to inform a human who is the ultimate
decision-maker while AI Fairness approaches assume a model that is making
decisions directly. We define these scenarios as indirect and direct
decision-making respectively and suggest that policy-making is best seen as a
joint decision where the causal machine learning model usually only has
indirect power. We lay out a definition of fairness for this scenario - a model
that provides the information a decision-maker needs to accurately make a value
judgement about just policy outcomes - and argue that the complexity of causal
machine learning models can make this difficult to achieve. The solution here
is not traditional AI Fairness adjustments, but careful modelling and awareness
of some of the decision-making biases that these methods might encourage which
we describe.
</p>
</div>
</dd>
<dt><a name="item762">[762]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.00807" title="Abstract">arXiv:2309.00807</a> (cross-list from eess.SP) [<a href="/pdf/2309.00807" title="Download PDF">pdf</a>, <a href="/format/2309.00807" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Consensus-based Distributed Variational Multi-object Tracker in  Multi-Sensor Network
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Li%2C+Q">Qing Li</a>, 
<a href="/search/eess?searchtype=author&query=Gan%2C+R">Runze Gan</a>, 
<a href="/search/eess?searchtype=author&query=Godsill%2C+S">Simon Godsill</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Networking and Internet Architecture (cs.NI)

</div>
<p class="mathjax">The growing need for accurate and reliable tracking systems has driven
significant progress in sensor fusion and object tracking techniques. In this
paper, we design two variational Bayesian trackers that effectively track
multiple targets in cluttered environments within a sensor network. We first
present a centralised sensor fusion scheme, which involves transmitting sensor
data to a fusion center. Then, we develop a distributed version leveraging the
average consensus algorithm, which is theoretically equivalent to the
centralised sensor fusion tracker and requires only local message passing with
neighbouring sensors. In addition, we empirically verify that our proposed
distributed variational tracker performs on par with the centralised version
with equal tracking accuracy. Simulation results show that our distributed
multi-target tracker outperforms the suboptimal distributed sensor fusion
strategy that fuses each sensor's posterior based on arithmetic sensor fusion
and an average consensus strategy.
</p>
</div>
</dd>
<dt><a name="item763">[763]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.00831" title="Abstract">arXiv:2309.00831</a> (cross-list from eess.IV) [<a href="/pdf/2309.00831" title="Download PDF">pdf</a>, <a href="/format/2309.00831" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Multi-scale Learning of Data-driven and Anatomically Constrained Image  Registration for Adult and Fetal Echo Images
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Hasan%2C+M+K">Md. Kamrul Hasan</a>, 
<a href="/search/eess?searchtype=author&query=Zhu%2C+H">Haobo Zhu</a>, 
<a href="/search/eess?searchtype=author&query=Yang%2C+G">Guang Yang</a>, 
<a href="/search/eess?searchtype=author&query=Yap%2C+C+H">Choon Hwai Yap</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Temporal echo image registration is a basis for clinical quantifications such
as cardiac motion estimation, myocardial strain assessments, and stroke volume
quantifications. Deep learning image registration (DLIR) is consistently
accurate, requires less computing effort, and has shown encouraging results in
earlier applications. However, we propose that a greater focus on the warped
moving image's anatomic plausibility and image quality can support robust DLIR
performance. Further, past implementations have focused on adult echo, and
there is an absence of DLIR implementations for fetal echo. We propose a
framework combining three strategies for DLIR for both fetal and adult echo:
(1) an anatomic shape-encoded loss to preserve physiological myocardial and
left ventricular anatomical topologies in warped images; (2) a data-driven loss
that is trained adversarially to preserve good image texture features in warped
images; and (3) a multi-scale training scheme of a data-driven and anatomically
constrained algorithm to improve accuracy. Our experiments show that the
shape-encoded loss and the data-driven adversarial loss are strongly correlated
to good anatomical topology and image textures, respectively. They improve
different aspects of registration performance in a non-overlapping way,
justifying their combination. We show that these strategies can provide
excellent registration results in both adult and fetal echo using the publicly
available CAMUS adult echo dataset and our private multi-demographic fetal echo
dataset, despite fundamental distinctions between adult and fetal echo images.
Our approach also outperforms traditional non-DL gold standard registration
approaches, including Optical Flow and Elastix. Registration improvements could
also be translated to more accurate and precise clinical quantification of
cardiac ejection fraction, demonstrating a potential for translation.
</p>
</div>
</dd>
<dt><a name="item764">[764]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.00853" title="Abstract">arXiv:2309.00853</a> (cross-list from eess.IV) [<a href="/pdf/2309.00853" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Correlated and Multi-frequency Diffusion Modeling for Highly  Under-sampled MRI Reconstruction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Guan%2C+Y">Yu Guan</a>, 
<a href="/search/eess?searchtype=author&query=Yu%2C+C">Chuanming Yu</a>, 
<a href="/search/eess?searchtype=author&query=Lu%2C+S">Shiyu Lu</a>, 
<a href="/search/eess?searchtype=author&query=Cui%2C+Z">Zhuoxu Cui</a>, 
<a href="/search/eess?searchtype=author&query=Liang%2C+D">Dong Liang</a>, 
<a href="/search/eess?searchtype=author&query=Liu%2C+Q">Qiegen Liu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Most existing MRI reconstruction methods perform tar-geted reconstruction of
the entire MR image without tak-ing specific tissue regions into consideration.
This may fail to emphasize the reconstruction accuracy on im-portant tissues
for diagnosis. In this study, leveraging a combination of the properties of
k-space data and the diffusion process, our novel scheme focuses on mining the
multi-frequency prior with different strategies to pre-serve fine texture
details in the reconstructed image. In addition, a diffusion process can
converge more quickly if its target distribution closely resembles the noise
distri-bution in the process. This can be accomplished through various
high-frequency prior extractors. The finding further solidifies the
effectiveness of the score-based gen-erative model. On top of all the
advantages, our method improves the accuracy of MRI reconstruction and
accel-erates sampling process. Experimental results verify that the proposed
method successfully obtains more accurate reconstruction and outperforms
state-of-the-art methods.
</p>
</div>
</dd>
<dt><a name="item765">[765]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.00866" title="Abstract">arXiv:2309.00866</a> (cross-list from stat.ME) [<a href="/pdf/2309.00866" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Tutorial: a priori estimation of sample size, effect size, and  statistical power for cluster analysis, latent class analysis, and  multivariate mixture models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Dalmaijer%2C+E+S">Edwin S Dalmaijer</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Code and data: <a href="https://github.com/esdalmaijer/cluster_power_tutorial">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Methodology (stat.ME)</span>; Machine Learning (cs.LG); Other Quantitative Biology (q-bio.OT)

</div>
<p class="mathjax">Before embarking on data collection, researchers typically compute how many
individual observations they should do. This is vital for doing studies with
sufficient statistical power, and often a cornerstone in study
pre-registrations and grant applications. For traditional statistical tests,
one would typically determine an acceptable level of statistical power,
(gu)estimate effect size, and then use both values to compute the required
sample size. However, for analyses that identify subgroups, statistical power
is harder to establish. Once sample size reaches a sufficient threshold, effect
size is primarily determined by the number of measured features and the
underlying subgroup separation. As a consequence, a priory computations of
statistical power are notoriously complex. In this tutorial, I will provide a
roadmap to determining sample size and effect size for analyses that identify
subgroups. First, I introduce a procedure that allows researchers to formalise
their expectations about effect sizes in their domain of choice, and use this
to compute the minimally required number of measured variables. Next, I outline
how to establish the minimum sample size in subgroup analyses. Finally, I use
simulations to provide a reference table for the most popular subgroup
analyses: k-means, Ward agglomerative hierarchical clustering, c-means fuzzy
clustering, latent class analysis, latent profile analysis, and Gaussian
mixture modelling. The table shows the minimum numbers of observations per
expected subgroup (sample size) and features (measured variables) to achieve
acceptable statistical power, and can be readily used in study design.
</p>
</div>
</dd>
<dt><a name="item766">[766]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.00885" title="Abstract">arXiv:2309.00885</a> (cross-list from eess.IV) [<a href="/pdf/2309.00885" title="Download PDF">pdf</a>, <a href="/format/2309.00885" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Generic Fundus Image Enhancement Network Boosted by Frequency  Self-supervised Representation Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Li%2C+H">Heng Li</a>, 
<a href="/search/eess?searchtype=author&query=Liu%2C+H">Haofeng Liu</a>, 
<a href="/search/eess?searchtype=author&query=Fu%2C+H">Huazhu Fu</a>, 
<a href="/search/eess?searchtype=author&query=Xu%2C+Y">Yanwu Xu</a>, 
<a href="/search/eess?searchtype=author&query=Shu%2C+H">Hui Shu</a>, 
<a href="/search/eess?searchtype=author&query=Niu%2C+K">Ke Niu</a>, 
<a href="/search/eess?searchtype=author&query=Hu%2C+Y">Yan Hu</a>, 
<a href="/search/eess?searchtype=author&query=Liu%2C+J">Jiang Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by Medical Image Analysis in Auguest, 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
<p class="mathjax">Fundus photography is prone to suffer from image quality degradation that
impacts clinical examination performed by ophthalmologists or intelligent
systems. Though enhancement algorithms have been developed to promote fundus
observation on degraded images, high data demands and limited applicability
hinder their clinical deployment. To circumvent this bottleneck, a generic
fundus image enhancement network (GFE-Net) is developed in this study to
robustly correct unknown fundus images without supervised or extra data.
Levering image frequency information, self-supervised representation learning
is conducted to learn robust structure-aware representations from degraded
images. Then with a seamless architecture that couples representation learning
and image enhancement, GFE-Net can accurately correct fundus images and
meanwhile preserve retinal structures. Comprehensive experiments are
implemented to demonstrate the effectiveness and advantages of GFE-Net.
Compared with state-of-the-art algorithms, GFE-Net achieves superior
performance in data dependency, enhancement performance, deployment efficiency,
and scale generalizability. Follow-up fundus image analysis is also facilitated
by GFE-Net, whose modules are respectively verified to be effective for image
enhancement.
</p>
</div>
</dd>
<dt><a name="item767">[767]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.00902" title="Abstract">arXiv:2309.00902</a> (cross-list from math.CO) [<a href="/pdf/2309.00902" title="Download PDF">pdf</a>, <a href="/format/2309.00902" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Characterising 4-tangles through a connectivity property
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Carmesin%2C+J">Johannes Carmesin</a>, 
<a href="/search/math?searchtype=author&query=Kurkofka%2C+J">Jan Kurkofka</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages, 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Combinatorics (math.CO)</span>; Discrete Mathematics (cs.DM)

</div>
<p class="mathjax">Every large $k$-connected graph-minor induces a $k$-tangle in its ambient
graph. The converse holds for $k\le 3$, but fails for $k\ge 4$. This raises the
question whether `$k$-connected' can be relaxed to obtain a characterisation of
$k$-tangles through highly cohesive graph-minors. We show that this can be
achieved for $k=4$ by proving that internally 4-connected graphs have unique
4-tangles, and that every graph with a 4-tangle $\tau$ has an internally
4-connected minor whose unique 4-tangle lifts to~$\tau$.
</p>
</div>
</dd>
<dt><a name="item768">[768]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.00907" title="Abstract">arXiv:2309.00907</a> (cross-list from eess.SP) [<a href="/pdf/2309.00907" title="Download PDF">pdf</a>, <a href="/format/2309.00907" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Multi-Head Ensemble Multi-Task Learning Approach for Dynamical  Computation Offloading
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Liang%2C+R">Ruihuai Liang</a>, 
<a href="/search/eess?searchtype=author&query=Yang%2C+B">Bo Yang</a>, 
<a href="/search/eess?searchtype=author&query=Yu%2C+Z">Zhiwen Yu</a>, 
<a href="/search/eess?searchtype=author&query=Cao%2C+X">Xuelin Cao</a>, 
<a href="/search/eess?searchtype=author&query=Ng%2C+D+W+K">Derrick Wing Kwan Ng</a>, 
<a href="/search/eess?searchtype=author&query=Yuen%2C+C">Chau Yuen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Computation offloading has become a popular solution to support
computationally intensive and latency-sensitive applications by transferring
computing tasks to mobile edge servers (MESs) for execution, which is known as
mobile/multi-access edge computing (MEC). To improve the MEC performance, it is
required to design an optimal offloading strategy that includes offloading
decision (i.e., whether offloading or not) and computational resource
allocation of MEC. The design can be formulated as a mixed-integer nonlinear
programming (MINLP) problem, which is generally NP-hard and its effective
solution can be obtained by performing online inference through a well-trained
deep neural network (DNN) model. However, when the system environments change
dynamically, the DNN model may lose efficacy due to the drift of input
parameters, thereby decreasing the generalization ability of the DNN model. To
address this unique challenge, in this paper, we propose a multi-head ensemble
multi-task learning (MEMTL) approach with a shared backbone and multiple
prediction heads (PHs). Specifically, the shared backbone will be invariant
during the PHs training and the inferred results will be ensembled, thereby
significantly reducing the required training overhead and improving the
inference performance. As a result, the joint optimization problem for
offloading decision and resource allocation can be efficiently solved even in a
time-varying wireless environment. Experimental results show that the proposed
MEMTL outperforms benchmark methods in both the inference accuracy and mean
square error without requiring additional training data.
</p>
</div>
</dd>
<dt><a name="item769">[769]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.00911" title="Abstract">arXiv:2309.00911</a> (cross-list from eess.IV) [<a href="/pdf/2309.00911" title="Download PDF">pdf</a>, <a href="/format/2309.00911" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A novel framework employing deep multi-attention channels network for  the autonomous detection of metastasizing cells through fluorescence  microscopy
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Mamalakis%2C+M">Michail Mamalakis</a>, 
<a href="/search/eess?searchtype=author&query=Macfarlane%2C+S+C">Sarah C. Macfarlane</a>, 
<a href="/search/eess?searchtype=author&query=Notley%2C+S+V">Scott V. Notley</a>, 
<a href="/search/eess?searchtype=author&query=Gad%2C+A+K+B">Annica K.B Gad</a>, 
<a href="/search/eess?searchtype=author&query=Panoutsos%2C+G">George Panoutsos</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
<p class="mathjax">We developed a transparent computational large-scale imaging-based framework
that can distinguish between normal and metastasizing human cells. The method
relies on fluorescence microscopy images showing the spatial organization of
actin and vimentin filaments in normal and metastasizing single cells, using a
combination of multi-attention channels network and global explainable
techniques. We test a classification between normal cells (Bj primary
fibroblast), and their isogenically matched, transformed and invasive
counterpart (BjTertSV40TRasV12). Manual annotation is not trivial to automate
due to the intricacy of the biologically relevant features. In this research,
we utilized established deep learning networks and our new multi-attention
channel architecture. To increase the interpretability of the network - crucial
for this application area - we developed an interpretable global explainable
approach correlating the weighted geometric mean of the total cell images and
their local GradCam scores. The significant results from our analysis
unprecedently allowed a more detailed, and biologically relevant understanding
of the cytoskeletal changes that accompany oncogenic transformation of normal
to invasive and metastasizing cells. We also paved the way for a possible
spatial micrometre-level biomarker for future development of diagnostic tools
against metastasis (spatial distribution of vimentin).
</p>
</div>
</dd>
<dt><a name="item770">[770]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.00971" title="Abstract">arXiv:2309.00971</a> (cross-list from eess.IV) [<a href="/pdf/2309.00971" title="Download PDF">pdf</a>, <a href="/format/2309.00971" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AdLER: Adversarial Training with Label Error Rectification for One-Shot  Medical Image Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Zhao%2C+X">Xiangyu Zhao</a>, 
<a href="/search/eess?searchtype=author&query=Wang%2C+S">Sheng Wang</a>, 
<a href="/search/eess?searchtype=author&query=Song%2C+Z">Zhiyun Song</a>, 
<a href="/search/eess?searchtype=author&query=Shen%2C+Z">Zhenrong Shen</a>, 
<a href="/search/eess?searchtype=author&query=Yao%2C+L">Linlin Yao</a>, 
<a href="/search/eess?searchtype=author&query=Yuan%2C+H">Haolei Yuan</a>, 
<a href="/search/eess?searchtype=author&query=Wang%2C+Q">Qian Wang</a>, 
<a href="/search/eess?searchtype=author&query=Zhang%2C+L">Lichi Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Accurate automatic segmentation of medical images typically requires large
datasets with high-quality annotations, making it less applicable in clinical
settings due to limited training data. One-shot segmentation based on learned
transformations (OSSLT) has shown promise when labeled data is extremely
limited, typically including unsupervised deformable registration, data
augmentation with learned registration, and segmentation learned from augmented
data. However, current one-shot segmentation methods are challenged by limited
data diversity during augmentation, and potential label errors caused by
imperfect registration. To address these issues, we propose a novel one-shot
medical image segmentation method with adversarial training and label error
rectification (AdLER), with the aim of improving the diversity of generated
data and correcting label errors to enhance segmentation performance.
Specifically, we implement a novel dual consistency constraint to ensure
anatomy-aligned registration that lessens registration errors. Furthermore, we
develop an adversarial training strategy to augment the atlas image, which
ensures both generation diversity and segmentation robustness. We also propose
to rectify potential label errors in the augmented atlas images by estimating
segmentation uncertainty, which can compensate for the imperfect nature of
deformable registration and improve segmentation authenticity. Experiments on
the CANDI and ABIDE datasets demonstrate that the proposed AdLER outperforms
previous state-of-the-art methods by 0.7% (CANDI), 3.6% (ABIDE "seen"), and
4.9% (ABIDE "unseen") in segmentation based on Dice scores, respectively. The
source code will be available at https://github.com/hsiangyuzhao/AdLER.
</p>
</div>
</dd>
<dt><a name="item771">[771]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.00983" title="Abstract">arXiv:2309.00983</a> (cross-list from stat.ML) [<a href="/pdf/2309.00983" title="Download PDF">pdf</a>, <a href="/format/2309.00983" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An Ensemble Score Filter for Tracking High-Dimensional Nonlinear  Dynamical Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Bao%2C+F">Feng Bao</a>, 
<a href="/search/stat?searchtype=author&query=Zhang%2C+Z">Zezhong Zhang</a>, 
<a href="/search/stat?searchtype=author&query=Zhang%2C+G">Guannan Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: text overlap with <a href="/abs/2306.09282">arXiv:2306.09282</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG); Optimization and Control (math.OC)

</div>
<p class="mathjax">We propose an ensemble score filter (EnSF) for solving high-dimensional
nonlinear filtering problems with superior accuracy. A major drawback of
existing filtering methods, e.g., particle filters or ensemble Kalman filters,
is the low accuracy in handling high-dimensional and highly nonlinear problems.
EnSF attacks this challenge by exploiting the score-based diffusion model,
defined in a pseudo-temporal domain, to characterizing the evolution of the
filtering density. EnSF stores the information of the recursively updated
filtering density function in the score function, in stead of storing the
information in a set of finite Monte Carlo samples (used in particle filters
and ensemble Kalman filters). Unlike existing diffusion models that train
neural networks to approximate the score function, we develop a training-free
score estimation that uses mini-batch-based Monte Carlo estimator to directly
approximate the score function at any pseudo-spatial-temporal location, which
provides sufficient accuracy in solving high-dimensional nonlinear problems as
well as saves tremendous amount of time spent on training neural networks.
Another essential aspect of EnSF is its analytical update step, gradually
incorporating data information into the score function, which is crucial in
mitigating the degeneracy issue faced when dealing with very high-dimensional
nonlinear filtering problems. High-dimensional Lorenz systems are used to
demonstrate the performance of our method. EnSF provides surprisingly
impressive performance in reliably tracking extremely high-dimensional Lorenz
systems (up to 1,000,000 dimension) with highly nonlinear observation
processes, which is a well-known challenging problem for existing filtering
methods.
</p>
</div>
</dd>
<dt><a name="item772">[772]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.00995" title="Abstract">arXiv:2309.00995</a> (cross-list from eess.IV) [<a href="/pdf/2309.00995" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Constrained CycleGAN for Effective Generation of Ultrasound Sector  Images of Improved Spatial Resolution
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Sun%2C+X">Xiaofei Sun</a>, 
<a href="/search/eess?searchtype=author&query=Li%2C+H">He Li</a>, 
<a href="/search/eess?searchtype=author&query=Lee%2C+W">Wei-Ning Lee</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Physics in Medicine &amp; Biology 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Objective. A phased or a curvilinear array produces ultrasound (US) images
with a sector field of view (FOV), which inherently exhibits spatially-varying
image resolution with inferior quality in the far zone and towards the two
sides azimuthally. Sector US images with improved spatial resolutions are
favorable for accurate quantitative analysis of large and dynamic organs, such
as the heart. Therefore, this study aims to translate US images with
spatially-varying resolution to ones with less spatially-varying resolution.
CycleGAN has been a prominent choice for unpaired medical image translation;
however, it neither guarantees structural consistency nor preserves
backscattering patterns between input and generated images for unpaired US
images. Approach. To circumvent this limitation, we propose a constrained
CycleGAN (CCycleGAN), which directly performs US image generation with unpaired
images acquired by different ultrasound array probes. In addition to
conventional adversarial and cycle-consistency losses of CycleGAN, CCycleGAN
introduces an identical loss and a correlation coefficient loss based on
intrinsic US backscattered signal properties to constrain structural
consistency and backscattering patterns, respectively. Instead of
post-processed B-mode images, CCycleGAN uses envelope data directly obtained
from beamformed radio-frequency signals without any other non-linear
postprocessing. Main Results. In vitro phantom results demonstrate that
CCycleGAN successfully generates images with improved spatial resolution as
well as higher peak signal-to-noise ratio (PSNR) and structural similarity
(SSIM) compared with benchmarks. Significance. CCycleGAN-generated US images of
the in vivo human beating heart further facilitate higher quality heart wall
motion estimation than benchmarks-generated ones, particularly in deep regions.
</p>
</div>
</dd>
<dt><a name="item773">[773]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.00999" title="Abstract">arXiv:2309.00999</a> (cross-list from stat.ML) [<a href="/pdf/2309.00999" title="Download PDF">pdf</a>, <a href="/format/2309.00999" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Bayesian sparsity and class sparsity priors for dictionary learning and  coding
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Bocchinfuso%2C+A">Alberto Bocchinfuso</a>, 
<a href="/search/stat?searchtype=author&query=Calvetti%2C+D">Daniela Calvetti</a>, 
<a href="/search/stat?searchtype=author&query=Somersalo%2C+E">Erkki Somersalo</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG); Numerical Analysis (math.NA)

</div>
<p class="mathjax">Dictionary learning methods continue to gain popularity for the solution of
challenging inverse problems. In the dictionary learning approach, the
computational forward model is replaced by a large dictionary of possible
outcomes, and the problem is to identify the dictionary entries that best match
the data, akin to traditional query matching in search engines. Sparse coding
techniques are used to guarantee that the dictionary matching identifies only
few of the dictionary entries, and dictionary compression methods are used to
reduce the complexity of the matching problem. In this article, we propose a
work flow to facilitate the dictionary matching process. First, the full
dictionary is divided into subdictionaries that are separately compressed. The
error introduced by the dictionary compression is handled in the Bayesian
framework as a modeling error. Furthermore, we propose a new Bayesian
data-driven group sparsity coding method to help identify subdictionaries that
are not relevant for the dictionary matching. After discarding irrelevant
subdictionaries, the dictionary matching is addressed as a deflated problem
using sparse coding. The compression and deflation steps can lead to
substantial decreases of the computational complexity. The effectiveness of
compensating for the dictionary compression error and using the novel group
sparsity promotion to deflate the original dictionary are illustrated by
applying the methodology to real world problems, the glitch detection in the
LIGO experiment and hyperspectral remote sensing.
</p>
</div>
</dd>
<dt><a name="item774">[774]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01001" title="Abstract">arXiv:2309.01001</a> (cross-list from math.CO) [<a href="/pdf/2309.01001" title="Download PDF">pdf</a>, <a href="/format/2309.01001" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Cops and Robbers on 1-Planar Graphs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Durocher%2C+S">Stephane Durocher</a>, 
<a href="/search/math?searchtype=author&query=Kamali%2C+S">Shahin Kamali</a>, 
<a href="/search/math?searchtype=author&query=Kryven%2C+M">Myroslav Kryven</a>, 
<a href="/search/math?searchtype=author&query=Liu%2C+F">Fengyi Liu</a>, 
<a href="/search/math?searchtype=author&query=Mashghdoust%2C+A">Amirhossein Mashghdoust</a>, 
<a href="/search/math?searchtype=author&query=Miller%2C+A">Avery Miller</a>, 
<a href="/search/math?searchtype=author&query=Nezhad%2C+P+Z">Pouria Zamani Nezhad</a>, 
<a href="/search/math?searchtype=author&query=Costa%2C+I+P">Ikaro Penha Costa</a>, 
<a href="/search/math?searchtype=author&query=Zapp%2C+T">Timothy Zapp</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Appears in the Proceedings of the 31st International Symposium on Graph Drawing and Network Visualization (GD 2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Combinatorics (math.CO)</span>; Discrete Mathematics (cs.DM)

</div>
<p class="mathjax">Cops and Robbers is a well-studied pursuit-evasion game in which a set of
cops seeks to catch a robber in a graph G, where cops and robber move along
edges of G. The cop number of G is the minimum number of cops that is
sufficient to catch the robber. Every planar graph has cop number at most
three, and there are planar graphs for which three cops are necessary [Aigner
and Fromme, DAM 1984]. We study the problem for beyond-planar graphs, that is,
graphs that can be drawn in the plane with few crossings. In particular, we
focus on 1-planar graphs, that is, graphs that can be drawn in the plane with
at most one crossing per edge. In contrast to planar graphs, we show that some
1-planar graphs have unbounded cop number. Meanwhile, for maximal 1-planar
graphs, we prove that three cops are always sufficient and sometimes necessary.
In addition, we characterize outer 1-planar graphs with respect to their cop
number.
</p>
</div>
</dd>
<dt><a name="item775">[775]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01007" title="Abstract">arXiv:2309.01007</a> (cross-list from eess.IV) [<a href="/pdf/2309.01007" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Comparative Analysis of Deep Learning Architectures for Breast Cancer  Diagnosis Using the BreaKHis Dataset
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Say%C4%B1n%2C+%C4%B0">&#x130;rem Say&#x131;n</a>, 
<a href="/search/eess?searchtype=author&query=Soyda%C5%9F%2C+M+A">Muhammed Ali Soyda&#x15f;</a>, 
<a href="/search/eess?searchtype=author&query=Mert%2C+Y+E">Yunus Emre Mert</a>, 
<a href="/search/eess?searchtype=author&query=Yarkada%C5%9F%2C+A">Arda Yarkada&#x15f;</a>, 
<a href="/search/eess?searchtype=author&query=Erg%C3%BCn%2C+B">Berk Erg&#xfc;n</a>, 
<a href="/search/eess?searchtype=author&query=Yeh%2C+S+S">Selma S&#xf6;zen Yeh</a>, 
<a href="/search/eess?searchtype=author&query=%C3%9Cvet%2C+H">H&#xfc;seyin &#xdc;vet</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, 1 figure, 2 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
<p class="mathjax">Cancer is an extremely difficult and dangerous health problem because it
manifests in so many different ways and affects so many different organs and
tissues. The primary goal of this research was to evaluate deep learning
models' ability to correctly identify breast cancer cases using the BreakHis
dataset. The BreakHis dataset covers a wide range of breast cancer subtypes
through its huge collection of histopathological pictures. In this study, we
use and compare the performance of five well-known deep learning models for
cancer classification: VGG, ResNet, Xception, Inception, and InceptionResNet.
The results placed the Xception model at the top, with an F1 score of 0.9 and
an accuracy of 89%. At the same time, the Inception and InceptionResNet models
both hit accuracy of 87% . However, the F1 score for the Inception model was
87, while that for the InceptionResNet model was 86. These results demonstrate
the importance of deep learning methods in making correct breast cancer
diagnoses. This highlights the potential to provide improved diagnostic
services to patients. The findings of this study not only improve current
methods of cancer diagnosis, but also make significant contributions to the
creation of new and improved cancer treatment strategies. In a nutshell, the
results of this study represent a major advancement in the direction of
achieving these vital healthcare goals.
</p>
</div>
</dd>
<dt><a name="item776">[776]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01043" title="Abstract">arXiv:2309.01043</a> (cross-list from math.ST) [<a href="/pdf/2309.01043" title="Download PDF">pdf</a>, <a href="/ps/2309.01043" title="Download PostScript">ps</a>, <a href="/format/2309.01043" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Distribution learning via neural differential equations: a nonparametric  statistical perspective
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Marzouk%2C+Y">Youssef Marzouk</a>, 
<a href="/search/math?searchtype=author&query=Ren%2C+Z">Zhi Ren</a>, 
<a href="/search/math?searchtype=author&query=Wang%2C+S">Sven Wang</a>, 
<a href="/search/math?searchtype=author&query=Zech%2C+J">Jakob Zech</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Statistics Theory (math.ST)</span>; Machine Learning (cs.LG); Classical Analysis and ODEs (math.CA); Machine Learning (stat.ML)

</div>
<p class="mathjax">Ordinary differential equations (ODEs), via their induced flow maps, provide
a powerful framework to parameterize invertible transformations for the purpose
of representing complex probability distributions. While such models have
achieved enormous success in machine learning, particularly for generative
modeling and density estimation, little is known about their statistical
properties. This work establishes the first general nonparametric statistical
convergence analysis for distribution learning via ODE models trained through
likelihood maximization. We first prove a convergence theorem applicable to
arbitrary velocity field classes $\mathcal{F}$ satisfying certain simple
boundary constraints. This general result captures the trade-off between
approximation error (`bias') and the complexity of the ODE model (`variance').
We show that the latter can be quantified via the $C^1$-metric entropy of the
class $\mathcal F$. We then apply this general framework to the setting of
$C^k$-smooth target densities, and establish nearly minimax-optimal convergence
rates for two relevant velocity field classes $\mathcal F$: $C^k$ functions and
neural networks. The latter is the practically important case of neural ODEs.
<br />Our proof techniques require a careful synthesis of (i) analytical stability
results for ODEs, (ii) classical theory for sieved M-estimators, and (iii)
recent results on approximation rates and metric entropies of neural network
classes. The results also provide theoretical insight on how the choice of
velocity field class, and the dependence of this choice on sample size $n$
(e.g., the scaling of width, depth, and sparsity of neural network classes),
impacts statistical performance.
</p>
</div>
</dd>
<dt><a name="item777">[777]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01072" title="Abstract">arXiv:2309.01072</a> (cross-list from eess.IV) [<a href="/pdf/2309.01072" title="Download PDF">pdf</a>, <a href="/format/2309.01072" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Channel Attention Separable Convolution Network for Skin Lesion  Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Guo%2C+C">Changlu Guo</a>, 
<a href="/search/eess?searchtype=author&query=Dai%2C+J">Jiangyan Dai</a>, 
<a href="/search/eess?searchtype=author&query=Szemenyei%2C+M">Marton Szemenyei</a>, 
<a href="/search/eess?searchtype=author&query=Yi%2C+Y">Yugen Yi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by ICONIP 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Skin cancer is a frequently occurring cancer in the human population, and it
is very important to be able to diagnose malignant tumors in the body early.
Lesion segmentation is crucial for monitoring the morphological changes of skin
lesions, extracting features to localize and identify diseases to assist
doctors in early diagnosis. Manual de-segmentation of dermoscopic images is
error-prone and time-consuming, thus there is a pressing demand for precise and
automated segmentation algorithms. Inspired by advanced mechanisms such as
U-Net, DenseNet, Separable Convolution, Channel Attention, and Atrous Spatial
Pyramid Pooling (ASPP), we propose a novel network called Channel Attention
Separable Convolution Network (CASCN) for skin lesions segmentation. The
proposed CASCN is evaluated on the PH2 dataset with limited images. Without
excessive pre-/post-processing of images, CASCN achieves state-of-the-art
performance on the PH2 dataset with Dice similarity coefficient of 0.9461 and
accuracy of 0.9645.
</p>
</div>
</dd>
<dt><a name="item778">[778]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01082" title="Abstract">arXiv:2309.01082</a> (cross-list from stat.ML) [<a href="/pdf/2309.01082" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Tropical Geometric Tools for Machine Learning: the TML package
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Barnhill%2C+D">David Barnhill</a>, 
<a href="/search/stat?searchtype=author&query=Yoshida%2C+R">Ruriko Yoshida</a>, 
<a href="/search/stat?searchtype=author&query=Aliatimis%2C+G">Georges Aliatimis</a>, 
<a href="/search/stat?searchtype=author&query=Miura%2C+K">Keiji Miura</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG); Algebraic Geometry (math.AG)

</div>
<p class="mathjax">In the last decade, developments in tropical geometry have provided a number
of uses directly applicable to problems in statistical learning. The TML
package is the first R package which contains a comprehensive set of tools and
methods used for basic computations related to tropical convexity,
visualization of tropically convex sets, as well as supervised and unsupervised
learning models using the tropical metric under the max-plus algebra over the
tropical projective torus. Primarily, the TML package employs a Hit and Run
Markov chain Monte Carlo sampler in conjunction with the tropical metric as its
main tool for statistical inference. In addition to basic computation and
various applications of the tropical HAR sampler, we also focus on several
supervised and unsupervised methods incorporated in the TML package including
tropical principal component analysis, tropical logistic regression and
tropical kernel density estimation.
</p>
</div>
</dd>
<dt><a name="item779">[779]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01108" title="Abstract">arXiv:2309.01108</a> (cross-list from eess.AS) [<a href="/pdf/2309.01108" title="Download PDF">pdf</a>, <a href="/format/2309.01108" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Acoustic-to-articulatory inversion for dysarthric speech: Are  pre-trained self-supervised representations favorable?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Maharana%2C+S+K">Sarthak Kumar Maharana</a>, 
<a href="/search/eess?searchtype=author&query=Adidam%2C+K+K">Krishna Kamal Adidam</a>, 
<a href="/search/eess?searchtype=author&query=Nandi%2C+S">Shoumik Nandi</a>, 
<a href="/search/eess?searchtype=author&query=Srivastava%2C+A">Ajitesh Srivastava</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Machine Learning (cs.LG); Sound (cs.SD)

</div>
<p class="mathjax">$ $Acoustic-to-articulatory inversion (AAI) involves mapping from the
acoustic space to the articulatory space. Signal-processing features like the
MFCCs, have been widely used for the AAI task. For subjects with dysarthric
speech, AAI is challenging because of an imprecise and indistinct
pronunciation. In this work, we perform AAI for dysarthric speech using
representations from pre-trained self-supervised learning (SSL) models. We
demonstrate the impact of different pre-trained features on this challenging
AAI task, at low-resource conditions. In addition, we also condition x-vectors
to the extracted SSL features to train a BLSTM network. In the seen case, we
experiment with three AAI training schemes (subject-specific, pooled, and
fine-tuned). The results, consistent across training schemes, reveal that
DeCoAR, in the fine-tuned scheme, achieves a relative improvement of the
Pearson Correlation Coefficient (CC) by ${\sim}$1.81\% and ${\sim}$4.56\% for
healthy controls and patients, respectively, over MFCCs. In the unseen case, we
observe similar average trends for different SSL features. Overall, SSL
networks like wav2vec, APC, and DeCoAR, which are trained with feature
reconstruction or future timestep prediction tasks, perform well in predicting
dysarthric articulatory trajectories.
</p>
</div>
</dd>
<dt><a name="item780">[780]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01122" title="Abstract">arXiv:2309.01122</a> (cross-list from q-bio.QM) [<a href="/pdf/2309.01122" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AI driven B-cell Immunotherapy Design
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-bio?searchtype=author&query=da+Silva%2C+B+M">Bruna Moreira da Silva</a> (1), 
<a href="/search/q-bio?searchtype=author&query=Ascher%2C+D+B">David B. Ascher</a> (2), 
<a href="/search/q-bio?searchtype=author&query=Geard%2C+N">Nicholas Geard</a> (1), 
<a href="/search/q-bio?searchtype=author&query=Pires%2C+D+E+V">Douglas E. V. Pires</a> (1) ((1) The University of Melbourne, (2) The University of Queensland)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantitative Methods (q-bio.QM)</span>; Computational Engineering, Finance, and Science (cs.CE); Machine Learning (cs.LG)

</div>
<p class="mathjax">Antibodies, a prominent class of approved biologics, play a crucial role in
detecting foreign antigens. The effectiveness of antigen neutralisation and
elimination hinges upon the strength, sensitivity, and specificity of the
paratope-epitope interaction, which demands resource-intensive experimental
techniques for characterisation. In recent years, artificial intelligence and
machine learning methods have made significant strides, revolutionising the
prediction of protein structures and their complexes. The past decade has also
witnessed the evolution of computational approaches aiming to support
immunotherapy design. This review focuses on the progress of machine
learning-based tools and their frameworks in the domain of B-cell immunotherapy
design, encompassing linear and conformational epitope prediction, paratope
prediction, and antibody design. We mapped the most commonly used data sources,
evaluation metrics, and method availability and thoroughly assessed their
significance and limitations, discussing the main challenges ahead.
</p>
</div>
</dd>
<dt><a name="item781">[781]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01127" title="Abstract">arXiv:2309.01127</a> (cross-list from quant-ph) [<a href="/pdf/2309.01127" title="Download PDF">pdf</a>, <a href="/format/2309.01127" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Financial Fraud Detection using Quantum Graph Neural Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Innan%2C+N">Nouhaila Innan</a>, 
<a href="/search/quant-ph?searchtype=author&query=Sawaika%2C+A">Abhishek Sawaika</a>, 
<a href="/search/quant-ph?searchtype=author&query=Dhor%2C+A">Ashim Dhor</a>, 
<a href="/search/quant-ph?searchtype=author&query=Dutta%2C+S">Siddhant Dutta</a>, 
<a href="/search/quant-ph?searchtype=author&query=Thota%2C+S">Sairupa Thota</a>, 
<a href="/search/quant-ph?searchtype=author&query=Gokal%2C+H">Husayn Gokal</a>, 
<a href="/search/quant-ph?searchtype=author&query=Patel%2C+N">Nandan Patel</a>, 
<a href="/search/quant-ph?searchtype=author&query=Khan%2C+M+A">Muhammad Al-Zafar Khan</a>, 
<a href="/search/quant-ph?searchtype=author&query=Theodonis%2C+I">Ioannis Theodonis</a>, 
<a href="/search/quant-ph?searchtype=author&query=Bennai%2C+M">Mohamed Bennai</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 15 pages, 18 figures, 4 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Financial fraud detection is essential for preventing significant financial
losses and maintaining the reputation of financial institutions. However,
conventional methods of detecting financial fraud have limited effectiveness,
necessitating the need for new approaches to improve detection rates. In this
paper, we propose a novel approach for detecting financial fraud using Quantum
Graph Neural Networks (QGNNs). QGNNs are a type of neural network that can
process graph-structured data and leverage the power of Quantum Computing (QC)
to perform computations more efficiently than classical neural networks. Our
approach uses Variational Quantum Circuits (VQC) to enhance the performance of
the QGNN. In order to evaluate the efficiency of our proposed method, we
compared the performance of QGNNs to Classical Graph Neural Networks using a
real-world financial fraud detection dataset. The results of our experiments
showed that QGNNs achieved an AUC of $0.85$, which outperformed classical GNNs.
Our research highlights the potential of QGNNs and suggests that QGNNs are a
promising new approach for improving financial fraud detection.
</p>
</div>
</dd>
<dt><a name="item782">[782]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01142" title="Abstract">arXiv:2309.01142</a> (cross-list from eess.AS) [<a href="/pdf/2309.01142" title="Download PDF">pdf</a>, <a href="/format/2309.01142" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MSM-VC: High-fidelity Source Style Transfer for Non-Parallel Voice  Conversion by Multi-scale Style Modeling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Wang%2C+Z">Zhichao Wang</a>, 
<a href="/search/eess?searchtype=author&query=Wang%2C+X">Xinsheng Wang</a>, 
<a href="/search/eess?searchtype=author&query=Xie%2C+Q">Qicong Xie</a>, 
<a href="/search/eess?searchtype=author&query=Li%2C+T">Tao Li</a>, 
<a href="/search/eess?searchtype=author&query=Xie%2C+L">Lei Xie</a>, 
<a href="/search/eess?searchtype=author&query=Tian%2C+Q">Qiao Tian</a>, 
<a href="/search/eess?searchtype=author&query=Wang%2C+Y">Yuping Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This work was submitted on April 10, 2022 and accepted on August 29, 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Sound (cs.SD)

</div>
<p class="mathjax">In addition to conveying the linguistic content from source speech to
converted speech, maintaining the speaking style of source speech also plays an
important role in the voice conversion (VC) task, which is essential in many
scenarios with highly expressive source speech, such as dubbing and data
augmentation. Previous work generally took explicit prosodic features or
fixed-length style embedding extracted from source speech to model the speaking
style of source speech, which is insufficient to achieve comprehensive style
modeling and target speaker timbre preservation. Inspired by the style's
multi-scale nature of human speech, a multi-scale style modeling method for the
VC task, referred to as MSM-VC, is proposed in this paper. MSM-VC models the
speaking style of source speech from different levels. To effectively convey
the speaking style and meanwhile prevent timbre leakage from source speech to
converted speech, each level's style is modeled by specific representation.
Specifically, prosodic features, pre-trained ASR model's bottleneck features,
and features extracted by a model trained with a self-supervised strategy are
adopted to model the frame, local, and global-level styles, respectively.
Besides, to balance the performance of source style modeling and target speaker
timbre preservation, an explicit constraint module consisting of a pre-trained
speech emotion recognition model and a speaker classifier is introduced to
MSM-VC. This explicit constraint module also makes it possible to simulate the
style transfer inference process during the training to improve the
disentanglement ability and alleviate the mismatch between training and
inference. Experiments performed on the highly expressive speech corpus
demonstrate that MSM-VC is superior to the state-of-the-art VC methods for
modeling source speech style while maintaining good speech quality and speaker
similarity.
</p>
</div>
</dd>
<dt><a name="item783">[783]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01156" title="Abstract">arXiv:2309.01156</a> (cross-list from hep-lat) [<a href="/pdf/2309.01156" title="Download PDF">pdf</a>, <a href="/format/2309.01156" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Advances in machine-learning-based sampling motivated by lattice quantum  chromodynamics
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/hep-lat?searchtype=author&query=Cranmer%2C+K">Kyle Cranmer</a>, 
<a href="/search/hep-lat?searchtype=author&query=Kanwar%2C+G">Gurtej Kanwar</a>, 
<a href="/search/hep-lat?searchtype=author&query=Racani%C3%A8re%2C+S">S&#xe9;bastien Racani&#xe8;re</a>, 
<a href="/search/hep-lat?searchtype=author&query=Rezende%2C+D+J">Danilo J. Rezende</a>, 
<a href="/search/hep-lat?searchtype=author&query=Shanahan%2C+P+E">Phiala E. Shanahan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages, 5 figures
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Nature Reviews Physics 5, 526-535 (2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">High Energy Physics - Lattice (hep-lat)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Sampling from known probability distributions is a ubiquitous task in
computational science, underlying calculations in domains from linguistics to
biology and physics. Generative machine-learning (ML) models have emerged as a
promising tool in this space, building on the success of this approach in
applications such as image, text, and audio generation. Often, however,
generative tasks in scientific domains have unique structures and features --
such as complex symmetries and the requirement of exactness guarantees -- that
present both challenges and opportunities for ML. This Perspective outlines the
advances in ML-based sampling motivated by lattice quantum field theory, in
particular for the theory of quantum chromodynamics. Enabling calculations of
the structure and interactions of matter from our most fundamental
understanding of particle physics, lattice quantum chromodynamics is one of the
main consumers of open-science supercomputing worldwide. The design of ML
algorithms for this application faces profound challenges, including the
necessity of scaling custom ML architectures to the largest supercomputers, but
also promises immense benefits, and is spurring a wave of development in
ML-based sampling more broadly. In lattice field theory, if this approach can
realize its early promise it will be a transformative step towards
first-principles physics calculations in particle, nuclear and condensed matter
physics that are intractable with traditional approaches.
</p>
</div>
</dd>
<dt><a name="item784">[784]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01161" title="Abstract">arXiv:2309.01161</a> (cross-list from math.OC) [<a href="/pdf/2309.01161" title="Download PDF">pdf</a>, <a href="/format/2309.01161" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Probabilistic Reduced-Dimensional Vector Autoregressive Modeling for  Dynamics Prediction and Reconstruction with Oblique Projections
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Mo%2C+Y">Yanfang Mo</a>, 
<a href="/search/math?searchtype=author&query=Yu%2C+J">Jiaxin Yu</a>, 
<a href="/search/math?searchtype=author&query=Qin%2C+S+J">S. Joe Qin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Systems and Control (eess.SY); Methodology (stat.ME)

</div>
<p class="mathjax">In this paper, we propose a probabilistic reduced-dimensional vector
autoregressive (PredVAR) model with oblique projections. This model partitions
the measurement space into a dynamic subspace and a static subspace that do not
need to be orthogonal. The partition allows us to apply an oblique projection
to extract dynamic latent variables (DLVs) from high-dimensional data with
maximized predictability. We develop an alternating iterative PredVAR algorithm
that exploits the interaction between updating the latent VAR dynamics and
estimating the oblique projection, using expectation maximization (EM) and a
statistical constraint. In addition, the noise covariance matrices are
estimated as a natural outcome of the EM method. A simulation case study of the
nonlinear Lorenz oscillation system illustrates the advantages of the proposed
approach over two alternatives.
</p>
</div>
</dd>
<dt><a name="item785">[785]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01164" title="Abstract">arXiv:2309.01164</a> (cross-list from eess.AS) [<a href="/pdf/2309.01164" title="Download PDF">pdf</a>, <a href="/format/2309.01164" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Noise robust speech emotion recognition with signal-to-noise ratio  adapting speech enhancement
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Chen%2C+Y">Yu-Wen Chen</a>, 
<a href="/search/eess?searchtype=author&query=Hirschberg%2C+J">Julia Hirschberg</a>, 
<a href="/search/eess?searchtype=author&query=Tsao%2C+Y">Yu Tsao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Machine Learning (cs.LG); Sound (cs.SD)

</div>
<p class="mathjax">Speech emotion recognition (SER) often experiences reduced performance due to
background noise. In addition, making a prediction on signals with only
background noise could undermine user trust in the system. In this study, we
propose a Noise Robust Speech Emotion Recognition system, NRSER. NRSER employs
speech enhancement (SE) to effectively reduce the noise in input signals. Then,
the signal-to-noise-ratio (SNR)-level detection structure and waveform
reconstitution strategy are introduced to reduce the negative impact of SE on
speech signals with no or little background noise. Our experimental results
show that NRSER can effectively improve the noise robustness of the SER system,
including preventing the system from making emotion recognition on signals
consisting solely of background noise. Moreover, the proposed SNR-level
detection structure can be used individually for tasks such as data selection.
</p>
</div>
</dd>
<dt><a name="item786">[786]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01167" title="Abstract">arXiv:2309.01167</a> (cross-list from physics.comp-ph) [<a href="/pdf/2309.01167" title="Download PDF">pdf</a>, <a href="/format/2309.01167" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Symbolically integrating tensor networks over various random tensors --  the second version of Python RTNI
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Fukuda%2C+M">Motohisa Fukuda</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> RTNI2 is at <a href="https://github.com/MotohisaFukuda/RTNI2">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Physics (physics.comp-ph)</span>; Strongly Correlated Electrons (cond-mat.str-el); Machine Learning (cs.LG); High Energy Physics - Theory (hep-th); Mathematical Physics (math-ph)

</div>
<p class="mathjax">We are upgrading the Python-version of RTNI, which symbolically integrates
tensor networks over the Haar-distributed unitary matrices. Now, RTNI2 can
treat the Haar-distributed orthogonal matrices and the real and complex normal
Gaussian tensors as well. Moreover, it can export tensor networks in the format
of TensorNetwork so that one can make further calculations with concrete
tensors, even for low dimensions, where the Weingarten functions differ from
the ones for high dimensions. The tutorial notebooks are found at GitHub:
https://github.com/MotohisaFukuda/RTNI2. In this paper, we explain maths behind
the program and show what kind of tensor network calculations can be made with
it. For the former, we interpret the element-wise moment calculus of the above
random matrices and tensors in terms of tensor network diagrams, and argue that
the view is natural, relating delta functions in the calculus to edges in
tensor network diagrams.
</p>
</div>
</dd>
<dt><a name="item787">[787]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01168" title="Abstract">arXiv:2309.01168</a> (cross-list from physics.flu-dyn) [<a href="/pdf/2309.01168" title="Download PDF">pdf</a>, <a href="/format/2309.01168" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Noise Measurement of a Wind Turbine using Thick Blades with Blunt  Trailing Edge
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Xue%2C+W">Weicheng Xue</a>, 
<a href="/search/physics?searchtype=author&query=Yang%2C+B">Bing Yang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Fluid Dynamics (physics.flu-dyn)</span>; Systems and Control (eess.SY)

</div>
<p class="mathjax">The noise generated by wind turbines can potentially cause significant harm
to the ecological environment and the living conditions of residents.
Therefore, a proper assessment of wind turbine noise is crucial. The IEC
61400-11 standard provides standardized guidelines for measuring turbine noise,
facilitating the comparison of noise characteristics among different wind
turbine models. This work aims to conduct a comprehensive noise measurement of
a 100kW wind turbine using thick blades with blunt trailing edge, which differs
from the typical turbines studied previously. The work takes into account the
unique design and dynamic characteristics of small-scale wind turbines and
adjusts the measurement accordingly, with deviations from the IEC standards
will be explicitly addressed.
</p>
</div>
</dd>
<dt><a name="item788">[788]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01171" title="Abstract">arXiv:2309.01171</a> (cross-list from eess.IV) [<a href="/pdf/2309.01171" title="Download PDF">pdf</a>, <a href="/format/2309.01171" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deep Unfolding Convolutional Dictionary Model for Multi-Contrast MRI  Super-resolution and Reconstruction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Lei%2C+P">Pengcheng Lei</a>, 
<a href="/search/eess?searchtype=author&query=Fang%2C+F">Faming Fang</a>, 
<a href="/search/eess?searchtype=author&query=Zhang%2C+G">Guixu Zhang</a>, 
<a href="/search/eess?searchtype=author&query=Xu%2C+M">Ming Xu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to IJCAI2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Magnetic resonance imaging (MRI) tasks often involve multiple contrasts.
Recently, numerous deep learning-based multi-contrast MRI super-resolution (SR)
and reconstruction methods have been proposed to explore the complementary
information from the multi-contrast images. However, these methods either
construct parameter-sharing networks or manually design fusion rules, failing
to accurately model the correlations between multi-contrast images and lacking
certain interpretations. In this paper, we propose a multi-contrast
convolutional dictionary (MC-CDic) model under the guidance of the optimization
algorithm with a well-designed data fidelity term. Specifically, we bulid an
observation model for the multi-contrast MR images to explicitly model the
multi-contrast images as common features and unique features. In this way, only
the useful information in the reference image can be transferred to the target
image, while the inconsistent information will be ignored. We employ the
proximal gradient algorithm to optimize the model and unroll the iterative
steps into a deep CDic model. Especially, the proximal operators are replaced
by learnable ResNet. In addition, multi-scale dictionaries are introduced to
further improve the model performance. We test our MC-CDic model on
multi-contrast MRI SR and reconstruction tasks. Experimental results
demonstrate the superior performance of the proposed MC-CDic model against
existing SOTA methods. Code is available at
https://github.com/lpcccc-cv/MC-CDic.
</p>
</div>
</dd>
<dt><a name="item789">[789]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01201" title="Abstract">arXiv:2309.01201</a> (cross-list from math.OC) [<a href="/pdf/2309.01201" title="Download PDF">pdf</a>, <a href="/format/2309.01201" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Distributed robust optimization for multi-agent systems with guaranteed  finite-time convergence
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Wu%2C+X">Xunhao Wu</a>, 
<a href="/search/math?searchtype=author&query=Fu%2C+J">Jun Fu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted for publication in Automatica
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Multiagent Systems (cs.MA); Systems and Control (eess.SY)

</div>
<p class="mathjax">A novel distributed algorithm is proposed for finite-time converging to a
feasible consensus solution satisfying global optimality to a certain accuracy
of the distributed robust convex optimization problem (DRCO) subject to bounded
uncertainty under a uniformly strongly connected network. Firstly, a
distributed lower bounding procedure is developed, which is based on an outer
iterative approximation of the DRCO through the discretization of the compact
uncertainty set into a finite number of points. Secondly, a distributed upper
bounding procedure is proposed, which is based on iteratively approximating the
DRCO by restricting the constraints right-hand side with a proper positive
parameter and enforcing the compact uncertainty set at finitely many points.
The lower and upper bounds of the global optimal objective for the DRCO are
obtained from these two procedures. Thirdly, two distributed termination
methods are proposed to make all agents stop updating simultaneously by
exploring whether the gap between the upper and the lower bounds reaches a
certain accuracy. Fourthly, it is proved that all the agents finite-time
converge to a feasible consensus solution that satisfies global optimality
within a certain accuracy. Finally, a numerical case study is included to
illustrate the effectiveness of the distributed algorithm.
</p>
</div>
</dd>
<dt><a name="item790">[790]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01207" title="Abstract">arXiv:2309.01207</a> (cross-list from eess.IV) [<a href="/pdf/2309.01207" title="Download PDF">pdf</a>, <a href="/format/2309.01207" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Spectral Adversarial MixUp for Few-Shot Unsupervised Domain Adaptation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Zhang%2C+J">Jiajin Zhang</a>, 
<a href="/search/eess?searchtype=author&query=Chao%2C+H">Hanqing Chao</a>, 
<a href="/search/eess?searchtype=author&query=Dhurandhar%2C+A">Amit Dhurandhar</a>, 
<a href="/search/eess?searchtype=author&query=Chen%2C+P">Pin-Yu Chen</a>, 
<a href="/search/eess?searchtype=author&query=Tajer%2C+A">Ali Tajer</a>, 
<a href="/search/eess?searchtype=author&query=Xu%2C+Y">Yangyang Xu</a>, 
<a href="/search/eess?searchtype=author&query=Yan%2C+P">Pingkun Yan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by MICCAI 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
<p class="mathjax">Domain shift is a common problem in clinical applications, where the training
images (source domain) and the test images (target domain) are under different
distributions. Unsupervised Domain Adaptation (UDA) techniques have been
proposed to adapt models trained in the source domain to the target domain.
However, those methods require a large number of images from the target domain
for model training. In this paper, we propose a novel method for Few-Shot
Unsupervised Domain Adaptation (FSUDA), where only a limited number of
unlabeled target domain samples are available for training. To accomplish this
challenging task, first, a spectral sensitivity map is introduced to
characterize the generalization weaknesses of models in the frequency domain.
We then developed a Sensitivity-guided Spectral Adversarial MixUp (SAMix)
method to generate target-style images to effectively suppresses the model
sensitivity, which leads to improved model generalizability in the target
domain. We demonstrated the proposed method and rigorously evaluated its
performance on multiple tasks using several public datasets.
</p>
</div>
</dd>
<dt><a name="item791">[791]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01213" title="Abstract">arXiv:2309.01213</a> (cross-list from stat.ML) [<a href="/pdf/2309.01213" title="Download PDF">pdf</a>, <a href="/format/2309.01213" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Implicit regularization of deep residual networks towards neural ODEs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Marion%2C+P">Pierre Marion</a>, 
<a href="/search/stat?searchtype=author&query=Wu%2C+Y">Yu-Han Wu</a>, 
<a href="/search/stat?searchtype=author&query=Sander%2C+M+E">Michael E. Sander</a>, 
<a href="/search/stat?searchtype=author&query=Biau%2C+G">G&#xe9;rard Biau</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 40 pages, 3 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Residual neural networks are state-of-the-art deep learning models. Their
continuous-depth analog, neural ordinary differential equations (ODEs), are
also widely used. Despite their success, the link between the discrete and
continuous models still lacks a solid mathematical foundation. In this article,
we take a step in this direction by establishing an implicit regularization of
deep residual networks towards neural ODEs, for nonlinear networks trained with
gradient flow. We prove that if the network is initialized as a discretization
of a neural ODE, then such a discretization holds throughout training. Our
results are valid for a finite training time, and also as the training time
tends to infinity provided that the network satisfies a Polyak-Lojasiewicz
condition. Importantly, this condition holds for a family of residual networks
where the residuals are two-layer perceptrons with an overparameterization in
width that is only linear, and implies the convergence of gradient flow to a
global minimum. Numerical experiments illustrate our results.
</p>
</div>
</dd>
<dt><a name="item792">[792]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01235" title="Abstract">arXiv:2309.01235</a> (cross-list from eess.IV) [<a href="/pdf/2309.01235" title="Download PDF">pdf</a>, <a href="/format/2309.01235" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Generalizability and Application of the Skin Reflectance Estimate Based  on Dichromatic Separation (SREDS)
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Drahos%2C+J">Joseph Drahos</a>, 
<a href="/search/eess?searchtype=author&query=Plesh%2C+R">Richard Plesh</a>, 
<a href="/search/eess?searchtype=author&query=Bahmani%2C+K">Keivan Bahmani</a>, 
<a href="/search/eess?searchtype=author&query=Banavar%2C+M">Mahesh Banavar</a>, 
<a href="/search/eess?searchtype=author&query=Schuckers%2C+S">Stephanie Schuckers</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Face recognition (FR) systems have become widely used and readily available
in recent history. However, differential performance between certain
demographics has been identified within popular FR models. Skin tone
differences between demographics can be one of the factors contributing to the
differential performance observed in face recognition models. Skin tone metrics
provide an alternative to self-reported race labels when such labels are
lacking or completely not available e.g. large-scale face recognition datasets.
In this work, we provide a further analysis of the generalizability of the Skin
Reflectance Estimate based on Dichromatic Separation (SREDS) against other skin
tone metrics and provide a use case for substituting race labels for SREDS
scores in a privacy-preserving learning solution. Our findings suggest that
SREDS consistently creates a skin tone metric with lower variability within
each subject and SREDS values can be utilized as an alternative to the
self-reported race labels at minimal drop in performance. Finally, we provide a
publicly available and open-source implementation of SREDS to help the research
community. Available at https://github.com/JosephDrahos/SREDS
</p>
</div>
</dd>
<dt><a name="item793">[793]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01271" title="Abstract">arXiv:2309.01271</a> (cross-list from cond-mat.mtrl-sci) [<a href="/pdf/2309.01271" title="Download PDF">pdf</a>, <a href="/format/2309.01271" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Bayesian inference of composition-dependent phase diagrams
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cond-mat?searchtype=author&query=Miryashkin%2C+T">Timofei Miryashkin</a>, 
<a href="/search/cond-mat?searchtype=author&query=Klimanova%2C+O">Olga Klimanova</a>, 
<a href="/search/cond-mat?searchtype=author&query=Ladygin%2C+V">Vladimir Ladygin</a>, 
<a href="/search/cond-mat?searchtype=author&query=Shapeev%2C+A">Alexander Shapeev</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Materials Science (cond-mat.mtrl-sci)</span>; Artificial Intelligence (cs.AI); Computational Physics (physics.comp-ph)

</div>
<p class="mathjax">Phase diagrams serve as a highly informative tool for materials design,
encapsulating information about the phases that a material can manifest under
specific conditions. In this work, we develop a method in which Bayesian
inference is employed to combine thermodynamic data from molecular dynamics
(MD), melting point simulations, and phonon calculations, process these data,
and yield a temperature-concentration phase diagram. The employed Bayesian
framework yields us not only the free energies of different phases as functions
of temperature and concentration but also the uncertainties of these free
energies originating from statistical errors inherent to finite-length MD
trajectories. Furthermore, it extrapolates the results of the finite-atom
calculations to the infinite-atom limit and facilitates the choice of
temperature, chemical potentials, and the number of atoms conducting the next
simulation with which will be the most efficient in reducing the uncertainty of
the phase diagram. The developed algorithm was successfully tested on two
binary systems, Ge-Si and K-Na, in the full range of concentrations and
temperatures.
</p>
</div>
</dd>
<dt><a name="item794">[794]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01312" title="Abstract">arXiv:2309.01312</a> (cross-list from eess.IV) [<a href="/pdf/2309.01312" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Enhancing Automated and Early Detection of Alzheimer&#x27;s Disease Using  Out-Of-Distribution Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Paleczny%2C+A">Audrey Paleczny</a>, 
<a href="/search/eess?searchtype=author&query=Parab%2C+S">Shubham Parab</a>, 
<a href="/search/eess?searchtype=author&query=Zhang%2C+M">Maxwell Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 8 figures, 3 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
<p class="mathjax">More than 10.7% of people aged 65 and older are affected by Alzheimer's
disease. Early diagnosis and treatment are crucial as most Alzheimer's patients
are unaware of having it until the effects become detrimental. AI has been
known to use magnetic resonance imaging (MRI) to diagnose Alzheimer's. However,
models which produce low rates of false diagnoses are critical to prevent
unnecessary treatments. Thus, we trained supervised Random Forest models with
segmented brain volumes and Convolutional Neural Network (CNN) outputs to
classify different Alzheimer's stages. We then applied out-of-distribution
(OOD) detection to the CNN model, enabling it to report OOD if
misclassification is likely, thereby reducing false diagnoses. With an accuracy
of 98% for detection and 95% for classification, our model based on CNN results
outperformed our segmented volume model, which had detection and classification
accuracies of 93% and 87%, respectively. Applying OOD detection to the CNN
model enabled it to flag brain tumor images as OOD with 96% accuracy and
minimal overall accuracy reduction. By using OOD detection to enhance the
reliability of MRI classification using CNNs, we lowered the rate of false
positives and eliminated a significant disadvantage of using Machine Learning
models for healthcare tasks. Source code available upon request.
</p>
</div>
</dd>
<dt><a name="item795">[795]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01319" title="Abstract">arXiv:2309.01319</a> (cross-list from eess.SP) [<a href="/pdf/2309.01319" title="Download PDF">pdf</a>, <a href="/format/2309.01319" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An ML-assisted OTFS vs. OFDM adaptable modem
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Ahmed%2C+I+Z">I. Zakir Ahmed</a>, 
<a href="/search/eess?searchtype=author&query=Sadjadpour%2C+H+R">Hamid R. Sadjadpour</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">The Orthogonal-Time-Frequency-Space (OTFS) signaling is known to be resilient
to doubly-dispersive channels, which impacts high mobility scenarios. On the
other hand, the Orthogonal-Frequency-Division-Multiplexing (OFDM) waveforms
enjoy the benefits of the reuse of legacy architectures, simplicity of receiver
design, and low-complexity detection. Several studies that compare the
performance of OFDM and OTFS have indicated mixed outcomes due to the plethora
of system parameters at play beyond high-mobility conditions. In this work, we
exemplify this observation using simulations and propose a deep neural network
(DNN)-based adaptation scheme to switch between using either an OTFS or OFDM
signal processing chain at the transmitter and receiver for optimal
mean-squared-error (MSE) performance. The DNN classifier is trained to switch
between the two schemes by observing the channel condition, received SNR, and
modulation format. We compare the performance of the OTFS, OFDM, and the
proposed switched-waveform scheme. The simulations indicate superior
performance with the proposed scheme with a well-trained DNN, thus improving
the MSE performance of the communication significantly.
</p>
</div>
</dd>
<dt><a name="item796">[796]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01322" title="Abstract">arXiv:2309.01322</a> (cross-list from eess.IV) [<a href="/pdf/2309.01322" title="Download PDF">pdf</a>, <a href="/format/2309.01322" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FAU-Net: An Attention U-Net Extension with Feature Pyramid Attention for  Prostate Cancer Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Quihui-Rubio%2C+P+C">Pablo Cesar Quihui-Rubio</a>, 
<a href="/search/eess?searchtype=author&query=Flores-Araiza%2C+D">Daniel Flores-Araiza</a>, 
<a href="/search/eess?searchtype=author&query=Gonzalez-Mendoza%2C+M">Miguel Gonzalez-Mendoza</a>, 
<a href="/search/eess?searchtype=author&query=Mata%2C+C">Christian Mata</a>, 
<a href="/search/eess?searchtype=author&query=Ochoa-Ruiz%2C+G">Gilberto Ochoa-Ruiz</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This paper has been accepted at the 22nd Mexican International Conference on Artificial Intelligence (MICAI 2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">This contribution presents a deep learning method for the segmentation of
prostate zones in MRI images based on U-Net using additive and feature pyramid
attention modules, which can improve the workflow of prostate cancer detection
and diagnosis. The proposed model is compared to seven different U-Net-based
architectures. The automatic segmentation performance of each model of the
central zone (CZ), peripheral zone (PZ), transition zone (TZ) and Tumor were
evaluated using Dice Score (DSC), and the Intersection over Union (IoU)
metrics. The proposed alternative achieved a mean DSC of 84.15% and IoU of
76.9% in the test set, outperforming most of the studied models in this work
except from R2U-Net and attention R2U-Net architectures.
</p>
</div>
</dd>
<dt><a name="item797">[797]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01345" title="Abstract">arXiv:2309.01345</a> (cross-list from eess.SP) [<a href="/pdf/2309.01345" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fault Point Detection for Recovery Planning of Resilient Grid
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Yoshiuchi%2C+H">Hideya Yoshiuchi</a>, 
<a href="/search/eess?searchtype=author&query=Takaaki%2C+H">Haruna Takaaki</a>, 
<a href="/search/eess?searchtype=author&query=Bembde%2C+S">Swapnil Bembde</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Numerical Analysis (math.NA)

</div>
<p class="mathjax">Large-scale meteorological disasters are increasing around the world, and
power outage damage by natural disaster such as typhoons and earthquakes is
increasing in Japan as well. Corresponding to the need of reduction of economic
losses due to power outages, we are promoting research of resilient grids that
minimizes power outage duration. In this report, we propose PACEM (Poles-Aware
moving Cost Estimation Method) for determining travel costs between failure
points based on the tilt angle and direction of electric poles obtained from
pole-mounted sensors and road condition data. Evaluation result shows that the
total recovery time can be reduced by 28% in the target area.
</p>
</div>
</dd>
<dt><a name="item798">[798]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01363" title="Abstract">arXiv:2309.01363</a> (cross-list from quant-ph) [<a href="/pdf/2309.01363" title="Download PDF">pdf</a>, <a href="/format/2309.01363" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Mutual Information Maximizing Quantum Generative Adversarial Network and  Its Applications in Finance
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Lee%2C+M">Mingyu Lee</a>, 
<a href="/search/quant-ph?searchtype=author&query=Shin%2C+M">Myeongjin Shin</a>, 
<a href="/search/quant-ph?searchtype=author&query=Lee%2C+J">Junseo Lee</a>, 
<a href="/search/quant-ph?searchtype=author&query=Jeong%2C+K">Kabgyun Jeong</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 15 pages, 15 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Machine Learning (cs.LG); Portfolio Management (q-fin.PM)

</div>
<p class="mathjax">One of the most promising applications in the era of NISQ (Noisy
Intermediate-Scale Quantum) computing is quantum machine learning. Quantum
machine learning offers significant quantum advantages over classical machine
learning across various domains. Specifically, generative adversarial networks
have been recognized for their potential utility in diverse fields such as
image generation, finance, and probability distribution modeling. However,
these networks necessitate solutions for inherent challenges like mode
collapse. In this study, we capitalize on the concept that the estimation of
mutual information between high-dimensional continuous random variables can be
achieved through gradient descent using neural networks. We introduce a novel
approach named InfoQGAN, which employs the Mutual Information Neural Estimator
(MINE) within the framework of quantum generative adversarial networks to
tackle the mode collapse issue. Furthermore, we elaborate on how this approach
can be applied to a financial scenario, specifically addressing the problem of
generating portfolio return distributions through dynamic asset allocation.
This illustrates the potential practical applicability of InfoQGAN in
real-world contexts.
</p>
</div>
</dd>
<dt><a name="item799">[799]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01384" title="Abstract">arXiv:2309.01384</a> (cross-list from q-bio.QM) [<a href="/pdf/2309.01384" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deep Learning Approach for Large-Scale, Real-Time Quantification of  Green Fluorescent Protein-Labeled Biological Samples in Microreactors
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-bio?searchtype=author&query=Wei%2C+Y">Yuanyuan Wei</a>, 
<a href="/search/q-bio?searchtype=author&query=Abaxi%2C+S+M+D">Sai Mu Dalike Abaxi</a>, 
<a href="/search/q-bio?searchtype=author&query=Mehmood%2C+N">Nawaz Mehmood</a>, 
<a href="/search/q-bio?searchtype=author&query=Li%2C+L">Luoquan Li</a>, 
<a href="/search/q-bio?searchtype=author&query=Qu%2C+F">Fuyang Qu</a>, 
<a href="/search/q-bio?searchtype=author&query=Cheng%2C+G">Guangyao Cheng</a>, 
<a href="/search/q-bio?searchtype=author&query=Hu%2C+D">Dehua Hu</a>, 
<a href="/search/q-bio?searchtype=author&query=Ho%2C+Y">Yi-Ping Ho</a>, 
<a href="/search/q-bio?searchtype=author&query=Yuan%2C+S+W">Scott Wu Yuan</a>, 
<a href="/search/q-bio?searchtype=author&query=Ho%2C+H">Ho-Pui Ho</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 23 pages, 6 figures, 1 table
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantitative Methods (q-bio.QM)</span>; Image and Video Processing (eess.IV); Systems and Control (eess.SY)

</div>
<p class="mathjax">Absolute quantification of biological samples entails determining expression
levels in precise numerical copies, offering enhanced accuracy and superior
performance for rare templates. However, existing methodologies suffer from
significant limitations: flow cytometers are both costly and intricate, while
fluorescence imaging relying on software tools or manual counting is
time-consuming and prone to inaccuracies. In this study, we have devised a
comprehensive deep-learning-enabled pipeline that enables the automated
segmentation and classification of GFP (green fluorescent protein)-labeled
microreactors, facilitating real-time absolute quantification. Our findings
demonstrate the efficacy of this technique in accurately predicting the sizes
and occupancy status of microreactors using standard laboratory fluorescence
microscopes, thereby providing precise measurements of template concentrations.
Notably, our approach exhibits an analysis speed of quantifying over 2,000
microreactors (across 10 images) within remarkably 2.5 seconds, and a dynamic
range spanning from 56.52 to 1569.43 copies per micron-liter. Furthermore, our
Deep-dGFP algorithm showcases remarkable generalization capabilities, as it can
be directly applied to various GFP-labeling scenarios, including droplet-based,
microwell-based, and agarose-based biological applications. To the best of our
knowledge, this represents the first successful implementation of an all-in-one
image analysis algorithm in droplet digital PCR (polymerase chain reaction),
microwell digital PCR, droplet single-cell sequencing, agarose digital PCR, and
bacterial quantification, without necessitating any transfer learning steps,
modifications, or retraining procedures. We firmly believe that our Deep-dGFP
technique will be readily embraced by biomedical laboratories and holds
potential for further development in related clinical applications.
</p>
</div>
</dd>
<dt><a name="item800">[800]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01412" title="Abstract">arXiv:2309.01412</a> (cross-list from math.OC) [<a href="/pdf/2309.01412" title="Download PDF">pdf</a>, <a href="/ps/2309.01412" title="Download PostScript">ps</a>, <a href="/format/2309.01412" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Finite/fixed-time Stabilization of Linear Systems with States  Quantization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Zhou%2C+Y">Yu Zhou</a>, 
<a href="/search/math?searchtype=author&query=Polyakov%2C+A">Andrey Polyakov</a>, 
<a href="/search/math?searchtype=author&query=Zheng%2C+G">Gang Zheng</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Systems and Control (eess.SY)

</div>
<p class="mathjax">This paper develops a homogeneity-based approach to finite/fixed-time
stabilization of linear time-invariant (LTI) system with quantized
measurements. A sufficient condition for finite/fixed-time stabilization of
multi-input LTI system under states quantization is derived. It is shown that a
homogeneous quantized state feedback with logarithmic quantizer can guarantee
finite/fixed-time stability of the closed-loop system provided that the
quantization is sufficiently dense. Theoretical results are supported with
numerical simulations.
</p>
</div>
</dd>
<dt><a name="item801">[801]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01415" title="Abstract">arXiv:2309.01415</a> (cross-list from physics.soc-ph) [<a href="/pdf/2309.01415" title="Download PDF">pdf</a>, <a href="/format/2309.01415" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A generalized vector-field framework for mobility
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Liu%2C+E">Erjian Liu</a>, 
<a href="/search/physics?searchtype=author&query=Mazzoli%2C+M">Mattia Mazzoli</a>, 
<a href="/search/physics?searchtype=author&query=Yan%2C+X">Xiao-Yong Yan</a>, 
<a href="/search/physics?searchtype=author&query=Ramasco%2C+J+J">Jose J. Ramasco</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, 8 figures, Appendices
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Physics and Society (physics.soc-ph)</span>; Computers and Society (cs.CY)

</div>
<p class="mathjax">Trip flow between areas is a fundamental metric for human mobility research.
Given its identification with travel demand and its relevance for
transportation and urban planning, many models have been developed for its
estimation. These models focus on flow intensity, disregarding the information
provided by the local mobility orientation. A field-theoretic approach can
overcome this issue and handling both intensity and direction at once. Here we
propose a general vector-field representation starting from individuals'
trajectories valid for any type of mobility. By introducing four models of
spatial exploration, we show how individuals' elections determine the
mesoscopic properties of the mobility field. Distance optimization in long
displacements and random-like local exploration are necessary to reproduce
empirical field features observed in Chinese logistic data and in New York City
Foursquare check-ins. Our framework is an essential tool to capture hidden
symmetries in mesoscopic urban mobility, it establishes a benchmark to test the
validity of mobility models and opens the doors to the use of field theory in a
wide spectrum of applications.
</p>
</div>
</dd>
<dt><a name="item802">[802]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01424" title="Abstract">arXiv:2309.01424</a> (cross-list from astro-ph.EP) [<a href="/pdf/2309.01424" title="Download PDF">pdf</a>, <a href="/format/2309.01424" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Expanding Mars Climate Modeling: Interpretable Machine Learning for  Modeling MSL Relative Humidity
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/astro-ph?searchtype=author&query=Abdelmoneim%2C+N">Nour Abdelmoneim</a>, 
<a href="/search/astro-ph?searchtype=author&query=Dhuri%2C+D+B">Dattaraj B. Dhuri</a>, 
<a href="/search/astro-ph?searchtype=author&query=Atri%2C+D">Dimitra Atri</a>, 
<a href="/search/astro-ph?searchtype=author&query=Mart%C3%ADnez%2C+G">Germ&#xe1;n Mart&#xed;nez</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, 7 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Earth and Planetary Astrophysics (astro-ph.EP)</span>; Instrumentation and Methods for Astrophysics (astro-ph.IM); Machine Learning (cs.LG)

</div>
<p class="mathjax">For the past several decades, numerous attempts have been made to model the
climate of Mars with extensive studies focusing on the planet's dynamics and
the understanding of its climate. While physical modeling and data assimilation
approaches have made significant progress, uncertainties persist in
comprehensively capturing and modeling the complexities of Martian climate. In
this work, we propose a novel approach to Martian climate modeling by
leveraging machine learning techniques that have shown remarkable success in
Earth climate modeling. Our study presents a deep neural network designed to
accurately model relative humidity in Gale Crater, as measured by NASA's Mars
Science Laboratory ``Curiosity'' rover. By utilizing simulated meteorological
variables produced by the Mars Planetary Climate Model, a robust Global
Circulation Model, our model accurately predicts relative humidity with a mean
error of 3\% and an $R^2$ score of 0.92. Furthermore, we present an approach to
predict quantile ranges of relative humidity, catering to applications that
require a range of values. To address the challenge of interpretability
associated with machine learning models, we utilize an interpretable model
architecture and conduct an in-depth analysis of its internal mechanisms and
decision making processes. We find that our neural network can effectively
model relative humidity at Gale crater using a few meteorological variables,
with the monthly mean surface H$_2$O layer, planetary boundary layer height,
convective wind speed, and solar zenith angle being the primary contributors to
the model predictions. In addition to providing a fast and efficient method to
modeling climate variables on Mars, this modeling approach can also be used to
expand on current datasets by filling spatial and temporal gaps in
observations.
</p>
</div>
</dd>
<dt><a name="item803">[803]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01482" title="Abstract">arXiv:2309.01482</a> (cross-list from math.CO) [<a href="/pdf/2309.01482" title="Download PDF">pdf</a>, <a href="/ps/2309.01482" title="Download PostScript">ps</a>, <a href="/format/2309.01482" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Thick Forests
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Dyer%2C+M">Martin Dyer</a>, 
<a href="/search/math?searchtype=author&query=M%C3%BCller%2C+H">Haiko M&#xfc;ller</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 40 pages, 19 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Combinatorics (math.CO)</span>; Discrete Mathematics (cs.DM)

</div>
<p class="mathjax">We consider classes of graphs, which we call thick graphs, that have their
vertices replaced by cliques and their edges replaced by bipartite graphs. In
particular, we consider the case of thick forests, which are a subclass of
perfect graphs. We show that this class can be recognised in polynomial time,
and examine the complexity of counting independent sets and colourings for
graphs in the class. We consider some extensions of our results to thick graphs
beyond thick forests.
</p>
</div>
</dd>
<dt><a name="item804">[804]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01513" title="Abstract">arXiv:2309.01513</a> (cross-list from eess.AS) [<a href="/pdf/2309.01513" title="Download PDF">pdf</a>, <a href="/format/2309.01513" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> RGI-Net: 3D Room Geometry Inference from Room Impulse Responses in the  Absence of First-order Echoes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Yeon%2C+I">Inmo Yeon</a>, 
<a href="/search/eess?searchtype=author&query=Choi%2C+J">Jung-Woo Choi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages, 3 figures, 3 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Artificial Intelligence (cs.AI); Sound (cs.SD)

</div>
<p class="mathjax">Room geometry is important prior information for implementing realistic 3D
audio rendering. For this reason, various room geometry inference (RGI) methods
have been developed by utilizing the time of arrival (TOA) or time difference
of arrival (TDOA) information in room impulse responses. However, the
conventional RGI technique poses several assumptions, such as convex room
shapes, the number of walls known in priori, and the visibility of first-order
reflections. In this work, we introduce the deep neural network (DNN), RGI-Net,
which can estimate room geometries without the aforementioned assumptions.
RGI-Net learns and exploits complex relationships between high-order
reflections in room impulse responses (RIRs) and, thus, can estimate room
shapes even when the shape is non-convex or first-order reflections are missing
in the RIRs. The network takes RIRs measured from a compact audio device
equipped with a circular microphone array and a single loudspeaker, which
greatly improves its practical applicability. RGI-Net includes the evaluation
network that separately evaluates the presence probability of walls, so the
geometry inference is possible without prior knowledge of the number of walls.
</p>
</div>
</dd>
<dt><a name="item805">[805]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01535" title="Abstract">arXiv:2309.01535</a> (cross-list from eess.AS) [<a href="/pdf/2309.01535" title="Download PDF">pdf</a>, <a href="/format/2309.01535" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Single-Channel Speech Enhancement with Deep Complex U-Networks and  Probabilistic Latent Space Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Nustede%2C+E+J">Eike J. Nustede</a>, 
<a href="/search/eess?searchtype=author&query=Anem%C3%BCller%2C+J">J&#xf6;rn Anem&#xfc;ller</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> ICASSP 2023 - 2023 IEEE International Conference on Acoustics,
  Speech and Signal Processing (ICASSP), Rhodes Island, Greece, 2023, pp. 1-5
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Sound (cs.SD)

</div>
<p class="mathjax">In this paper, we propose to extend the deep, complex U-Network architecture
for speech enhancement by incorporating a probabilistic (i.e., variational)
latent space model. The proposed model is evaluated against several ablated
versions of itself in order to study the effects of the variational latent
space model, complex-value processing, and self-attention. Evaluation on the
MS-DNS 2020 and Voicebank+Demand datasets yields consistently high performance.
E.g., the proposed model achieves an SI-SDR of up to 20.2 dB, about 0.5 to 1.4
dB higher than its ablated version without probabilistic latent space, 2-2.4 dB
higher than WaveUNet, and 6.7 dB above PHASEN. Compared to real-valued
magnitude spectrogram processing with a variational U-Net, the complex U-Net
achieves an improvement of up to 4.5 dB SI-SDR. Complex spectrum encoding as
magnitude and phase yields best performance in anechoic conditions whereas real
and imaginary part representation results in better generalization to (novel)
reverberation conditions, possibly due to the underlying physics of sound.
</p>
</div>
</dd>
<dt><a name="item806">[806]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01592" title="Abstract">arXiv:2309.01592</a> (cross-list from stat.ML) [<a href="/pdf/2309.01592" title="Download PDF">pdf</a>, <a href="/format/2309.01592" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Les Houches Lectures on Deep Learning at Large &amp; Infinite Width
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Bahri%2C+Y">Yasaman Bahri</a>, 
<a href="/search/stat?searchtype=author&query=Hanin%2C+B">Boris Hanin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); High Energy Physics - Theory (hep-th); Probability (math.PR)

</div>
<p class="mathjax">These lectures, presented at the 2022 Les Houches Summer School on
Statistical Physics and Machine Learning, focus on the infinite-width limit and
large-width regime of deep neural networks. Topics covered include various
statistical and dynamical properties of these networks. In particular, the
lecturers discuss properties of random deep neural networks; connections
between trained deep neural networks, linear models, kernels, and Gaussian
processes that arise in the infinite-width limit; and perturbative and
non-perturbative treatments of large but finite-width networks, at
initialization and after training.
</p>
</div>
</dd>
<dt><a name="item807">[807]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01615" title="Abstract">arXiv:2309.01615</a> (cross-list from eess.SP) [<a href="/pdf/2309.01615" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A balanced Memristor-CMOS ternary logic family and its application
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Wang%2C+X">Xiao-Yuan Wang</a>, 
<a href="/search/eess?searchtype=author&query=Zhou%2C+J">Jia-Wei Zhou</a>, 
<a href="/search/eess?searchtype=author&query=Dong%2C+C">Chuan-Tao Dong</a>, 
<a href="/search/eess?searchtype=author&query=Chen%2C+X">Xin-Hui Chen</a>, 
<a href="/search/eess?searchtype=author&query=Nandi%2C+S+K">Sanjoy Kumar Nandi</a>, 
<a href="/search/eess?searchtype=author&query=Elliman%2C+R+G">Robert G. Elliman</a>, 
<a href="/search/eess?searchtype=author&query=Kang%2C+S">Sung-Mo Kang</a>, 
<a href="/search/eess?searchtype=author&query=Iu%2C+H+H">Herbert Ho-Ching Iu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 15 pages, 30 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Emerging Technologies (cs.ET)

</div>
<p class="mathjax">The design of balanced ternary digital logic circuits based on memristors and
conventional CMOS devices is proposed. First, balanced ternary minimum gate
TMIN, maximum gate TMAX and ternary inverters are systematically designed and
verified by simulation, and then logic circuits such as ternary encoders,
decoders and multiplexers are designed on this basis. Two different schemes are
then used to realize the design of functional combinational logic circuits such
as a balanced ternary half adder, multiplier, and numerical comparator.
Finally, we report a series of comparisons and analyses of the two design
schemes, which provide a reference for subsequent research and development of
three-valued logic circuits.
</p>
</div>
</dd>
<dt><a name="item808">[808]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01628" title="Abstract">arXiv:2309.01628</a> (cross-list from math.OC) [<a href="/pdf/2309.01628" title="Download PDF">pdf</a>, <a href="/ps/2309.01628" title="Download PostScript">ps</a>, <a href="/format/2309.01628" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Bowen&#x27;s equations for invariance pressure of control systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Yang%2C+R">Rui Yang</a>, 
<a href="/search/math?searchtype=author&query=Chen%2C+E">Ercai Chen</a>, 
<a href="/search/math?searchtype=author&query=Yang%2C+J">Jiao Yang</a>, 
<a href="/search/math?searchtype=author&query=Zhou%2C+X">Xiaoyao Zhou</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 23pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Information Theory (cs.IT); Dynamical Systems (math.DS)

</div>
<p class="mathjax">We aim to establish Bowen's equations for upper capacity invariance pressure
and Pesin-Pitskel invariance pressure of discrete-time control systems. We
first introduce a new invariance pressure called induced invariance pressure on
partitions that specializes the upper capacity invariance pressure on
partitions, and then show that the two types of invariance pressures are
related by a Bowen's equation. Besides, to establish Bowen's equation for
Pesin-Pitskel invariance pressure on partitions we also introduce a new notion
called BS invariance dimension on subsets. Moreover, a variational principle
for BS invariance dimension on subsets is established.
</p>
</div>
</dd>
<dt><a name="item809">[809]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01657" title="Abstract">arXiv:2309.01657</a> (cross-list from stat.ML) [<a href="/pdf/2309.01657" title="Download PDF">pdf</a>, <a href="/format/2309.01657" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Locally Stationary Graph Processes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Canbolat%2C+A">Abdullah Canbolat</a>, 
<a href="/search/stat?searchtype=author&query=Vural%2C+E">Elif Vural</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Stationary graph process models are commonly used in the analysis and
inference of data sets collected on irregular network topologies. While most of
the existing methods represent graph signals with a single stationary process
model that is globally valid on the entire graph, in many practical problems,
the characteristics of the process may be subject to local variations in
different regions of the graph. In this work, we propose a locally stationary
graph process (LSGP) model that aims to extend the classical concept of local
stationarity to irregular graph domains. We characterize local stationarity by
expressing the overall process as the combination of a set of component
processes such that the extent to which the process adheres to each component
varies smoothly over the graph. We propose an algorithm for computing LSGP
models from realizations of the process, and also study the approximation of
LSGPs locally with WSS processes. Experiments on signal interpolation problems
show that the proposed process model provides accurate signal representations
competitive with the state of the art.
</p>
</div>
</dd>
<dt><a name="item810">[810]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01661" title="Abstract">arXiv:2309.01661</a> (cross-list from quant-ph) [<a href="/pdf/2309.01661" title="Download PDF">pdf</a>, <a href="/format/2309.01661" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Toward a Unified Hybrid HPCQC Toolchain
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Seitz%2C+P">Philipp Seitz</a>, 
<a href="/search/quant-ph?searchtype=author&query=Elsharkawy%2C+A">Amr Elsharkawy</a>, 
<a href="/search/quant-ph?searchtype=author&query=To%2C+X+M">Xiao-Ting Michelle To</a>, 
<a href="/search/quant-ph?searchtype=author&query=Schulz%2C+M">Martin Schulz</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, 3 figures, IEEE Quantum Week 2023 WKS17 - Third International Workshop on Integrating High-Performance Computing with Quantum Computing
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Distributed, Parallel, and Cluster Computing (cs.DC)

</div>
<p class="mathjax">In the expanding field of Quantum Computing (QC), efficient and seamless
integration of QC and high performance computing (HPC) elements (e.g., quantum
hardware, classical hardware, and software infrastructure on both sides) plays
a crucial role. This paper addresses the development of a unified toolchain
designed for hybrid quantum-classical systems. Our work proposes a design for a
unified hybrid high performance computing - quantum computing (HPCQC) toolchain
that tackles pressing issues such as scalability, cross-technology execution,
and ahead-of-time (AOT) optimization.
</p>
</div>
</dd>
<dt><a name="item811">[811]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01666" title="Abstract">arXiv:2309.01666</a> (cross-list from stat.ML) [<a href="/pdf/2309.01666" title="Download PDF">pdf</a>, <a href="/ps/2309.01666" title="Download PostScript">ps</a>, <a href="/format/2309.01666" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Robust penalized least squares of depth trimmed residuals regression for  high-dimensional data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Zuo%2C+Y">Yijun Zuo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 31 pages, 6 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG); Methodology (stat.ME)

</div>
<p class="mathjax">Challenges with data in the big-data era include (i) the dimension $p$ is
often larger than the sample size $n$ (ii) outliers or contaminated points are
frequently hidden and more difficult to detect. Challenge (i) renders most
conventional methods inapplicable. Thus, it attracts tremendous attention from
statistics, computer science, and bio-medical communities. Numerous penalized
regression methods have been introduced as modern methods for analyzing
high-dimensional data. Disproportionate attention has been paid to the
challenge (ii) though. Penalized regression methods can do their job very well
and are expected to handle the challenge (ii) simultaneously. Most of them,
however, can break down by a single outlier (or single adversary contaminated
point) as revealed in this article.
<br />The latter systematically examines leading penalized regression methods in
the literature in terms of their robustness, provides quantitative assessment,
and reveals that most of them can break down by a single outlier. Consequently,
a novel robust penalized regression method based on the least sum of squares of
depth trimmed residuals is proposed and studied carefully. Experiments with
simulated and real data reveal that the newly proposed method can outperform
some leading competitors in estimation and prediction accuracy in the cases
considered.
</p>
</div>
</dd>
<dt><a name="item812">[812]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01670" title="Abstract">arXiv:2309.01670</a> (cross-list from q-bio.GN) [<a href="/pdf/2309.01670" title="Download PDF">pdf</a>, <a href="/format/2309.01670" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Blind Biological Sequence Denoising with Self-Supervised Set Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-bio?searchtype=author&query=Ng%2C+N">Nathan Ng</a>, 
<a href="/search/q-bio?searchtype=author&query=Park%2C+J+W">Ji Won Park</a>, 
<a href="/search/q-bio?searchtype=author&query=Lee%2C+J+H">Jae Hyeon Lee</a>, 
<a href="/search/q-bio?searchtype=author&query=Kelly%2C+R+L">Ryan Lewis Kelly</a>, 
<a href="/search/q-bio?searchtype=author&query=Ra%2C+S">Stephen Ra</a>, 
<a href="/search/q-bio?searchtype=author&query=Cho%2C+K">Kyunghyun Cho</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Genomics (q-bio.GN)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Biological sequence analysis relies on the ability to denoise the imprecise
output of sequencing platforms. We consider a common setting where a short
sequence is read out repeatedly using a high-throughput long-read platform to
generate multiple subreads, or noisy observations of the same sequence.
Denoising these subreads with alignment-based approaches often fails when too
few subreads are available or error rates are too high. In this paper, we
propose a novel method for blindly denoising sets of sequences without directly
observing clean source sequence labels. Our method, Self-Supervised Set
Learning (SSSL), gathers subreads together in an embedding space and estimates
a single set embedding as the midpoint of the subreads in both the latent and
sequence spaces. This set embedding represents the "average" of the subreads
and can be decoded into a prediction of the clean sequence. In experiments on
simulated long-read DNA data, SSSL methods denoise small reads of $\leq 6$
subreads with 17% fewer errors and large reads of $&gt;6$ subreads with 8% fewer
errors compared to the best baseline. On a real dataset of antibody sequences,
SSSL improves over baselines on two self-supervised metrics, with a significant
improvement on difficult small reads that comprise over 60% of the test set. By
accurately denoising these reads, SSSL promises to better realize the potential
of high-throughput DNA sequencing data for downstream scientific applications.
</p>
</div>
</dd>
<dt><a name="item813">[813]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01675" title="Abstract">arXiv:2309.01675</a> (cross-list from physics.soc-ph) [<a href="/pdf/2309.01675" title="Download PDF">pdf</a>, <a href="/format/2309.01675" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fundamental dynamics of popularity-similarity trajectories in real  networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Papaefthymiou%2C+E+S">Evangelos S. Papaefthymiou</a>, 
<a href="/search/physics?searchtype=author&query=Iordanou%2C+C">Costas Iordanou</a>, 
<a href="/search/physics?searchtype=author&query=Papadopoulos%2C+F">Fragkiskos Papadopoulos</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Physics and Society (physics.soc-ph)</span>; Social and Information Networks (cs.SI)

</div>
<p class="mathjax">Real networks are complex dynamical systems, evolving over time with the
addition and deletion of nodes and links. Currently, there exists no principled
mathematical theory for their dynamics -- a grand-challenge open problem in
complex networks. Here, we show that the popularity and similarity trajectories
of nodes in hyperbolic embeddings of different real networks manifest universal
self-similar properties with typical Hurst exponents $H \ll 0.5$. This means
that the trajectories are anti-persistent or 'mean-reverting' with short-term
memory, and they can be adequately captured by a fractional Brownian motion
process. The observed behavior can be qualitatively reproduced in synthetic
networks that possess a latent geometric space, but not in networks that lack
such space, suggesting that the observed subdiffusive dynamics are inherently
linked to the hidden geometry of real networks. These results set the
foundations for rigorous mathematical machinery for describing and predicting
real network dynamics.
</p>
</div>
</dd>
<dt><a name="item814">[814]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01740" title="Abstract">arXiv:2309.01740</a> (cross-list from eess.IV) [<a href="/pdf/2309.01740" title="Download PDF">pdf</a>, <a href="/format/2309.01740" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An Empirical Analysis for Zero-Shot Multi-Label Classification on  COVID-19 CT Scans and Uncurated Reports
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Dack%2C+E">Ethan Dack</a>, 
<a href="/search/eess?searchtype=author&query=Brigato%2C+L">Lorenzo Brigato</a>, 
<a href="/search/eess?searchtype=author&query=McMurray%2C+M">Matthew McMurray</a>, 
<a href="/search/eess?searchtype=author&query=Fontanellaz%2C+M">Matthias Fontanellaz</a>, 
<a href="/search/eess?searchtype=author&query=Frauenfelder%2C+T">Thomas Frauenfelder</a>, 
<a href="/search/eess?searchtype=author&query=Hoppe%2C+H">Hanno Hoppe</a>, 
<a href="/search/eess?searchtype=author&query=Exadaktylos%2C+A">Aristomenis Exadaktylos</a>, 
<a href="/search/eess?searchtype=author&query=Geiser%2C+T">Thomas Geiser</a>, 
<a href="/search/eess?searchtype=author&query=Funke-Chambour%2C+M">Manuela Funke-Chambour</a>, 
<a href="/search/eess?searchtype=author&query=Christe%2C+A">Andreas Christe</a>, 
<a href="/search/eess?searchtype=author&query=Ebner%2C+L">Lukas Ebner</a>, 
<a href="/search/eess?searchtype=author&query=Mougiakakou%2C+S">Stavroula Mougiakakou</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 3 figures, Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV) Workshops 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computation and Language (cs.CL); Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
<p class="mathjax">The pandemic resulted in vast repositories of unstructured data, including
radiology reports, due to increased medical examinations. Previous research on
automated diagnosis of COVID-19 primarily focuses on X-ray images, despite
their lower precision compared to computed tomography (CT) scans. In this work,
we leverage unstructured data from a hospital and harness the fine-grained
details offered by CT scans to perform zero-shot multi-label classification
based on contrastive visual language learning. In collaboration with human
experts, we investigate the effectiveness of multiple zero-shot models that aid
radiologists in detecting pulmonary embolisms and identifying intricate lung
details like ground glass opacities and consolidations. Our empirical analysis
provides an overview of the possible solutions to target such fine-grained
tasks, so far overlooked in the medical multimodal pretraining literature. Our
investigation promises future advancements in the medical image analysis
community by addressing some challenges associated with unstructured data and
fine-grained multi-label classification.
</p>
</div>
</dd>
<dt><a name="item815">[815]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01750" title="Abstract">arXiv:2309.01750</a> (cross-list from math.CO) [<a href="/pdf/2309.01750" title="Download PDF">pdf</a>, <a href="/ps/2309.01750" title="Download PostScript">ps</a>, <a href="/format/2309.01750" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the size of irredundant propagation complete CNF formulas
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Savick%C3%BD%2C+P">Petr Savick&#xfd;</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Combinatorics (math.CO)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">We investigate propagation complete (PC) CNF formulas for a symmetric
definite Horn function of $n$ variables and demonstrate that the minimum size
of these formulas is closely related to specific covering numbers, namely, to
the smallest number of $k$-subsets of an $n$-set covering all $(k-1)$-subsets
for a suitable $k$. As a consequence, we demonstrate an irredundant PC formula
whose size is larger than the size of a smallest PC formula for the same
function by a factor $\Omega(n/\ln n)$. This complements a known polynomial
upper bound on this factor.
</p>
</div>
</dd>
<dt><a name="item816">[816]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01751" title="Abstract">arXiv:2309.01751</a> (cross-list from eess.IV) [<a href="/pdf/2309.01751" title="Download PDF">pdf</a>, <a href="/format/2309.01751" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multispectral Indices for Wildfire Management
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Oliveira%2C+A">Afonso Oliveira</a>, 
<a href="/search/eess?searchtype=author&query=Matos-Carvalho%2C+J+P">Jo&#xe3;o P. Matos-Carvalho</a>, 
<a href="/search/eess?searchtype=author&query=Moutinho%2C+F">Filipe Moutinho</a>, 
<a href="/search/eess?searchtype=author&query=Fachada%2C+N">Nuno Fachada</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV); Geophysics (physics.geo-ph)

</div>
<p class="mathjax">This paper highlights and summarizes the most important multispectral indices
and associated methodologies for fire management. Various fields of study are
examined where multispectral indices align with wildfire prevention and
management, including vegetation and soil attribute extraction, water feature
mapping, artificial structure identification, and post-fire burnt area
estimation. The versatility and effectiveness of multispectral indices in
addressing specific issues in wildfire management are emphasized. Fundamental
insights for optimizing data extraction are presented. Concrete indices for
each task, including the NDVI and the NDWI, are suggested. Moreover, to enhance
accuracy and address inherent limitations of individual index applications, the
integration of complementary processing solutions and additional data sources
like high-resolution imagery and ground-based measurements is recommended. This
paper aims to be an immediate and comprehensive reference for researchers and
stakeholders working on multispectral indices related to the prevention and
management of fires.
</p>
</div>
</dd>
<dt><a name="item817">[817]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01753" title="Abstract">arXiv:2309.01753</a> (cross-list from math.OC) [<a href="/pdf/2309.01753" title="Download PDF">pdf</a>, <a href="/format/2309.01753" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On Penalty Methods for Nonconvex Bilevel Optimization and First-Order  Stochastic Approximation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Kwon%2C+J">Jeongyeol Kwon</a>, 
<a href="/search/math?searchtype=author&query=Kwon%2C+D">Dohyun Kwon</a>, 
<a href="/search/math?searchtype=author&query=Wright%2C+S">Steve Wright</a>, 
<a href="/search/math?searchtype=author&query=Nowak%2C+R">Robert Nowak</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">In this work, we study first-order algorithms for solving Bilevel
Optimization (BO) where the objective functions are smooth but possibly
nonconvex in both levels and the variables are restricted to closed convex
sets. As a first step, we study the landscape of BO through the lens of penalty
methods, in which the upper- and lower-level objectives are combined in a
weighted sum with penalty parameter $\sigma &gt; 0$. In particular, we establish a
strong connection between the penalty function and the hyper-objective by
explicitly characterizing the conditions under which the values and derivatives
of the two must be $O(\sigma)$-close. A by-product of our analysis is the
explicit formula for the gradient of hyper-objective when the lower-level
problem has multiple solutions under minimal conditions, which could be of
independent interest. Next, viewing the penalty formulation as
$O(\sigma)$-approximation of the original BO, we propose first-order algorithms
that find an $\epsilon$-stationary solution by optimizing the penalty
formulation with $\sigma = O(\epsilon)$. When the perturbed lower-level problem
uniformly satisfies the small-error proximal error-bound (EB) condition, we
propose a first-order algorithm that converges to an $\epsilon$-stationary
point of the penalty function, using in total $O(\epsilon^{-3})$ and
$O(\epsilon^{-7})$ accesses to first-order (stochastic) gradient oracles when
the oracle is deterministic and oracles are noisy, respectively. Under an
additional assumption on stochastic oracles, we show that the algorithm can be
implemented in a fully {\it single-loop} manner, i.e., with $O(1)$ samples per
iteration, and achieves the improved oracle-complexity of $O(\epsilon^{-3})$
and $O(\epsilon^{-5})$, respectively.
</p>
</div>
</dd>
<dt><a name="item818">[818]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01781" title="Abstract">arXiv:2309.01781</a> (cross-list from math.OC) [<a href="/pdf/2309.01781" title="Download PDF">pdf</a>, <a href="/format/2309.01781" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Self-concordant Smoothing for Convex Composite Optimization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Adeoye%2C+A+D">Adeyemi D. Adeoye</a>, 
<a href="/search/math?searchtype=author&query=Bemporad%2C+A">Alberto Bemporad</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 37 pages, 7 figures, 3 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">We introduce the notion of self-concordant smoothing for minimizing the sum
of two convex functions: the first is smooth and the second may be nonsmooth.
Our framework results naturally from the smoothing approximation technique
referred to as partial smoothing in which only a part of the nonsmooth function
is smoothed. The key highlight of our approach is in a natural property of the
resulting problem's structure which provides us with a variable-metric
selection method and a step-length selection rule particularly suitable for
proximal Newton-type algorithms. In addition, we efficiently handle specific
structures promoted by the nonsmooth function, such as $\ell_1$-regularization
and group-lasso penalties. We prove local quadratic convergence rates for two
resulting algorithms: Prox-N-SCORE, a proximal Newton algorithm and
Prox-GGN-SCORE, a proximal generalized Gauss-Newton (GGN) algorithm. The
Prox-GGN-SCORE algorithm highlights an important approximation procedure which
helps to significantly reduce most of the computational overhead associated
with the inverse Hessian. This approximation is essentially useful for
overparameterized machine learning models and in the mini-batch settings.
Numerical examples on both synthetic and real datasets demonstrate the
efficiency of our approach and its superiority over existing approaches.
</p>
</div>
</dd>
<dt><a name="item819">[819]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01791" title="Abstract">arXiv:2309.01791</a> (cross-list from stat.ME) [<a href="/pdf/2309.01791" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Non-transitivity of the Win Ratio and Area Under the Receiver Operating  Characteristics Curve (AUC): a case for evaluating the strength of stochastic  comparisons
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Demler%2C+O+V">Olga V. Demler</a>, 
<a href="/search/stat?searchtype=author&query=Demler%2C+I+A">Ilona A. Demler</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Methodology (stat.ME)</span>; Performance (cs.PF); Econometrics (econ.EM); Statistics Theory (math.ST); Applications (stat.AP)

</div>
<p class="mathjax">The win ratio (WR) is a novel statistic used in randomized controlled trials
that can account for hierarchies within event outcomes. In this paper we report
and study the long-run non-transitive behavior of the win ratio and the closely
related Area Under the Receiver Operating Characteristics Curve (AUC) and argue
that their transitivity cannot be taken for granted. Crucially, traditional
within-group statistics (i.e., comparison of means) are always transitive,
while the WR can detect non-transitivity. Non-transitivity provides valuable
information on the stochastic relationship between two treatment groups, which
should be tested and reported. We specify the necessary conditions for
transitivity, the sufficient conditions for non-transitivity and demonstrate
non-transitivity in a real-life large randomized controlled trial for the WR of
time-to-death. Our results can be used to rule out or evaluate possibility of
non-transitivity and show the importance of studying the strength of stochastic
relationships.
</p>
</div>
</dd>
<dt><a name="item820">[820]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01803" title="Abstract">arXiv:2309.01803</a> (cross-list from physics.ao-ph) [<a href="/pdf/2309.01803" title="Download PDF">pdf</a>, <a href="/format/2309.01803" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Importance of overnight parameters to predict Sea Breeze on Long Island
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Adaricheva%2C+K">Kira Adaricheva</a>, 
<a href="/search/physics?searchtype=author&query=Bernhardt%2C+J+E">Jase E. Bernhardt</a>, 
<a href="/search/physics?searchtype=author&query=Liu%2C+W">Wenxin Liu</a>, 
<a href="/search/physics?searchtype=author&query=Schmidt%2C+B">Briana Schmidt</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 17 Figures, 12 Tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Atmospheric and Oceanic Physics (physics.ao-ph)</span>; Logic in Computer Science (cs.LO)

</div>
<p class="mathjax">The sea breeze is a phenomenon frequently impacting Long Island, New York,
especially during the spring and early summer, when land surface temperatures
can exceed ocean temperatures considerably. The sea breeze influences daily
weather conditions by causing a shift in wind direction and speed, limiting the
maximum temperature, and occasionally serving as a trigger for precipitation
and thunderstorms. Advance prediction of the presence or absence of the sea
breeze for a certain location on a given day would therefore be beneficial to
weather forecasters. To forecast sea breeze occurrence based on the previous
night's weather conditions, we used a novel algorithm called the $D$-Basis. We
analyzed sea breeze data from a recent four year period (2017-2020) at a single
weather station several miles inland from the coast. High or constant station
pressure, high or constant dew point, and onshore wind from the previous night
were found to be strong predictors of sea breeze formation the following day.
The accuracy of the prediction was around 74\% for June 2020. Unlike other
prediction methods which involve the comparison of sea surface and land surface
temperatures in near real time, our prediction method is based on the
parameters from the prior night, allowing it to potentially aid in advanced
forecasting of the sea breeze.
</p>
</div>
</dd>
<dt><a name="item821">[821]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01823" title="Abstract">arXiv:2309.01823</a> (cross-list from eess.IV) [<a href="/pdf/2309.01823" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multi-dimension unified Swin Transformer for 3D Lesion Segmentation in  Multiple Anatomical Locations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Pan%2C+S">Shaoyan Pan</a>, 
<a href="/search/eess?searchtype=author&query=Liu%2C+Y">Yiqiao Liu</a>, 
<a href="/search/eess?searchtype=author&query=Halek%2C+S">Sarah Halek</a>, 
<a href="/search/eess?searchtype=author&query=Tomaszewski%2C+M">Michal Tomaszewski</a>, 
<a href="/search/eess?searchtype=author&query=Wang%2C+S">Shubing Wang</a>, 
<a href="/search/eess?searchtype=author&query=Baumgartner%2C+R">Richard Baumgartner</a>, 
<a href="/search/eess?searchtype=author&query=Yuan%2C+J">Jianda Yuan</a>, 
<a href="/search/eess?searchtype=author&query=Goldmacher%2C+G">Gregory Goldmacher</a>, 
<a href="/search/eess?searchtype=author&query=Chen%2C+A">Antong Chen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">In oncology research, accurate 3D segmentation of lesions from CT scans is
essential for the modeling of lesion growth kinetics. However, following the
RECIST criteria, radiologists routinely only delineate each lesion on the axial
slice showing the largest transverse area, and delineate a small number of
lesions in 3D for research purposes. As a result, we have plenty of unlabeled
3D volumes and labeled 2D images, and scarce labeled 3D volumes, which makes
training a deep-learning 3D segmentation model a challenging task. In this
work, we propose a novel model, denoted a multi-dimension unified Swin
transformer (MDU-ST), for 3D lesion segmentation. The MDU-ST consists of a
Shifted-window transformer (Swin-transformer) encoder and a convolutional
neural network (CNN) decoder, allowing it to adapt to 2D and 3D inputs and
learn the corresponding semantic information in the same encoder. Based on this
model, we introduce a three-stage framework: 1) leveraging large amount of
unlabeled 3D lesion volumes through self-supervised pretext tasks to learn the
underlying pattern of lesion anatomy in the Swin-transformer encoder; 2)
fine-tune the Swin-transformer encoder to perform 2D lesion segmentation with
2D RECIST slices to learn slice-level segmentation information; 3) further
fine-tune the Swin-transformer encoder to perform 3D lesion segmentation with
labeled 3D volumes. The network's performance is evaluated by the Dice
similarity coefficient (DSC) and Hausdorff distance (HD) using an internal 3D
lesion dataset with 593 lesions extracted from multiple anatomical locations.
The proposed MDU-ST demonstrates significant improvement over the competing
models. The proposed method can be used to conduct automated 3D lesion
segmentation to assist radiomics and tumor growth modeling studies. This paper
has been accepted by the IEEE International Symposium on Biomedical Imaging
(ISBI) 2023.
</p>
</div>
</dd>
<dt><a name="item822">[822]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01829" title="Abstract">arXiv:2309.01829</a> (cross-list from quant-ph) [<a href="/pdf/2309.01829" title="Download PDF">pdf</a>, <a href="/format/2309.01829" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Soft-Dropout: A Practical Approach for Mitigating Overfitting in Quantum  Convolutional Neural Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Shinde%2C+A+R">Aakash Ravindra Shinde</a>, 
<a href="/search/quant-ph?searchtype=author&query=Jain%2C+C">Charu Jain</a>, 
<a href="/search/quant-ph?searchtype=author&query=Kalev%2C+A">Amir Kalev</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages, 14 images, 6 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Quantum convolutional neural network (QCNN), an early application for quantum
computers in the NISQ era, has been consistently proven successful as a machine
learning (ML) algorithm for several tasks with significant accuracy. Derived
from its classical counterpart, QCNN is prone to overfitting. Overfitting is a
typical shortcoming of ML models that are trained too closely to the availed
training dataset and perform relatively poorly on unseen datasets for a similar
problem. In this work we study the adaptation of one of the most successful
overfitting mitigation method, knows as the (post-training) dropout method, to
the quantum setting. We find that a straightforward implementation of this
method in the quantum setting leads to a significant and undesirable
consequence: a substantial decrease in success probability of the QCNN. We
argue that this effect exposes the crucial role of entanglement in QCNNs and
the vulnerability of QCNNs to entanglement loss. To handle overfitting, we
proposed a softer version of the dropout method. We find that the proposed
method allows us to handle successfully overfitting in the test cases.
</p>
</div>
</dd>
<dt><a name="item823">[823]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01840" title="Abstract">arXiv:2309.01840</a> (cross-list from math.PR) [<a href="/pdf/2309.01840" title="Download PDF">pdf</a>, <a href="/format/2309.01840" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Minimum entropy of a log-concave variable for fixed variance
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Melbourne%2C+J">James Melbourne</a>, 
<a href="/search/math?searchtype=author&query=Nayar%2C+P">Piotr Nayar</a>, 
<a href="/search/math?searchtype=author&query=Roberto%2C+C">Cyril Roberto</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Probability (math.PR)</span>; Information Theory (cs.IT)

</div>
<p class="mathjax">We show that for log-concave real random variables with fixed variance the
Shannon differential entropy is minimized for an exponential random variable.
We apply this result to derive upper bounds on capacities of additive noise
channels with log-concave noise. We also improve constants in the reverse
entropy power inequalities for log-concave random variables.
</p>
</div>
</dd>
<dt><a name="item824">[824]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01865" title="Abstract">arXiv:2309.01865</a> (cross-list from eess.IV) [<a href="/pdf/2309.01865" title="Download PDF">pdf</a>, <a href="/format/2309.01865" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> BigFUSE: Global Context-Aware Image Fusion in Dual-View Light-Sheet  Fluorescence Microscopy with Image Formation Prior
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Liu%2C+Y">Yu Liu</a>, 
<a href="/search/eess?searchtype=author&query=Muller%2C+G">Gesine Muller</a>, 
<a href="/search/eess?searchtype=author&query=Navab%2C+N">Nassir Navab</a>, 
<a href="/search/eess?searchtype=author&query=Marr%2C+C">Carsten Marr</a>, 
<a href="/search/eess?searchtype=author&query=Huisken%2C+J">Jan Huisken</a>, 
<a href="/search/eess?searchtype=author&query=Peng%2C+T">Tingying Peng</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> paper in MICCAI 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Light-sheet fluorescence microscopy (LSFM), a planar illumination technique
that enables high-resolution imaging of samples, experiences defocused image
quality caused by light scattering when photons propagate through thick
tissues. To circumvent this issue, dualview imaging is helpful. It allows
various sections of the specimen to be scanned ideally by viewing the sample
from opposing orientations. Recent image fusion approaches can then be applied
to determine in-focus pixels by comparing image qualities of two views locally
and thus yield spatially inconsistent focus measures due to their limited
field-of-view. Here, we propose BigFUSE, a global context-aware image fuser
that stabilizes image fusion in LSFM by considering the global impact of photon
propagation in the specimen while determining focus-defocus based on local
image qualities. Inspired by the image formation prior in dual-view LSFM, image
fusion is considered as estimating a focus-defocus boundary using Bayes
Theorem, where (i) the effect of light scattering onto focus measures is
included within Likelihood; and (ii) the spatial consistency regarding
focus-defocus is imposed in Prior. The expectation-maximum algorithm is then
adopted to estimate the focus-defocus boundary. Competitive experimental
results show that BigFUSE is the first dual-view LSFM fuser that is able to
exclude structured artifacts when fusing information, highlighting its
abilities of automatic image fusion.
</p>
</div>
</dd>
<dt><a name="item825">[825]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01869" title="Abstract">arXiv:2309.01869</a> (cross-list from math.CO) [<a href="/pdf/2309.01869" title="Download PDF">pdf</a>, <a href="/format/2309.01869" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Three Tree Theorem
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Knill%2C+O">Oliver Knill</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 17 pages, 3 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Combinatorics (math.CO)</span>; Discrete Mathematics (cs.DM)

</div>
<p class="mathjax">We prove that every 2-sphere graph different from a prism can be vertex
4-colored in such a way that all Kempe chains are forests. This implies the
following three tree theorem: the arboricity of a discrete 2-sphere is 3.
Moreover, the three trees can be chosen so that each hits every triangle. A
consequence is a result of an exercise in the book of Bondy and Murty based on
work of A. Frank, A. Gyarfas and C. Nash-Williams: the arboricity of a planar
graph is less or equal than 3.
</p>
</div>
</dd>
<dt><a name="item826">[826]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01885" title="Abstract">arXiv:2309.01885</a> (cross-list from stat.ML) [<a href="/pdf/2309.01885" title="Download PDF">pdf</a>, <a href="/format/2309.01885" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> QuantEase: Optimization-based Quantization for Language Models -- An  Efficient and Intuitive Algorithm
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Behdin%2C+K">Kayhan Behdin</a>, 
<a href="/search/stat?searchtype=author&query=Acharya%2C+A">Ayan Acharya</a>, 
<a href="/search/stat?searchtype=author&query=Gupta%2C+A">Aman Gupta</a>, 
<a href="/search/stat?searchtype=author&query=Keerthi%2C+S">Sathiya Keerthi</a>, 
<a href="/search/stat?searchtype=author&query=Mazumder%2C+R">Rahul Mazumder</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Computation and Language (cs.CL); Machine Learning (cs.LG)

</div>
<p class="mathjax">With the rising popularity of Large Language Models (LLMs), there has been an
increasing interest in compression techniques that enable their efficient
deployment. This study focuses on the Post-Training Quantization (PTQ) of LLMs.
Drawing from recent advances, our work introduces QuantEase, a layer-wise
quantization framework where individual layers undergo separate quantization.
The problem is framed as a discrete-structured non-convex optimization,
prompting the development of algorithms rooted in Coordinate Descent (CD)
techniques. These CD-based methods provide high-quality solutions to the
complex non-convex layer-wise quantization problems. Notably, our CD-based
approach features straightforward updates, relying solely on matrix and vector
operations, circumventing the need for matrix inversion or decomposition. We
also explore an outlier-aware variant of our approach, allowing for retaining
significant weights (outliers) with complete precision. Our proposal attains
state-of-the-art performance in terms of perplexity and zero-shot accuracy in
empirical evaluations across various LLMs and datasets, with relative
improvements up to 15% over methods such as GPTQ. Particularly noteworthy is
our outlier-aware algorithm's capability to achieve near or sub-3-bit
quantization of LLMs with an acceptable drop in accuracy, obviating the need
for non-uniform quantization or grouping techniques, improving upon methods
such as SpQR by up to two times in terms of perplexity.
</p>
</div>
</dd>
<dt><a name="item827">[827]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01886" title="Abstract">arXiv:2309.01886</a> (cross-list from hep-ex) [<a href="/pdf/2309.01886" title="Download PDF">pdf</a>, <a href="/format/2309.01886" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Extended Symmetry Preserving Attention Networks for LHC Analysis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/hep-ex?searchtype=author&query=Fenton%2C+M+J">Michael James Fenton</a>, 
<a href="/search/hep-ex?searchtype=author&query=Shmakov%2C+A">Alexander Shmakov</a>, 
<a href="/search/hep-ex?searchtype=author&query=Okawa%2C+H">Hideki Okawa</a>, 
<a href="/search/hep-ex?searchtype=author&query=Li%2C+Y">Yuji Li</a>, 
<a href="/search/hep-ex?searchtype=author&query=Hsiao%2C+K">Ko-Yang Hsiao</a>, 
<a href="/search/hep-ex?searchtype=author&query=Hsu%2C+S">Shih-Chieh Hsu</a>, 
<a href="/search/hep-ex?searchtype=author&query=Whiteson%2C+D">Daniel Whiteson</a>, 
<a href="/search/hep-ex?searchtype=author&query=Baldi%2C+P">Pierre Baldi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">High Energy Physics - Experiment (hep-ex)</span>; Machine Learning (cs.LG); High Energy Physics - Phenomenology (hep-ph)

</div>
<p class="mathjax">Reconstructing unstable heavy particles requires sophisticated techniques to
sift through the large number of possible permutations for assignment of
detector objects to partons. An approach based on a generalized attention
mechanism, symmetry preserving attention networks (SPANet), has been previously
applied to top quark pair decays at the Large Hadron Collider, which produce
six hadronic jets. Here we extend the SPANet architecture to consider multiple
input streams, such as leptons, as well as global event features, such as the
missing transverse momentum. In addition, we provide regression and
classification outputs to supplement the parton assignment. We explore the
performance of the extended capability of SPANet in the context of
semi-leptonic decays of top quark pairs as well as top quark pairs produced in
association with a Higgs boson. We find significant improvements in the power
of three representative studies: search for ttH, measurement of the top quark
mass and a search for a heavy Z' decaying to top quark pairs. We present
ablation studies to provide insight on what the network has learned in each
case.
</p>
</div>
</dd>
<dt><a name="item828">[828]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01941" title="Abstract">arXiv:2309.01941</a> (cross-list from q-bio.NC) [<a href="/pdf/2309.01941" title="Download PDF">pdf</a>, <a href="/format/2309.01941" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Dynamic Brain Transformer with Multi-level Attention for Functional  Brain Network Analysis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-bio?searchtype=author&query=Kan%2C+X">Xuan Kan</a>, 
<a href="/search/q-bio?searchtype=author&query=Gu%2C+A+A+C">Antonio Aodong Chen Gu</a>, 
<a href="/search/q-bio?searchtype=author&query=Cui%2C+H">Hejie Cui</a>, 
<a href="/search/q-bio?searchtype=author&query=Guo%2C+Y">Ying Guo</a>, 
<a href="/search/q-bio?searchtype=author&query=Yang%2C+C">Carl Yang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to IEEE BHI 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neurons and Cognition (q-bio.NC)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Recent neuroimaging studies have highlighted the importance of
network-centric brain analysis, particularly with functional magnetic resonance
imaging. The emergence of Deep Neural Networks has fostered a substantial
interest in predicting clinical outcomes and categorizing individuals based on
brain networks. However, the conventional approach involving static brain
network analysis offers limited potential in capturing the dynamism of brain
function. Although recent studies have attempted to harness dynamic brain
networks, their high dimensionality and complexity present substantial
challenges. This paper proposes a novel methodology, Dynamic bRAin Transformer
(DART), which combines static and dynamic brain networks for more effective and
nuanced brain function analysis. Our model uses the static brain network as a
baseline, integrating dynamic brain networks to enhance performance against
traditional methods. We innovatively employ attention mechanisms, enhancing
model explainability and exploiting the dynamic brain network's temporal
variations. The proposed approach offers a robust solution to the low
signal-to-noise ratio of blood-oxygen-level-dependent signals, a recurring
issue in direct DNN modeling. It also provides valuable insights into which
brain circuits or dynamic networks contribute more to final predictions. As
such, DRAT shows a promising direction in neuroimaging studies, contributing to
the comprehensive understanding of brain organization and the role of neural
circuits.
</p>
</div>
</dd>
<dt><a name="item829">[829]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01984" title="Abstract">arXiv:2309.01984</a> (cross-list from physics.optics) [<a href="/pdf/2309.01984" title="Download PDF">pdf</a>, <a href="/format/2309.01984" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Focal Surface Projection: Extending Projector Depth-of-Field Using a  Phase-Only Spatial Light Modulator
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Ueda%2C+F">Fumitaka Ueda</a>, 
<a href="/search/physics?searchtype=author&query=Kageyama%2C+Y">Yuta Kageyama</a>, 
<a href="/search/physics?searchtype=author&query=Iwai%2C+D">Daisuke Iwai</a>, 
<a href="/search/physics?searchtype=author&query=Sato%2C+K">Kosuke Sato</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optics (physics.optics)</span>; Graphics (cs.GR)

</div>
<p class="mathjax">We present a focal surface projection to solve the narrow depth-of-field
problem in projection mapping applications. We apply a phase-only spatial light
modulator to realize nonuniform focusing distances, whereby the projected
contents appear focused on a surface with considerable depth variations. The
feasibility of the proposed technique was validated through a physical
experiment.
</p>
</div>
</dd>
<dt><a name="item830">[830]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01995" title="Abstract">arXiv:2309.01995</a> (cross-list from physics.optics) [<a href="/pdf/2309.01995" title="Download PDF">pdf</a>, <a href="/format/2309.01995" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Photonic Structures Optimization Using Highly Data-Efficient Deep  Learning: Application To Nanofin And Annular Groove Phase Masks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Roy%2C+N">Nicolas Roy</a>, 
<a href="/search/physics?searchtype=author&query=K%C3%B6nig%2C+L">Lorenzo K&#xf6;nig</a>, 
<a href="/search/physics?searchtype=author&query=Absil%2C+O">Olivier Absil</a>, 
<a href="/search/physics?searchtype=author&query=Beauthier%2C+C">Charlotte Beauthier</a>, 
<a href="/search/physics?searchtype=author&query=Mayer%2C+A">Alexandre Mayer</a>, 
<a href="/search/physics?searchtype=author&query=Lobet%2C+M">Micha&#xeb;l Lobet</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optics (physics.optics)</span>; Mesoscale and Nanoscale Physics (cond-mat.mes-hall); Artificial Intelligence (cs.AI); Space Physics (physics.space-ph)

</div>
<p class="mathjax">Metasurfaces offer a flexible framework for the manipulation of light
properties in the realm of thin film optics. Specifically, the polarization of
light can be effectively controlled through the use of thin phase plates. This
study aims to introduce a surrogate optimization framework for these devices.
The framework is applied to develop two kinds of vortex phase masks (VPMs)
tailored for application in astronomical high-contrast imaging. Computational
intelligence techniques are exploited to optimize the geometric features of
these devices. The large design space and computational limitations necessitate
the use of surrogate models like partial least squares Kriging, radial basis
functions, or neural networks. However, we demonstrate the inadequacy of these
methods in modeling the performance of VPMs. To address the shortcomings of
these methods, a data-efficient evolutionary optimization setup using a deep
neural network as a highly accurate and efficient surrogate model is proposed.
The optimization process in this study employs a robust particle swarm
evolutionary optimization scheme, which operates on explicit geometric
parameters of the photonic device. Through this approach, optimal designs are
developed for two design candidates. In the most complex case, evolutionary
optimization enables optimization of the design that would otherwise be
impractical (requiring too much simulations). In both cases, the surrogate
model improves the reliability and efficiency of the procedure, effectively
reducing the required number of simulations by up to 75% compared to
conventional optimization techniques.
</p>
</div>
</dd>
<dt><a name="item831">[831]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.02003" title="Abstract">arXiv:2309.02003</a> (cross-list from eess.SP) [<a href="/pdf/2309.02003" title="Download PDF">pdf</a>, <a href="/ps/2309.02003" title="Download PostScript">ps</a>, <a href="/format/2309.02003" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Bayesian Phase Search for Probabilistic Amplitude Shaping
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Askari%2C+M+T">Mohammad Taha Askari</a>, 
<a href="/search/eess?searchtype=author&query=Lampe%2C+L">Lutz Lampe</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 4 pages, 2 figures. Submitted to the 49th European Conference on Optical Communications
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Information Theory (cs.IT)

</div>
<p class="mathjax">We introduce a Bayesian carrier phase recovery (CPR) algorithm which is
robust against low signal-to-noise ratio scenarios. It is therefore effective
for phase recovery for probabilistic amplitude shaping (PAS). Results validate
that the new algorithm overcomes the degradation experienced by blind
phase-search CPR for PAS.
</p>
</div>
</dd>
<dt><a name="item832">[832]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.02007" title="Abstract">arXiv:2309.02007</a> (cross-list from eess.IV) [<a href="/pdf/2309.02007" title="Download PDF">pdf</a>, <a href="/format/2309.02007" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Logarithmic Mathematical Morphology: theory and applications
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Noyel%2C+G">Guillaume Noyel</a> (LHC)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV); Functional Analysis (math.FA); Numerical Analysis (math.NA)

</div>
<p class="mathjax">Classically, in Mathematical Morphology, an image (i.e., a grey-level
function) is analysed by another image which is named the structuring element
or the structuring function. This structuring function is moved over the image
domain and summed to the image. However, in an image presenting lighting
variations, the analysis by a structuring function should require that its
amplitude varies according to the image intensity. Such a property is not
verified in Mathematical Morphology for grey level functions, when the
structuring function is summed to the image with the usual additive law. In
order to address this issue, a new framework is defined with an additive law
for which the amplitude of the structuring function varies according to the
image amplitude. This additive law is chosen within the Logarithmic Image
Processing framework and models the lighting variations with a physical cause
such as a change of light intensity or a change of camera exposure-time. The
new framework is named Logarithmic Mathematical Morphology (LMM) and allows the
definition of operators which are robust to such lighting variations. In images
with uniform lighting variations, those new LMM operators perform better than
usual morphological operators. In eye-fundus images with non-uniform lighting
variations, a LMM method for vessel segmentation is compared to three
state-of-the-art approaches. Results show that the LMM approach has a better
robustness to such variations than the three others.
</p>
</div>
</dd>
<dt><a name="item833">[833]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.02014" title="Abstract">arXiv:2309.02014</a> (cross-list from math.OC) [<a href="/pdf/2309.02014" title="Download PDF">pdf</a>, <a href="/format/2309.02014" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PROMISE: Preconditioned Stochastic Optimization Methods by Incorporating  Scalable Curvature Estimates
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Frangella%2C+Z">Zachary Frangella</a>, 
<a href="/search/math?searchtype=author&query=Rathore%2C+P">Pratik Rathore</a>, 
<a href="/search/math?searchtype=author&query=Zhao%2C+S">Shipu Zhao</a>, 
<a href="/search/math?searchtype=author&query=Udell%2C+M">Madeleine Udell</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 127 pages, 31 Figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">This paper introduces PROMISE ($\textbf{Pr}$econditioned Stochastic
$\textbf{O}$ptimization $\textbf{M}$ethods by $\textbf{I}$ncorporating
$\textbf{S}$calable Curvature $\textbf{E}$stimates), a suite of sketching-based
preconditioned stochastic gradient algorithms for solving large-scale convex
optimization problems arising in machine learning. PROMISE includes
preconditioned versions of SVRG, SAGA, and Katyusha; each algorithm comes with
a strong theoretical analysis and effective default hyperparameter values. In
contrast, traditional stochastic gradient methods require careful
hyperparameter tuning to succeed, and degrade in the presence of
ill-conditioning, a ubiquitous phenomenon in machine learning. Empirically, we
verify the superiority of the proposed algorithms by showing that, using
default hyperparameter values, they outperform or match popular tuned
stochastic gradient optimizers on a test bed of $51$ ridge and logistic
regression problems assembled from benchmark machine learning repositories. On
the theoretical side, this paper introduces the notion of quadratic regularity
in order to establish linear convergence of all proposed methods even when the
preconditioner is updated infrequently. The speed of linear convergence is
determined by the quadratic regularity ratio, which often provides a tighter
bound on the convergence rate compared to the condition number, both in theory
and in practice, and explains the fast global linear convergence of the
proposed methods.
</p>
</div>
</dd>
<dt><a name="item834">[834]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.02020" title="Abstract">arXiv:2309.02020</a> (cross-list from eess.IV) [<a href="/pdf/2309.02020" title="Download PDF">pdf</a>, <a href="/format/2309.02020" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> RawHDR: High Dynamic Range Image Reconstruction from a Single Raw Image
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Zou%2C+Y">Yunhao Zou</a>, 
<a href="/search/eess?searchtype=author&query=Yan%2C+C">Chenggang Yan</a>, 
<a href="/search/eess?searchtype=author&query=Fu%2C+Y">Ying Fu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ICCV 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">High dynamic range (HDR) images capture much more intensity levels than
standard ones. Current methods predominantly generate HDR images from 8-bit low
dynamic range (LDR) sRGB images that have been degraded by the camera
processing pipeline. However, it becomes a formidable task to retrieve
extremely high dynamic range scenes from such limited bit-depth data. Unlike
existing methods, the core idea of this work is to incorporate more informative
Raw sensor data to generate HDR images, aiming to recover scene information in
hard regions (the darkest and brightest areas of an HDR scene). To this end, we
propose a model tailor-made for Raw images, harnessing the unique features of
Raw data to facilitate the Raw-to-HDR mapping. Specifically, we learn exposure
masks to separate the hard and easy regions of a high dynamic scene. Then, we
introduce two important guidances, dual intensity guidance, which guides less
informative channels with more informative ones, and global spatial guidance,
which extrapolates scene specifics over an extended spatial domain. To verify
our Raw-to-HDR approach, we collect a large Raw/HDR paired dataset for both
training and testing. Our empirical evaluations validate the superiority of the
proposed Raw-to-HDR reconstruction model, as well as our newly captured dataset
in the experiments.
</p>
</div>
</dd>
<dt><a name="item835">[835]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.02062" title="Abstract">arXiv:2309.02062</a> (cross-list from math.CO) [<a href="/pdf/2309.02062" title="Download PDF">pdf</a>, <a href="/format/2309.02062" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Boxicity and Interval-Orders: Petersen and the Complements of Line  Graphs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Caoduro%2C+M">Marco Caoduro</a>, 
<a href="/search/math?searchtype=author&query=Seb%C5%91%2C+A">Andr&#xe1;s Seb&#x151;</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 17 pages, 5 figures, appears in the Proceedings of the 31st International Symposium on Graph Drawing and Network Visualization (GD 2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Combinatorics (math.CO)</span>; Discrete Mathematics (cs.DM)

</div>
<p class="mathjax">The boxicity of a graph is the smallest dimension $d$ allowing a
representation of it as the intersection graph of a set of $d$-dimensional
axis-parallel boxes. We present a simple general approach to determining the
boxicity of a graph based on studying its ``interval-order subgraphs''.
<br />The power of the method is first tested on the boxicity of some popular
graphs that have resisted previous attempts: the boxicity of the Petersen graph
is $3$, and more generally, that of the Kneser-graphs $K(n,2)$ is $n-2$ if
$n\ge 5$, confirming a conjecture of Caoduro and Lichev [Discrete Mathematics,
Vol. 346, 5, 2023].
<br />Since every line graph is an induced subgraph of the complement of $K(n,2)$,
the developed tools show furthermore that line graphs have only a polynomial
number of edge-maximal interval-order subgraphs. This opens the way to
polynomial-time algorithms for problems that are in general
$\mathcal{NP}$-hard: for the existence and optimization of interval-order
subgraphs of line-graphs, or of interval-completions of their complement.
</p>
</div>
</dd>
<dt><a name="item836">[836]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.02071" title="Abstract">arXiv:2309.02071</a> (cross-list from q-bio.QM) [<a href="/pdf/2309.02071" title="Download PDF">pdf</a>, <a href="/format/2309.02071" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> BeeTLe: A Framework for Linear B-Cell Epitope Prediction and  Classification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-bio?searchtype=author&query=Yuan%2C+X">Xiao Yuan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 18 pages, 3 figures, accepted at ECML PKDD 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantitative Methods (q-bio.QM)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">The process of identifying and characterizing B-cell epitopes, which are the
portions of antigens recognized by antibodies, is important for our
understanding of the immune system, and for many applications including vaccine
development, therapeutics, and diagnostics. Computational epitope prediction is
challenging yet rewarding as it significantly reduces the time and cost of
laboratory work. Most of the existing tools do not have satisfactory
performance and only discriminate epitopes from non-epitopes. This paper
presents a new deep learning-based multi-task framework for linear B-cell
epitope prediction as well as antibody type-specific epitope classification.
Specifically, a sequenced-based neural network model using recurrent layers and
Transformer blocks is developed. We propose an amino acid encoding method based
on eigen decomposition to help the model learn the representations of epitopes.
We introduce modifications to standard cross-entropy loss functions by
extending a logit adjustment technique to cope with the class imbalance.
Experimental results on data curated from the largest public epitope database
demonstrate the validity of the proposed methods and the superior performance
compared to competing ones.
</p>
</div>
</dd>
<dt><a name="item837">[837]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.02072" title="Abstract">arXiv:2309.02072</a> (cross-list from econ.EM) [<a href="/pdf/2309.02072" title="Download PDF">pdf</a>, <a href="/ps/2309.02072" title="Download PostScript">ps</a>, <a href="/format/2309.02072" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DeepVol: A Deep Transfer Learning Approach for Universal Asset  Volatility Modeling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/econ?searchtype=author&query=Liu%2C+C">Chen Liu</a>, 
<a href="/search/econ?searchtype=author&query=Tran%2C+M">Minh-Ngoc Tran</a>, 
<a href="/search/econ?searchtype=author&query=Wang%2C+C">Chao Wang</a>, 
<a href="/search/econ?searchtype=author&query=Gerlach%2C+R">Richard Gerlach</a>, 
<a href="/search/econ?searchtype=author&query=Kohn%2C+R">Robert Kohn</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Econometrics (econ.EM)</span>; Artificial Intelligence (cs.AI); Computational Finance (q-fin.CP)

</div>
<p class="mathjax">This paper introduces DeepVol, a promising new deep learning volatility model
that outperforms traditional econometric models in terms of model generality.
DeepVol leverages the power of transfer learning to effectively capture and
model the volatility dynamics of all financial assets, including previously
unseen ones, using a single universal model. This contrasts to the prevailing
practice in econometrics literature, which necessitates training separate
models for individual datasets. The introduction of DeepVol opens up new
avenues for volatility modeling and forecasting in the finance industry,
potentially transforming the way volatility is understood and predicted.
</p>
</div>
</dd>
<dt><a name="item838">[838]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.02082" title="Abstract">arXiv:2309.02082</a> (cross-list from math.OC) [<a href="/pdf/2309.02082" title="Download PDF">pdf</a>, <a href="/ps/2309.02082" title="Download PostScript">ps</a>, <a href="/format/2309.02082" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Backward error analysis and the qualitative behaviour of stochastic  optimization algorithms: Application to stochastic coordinate descent
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Di+Giovacchino%2C+S">Stefano Di Giovacchino</a>, 
<a href="/search/math?searchtype=author&query=Higham%2C+D+J">Desmond J. Higham</a>, 
<a href="/search/math?searchtype=author&query=Zygalakis%2C+K">Konstantinos Zygalakis</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 15 pages; 3 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Numerical Analysis (math.NA); Machine Learning (stat.ML)

</div>
<p class="mathjax">Stochastic optimization methods have been hugely successful in making
large-scale optimization problems feasible when computing the full gradient is
computationally prohibitive. Using the theory of modified equations for
numerical integrators, we propose a class of stochastic differential equations
that approximate the dynamics of general stochastic optimization methods more
closely than the original gradient flow. Analyzing a modified stochastic
differential equation can reveal qualitative insights about the associated
optimization method. Here, we study mean-square stability of the modified
equation in the case of stochastic coordinate descent.
</p>
</div>
</dd>
<dt><a name="item839">[839]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.02098" title="Abstract">arXiv:2309.02098</a> (cross-list from quant-ph) [<a href="/pdf/2309.02098" title="Download PDF">pdf</a>, <a href="/format/2309.02098" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Control Architecture for Entanglement Generation Switches in Quantum  Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Gauthier%2C+S">Scarlett Gauthier</a>, 
<a href="/search/quant-ph?searchtype=author&query=Vardoyan%2C+G">Gayane Vardoyan</a>, 
<a href="/search/quant-ph?searchtype=author&query=Wehner%2C+S">Stephanie Wehner</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Networking and Internet Architecture (cs.NI)

</div>
<p class="mathjax">Entanglement between quantum network nodes is often produced using
intermediary devices - such as heralding stations - as a resource. When scaling
quantum networks to many nodes, requiring a dedicated intermediary device for
every pair of nodes introduces high costs. Here, we propose a cost-effective
architecture to connect many quantum network nodes via a central quantum
network hub called an Entanglement Generation Switch (EGS). The EGS allows
multiple quantum nodes to be connected at a fixed resource cost, by sharing the
resources needed to make entanglement. We propose an algorithm called the Rate
Control Protocol (RCP) which moderates the level of competition for access to
the hub's resources between sets of users. We proceed to prove a convergence
theorem for rates yielded by the algorithm. To derive the algorithm we work in
the framework of Network Utility Maximization (NUM) and make use of the theory
of Lagrange multipliers and Lagrangian duality. Our EGS architecture lays the
groundwork for developing control architectures compatible with other types of
quantum network hubs as well as system models of greater complexity.
</p>
</div>
</dd>
<dt><a name="item840">[840]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.02110" title="Abstract">arXiv:2309.02110</a> (cross-list from math.HO) [<a href="/pdf/2309.02110" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Wordle: A Microcosm of Life. Luck, Skill, Cheating, Loyalty, and  Influence!
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Dilger%2C+J+P">James P. Dilger</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">History and Overview (math.HO)</span>; Computation and Language (cs.CL)

</div>
<p class="mathjax">Wordle is a popular, online word game offered by the New York Times
(nytimes.com). Currently there are some 2 million players of the English
version worldwide. Players have 6 attempts to guess the daily word (target
word) and after each attempt, the player receives color-coded information about
the correctness and position of each letter in the guess. After either a
successful completion of the puzzle or the final unsuccessful attempt, software
can assess the player's luck and skill using Information Theory and can display
data for the first, second, ..., sixth guesses of a random sample of all
players. Recently, I discovered that the latter data is presented in a format
that can easily be copied and pasted into a spreadsheet. I compiled data on
Wordle players' first guesses from May 2023 - August 2023 and inferred some
interesting information about Wordle players. A) Every day, about 0.2-0.5% of
players solve the puzzle in one attempt. Because the odds of guessing the one
of 2,315 possible target words at random is 0.043%, this implies that 4,000 -
10,000 players cheat by obtaining the target word outside of playing the game!
B) At least 1/3 of the players have a favorite starting word, or cycle through
several. And even though players should be aware that target words are never
repeated, most players appear to remain loyal to their starting word even after
its appearance as a target word. C) On August 15, 2023, about 30,000 players
abruptly changed their starting word, presumably based on a crossword puzzle
clue! Wordle players can be influenced! This study goes beyond social media
postings, surveys, and Google Trends to provide solid, quantitative evidence
about cheating in Wordle.
</p>
</div>
</dd>
<dt><a name="item841">[841]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.02140" title="Abstract">arXiv:2309.02140</a> (cross-list from eess.IV) [<a href="/pdf/2309.02140" title="Download PDF">pdf</a>, <a href="/format/2309.02140" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Lightweight, Rapid and Efficient Deep Convolutional Network for Chest  X-Ray Tuberculosis Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Capell%C3%A1n-Mart%C3%ADn%2C+D">Daniel Capell&#xe1;n-Mart&#xed;n</a>, 
<a href="/search/eess?searchtype=author&query=G%C3%B3mez-Valverde%2C+J+J">Juan J. G&#xf3;mez-Valverde</a>, 
<a href="/search/eess?searchtype=author&query=Bermejo-Pel%C3%A1ez%2C+D">David Bermejo-Pel&#xe1;ez</a>, 
<a href="/search/eess?searchtype=author&query=Ledesma-Carbayo%2C+M+J">Mar&#xed;a J. Ledesma-Carbayo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages, 3 figures, 3 tables. This paper has been accepted at ISBI 2023
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> 2023 IEEE 20th International Symposium on Biomedical Imaging
  (ISBI), Cartagena, Colombia, 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
<p class="mathjax">Tuberculosis (TB) is still recognized as one of the leading causes of death
worldwide. Recent advances in deep learning (DL) have shown to enhance
radiologists' ability to interpret chest X-ray (CXR) images accurately and with
fewer errors, leading to a better diagnosis of this disease. However, little
work has been done to develop models capable of diagnosing TB that offer good
performance while being efficient, fast and computationally inexpensive. In
this work, we propose LightTBNet, a novel lightweight, fast and efficient deep
convolutional network specially customized to detect TB from CXR images. Using
a total of 800 frontal CXR images from two publicly available datasets, our
solution yielded an accuracy, F1 and area under the ROC curve (AUC) of 0.906,
0.907 and 0.961, respectively, on an independent test subset. The proposed
model demonstrates outstanding performance while delivering a rapid prediction,
with minimal computational and memory requirements, making it highly suitable
for deployment in handheld devices that can be used in low-resource areas with
high TB prevalence. Code publicly available at
https://github.com/dani-capellan/LightTBNet.
</p>
</div>
</dd>
<dt><a name="item842">[842]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.02147" title="Abstract">arXiv:2309.02147</a> (cross-list from eess.IV) [<a href="/pdf/2309.02147" title="Download PDF">pdf</a>, <a href="/format/2309.02147" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> INCEPTNET: Precise And Early Disease Detection Application For Medical  Images Analyses
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Sajedi%2C+A">Amirhossein Sajedi</a>, 
<a href="/search/eess?searchtype=author&query=Fadaeieslam%2C+M+J">Mohammad Javad Fadaeieslam</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">In view of the recent paradigm shift in deep AI based image processing
methods, medical image processing has advanced considerably. In this study, we
propose a novel deep neural network (DNN), entitled InceptNet, in the scope of
medical image processing, for early disease detection and segmentation of
medical images in order to enhance precision and performance. We also
investigate the interaction of users with the InceptNet application to present
a comprehensive application including the background processes, and foreground
interactions with users. Fast InceptNet is shaped by the prominent Unet
architecture, and it seizes the power of an Inception module to be fast and
cost effective while aiming to approximate an optimal local sparse structure.
Adding Inception modules with various parallel kernel sizes can improve the
network's ability to capture the variations in the scaled regions of interest.
To experiment, the model is tested on four benchmark datasets, including retina
blood vessel segmentation, lung nodule segmentation, skin lesion segmentation,
and breast cancer cell detection. The improvement was more significant on
images with small scale structures. The proposed method improved the accuracy
from 0.9531, 0.8900, 0.9872, and 0.9881 to 0.9555, 0.9510, 0.9945, and 0.9945
on the mentioned datasets, respectively, which show outperforming of the
proposed method over the previous works. Furthermore, by exploring the
procedure from start to end, individuals who have utilized a trial edition of
InceptNet, in the form of a complete application, are presented with thirteen
multiple choice questions in order to assess the proposed method. The outcomes
are evaluated through the means of Human Computer Interaction.
</p>
</div>
</dd>
<dt><a name="item843">[843]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.02179" title="Abstract">arXiv:2309.02179</a> (cross-list from eess.IV) [<a href="/pdf/2309.02179" title="Download PDF">pdf</a>, <a href="/format/2309.02179" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> High-resolution 3D Maps of Left Atrial Displacements using an  Unsupervised Image Registration Neural Network
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Galazis%2C+C">Christoforos Galazis</a>, 
<a href="/search/eess?searchtype=author&query=Bharath%2C+A+A">Anil Anthony Bharath</a>, 
<a href="/search/eess?searchtype=author&query=Varela%2C+M">Marta Varela</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Medical Imaging with Deep Learning, short paper track, 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Functional analysis of the left atrium (LA) plays an increasingly important
role in the prognosis and diagnosis of cardiovascular diseases.
Echocardiography-based measurements of LA dimensions and strains are useful
biomarkers, but they provide an incomplete picture of atrial deformations.
High-resolution dynamic magnetic resonance images (Cine MRI) offer the
opportunity to examine LA motion and deformation in 3D, at higher spatial
resolution and with full LA coverage. However, there are no dedicated tools to
automatically characterise LA motion in 3D. Thus, we propose a tool that
automatically segments the LA and extracts the displacement fields across the
cardiac cycle. The pipeline is able to accurately track the LA wall across the
cardiac cycle with an average Hausdorff distance of $2.51 \pm 1.3~mm$ and Dice
score of $0.96 \pm 0.02$.
</p>
</div>
</dd>
<dt><a name="item844">[844]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.02195" title="Abstract">arXiv:2309.02195</a> (cross-list from stat.ML) [<a href="/pdf/2309.02195" title="Download PDF">pdf</a>, <a href="/ps/2309.02195" title="Download PostScript">ps</a>, <a href="/format/2309.02195" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Sparse Function-space Representation of Neural Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Scannell%2C+A">Aidan Scannell</a>, 
<a href="/search/stat?searchtype=author&query=Mereu%2C+R">Riccardo Mereu</a>, 
<a href="/search/stat?searchtype=author&query=Chang%2C+P">Paul Chang</a>, 
<a href="/search/stat?searchtype=author&query=Tamir%2C+E">Ella Tamir</a>, 
<a href="/search/stat?searchtype=author&query=Pajarinen%2C+J">Joni Pajarinen</a>, 
<a href="/search/stat?searchtype=author&query=Solin%2C+A">Arno Solin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to ICML 2023 Workshop on Duality for Modern Machine Learning, Honolulu, Hawaii, USA. 4 pages, 2 figures, 1 table
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Deep neural networks (NNs) are known to lack uncertainty estimates and
struggle to incorporate new data. We present a method that mitigates these
issues by converting NNs from weight space to function space, via a dual
parameterization. Importantly, the dual parameterization enables us to
formulate a sparse representation that captures information from the entire
data set. This offers a compact and principled way of capturing uncertainty and
enables us to incorporate new data without retraining whilst retaining
predictive performance. We provide proof-of-concept demonstrations with the
proposed approach for quantifying uncertainty in supervised learning on UCI
benchmark tasks.
</p>
</div>
</dd>
<dt><a name="item845">[845]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.02202" title="Abstract">arXiv:2309.02202</a> (cross-list from stat.ML) [<a href="/pdf/2309.02202" title="Download PDF">pdf</a>, <a href="/format/2309.02202" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the Complexity of Differentially Private Best-Arm Identification with  Fixed Confidence
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Azize%2C+A">Achraf Azize</a>, 
<a href="/search/stat?searchtype=author&query=Jourdan%2C+M">Marc Jourdan</a>, 
<a href="/search/stat?searchtype=author&query=Marjani%2C+A+A">Aymen Al Marjani</a>, 
<a href="/search/stat?searchtype=author&query=Basu%2C+D">Debabrota Basu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Cryptography and Security (cs.CR); Machine Learning (cs.LG); Statistics Theory (math.ST)

</div>
<p class="mathjax">Best Arm Identification (BAI) problems are progressively used for
data-sensitive applications, such as designing adaptive clinical trials, tuning
hyper-parameters, and conducting user studies to name a few. Motivated by the
data privacy concerns invoked by these applications, we study the problem of
BAI with fixed confidence under $\epsilon$-global Differential Privacy (DP).
First, to quantify the cost of privacy, we derive a lower bound on the sample
complexity of any $\delta$-correct BAI algorithm satisfying $\epsilon$-global
DP. Our lower bound suggests the existence of two privacy regimes depending on
the privacy budget $\epsilon$. In the high-privacy regime (small $\epsilon$),
the hardness depends on a coupled effect of privacy and a novel
information-theoretic quantity, called the Total Variation Characteristic Time.
In the low-privacy regime (large $\epsilon$), the sample complexity lower bound
reduces to the classical non-private lower bound. Second, we propose AdaP-TT,
an $\epsilon$-global DP variant of the Top Two algorithm. AdaP-TT runs in
arm-dependent adaptive episodes and adds Laplace noise to ensure a good
privacy-utility trade-off. We derive an asymptotic upper bound on the sample
complexity of AdaP-TT that matches with the lower bound up to multiplicative
constants in the high-privacy regime. Finally, we provide an experimental
analysis of AdaP-TT that validates our theoretical results.
</p>
</div>
</dd>
<dt><a name="item846">[846]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.02211" title="Abstract">arXiv:2309.02211</a> (cross-list from stat.ML) [<a href="/pdf/2309.02211" title="Download PDF">pdf</a>, <a href="/format/2309.02211" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Distributionally Robust Machine Learning with Multi-source Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Wang%2C+Z">Zhenyu Wang</a>, 
<a href="/search/stat?searchtype=author&query=B%C3%BChlmann%2C+P">Peter B&#xfc;hlmann</a>, 
<a href="/search/stat?searchtype=author&query=Guo%2C+Z">Zijian Guo</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG); Methodology (stat.ME)

</div>
<p class="mathjax">Classical machine learning methods may lead to poor prediction performance
when the target distribution differs from the source populations. This paper
utilizes data from multiple sources and introduces a group distributionally
robust prediction model defined to optimize an adversarial reward about
explained variance with respect to a class of target distributions. Compared to
classical empirical risk minimization, the proposed robust prediction model
improves the prediction accuracy for target populations with distribution
shifts. We show that our group distributionally robust prediction model is a
weighted average of the source populations' conditional outcome models. We
leverage this key identification result to robustify arbitrary machine learning
algorithms, including, for example, random forests and neural networks. We
devise a novel bias-corrected estimator to estimate the optimal aggregation
weight for general machine-learning algorithms and demonstrate its improvement
in the convergence rate. Our proposal can be seen as a distributionally robust
federated learning approach that is computationally efficient and easy to
implement using arbitrary machine learning base algorithms, satisfies some
privacy constraints, and has a nice interpretation of different sources'
importance for predicting a given target covariate distribution. We demonstrate
the performance of our proposed group distributionally robust method on
simulated and real data with random forests and neural networks as
base-learning algorithms.
</p>
</div>
</dd>
<dt><a name="item847">[847]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.02265" title="Abstract">arXiv:2309.02265</a> (cross-list from eess.AS) [<a href="/pdf/2309.02265" title="Download PDF">pdf</a>, <a href="/format/2309.02265" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PESTO: Pitch Estimation with Self-supervised Transposition-equivariant  Objective
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Riou%2C+A">Alain Riou</a>, 
<a href="/search/eess?searchtype=author&query=Lattner%2C+S">Stefan Lattner</a>, 
<a href="/search/eess?searchtype=author&query=Hadjeres%2C+G">Ga&#xeb;tan Hadjeres</a>, 
<a href="/search/eess?searchtype=author&query=Peeters%2C+G">Geoffroy Peeters</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Sound (cs.SD)

</div>
<p class="mathjax">In this paper, we address the problem of pitch estimation using Self
Supervised Learning (SSL). The SSL paradigm we use is equivariance to pitch
transposition, which enables our model to accurately perform pitch estimation
on monophonic audio after being trained only on a small unlabeled dataset. We
use a lightweight ($&lt;$ 30k parameters) Siamese neural network that takes as
inputs two different pitch-shifted versions of the same audio represented by
its Constant-Q Transform. To prevent the model from collapsing in an
encoder-only setting, we propose a novel class-based transposition-equivariant
objective which captures pitch information. Furthermore, we design the
architecture of our network to be transposition-preserving by introducing
learnable Toeplitz matrices.
<br />We evaluate our model for the two tasks of singing voice and musical
instrument pitch estimation and show that our model is able to generalize
across tasks and datasets while being lightweight, hence remaining compatible
with low-resource devices and suitable for real-time applications. In
particular, our results surpass self-supervised baselines and narrow the
performance gap between self-supervised and supervised methods for pitch
estimation.
</p>
</div>
</dd>
<dt><a name="item848">[848]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.02285" title="Abstract">arXiv:2309.02285</a> (cross-list from eess.AS) [<a href="/pdf/2309.02285" title="Download PDF">pdf</a>, <a href="/format/2309.02285" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PromptTTS 2: Describing and Generating Voices with Text Prompt
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Leng%2C+Y">Yichong Leng</a>, 
<a href="/search/eess?searchtype=author&query=Guo%2C+Z">Zhifang Guo</a>, 
<a href="/search/eess?searchtype=author&query=Shen%2C+K">Kai Shen</a>, 
<a href="/search/eess?searchtype=author&query=Tan%2C+X">Xu Tan</a>, 
<a href="/search/eess?searchtype=author&query=Ju%2C+Z">Zeqian Ju</a>, 
<a href="/search/eess?searchtype=author&query=Liu%2C+Y">Yanqing Liu</a>, 
<a href="/search/eess?searchtype=author&query=Liu%2C+Y">Yufei Liu</a>, 
<a href="/search/eess?searchtype=author&query=Yang%2C+D">Dongchao Yang</a>, 
<a href="/search/eess?searchtype=author&query=Zhang%2C+L">Leying Zhang</a>, 
<a href="/search/eess?searchtype=author&query=Song%2C+K">Kaitao Song</a>, 
<a href="/search/eess?searchtype=author&query=He%2C+L">Lei He</a>, 
<a href="/search/eess?searchtype=author&query=Li%2C+X">Xiang-Yang Li</a>, 
<a href="/search/eess?searchtype=author&query=Zhao%2C+S">Sheng Zhao</a>, 
<a href="/search/eess?searchtype=author&query=Qin%2C+T">Tao Qin</a>, 
<a href="/search/eess?searchtype=author&query=Bian%2C+J">Jiang Bian</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Demo page: <a href="https://speechresearch.github.io/prompttts2">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Computation and Language (cs.CL); Machine Learning (cs.LG); Sound (cs.SD)

</div>
<p class="mathjax">Speech conveys more information than just text, as the same word can be
uttered in various voices to convey diverse information. Compared to
traditional text-to-speech (TTS) methods relying on speech prompts (reference
speech) for voice variability, using text prompts (descriptions) is more
user-friendly since speech prompts can be hard to find or may not exist at all.
TTS approaches based on the text prompt face two challenges: 1) the one-to-many
problem, where not all details about voice variability can be described in the
text prompt, and 2) the limited availability of text prompt datasets, where
vendors and large cost of data labeling are required to write text prompt for
speech. In this work, we introduce PromptTTS 2 to address these challenges with
a variation network to provide variability information of voice not captured by
text prompts, and a prompt generation pipeline to utilize the large language
models (LLM) to compose high quality text prompts. Specifically, the variation
network predicts the representation extracted from the reference speech (which
contains full information about voice) based on the text prompt representation.
For the prompt generation pipeline, it generates text prompts for speech with a
speech understanding model to recognize voice attributes (e.g., gender, speed)
from speech and a large language model to formulate text prompt based on the
recognition results. Experiments on a large-scale (44K hours) speech dataset
demonstrate that compared to the previous works, PromptTTS 2 generates voices
more consistent with text prompts and supports the sampling of diverse voice
variability, thereby offering users more choices on voice generation.
Additionally, the prompt generation pipeline produces high-quality prompts,
eliminating the large labeling cost. The demo page of PromptTTS 2 is available
online\footnote{https://speechresearch.github.io/prompttts2}.
</p>
</div>
</dd>
<dt><a name="item849">[849]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.02292" title="Abstract">arXiv:2309.02292</a> (cross-list from cond-mat.dis-nn) [<a href="/pdf/2309.02292" title="Download PDF">pdf</a>, <a href="/format/2309.02292" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Inferring effective couplings with Restricted Boltzmann Machines
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cond-mat?searchtype=author&query=Decelle%2C+A">Aur&#xe9;lien Decelle</a>, 
<a href="/search/cond-mat?searchtype=author&query=Furtlehner%2C+C">Cyril Furtlehner</a>, 
<a href="/search/cond-mat?searchtype=author&query=De+Jesus+Navas+G%C3%B3mez%2C+A">Alfonso De Jesus Navas G&#xf3;mez</a>, 
<a href="/search/cond-mat?searchtype=author&query=Seoane%2C+B">Beatriz Seoane</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 figures, 22 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Disordered Systems and Neural Networks (cond-mat.dis-nn)</span>; Statistical Mechanics (cond-mat.stat-mech); Machine Learning (cs.LG)

</div>
<p class="mathjax">Generative models offer a direct way to model complex data. Among them,
energy-based models provide us with a neural network model that aims to
accurately reproduce all statistical correlations observed in the data at the
level of the Boltzmann weight of the model. However, one challenge is to
understand the physical interpretation of such models. In this study, we
propose a simple solution by implementing a direct mapping between the energy
function of the Restricted Boltzmann Machine and an effective Ising spin
Hamiltonian that includes high-order interactions between spins. This mapping
includes interactions of all possible orders, going beyond the conventional
pairwise interactions typically considered in the inverse Ising approach, and
allowing the description of complex datasets. Earlier work attempted to achieve
this goal, but the proposed mappings did not do properly treat the complexity
of the problem or did not contain direct prescriptions for practical
application. To validate our method, we perform several controlled numerical
experiments where the training samples are equilibrium samples of predefined
models containing local external fields, two-body and three-body interactions
in various low-dimensional topologies. The results demonstrate the
effectiveness of our proposed approach in learning the correct interaction
network and pave the way for its application in modeling interesting datasets.
We also evaluate the quality of the inferred model based on different training
methods.
</p>
</div>
</dd>
<dt><a name="item850">[850]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.02320" title="Abstract">arXiv:2309.02320</a> (cross-list from physics.geo-ph) [<a href="/pdf/2309.02320" title="Download PDF">pdf</a>, <a href="/format/2309.02320" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SeisCLIP: A seismology foundation model pre-trained by multi-modal data  for multi-purpose seismic feature extraction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Si%2C+X">Xu Si</a>, 
<a href="/search/physics?searchtype=author&query=Wu%2C+X">Xinming Wu</a>, 
<a href="/search/physics?searchtype=author&query=Sheng%2C+H">Hanlin Sheng</a>, 
<a href="/search/physics?searchtype=author&query=Zhu%2C+J">Jun Zhu</a>, 
<a href="/search/physics?searchtype=author&query=Li%2C+Z">Zefeng Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 27 pages, 9 figures, 4 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Geophysics (physics.geo-ph)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Training specific deep learning models for particular tasks is common across
various domains within seismology. However, this approach encounters two
limitations: inadequate labeled data for certain tasks and limited
generalization across regions. To address these challenges, we develop
SeisCLIP, a seismology foundation model trained through contrastive learning
from multi-modal data. It consists of a transformer encoder for extracting
crucial features from time-frequency seismic spectrum and an MLP encoder for
integrating the phase and source information of the same event. These encoders
are jointly pre-trained on a vast dataset and the spectrum encoder is
subsequently fine-tuned on smaller datasets for various downstream tasks.
Notably, SeisCLIP's performance surpasses that of baseline methods in event
classification, localization, and focal mechanism analysis tasks, employing
distinct datasets from different regions. In conclusion, SeisCLIP holds
significant potential as a foundational model in the field of seismology,
paving the way for innovative directions in foundation-model-based seismology
research.
</p>
</div>
</dd>
<dt><a name="item851">[851]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.02332" title="Abstract">arXiv:2309.02332</a> (cross-list from q-bio.NC) [<a href="/pdf/2309.02332" title="Download PDF">pdf</a>, <a href="/format/2309.02332" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Information Processing by Neuron Populations in the Central Nervous  System: Mathematical Structure of Data and Operations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-bio?searchtype=author&query=Nilsson%2C+M+N+P">Martin N. P. Nilsson</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 34 pages, 12 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neurons and Cognition (q-bio.NC)</span>; Artificial Intelligence (cs.AI); Neural and Evolutionary Computing (cs.NE)

</div>
<p class="mathjax">In the intricate architecture of the mammalian central nervous system,
neurons form populations. Axonal bundles communicate between these clusters
using spike trains as their medium. However, these neuron populations' precise
encoding and operations have yet to be discovered. In our analysis, the
starting point is a state-of-the-art mechanistic model of a generic neuron
endowed with plasticity. From this simple framework emerges a profound
mathematical construct: The representation and manipulation of information can
be precisely characterized by an algebra of finite convex cones. Furthermore,
these neuron populations are not merely passive transmitters. They act as
operators within this algebraic structure, mirroring the functionality of a
low-level programming language. When these populations interconnect, they
embody succinct yet potent algebraic expressions. These networks allow them to
implement many operations, such as specialization, generalization, novelty
detection, dimensionality reduction, inverse modeling, prediction, and
associative memory. In broader terms, this work illuminates the potential of
matrix embeddings in advancing our understanding in fields like cognitive
science and AI. These embeddings enhance the capacity for concept processing
and hierarchical description over their vector counterparts.
</p>
</div>
</dd>
<dt><a name="item852">[852]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.02333" title="Abstract">arXiv:2309.02333</a> (cross-list from physics.acc-ph) [<a href="/pdf/2309.02333" title="Download PDF">pdf</a>, <a href="/format/2309.02333" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Resilient VAE: Unsupervised Anomaly Detection at the SLAC Linac Coherent  Light Source
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Humble%2C+R">Ryan Humble</a>, 
<a href="/search/physics?searchtype=author&query=Colocho%2C+W">William Colocho</a>, 
<a href="/search/physics?searchtype=author&query=O%27Shea%2C+F">Finn O&#x27;Shea</a>, 
<a href="/search/physics?searchtype=author&query=Ratner%2C+D">Daniel Ratner</a>, 
<a href="/search/physics?searchtype=author&query=Darve%2C+E">Eric Darve</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Accelerator Physics (physics.acc-ph)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Significant advances in utilizing deep learning for anomaly detection have
been made in recent years. However, these methods largely assume the existence
of a normal training set (i.e., uncontaminated by anomalies) or even a
completely labeled training set. In many complex engineering systems, such as
particle accelerators, labels are sparse and expensive; in order to perform
anomaly detection in these cases, we must drop these assumptions and utilize a
completely unsupervised method. This paper introduces the Resilient Variational
Autoencoder (ResVAE), a deep generative model specifically designed for anomaly
detection. ResVAE exhibits resilience to anomalies present in the training data
and provides feature-level anomaly attribution. During the training process,
ResVAE learns the anomaly probability for each sample as well as each
individual feature, utilizing these probabilities to effectively disregard
anomalous examples in the training data. We apply our proposed method to detect
anomalies in the accelerator status at the SLAC Linac Coherent Light Source
(LCLS). By utilizing shot-to-shot data from the beam position monitoring
system, we demonstrate the exceptional capability of ResVAE in identifying
various types of anomalies that are visible in the accelerator.
</p>
</div>
</dd>
<dt><a name="item853">[853]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.02335" title="Abstract">arXiv:2309.02335</a> (cross-list from eess.IV) [<a href="/pdf/2309.02335" title="Download PDF">pdf</a>, <a href="/ps/2309.02335" title="Download PostScript">ps</a>, <a href="/format/2309.02335" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DEEPBEAS3D: Deep Learning and B-Spline Explicit Active Surfaces
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Williams%2C+H">Helena Williams</a>, 
<a href="/search/eess?searchtype=author&query=Pedrosa%2C+J">Jo&#xe3;o Pedrosa</a>, 
<a href="/search/eess?searchtype=author&query=Asad%2C+M">Muhammad Asad</a>, 
<a href="/search/eess?searchtype=author&query=Cattani%2C+L">Laura Cattani</a>, 
<a href="/search/eess?searchtype=author&query=Vercauteren%2C+T">Tom Vercauteren</a>, 
<a href="/search/eess?searchtype=author&query=Deprest%2C+J">Jan Deprest</a>, 
<a href="/search/eess?searchtype=author&query=D%27hooge%2C+J">Jan D&#x27;hooge</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 4 pages, 3 figures, 1 table, conference
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Deep learning-based automatic segmentation methods have become
state-of-the-art. However, they are often not robust enough for direct clinical
application, as domain shifts between training and testing data affect their
performance. Failure in automatic segmentation can cause sub-optimal results
that require correction. To address these problems, we propose a novel 3D
extension of an interactive segmentation framework that represents a
segmentation from a convolutional neural network (CNN) as a B-spline explicit
active surface (BEAS). BEAS ensures segmentations are smooth in 3D space,
increasing anatomical plausibility, while allowing the user to precisely edit
the 3D surface. We apply this framework to the task of 3D segmentation of the
anal sphincter complex (AS) from transperineal ultrasound (TPUS) images, and
compare it to the clinical tool used in the pelvic floor disorder clinic (4D
View VOCAL, GE Healthcare; Zipf, Austria). Experimental results show that: 1)
the proposed framework gives the user explicit control of the surface contour;
2) the perceived workload calculated via the NASA-TLX index was reduced by 30%
compared to VOCAL; and 3) it required 7 0% (170 seconds) less user time than
VOCAL (p&lt; 0.00001)
</p>
</div>
</dd>
<dt><a name="item854">[854]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.02338" title="Abstract">arXiv:2309.02338</a> (cross-list from astro-ph.EP) [<a href="/pdf/2309.02338" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Sustainability assessment of Low Earth Orbit (LEO) satellite broadband  mega-constellations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/astro-ph?searchtype=author&query=Osoro%2C+O+B">Ogutu B. Osoro</a>, 
<a href="/search/astro-ph?searchtype=author&query=Oughton%2C+E+J">Edward J. Oughton</a>, 
<a href="/search/astro-ph?searchtype=author&query=Wilson%2C+A+R">Andrew R. Wilson</a>, 
<a href="/search/astro-ph?searchtype=author&query=Rao%2C+A">Akhil Rao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Earth and Planetary Astrophysics (astro-ph.EP)</span>; General Economics (econ.GN); Systems and Control (eess.SY)

</div>
<p class="mathjax">The growth of mega-constellations is rapidly increasing the number of rocket
launches required to place new satellites in space. While Low Earth Orbit (LEO)
broadband satellites help to connect unconnected communities and achieve the
Sustainable Development Goals, there are also a range of negative environmental
externalities, from the burning of rocket fuels and resulting environmental
emissions. We present sustainability analytics for phase 1 of the three main
LEO constellations including Amazon Kuiper (3,236 satellites), OneWeb (648
satellites), and SpaceX Starlink (4,425 satellites). In baseline scenarios over
five years, we find a per subscriber carbon dioxide equivalent (CO$_2$eq) of
0.70$\pm$0.34 tonnes for Kuiper, 1.41$\pm$0.71 tonnes for OneWeb and
0.47$\pm$0.15 tonnes CO$_2$eq/subscriber for Starlink. However, in the
worst-case emissions scenario these values increase to 3.02$\pm$1.48 tonnes for
Kuiper, 1.7$\pm$0.71 tonnes for OneWeb and 1.04$\pm$0.33 tonnes
CO$_2$eq/subscriber for Starlink, more than 31-91 times higher than equivalent
terrestrial mobile broadband. Importantly, phase 2 constellations propose to
increase the number of satellites by an order-of-magnitude higher, highlighting
the pressing need to mitigate negative environmental impacts. Strategic choices
in rocket design and fuel options can help to substantially mitigate negative
sustainability impacts.
</p>
</div>
</dd>
<dt><a name="item855">[855]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.02393" title="Abstract">arXiv:2309.02393</a> (cross-list from eess.AS) [<a href="/pdf/2309.02393" title="Download PDF">pdf</a>, <a href="/format/2309.02393" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> In-Ear-Voice: Towards Milli-Watt Audio Enhancement With Bone-Conduction  Microphones for In-Ear Sensing Platforms
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Schilk%2C+P">Philipp Schilk</a>, 
<a href="/search/eess?searchtype=author&query=Polvani%2C+N">Niccol&#xf2; Polvani</a>, 
<a href="/search/eess?searchtype=author&query=Ronco%2C+A">Andrea Ronco</a>, 
<a href="/search/eess?searchtype=author&query=Cernak%2C+M">Milos Cernak</a>, 
<a href="/search/eess?searchtype=author&query=Magno%2C+M">Michele Magno</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">The recent ubiquitous adoption of remote conferencing has been accompanied by
omnipresent frustration with distorted or otherwise unclear voice
communication. Audio enhancement can compensate for low-quality input signals
from, for example, small true wireless earbuds, by applying noise suppression
techniques. Such processing relies on voice activity detection (VAD) with low
latency and the added capability of discriminating the wearer's voice from
others - a task of significant computational complexity. The tight energy
budget of devices as small as modern earphones, however, requires any system
attempting to tackle this problem to do so with minimal power and processing
overhead, while not relying on speaker-specific voice samples and training due
to usability concerns.
<br />This paper presents the design and implementation of a custom research
platform for low-power wireless earbuds based on novel, commercial, MEMS
bone-conduction microphones. Such microphones can record the wearer's speech
with much greater isolation, enabling personalized voice activity detection and
further audio enhancement applications. Furthermore, the paper accurately
evaluates a proposed low-power personalized speech detection algorithm based on
bone conduction data and a recurrent neural network running on the implemented
research platform. This algorithm is compared to an approach based on
traditional microphone input. The performance of the bone conduction system,
achieving detection of speech within 12.8ms at an accuracy of 95\% is
evaluated. Different SoC choices are contrasted, with the final implementation
based on the cutting-edge Ambiq Apollo 4 Blue SoC achieving 2.64mW average
power consumption at 14uJ per inference, reaching 43h of battery life on a
miniature 32mAh li-ion cell and without duty cycling.
</p>
</div>
</dd>
<dt><a name="item856">[856]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.02412" title="Abstract">arXiv:2309.02412</a> (cross-list from math.OC) [<a href="/pdf/2309.02412" title="Download PDF">pdf</a>, <a href="/format/2309.02412" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> First and zeroth-order implementations of the regularized Newton method  with lazy approximated Hessians
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Doikov%2C+N">Nikita Doikov</a>, 
<a href="/search/math?searchtype=author&query=Grapiglia%2C+G+N">Geovani Nunes Grapiglia</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">In this work, we develop first-order (Hessian-free) and zero-order
(derivative-free) implementations of the Cubically regularized Newton method
for solving general non-convex optimization problems. For that, we employ
finite difference approximations of the derivatives. We use a special adaptive
search procedure in our algorithms, which simultaneously fits both the
regularization constant and the parameters of the finite difference
approximations. It makes our schemes free from the need to know the actual
Lipschitz constants. Additionally, we equip our algorithms with the lazy
Hessian update that reuse a previously computed Hessian approximation matrix
for several iterations. Specifically, we prove the global complexity bound of
$\mathcal{O}( n^{1/2} \epsilon^{-3/2})$ function and gradient evaluations for
our new Hessian-free method, and a bound of $\mathcal{O}( n^{3/2}
\epsilon^{-3/2} )$ function evaluations for the derivative-free method, where
$n$ is the dimension of the problem and $\epsilon$ is the desired accuracy for
the gradient norm. These complexity bounds significantly improve the previously
known ones in terms of the joint dependence on $n$ and $\epsilon$, for the
first-order and zeroth-order non-convex optimization.
</p>
</div>
</dd>
<dt><a name="item857">[857]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.02417" title="Abstract">arXiv:2309.02417</a> (cross-list from stat.ML) [<a href="/pdf/2309.02417" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Computing SHAP Efficiently Using Model Structure Information
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Hu%2C+L">Linwei Hu</a>, 
<a href="/search/stat?searchtype=author&query=Wang%2C+K">Ke Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 15 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">SHAP (SHapley Additive exPlanations) has become a popular method to attribute
the prediction of a machine learning model on an input to its features. One
main challenge of SHAP is the computation time. An exact computation of Shapley
values requires exponential time complexity. Therefore, many approximation
methods are proposed in the literature. In this paper, we propose methods that
can compute SHAP exactly in polynomial time or even faster for SHAP definitions
that satisfy our additivity and dummy assumptions (eg, kernal SHAP and baseline
SHAP). We develop different strategies for models with different levels of
model structure information: known functional decomposition, known order of
model (defined as highest order of interaction in the model), or unknown order.
For the first case, we demonstrate an additive property and a way to compute
SHAP from the lower-order functional components. For the second case, we derive
formulas that can compute SHAP in polynomial time. Both methods yield exact
SHAP results. Finally, if even the order of model is unknown, we propose an
iterative way to approximate Shapley values. The three methods we propose are
computationally efficient when the order of model is not high which is
typically the case in practice. We compare with sampling approach proposed in
Castor &amp; Gomez (2008) using simulation studies to demonstrate the efficacy of
our proposed methods.
</p>
</div>
</dd>
<dt><a name="item858">[858]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.02418" title="Abstract">arXiv:2309.02418</a> (cross-list from eess.AS) [<a href="/pdf/2309.02418" title="Download PDF">pdf</a>, <a href="/format/2309.02418" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Personalized Adaptation with Pre-trained Speech Encoders for Continuous  Emotion Recognition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Tran%2C+M">Minh Tran</a>, 
<a href="/search/eess?searchtype=author&query=Yin%2C+Y">Yufeng Yin</a>, 
<a href="/search/eess?searchtype=author&query=Soleymani%2C+M">Mohammad Soleymani</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by INTERSPEECH 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Sound (cs.SD); Signal Processing (eess.SP)

</div>
<p class="mathjax">There are individual differences in expressive behaviors driven by cultural
norms and personality. This between-person variation can result in reduced
emotion recognition performance. Therefore, personalization is an important
step in improving the generalization and robustness of speech emotion
recognition. In this paper, to achieve unsupervised personalized emotion
recognition, we first pre-train an encoder with learnable speaker embeddings in
a self-supervised manner to learn robust speech representations conditioned on
speakers. Second, we propose an unsupervised method to compensate for the label
distribution shifts by finding similar speakers and leveraging their label
distributions from the training set. Extensive experimental results on the
MSP-Podcast corpus indicate that our method consistently outperforms strong
personalization baselines and achieves state-of-the-art performance for valence
estimation.
</p>
</div>
</dd>
<dt><a name="item859">[859]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.02422" title="Abstract">arXiv:2309.02422</a> (cross-list from stat.ML) [<a href="/pdf/2309.02422" title="Download PDF">pdf</a>, <a href="/format/2309.02422" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Maximum Mean Discrepancy Meets Neural Networks: The  Radon-Kolmogorov-Smirnov Test
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Paik%2C+S">Seunghoon Paik</a>, 
<a href="/search/stat?searchtype=author&query=Celentano%2C+M">Michael Celentano</a>, 
<a href="/search/stat?searchtype=author&query=Green%2C+A">Alden Green</a>, 
<a href="/search/stat?searchtype=author&query=Tibshirani%2C+R+J">Ryan J. Tibshirani</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG); Methodology (stat.ME)

</div>
<p class="mathjax">Maximum mean discrepancy (MMD) refers to a general class of nonparametric
two-sample tests that are based on maximizing the mean difference over samples
from one distribution $P$ versus another $Q$, over all choices of data
transformations $f$ living in some function space $\mathcal{F}$. Inspired by
recent work that connects what are known as functions of $\textit{Radon bounded
variation}$ (RBV) and neural networks (Parhi and Nowak, 2021, 2023), we study
the MMD defined by taking $\mathcal{F}$ to be the unit ball in the RBV space of
a given smoothness order $k \geq 0$. This test, which we refer to as the
$\textit{Radon-Kolmogorov-Smirnov}$ (RKS) test, can be viewed as a
generalization of the well-known and classical Kolmogorov-Smirnov (KS) test to
multiple dimensions and higher orders of smoothness. It is also intimately
connected to neural networks: we prove that the witness in the RKS test -- the
function $f$ achieving the maximum mean difference -- is always a ridge spline
of degree $k$, i.e., a single neuron in a neural network. This allows us to
leverage the power of modern deep learning toolkits to (approximately) optimize
the criterion that underlies the RKS test. We prove that the RKS test has
asymptotically full power at distinguishing any distinct pair $P \not= Q$ of
distributions, derive its asymptotic null distribution, and carry out extensive
experiments to elucidate the strengths and weakenesses of the RKS test versus
the more traditional kernel MMD test.
</p>
</div>
</dd>
<dt><a name="item860">[860]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.02426" title="Abstract">arXiv:2309.02426</a> (cross-list from stat.ML) [<a href="/pdf/2309.02426" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Monotone Tree-Based GAMI Models by Adapting XGBoost
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Hu%2C+L">Linwei Hu</a>, 
<a href="/search/stat?searchtype=author&query=Aramideh%2C+S">Soroush Aramideh</a>, 
<a href="/search/stat?searchtype=author&query=Chen%2C+J">Jie Chen</a>, 
<a href="/search/stat?searchtype=author&query=Nair%2C+V+N">Vijayan N. Nair</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Recent papers have used machine learning architecture to fit low-order
functional ANOVA models with main effects and second-order interactions. These
GAMI (GAM + Interaction) models are directly interpretable as the functional
main effects and interactions can be easily plotted and visualized.
Unfortunately, it is not easy to incorporate the monotonicity requirement into
the existing GAMI models based on boosted trees, such as EBM (Lou et al. 2013)
and GAMI-Lin-T (Hu et al. 2022). This paper considers models of the form
$f(x)=\sum_{j,k}f_{j,k}(x_j, x_k)$ and develops monotone tree-based GAMI
models, called monotone GAMI-Tree, by adapting the XGBoost algorithm. It is
straightforward to fit a monotone model to $f(x)$ using the options in XGBoost.
However, the fitted model is still a black box. We take a different approach:
i) use a filtering technique to determine the important interactions, ii) fit a
monotone XGBoost algorithm with the selected interactions, and finally iii)
parse and purify the results to get a monotone GAMI model. Simulated datasets
are used to demonstrate the behaviors of mono-GAMI-Tree and EBM, both of which
use piecewise constant fits. Note that the monotonicity requirement is for the
full model. Under certain situations, the main effects will also be monotone.
But, as seen in the examples, the interactions will not be monotone.
</p>
</div>
</dd>
<dt><a name="item861">[861]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.02432" title="Abstract">arXiv:2309.02432</a> (cross-list from eess.AS) [<a href="/pdf/2309.02432" title="Download PDF">pdf</a>, <a href="/format/2309.02432" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Employing Real Training Data for Deep Noise Suppression
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Xu%2C+Z">Ziyi Xu</a>, 
<a href="/search/eess?searchtype=author&query=Sach%2C+M">Marvin Sach</a>, 
<a href="/search/eess?searchtype=author&query=Pirklbauer%2C+J">Jan Pirklbauer</a>, 
<a href="/search/eess?searchtype=author&query=Fingscheidt%2C+T">Tim Fingscheidt</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Sound (cs.SD)

</div>
<p class="mathjax">Most deep noise suppression (DNS) models are trained with reference-based
losses requiring access to clean speech. However, sometimes an additive
microphone model is insufficient for real-world applications. Accordingly, ways
to use real training data in supervised learning for DNS models promise to
reduce a potential training/inference mismatch. Employing real data for DNS
training requires either generative approaches or a reference-free loss without
access to the corresponding clean speech. In this work, we propose to employ an
end-to-end non-intrusive deep neural network (DNN), named PESQ-DNN, to estimate
perceptual evaluation of speech quality (PESQ) scores of enhanced real data. It
provides a reference-free perceptual loss for employing real data during DNS
training, maximizing the PESQ scores. Furthermore, we use an epoch-wise
alternating training protocol, updating the DNS model on real data, followed by
PESQ-DNN updating on synthetic data. The DNS model trained with the PESQ-DNN
employing real data outperforms all reference methods employing only synthetic
training data. On synthetic test data, our proposed method excels the
Interspeech 2021 DNS Challenge baseline by a significant 0.32 PESQ points. Both
on synthetic and real test data, the proposed method beats the baseline by 0.05
DNSMOS points - although PESQ-DNN optimizes for a different perceptual metric.
</p>
</div>
</dd>
</dl>
<h3>Replacements for Wed,  6 Sep 23</h3>
<dl>
<dt><a name="item862">[862]</a>&nbsp;  <span class="list-identifier"><a href="/abs/1703.08853" title="Abstract">arXiv:1703.08853</a> (replaced) [<a href="/pdf/1703.08853" title="Download PDF">pdf</a>, <a href="/format/1703.08853" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A categorical characterization of relative entropy on standard Borel  spaces
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gagne%2C+N">Nicolas Gagne</a>, 
<a href="/search/cs?searchtype=author&query=Panangaden%2C+P">Prakash Panangaden</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>

</div>
</div>
</dd>
<dt><a name="item863">[863]</a>&nbsp;  <span class="list-identifier"><a href="/abs/1806.08389" title="Abstract">arXiv:1806.08389</a> (replaced) [<a href="/pdf/1806.08389" title="Download PDF">pdf</a>, <a href="/format/1806.08389" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Using Nonlinear Normal Modes for Execution of Efficient Cyclic Motions  in Articulated Soft Robots
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Della+Santina%2C+C">Cosimo Della Santina</a>, 
<a href="/search/cs?searchtype=author&query=Lakatos%2C+D">Dominic Lakatos</a>, 
<a href="/search/cs?searchtype=author&query=Bicchi%2C+A">Antonio Bicchi</a>, 
<a href="/search/cs?searchtype=author&query=Albu-Sch%C3%A4ffer%2C+A">Alin Albu-Sch&#xe4;ffer</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This is a paper recently submitted to ISER, extracted from the previous version which was rejected by TRO
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> International Symposium on Experimental Robotics 2020
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Systems and Control (eess.SY)

</div>
</div>
</dd>
<dt><a name="item864">[864]</a>&nbsp;  <span class="list-identifier"><a href="/abs/1903.00226" title="Abstract">arXiv:1903.00226</a> (replaced) [<a href="/pdf/1903.00226" title="Download PDF">pdf</a>, <a href="/format/1903.00226" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Trichotomy for Regular Trail Queries
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Martens%2C+W">Wim Martens</a>, 
<a href="/search/cs?searchtype=author&query=Niewerth%2C+M">Matthias Niewerth</a>, 
<a href="/search/cs?searchtype=author&query=Popp%2C+T">Tina Popp</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Formal Languages and Automata Theory (cs.FL)</span>; Databases (cs.DB); Logic in Computer Science (cs.LO)

</div>
</div>
</dd>
<dt><a name="item865">[865]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2005.13416" title="Abstract">arXiv:2005.13416</a> (replaced) [<a href="/pdf/2005.13416" title="Download PDF">pdf</a>, <a href="/ps/2005.13416" title="Download PostScript">ps</a>, <a href="/format/2005.13416" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Bibliometric indices as a measure of performance and competitive balance  in the knockout stage of the UEFA Champions League
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Csat%C3%B3%2C+L">L&#xe1;szl&#xf3; Csat&#xf3;</a>, 
<a href="/search/stat?searchtype=author&query=Petr%C3%B3czy%2C+D+G">D&#xf3;ra Gr&#xe9;ta Petr&#xf3;czy</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 25 pages, 9 figures, 7 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Applications (stat.AP)</span>; Computer Science and Game Theory (cs.GT); General Economics (econ.GN)

</div>
</div>
</dd>
<dt><a name="item866">[866]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2006.14925" title="Abstract">arXiv:2006.14925</a> (replaced) [<a href="/pdf/2006.14925" title="Download PDF">pdf</a>, <a href="/format/2006.14925" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Does the $\ell_1$-norm Learn a Sparse Graph under Laplacian Constrained  Graphical Models?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ying%2C+J">Jiaxi Ying</a>, 
<a href="/search/cs?searchtype=author&query=de+M.+Cardoso%2C+J+V">Jos&#xe9; Vin&#xed;cius de M. Cardoso</a>, 
<a href="/search/cs?searchtype=author&query=Palomar%2C+D+P">Daniel P. Palomar</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item867">[867]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2010.04396" title="Abstract">arXiv:2010.04396</a> (replaced) [<a href="/pdf/2010.04396" title="Download PDF">pdf</a>, <a href="/format/2010.04396" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Dropping Standardized Testing for Admissions Trades Off Information and  Access
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Garg%2C+N">Nikhil Garg</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Hannah Li</a>, 
<a href="/search/cs?searchtype=author&query=Monachou%2C+F">Faidra Monachou</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> An earlier version of this work appeared at ACM FAccT 2021
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>; Computer Science and Game Theory (cs.GT)

</div>
</div>
</dd>
<dt><a name="item868">[868]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2010.09471" title="Abstract">arXiv:2010.09471</a> (replaced) [<a href="/pdf/2010.09471" title="Download PDF">pdf</a>, <a href="/format/2010.09471" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Finding Cut-Offs in Leaderless Rendez-Vous Protocols is Easy
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Balasubramanian%2C+A+R">A. R. Balasubramanian</a>, 
<a href="/search/cs?searchtype=author&query=Esparza%2C+J">Javier Esparza</a>, 
<a href="/search/cs?searchtype=author&query=Raskin%2C+M">Mikhail Raskin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>

</div>
</div>
</dd>
<dt><a name="item869">[869]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2010.16045" title="Abstract">arXiv:2010.16045</a> (replaced) [<a href="/pdf/2010.16045" title="Download PDF">pdf</a>, <a href="/format/2010.16045" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Machine Learning (In) Security: A Stream of Problems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ceschin%2C+F">Fabr&#xed;cio Ceschin</a>, 
<a href="/search/cs?searchtype=author&query=Botacin%2C+M">Marcus Botacin</a>, 
<a href="/search/cs?searchtype=author&query=Bifet%2C+A">Albert Bifet</a>, 
<a href="/search/cs?searchtype=author&query=Pfahringer%2C+B">Bernhard Pfahringer</a>, 
<a href="/search/cs?searchtype=author&query=Oliveira%2C+L+S">Luiz S. Oliveira</a>, 
<a href="/search/cs?searchtype=author&query=Gomes%2C+H+M">Heitor Murilo Gomes</a>, 
<a href="/search/cs?searchtype=author&query=Gr%C3%A9gio%2C+A">Andr&#xe9; Gr&#xe9;gio</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Digital Threats 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item870">[870]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2011.01783" title="Abstract">arXiv:2011.01783</a> (replaced) [<a href="/pdf/2011.01783" title="Download PDF">pdf</a>, <a href="/format/2011.01783" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An Efficiency-boosting Client Selection Scheme for Federated Learning  with Fairness Guarantee
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+T">Tiansheng Huang</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+W">Weiwei Lin</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+W">Wentai Wu</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+L">Ligang He</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+K">Keqin Li</a>, 
<a href="/search/cs?searchtype=author&query=Zomaya%2C+A+Y">Albert Y.Zomaya</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by IEEE TPDS. DOI: 10.1109/TPDS.2020.3040887
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Distributed, Parallel, and Cluster Computing (cs.DC)

</div>
</div>
</dd>
<dt><a name="item871">[871]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2011.04412" title="Abstract">arXiv:2011.04412</a> (replaced) [<a href="/pdf/2011.04412" title="Download PDF">pdf</a>, <a href="/format/2011.04412" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Look Before You Leap: Detecting Phishing Web Pages by Exploiting Raw URL  And HTML Characteristics
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Opara%2C+C">Chidimma Opara</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yingke Chen</a>, 
<a href="/search/cs?searchtype=author&query=wei%2C+B">Bo.wei</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Expert Systems with Applications, Volume 236, 2024, 121183, ISSN
  0957-4174
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
</div>
</dd>
<dt><a name="item872">[872]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2012.04174" title="Abstract">arXiv:2012.04174</a> (replaced) [<a href="/pdf/2012.04174" title="Download PDF">pdf</a>, <a href="/format/2012.04174" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A wireless signal-based sensing framework for robotics
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jadhav%2C+N">Ninad Jadhav</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+W">Weiying Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+D">Diana Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Khatib%2C+O">Oussama Khatib</a>, 
<a href="/search/cs?searchtype=author&query=Kumar%2C+S">Swarun Kumar</a>, 
<a href="/search/cs?searchtype=author&query=Gil%2C+S">Stephanie Gil</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 27 pages, 27 figures, *co-primary authors
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Multiagent Systems (cs.MA)

</div>
</div>
</dd>
<dt><a name="item873">[873]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2012.11060" title="Abstract">arXiv:2012.11060</a> (replaced) [<a href="/pdf/2012.11060" title="Download PDF">pdf</a>, <a href="/format/2012.11060" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Adversarial Patch Generation for Automated Program Repair
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Alhefdhi%2C+A">Abdulaziz Alhefdhi</a> (1 and 2), 
<a href="/search/cs?searchtype=author&query=Dam%2C+H+K">Hoa Khanh Dam</a> (1), 
<a href="/search/cs?searchtype=author&query=Le-Cong%2C+T">Thanh Le-Cong</a> (3), 
<a href="/search/cs?searchtype=author&query=Le%2C+B">Bach Le</a> (3), 
<a href="/search/cs?searchtype=author&query=Ghose%2C+A">Aditya Ghose</a> (1) ((1) University of Wollongong, (2) Prince Sattam bin Abdulaziz University, (3) The University of Melbourne)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
</div>
</dd>
<dt><a name="item874">[874]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2101.01425" title="Abstract">arXiv:2101.01425</a> (replaced) [<a href="/pdf/2101.01425" title="Download PDF">pdf</a>, <a href="/format/2101.01425" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Het-node2vec: second order random walk sampling for heterogeneous  multigraphs embedding
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Valentini%2C+G">Giorgio Valentini</a>, 
<a href="/search/cs?searchtype=author&query=Casiraghi%2C+E">Elena Casiraghi</a>, 
<a href="/search/cs?searchtype=author&query=Cappelletti%2C+L">Luca Cappelletti</a>, 
<a href="/search/cs?searchtype=author&query=Fontana%2C+T">Tommaso Fontana</a>, 
<a href="/search/cs?searchtype=author&query=Reese%2C+J">Justin Reese</a>, 
<a href="/search/cs?searchtype=author&query=Robinson%2C+P">Peter Robinson</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 20 pages, 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Social and Information Networks (cs.SI); Physics and Society (physics.soc-ph)

</div>
</div>
</dd>
<dt><a name="item875">[875]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2101.05890" title="Abstract">arXiv:2101.05890</a> (replaced) [<a href="/pdf/2101.05890" title="Download PDF">pdf</a>, <a href="/format/2101.05890" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Transactive Framework for Dynamic Energy Storage Allocation for Critical  Load Management
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Dey%2C+A">Arnab Dey</a>, 
<a href="/search/eess?searchtype=author&query=Khatana%2C+V">Vivek Khatana</a>, 
<a href="/search/eess?searchtype=author&query=Mani%2C+A">Ankur Mani</a>, 
<a href="/search/eess?searchtype=author&query=Salapaka%2C+M+V">Murti V. Salapaka</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
</div>
</dd>
<dt><a name="item876">[876]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2102.01567" title="Abstract">arXiv:2102.01567</a> (replaced) [<a href="/pdf/2102.01567" title="Download PDF">pdf</a>, <a href="/ps/2102.01567" title="Download PostScript">ps</a>, <a href="/format/2102.01567" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Lyapunov Theory for Finite-Sample Guarantees of Asynchronous  Q-Learning and TD-Learning Variants
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+Z">Zaiwei Chen</a>, 
<a href="/search/cs?searchtype=author&query=Maguluri%2C+S+T">Siva Theja Maguluri</a>, 
<a href="/search/cs?searchtype=author&query=Shakkottai%2C+S">Sanjay Shakkottai</a>, 
<a href="/search/cs?searchtype=author&query=Shanmugam%2C+K">Karthikeyan Shanmugam</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Optimization and Control (math.OC); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item877">[877]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2103.14511" title="Abstract">arXiv:2103.14511</a> (replaced) [<a href="/pdf/2103.14511" title="Download PDF">pdf</a>, <a href="/format/2103.14511" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Testing identity of collections of quantum states: sample complexity  analysis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Fanizza%2C+M">Marco Fanizza</a>, 
<a href="/search/quant-ph?searchtype=author&query=Salvia%2C+R">Raffaele Salvia</a>, 
<a href="/search/quant-ph?searchtype=author&query=Giovannetti%2C+V">Vittorio Giovannetti</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 23+6 pages, 1 figure
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Data Structures and Algorithms (cs.DS)

</div>
</div>
</dd>
<dt><a name="item878">[878]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2104.04391" title="Abstract">arXiv:2104.04391</a> (replaced) [<a href="/pdf/2104.04391" title="Download PDF">pdf</a>, <a href="/format/2104.04391" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Flow-based Spatio-Temporal Structured Prediction of Motion Dynamics
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zand%2C+M">Mohsen Zand</a>, 
<a href="/search/cs?searchtype=author&query=Etemad%2C+A">Ali Etemad</a>, 
<a href="/search/cs?searchtype=author&query=Greenspan%2C+M">Michael Greenspan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, LaTeX; typos corrected, updated, in IEEE Transactions on Pattern Analysis and Machine Intelligence
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item879">[879]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2105.13859" title="Abstract">arXiv:2105.13859</a> (replaced) [<a href="/pdf/2105.13859" title="Download PDF">pdf</a>, <a href="/format/2105.13859" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Generative Network-Based Reduced-Order Model for Prediction, Data  Assimilation and Uncertainty Quantification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Silva%2C+V+L+S">Vinicius L. S. Silva</a>, 
<a href="/search/cs?searchtype=author&query=Heaney%2C+C+E">Claire E. Heaney</a>, 
<a href="/search/cs?searchtype=author&query=Nenov%2C+N">Nenko Nenov</a>, 
<a href="/search/cs?searchtype=author&query=Pain%2C+C+C">Christopher C. Pain</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: text overlap with <a href="/abs/2105.07729">arXiv:2105.07729</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item880">[880]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2107.06312" title="Abstract">arXiv:2107.06312</a> (replaced) [<a href="/pdf/2107.06312" title="Download PDF">pdf</a>, <a href="/ps/2107.06312" title="Download PostScript">ps</a>, <a href="/format/2107.06312" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Correlated Equilibria in Large Anonymous Bayesian Games
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Koessler%2C+F">Frederic Koessler</a>, 
<a href="/search/cs?searchtype=author&query=Scarsini%2C+M">Marco Scarsini</a>, 
<a href="/search/cs?searchtype=author&query=Tomala%2C+T">Tristan Tomala</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 27 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>; Theoretical Economics (econ.TH)

</div>
</div>
</dd>
<dt><a name="item881">[881]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2107.13658" title="Abstract">arXiv:2107.13658</a> (replaced) [<a href="/pdf/2107.13658" title="Download PDF">pdf</a>, <a href="/format/2107.13658" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On Families of Planar DAGs with Constant Stack Number
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=N%C3%B6llenburg%2C+M">Martin N&#xf6;llenburg</a>, 
<a href="/search/math?searchtype=author&query=Pupyrev%2C+S">Sergey Pupyrev</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Appears in the Proceedings of the 31st International Symposium on Graph Drawing and Network Visualization (GD 2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Combinatorics (math.CO)</span>; Discrete Mathematics (cs.DM); Data Structures and Algorithms (cs.DS)

</div>
</div>
</dd>
<dt><a name="item882">[882]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2109.03459" title="Abstract">arXiv:2109.03459</a> (replaced) [<a href="/pdf/2109.03459" title="Download PDF">pdf</a>, <a href="/format/2109.03459" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Dual Correction Strategy for Ranking Distillation in Top-N Recommender  System
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lee%2C+Y">Youngjune Lee</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+K">Kee-Eung Kim</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> CIKM 2021
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item883">[883]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2109.03870" title="Abstract">arXiv:2109.03870</a> (replaced) [<a href="/pdf/2109.03870" title="Download PDF">pdf</a>, <a href="/ps/2109.03870" title="Download PostScript">ps</a>, <a href="/format/2109.03870" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Secure Blockchain-Based Supply Chain Management with Verifiable Digital  Twins
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Botta%2C+V">Vincenzo Botta</a>, 
<a href="/search/cs?searchtype=author&query=Fusco%2C+L">Laura Fusco</a>, 
<a href="/search/cs?searchtype=author&query=Mondelli%2C+A">Attilio Mondelli</a>, 
<a href="/search/cs?searchtype=author&query=Visconti%2C+I">Ivan Visconti</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
</div>
</dd>
<dt><a name="item884">[884]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2109.04415" title="Abstract">arXiv:2109.04415</a> (replaced) [<a href="/pdf/2109.04415" title="Download PDF">pdf</a>, <a href="/format/2109.04415" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Algorithms and Certificates for Boolean CSP Refutation: &quot;Smoothed is no  harder than Random&quot;
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Guruswami%2C+V">Venkatesan Guruswami</a>, 
<a href="/search/cs?searchtype=author&query=Kothari%2C+P+K">Pravesh K. Kothari</a>, 
<a href="/search/cs?searchtype=author&query=Manohar%2C+P">Peter Manohar</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Complexity (cs.CC)</span>; Data Structures and Algorithms (cs.DS)

</div>
</div>
</dd>
<dt><a name="item885">[885]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2109.08868" title="Abstract">arXiv:2109.08868</a> (replaced) [<a href="/pdf/2109.08868" title="Download PDF">pdf</a>, <a href="/format/2109.08868" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Backdoor Attack on Hash-based Image Retrieval via Clean-label Data  Poisoning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gao%2C+K">Kuofeng Gao</a>, 
<a href="/search/cs?searchtype=author&query=Bai%2C+J">Jiawang Bai</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+B">Bin Chen</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+D">Dongxian Wu</a>, 
<a href="/search/cs?searchtype=author&query=Xia%2C+S">Shu-Tao Xia</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by BMVC 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item886">[886]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2110.01358" title="Abstract">arXiv:2110.01358</a> (replaced) [<a href="/pdf/2110.01358" title="Download PDF">pdf</a>, <a href="/format/2110.01358" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Model Based Control of Soft Robots: A Survey of the State of the Art and  Open Challenges
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Della+Santina%2C+C">Cosimo Della Santina</a>, 
<a href="/search/eess?searchtype=author&query=Duriez%2C+C">Christian Duriez</a>, 
<a href="/search/eess?searchtype=author&query=Rus%2C+D">Daniela Rus</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 69 pages, 13 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Robotics (cs.RO)

</div>
</div>
</dd>
<dt><a name="item887">[887]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2110.05063" title="Abstract">arXiv:2110.05063</a> (replaced) [<a href="/pdf/2110.05063" title="Download PDF">pdf</a>, <a href="/ps/2110.05063" title="Download PostScript">ps</a>, <a href="/format/2110.05063" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Efficient Extensional Binary Tries
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Appel%2C+A+W">Andrew W Appel</a>, 
<a href="/search/cs?searchtype=author&query=Leroy%2C+X">Xavier Leroy</a> (CAMBIUM)
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Journal of Automated Reasoning, 2023, 67, pp.Article number 8
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>; Programming Languages (cs.PL)

</div>
</div>
</dd>
<dt><a name="item888">[888]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2110.06148" title="Abstract">arXiv:2110.06148</a> (replaced) [<a href="/pdf/2110.06148" title="Download PDF">pdf</a>, <a href="/ps/2110.06148" title="Download PostScript">ps</a>, <a href="/format/2110.06148" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Optimal rate of convergence for approximations of SPDEs with non-regular  drift
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Butkovsky%2C+O">Oleg Butkovsky</a>, 
<a href="/search/math?searchtype=author&query=Dareiotis%2C+K">Konstantinos Dareiotis</a>, 
<a href="/search/math?searchtype=author&query=Gerencs%C3%A9r%2C+M">M&#xe1;t&#xe9; Gerencs&#xe9;r</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 35 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Probability (math.PR)</span>; Analysis of PDEs (math.AP); Numerical Analysis (math.NA)

</div>
</div>
</dd>
<dt><a name="item889">[889]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2111.06675" title="Abstract">arXiv:2111.06675</a> (replaced) [<a href="/pdf/2111.06675" title="Download PDF">pdf</a>, <a href="/ps/2111.06675" title="Download PostScript">ps</a>, <a href="/format/2111.06675" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Construction of Spectrally-Null-Constrained Zero-Correlation Zone  Sequences with Flexible Support
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kumar%2C+N">Nishant Kumar</a>, 
<a href="/search/cs?searchtype=author&query=Sarkar%2C+P">Palash Sarkar</a>, 
<a href="/search/cs?searchtype=author&query=Majhi%2C+S">Sudhan Majhi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>

</div>
</div>
</dd>
<dt><a name="item890">[890]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2112.00710" title="Abstract">arXiv:2112.00710</a> (replaced) [<a href="/pdf/2112.00710" title="Download PDF">pdf</a>, <a href="/format/2112.00710" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Stateful Entities: Object-oriented Cloud Applications as Distributed  Dataflows
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Psarakis%2C+K">Kyriakos Psarakis</a>, 
<a href="/search/cs?searchtype=author&query=Zorgdrager%2C+W">Wouter Zorgdrager</a>, 
<a href="/search/cs?searchtype=author&query=Fragkoulis%2C+M">Marios Fragkoulis</a>, 
<a href="/search/cs?searchtype=author&query=Salvaneschi%2C+G">Guido Salvaneschi</a>, 
<a href="/search/cs?searchtype=author&query=Katsifodimos%2C+A">Asterios Katsifodimos</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>; Databases (cs.DB)

</div>
</div>
</dd>
<dt><a name="item891">[891]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2112.02333" title="Abstract">arXiv:2112.02333</a> (replaced) [<a href="/pdf/2112.02333" title="Download PDF">pdf</a>, <a href="/format/2112.02333" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LoNLI: An Extensible Framework for Testing Diverse Logical Reasoning  Capabilities for NLI
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tarunesh%2C+I">Ishan Tarunesh</a>, 
<a href="/search/cs?searchtype=author&query=Aditya%2C+S">Somak Aditya</a>, 
<a href="/search/cs?searchtype=author&query=Choudhury%2C+M">Monojit Choudhury</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: substantial text overlap with <a href="/abs/2107.07229">arXiv:2107.07229</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
</div>
</dd>
<dt><a name="item892">[892]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2112.13314" title="Abstract">arXiv:2112.13314</a> (replaced) [<a href="/pdf/2112.13314" title="Download PDF">pdf</a>, <a href="/format/2112.13314" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Silent Bugs in Deep Learning Frameworks: An Empirical Study of Keras and  TensorFlow
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tambon%2C+F">Florian Tambon</a>, 
<a href="/search/cs?searchtype=author&query=Nikanjam%2C+A">Amin Nikanjam</a>, 
<a href="/search/cs?searchtype=author&query=An%2C+L">Le An</a>, 
<a href="/search/cs?searchtype=author&query=Khomh%2C+F">Foutse Khomh</a>, 
<a href="/search/cs?searchtype=author&query=Antoniol%2C+G">Giuliano Antoniol</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item893">[893]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2202.02878" title="Abstract">arXiv:2202.02878</a> (replaced) [<a href="/pdf/2202.02878" title="Download PDF">pdf</a>, <a href="/format/2202.02878" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> When to pull data from sensors for minimum Distance-based Age of  incorrect Information metric
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kriouile%2C+S">Saad Kriouile</a>, 
<a href="/search/cs?searchtype=author&query=Assaad%2C+M">Mohamad Assaad</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: substantial text overlap with <a href="/abs/2102.03245">arXiv:2102.03245</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>

</div>
</div>
</dd>
<dt><a name="item894">[894]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2202.02980" title="Abstract">arXiv:2202.02980</a> (replaced) [<a href="/pdf/2202.02980" title="Download PDF">pdf</a>, <a href="/format/2202.02980" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> 3D Object Detection from Images for Autonomous Driving: A Survey
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ma%2C+X">Xinzhu Ma</a>, 
<a href="/search/cs?searchtype=author&query=Ouyang%2C+W">Wanli Ouyang</a>, 
<a href="/search/cs?searchtype=author&query=Simonelli%2C+A">Andrea Simonelli</a>, 
<a href="/search/cs?searchtype=author&query=Ricci%2C+E">Elisa Ricci</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item895">[895]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2202.04965" title="Abstract">arXiv:2202.04965</a> (replaced) [<a href="/pdf/2202.04965" title="Download PDF">pdf</a>, <a href="/format/2202.04965" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> $&#x393;$-Convergence of an Ambrosio-Tortorelli approximation scheme for  image segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Fonseca%2C+I">Irene Fonseca</a>, 
<a href="/search/math?searchtype=author&query=Kreusser%2C+L+M">Lisa Maria Kreusser</a>, 
<a href="/search/math?searchtype=author&query=Sch%C3%B6nlieb%2C+C">Carola-Bibiane Sch&#xf6;nlieb</a>, 
<a href="/search/math?searchtype=author&query=Thorpe%2C+M">Matthew Thorpe</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Analysis of PDEs (math.AP); Numerical Analysis (math.NA)

</div>
</div>
</dd>
<dt><a name="item896">[896]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2202.10587" title="Abstract">arXiv:2202.10587</a> (replaced) [<a href="/pdf/2202.10587" title="Download PDF">pdf</a>, <a href="/format/2202.10587" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Knowledge-informed Molecular Learning: A Survey on Paradigm Transfer
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fang%2C+Y">Yin Fang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Z">Zhuo Chen</a>, 
<a href="/search/cs?searchtype=author&query=Fan%2C+X">Xiaohui Fan</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+N">Ningyu Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 3 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Chemical Physics (physics.chem-ph); Quantitative Methods (q-bio.QM)

</div>
</div>
</dd>
<dt><a name="item897">[897]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2202.13844" title="Abstract">arXiv:2202.13844</a> (replaced) [<a href="/pdf/2202.13844" title="Download PDF">pdf</a>, <a href="/format/2202.13844" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> All Graphs with at most 8 nodes are 2-interval-PCGs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Calamoneri%2C+T">Tiziana Calamoneri</a>, 
<a href="/search/cs?searchtype=author&query=Monti%2C+A">Angelo Monti</a>, 
<a href="/search/cs?searchtype=author&query=Petroni%2C+F">Fabrizio Petroni</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages, 3 figures, never published
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Discrete Mathematics (cs.DM)</span>; Combinatorics (math.CO)

</div>
</div>
</dd>
<dt><a name="item898">[898]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2203.03996" title="Abstract">arXiv:2203.03996</a> (replaced) [<a href="/pdf/2203.03996" title="Download PDF">pdf</a>, <a href="/format/2203.03996" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DeltaCNN: End-to-End CNN Inference of Sparse Frame Differences in Videos
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Parger%2C+M">Mathias Parger</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+C">Chengcheng Tang</a>, 
<a href="/search/cs?searchtype=author&query=Twigg%2C+C+D">Christopher D. Twigg</a>, 
<a href="/search/cs?searchtype=author&query=Keskin%2C+C">Cem Keskin</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+R">Robert Wang</a>, 
<a href="/search/cs?searchtype=author&query=Steinberger%2C+M">Markus Steinberger</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> CVPR 2022
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item899">[899]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2203.05377" title="Abstract">arXiv:2203.05377</a> (replaced) [<a href="/pdf/2203.05377" title="Download PDF">pdf</a>, <a href="/format/2203.05377" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Robust and Scalable Game-theoretic Security Investment Methods for  Voltage Stability of Power Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=An%2C+L">Lu An</a>, 
<a href="/search/eess?searchtype=author&query=Shukla%2C+P">Pratishtha Shukla</a>, 
<a href="/search/eess?searchtype=author&query=Chakrabortty%2C+A">Aranya Chakrabortty</a>, 
<a href="/search/eess?searchtype=author&query=Duel-Hallen%2C+A">Alexandra Duel-Hallen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages, 6 figures, accepted by IEEE CDC 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Distributed, Parallel, and Cluster Computing (cs.DC)

</div>
</div>
</dd>
<dt><a name="item900">[900]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2203.06804" title="Abstract">arXiv:2203.06804</a> (replaced) [<a href="/pdf/2203.06804" title="Download PDF">pdf</a>, <a href="/ps/2203.06804" title="Download PostScript">ps</a>, <a href="/format/2203.06804" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Infinite Wordle and the Mastermind numbers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Hamkins%2C+J+D">Joel David Hamkins</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 22 pages, 5 figures. Comments can be made at <a href="http://jdh.hamkins.org/infinite-wordle-mastermind.">this http URL</a> v2 has minor updates and corrections. v3 makes a minor correction to theorem 11 statement 2 and a few other minor ambiguities
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic (math.LO)</span>; Computer Science and Game Theory (cs.GT)

</div>
</div>
</dd>
<dt><a name="item901">[901]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2203.07378" title="Abstract">arXiv:2203.07378</a> (replaced) [<a href="/pdf/2203.07378" title="Download PDF">pdf</a>, <a href="/format/2203.07378" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Dawn of the transformer era in speech emotion recognition: closing the  valence gap
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Wagner%2C+J">Johannes Wagner</a>, 
<a href="/search/eess?searchtype=author&query=Triantafyllopoulos%2C+A">Andreas Triantafyllopoulos</a>, 
<a href="/search/eess?searchtype=author&query=Wierstorf%2C+H">Hagen Wierstorf</a>, 
<a href="/search/eess?searchtype=author&query=Schmitt%2C+M">Maximilian Schmitt</a>, 
<a href="/search/eess?searchtype=author&query=Burkhardt%2C+F">Felix Burkhardt</a>, 
<a href="/search/eess?searchtype=author&query=Eyben%2C+F">Florian Eyben</a>, 
<a href="/search/eess?searchtype=author&query=Schuller%2C+B+W">Bj&#xf6;rn W. Schuller</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> in IEEE Transactions on Pattern Analysis and Machine Intelligence,
  vol. 45, no. 9, pp. 10745-10759, 1 Sept. 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Machine Learning (cs.LG); Sound (cs.SD)

</div>
</div>
</dd>
<dt><a name="item902">[902]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2203.08546" title="Abstract">arXiv:2203.08546</a> (replaced) [<a href="/pdf/2203.08546" title="Download PDF">pdf</a>, <a href="/format/2203.08546" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Subgame-perfect Equilibria in Mean-payoff Games (journal version)
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Brice%2C+L">L&#xe9;onard Brice</a>, 
<a href="/search/cs?searchtype=author&query=van+den+Bogaard%2C+M">Marie van den Bogaard</a>, 
<a href="/search/cs?searchtype=author&query=Raskin%2C+J">Jean-Fran&#xe7;ois Raskin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: substantial text overlap with <a href="/abs/2101.10685">arXiv:2101.10685</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>

</div>
</div>
</dd>
<dt><a name="item903">[903]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2203.15201" title="Abstract">arXiv:2203.15201</a> (replaced) [<a href="/pdf/2203.15201" title="Download PDF">pdf</a>, <a href="/format/2203.15201" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Light Field Depth Estimation via Stitched Epipolar Plane Images
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhou%2C+P">Ping Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xiaoyang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+J">Jing Jin</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yuting Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Hou%2C+J">Junhui Hou</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item904">[904]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2204.11054" title="Abstract">arXiv:2204.11054</a> (replaced) [<a href="/pdf/2204.11054" title="Download PDF">pdf</a>, <a href="/format/2204.11054" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MLP-Hash: Protecting Face Templates via Hashing of Randomized  Multi-Layer Perceptron
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shahreza%2C+H+O">Hatef Otroshi Shahreza</a>, 
<a href="/search/cs?searchtype=author&query=Hahn%2C+V+K">Vedrana Krivoku&#x107;a Hahn</a>, 
<a href="/search/cs?searchtype=author&query=Marcel%2C+S">S&#xe9;bastien Marcel</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted in the 31st European Signal Processing Conference (EUSIPCO 2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Cryptography and Security (cs.CR)

</div>
</div>
</dd>
<dt><a name="item905">[905]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2205.00334" title="Abstract">arXiv:2205.00334</a> (replaced) [<a href="/pdf/2205.00334" title="Download PDF">pdf</a>, <a href="/format/2205.00334" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Engineering flexible machine learning systems by traversing  functionally-invariant paths
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Raghavan%2C+G">Guruprasad Raghavan</a>, 
<a href="/search/cs?searchtype=author&query=Tharwat%2C+B">Bahey Tharwat</a>, 
<a href="/search/cs?searchtype=author&query=Hari%2C+S+N">Surya Narayanan Hari</a>, 
<a href="/search/cs?searchtype=author&query=Satani%2C+D">Dhruvil Satani</a>, 
<a href="/search/cs?searchtype=author&query=Thomson%2C+M">Matt Thomson</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 22 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Differential Geometry (math.DG)

</div>
</div>
</dd>
<dt><a name="item906">[906]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2205.04449" title="Abstract">arXiv:2205.04449</a> (replaced) [<a href="/pdf/2205.04449" title="Download PDF">pdf</a>, <a href="/format/2205.04449" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Introspective Deep Metric Learning for Image Retrieval
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zheng%2C+W">Wenzhao Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+C">Chengkun Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+J">Jie Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+J">Jiwen Lu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> The extended version of this paper is accepted to T-PAMI. Source code available at <a href="https://github.com/wzzheng/IDML">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item907">[907]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2205.06192" title="Abstract">arXiv:2205.06192</a> (replaced) [<a href="/pdf/2205.06192" title="Download PDF">pdf</a>, <a href="/ps/2205.06192" title="Download PostScript">ps</a>, <a href="/format/2205.06192" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Circumventing Unstable Zero Dynamics in Input-Output Linearization of  Longitudinal Flight Dynamics
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Delgado%2C+J+M+P">Jhon Manuel Portella Delgado</a>, 
<a href="/search/math?searchtype=author&query=Goel%2C+A">Ankit Goel</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Systems and Control (eess.SY)

</div>
</div>
</dd>
<dt><a name="item908">[908]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2205.07019" title="Abstract">arXiv:2205.07019</a> (replaced) [<a href="/pdf/2205.07019" title="Download PDF">pdf</a>, <a href="/format/2205.07019" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Evaluating the Generalization Ability of Super-Resolution Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yihao Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+H">Hengyuan Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Gu%2C+J">Jinjin Gu</a>, 
<a href="/search/cs?searchtype=author&query=Qiao%2C+Y">Yu Qiao</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+C">Chao Dong</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by TPAMI
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Image and Video Processing (eess.IV)

</div>
</div>
</dd>
<dt><a name="item909">[909]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2205.08529" title="Abstract">arXiv:2205.08529</a> (replaced) [<a href="/pdf/2205.08529" title="Download PDF">pdf</a>, <a href="/format/2205.08529" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> F3B: A Low-Overhead Blockchain Architecture with Per-Transaction  Front-Running Protection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Haoqian Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Merino%2C+L">Louis-Henri Merino</a>, 
<a href="/search/cs?searchtype=author&query=Qu%2C+Z">Ziyan Qu</a>, 
<a href="/search/cs?searchtype=author&query=Bastankhah%2C+M">Mahsa Bastankhah</a>, 
<a href="/search/cs?searchtype=author&query=Estrada-Galinanes%2C+V">Vero Estrada-Galinanes</a>, 
<a href="/search/cs?searchtype=author&query=Ford%2C+B">Bryan Ford</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
</div>
</dd>
<dt><a name="item910">[910]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2205.08589" title="Abstract">arXiv:2205.08589</a> (replaced) [<a href="/pdf/2205.08589" title="Download PDF">pdf</a>, <a href="/format/2205.08589" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Hierarchical Distribution-Aware Testing of Deep Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+W">Wei Huang</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+X">Xingyu Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Banks%2C+A">Alec Banks</a>, 
<a href="/search/cs?searchtype=author&query=Cox%2C+V">Victoria Cox</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+X">Xiaowei Huang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by ACM Transactions on Software Engineering and Methodology (TOSEM)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item911">[911]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2205.09169" title="Abstract">arXiv:2205.09169</a> (replaced) [<a href="/pdf/2205.09169" title="Download PDF">pdf</a>, <a href="/format/2205.09169" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Anonymous conference key agreement in linear quantum networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=de+Jong%2C+J">Jarn de Jong</a>, 
<a href="/search/quant-ph?searchtype=author&query=Hahn%2C+F">Frederik Hahn</a>, 
<a href="/search/quant-ph?searchtype=author&query=Eisert%2C+J">Jens Eisert</a>, 
<a href="/search/quant-ph?searchtype=author&query=Walk%2C+N">Nathan Walk</a>, 
<a href="/search/quant-ph?searchtype=author&query=Pappa%2C+A">Anna Pappa</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages of main text, 3 figures in main text, 3 tables in main text, 10 pages of appendices, 1 figure in appendices, 3 tables in appendices
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Cryptography and Security (cs.CR)

</div>
</div>
</dd>
<dt><a name="item912">[912]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2205.11488" title="Abstract">arXiv:2205.11488</a> (replaced) [<a href="/pdf/2205.11488" title="Download PDF">pdf</a>, <a href="/format/2205.11488" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Entanglements
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Carmesin%2C+J">Johannes Carmesin</a>, 
<a href="/search/math?searchtype=author&query=Kurkofka%2C+J">Jan Kurkofka</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 4 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Combinatorics (math.CO)</span>; Discrete Mathematics (cs.DM)

</div>
</div>
</dd>
<dt><a name="item913">[913]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2206.00205" title="Abstract">arXiv:2206.00205</a> (replaced) [<a href="/pdf/2206.00205" title="Download PDF">pdf</a>, <a href="/format/2206.00205" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CAFA: Class-Aware Feature Alignment for Test-Time Adaptation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jung%2C+S">Sanghun Jung</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+J">Jungsoo Lee</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+N">Nanhee Kim</a>, 
<a href="/search/cs?searchtype=author&query=Shaban%2C+A">Amirreza Shaban</a>, 
<a href="/search/cs?searchtype=author&query=Boots%2C+B">Byron Boots</a>, 
<a href="/search/cs?searchtype=author&query=Choo%2C+J">Jaegul Choo</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item914">[914]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2206.02194" title="Abstract">arXiv:2206.02194</a> (replaced) [<a href="/pdf/2206.02194" title="Download PDF">pdf</a>, <a href="/format/2206.02194" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FOF: Learning Fourier Occupancy Field for Monocular Real-time Human  Reconstruction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Feng%2C+Q">Qiao Feng</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yebin Liu</a>, 
<a href="/search/cs?searchtype=author&query=Lai%2C+Y">Yu-Kun Lai</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+J">Jingyu Yang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+K">Kun Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item915">[915]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2206.02217" title="Abstract">arXiv:2206.02217</a> (replaced) [<a href="/pdf/2206.02217" title="Download PDF">pdf</a>, <a href="/format/2206.02217" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning Mesh Motion Techniques with Application to Fluid-Structure  Interaction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Haubner%2C+J">Johannes Haubner</a>, 
<a href="/search/math?searchtype=author&query=Hellan%2C+O">Ottar Hellan</a>, 
<a href="/search/math?searchtype=author&query=Zeinhofer%2C+M">Marius Zeinhofer</a>, 
<a href="/search/math?searchtype=author&query=Kuchta%2C+M">Miroslav Kuchta</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Optimization and Control (math.OC)

</div>
</div>
</dd>
<dt><a name="item916">[916]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2206.03482" title="Abstract">arXiv:2206.03482</a> (replaced) [<a href="/pdf/2206.03482" title="Download PDF">pdf</a>, <a href="/format/2206.03482" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Chordal Sparsity for SDP-based Neural Network Verification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xue%2C+A">Anton Xue</a>, 
<a href="/search/cs?searchtype=author&query=Lindemann%2C+L">Lars Lindemann</a>, 
<a href="/search/cs?searchtype=author&query=Alur%2C+R">Rajeev Alur</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Optimization and Control (math.OC)

</div>
</div>
</dd>
<dt><a name="item917">[917]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2206.08181" title="Abstract">arXiv:2206.08181</a> (replaced) [<a href="/pdf/2206.08181" title="Download PDF">pdf</a>, <a href="/format/2206.08181" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ResNorm: Tackling Long-tailed Degree Distribution Issue in Graph Neural  Networks via Normalization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liang%2C+L">Langzhang Liang</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+Z">Zenglin Xu</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+Z">Zixing Song</a>, 
<a href="/search/cs?searchtype=author&query=King%2C+I">Irwin King</a>, 
<a href="/search/cs?searchtype=author&query=Qi%2C+Y">Yuan Qi</a>, 
<a href="/search/cs?searchtype=author&query=Ye%2C+J">Jieping Ye</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item918">[918]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2206.08316" title="Abstract">arXiv:2206.08316</a> (replaced) [<a href="/pdf/2206.08316" title="Download PDF">pdf</a>, <a href="/format/2206.08316" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Boosting the Adversarial Transferability of Surrogate Models with Dark  Knowledge
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+D">Dingcheng Yang</a>, 
<a href="/search/cs?searchtype=author&query=Xiao%2C+Z">Zihao Xiao</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+W">Wenjian Yu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at 2023 International Conference on Tools with Artificial Intelligence (ICTAI)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Cryptography and Security (cs.CR); Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item919">[919]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2206.08903" title="Abstract">arXiv:2206.08903</a> (replaced) [<a href="/pdf/2206.08903" title="Download PDF">pdf</a>, <a href="/format/2206.08903" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Colonoscopy 3D Video Dataset with Paired Depth from 2D-3D Registration
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bobrow%2C+T+L">Taylor L. Bobrow</a>, 
<a href="/search/cs?searchtype=author&query=Golhar%2C+M">Mayank Golhar</a>, 
<a href="/search/cs?searchtype=author&query=Vijayan%2C+R">Rohan Vijayan</a>, 
<a href="/search/cs?searchtype=author&query=Akshintala%2C+V+S">Venkata S. Akshintala</a>, 
<a href="/search/cs?searchtype=author&query=Garcia%2C+J+R">Juan R. Garcia</a>, 
<a href="/search/cs?searchtype=author&query=Durr%2C+N+J">Nicholas J. Durr</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item920">[920]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2206.09410" title="Abstract">arXiv:2206.09410</a> (replaced) [<a href="/pdf/2206.09410" title="Download PDF">pdf</a>, <a href="/format/2206.09410" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Low-Mid Adversarial Perturbation against Unauthorized Face Recognition  System
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jiaming Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Yi%2C+Q">Qi Yi</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+D">Dongyuan Lu</a>, 
<a href="/search/cs?searchtype=author&query=Sang%2C+J">Jitao Sang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> published in Information Sciences
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Image and Video Processing (eess.IV)

</div>
</div>
</dd>
<dt><a name="item921">[921]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2206.11048" title="Abstract">arXiv:2206.11048</a> (replaced) [<a href="/pdf/2206.11048" title="Download PDF">pdf</a>, <a href="/format/2206.11048" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Automated GI tract segmentation using deep learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Sharma%2C+M">Manhar Sharma</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 9 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item922">[922]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2206.12100" title="Abstract">arXiv:2206.12100</a> (replaced) [<a href="/pdf/2206.12100" title="Download PDF">pdf</a>, <a href="/format/2206.12100" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> zPROBE: Zero Peek Robustness Checks for Federated Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ghodsi%2C+Z">Zahra Ghodsi</a>, 
<a href="/search/cs?searchtype=author&query=Javaheripi%2C+M">Mojan Javaheripi</a>, 
<a href="/search/cs?searchtype=author&query=Sheybani%2C+N">Nojan Sheybani</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xinqiao Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+K">Ke Huang</a>, 
<a href="/search/cs?searchtype=author&query=Koushanfar%2C+F">Farinaz Koushanfar</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ICCV 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Cryptography and Security (cs.CR)

</div>
</div>
</dd>
<dt><a name="item923">[923]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2206.13964" title="Abstract">arXiv:2206.13964</a> (replaced) [<a href="/pdf/2206.13964" title="Download PDF">pdf</a>, <a href="/format/2206.13964" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning Gait Representation from Massive Unlabelled Walking Videos: A  Benchmark
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fan%2C+C">Chao Fan</a>, 
<a href="/search/cs?searchtype=author&query=Hou%2C+S">Saihui Hou</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jilong Wang</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+Y">Yongzhen Huang</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+S">Shiqi Yu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item924">[924]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2207.00430" title="Abstract">arXiv:2207.00430</a> (replaced) [<a href="/pdf/2207.00430" title="Download PDF">pdf</a>, <a href="/format/2207.00430" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> How trial-to-trial learning shapes mappings in the mental lexicon:  Modelling Lexical Decision with Linear Discriminative Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Heitmeier%2C+M">Maria Heitmeier</a>, 
<a href="/search/cs?searchtype=author&query=Chuang%2C+Y">Yu-Ying Chuang</a>, 
<a href="/search/cs?searchtype=author&query=Baayen%2C+R+H">R. Harald Baayen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 48 pages, 13 figures; revised version
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Neurons and Cognition (q-bio.NC)

</div>
</div>
</dd>
<dt><a name="item925">[925]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2207.08569" title="Abstract">arXiv:2207.08569</a> (replaced) [<a href="/pdf/2207.08569" title="Download PDF">pdf</a>, <a href="/format/2207.08569" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multi-manifold Attention for Vision Transformers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Konstantinidis%2C+D">Dimitrios Konstantinidis</a>, 
<a href="/search/cs?searchtype=author&query=Papastratis%2C+I">Ilias Papastratis</a>, 
<a href="/search/cs?searchtype=author&query=Dimitropoulos%2C+K">Kosmas Dimitropoulos</a>, 
<a href="/search/cs?searchtype=author&query=Daras%2C+P">Petros Daras</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item926">[926]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2207.10802" title="Abstract">arXiv:2207.10802</a> (replaced) [<a href="/pdf/2207.10802" title="Download PDF">pdf</a>, <a href="/format/2207.10802" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Combing for Credentials: Active Pattern Extraction from Smart Reply
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jayaraman%2C+B">Bargav Jayaraman</a>, 
<a href="/search/cs?searchtype=author&query=Ghosh%2C+E">Esha Ghosh</a>, 
<a href="/search/cs?searchtype=author&query=Chase%2C+M">Melissa Chase</a>, 
<a href="/search/cs?searchtype=author&query=Roy%2C+S">Sambuddha Roy</a>, 
<a href="/search/cs?searchtype=author&query=Dai%2C+W">Wei Dai</a>, 
<a href="/search/cs?searchtype=author&query=Evans%2C+D">David Evans</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Computation and Language (cs.CL); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item927">[927]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2208.00164" title="Abstract">arXiv:2208.00164</a> (replaced) [<a href="/e-print/2208.00164" title="Download source">src</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Distilled Low Rank Neural Radiance Field with Quantization for Light  Field Compression
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shi%2C+J">Jinglei Shi</a>, 
<a href="/search/cs?searchtype=author&query=Guillemot%2C+C">Christine Guillemot</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> The explanation of this paper lacks many details and is not well organized, we withdraw it to avoid misleading readers
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Multimedia (cs.MM)

</div>
</div>
</dd>
<dt><a name="item928">[928]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2208.02484" title="Abstract">arXiv:2208.02484</a> (replaced) [<a href="/pdf/2208.02484" title="Download PDF">pdf</a>, <a href="/format/2208.02484" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Customs Import Declaration Datasets
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jeong%2C+C">Chaeyoon Jeong</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+S">Sundong Kim</a>, 
<a href="/search/cs?searchtype=author&query=Park%2C+J">Jaewoo Park</a>, 
<a href="/search/cs?searchtype=author&query=Choi%2C+Y">Yeonsoo Choi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Datasets: <a href="https://github.com/Seondong/Customs-Declaration-Datasets">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Other Statistics (stat.OT)

</div>
</div>
</dd>
<dt><a name="item929">[929]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2208.04727" title="Abstract">arXiv:2208.04727</a> (replaced) [<a href="/pdf/2208.04727" title="Download PDF">pdf</a>, <a href="/format/2208.04727" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Responsible Urban Intelligence: Towards a Research Agenda
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cao%2C+R">Rui Cao</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+Q">Qi-Li Gao</a>, 
<a href="/search/cs?searchtype=author&query=Qiu%2C+G">Guoping Qiu</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Spatial Data Science Symposium 2023 Short Paper Proceedings
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>

</div>
</div>
</dd>
<dt><a name="item930">[930]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2208.06616" title="Abstract">arXiv:2208.06616</a> (replaced) [<a href="/pdf/2208.06616" title="Download PDF">pdf</a>, <a href="/format/2208.06616" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Self-supervised Contrastive Representation Learning for Semi-supervised  Time-Series Classification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Eldele%2C+E">Emadeldeen Eldele</a>, 
<a href="/search/cs?searchtype=author&query=Ragab%2C+M">Mohamed Ragab</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Z">Zhenghua Chen</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+M">Min Wu</a>, 
<a href="/search/cs?searchtype=author&query=Kwoh%2C+C">Chee-Keong Kwoh</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xiaoli Li</a>, 
<a href="/search/cs?searchtype=author&query=Guan%2C+C">Cuntai Guan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted in the IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI). arXiv admin note: text overlap with <a href="/abs/2106.14112">arXiv:2106.14112</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item931">[931]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2208.06680" title="Abstract">arXiv:2208.06680</a> (replaced) [<a href="/pdf/2208.06680" title="Download PDF">pdf</a>, <a href="/format/2208.06680" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Locating disparities in machine learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=von+Zahn%2C+M">Moritz von Zahn</a>, 
<a href="/search/cs?searchtype=author&query=Hinz%2C+O">Oliver Hinz</a>, 
<a href="/search/cs?searchtype=author&query=Feuerriegel%2C+S">Stefan Feuerriegel</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item932">[932]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2208.07737" title="Abstract">arXiv:2208.07737</a> (replaced) [<a href="/pdf/2208.07737" title="Download PDF">pdf</a>, <a href="/format/2208.07737" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning Efficient Abstract Planning Models that Choose What to Predict
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kumar%2C+N">Nishanth Kumar</a>, 
<a href="/search/cs?searchtype=author&query=McClinton%2C+W">Willie McClinton</a>, 
<a href="/search/cs?searchtype=author&query=Chitnis%2C+R">Rohan Chitnis</a>, 
<a href="/search/cs?searchtype=author&query=Silver%2C+T">Tom Silver</a>, 
<a href="/search/cs?searchtype=author&query=Lozano-P%C3%A9rez%2C+T">Tom&#xe1;s Lozano-P&#xe9;rez</a>, 
<a href="/search/cs?searchtype=author&query=Kaelbling%2C+L+P">Leslie Pack Kaelbling</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Machine Learning (cs.LG); Robotics (cs.RO)

</div>
</div>
</dd>
<dt><a name="item933">[933]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2208.09944" title="Abstract">arXiv:2208.09944</a> (replaced) [<a href="/pdf/2208.09944" title="Download PDF">pdf</a>, <a href="/format/2208.09944" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MolGraph: a Python package for the implementation of molecular graphs  and graph neural networks with TensorFlow and Keras
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kensert%2C+A">Alexander Kensert</a>, 
<a href="/search/cs?searchtype=author&query=Desmet%2C+G">Gert Desmet</a>, 
<a href="/search/cs?searchtype=author&query=Cabooter%2C+D">Deirdre Cabooter</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages, 4 figures, 4 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Quantitative Methods (q-bio.QM)

</div>
</div>
</dd>
<dt><a name="item934">[934]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2208.10993" title="Abstract">arXiv:2208.10993</a> (replaced) [<a href="/pdf/2208.10993" title="Download PDF">pdf</a>, <a href="/format/2208.10993" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Application of federated learning techniques for arrhythmia  classification using 12-lead ECG signals
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gutierrez%2C+D+M+J">Daniel Mauricio Jimenez Gutierrez</a>, 
<a href="/search/cs?searchtype=author&query=Hassan%2C+H+M">Hafiz Muuhammad Hassan</a>, 
<a href="/search/cs?searchtype=author&query=Landi%2C+L">Lorella Landi</a>, 
<a href="/search/cs?searchtype=author&query=Vitaletti%2C+A">Andrea Vitaletti</a>, 
<a href="/search/cs?searchtype=author&query=Chatzigiannakis%2C+I">Ioannis Chatzigiannakis</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Preprint of International Symposium on Algorithmic Aspects of Cloud Computing (ALGOCLOUD) 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item935">[935]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2208.11718" title="Abstract">arXiv:2208.11718</a> (replaced) [<a href="/pdf/2208.11718" title="Download PDF">pdf</a>, <a href="/format/2208.11718" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> gSwin: Gated MLP Vision Model with Hierarchical Structure of Shifted  Window
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Go%2C+M">Mocho Go</a>, 
<a href="/search/cs?searchtype=author&query=Tachibana%2C+H">Hideyuki Tachibana</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages, 7 figures, IEEE ICASSP 2023
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Proc. ICASSP (2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item936">[936]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2209.00626" title="Abstract">arXiv:2209.00626</a> (replaced) [<a href="/pdf/2209.00626" title="Download PDF">pdf</a>, <a href="/ps/2209.00626" title="Download PostScript">ps</a>, <a href="/format/2209.00626" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The alignment problem from a deep learning perspective
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ngo%2C+R">Richard Ngo</a>, 
<a href="/search/cs?searchtype=author&query=Chan%2C+L">Lawrence Chan</a>, 
<a href="/search/cs?searchtype=author&query=Mindermann%2C+S">S&#xf6;ren Mindermann</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item937">[937]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2209.02339" title="Abstract">arXiv:2209.02339</a> (replaced) [<a href="/pdf/2209.02339" title="Download PDF">pdf</a>, <a href="/format/2209.02339" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> TransCAB: Transferable Clean-Annotation Backdoor to Object Detection  with Natural Trigger in Real-World
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ma%2C+H">Hua Ma</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yinshan Li</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+Y">Yansong Gao</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zhi Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Abuadbba%2C+A">Alsharif Abuadbba</a>, 
<a href="/search/cs?searchtype=author&query=Fu%2C+A">Anmin Fu</a>, 
<a href="/search/cs?searchtype=author&query=Al-Sarawi%2C+S+F">Said F. Al-Sarawi</a>, 
<a href="/search/cs?searchtype=author&query=Surya%2C+N">Nepal Surya</a>, 
<a href="/search/cs?searchtype=author&query=Abbott%2C+D">Derek Abbott</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Cryptography and Security (cs.CR)

</div>
</div>
</dd>
<dt><a name="item938">[938]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2209.04473" title="Abstract">arXiv:2209.04473</a> (replaced) [<a href="/pdf/2209.04473" title="Download PDF">pdf</a>, <a href="/format/2209.04473" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Reconstructing the Dynamic Directivity of Unconstrained Speech
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Noufi%2C+C">Camille Noufi</a>, 
<a href="/search/eess?searchtype=author&query=Markovic%2C+D">Dejan Markovic</a>, 
<a href="/search/eess?searchtype=author&query=Dodds%2C+P">Peter Dodds</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> In proceedings of I3DA 2023 - The 2023 International Conference on Immersive and 3D Audio. DOI coming soon
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Sound (cs.SD); Signal Processing (eess.SP)

</div>
</div>
</dd>
<dt><a name="item939">[939]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2209.04920" title="Abstract">arXiv:2209.04920</a> (replaced) [<a href="/pdf/2209.04920" title="Download PDF">pdf</a>, <a href="/format/2209.04920" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Vec2Face-v2: Unveil Human Faces from their Blackbox Features via  Attention-based Network in Face Recognition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Truong%2C+T">Thanh-Dat Truong</a>, 
<a href="/search/cs?searchtype=author&query=Duong%2C+C+N">Chi Nhan Duong</a>, 
<a href="/search/cs?searchtype=author&query=Le%2C+N">Ngan Le</a>, 
<a href="/search/cs?searchtype=author&query=Savvides%2C+M">Marios Savvides</a>, 
<a href="/search/cs?searchtype=author&query=Luu%2C+K">Khoa Luu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: substantial text overlap with <a href="/abs/2003.06958">arXiv:2003.06958</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item940">[940]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2209.12563" title="Abstract">arXiv:2209.12563</a> (replaced) [<a href="/pdf/2209.12563" title="Download PDF">pdf</a>, <a href="/format/2209.12563" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Impact-Friendly Object Catching at Non-Zero Velocity Based on Combined  Optimization and Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhao%2C+J">Jianzhuang Zhao</a> (1,2), 
<a href="/search/cs?searchtype=author&query=Lahr%2C+G+J+G">Gustavo J. G. Lahr</a> (1), 
<a href="/search/cs?searchtype=author&query=Tassi%2C+F">Francesco Tassi</a> (1,2), 
<a href="/search/cs?searchtype=author&query=Santopaolo%2C+A">Alessandro Santopaolo</a> (1), 
<a href="/search/cs?searchtype=author&query=De+Momi%2C+E">Elena De Momi</a> (2), 
<a href="/search/cs?searchtype=author&query=Ajoudani%2C+A">Arash Ajoudani</a> (1) ((1) Human-Robot Interfaces and Interaction Lab, Istituto Italiano di Tecnologia, Genoa, Italy, (2) Dept. of Electronics, Information and Bioengineering, Politecnico di Milano, Italy.)
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 9 figures, accepted by 2023 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS 2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
</div>
</dd>
<dt><a name="item941">[941]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2209.12573" title="Abstract">arXiv:2209.12573</a> (replaced) [<a href="/pdf/2209.12573" title="Download PDF">pdf</a>, <a href="/format/2209.12573" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Faked Speech Detection with Zero Knowledge
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ajmi%2C+S+A">Sahar Al Ajmi</a>, 
<a href="/search/cs?searchtype=author&query=Hayat%2C+K">Khizar Hayat</a>, 
<a href="/search/cs?searchtype=author&query=Obaidi%2C+A+M+A">Alaa M. Al Obaidi</a>, 
<a href="/search/cs?searchtype=author&query=Kumar%2C+N">Naresh Kumar</a>, 
<a href="/search/cs?searchtype=author&query=Najmuldeen%2C+M">Munaf Najmuldeen</a>, 
<a href="/search/cs?searchtype=author&query=Magnier%2C+B">Baptiste Magnier</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages, 4 figures (6 if you count subfigures), 2 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Multimedia (cs.MM); Neural and Evolutionary Computing (cs.NE); Audio and Speech Processing (eess.AS)

</div>
</div>
</dd>
<dt><a name="item942">[942]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2209.13492" title="Abstract">arXiv:2209.13492</a> (replaced) [<a href="/pdf/2209.13492" title="Download PDF">pdf</a>, <a href="/format/2209.13492" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Unraveling Key Elements Underlying Molecular Property Prediction: A  Systematic Study
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-bio?searchtype=author&query=Deng%2C+J">Jianyuan Deng</a>, 
<a href="/search/q-bio?searchtype=author&query=Yang%2C+Z">Zhibo Yang</a>, 
<a href="/search/q-bio?searchtype=author&query=Wang%2C+H">Hehe Wang</a>, 
<a href="/search/q-bio?searchtype=author&query=Ojima%2C+I">Iwao Ojima</a>, 
<a href="/search/q-bio?searchtype=author&query=Samaras%2C+D">Dimitris Samaras</a>, 
<a href="/search/q-bio?searchtype=author&query=Wang%2C+F">Fusheng Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantitative Methods (q-bio.QM)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item943">[943]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2209.15410" title="Abstract">arXiv:2209.15410</a> (replaced) [<a href="/pdf/2209.15410" title="Download PDF">pdf</a>, <a href="/ps/2209.15410" title="Download PostScript">ps</a>, <a href="/format/2209.15410" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> $\mathcal{P}\neq \mathcal{NP}$
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tang%2C+J">Jian-Gang Tang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Correct some mistakes in the article: 1. It is more appropriate to modify "instance Q" and "instance S" in the abstract as "problem Q" and "problem S" respectively. 2. "$\sqcup$" is the "quasiblanks" in Theorem 3.8 proof should be modified to "$\sqcup$" is the "pseudo-blank symbol"
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Complexity (cs.CC)</span>; Logic (math.LO)

</div>
</div>
</dd>
<dt><a name="item944">[944]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2210.02328" title="Abstract">arXiv:2210.02328</a> (replaced) [<a href="/pdf/2210.02328" title="Download PDF">pdf</a>, <a href="/format/2210.02328" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Geometric discretization of diffeomorphisms
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Jansson%2C+E">Erik Jansson</a>, 
<a href="/search/math?searchtype=author&query=Modin%2C+K">Klas Modin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 17 pages, 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Differential Geometry (math.DG)

</div>
</div>
</dd>
<dt><a name="item945">[945]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2210.07765" title="Abstract">arXiv:2210.07765</a> (replaced) [<a href="/pdf/2210.07765" title="Download PDF">pdf</a>, <a href="/format/2210.07765" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Activity-aware Human Mobility Prediction with Hierarchical Graph  Attention Recurrent Network
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tang%2C+Y">Yihong Tang</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+J">Junlin He</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Z">Zhan Zhao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item946">[946]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2210.08295" title="Abstract">arXiv:2210.08295</a> (replaced) [<a href="/pdf/2210.08295" title="Download PDF">pdf</a>, <a href="/format/2210.08295" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Secure Federated Data-Driven Evolutionary Multi-objective Optimization  Algorithm
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+Q">Qiqi Liu</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+Y">Yuping Yan</a>, 
<a href="/search/cs?searchtype=author&query=Ligeti%2C+P">Peter Ligeti</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+Y">Yaochu Jin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This paper has been accepted by IEEE Transactions on Emerging Topics in Computational Intelligence journal
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Cryptography and Security (cs.CR); Neural and Evolutionary Computing (cs.NE)

</div>
</div>
</dd>
<dt><a name="item947">[947]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2210.09914" title="Abstract">arXiv:2210.09914</a> (replaced) [<a href="/pdf/2210.09914" title="Download PDF">pdf</a>, <a href="/format/2210.09914" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Computing MEMs and Relatives on Repetitive Text Collections
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Navarro%2C+G">Gonzalo Navarro</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>

</div>
</div>
</dd>
<dt><a name="item948">[948]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2210.11510" title="Abstract">arXiv:2210.11510</a> (replaced) [<a href="/pdf/2210.11510" title="Download PDF">pdf</a>, <a href="/format/2210.11510" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Nonlinear Attitude Estimation Using Intermittent and Multi-Rate Vector  Measurements
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Wang%2C+M">Miaomiao Wang</a>, 
<a href="/search/eess?searchtype=author&query=Tayebi%2C+A">Abdelhamid Tayebi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 22 pages, 7 figures, submitted to IEEE TAC for possible publication
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
</div>
</dd>
<dt><a name="item949">[949]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2210.11584" title="Abstract">arXiv:2210.11584</a> (replaced) [<a href="/pdf/2210.11584" title="Download PDF">pdf</a>, <a href="/format/2210.11584" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Human-centered Explainable AI: A Survey of User Studies for  Model Explanations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rong%2C+Y">Yao Rong</a>, 
<a href="/search/cs?searchtype=author&query=Leemann%2C+T">Tobias Leemann</a>, 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+T">Thai-trang Nguyen</a>, 
<a href="/search/cs?searchtype=author&query=Fiedler%2C+L">Lisa Fiedler</a>, 
<a href="/search/cs?searchtype=author&query=Qian%2C+P">Peizhu Qian</a>, 
<a href="/search/cs?searchtype=author&query=Unhelkar%2C+V">Vaibhav Unhelkar</a>, 
<a href="/search/cs?searchtype=author&query=Seidel%2C+T">Tina Seidel</a>, 
<a href="/search/cs?searchtype=author&query=Kasneci%2C+G">Gjergji Kasneci</a>, 
<a href="/search/cs?searchtype=author&query=Kasneci%2C+E">Enkelejda Kasneci</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Human-Computer Interaction (cs.HC)

</div>
</div>
</dd>
<dt><a name="item950">[950]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2210.12842" title="Abstract">arXiv:2210.12842</a> (replaced) [<a href="/pdf/2210.12842" title="Download PDF">pdf</a>, <a href="/ps/2210.12842" title="Download PostScript">ps</a>, <a href="/format/2210.12842" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Entropic exercises around the Kneser-Poulsen conjecture
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Aishwarya%2C+G">Gautam Aishwarya</a>, 
<a href="/search/math?searchtype=author&query=Alam%2C+I">Irfan Alam</a>, 
<a href="/search/math?searchtype=author&query=Li%2C+D">Dongbin Li</a>, 
<a href="/search/math?searchtype=author&query=Myroshnychenko%2C+S">Sergii Myroshnychenko</a>, 
<a href="/search/math?searchtype=author&query=Zatarain-Vera%2C+O">Oscar Zatarain-Vera</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 23 pages, comments welcome! Final version with minor changes, added Corollary 2.8 (linear contractions decrease intrinsic volumes of convex bodies)
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Mathematika, Volume 69, Issue 3, pp. 841-866 (2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Metric Geometry (math.MG)</span>; Information Theory (cs.IT); Probability (math.PR)

</div>
</div>
</dd>
<dt><a name="item951">[951]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2210.14309" title="Abstract">arXiv:2210.14309</a> (replaced) [<a href="/pdf/2210.14309" title="Download PDF">pdf</a>, <a href="/format/2210.14309" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Empowering Long-tail Item Recommendation through Cross Decoupling  Network (CDN)
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yin Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+R">Ruoxi Wang</a>, 
<a href="/search/cs?searchtype=author&query=Yao%2C+T">Tiansheng Yao</a>, 
<a href="/search/cs?searchtype=author&query=Yi%2C+X">Xinyang Yi</a>, 
<a href="/search/cs?searchtype=author&query=Hong%2C+L">Lichan Hong</a>, 
<a href="/search/cs?searchtype=author&query=Caverlee%2C+J">James Caverlee</a>, 
<a href="/search/cs?searchtype=author&query=Chi%2C+E+H">Ed H. Chi</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+D+Z">Derek Zhiyuan Cheng</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by KDD 2023 Applied Data Science (ADS) track
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>

</div>
</div>
</dd>
<dt><a name="item952">[952]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2210.14312" title="Abstract">arXiv:2210.14312</a> (replaced) [<a href="/pdf/2210.14312" title="Download PDF">pdf</a>, <a href="/format/2210.14312" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> JAX-DIPS: Neural bootstrapping of finite discretization methods and  application to elliptic problems with discontinuities
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Mistani%2C+P">Pouria Mistani</a>, 
<a href="/search/math?searchtype=author&query=Pakravan%2C+S">Samira Pakravan</a>, 
<a href="/search/math?searchtype=author&query=Ilango%2C+R">Rajesh Ilango</a>, 
<a href="/search/math?searchtype=author&query=Gibou%2C+F">Frederic Gibou</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted for publication in the Journal of Computational Physics
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Artificial Intelligence (cs.AI); Computational Engineering, Finance, and Science (cs.CE)

</div>
</div>
</dd>
<dt><a name="item953">[953]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2211.01022" title="Abstract">arXiv:2211.01022</a> (replaced) [<a href="/pdf/2211.01022" title="Download PDF">pdf</a>, <a href="/ps/2211.01022" title="Download PostScript">ps</a>, <a href="/format/2211.01022" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Verifying And Interpreting Neural Networks using Finite Automata
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=S%C3%A4lzer%2C+M">Marco S&#xe4;lzer</a>, 
<a href="/search/cs?searchtype=author&query=Alsmann%2C+E">Eric Alsmann</a>, 
<a href="/search/cs?searchtype=author&query=Bruse%2C+F">Florian Bruse</a>, 
<a href="/search/cs?searchtype=author&query=Lange%2C+M">Martin Lange</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Formal Languages and Automata Theory (cs.FL)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item954">[954]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2211.01334" title="Abstract">arXiv:2211.01334</a> (replaced) [<a href="/pdf/2211.01334" title="Download PDF">pdf</a>, <a href="/format/2211.01334" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MemoNet: Memorizing All Cross Features&#x27; Representations Efficiently via  Multi-Hash Codebook Network for CTR Prediction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+P">Pengtao Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Junlin Zhang</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> ACM International Conference on Information and Knowledge
  Management(CIKM '23), October 21-25,2023,Birmingham,United Kingdom
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item955">[955]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2211.02676" title="Abstract">arXiv:2211.02676</a> (replaced) [<a href="/pdf/2211.02676" title="Download PDF">pdf</a>, <a href="/format/2211.02676" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Context-tree weighting and Bayesian Context Trees: Asymptotic and  non-asymptotic justifications
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kontoyiannis%2C+I">Ioannis Kontoyiannis</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Minor corrections, references added. To appear in the IEEE Transactions on Information Theory
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Statistics Theory (math.ST)

</div>
</div>
</dd>
<dt><a name="item956">[956]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2211.03194" title="Abstract">arXiv:2211.03194</a> (replaced) [<a href="/pdf/2211.03194" title="Download PDF">pdf</a>, <a href="/ps/2211.03194" title="Download PostScript">ps</a>, <a href="/format/2211.03194" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Side-Constrained Dynamic Traffic Equilibria
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Graf%2C+L">Lukas Graf</a>, 
<a href="/search/math?searchtype=author&query=Harks%2C+T">Tobias Harks</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 59 pages, 10 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Computer Science and Game Theory (cs.GT)

</div>
</div>
</dd>
<dt><a name="item957">[957]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2211.04829" title="Abstract">arXiv:2211.04829</a> (replaced) [<a href="/pdf/2211.04829" title="Download PDF">pdf</a>, <a href="/ps/2211.04829" title="Download PostScript">ps</a>, <a href="/format/2211.04829" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Frozen Gaussian Sampling for Scalar Wave Equations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Chai%2C+L">Lihui Chai</a>, 
<a href="/search/math?searchtype=author&query=Feng%2C+Y">Ye Feng</a>, 
<a href="/search/math?searchtype=author&query=Zhou%2C+Z">Zhennan Zhou</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
</div>
</dd>
<dt><a name="item958">[958]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2211.05222" title="Abstract">arXiv:2211.05222</a> (replaced) [<a href="/pdf/2211.05222" title="Download PDF">pdf</a>, <a href="/format/2211.05222" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ViSE: Vision-Based 3D Online Shape Estimation of Continuously Deformable  Robots
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zheng%2C+H">Hehui Zheng</a> (1 and 2), 
<a href="/search/cs?searchtype=author&query=Pinzello%2C+S">Sebastian Pinzello</a> (1), 
<a href="/search/cs?searchtype=author&query=Cangan%2C+B+G">Barnabas Gavin Cangan</a> (1), 
<a href="/search/cs?searchtype=author&query=Buchner%2C+T">Thomas Buchner</a> (1), 
<a href="/search/cs?searchtype=author&query=Katzschmann%2C+R+K">Robert K. Katzschmann</a> (1) ((1) Soft Robotics Lab ETH Zurich, (2) ETH AI Center)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
</div>
</dd>
<dt><a name="item959">[959]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2211.06326" title="Abstract">arXiv:2211.06326</a> (replaced) [<a href="/pdf/2211.06326" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Bad, mad and cooked: Responsibility for civilian harms in human-AI  military teams
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Devitt%2C+S+K">Susannah Kate Devitt</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 30 pages, accepted for publication in Jan Maarten Schraagen (Ed.) 'Responsible Use of AI in Military Systems', CRC Press [Forthcoming]
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>

</div>
</div>
</dd>
<dt><a name="item960">[960]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2211.08142" title="Abstract">arXiv:2211.08142</a> (replaced) [<a href="/pdf/2211.08142" title="Download PDF">pdf</a>, <a href="/format/2211.08142" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Semantic Representations of Mathematical Expressions in a Continuous  Vector Space
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gangwar%2C+N">Neeraj Gangwar</a>, 
<a href="/search/cs?searchtype=author&query=Kani%2C+N">Nickvash Kani</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Transactions on Machine Learning Research (TMLR), September 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Logic in Computer Science (cs.LO)

</div>
</div>
</dd>
<dt><a name="item961">[961]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2211.08194" title="Abstract">arXiv:2211.08194</a> (replaced) [<a href="/pdf/2211.08194" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Machine learning for classifying and interpreting coherent X-ray speckle  patterns
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cond-mat?searchtype=author&query=Shen%2C+M">Mingren Shen</a>, 
<a href="/search/cond-mat?searchtype=author&query=Sheyfer%2C+D">Dina Sheyfer</a>, 
<a href="/search/cond-mat?searchtype=author&query=Loeffler%2C+T+D">Troy David Loeffler</a>, 
<a href="/search/cond-mat?searchtype=author&query=Sankaranarayanan%2C+S+K+R+S">Subramanian K.R.S. Sankaranarayanan</a>, 
<a href="/search/cond-mat?searchtype=author&query=Stephenson%2C+G+B">G. Brian Stephenson</a>, 
<a href="/search/cond-mat?searchtype=author&query=Chan%2C+M+K+Y">Maria K. Y. Chan</a>, 
<a href="/search/cond-mat?searchtype=author&query=Morgan%2C+D">Dane Morgan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Materials Science (cond-mat.mtrl-sci)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item962">[962]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2211.08375" title="Abstract">arXiv:2211.08375</a> (replaced) [<a href="/pdf/2211.08375" title="Download PDF">pdf</a>, <a href="/ps/2211.08375" title="Download PostScript">ps</a>, <a href="/format/2211.08375" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Stability and convergence of the Euler scheme for stochastic linear  evolution equations in Banach spaces
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Li%2C+B">Binjie Li</a>, 
<a href="/search/math?searchtype=author&query=Xie%2C+X">Xiaoping Xie</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Probability (math.PR)

</div>
</div>
</dd>
<dt><a name="item963">[963]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2211.08904" title="Abstract">arXiv:2211.08904</a> (replaced) [<a href="/pdf/2211.08904" title="Download PDF">pdf</a>, <a href="/format/2211.08904" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SelfOdom: Self-supervised Egomotion and Depth Learning via  Bi-directional Coarse-to-Fine Scale Recovery
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Qu%2C+H">Hao Qu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+L">Lilian Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+X">Xiaoping Hu</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+X">Xiaofeng He</a>, 
<a href="/search/cs?searchtype=author&query=Pan%2C+X">Xianfei Pan</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+C">Changhao Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages, 8 figures, in submission
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Robotics (cs.RO)

</div>
</div>
</dd>
<dt><a name="item964">[964]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2211.10245" title="Abstract">arXiv:2211.10245</a> (replaced) [<a href="/pdf/2211.10245" title="Download PDF">pdf</a>, <a href="/format/2211.10245" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the inadequacy of nominal assortativity for assessing homophily in  networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Karimi%2C+F">Fariba Karimi</a>, 
<a href="/search/physics?searchtype=author&query=Oliveira%2C+M">Marcos Oliveira</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 19 pages, 3 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Physics and Society (physics.soc-ph)</span>; Computers and Society (cs.CY); Social and Information Networks (cs.SI); Data Analysis, Statistics and Probability (physics.data-an); Methodology (stat.ME)

</div>
</div>
</dd>
<dt><a name="item965">[965]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2211.10437" title="Abstract">arXiv:2211.10437</a> (replaced) [<a href="/pdf/2211.10437" title="Download PDF">pdf</a>, <a href="/format/2211.10437" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Structure-Guided Diffusion Model for Large-Hole Image Completion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Horita%2C+D">Daichi Horita</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+J">Jiaolong Yang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+D">Dong Chen</a>, 
<a href="/search/cs?searchtype=author&query=Koyama%2C+Y">Yuki Koyama</a>, 
<a href="/search/cs?searchtype=author&query=Aizawa%2C+K">Kiyoharu Aizawa</a>, 
<a href="/search/cs?searchtype=author&query=Sebe%2C+N">Nicu Sebe</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> BMVC2023. Code: <a href="https://github.com/UdonDa/Structure_Guided_Diffusion_Model">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item966">[966]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2211.10443" title="Abstract">arXiv:2211.10443</a> (replaced) [<a href="/pdf/2211.10443" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Social media mining for toxicovigilance of prescription medications:  End-to-end pipeline, challenges and future work
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sarker%2C+A">Abeed Sarker</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item967">[967]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2211.11750" title="Abstract">arXiv:2211.11750</a> (replaced) [<a href="/pdf/2211.11750" title="Download PDF">pdf</a>, <a href="/format/2211.11750" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Reconstructing high-order sequence features of dynamic functional  connectivity networks based on diversified covert attention patterns for  Alzheimer&#x27;s disease classification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Zhang%2C+Z">Zhixiang Zhang</a>, 
<a href="/search/eess?searchtype=author&query=Jie%2C+B">Biao Jie</a>, 
<a href="/search/eess?searchtype=author&query=Wang%2C+Z">Zhengdong Wang</a>, 
<a href="/search/eess?searchtype=author&query=Zhou%2C+J">Jie Zhou</a>, 
<a href="/search/eess?searchtype=author&query=Yang%2C+Y">Yang Yang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV); Neurons and Cognition (q-bio.NC)

</div>
</div>
</dd>
<dt><a name="item968">[968]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2211.12222" title="Abstract">arXiv:2211.12222</a> (replaced) [<a href="/pdf/2211.12222" title="Download PDF">pdf</a>, <a href="/format/2211.12222" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Event Transformer+. A multi-purpose solution for efficient event data  processing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sabater%2C+A">Alberto Sabater</a>, 
<a href="/search/cs?searchtype=author&query=Montesano%2C+L">Luis Montesano</a>, 
<a href="/search/cs?searchtype=author&query=Murillo%2C+A+C">Ana C. Murillo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: text overlap with <a href="/abs/2204.03355">arXiv:2204.03355</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item969">[969]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2211.12506" title="Abstract">arXiv:2211.12506</a> (replaced) [<a href="/pdf/2211.12506" title="Download PDF">pdf</a>, <a href="/format/2211.12506" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Dynamic Loss For Robust Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jiang%2C+S">Shenwang Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jianan Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jizhou Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Ying Wang</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+T">Tingfa Xu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item970">[970]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2211.15398" title="Abstract">arXiv:2211.15398</a> (replaced) [<a href="/pdf/2211.15398" title="Download PDF">pdf</a>, <a href="/format/2211.15398" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Leveraging per Image-Token Consistency for Vision-Language Pre-training
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gou%2C+Y">Yunhao Gou</a>, 
<a href="/search/cs?searchtype=author&query=Ko%2C+T">Tom Ko</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+H">Hansi Yang</a>, 
<a href="/search/cs?searchtype=author&query=Kwok%2C+J">James Kwok</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yu Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+M">Mingxuan Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by CVPR 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item971">[971]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2211.15643" title="Abstract">arXiv:2211.15643</a> (replaced) [<a href="/pdf/2211.15643" title="Download PDF">pdf</a>, <a href="/format/2211.15643" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A posteriori error bounds for the block-Lanczos method for matrix  function approximation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Xu%2C+Q">Qichen Xu</a>, 
<a href="/search/math?searchtype=author&query=Chen%2C+T">Tyler Chen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
</div>
</dd>
<dt><a name="item972">[972]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2211.17096" title="Abstract">arXiv:2211.17096</a> (replaced) [<a href="/pdf/2211.17096" title="Download PDF">pdf</a>, <a href="/ps/2211.17096" title="Download PostScript">ps</a>, <a href="/format/2211.17096" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PAC Verification of Statistical Algorithms
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Mutreja%2C+S">Saachi Mutreja</a>, 
<a href="/search/stat?searchtype=author&query=Shafer%2C+J">Jonathan Shafer</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> The 36th Annual Conference on Learning Theory, COLT 2023, 12-15
  July 2023. Vol. 195. Proceedings of Machine Learning Research. PMLR, 2023,
  pp. 5021-5043
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item973">[973]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2212.00219" title="Abstract">arXiv:2212.00219</a> (replaced) [<a href="/pdf/2212.00219" title="Download PDF">pdf</a>, <a href="/format/2212.00219" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Are you using test log-likelihood correctly?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Deshpande%2C+S+K">Sameer K. Deshpande</a>, 
<a href="/search/stat?searchtype=author&query=Ghosh%2C+S">Soumya Ghosh</a>, 
<a href="/search/stat?searchtype=author&query=Nguyen%2C+T+D">Tin D. Nguyen</a>, 
<a href="/search/stat?searchtype=author&query=Broderick%2C+T">Tamara Broderick</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Presented at the ICBINB Workshop at NeurIPS 2022
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG); Other Statistics (stat.OT)

</div>
</div>
</dd>
<dt><a name="item974">[974]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2212.00296" title="Abstract">arXiv:2212.00296</a> (replaced) [<a href="/pdf/2212.00296" title="Download PDF">pdf</a>, <a href="/format/2212.00296" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning Markov Random Fields for Combinatorial Structures via Sampling  through Lov&#xe1;sz Local Lemma
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jiang%2C+N">Nan Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Gu%2C+Y">Yi Gu</a>, 
<a href="/search/cs?searchtype=author&query=Xue%2C+Y">Yexiang Xue</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> accepted by AAAI 2023. The first two authors contribute equally
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item975">[975]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2212.01381" title="Abstract">arXiv:2212.01381</a> (replaced) [<a href="/pdf/2212.01381" title="Download PDF">pdf</a>, <a href="/format/2212.01381" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LatentSwap3D: Semantic Edits on 3D Image GANs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Simsar%2C+E">Enis Simsar</a>, 
<a href="/search/cs?searchtype=author&query=Tonioni%2C+A">Alessio Tonioni</a>, 
<a href="/search/cs?searchtype=author&query=%C3%96rnek%2C+E+P">Evin P&#x131;nar &#xd6;rnek</a>, 
<a href="/search/cs?searchtype=author&query=Tombari%2C+F">Federico Tombari</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> The paper has been accepted by ICCV'23 AI3DCC
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item976">[976]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2212.05343" title="Abstract">arXiv:2212.05343</a> (replaced) [<a href="/pdf/2212.05343" title="Download PDF">pdf</a>, <a href="/ps/2212.05343" title="Download PostScript">ps</a>, <a href="/format/2212.05343" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Space-time virtual elements for the heat equation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=G%C3%B3mez%2C+S">Sergio G&#xf3;mez</a>, 
<a href="/search/math?searchtype=author&query=Mascotto%2C+L">Lorenzo Mascotto</a>, 
<a href="/search/math?searchtype=author&query=Moiola%2C+A">Andrea Moiola</a>, 
<a href="/search/math?searchtype=author&query=Perugia%2C+I">Ilaria Perugia</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
</div>
</dd>
<dt><a name="item977">[977]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2212.07090" title="Abstract">arXiv:2212.07090</a> (replaced) [<a href="/pdf/2212.07090" title="Download PDF">pdf</a>, <a href="/format/2212.07090" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Database Matching Under Adversarial Column Deletions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bakirtas%2C+S">Serhat Bakirtas</a>, 
<a href="/search/cs?searchtype=author&query=Erkip%2C+E">Elza Erkip</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>

</div>
</div>
</dd>
<dt><a name="item978">[978]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2212.08059" title="Abstract">arXiv:2212.08059</a> (replaced) [<a href="/pdf/2212.08059" title="Download PDF">pdf</a>, <a href="/format/2212.08059" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Rethinking Vision Transformers for MobileNet Size and Speed
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yanyu Li</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+J">Ju Hu</a>, 
<a href="/search/cs?searchtype=author&query=Wen%2C+Y">Yang Wen</a>, 
<a href="/search/cs?searchtype=author&query=Evangelidis%2C+G">Georgios Evangelidis</a>, 
<a href="/search/cs?searchtype=author&query=Salahi%2C+K">Kamyar Salahi</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yanzhi Wang</a>, 
<a href="/search/cs?searchtype=author&query=Tulyakov%2C+S">Sergey Tulyakov</a>, 
<a href="/search/cs?searchtype=author&query=Ren%2C+J">Jian Ren</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Code is available at: <a href="https://github.com/snap-research/EfficientFormer">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item979">[979]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2212.10230" title="Abstract">arXiv:2212.10230</a> (replaced) [<a href="/pdf/2212.10230" title="Download PDF">pdf</a>, <a href="/format/2212.10230" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Comprehensive Study and Comparison of the Robustness of 3D Object  Detectors Against Adversarial Attacks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yifan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Hou%2C+J">Junhui Hou</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+Y">Yixuan Yuan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 30 pages, 14 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item980">[980]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2212.10313" title="Abstract">arXiv:2212.10313</a> (replaced) [<a href="/pdf/2212.10313" title="Download PDF">pdf</a>, <a href="/format/2212.10313" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Beyond Triplet: Leveraging the Most Data for Multimodal Machine  Translation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhu%2C+Y">Yaoming Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+Z">Zewei Sun</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+S">Shanbo Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+L">Luyang Huang</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+L">Liwei Wu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+M">Mingxuan Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, ACL 2023 Finding
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item981">[981]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2212.11613" title="Abstract">arXiv:2212.11613</a> (replaced) [<a href="/pdf/2212.11613" title="Download PDF">pdf</a>, <a href="/format/2212.11613" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DDColor: Towards Photo-Realistic Image Colorization via Dual Decoders
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kang%2C+X">Xiaoyang Kang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+T">Tao Yang</a>, 
<a href="/search/cs?searchtype=author&query=Ouyang%2C+W">Wenqi Ouyang</a>, 
<a href="/search/cs?searchtype=author&query=Ren%2C+P">Peiran Ren</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+L">Lingzhi Li</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+X">Xuansong Xie</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ICCV 2023; Code: <a href="https://github.com/piddnad/DDColor">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item982">[982]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2212.11653" title="Abstract">arXiv:2212.11653</a> (replaced) [<a href="/pdf/2212.11653" title="Download PDF">pdf</a>, <a href="/ps/2212.11653" title="Download PostScript">ps</a>, <a href="/format/2212.11653" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Parameterizing Path Partitions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fernau%2C+H">Henning Fernau</a>, 
<a href="/search/cs?searchtype=author&query=Foucaud%2C+F">Florent Foucaud</a>, 
<a href="/search/cs?searchtype=author&query=Mann%2C+K">Kevin Mann</a>, 
<a href="/search/cs?searchtype=author&query=Padariya%2C+U">Utkarsh Padariya</a>, 
<a href="/search/cs?searchtype=author&query=N%2C+R+R+K">Rajath Rao K.N</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 27 pages, 8 figures. A short version appeared in the proceedings of the CIAC 2023 conference
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>

</div>
</div>
</dd>
<dt><a name="item983">[983]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2212.11777" title="Abstract">arXiv:2212.11777</a> (replaced) [<a href="/pdf/2212.11777" title="Download PDF">pdf</a>, <a href="/format/2212.11777" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Dataset of Pathloss and ToA Radio Maps With Localization Application
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yapar%2C+%C3%87">&#xc7;a&#x11f;kan Yapar</a>, 
<a href="/search/cs?searchtype=author&query=Levie%2C+R">Ron Levie</a>, 
<a href="/search/cs?searchtype=author&query=Kutyniok%2C+G">Gitta Kutyniok</a>, 
<a href="/search/cs?searchtype=author&query=Caire%2C+G">Giuseppe Caire</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>; Machine Learning (cs.LG); Signal Processing (eess.SP)

</div>
</div>
</dd>
<dt><a name="item984">[984]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2212.12196" title="Abstract">arXiv:2212.12196</a> (replaced) [<a href="/pdf/2212.12196" title="Download PDF">pdf</a>, <a href="/format/2212.12196" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Manipulator-Assisted Multiple UAV Landing System for USV Subject to  Disturbance
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+R">Ruoyu Xu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+C">Chongfeng Liu</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+Z">Zhongzhong Cao</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yuquan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Qian%2C+H">Huihuan Qian</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
</div>
</dd>
<dt><a name="item985">[985]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2212.14214" title="Abstract">arXiv:2212.14214</a> (replaced) [<a href="/pdf/2212.14214" title="Download PDF">pdf</a>, <a href="/format/2212.14214" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Backward Curriculum Reinforcement Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ko%2C+K">KyungMin Ko</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> In the proceedings of the 32nd IEEE International Conference on Robot and Human Interactive Communication (IEEE RO-MAN 2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item986">[986]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2212.14306" title="Abstract">arXiv:2212.14306</a> (replaced) [<a href="/pdf/2212.14306" title="Download PDF">pdf</a>, <a href="/format/2212.14306" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Foreground-Background Separation through Concept Distillation from  Generative Image Foundation Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dombrowski%2C+M">Mischa Dombrowski</a>, 
<a href="/search/cs?searchtype=author&query=Reynaud%2C+H">Hadrien Reynaud</a>, 
<a href="/search/cs?searchtype=author&query=Baugh%2C+M">Matthew Baugh</a>, 
<a href="/search/cs?searchtype=author&query=Kainz%2C+B">Bernhard Kainz</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at ICCV2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item987">[987]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.00743" title="Abstract">arXiv:2301.00743</a> (replaced) [<a href="/pdf/2301.00743" title="Download PDF">pdf</a>, <a href="/ps/2301.00743" title="Download PostScript">ps</a>, <a href="/format/2301.00743" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Computing square roots in quaternion algebras
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Koprowski%2C+P">Przemys&#x142;aw Koprowski</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Minor changes requested by the reviewers
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Symbolic Computation (cs.SC)</span>; Rings and Algebras (math.RA)

</div>
</div>
</dd>
<dt><a name="item988">[988]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.00955" title="Abstract">arXiv:2301.00955</a> (replaced) [<a href="/pdf/2301.00955" title="Download PDF">pdf</a>, <a href="/format/2301.00955" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Differentially Private Federated Clustering over Non-IID Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yiwei Li</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Shuai Wang</a>, 
<a href="/search/cs?searchtype=author&query=Chi%2C+C">Chong-Yung Chi</a>, 
<a href="/search/cs?searchtype=author&query=Quek%2C+T+Q+S">Tony Q. S. Quek</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 31 pages, 4 figures, 1 table
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>

</div>
</div>
</dd>
<dt><a name="item989">[989]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.01635" title="Abstract">arXiv:2301.01635</a> (replaced) [<a href="/pdf/2301.01635" title="Download PDF">pdf</a>, <a href="/format/2301.01635" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SPTS v2: Single-Point Scene Text Spotting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yuliang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jiaxin Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+D">Dezhi Peng</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+M">Mingxin Huang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xinyu Wang</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+J">Jingqun Tang</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+C">Can Huang</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+D">Dahua Lin</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+C">Chunhua Shen</a>, 
<a href="/search/cs?searchtype=author&query=Bai%2C+X">Xiang Bai</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+L">Lianwen Jin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted for publication in TPAMI 2023. arXiv admin note: text overlap with <a href="/abs/2112.07917">arXiv:2112.07917</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item990">[990]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.01661" title="Abstract">arXiv:2301.01661</a> (replaced) [<a href="/pdf/2301.01661" title="Download PDF">pdf</a>, <a href="/format/2301.01661" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> RecRecNet: Rectangling Rectified Wide-Angle Images by Thin-Plate Spline  Model and DoF-based Curriculum Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liao%2C+K">Kang Liao</a>, 
<a href="/search/cs?searchtype=author&query=Nie%2C+L">Lang Nie</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+C">Chunyu Lin</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+Z">Zishuo Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Y">Yao Zhao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to ICCV 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item991">[991]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.02714" title="Abstract">arXiv:2301.02714</a> (replaced) [<a href="/pdf/2301.02714" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Deep Reinforcement Learning-Based Controller for  Magnetorheological-Damped Vehicle Suspension
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=BabaAhmadi%2C+A">AmirReza BabaAhmadi</a>, 
<a href="/search/eess?searchtype=author&query=ShariatPanahi%2C+M">Masoud ShariatPanahi</a>, 
<a href="/search/eess?searchtype=author&query=Ayati%2C+M">Moosa Ayati</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 19 pages , 9 figures , 5 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
</div>
</dd>
<dt><a name="item992">[992]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.02735" title="Abstract">arXiv:2301.02735</a> (replaced) [<a href="/pdf/2301.02735" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Designing an Improved Deep Learning-based Model for COVID-19 Recognition  in Chest X-ray Images: A Knowledge Distillation Approach
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=BabaAhmadi%2C+A">AmirReza BabaAhmadi</a>, 
<a href="/search/eess?searchtype=author&query=Khalafi%2C+S">Sahar Khalafi</a>, 
<a href="/search/eess?searchtype=author&query=ShariatPanahi%2C+M">Masoud ShariatPanahi</a>, 
<a href="/search/eess?searchtype=author&query=Ayati%2C+M">Moosa Ayati</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 25 pages, 3 figures , 5 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item993">[993]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.02791" title="Abstract">arXiv:2301.02791</a> (replaced) [<a href="/pdf/2301.02791" title="Download PDF">pdf</a>, <a href="/format/2301.02791" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Faithful and Consistent Graph Neural Network Explanations with Rationale  Alignment
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhao%2C+T">Tianxiang Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+D">Dongsheng Luo</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xiang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Suhang Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> TIST2023. arXiv admin note: substantial text overlap with <a href="/abs/2205.13733">arXiv:2205.13733</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Human-Computer Interaction (cs.HC); Social and Information Networks (cs.SI)

</div>
</div>
</dd>
<dt><a name="item994">[994]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.02882" title="Abstract">arXiv:2301.02882</a> (replaced) [<a href="/pdf/2301.02882" title="Download PDF">pdf</a>, <a href="/format/2301.02882" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MLMC techniques for discontinuous functions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Giles%2C+M+B">Michael B Giles</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 15 pages, 6 figures, submitted to proceedings of MCQMC22 conference
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
</div>
</dd>
<dt><a name="item995">[995]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.03183" title="Abstract">arXiv:2301.03183</a> (replaced) [<a href="/pdf/2301.03183" title="Download PDF">pdf</a>, <a href="/format/2301.03183" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Minimax Weight Learning for Absorbing MDPs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+F">Fengyin Li</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yuqiang Li</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+X">Xianyi Wu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 36 pages, 9 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item996">[996]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.03539" title="Abstract">arXiv:2301.03539</a> (replaced) [<a href="/pdf/2301.03539" title="Download PDF">pdf</a>, <a href="/format/2301.03539" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Securely Aggregated Coded Matrix Inversion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Charalambides%2C+N">Neophytos Charalambides</a>, 
<a href="/search/cs?searchtype=author&query=Pilanci%2C+M">Mert Pilanci</a>, 
<a href="/search/cs?searchtype=author&query=Hero%2C+A">Alfred Hero</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: substantial text overlap with <a href="/abs/2207.06271">arXiv:2207.06271</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Cryptography and Security (cs.CR); Numerical Analysis (math.NA)

</div>
</div>
</dd>
<dt><a name="item997">[997]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.06662" title="Abstract">arXiv:2301.06662</a> (replaced) [<a href="/pdf/2301.06662" title="Download PDF">pdf</a>, <a href="/format/2301.06662" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Graph Topology Learning Under Privacy Constraints
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xiang Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 17 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Cryptography and Security (cs.CR); Signal Processing (eess.SP)

</div>
</div>
</dd>
<dt><a name="item998">[998]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.06838" title="Abstract">arXiv:2301.06838</a> (replaced) [<a href="/pdf/2301.06838" title="Download PDF">pdf</a>, <a href="/format/2301.06838" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Generalized Zurek&#x27;s bound on the cost of an individual classical or  quantum computation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cond-mat?searchtype=author&query=Kolchinsky%2C+A">Artemy Kolchinsky</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Statistical Mechanics (cond-mat.stat-mech)</span>; Information Theory (cs.IT); Quantum Physics (quant-ph)

</div>
</div>
</dd>
<dt><a name="item999">[999]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.07283" title="Abstract">arXiv:2301.07283</a> (replaced) [<a href="/pdf/2301.07283" title="Download PDF">pdf</a>, <a href="/format/2301.07283" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Contrastive Learning for Self-Supervised Pre-Training of Point Cloud  Segmentation Networks With Image Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Janda%2C+A">Andrej Janda</a>, 
<a href="/search/cs?searchtype=author&query=Wagstaff%2C+B">Brandon Wagstaff</a>, 
<a href="/search/cs?searchtype=author&query=Ng%2C+E+G">Edwin G. Ng</a>, 
<a href="/search/cs?searchtype=author&query=Kelly%2C+J">Jonathan Kelly</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> In Proceedings of the Conference on Robots and Vision (CRV'23), Montreal, Canada, Jun. 6-8, 2023. arXiv admin note: substantial text overlap with <a href="/abs/2211.11801">arXiv:2211.11801</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item1000">[1000]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.07306" title="Abstract">arXiv:2301.07306</a> (replaced) [<a href="/pdf/2301.07306" title="Download PDF">pdf</a>, <a href="/format/2301.07306" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Improve Noise Tolerance of Robust Loss via Noise-Awareness
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ding%2C+K">Kehui Ding</a>, 
<a href="/search/cs?searchtype=author&query=Shu%2C+J">Jun Shu</a>, 
<a href="/search/cs?searchtype=author&query=Meng%2C+D">Deyu Meng</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+Z">Zongben Xu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: text overlap with <a href="/abs/2002.06482">arXiv:2002.06482</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item1001">[1001]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.07849" title="Abstract">arXiv:2301.07849</a> (replaced) [<a href="/pdf/2301.07849" title="Download PDF">pdf</a>, <a href="/format/2301.07849" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Efficient Computation in Congested Anonymous Dynamic Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Di+Luna%2C+G+A">Giuseppe A. Di Luna</a>, 
<a href="/search/cs?searchtype=author&query=Viglietta%2C+G">Giovanni Viglietta</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 26 pages, 2 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>; Discrete Mathematics (cs.DM)

</div>
</div>
</dd>
<dt><a name="item1002">[1002]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.09162" title="Abstract">arXiv:2301.09162</a> (replaced) [<a href="/pdf/2301.09162" title="Download PDF">pdf</a>, <a href="/format/2301.09162" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deep Reinforcement Learning for Concentric Tube Robot Path Following
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Iyengar%2C+K">Keshav Iyengar</a>, 
<a href="/search/cs?searchtype=author&query=Spurgeon%2C+S">Sarah Spurgeon</a>, 
<a href="/search/cs?searchtype=author&query=Stoyanov%2C+D">Danail Stoyanov</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, 13 figures. Accepted to IEEE Transactions on Medical Robotics and Bionics Symposium Special Issue
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
</div>
</dd>
<dt><a name="item1003">[1003]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.09881" title="Abstract">arXiv:2301.09881</a> (replaced) [<a href="/pdf/2301.09881" title="Download PDF">pdf</a>, <a href="/format/2301.09881" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fever: Optimal Responsive View Synchronisation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lewis-Pye%2C+A">Andrew Lewis-Pye</a>, 
<a href="/search/cs?searchtype=author&query=Abraham%2C+I">Ittai Abraham</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>

</div>
</div>
</dd>
<dt><a name="item1004">[1004]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.10816" title="Abstract">arXiv:2301.10816</a> (replaced) [<a href="/pdf/2301.10816" title="Download PDF">pdf</a>, <a href="/format/2301.10816" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Into the Unknown: Assigning Reviewers to Papers with Uncertain  Affinities
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cousins%2C+C">Cyrus Cousins</a>, 
<a href="/search/cs?searchtype=author&query=Payan%2C+J">Justin Payan</a>, 
<a href="/search/cs?searchtype=author&query=Zick%2C+Y">Yair Zick</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 23 pages, 1 figure. In Proceedings of the 16th International Symposium on Algorithmic Game Theory (SAGT). For associated code and data, see <a href="https://github.com/justinpayan/RAU">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>

</div>
</div>
</dd>
<dt><a name="item1005">[1005]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.11368" title="Abstract">arXiv:2301.11368</a> (replaced) [<a href="/pdf/2301.11368" title="Download PDF">pdf</a>, <a href="/format/2301.11368" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Coincident Learning for Unsupervised Anomaly Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Humble%2C+R">Ryan Humble</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zhe Zhang</a>, 
<a href="/search/cs?searchtype=author&query=O%27Shea%2C+F">Finn O&#x27;Shea</a>, 
<a href="/search/cs?searchtype=author&query=Darve%2C+E">Eric Darve</a>, 
<a href="/search/cs?searchtype=author&query=Ratner%2C+D">Daniel Ratner</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item1006">[1006]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.12047" title="Abstract">arXiv:2301.12047</a> (replaced) [<a href="/pdf/2301.12047" title="Download PDF">pdf</a>, <a href="/format/2301.12047" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Backpropagation of Unrolled Solvers with Folded Optimization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kotary%2C+J">James Kotary</a>, 
<a href="/search/cs?searchtype=author&query=Dinh%2C+M+H">My H. Dinh</a>, 
<a href="/search/cs?searchtype=author&query=Fioretto%2C+F">Ferdinando Fioretto</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Published in IJCAI
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> In International Joint Conference on Artificial Intelligence,
  2023. pp 1963--1970
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item1007">[1007]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.13120" title="Abstract">arXiv:2301.13120</a> (replaced) [<a href="/pdf/2301.13120" title="Download PDF">pdf</a>, <a href="/format/2301.13120" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Doubly Optimal No-Regret Learning in Monotone Games
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cai%2C+Y">Yang Cai</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+W">Weiqiang Zheng</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Published at ICML 2023. V2 incorporates reviewers' feedback
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Science and Game Theory (cs.GT)

</div>
</div>
</dd>
<dt><a name="item1008">[1008]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.13348" title="Abstract">arXiv:2301.13348</a> (replaced) [<a href="/pdf/2301.13348" title="Download PDF">pdf</a>, <a href="/format/2301.13348" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Reinforcement Learning Framework for Dynamic Mediation Analysis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Ge%2C+L">Lin Ge</a>, 
<a href="/search/stat?searchtype=author&query=Wang%2C+J">Jitao Wang</a>, 
<a href="/search/stat?searchtype=author&query=Shi%2C+C">Chengchun Shi</a>, 
<a href="/search/stat?searchtype=author&query=Wu%2C+Z">Zhenke Wu</a>, 
<a href="/search/stat?searchtype=author&query=Song%2C+R">Rui Song</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG); Methodology (stat.ME)

</div>
</div>
</dd>
<dt><a name="item1009">[1009]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.00162" title="Abstract">arXiv:2302.00162</a> (replaced) [<a href="/pdf/2302.00162" title="Download PDF">pdf</a>, <a href="/format/2302.00162" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Continual Segment: Towards a Single, Unified and Accessible Continual  Segmentation Model of 143 Whole-body Organs in CT Scans
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ji%2C+Z">Zhanghexuan Ji</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+D">Dazhou Guo</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+P">Puyang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+K">Ke Yan</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+L">Le Lu</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+M">Minfeng Xu</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+J">Jingren Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Q">Qifeng Wang</a>, 
<a href="/search/cs?searchtype=author&query=Ge%2C+J">Jia Ge</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+M">Mingchen Gao</a>, 
<a href="/search/cs?searchtype=author&query=Ye%2C+X">Xianghua Ye</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+D">Dakai Jin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item1010">[1010]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.01222" title="Abstract">arXiv:2302.01222</a> (replaced) [<a href="/pdf/2302.01222" title="Download PDF">pdf</a>, <a href="/format/2302.01222" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A novel automatic wind power prediction framework based on multi-time  scale and temporal attention mechanisms
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jiang%2C+M">Meiyu Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+J">Jun Shen</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+X">Xuetao Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+L">Lihui Luo</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+R">Rui Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Q">Qingguo Zhou</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item1011">[1011]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.02261" title="Abstract">arXiv:2302.02261</a> (replaced) [<a href="/pdf/2302.02261" title="Download PDF">pdf</a>, <a href="/format/2302.02261" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> NeuRI: Diversifying DNN Generation via Inductive Rule Inference
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jiawei Liu</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+J">Jinjun Peng</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yuyao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+L">Lingming Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item1012">[1012]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.02928" title="Abstract">arXiv:2302.02928</a> (replaced) [<a href="/pdf/2302.02928" title="Download PDF">pdf</a>, <a href="/format/2302.02928" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Generating Evidential BEV Maps in Continuous Driving Space
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yuan%2C+Y">Yunshuang Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+H">Hao Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+M+Y">Michael Ying Yang</a>, 
<a href="/search/cs?searchtype=author&query=Sester%2C+M">Monika Sester</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> ISPRS Journal of Photogrammetry and Remote Sensing, 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item1013">[1013]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.03023" title="Abstract">arXiv:2302.03023</a> (replaced) [<a href="/pdf/2302.03023" title="Download PDF">pdf</a>, <a href="/format/2302.03023" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> V1T: large-scale mouse V1 response prediction using a Vision Transformer
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+B+M">Bryan M. Li</a>, 
<a href="/search/cs?searchtype=author&query=Cornacchia%2C+I+M">Isabel M. Cornacchia</a>, 
<a href="/search/cs?searchtype=author&query=Rochefort%2C+N+L">Nathalie L. Rochefort</a>, 
<a href="/search/cs?searchtype=author&query=Onken%2C+A">Arno Onken</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> updated references and added link to code repository; add analysis on generalization and visualize aRFs; updated with TMLR publication
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG); Neural and Evolutionary Computing (cs.NE); Neurons and Cognition (q-bio.NC)

</div>
</div>
</dd>
<dt><a name="item1014">[1014]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.03408" title="Abstract">arXiv:2302.03408</a> (replaced) [<a href="/pdf/2302.03408" title="Download PDF">pdf</a>, <a href="/format/2302.03408" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multiple-bounce Smith Microfacet BRDFs using the Invariance Principle
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cui%2C+Y">Yuang Cui</a>, 
<a href="/search/cs?searchtype=author&query=Pan%2C+G">Gaole Pan</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+J">Jian Yang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+L">Lei Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+L">Ling-qi Yan</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+B">Beibei Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Graphics (cs.GR)</span>

</div>
</div>
</dd>
<dt><a name="item1015">[1015]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.03732" title="Abstract">arXiv:2302.03732</a> (replaced) [<a href="/pdf/2302.03732" title="Download PDF">pdf</a>, <a href="/format/2302.03732" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Adding Explicit Load-Acquire and Store-Release Instructions to the  RISC-V ISA
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Arden%2C+B">Bryce Arden</a>, 
<a href="/search/cs?searchtype=author&query=Susskind%2C+Z">Zachary Susskind</a>, 
<a href="/search/cs?searchtype=author&query=Sweeney%2C+B">Brendan Sweeney</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 7 figures, 4 listings, class project, ECE 382N-10
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Hardware Architecture (cs.AR)</span>

</div>
</div>
</dd>
<dt><a name="item1016">[1016]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.05322" title="Abstract">arXiv:2302.05322</a> (replaced) [<a href="/pdf/2302.05322" title="Download PDF">pdf</a>, <a href="/ps/2302.05322" title="Download PostScript">ps</a>, <a href="/format/2302.05322" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Numerical Methods For PDEs Over Manifolds Using Spectral Physics  Informed Neural Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zelig%2C+Y">Yuval Zelig</a>, 
<a href="/search/cs?searchtype=author&query=Dekel%2C+S">Shai Dekel</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 25 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Numerical Analysis (math.NA)

</div>
</div>
</dd>
<dt><a name="item1017">[1017]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.05543" title="Abstract">arXiv:2302.05543</a> (replaced) [<a href="/pdf/2302.05543" title="Download PDF">pdf</a>, <a href="/format/2302.05543" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Adding Conditional Control to Text-to-Image Diffusion Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+L">Lvmin Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Rao%2C+A">Anyi Rao</a>, 
<a href="/search/cs?searchtype=author&query=Agrawala%2C+M">Maneesh Agrawala</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Codes and Supplementary Material: <a href="https://github.com/lllyasviel/ControlNet">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Graphics (cs.GR); Human-Computer Interaction (cs.HC); Multimedia (cs.MM)

</div>
</div>
</dd>
<dt><a name="item1018">[1018]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.06763" title="Abstract">arXiv:2302.06763</a> (replaced) [<a href="/pdf/2302.06763" title="Download PDF">pdf</a>, <a href="/ps/2302.06763" title="Download PostScript">ps</a>, <a href="/format/2302.06763" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Breaking the Lower Bound with (Little) Structure: Acceleration in  Non-Convex Stochastic Optimization with Heavy-Tailed Noise
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zijian Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jiawei Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Z">Zhengyuan Zhou</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Optimization and Control (math.OC); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item1019">[1019]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.06800" title="Abstract">arXiv:2302.06800</a> (replaced) [<a href="/pdf/2302.06800" title="Download PDF">pdf</a>, <a href="/format/2302.06800" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Perfect divisibility and coloring of some fork-free graphs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Wu%2C+D">Di Wu</a>, 
<a href="/search/math?searchtype=author&query=Xu%2C+B">Baogang Xu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Combinatorics (math.CO)</span>; Discrete Mathematics (cs.DM)

</div>
</div>
</dd>
<dt><a name="item1020">[1020]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.07189" title="Abstract">arXiv:2302.07189</a> (replaced) [<a href="/pdf/2302.07189" title="Download PDF">pdf</a>, <a href="/format/2302.07189" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Reveal the Unknown: Out-of-Knowledge-Base Mention Discovery with Entity  Linking
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dong%2C+H">Hang Dong</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Jiaoyan Chen</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+Y">Yuan He</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yinan Liu</a>, 
<a href="/search/cs?searchtype=author&query=Horrocks%2C+I">Ian Horrocks</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages, 3 figures, accepted for CIKM 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item1021">[1021]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.07371" title="Abstract">arXiv:2302.07371</a> (replaced) [<a href="/pdf/2302.07371" title="Download PDF">pdf</a>, <a href="/format/2302.07371" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> BiasTestGPT: Using ChatGPT for Social Bias Testing of Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kocielnik%2C+R">Rafal Kocielnik</a>, 
<a href="/search/cs?searchtype=author&query=Prabhumoye%2C+S">Shrimai Prabhumoye</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+V">Vivian Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+R">Roy Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Alvarez%2C+R+M">R. Michael Alvarez</a>, 
<a href="/search/cs?searchtype=author&query=Anandkumar%2C+A">Anima Anandkumar</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Computers and Society (cs.CY)

</div>
</div>
</dd>
<dt><a name="item1022">[1022]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.07584" title="Abstract">arXiv:2302.07584</a> (replaced) [<a href="/pdf/2302.07584" title="Download PDF">pdf</a>, <a href="/format/2302.07584" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fast and Blind Speech Copy-Move Detection and Localization in Noise
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Yang%2C+D">Dong Yang</a>, 
<a href="/search/eess?searchtype=author&query=Liu%2C+M">Mingle Liu</a>, 
<a href="/search/eess?searchtype=author&query=Cao%2C+M">Muyong Cao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Information Theory (cs.IT); Sound (cs.SD); Signal Processing (eess.SP)

</div>
</div>
</dd>
<dt><a name="item1023">[1023]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.09221" title="Abstract">arXiv:2302.09221</a> (replaced) [<a href="/pdf/2302.09221" title="Download PDF">pdf</a>, <a href="/format/2302.09221" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Moby: Empowering 2D Models for Efficient Point Cloud Analytics on the  Edge
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jingzong Li</a>, 
<a href="/search/cs?searchtype=author&query=Cai%2C+Y+H">Yik Hong Cai</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+L">Libin Liu</a>, 
<a href="/search/cs?searchtype=author&query=Mao%2C+Y">Yu Mao</a>, 
<a href="/search/cs?searchtype=author&query=Xue%2C+C+J">Chun Jason Xue</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+H">Hong Xu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to ACM International Conference on Multimedia (MM) 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item1024">[1024]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.09374" title="Abstract">arXiv:2302.09374</a> (replaced) [<a href="/pdf/2302.09374" title="Download PDF">pdf</a>, <a href="/format/2302.09374" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multiscale constitutive framework of 1D blood flow modeling: Asymptotic  limits and numerical methods
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Bertaglia%2C+G">Giulia Bertaglia</a>, 
<a href="/search/math?searchtype=author&query=Pareschi%2C+L">Lorenzo Pareschi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Fluid Dynamics (physics.flu-dyn)

</div>
</div>
</dd>
<dt><a name="item1025">[1025]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.09676" title="Abstract">arXiv:2302.09676</a> (replaced) [<a href="/pdf/2302.09676" title="Download PDF">pdf</a>, <a href="/format/2302.09676" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Leveraging Prior Knowledge in Reinforcement Learning via Double-Sided  Bounds on the Value Function
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Adamczyk%2C+J">Jacob Adamczyk</a>, 
<a href="/search/cs?searchtype=author&query=Tiomkin%2C+S">Stas Tiomkin</a>, 
<a href="/search/cs?searchtype=author&query=Kulkarni%2C+R">Rahul Kulkarni</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item1026">[1026]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.11291" title="Abstract">arXiv:2302.11291</a> (replaced) [<a href="/pdf/2302.11291" title="Download PDF">pdf</a>, <a href="/format/2302.11291" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Complexity of Manipulating and Controlling Approval-Based Multiwinner  Voting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yongjie Yang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 45pages, 1figure, full version of a paper at IJCAI 2019
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>

</div>
</div>
</dd>
<dt><a name="item1027">[1027]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.11728" title="Abstract">arXiv:2302.11728</a> (replaced) [<a href="/pdf/2302.11728" title="Download PDF">pdf</a>, <a href="/format/2302.11728" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Convolutional-Transformer Network for Crack Segmentation with Boundary  Awareness
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tao%2C+H">Huaqi Tao</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+B">Bingxi Liu</a>, 
<a href="/search/cs?searchtype=author&query=Cui%2C+J">Jinqiang Cui</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Hong Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Image and Video Processing (eess.IV)

</div>
</div>
</dd>
<dt><a name="item1028">[1028]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.12601" title="Abstract">arXiv:2302.12601</a> (replaced) [<a href="/pdf/2302.12601" title="Download PDF">pdf</a>, <a href="/format/2302.12601" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> &quot;An Adapt-or-Die Type of Situation&quot;: Perception, Adoption, and Use of  Text-To-Image-Generation AI by Game Industry Professionals
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Vimpari%2C+V">Veera Vimpari</a>, 
<a href="/search/cs?searchtype=author&query=Kultima%2C+A">Annakaisa Kultima</a>, 
<a href="/search/cs?searchtype=author&query=H%C3%A4m%C3%A4l%C3%A4inen%2C+P">Perttu H&#xe4;m&#xe4;l&#xe4;inen</a>, 
<a href="/search/cs?searchtype=author&query=Guckelsberger%2C+C">Christian Guckelsberger</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 34 pages (incl. appendix), 3 figures, 4 tables. Coding template (31 pages, 10 tables), study invitations (email, social media) and pre-study survey provided as supplementary (ancillary) material. Accepted at ACM CHI Play 2023
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Proc. ACM Hum.-Comput. Interact., Vol. 7, No. CHI PLAY, 2023,
  Article 379
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item1029">[1029]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.13005" title="Abstract">arXiv:2302.13005</a> (replaced) [<a href="/pdf/2302.13005" title="Download PDF">pdf</a>, <a href="/format/2302.13005" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Accurate Gaussian Process Distance Fields with applications to  Echolocation and Mapping
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gentil%2C+C+L">Cedric Le Gentil</a>, 
<a href="/search/cs?searchtype=author&query=Ouabi%2C+O">Othmane-Latif Ouabi</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+L">Lan Wu</a>, 
<a href="/search/cs?searchtype=author&query=Pradalier%2C+C">Cedric Pradalier</a>, 
<a href="/search/cs?searchtype=author&query=Vidal-Calleja%2C+T">Teresa Vidal-Calleja</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
</div>
</dd>
<dt><a name="item1030">[1030]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.13356" title="Abstract">arXiv:2302.13356</a> (replaced) [<a href="/pdf/2302.13356" title="Download PDF">pdf</a>, <a href="/format/2302.13356" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Performance is not enough: the story told by a Rashomon quartet
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Biecek%2C+P">Przemyslaw Biecek</a>, 
<a href="/search/stat?searchtype=author&query=Baniecki%2C+H">Hubert Baniecki</a>, 
<a href="/search/stat?searchtype=author&query=Krzyzinski%2C+M">Mateusz Krzyzinski</a>, 
<a href="/search/stat?searchtype=author&query=Cook%2C+D">Dianne Cook</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG); Applications (stat.AP)

</div>
</div>
</dd>
<dt><a name="item1031">[1031]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.04508" title="Abstract">arXiv:2303.04508</a> (replaced) [<a href="/pdf/2303.04508" title="Download PDF">pdf</a>, <a href="/format/2303.04508" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> InFusionSurf: Refining Neural RGB-D Surface Reconstruction Using  Per-Frame Intrinsic Refinement and TSDF Fusion Prior Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lee%2C+S">Seunghwan Lee</a>, 
<a href="/search/cs?searchtype=author&query=Park%2C+G">Gwanmo Park</a>, 
<a href="/search/cs?searchtype=author&query=Son%2C+H">Hyewon Son</a>, 
<a href="/search/cs?searchtype=author&query=Ryu%2C+J">Jiwon Ryu</a>, 
<a href="/search/cs?searchtype=author&query=Chae%2C+H+J">Han Joo Chae</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item1032">[1032]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.04613" title="Abstract">arXiv:2303.04613</a> (replaced) [<a href="/pdf/2303.04613" title="Download PDF">pdf</a>, <a href="/ps/2303.04613" title="Download PostScript">ps</a>, <a href="/format/2303.04613" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Descriptive Complexity of Graph Neural Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Grohe%2C+M">Martin Grohe</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>; Computational Complexity (cs.CC); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item1033">[1033]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.05367" title="Abstract">arXiv:2303.05367</a> (replaced) [<a href="/pdf/2303.05367" title="Download PDF">pdf</a>, <a href="/format/2303.05367" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Rethinking Range View Representation for LiDAR Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kong%2C+L">Lingdong Kong</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Youquan Liu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+R">Runnan Chen</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+Y">Yuexin Ma</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+X">Xinge Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yikang Li</a>, 
<a href="/search/cs?searchtype=author&query=Hou%2C+Y">Yuenan Hou</a>, 
<a href="/search/cs?searchtype=author&query=Qiao%2C+Y">Yu Qiao</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Ziwei Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ICCV 2023; 24 pages, 10 figures, 14 tables; Webpage at <a href="https://ldkong.com/RangeFormer">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Robotics (cs.RO)

</div>
</div>
</dd>
<dt><a name="item1034">[1034]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.07271" title="Abstract">arXiv:2303.07271</a> (replaced) [<a href="/pdf/2303.07271" title="Download PDF">pdf</a>, <a href="/format/2303.07271" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Provably Convergent Plug-and-Play Quasi-Newton Methods
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Tan%2C+H+Y">Hong Ye Tan</a>, 
<a href="/search/math?searchtype=author&query=Mukherjee%2C+S">Subhadip Mukherjee</a>, 
<a href="/search/math?searchtype=author&query=Tang%2C+J">Junqi Tang</a>, 
<a href="/search/math?searchtype=author&query=Sch%C3%B6nlieb%2C+C">Carola-Bibiane Sch&#xf6;nlieb</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item1035">[1035]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.07891" title="Abstract">arXiv:2303.07891</a> (replaced) [<a href="/pdf/2303.07891" title="Download PDF">pdf</a>, <a href="/ps/2303.07891" title="Download PostScript">ps</a>, <a href="/format/2303.07891" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PRISMA: A Novel Approach for Deriving Probabilistic Surrogate Safety  Measures for Risk Evaluation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=de+Gelder%2C+E">Erwin de Gelder</a>, 
<a href="/search/cs?searchtype=author&query=Adjenughwure%2C+K">Kingsley Adjenughwure</a>, 
<a href="/search/cs?searchtype=author&query=Manders%2C+J">Jeroen Manders</a>, 
<a href="/search/cs?searchtype=author&query=Snijders%2C+R">Ron Snijders</a>, 
<a href="/search/cs?searchtype=author&query=Paardekooper%2C+J">Jan-Pieter Paardekooper</a>, 
<a href="/search/cs?searchtype=author&query=Camp%2C+O+O+d">Olaf Op den Camp</a>, 
<a href="/search/cs?searchtype=author&query=Tejada%2C+A">Arturo Tejada</a>, 
<a href="/search/cs?searchtype=author&query=De+Schutter%2C+B">Bart De Schutter</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted for publication in Accident Analysis &amp; Prevention. 28 pages, 5 figures, 1 table
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
</div>
</dd>
<dt><a name="item1036">[1036]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.08161" title="Abstract">arXiv:2303.08161</a> (replaced) [<a href="/pdf/2303.08161" title="Download PDF">pdf</a>, <a href="/ps/2303.08161" title="Download PostScript">ps</a>, <a href="/format/2303.08161" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Normal Form Bisimulations By Value
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Accattoli%2C+B">Beniamino Accattoli</a>, 
<a href="/search/cs?searchtype=author&query=Lancelot%2C+A">Adrienne Lancelot</a>, 
<a href="/search/cs?searchtype=author&query=Faggian%2C+C">Claudia Faggian</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Rewritten version (deleted toy similarity and explained proof method on naive similarity) -- Submitted to POPL24
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>; Programming Languages (cs.PL)

</div>
</div>
</dd>
<dt><a name="item1037">[1037]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.08644" title="Abstract">arXiv:2303.08644</a> (replaced) [<a href="/pdf/2303.08644" title="Download PDF">pdf</a>, <a href="/format/2303.08644" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Feature propagation as self-supervision signals on graphs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pina%2C+O">Oscar Pina</a>, 
<a href="/search/cs?searchtype=author&query=Vilaplana%2C+V">Ver&#xf3;nica Vilaplana</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 pages, 1 figure, preprint
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item1038">[1038]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.08665" title="Abstract">arXiv:2303.08665</a> (replaced) [<a href="/pdf/2303.08665" title="Download PDF">pdf</a>, <a href="/format/2303.08665" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Cross-resolution Face Recognition via Identity-Preserving Network and  Knowledge Distillation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lu%2C+Y">Yuhang Lu</a>, 
<a href="/search/cs?searchtype=author&query=Ebrahimi%2C+T">Touradj Ebrahimi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Image and Video Processing (eess.IV)

</div>
</div>
</dd>
<dt><a name="item1039">[1039]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.09044" title="Abstract">arXiv:2303.09044</a> (replaced) [<a href="/pdf/2303.09044" title="Download PDF">pdf</a>, <a href="/format/2303.09044" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CoLo-CAM: Class Activation Mapping for Object Co-Localization in  Weakly-Labeled Unconstrained Videos
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Belharbi%2C+S">Soufiane Belharbi</a>, 
<a href="/search/cs?searchtype=author&query=Murtaza%2C+S">Shakeeb Murtaza</a>, 
<a href="/search/cs?searchtype=author&query=Pedersoli%2C+M">Marco Pedersoli</a>, 
<a href="/search/cs?searchtype=author&query=Ayed%2C+I+B">Ismail Ben Ayed</a>, 
<a href="/search/cs?searchtype=author&query=McCaffrey%2C+L">Luke McCaffrey</a>, 
<a href="/search/cs?searchtype=author&query=Granger%2C+E">Eric Granger</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 pages, 8 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item1040">[1040]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.10076" title="Abstract">arXiv:2303.10076</a> (replaced) [<a href="/pdf/2303.10076" title="Download PDF">pdf</a>, <a href="/format/2303.10076" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Simple Attempt for 3D Occupancy Estimation in Autonomous Driving
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gan%2C+W">Wanshui Gan</a>, 
<a href="/search/cs?searchtype=author&query=Mo%2C+N">Ningkai Mo</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+H">Hongbin Xu</a>, 
<a href="/search/cs?searchtype=author&query=Yokoya%2C+N">Naoto Yokoya</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item1041">[1041]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.11196" title="Abstract">arXiv:2303.11196</a> (replaced) [<a href="/pdf/2303.11196" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Bridging the Global Divide in AI Regulation: A Proposal for a  Contextual, Coherent, and Commensurable Framework
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Park%2C+S">Sangchul Park</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computers and Society (cs.CY)

</div>
</div>
</dd>
<dt><a name="item1042">[1042]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.11910" title="Abstract">arXiv:2303.11910</a> (replaced) [<a href="/pdf/2303.11910" title="Download PDF">pdf</a>, <a href="/format/2303.11910" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> 360BEV: Panoramic Semantic Mapping for Indoor Bird&#x27;s-Eye View
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Teng%2C+Z">Zhifeng Teng</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jiaming Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+K">Kailun Yang</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+K">Kunyu Peng</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+H">Hao Shi</a>, 
<a href="/search/cs?searchtype=author&query=Rei%C3%9F%2C+S">Simon Rei&#xdf;</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+K">Ke Cao</a>, 
<a href="/search/cs?searchtype=author&query=Stiefelhagen%2C+R">Rainer Stiefelhagen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Code and datasets are available at the project page: <a href="https://jamycheung.github.io/360BEV.html.">this https URL</a> Accepted to WACV 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item1043">[1043]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.12123" title="Abstract">arXiv:2303.12123</a> (replaced) [<a href="/pdf/2303.12123" title="Download PDF">pdf</a>, <a href="/format/2303.12123" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Oral-3Dv2: 3D Oral Reconstruction from Panoramic X-Ray Imaging with  Implicit Neural Representation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Song%2C+W">Weinan Song</a>, 
<a href="/search/eess?searchtype=author&query=Zheng%2C+H">Haoxin Zheng</a>, 
<a href="/search/eess?searchtype=author&query=Tu%2C+D">Dezhan Tu</a>, 
<a href="/search/eess?searchtype=author&query=Liang%2C+C">Chengwen Liang</a>, 
<a href="/search/eess?searchtype=author&query=He%2C+L">Lei He</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item1044">[1044]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.12243" title="Abstract">arXiv:2303.12243</a> (replaced) [<a href="/pdf/2303.12243" title="Download PDF">pdf</a>, <a href="/format/2303.12243" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Zero-Sum Games between Mean-Field Teams: A Common Information and  Reachability based Analysis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Guan%2C+Y">Yue Guan</a>, 
<a href="/search/eess?searchtype=author&query=Afshari%2C+M">Mohammad Afshari</a>, 
<a href="/search/eess?searchtype=author&query=Tsiotras%2C+P">Panagiotis Tsiotras</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
</div>
</dd>
<dt><a name="item1045">[1045]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.12671" title="Abstract">arXiv:2303.12671</a> (replaced) [<a href="/pdf/2303.12671" title="Download PDF">pdf</a>, <a href="/format/2303.12671" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Integrating Image Features with Convolutional Sequence-to-sequence  Network for Multilingual Visual Question Answering
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Thai%2C+T+M">Triet Minh Thai</a>, 
<a href="/search/cs?searchtype=author&query=Luu%2C+S+T">Son T. Luu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> VLSP2022-EVJVQA
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Computation and Language (cs.CL)

</div>
</div>
</dd>
<dt><a name="item1046">[1046]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.12937" title="Abstract">arXiv:2303.12937</a> (replaced) [<a href="/pdf/2303.12937" title="Download PDF">pdf</a>, <a href="/format/2303.12937" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Wireless Network Demands of Data Products from Small Uncrewed Aerial  Systems at Hurricane Ian
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Manzini%2C+T">Thomas Manzini</a>, 
<a href="/search/cs?searchtype=author&query=Murphy%2C+R">Robin Murphy</a>, 
<a href="/search/cs?searchtype=author&query=Merrick%2C+D">David Merrick</a>, 
<a href="/search/cs?searchtype=author&query=Adams%2C+J">Justin Adams</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages, 8 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Networking and Internet Architecture (cs.NI)

</div>
</div>
</dd>
<dt><a name="item1047">[1047]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.13148" title="Abstract">arXiv:2303.13148</a> (replaced) [<a href="/pdf/2303.13148" title="Download PDF">pdf</a>, <a href="/format/2303.13148" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Calibrated Out-of-Distribution Detection with a Generic Representation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Vojir%2C+T">Tomas Vojir</a>, 
<a href="/search/cs?searchtype=author&query=Sochman%2C+J">Jan Sochman</a>, 
<a href="/search/cs?searchtype=author&query=Aljundi%2C+R">Rahaf Aljundi</a>, 
<a href="/search/cs?searchtype=author&query=Matas%2C+J">Jiri Matas</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, accepted to Workshop on Uncertainty Quantification for Computer Vision, ICCV 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item1048">[1048]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.13396" title="Abstract">arXiv:2303.13396</a> (replaced) [<a href="/pdf/2303.13396" title="Download PDF">pdf</a>, <a href="/format/2303.13396" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Zero-guidance Segmentation Using Zero Segment Labels
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rewatbowornwong%2C+P">Pitchaporn Rewatbowornwong</a>, 
<a href="/search/cs?searchtype=author&query=Chatthee%2C+N">Nattanat Chatthee</a>, 
<a href="/search/cs?searchtype=author&query=Chuangsuwanich%2C+E">Ekapol Chuangsuwanich</a>, 
<a href="/search/cs?searchtype=author&query=Suwajanakorn%2C+S">Supasorn Suwajanakorn</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item1049">[1049]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.13845" title="Abstract">arXiv:2303.13845</a> (replaced) [<a href="/pdf/2303.13845" title="Download PDF">pdf</a>, <a href="/format/2303.13845" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Anomaly Detection under Distribution Shift
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cao%2C+T">Tri Cao</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+J">Jiawen Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Pang%2C+G">Guansong Pang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at ICCV 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item1050">[1050]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.15049" title="Abstract">arXiv:2303.15049</a> (replaced) [<a href="/pdf/2303.15049" title="Download PDF">pdf</a>, <a href="/format/2303.15049" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> InterviewBot: Real-Time End-to-End Dialogue System to Interview Students  for College Admission
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zihao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Keyes%2C+N">Nathan Keyes</a>, 
<a href="/search/cs?searchtype=author&query=Crawford%2C+T">Terry Crawford</a>, 
<a href="/search/cs?searchtype=author&query=Choi%2C+J+D">Jinho D. Choi</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Information 2023, 14, 460
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Human-Computer Interaction (cs.HC)

</div>
</div>
</dd>
<dt><a name="item1051">[1051]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.15082" title="Abstract">arXiv:2303.15082</a> (replaced) [<a href="/pdf/2303.15082" title="Download PDF">pdf</a>, <a href="/format/2303.15082" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A new perspective on dynamic network flow problems via port-Hamiltonian  systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Doganay%2C+O+T">Onur Tanil Doganay</a>, 
<a href="/search/math?searchtype=author&query=Klamroth%2C+K">Kathrin Klamroth</a>, 
<a href="/search/math?searchtype=author&query=Lang%2C+B">Bruno Lang</a>, 
<a href="/search/math?searchtype=author&query=Stiglmayr%2C+M">Michael Stiglmayr</a>, 
<a href="/search/math?searchtype=author&query=Totzeck%2C+C">Claudia Totzeck</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Dynamical Systems (math.DS); Numerical Analysis (math.NA)

</div>
</div>
</dd>
<dt><a name="item1052">[1052]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.15840" title="Abstract">arXiv:2303.15840</a> (replaced) [<a href="/pdf/2303.15840" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Sparse Depth-Guided Attention for Accurate Depth Completion: A  Stereo-Assisted Monitored Distillation Approach
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Guo%2C+J">Jia-Wei Guo</a>, 
<a href="/search/cs?searchtype=author&query=Chou%2C+H">Hung-Chyun Chou</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+S">Sen-Hua Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+C">Chang-Zheng Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Ouyang%2C+M">Ming Ouyang</a>, 
<a href="/search/cs?searchtype=author&query=Ding%2C+N">Ning Ding</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, 8 figures, references added
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item1053">[1053]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.15936" title="Abstract">arXiv:2303.15936</a> (replaced) [<a href="/pdf/2303.15936" title="Download PDF">pdf</a>, <a href="/format/2303.15936" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Searching for long faint astronomical high energy transients: a data  driven approach
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/astro-ph?searchtype=author&query=Crupi%2C+R">Riccardo Crupi</a>, 
<a href="/search/astro-ph?searchtype=author&query=Dilillo%2C+G">Giuseppe Dilillo</a>, 
<a href="/search/astro-ph?searchtype=author&query=Ward%2C+K">Kester Ward</a>, 
<a href="/search/astro-ph?searchtype=author&query=Bissaldi%2C+E">Elisabetta Bissaldi</a>, 
<a href="/search/astro-ph?searchtype=author&query=Fiore%2C+F">Fabrizio Fiore</a>, 
<a href="/search/astro-ph?searchtype=author&query=Vacchi%2C+A">Andrea Vacchi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">High Energy Astrophysical Phenomena (astro-ph.HE)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item1054">[1054]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.16491" title="Abstract">arXiv:2303.16491</a> (replaced) [<a href="/pdf/2303.16491" title="Download PDF">pdf</a>, <a href="/format/2303.16491" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Implicit Diffusion Models for Continuous Super-Resolution
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gao%2C+S">Sicheng Gao</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xuhui Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zeng%2C+B">Bohan Zeng</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+S">Sheng Xu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yanjing Li</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+X">Xiaoyan Luo</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jianzhuang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhen%2C+X">Xiantong Zhen</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+B">Baochang Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 9 figures, published to CVPR2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item1055">[1055]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.16535" title="Abstract">arXiv:2303.16535</a> (replaced) [<a href="/pdf/2303.16535" title="Download PDF">pdf</a>, <a href="/format/2303.16535" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Nonlinear Independent Component Analysis for Principled Disentanglement  in Unsupervised Deep Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hyvarinen%2C+A">Aapo Hyvarinen</a>, 
<a href="/search/cs?searchtype=author&query=Khemakhem%2C+I">Ilyes Khemakhem</a>, 
<a href="/search/cs?searchtype=author&query=Morioka%2C+H">Hiroshi Morioka</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Revised version, to appear in Patterns
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item1056">[1056]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.16879" title="Abstract">arXiv:2303.16879</a> (replaced) [<a href="/pdf/2303.16879" title="Download PDF">pdf</a>, <a href="/format/2303.16879" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On Lattice Constructions D and D&#x27; from q-ary Linear Codes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Silva%2C+F+d+C">Franciele do Carmo Silva</a>, 
<a href="/search/cs?searchtype=author&query=de+Souza%2C+A+P">Ana Paula de Souza</a>, 
<a href="/search/cs?searchtype=author&query=Strey%2C+E">Eleonesio Strey</a>, 
<a href="/search/cs?searchtype=author&query=Costa%2C+S+I+R">Sueli I. R. Costa</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>

</div>
</div>
</dd>
<dt><a name="item1057">[1057]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.17597" title="Abstract">arXiv:2303.17597</a> (replaced) [<a href="/pdf/2303.17597" title="Download PDF">pdf</a>, <a href="/format/2303.17597" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Robo3D: Towards Robust and Reliable 3D Perception against Corruptions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kong%2C+L">Lingdong Kong</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Youquan Liu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xin Li</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+R">Runnan Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+W">Wenwei Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Ren%2C+J">Jiawei Ren</a>, 
<a href="/search/cs?searchtype=author&query=Pan%2C+L">Liang Pan</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+K">Kai Chen</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Ziwei Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ICCV 2023; 34 pages, 26 figures, 26 tables; Code at <a href="https://github.com/ldkong1205/Robo3D">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Robotics (cs.RO)

</div>
</div>
</dd>
<dt><a name="item1058">[1058]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.17712" title="Abstract">arXiv:2303.17712</a> (replaced) [<a href="/pdf/2303.17712" title="Download PDF">pdf</a>, <a href="/format/2303.17712" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> S-VolSDF: Sparse Multi-View Stereo Regularization of Neural Implicit  Surfaces
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+H">Haoyu Wu</a>, 
<a href="/search/cs?searchtype=author&query=Graikos%2C+A">Alexandros Graikos</a>, 
<a href="/search/cs?searchtype=author&query=Samaras%2C+D">Dimitris Samaras</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ICCV 2023, Project page: <a href="https://hao-yu-wu.github.io/s-volsdf/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item1059">[1059]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.17859" title="Abstract">arXiv:2303.17859</a> (replaced) [<a href="/pdf/2303.17859" title="Download PDF">pdf</a>, <a href="/format/2303.17859" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MapFormer: Boosting Change Detection by Using Pre-change Information
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bernhard%2C+M">Maximilian Bernhard</a>, 
<a href="/search/cs?searchtype=author&query=Strau%C3%9F%2C+N">Niklas Strau&#xdf;</a>, 
<a href="/search/cs?searchtype=author&query=Schubert%2C+M">Matthias Schubert</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item1060">[1060]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.17898" title="Abstract">arXiv:2303.17898</a> (replaced) [<a href="/pdf/2303.17898" title="Download PDF">pdf</a>, <a href="/format/2303.17898" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Information-Theoretic Study of Time-Domain Energy-Saving Techniques in  Radio Access
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rottenberg%2C+F">Fran&#xe7;ois Rottenberg</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
</div>
</dd>
<dt><a name="item1061">[1061]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.00077" title="Abstract">arXiv:2304.00077</a> (replaced) [<a href="/pdf/2304.00077" title="Download PDF">pdf</a>, <a href="/ps/2304.00077" title="Download PostScript">ps</a>, <a href="/format/2304.00077" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Decentralized Attack Search and the Design of Bug Bounty Schemes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/econ?searchtype=author&query=Gersbach%2C+H">Hans Gersbach</a>, 
<a href="/search/econ?searchtype=author&query=Mamageishvili%2C+A">Akaki Mamageishvili</a>, 
<a href="/search/econ?searchtype=author&query=Pitsuwan%2C+F">Fikri Pitsuwan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Theoretical Economics (econ.TH)</span>; Computer Science and Game Theory (cs.GT)

</div>
</div>
</dd>
<dt><a name="item1062">[1062]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.00435" title="Abstract">arXiv:2304.00435</a> (replaced) [<a href="/pdf/2304.00435" title="Download PDF">pdf</a>, <a href="/format/2304.00435" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On Degeneracy Issues in Multi-parametric Programming and Critical Region  Exploration based Distributed Optimization in Smart Grid Operations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Liu%2C+H">Haitian Liu</a>, 
<a href="/search/eess?searchtype=author&query=Guo%2C+Y">Ye Guo</a>, 
<a href="/search/eess?searchtype=author&query=Liu%2C+H">Hao Liu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Optimization and Control (math.OC)

</div>
</div>
</dd>
<dt><a name="item1063">[1063]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.01055" title="Abstract">arXiv:2304.01055</a> (replaced) [<a href="/pdf/2304.01055" title="Download PDF">pdf</a>, <a href="/format/2304.01055" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Eigen-Factors an Alternating Optimization for Back-end Plane SLAM of 3D  Point Clouds
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ferrer%2C+G">Gonzalo Ferrer</a>, 
<a href="/search/cs?searchtype=author&query=Iarosh%2C+D">Dmitrii Iarosh</a>, 
<a href="/search/cs?searchtype=author&query=Kornilova%2C+A">Anastasiia Kornilova</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
</div>
</dd>
<dt><a name="item1064">[1064]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.01786" title="Abstract">arXiv:2304.01786</a> (replaced) [<a href="/pdf/2304.01786" title="Download PDF">pdf</a>, <a href="/ps/2304.01786" title="Download PostScript">ps</a>, <a href="/format/2304.01786" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Distributionally robust stability of payoff allocations in stochastic  coalitional games
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Pantazis%2C+G">George Pantazis</a>, 
<a href="/search/math?searchtype=author&query=Franci%2C+B">Barbara Franci</a>, 
<a href="/search/math?searchtype=author&query=Grammatico%2C+S">Sergio Grammatico</a>, 
<a href="/search/math?searchtype=author&query=Margellos%2C+K">Kostas Margellos</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted for publication at the IEEE Conference on Decision and Control 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Systems and Control (eess.SY)

</div>
</div>
</dd>
<dt><a name="item1065">[1065]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.02525" title="Abstract">arXiv:2304.02525</a> (replaced) [<a href="/pdf/2304.02525" title="Download PDF">pdf</a>, <a href="/format/2304.02525" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Supporting Energy-Based Learning With An Ising Machine Substrate: A Case  Study on RBM
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Vengalam%2C+U+K+R">Uday Kumar Reddy Vengalam</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yongchao Liu</a>, 
<a href="/search/cs?searchtype=author&query=Geng%2C+T">Tong Geng</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+H">Hui Wu</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+M">Michael Huang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Emerging Technologies (cs.ET)</span>

</div>
</div>
</dd>
<dt><a name="item1066">[1066]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.03590" title="Abstract">arXiv:2304.03590</a> (replaced) [<a href="/pdf/2304.03590" title="Download PDF">pdf</a>, <a href="/format/2304.03590" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Graphon Estimation in bipartite graphs with observable edge labels and  unobservable node labels
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Donier-Meroz%2C+E">Etienne Donier-Meroz</a>, 
<a href="/search/math?searchtype=author&query=Dalalyan%2C+A+S">Arnak S. Dalalyan</a>, 
<a href="/search/math?searchtype=author&query=Kramarz%2C+F">Francis Kramarz</a>, 
<a href="/search/math?searchtype=author&query=Chon%C3%A9%2C+P">Philippe Chon&#xe9;</a>, 
<a href="/search/math?searchtype=author&query=D%27Haultfoeuille%2C+X">Xavier D&#x27;Haultfoeuille</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Statistics Theory (math.ST)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item1067">[1067]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.04278" title="Abstract">arXiv:2304.04278</a> (replaced) [<a href="/pdf/2304.04278" title="Download PDF">pdf</a>, <a href="/format/2304.04278" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Point-SLAM: Dense Neural Point Cloud-based SLAM
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sandstr%C3%B6m%2C+E">Erik Sandstr&#xf6;m</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yue Li</a>, 
<a href="/search/cs?searchtype=author&query=Van+Gool%2C+L">Luc Van Gool</a>, 
<a href="/search/cs?searchtype=author&query=Oswald%2C+M+R">Martin R. Oswald</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ICCV 2023. 18 Pages, 12 Figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item1068">[1068]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.04320" title="Abstract">arXiv:2304.04320</a> (replaced) [<a href="/pdf/2304.04320" title="Download PDF">pdf</a>, <a href="/format/2304.04320" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Hybrid Automatic Repeat Request for Downlink Rate-Splitting Multiple  Access
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Loli%2C+R+C">Rafael Cerna Loli</a>, 
<a href="/search/cs?searchtype=author&query=Dizdar%2C+O">Onur Dizdar</a>, 
<a href="/search/cs?searchtype=author&query=Clerckx%2C+B">Bruno Clerckx</a>, 
<a href="/search/cs?searchtype=author&query=Popovski%2C+P">Petar Popovski</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
</div>
</dd>
<dt><a name="item1069">[1069]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.04395" title="Abstract">arXiv:2304.04395</a> (replaced) [<a href="/pdf/2304.04395" title="Download PDF">pdf</a>, <a href="/format/2304.04395" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Instance Neural Radiance Field
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yichen Liu</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+B">Benran Hu</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+J">Junkai Huang</a>, 
<a href="/search/cs?searchtype=author&query=Tai%2C+Y">Yu-Wing Tai</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+C">Chi-Keung Tang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> International Conference on Computer Vision (ICCV) 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item1070">[1070]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.04797" title="Abstract">arXiv:2304.04797</a> (replaced) [<a href="/pdf/2304.04797" title="Download PDF">pdf</a>, <a href="/format/2304.04797" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> RAPID: Enabling Fast Online Policy Learning in Dynamic Public Cloud  Environments
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Penney%2C+D">Drew Penney</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+B">Bin Li</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+L">Lizhong Chen</a>, 
<a href="/search/cs?searchtype=author&query=Sydir%2C+J+J">Jaroslaw J. Sydir</a>, 
<a href="/search/cs?searchtype=author&query=Drewek-Ossowicka%2C+A">Anna Drewek-Ossowicka</a>, 
<a href="/search/cs?searchtype=author&query=Illikkal%2C+R">Ramesh Illikkal</a>, 
<a href="/search/cs?searchtype=author&query=Tai%2C+C">Charlie Tai</a>, 
<a href="/search/cs?searchtype=author&query=Iyer%2C+R">Ravi Iyer</a>, 
<a href="/search/cs?searchtype=author&query=Herdrich%2C+A">Andrew Herdrich</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted in Neurocomputing
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Distributed, Parallel, and Cluster Computing (cs.DC); Systems and Control (eess.SY)

</div>
</div>
</dd>
<dt><a name="item1071">[1071]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.06322" title="Abstract">arXiv:2304.06322</a> (replaced) [<a href="/e-print/2304.06322" title="Download source">src</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning-based Spatial and Angular Information Separation for Light  Field Compression
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shi%2C+J">Jinglei Shi</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+Y">Yihong Xu</a>, 
<a href="/search/cs?searchtype=author&query=Guillemot%2C+C">Christine Guillemot</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> The explanation of this paper is not well organized, we hence withdraw it for avoid misleading readers
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Image and Video Processing (eess.IV)

</div>
</div>
</dd>
<dt><a name="item1072">[1072]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.06539" title="Abstract">arXiv:2304.06539</a> (replaced) [<a href="/pdf/2304.06539" title="Download PDF">pdf</a>, <a href="/ps/2304.06539" title="Download PostScript">ps</a>, <a href="/format/2304.06539" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Taxing Collaborative Software Engineering
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dorner%2C+M">Michael Dorner</a>, 
<a href="/search/cs?searchtype=author&query=Capraro%2C+M">Maximilian Capraro</a>, 
<a href="/search/cs?searchtype=author&query=Treidler%2C+O">Oliver Treidler</a>, 
<a href="/search/cs?searchtype=author&query=Kunz%2C+T">Tom-Eric Kunz</a>, 
<a href="/search/cs?searchtype=author&query=%C5%A0mite%2C+D">Darja &#x160;mite</a>, 
<a href="/search/cs?searchtype=author&query=Zabardast%2C+E">Ehsan Zabardast</a>, 
<a href="/search/cs?searchtype=author&query=Mendez%2C+D">Daniel Mendez</a>, 
<a href="/search/cs?searchtype=author&query=Wnuk%2C+K">Krzysztof Wnuk</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages; 3 figures; submitted to IEEE Software
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
</div>
</dd>
<dt><a name="item1073">[1073]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.06875" title="Abstract">arXiv:2304.06875</a> (replaced) [<a href="/pdf/2304.06875" title="Download PDF">pdf</a>, <a href="/format/2304.06875" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Research without Re-search: Maximal Update Parametrization Yields  Accurate Loss Prediction across Scales
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yao%2C+Y">Yiqun Yao</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yequan Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Code is publicly available at <a href="https://github.com/cofe-ai/Mu-scaling">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item1074">[1074]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.07485" title="Abstract">arXiv:2304.07485</a> (replaced) [<a href="/pdf/2304.07485" title="Download PDF">pdf</a>, <a href="/format/2304.07485" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Critical Sampling for Robust Evolution Operator Learning of Unknown  Dynamical Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+C">Ce Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+K">Kailiang Wu</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+Z">Zhihai He</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Numerical Analysis (math.NA)

</div>
</div>
</dd>
<dt><a name="item1075">[1075]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.08566" title="Abstract">arXiv:2304.08566</a> (replaced) [<a href="/pdf/2304.08566" title="Download PDF">pdf</a>, <a href="/format/2304.08566" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GrOVe: Ownership Verification of Graph Neural Networks using Embeddings
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Waheed%2C+A">Asim Waheed</a>, 
<a href="/search/cs?searchtype=author&query=Duddu%2C+V">Vasisht Duddu</a>, 
<a href="/search/cs?searchtype=author&query=Asokan%2C+N">N. Asokan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To appear in the IEEE Symposium on Security and Privacy, 2024. 12 pages, 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Cryptography and Security (cs.CR)

</div>
</div>
</dd>
<dt><a name="item1076">[1076]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.08600" title="Abstract">arXiv:2304.08600</a> (replaced) [<a href="/pdf/2304.08600" title="Download PDF">pdf</a>, <a href="/format/2304.08600" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> RS2G: Data-Driven Scene-Graph Extraction and Embedding for Robust  Autonomous Perception and Scenario Understanding
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Junyao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Malawade%2C+A+V">Arnav Vaibhav Malawade</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+J">Junhong Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+S">Shih-Yuan Yu</a>, 
<a href="/search/cs?searchtype=author&query=Faruque%2C+M+A+A">Mohammad Abdullah Al Faruque</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item1077">[1077]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.09823" title="Abstract">arXiv:2304.09823</a> (replaced) [<a href="/pdf/2304.09823" title="Download PDF">pdf</a>, <a href="/format/2304.09823" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Future of ChatGPT-enabled Labor Market: A Preliminary Study
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+L">Lan Chen</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+X">Xi Chen</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+S">Shiyu Wu</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yaqi Yang</a>, 
<a href="/search/cs?searchtype=author&query=Chang%2C+M">Meng Chang</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+H">Hengshu Zhu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item1078">[1078]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.10701" title="Abstract">arXiv:2304.10701</a> (replaced) [<a href="/pdf/2304.10701" title="Download PDF">pdf</a>, <a href="/format/2304.10701" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GMValuator: Similarity-based Data Valuation for Generative Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+J">Jiaxi Yang</a>, 
<a href="/search/cs?searchtype=author&query=Deng%2C+W">Wenglong Deng</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+B">Benlin Liu</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+Y">Yangsibo Huang</a>, 
<a href="/search/cs?searchtype=author&query=Zou%2C+J">James Zou</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xiaoxiao Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item1079">[1079]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.10835" title="Abstract">arXiv:2304.10835</a> (replaced) [<a href="/pdf/2304.10835" title="Download PDF">pdf</a>, <a href="/format/2304.10835" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A numerical method for the stability analysis of linear age-structured  models with nonlocal diffusion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Breda%2C+D">Dimitri Breda</a>, 
<a href="/search/math?searchtype=author&query=De+Reggi%2C+S">Simone De Reggi</a>, 
<a href="/search/math?searchtype=author&query=Vermiglio%2C+R">Rossana Vermiglio</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 23 pages, 11 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Dynamical Systems (math.DS)

</div>
</div>
</dd>
<dt><a name="item1080">[1080]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.10940" title="Abstract">arXiv:2304.10940</a> (replaced) [<a href="/pdf/2304.10940" title="Download PDF">pdf</a>, <a href="/ps/2304.10940" title="Download PostScript">ps</a>, <a href="/format/2304.10940" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Epistemic Selection of Costly Alternatives: The Case of Participatory  Budgeting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rey%2C+S">Simon Rey</a>, 
<a href="/search/cs?searchtype=author&query=Endriss%2C+U">Ulle Endriss</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>

</div>
</div>
</dd>
<dt><a name="item1081">[1081]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.11136" title="Abstract">arXiv:2304.11136</a> (replaced) [<a href="/pdf/2304.11136" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Integrating Per-Stream Stat Tracking into Accel-Sim
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Qiao%2C+S">Shichen Qiao</a>, 
<a href="/search/cs?searchtype=author&query=Su%2C+X">Xin Su</a>, 
<a href="/search/cs?searchtype=author&query=Sinclair%2C+M+D">Matthew D. Sinclair</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Hardware Architecture (cs.AR)</span>; Performance (cs.PF)

</div>
</div>
</dd>
<dt><a name="item1082">[1082]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.11284" title="Abstract">arXiv:2304.11284</a> (replaced) [<a href="/pdf/2304.11284" title="Download PDF">pdf</a>, <a href="/format/2304.11284" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Optimal Vehicle Charging in Bilevel Power-Traffic Networks via Charging  Demand Function
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Zhang%2C+Y">Yufan Zhang</a>, 
<a href="/search/eess?searchtype=author&query=Dey%2C+S">Sujit Dey</a>, 
<a href="/search/eess?searchtype=author&query=Shi%2C+Y">Yuanyuan Shi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> submitted to IEEE Transactions on Smart Grid
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
</div>
</dd>
<dt><a name="item1083">[1083]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.11335" title="Abstract">arXiv:2304.11335</a> (replaced) [<a href="/pdf/2304.11335" title="Download PDF">pdf</a>, <a href="/format/2304.11335" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Two Birds, One Stone: A Unified Framework for Joint Learning of Image  and Video Style Transfers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gu%2C+B">Bohai Gu</a>, 
<a href="/search/cs?searchtype=author&query=Fan%2C+H">Heng Fan</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+L">Libo Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Conference on International Conference on Computer Vision.(ICCV 2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item1084">[1084]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.11686" title="Abstract">arXiv:2304.11686</a> (replaced) [<a href="/pdf/2304.11686" title="Download PDF">pdf</a>, <a href="/format/2304.11686" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Nuances are the Key: Unlocking ChatGPT to Find Failure-Inducing Tests  with Differential Prompting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+T">Tsz-On Li</a>, 
<a href="/search/cs?searchtype=author&query=Zong%2C+W">Wenxi Zong</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yibo Wang</a>, 
<a href="/search/cs?searchtype=author&query=Tian%2C+H">Haoye Tian</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Ying Wang</a>, 
<a href="/search/cs?searchtype=author&query=Cheung%2C+S">Shing-Chi Cheung</a>, 
<a href="/search/cs?searchtype=author&query=Kramer%2C+J">Jeff Kramer</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to the 38th IEEE/ACM International Conference on Automated Software Engineering (ASE 2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
</div>
</dd>
<dt><a name="item1085">[1085]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.12737" title="Abstract">arXiv:2304.12737</a> (replaced) [<a href="/pdf/2304.12737" title="Download PDF">pdf</a>, <a href="/format/2304.12737" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> NPRL: Nightly Profile Representation Learning for Early Sepsis Onset  Prediction in ICU Trauma Patients
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Stewart%2C+T">Tucker Stewart</a>, 
<a href="/search/cs?searchtype=author&query=Stern%2C+K">Katherine Stern</a>, 
<a href="/search/cs?searchtype=author&query=O%27Keefe%2C+G">Grant O&#x27;Keefe</a>, 
<a href="/search/cs?searchtype=author&query=Teredesai%2C+A">Ankur Teredesai</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+J">Juhua Hu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item1086">[1086]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.13681" title="Abstract">arXiv:2304.13681</a> (replaced) [<a href="/pdf/2304.13681" title="Download PDF">pdf</a>, <a href="/format/2304.13681" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Ray Conditioning: Trading Photo-consistency for Photo-realism in  Multi-view Image Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+E+M">Eric Ming Chen</a>, 
<a href="/search/cs?searchtype=author&query=Holalkere%2C+S">Sidhanth Holalkere</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+R">Ruyu Yan</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+K">Kai Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Davis%2C+A">Abe Davis</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ICCV 2023 paper. Project page at <a href="https://ray-cond.github.io/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item1087">[1087]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.14185" title="Abstract">arXiv:2304.14185</a> (replaced) [<a href="/pdf/2304.14185" title="Download PDF">pdf</a>, <a href="/format/2304.14185" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ClusterNet: A Perception-Based Clustering Model for Scattered Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hartwig%2C+S">Sebastian Hartwig</a>, 
<a href="/search/cs?searchtype=author&query=van+Onzenoodt%2C+C">Christian van Onzenoodt</a>, 
<a href="/search/cs?searchtype=author&query=Hermosilla%2C+P">Pedro Hermosilla</a>, 
<a href="/search/cs?searchtype=author&query=Ropinski%2C+T">Timo Ropinski</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Currently, this manuscript is under revision at TVCG
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Human-Computer Interaction (cs.HC)

</div>
</div>
</dd>
<dt><a name="item1088">[1088]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.14389" title="Abstract">arXiv:2304.14389</a> (replaced) [<a href="/pdf/2304.14389" title="Download PDF">pdf</a>, <a href="/format/2304.14389" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SLoMo: A General System for Legged Robot Motion Imitation from Casual  Videos
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J+Z">John Z. Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+S">Shuo Yang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+G">Gengshan Yang</a>, 
<a href="/search/cs?searchtype=author&query=Bishop%2C+A+L">Arun L. Bishop</a>, 
<a href="/search/cs?searchtype=author&query=Ramanan%2C+D">Deva Ramanan</a>, 
<a href="/search/cs?searchtype=author&query=Manchester%2C+Z">Zachary Manchester</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> accepted at RA-L 2023, with ICRA 2024 option
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
</div>
</dd>
<dt><a name="item1089">[1089]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.00009" title="Abstract">arXiv:2305.00009</a> (replaced) [<a href="/pdf/2305.00009" title="Download PDF">pdf</a>, <a href="/format/2305.00009" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Reconstructing Cardiac Electrical Excitations from Optical Mapping  Recordings
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-bio?searchtype=author&query=Marcotte%2C+C+D">Christopher D. Marcotte</a>, 
<a href="/search/q-bio?searchtype=author&query=Hoffman%2C+M+J">Matthew J. Hoffman</a>, 
<a href="/search/q-bio?searchtype=author&query=Fenton%2C+F+H">Flavio H. Fenton</a>, 
<a href="/search/q-bio?searchtype=author&query=Cherry%2C+E+M">Elizabeth M. Cherry</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> main text: 18 pages, 10 figures; supplement: 5 pages, 9 figures, 2 movies
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantitative Methods (q-bio.QM)</span>; Computational Engineering, Finance, and Science (cs.CE)

</div>
</div>
</dd>
<dt><a name="item1090">[1090]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.00680" title="Abstract">arXiv:2305.00680</a> (replaced) [<a href="/pdf/2305.00680" title="Download PDF">pdf</a>, <a href="/format/2305.00680" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Noise is resource-contextual in quantum communication
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Nema%2C+A">Aditya Nema</a>, 
<a href="/search/quant-ph?searchtype=author&query=Maity%2C+A+G">Ananda G. Maity</a>, 
<a href="/search/quant-ph?searchtype=author&query=Strelchuk%2C+S">Sergii Strelchuk</a>, 
<a href="/search/quant-ph?searchtype=author&query=Elkouss%2C+D">David Elkouss</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 pages, 6 figures, Updated with additional and elaborated references. Sincere, thanks to Felix Leditzky and Stefano Pirandola for pointing out the appropriate references. Added note on general applicability of results
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Information Theory (cs.IT)

</div>
</div>
</dd>
<dt><a name="item1091">[1091]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.00967" title="Abstract">arXiv:2305.00967</a> (replaced) [<a href="/pdf/2305.00967" title="Download PDF">pdf</a>, <a href="/format/2305.00967" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Comparison of Pneumatic Actuators for Soft Growing Vine Robots
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=K%C3%BCbler%2C+A+M">Alexander M. K&#xfc;bler</a>, 
<a href="/search/cs?searchtype=author&query=Pasquier%2C+C+d">Cosima du Pasquier</a>, 
<a href="/search/cs?searchtype=author&query=Low%2C+A">Andrew Low</a>, 
<a href="/search/cs?searchtype=author&query=Djambazi%2C+B">Betim Djambazi</a>, 
<a href="/search/cs?searchtype=author&query=Aymon%2C+N">Nicolas Aymon</a>, 
<a href="/search/cs?searchtype=author&query=F%C3%B6rster%2C+J">Julian F&#xf6;rster</a>, 
<a href="/search/cs?searchtype=author&query=Agharese%2C+N">Nathaniel Agharese</a>, 
<a href="/search/cs?searchtype=author&query=Siegwart%2C+R">Roland Siegwart</a>, 
<a href="/search/cs?searchtype=author&query=Okamura%2C+A+M">Allison M. Okamura</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, 8 figures, 3 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
</div>
</dd>
<dt><a name="item1092">[1092]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.01083" title="Abstract">arXiv:2305.01083</a> (replaced) [<a href="/pdf/2305.01083" title="Download PDF">pdf</a>, <a href="/format/2305.01083" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Computationally Relaxed Locally Decodable Codes, Revisited
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Block%2C+A+R">Alexander R. Block</a> (1 and 2), 
<a href="/search/cs?searchtype=author&query=Blocki%2C+J">Jeremiah Blocki</a> (3) ((1) Georgetown University, (2) University of Maryland, College Park, (3) Purdue University)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Cryptography and Security (cs.CR)

</div>
</div>
</dd>
<dt><a name="item1093">[1093]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.01756" title="Abstract">arXiv:2305.01756</a> (replaced) [<a href="/pdf/2305.01756" title="Download PDF">pdf</a>, <a href="/format/2305.01756" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Connectivity Queries under Vertex Failures: Not Optimal, but Practical
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kosinas%2C+E">Evangelos Kosinas</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at ESA 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>

</div>
</div>
</dd>
<dt><a name="item1094">[1094]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.03122" title="Abstract">arXiv:2305.03122</a> (replaced) [<a href="/pdf/2305.03122" title="Download PDF">pdf</a>, <a href="/ps/2305.03122" title="Download PostScript">ps</a>, <a href="/format/2305.03122" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Capacity of Classical Summation over a Quantum MAC with Arbitrarily  Distributed Inputs and Entanglements
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yao%2C+Y">Yuhang Yao</a>, 
<a href="/search/cs?searchtype=author&query=Jafar%2C+S+A">Syed A. Jafar</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>

</div>
</div>
</dd>
<dt><a name="item1095">[1095]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.04063" title="Abstract">arXiv:2305.04063</a> (replaced) [<a href="/pdf/2305.04063" title="Download PDF">pdf</a>, <a href="/format/2305.04063" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exploring One-shot Semi-supervised Federated Learning with A Pre-trained  Diffusion Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+M">Mingzhao Yang</a>, 
<a href="/search/cs?searchtype=author&query=Su%2C+S">Shangchao Su</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+B">Bin Li</a>, 
<a href="/search/cs?searchtype=author&query=Xue%2C+X">Xiangyang Xue</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item1096">[1096]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.04161" title="Abstract">arXiv:2305.04161</a> (replaced) [<a href="/pdf/2305.04161" title="Download PDF">pdf</a>, <a href="/format/2305.04161" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PhysBench: A Benchmark Framework for rPPG with a New Dataset and  Baseline
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+K">Kegang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+Y">Yantao Wei</a>, 
<a href="/search/cs?searchtype=author&query=Tong%2C+M">Mingwen Tong</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+J">Jie Gao</a>, 
<a href="/search/cs?searchtype=author&query=Tian%2C+Y">Yi Tian</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+Y">YuJian Ma</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Z">ZhongJin Zhao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item1097">[1097]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.04205" title="Abstract">arXiv:2305.04205</a> (replaced) [<a href="/pdf/2305.04205" title="Download PDF">pdf</a>, <a href="/format/2305.04205" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Bi-Mapper: Holistic BEV Semantic Mapping for Autonomous Driving
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+S">Siyu Li</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+K">Kailun Yang</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+H">Hao Shi</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jiaming Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+J">Jiacheng Lin</a>, 
<a href="/search/cs?searchtype=author&query=Teng%2C+Z">Zhifeng Teng</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zhiyong Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Code is available at <a href="https://github.com/lynn-yu/Bi-Mapper">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Robotics (cs.RO); Image and Video Processing (eess.IV)

</div>
</div>
</dd>
<dt><a name="item1098">[1098]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.04334" title="Abstract">arXiv:2305.04334</a> (replaced) [<a href="/pdf/2305.04334" title="Download PDF">pdf</a>, <a href="/format/2305.04334" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Living in a Material World: Learning Material Properties from  Full-Waveform Flash Lidar Data for Semantic Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Janda%2C+A">Andrej Janda</a>, 
<a href="/search/cs?searchtype=author&query=Merriaux%2C+P">Pierre Merriaux</a>, 
<a href="/search/cs?searchtype=author&query=Olivier%2C+P">Pierre Olivier</a>, 
<a href="/search/cs?searchtype=author&query=Kelly%2C+J">Jonathan Kelly</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> In Proceedings of the Conference on Robots and Vision (CRV'23), Montreal, Canada, Jun. 6-8, 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item1099">[1099]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.04581" title="Abstract">arXiv:2305.04581</a> (replaced) [<a href="/pdf/2305.04581" title="Download PDF">pdf</a>, <a href="/format/2305.04581" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Capturing Smart Contract Design with DCR Graphs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Eshghie%2C+M">Mojtaba Eshghie</a>, 
<a href="/search/cs?searchtype=author&query=Ahrendt%2C+W">Wolfgang Ahrendt</a>, 
<a href="/search/cs?searchtype=author&query=Artho%2C+C">Cyrille Artho</a>, 
<a href="/search/cs?searchtype=author&query=Hildebrandt%2C+T+T">Thomas Troels Hildebrandt</a>, 
<a href="/search/cs?searchtype=author&query=Schneider%2C+G">Gerardo Schneider</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>; Computers and Society (cs.CY); Formal Languages and Automata Theory (cs.FL)

</div>
</div>
</dd>
<dt><a name="item1100">[1100]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.04891" title="Abstract">arXiv:2305.04891</a> (replaced) [<a href="/pdf/2305.04891" title="Download PDF">pdf</a>, <a href="/format/2305.04891" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DELTA: Dynamic Embedding Learning with Truncated Conscious Attention for  CTR Prediction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhu%2C+C">Chen Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Du%2C+L">Liang Du</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+H">Hong Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+S">Shuang Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+Z">Zixun Sun</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xin Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+W">Wenwu Zhu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item1101">[1101]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.05127" title="Abstract">arXiv:2305.05127</a> (replaced) [<a href="/pdf/2305.05127" title="Download PDF">pdf</a>, <a href="/ps/2305.05127" title="Download PostScript">ps</a>, <a href="/format/2305.05127" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Accelerated gradient descent method for functionals of probability  measures by new convexity and smoothness based on transport maps
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Tanaka%2C+K">Ken&#x27;ichiro Tanaka</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 31 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Numerical Analysis (math.NA)

</div>
</div>
</dd>
<dt><a name="item1102">[1102]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.05389" title="Abstract">arXiv:2305.05389</a> (replaced) [<a href="/pdf/2305.05389" title="Download PDF">pdf</a>, <a href="/format/2305.05389" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Two to Five Truths in Non-Negative Matrix Factorization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Conroy%2C+J+M">John M. Conroy</a>, 
<a href="/search/cs?searchtype=author&query=Molino%2C+N+P">Neil P Molino</a>, 
<a href="/search/cs?searchtype=author&query=Baughman%2C+B">Brian Baughman</a>, 
<a href="/search/cs?searchtype=author&query=Gomez%2C+R">Rod Gomez</a>, 
<a href="/search/cs?searchtype=author&query=Kaliszewski%2C+R">Ryan Kaliszewski</a>, 
<a href="/search/cs?searchtype=author&query=Lines%2C+N+A">Nicholas A. Lines</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item1103">[1103]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.06003" title="Abstract">arXiv:2305.06003</a> (replaced) [<a href="/pdf/2305.06003" title="Download PDF">pdf</a>, <a href="/format/2305.06003" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On Riccati contraction in time-varying linear-quadratic control
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Sun%2C+J">Jintao Sun</a>, 
<a href="/search/eess?searchtype=author&query=Cantoni%2C+M">Michael Cantoni</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Optimization and Control (math.OC)

</div>
</div>
</dd>
<dt><a name="item1104">[1104]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.06010" title="Abstract">arXiv:2305.06010</a> (replaced) [<a href="/pdf/2305.06010" title="Download PDF">pdf</a>, <a href="/ps/2305.06010" title="Download PostScript">ps</a>, <a href="/format/2305.06010" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On receding-horizon approximation in time-varying optimal control
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Sun%2C+J">Jintao Sun</a>, 
<a href="/search/eess?searchtype=author&query=Cantoni%2C+M">Michael Cantoni</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Optimization and Control (math.OC)

</div>
</div>
</dd>
<dt><a name="item1105">[1105]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.06044" title="Abstract">arXiv:2305.06044</a> (replaced) [<a href="/pdf/2305.06044" title="Download PDF">pdf</a>, <a href="/format/2305.06044" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Correlation visualization under missing values: a comparison between  imputation and direct parameter estimation methods
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pham%2C+N">Nhat-Hao Pham</a>, 
<a href="/search/cs?searchtype=author&query=Vo%2C+K">Khanh-Linh Vo</a>, 
<a href="/search/cs?searchtype=author&query=Vu%2C+M+A">Mai Anh Vu</a>, 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+T">Thu Nguyen</a>, 
<a href="/search/cs?searchtype=author&query=Riegler%2C+M+A">Michael A. Riegler</a>, 
<a href="/search/cs?searchtype=author&query=Halvorsen%2C+P">P&#xe5;l Halvorsen</a>, 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+B+T">Binh T. Nguyen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item1106">[1106]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.06221" title="Abstract">arXiv:2305.06221</a> (replaced) [<a href="/pdf/2305.06221" title="Download PDF">pdf</a>, <a href="/format/2305.06221" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multi-Prompt with Depth Partitioned Cross-Modal Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tian%2C+Y">Yingjie Tian</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yiqi Wang</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+X">Xianda Guo</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+Z">Zheng Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+L">Long Chen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item1107">[1107]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.06436" title="Abstract">arXiv:2305.06436</a> (replaced) [<a href="/pdf/2305.06436" title="Download PDF">pdf</a>, <a href="/format/2305.06436" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multi-Robot Coordination and Layout Design for Automated Warehousing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yulun Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Fontaine%2C+M+C">Matthew C. Fontaine</a>, 
<a href="/search/cs?searchtype=author&query=Bhatt%2C+V">Varun Bhatt</a>, 
<a href="/search/cs?searchtype=author&query=Nikolaidis%2C+S">Stefanos Nikolaidis</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jiaoyang Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to International Joint Conference on Artificial Intelligence (IJCAI), 2023. The paper can be found at IJCAI 2023 proceeding at <a href="https://www.ijcai.org/proceedings/2023/0611">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI); Neural and Evolutionary Computing (cs.NE)

</div>
</div>
</dd>
<dt><a name="item1108">[1108]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.08055" title="Abstract">arXiv:2305.08055</a> (replaced) [<a href="/pdf/2305.08055" title="Download PDF">pdf</a>, <a href="/format/2305.08055" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Dynamic Convex Hulls under Window-Sliding Updates
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Haitao Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> A previous version appeared in WADS 2023, where the query time was O(log |S|). This new version improves the query time to O(log h)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Geometry (cs.CG)</span>; Data Structures and Algorithms (cs.DS)

</div>
</div>
</dd>
<dt><a name="item1109">[1109]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.08491" title="Abstract">arXiv:2305.08491</a> (replaced) [<a href="/pdf/2305.08491" title="Download PDF">pdf</a>, <a href="/format/2305.08491" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Masked Collaborative Contrast for Weakly Supervised Semantic  Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+F">Fangwen Wu</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+J">Jingxuan He</a>, 
<a href="/search/cs?searchtype=author&query=Yin%2C+Y">Yufei Yin</a>, 
<a href="/search/cs?searchtype=author&query=Hao%2C+Y">Yanbin Hao</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+G">Gang Huang</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+L">Lechao Cheng</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> version 3.0
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item1110">[1110]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.08673" title="Abstract">arXiv:2305.08673</a> (replaced) [<a href="/pdf/2305.08673" title="Download PDF">pdf</a>, <a href="/format/2305.08673" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> aUToLights: A Robust Multi-Camera Traffic Light Detection and Tracking  System
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+S">Sean Wu</a>, 
<a href="/search/cs?searchtype=author&query=Amenta%2C+N">Nicole Amenta</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+J">Jiachen Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Papais%2C+S">Sandro Papais</a>, 
<a href="/search/cs?searchtype=author&query=Kelly%2C+J">Jonathan Kelly</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> In Proceedings of the Conference on Robots and Vision (CRV'23), Montreal, Canada, Jun. 6-8, 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Robotics (cs.RO)

</div>
</div>
</dd>
<dt><a name="item1111">[1111]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.09538" title="Abstract">arXiv:2305.09538</a> (replaced) [<a href="/pdf/2305.09538" title="Download PDF">pdf</a>, <a href="/format/2305.09538" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Local Perspective on the Polynomial Hierarchy
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Reiter%2C+F">Fabian Reiter</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 63 pages, 11 figures; v2: Additional hardness and completeness results, more examples, improved presentation
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>; Computational Complexity (cs.CC); Formal Languages and Automata Theory (cs.FL); Logic in Computer Science (cs.LO)

</div>
</div>
</dd>
<dt><a name="item1112">[1112]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.09850" title="Abstract">arXiv:2305.09850</a> (replaced) [<a href="/pdf/2305.09850" title="Download PDF">pdf</a>, <a href="/format/2305.09850" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MINT: Multiplier-less Integer Quantization for Spiking Neural Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yin%2C+R">Ruokai Yin</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yuhang Li</a>, 
<a href="/search/cs?searchtype=author&query=Moitra%2C+A">Abhishek Moitra</a>, 
<a href="/search/cs?searchtype=author&query=Panda%2C+P">Priyadarshini Panda</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages. Accepted to 29th Asia and South Pacific Design Automation Conference (ASP-DAC 2024)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neural and Evolutionary Computing (cs.NE)</span>

</div>
</div>
</dd>
<dt><a name="item1113">[1113]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.10143" title="Abstract">arXiv:2305.10143</a> (replaced) [<a href="/pdf/2305.10143" title="Download PDF">pdf</a>, <a href="/format/2305.10143" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An Empirical Study on the Language Modal in Visual Question Answering
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Peng%2C+D">Daowan Peng</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+W">Wei Wei</a>, 
<a href="/search/cs?searchtype=author&query=Mao%2C+X">Xian-Ling Mao</a>, 
<a href="/search/cs?searchtype=author&query=Fu%2C+Y">Yuanyuan Fu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+D">Dangyang Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by IJCAI2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item1114">[1114]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.10531" title="Abstract">arXiv:2305.10531</a> (replaced) [<a href="/pdf/2305.10531" title="Download PDF">pdf</a>, <a href="/format/2305.10531" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Iteratively Learning Representations for Unseen Entities with Inter-Rule  Correlations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zihan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+K">Kai Zhao</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+Y">Yongquan He</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Z">Zhumin Chen</a>, 
<a href="/search/cs?searchtype=author&query=Ren%2C+P">Pengjie Ren</a>, 
<a href="/search/cs?searchtype=author&query=de+Rijke%2C+M">Maarten de Rijke</a>, 
<a href="/search/cs?searchtype=author&query=Ren%2C+Z">Zhaochun Ren</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at CIKM 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>

</div>
</div>
</dd>
<dt><a name="item1115">[1115]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.10623" title="Abstract">arXiv:2305.10623</a> (replaced) [<a href="/pdf/2305.10623" title="Download PDF">pdf</a>, <a href="/format/2305.10623" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The star-shaped space of solutions of the spherical negative perceptron
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cond-mat?searchtype=author&query=Annesi%2C+B+L">Brandon Livio Annesi</a>, 
<a href="/search/cond-mat?searchtype=author&query=Lauditi%2C+C">Clarissa Lauditi</a>, 
<a href="/search/cond-mat?searchtype=author&query=Lucibello%2C+C">Carlo Lucibello</a>, 
<a href="/search/cond-mat?searchtype=author&query=Malatesta%2C+E+M">Enrico M. Malatesta</a>, 
<a href="/search/cond-mat?searchtype=author&query=Perugini%2C+G">Gabriele Perugini</a>, 
<a href="/search/cond-mat?searchtype=author&query=Pittorino%2C+F">Fabrizio Pittorino</a>, 
<a href="/search/cond-mat?searchtype=author&query=Saglietti%2C+L">Luca Saglietti</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 27 pages, 16 figures, comments are welcome
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Disordered Systems and Neural Networks (cond-mat.dis-nn)</span>; Machine Learning (cs.LG); Probability (math.PR); Statistics Theory (math.ST)

</div>
</div>
</dd>
<dt><a name="item1116">[1116]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.11509" title="Abstract">arXiv:2305.11509</a> (replaced) [<a href="/pdf/2305.11509" title="Download PDF">pdf</a>, <a href="/format/2305.11509" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> From Random Search to Bandit Learning in Metric Measure Spaces
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Han%2C+C">Chuying Han</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+Y">Yasong Feng</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+T">Tianyu Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item1117">[1117]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.12178" title="Abstract">arXiv:2305.12178</a> (replaced) [<a href="/pdf/2305.12178" title="Download PDF">pdf</a>, <a href="/format/2305.12178" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Model Debiasing via Gradient-based Explanation on Representation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jindi Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+L">Luning Wang</a>, 
<a href="/search/cs?searchtype=author&query=Su%2C+D">Dan Su</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+Y">Yongxiang Huang</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+C+C">Caleb Chen Cao</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+L">Lei Chen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computers and Society (cs.CY)

</div>
</div>
</dd>
<dt><a name="item1118">[1118]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.13879" title="Abstract">arXiv:2305.13879</a> (replaced) [<a href="/pdf/2305.13879" title="Download PDF">pdf</a>, <a href="/format/2305.13879" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Stochastic PDE representation of random fields for large-scale Gaussian  process regression and statistical finite element analysis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Koh%2C+K+J">Kim Jie Koh</a>, 
<a href="/search/math?searchtype=author&query=Cirak%2C+F">Fehmi Cirak</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Computational Physics (physics.comp-ph); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item1119">[1119]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.14683" title="Abstract">arXiv:2305.14683</a> (replaced) [<a href="/pdf/2305.14683" title="Download PDF">pdf</a>, <a href="/format/2305.14683" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On progressive sharpening, flat minima and generalisation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=MacDonald%2C+L+E">Lachlan Ewen MacDonald</a>, 
<a href="/search/cs?searchtype=author&query=Valmadre%2C+J">Jack Valmadre</a>, 
<a href="/search/cs?searchtype=author&query=Lucey%2C+S">Simon Lucey</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item1120">[1120]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.14730" title="Abstract">arXiv:2305.14730</a> (replaced) [<a href="/e-print/2305.14730" title="Download source">src</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> BinaryViT: Towards Efficient and Accurate Binary Vision Transformers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xiao%2C+J">Junrui Xiao</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zhikai Li</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+L">Lianwei Yang</a>, 
<a href="/search/cs?searchtype=author&query=Gu%2C+Q">Qingyi Gu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> We will be making some significant changes to the paper, including the title and methodology. We therefore wish to withdraw the paper for now
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item1121">[1121]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.15259" title="Abstract">arXiv:2305.15259</a> (replaced) [<a href="/pdf/2305.15259" title="Download PDF">pdf</a>, <a href="/format/2305.15259" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Automated Sensitivity Analysis for Probabilistic Loops
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Moosbrugger%2C+M">Marcel Moosbrugger</a>, 
<a href="/search/cs?searchtype=author&query=M%C3%BCllner%2C+J">Julian M&#xfc;llner</a>, 
<a href="/search/cs?searchtype=author&query=Kov%C3%A1cs%2C+L">Laura Kov&#xe1;cs</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Programming Languages (cs.PL)</span>

</div>
</div>
</dd>
<dt><a name="item1122">[1122]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.15836" title="Abstract">arXiv:2305.15836</a> (replaced) [<a href="/pdf/2305.15836" title="Download PDF">pdf</a>, <a href="/format/2305.15836" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Improved Multi-Scale Grid Rendering of Point Clouds for Radar Object  Detection Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=K%C3%B6hler%2C+D">Daniel K&#xf6;hler</a>, 
<a href="/search/cs?searchtype=author&query=Quach%2C+M">Maurice Quach</a>, 
<a href="/search/cs?searchtype=author&query=Ulrich%2C+M">Michael Ulrich</a>, 
<a href="/search/cs?searchtype=author&query=Meinl%2C+F">Frank Meinl</a>, 
<a href="/search/cs?searchtype=author&query=Bischoff%2C+B">Bastian Bischoff</a>, 
<a href="/search/cs?searchtype=author&query=Blume%2C+H">Holger Blume</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> (c) 2023 IEEE. Personal use of this material is permitted. Permission from IEEE must be obtained for all other uses, in any current or future media, including reprinting/republishing this material for advertising or promotional purposes, creating new collective works, for resale or redistribution to servers or lists, or reuse of any copyrighted component of this work in other works
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Robotics (cs.RO)

</div>
</div>
</dd>
<dt><a name="item1123">[1123]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.16460" title="Abstract">arXiv:2305.16460</a> (replaced) [<a href="/pdf/2305.16460" title="Download PDF">pdf</a>, <a href="/format/2305.16460" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Optimized Custom Dataset for Efficient Detection of Underwater Trash
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Walia%2C+J+S">Jaskaran Singh Walia</a>, 
<a href="/search/cs?searchtype=author&query=Seemakurthy%2C+K">Karthik Seemakurthy</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Robotics (cs.RO)

</div>
</div>
</dd>
<dt><a name="item1124">[1124]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.17201" title="Abstract">arXiv:2305.17201</a> (replaced) [<a href="/pdf/2305.17201" title="Download PDF">pdf</a>, <a href="/format/2305.17201" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Improved Sales Forecasting using Trend and Seasonality Decomposition  with LightGBM
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhou%2C+T">Tong Zhou</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> (2003) 656-661
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item1125">[1125]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.17558" title="Abstract">arXiv:2305.17558</a> (replaced) [<a href="/pdf/2305.17558" title="Download PDF">pdf</a>, <a href="/format/2305.17558" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Provably Fast Finite Particle Variants of SVGD via Virtual Particle  Stochastic Approximation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Das%2C+A">Aniket Das</a>, 
<a href="/search/stat?searchtype=author&query=Nagaraj%2C+D">Dheeraj Nagaraj</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Improved finite-particle rates with polynomial dimension dependence in oracle complexities
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG); Statistics Theory (math.ST)

</div>
</div>
</dd>
<dt><a name="item1126">[1126]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.17842" title="Abstract">arXiv:2305.17842</a> (replaced) [<a href="/pdf/2305.17842" title="Download PDF">pdf</a>, <a href="/format/2305.17842" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> RL + Model-based Control: Using On-demand Optimal Control to Learn  Versatile Legged Locomotion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kang%2C+D">Dongho Kang</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+J">Jin Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Zamora%2C+M">Miguel Zamora</a>, 
<a href="/search/cs?searchtype=author&query=Zargarbashi%2C+F">Fatemeh Zargarbashi</a>, 
<a href="/search/cs?searchtype=author&query=Coros%2C+S">Stelian Coros</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> The paper has been accepted for publication in IEEE Robotics and Automation Letters (RA-L). You can find the copyright information on the front page of the paper. The supplementary video is available in <a href="https://www.youtube.com/watch?v=qPttVfzGS84">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI); Systems and Control (eess.SY)

</div>
</div>
</dd>
<dt><a name="item1127">[1127]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.18798" title="Abstract">arXiv:2305.18798</a> (replaced) [<a href="/pdf/2305.18798" title="Download PDF">pdf</a>, <a href="/format/2305.18798" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AnoOnly: Semi-Supervised Anomaly Detection without Loss on Normal Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Y">Yixuan Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+P">Peiyu Yang</a>, 
<a href="/search/cs?searchtype=author&query=Qu%2C+Y">Yi Qu</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+X">Xing Xu</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+Z">Zhe Sun</a>, 
<a href="/search/cs?searchtype=author&query=Cichocki%2C+A">Andrzej Cichocki</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item1128">[1128]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.19565" title="Abstract">arXiv:2305.19565</a> (replaced) [<a href="/pdf/2305.19565" title="Download PDF">pdf</a>, <a href="/ps/2305.19565" title="Download PostScript">ps</a>, <a href="/format/2305.19565" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A new generalization of Reed-Solomon codes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+C">Chunlei Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> The artical is reorganized
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>

</div>
</div>
</dd>
<dt><a name="item1129">[1129]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.00402" title="Abstract">arXiv:2306.00402</a> (replaced) [<a href="/pdf/2306.00402" title="Download PDF">pdf</a>, <a href="/format/2306.00402" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Discriminative Deep Feature Visualization for Explainable Face  Recognition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+Z">Zewei Xu</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+Y">Yuhang Lu</a>, 
<a href="/search/cs?searchtype=author&query=Ebrahimi%2C+T">Touradj Ebrahimi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Image and Video Processing (eess.IV)

</div>
</div>
</dd>
<dt><a name="item1130">[1130]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.00443" title="Abstract">arXiv:2306.00443</a> (replaced) [<a href="/pdf/2306.00443" title="Download PDF">pdf</a>, <a href="/format/2306.00443" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Efficient Near Maximum-Likelihood Reliability-Based Decoding for Short  LDPC Codes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+W">Weiyang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Yue%2C+C">Chentao Yue</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yonghui Li</a>, 
<a href="/search/cs?searchtype=author&query=Vucetic%2C+B">Branka Vucetic</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>

</div>
</div>
</dd>
<dt><a name="item1131">[1131]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.00936" title="Abstract">arXiv:2306.00936</a> (replaced) [<a href="/pdf/2306.00936" title="Download PDF">pdf</a>, <a href="/format/2306.00936" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AMR4NLI: Interpretable and robust NLI measures from semantic graphs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Opitz%2C+J">Juri Opitz</a>, 
<a href="/search/cs?searchtype=author&query=Wein%2C+S">Shira Wein</a>, 
<a href="/search/cs?searchtype=author&query=Steen%2C+J">Julius Steen</a>, 
<a href="/search/cs?searchtype=author&query=Frank%2C+A">Anette Frank</a>, 
<a href="/search/cs?searchtype=author&query=Schneider%2C+N">Nathan Schneider</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> International Conference on Computational Semantics (IWCS 2023); v2 fixes an imprecise sentence below Eq. 5
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Information Retrieval (cs.IR)

</div>
</div>
</dd>
<dt><a name="item1132">[1132]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.01188" title="Abstract">arXiv:2306.01188</a> (replaced) [<a href="/pdf/2306.01188" title="Download PDF">pdf</a>, <a href="/format/2306.01188" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Event-based Stereo Visual Odometry with Native Temporal Resolution via  Continuous-time Gaussian Process Regression
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jianeng Wang</a>, 
<a href="/search/cs?searchtype=author&query=Gammell%2C+J+D">Jonathan D. Gammell</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To appear in IEEE Robotics and Automation Letters (RA-L). 8 pages, 4 figures. DOI: 10.1109/LRA.2023.3311374
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item1133">[1133]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.01344" title="Abstract">arXiv:2306.01344</a> (replaced) [<a href="/pdf/2306.01344" title="Download PDF">pdf</a>, <a href="/format/2306.01344" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Adjustable Visual Appearance for Generalizable Novel View Synthesis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bengtson%2C+J">Josef Bengtson</a>, 
<a href="/search/cs?searchtype=author&query=Nilsson%2C+D">David Nilsson</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+C">Che-Tsung Lin</a>, 
<a href="/search/cs?searchtype=author&query=B%C3%BCsching%2C+M">Marcel B&#xfc;sching</a>, 
<a href="/search/cs?searchtype=author&query=Kahl%2C+F">Fredrik Kahl</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item1134">[1134]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.02072" title="Abstract">arXiv:2306.02072</a> (replaced) [<a href="/pdf/2306.02072" title="Download PDF">pdf</a>, <a href="/format/2306.02072" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exact Dynamic Programming for Positive Systems with Linear Optimal Cost
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Li%2C+Y">Yuchao Li</a>, 
<a href="/search/math?searchtype=author&query=Rantzer%2C+A">Anders Rantzer</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Systems and Control (eess.SY)

</div>
</div>
</dd>
<dt><a name="item1135">[1135]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.02841" title="Abstract">arXiv:2306.02841</a> (replaced) [<a href="/pdf/2306.02841" title="Download PDF">pdf</a>, <a href="/format/2306.02841" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CTRL: Connect Collaborative and Language Model for CTR Prediction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xiangyang Li</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+B">Bo Chen</a>, 
<a href="/search/cs?searchtype=author&query=Hou%2C+L">Lu Hou</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+R">Ruiming Tang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>

</div>
</div>
</dd>
<dt><a name="item1136">[1136]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.05029" title="Abstract">arXiv:2306.05029</a> (replaced) [<a href="/pdf/2306.05029" title="Download PDF">pdf</a>, <a href="/format/2306.05029" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multi-level Multiple Instance Learning with Transformer for Whole Slide  Image Classification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+R">Ruijie Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Q">Qiaozhe Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yingzhuang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Xin%2C+H">Hao Xin</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yan Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xinggang Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item1137">[1137]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.05152" title="Abstract">arXiv:2306.05152</a> (replaced) [<a href="/pdf/2306.05152" title="Download PDF">pdf</a>, <a href="/ps/2306.05152" title="Download PostScript">ps</a>, <a href="/format/2306.05152" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Autonomous Testing Agents via Conversational Large Language  Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Feldt%2C+R">Robert Feldt</a>, 
<a href="/search/cs?searchtype=author&query=Kang%2C+S">Sungmin Kang</a>, 
<a href="/search/cs?searchtype=author&query=Yoon%2C+J">Juyeon Yoon</a>, 
<a href="/search/cs?searchtype=author&query=Yoo%2C+S">Shin Yoo</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
</div>
</dd>
<dt><a name="item1138">[1138]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.05274" title="Abstract">arXiv:2306.05274</a> (replaced) [<a href="/pdf/2306.05274" title="Download PDF">pdf</a>, <a href="/format/2306.05274" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Structify-Net: Random Graph generation with controlled size and  customized structure
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cazabet%2C+R">Remy Cazabet</a>, 
<a href="/search/cs?searchtype=author&query=Citraro%2C+S">Salvatore Citraro</a>, 
<a href="/search/cs?searchtype=author&query=Rossetti%2C+G">Giulio Rossetti</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Revision after a round of review on PCI Network Science
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>

</div>
</div>
</dd>
<dt><a name="item1139">[1139]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.06306" title="Abstract">arXiv:2306.06306</a> (replaced) [<a href="/pdf/2306.06306" title="Download PDF">pdf</a>, <a href="/format/2306.06306" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DocumentCLIP: Linking Figures and Main Body Text in Reflowed Documents
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+F">Fuxiao Liu</a>, 
<a href="/search/cs?searchtype=author&query=Tan%2C+H">Hao Tan</a>, 
<a href="/search/cs?searchtype=author&query=Tensmeyer%2C+C">Chris Tensmeyer</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 5 figures. In submission
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item1140">[1140]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.06777" title="Abstract">arXiv:2306.06777</a> (replaced) [<a href="/pdf/2306.06777" title="Download PDF">pdf</a>, <a href="/format/2306.06777" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Improving the Validity of Decision Trees as Explanations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nemecek%2C+J">Jiri Nemecek</a>, 
<a href="/search/cs?searchtype=author&query=Pevny%2C+T">Tomas Pevny</a>, 
<a href="/search/cs?searchtype=author&query=Marecek%2C+J">Jakub Marecek</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Optimization and Control (math.OC)

</div>
</div>
</dd>
<dt><a name="item1141">[1141]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.07056" title="Abstract">arXiv:2306.07056</a> (replaced) [<a href="/pdf/2306.07056" title="Download PDF">pdf</a>, <a href="/format/2306.07056" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Kernel Random Projection Depth for Outlier Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Tamamori%2C+A">Akira Tamamori</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to APSIPA ASC 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG); Applications (stat.AP); Methodology (stat.ME)

</div>
</div>
</dd>
<dt><a name="item1142">[1142]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.07237" title="Abstract">arXiv:2306.07237</a> (replaced) [<a href="/pdf/2306.07237" title="Download PDF">pdf</a>, <a href="/format/2306.07237" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Three Edge-disjoint Plane Spanning Paths in a Point Set
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kindermann%2C+P">Philipp Kindermann</a>, 
<a href="/search/cs?searchtype=author&query=Kratochv%C3%ADl%2C+J">Jan Kratochv&#xed;l</a>, 
<a href="/search/cs?searchtype=author&query=Liotta%2C+G">Giuseppe Liotta</a>, 
<a href="/search/cs?searchtype=author&query=Valtr%2C+P">Pavel Valtr</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Appears in the Proceedings of the 31st International Symposium on Graph Drawing and Network Visualization (GD 2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Geometry (cs.CG)</span>

</div>
</div>
</dd>
<dt><a name="item1143">[1143]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.07713" title="Abstract">arXiv:2306.07713</a> (replaced) [<a href="/pdf/2306.07713" title="Download PDF">pdf</a>, <a href="/format/2306.07713" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Robustness of SAM: Segment Anything Under Corruptions and Beyond
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Qiao%2C+Y">Yu Qiao</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+C">Chaoning Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Kang%2C+T">Taegoo Kang</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+D">Donghun Kim</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+C">Chenshuang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Hong%2C+C+S">Choong Seon Hong</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> The first work evaluates the robustness of SAM under various corruptions such as style transfer, local occlusion, and adversarial patch attack
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item1144">[1144]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.07765" title="Abstract">arXiv:2306.07765</a> (replaced) [<a href="/pdf/2306.07765" title="Download PDF">pdf</a>, <a href="/format/2306.07765" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Affine Frequency Division Multiplexing For Communications on Sparse  Time-Varying Channels
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Benzine%2C+W">Wissal Benzine</a>, 
<a href="/search/cs?searchtype=author&query=Bemani%2C+A">Ali Bemani</a>, 
<a href="/search/cs?searchtype=author&query=Ksairi%2C+N">Nassar Ksairi</a>, 
<a href="/search/cs?searchtype=author&query=Slock%2C+D">Dirk Slock</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages, 9 figures, Accepted in Globecom 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Emerging Technologies (cs.ET)

</div>
</div>
</dd>
<dt><a name="item1145">[1145]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.07946" title="Abstract">arXiv:2306.07946</a> (replaced) [<a href="/pdf/2306.07946" title="Download PDF">pdf</a>, <a href="/format/2306.07946" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> STUDY: Socially Aware Temporally Causal Decoder Recommender Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ahmed%2C+E">Eltayeb Ahmed</a>, 
<a href="/search/cs?searchtype=author&query=Mincu%2C+D">Diana Mincu</a>, 
<a href="/search/cs?searchtype=author&query=Harrell%2C+L">Lauren Harrell</a>, 
<a href="/search/cs?searchtype=author&query=Heller%2C+K">Katherine Heller</a>, 
<a href="/search/cs?searchtype=author&query=Roy%2C+S">Subhrajit Roy</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 15 pages, 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>; Artificial Intelligence (cs.AI); Information Retrieval (cs.IR)

</div>
</div>
</dd>
<dt><a name="item1146">[1146]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.08288" title="Abstract">arXiv:2306.08288</a> (replaced) [<a href="/pdf/2306.08288" title="Download PDF">pdf</a>, <a href="/format/2306.08288" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> System Information Decomposition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lyu%2C+A">Aobo Lyu</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+B">Bing Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Deng%2C+O">Ou Deng</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+M">Mingzhe Yang</a>, 
<a href="/search/cs?searchtype=author&query=Clark%2C+A">Andrew Clark</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jiang Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>

</div>
</div>
</dd>
<dt><a name="item1147">[1147]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.08528" title="Abstract">arXiv:2306.08528</a> (replaced) [<a href="/pdf/2306.08528" title="Download PDF">pdf</a>, <a href="/format/2306.08528" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Predict to Detect: Prediction-guided 3D Object Detection using  Sequential Images
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kim%2C+S">Sanmin Kim</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+Y">Youngseok Kim</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+I">In-Jae Lee</a>, 
<a href="/search/cs?searchtype=author&query=Kum%2C+D">Dongsuk Kum</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ICCV 2023, Code: <a href="https://github.com/sanmin0312/P2D">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item1148">[1148]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.09067" title="Abstract">arXiv:2306.09067</a> (replaced) [<a href="/pdf/2306.09067" title="Download PDF">pdf</a>, <a href="/format/2306.09067" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> 2nd Place Winning Solution for the CVPR2023 Visual Anomaly and Novelty  Detection Challenge: Multimodal Prompting for Data-centric Anomaly Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cao%2C+Y">Yunkang Cao</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+X">Xiaohao Xu</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+C">Chen Sun</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+Y">Yuqi Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+L">Liang Gao</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+W">Weiming Shen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> The first two author contribute equally. CVPR workshop challenge report. arXiv admin note: substantial text overlap with <a href="/abs/2305.10724">arXiv:2305.10724</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item1149">[1149]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.09209" title="Abstract">arXiv:2306.09209</a> (replaced) [<a href="/pdf/2306.09209" title="Download PDF">pdf</a>, <a href="/ps/2306.09209" title="Download PostScript">ps</a>, <a href="/format/2306.09209" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Bayesian Game Formulation of Power Allocation in Multiple Access Wiretap  Channel with Incomplete CSI
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rashid%2C+B">Basharat Rashid</a>, 
<a href="/search/cs?searchtype=author&query=Haddad%2C+M">Majed Haddad</a>, 
<a href="/search/cs?searchtype=author&query=Shah%2C+S+M">Shahid Mehraj Shah</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 Pages, 2 Figures, submitted for possible publication
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Computer Science and Game Theory (cs.GT); Signal Processing (eess.SP)

</div>
</div>
</dd>
<dt><a name="item1150">[1150]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.09237" title="Abstract">arXiv:2306.09237</a> (replaced) [<a href="/pdf/2306.09237" title="Download PDF">pdf</a>, <a href="/format/2306.09237" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SCALE: Scaling up the Complexity for Advanced Language Model Evaluation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rasiah%2C+V">Vishvaksenan Rasiah</a>, 
<a href="/search/cs?searchtype=author&query=Stern%2C+R">Ronja Stern</a>, 
<a href="/search/cs?searchtype=author&query=Matoshi%2C+V">Veton Matoshi</a>, 
<a href="/search/cs?searchtype=author&query=St%C3%BCrmer%2C+M">Matthias St&#xfc;rmer</a>, 
<a href="/search/cs?searchtype=author&query=Chalkidis%2C+I">Ilias Chalkidis</a>, 
<a href="/search/cs?searchtype=author&query=Ho%2C+D+E">Daniel E. Ho</a>, 
<a href="/search/cs?searchtype=author&query=Niklaus%2C+J">Joel Niklaus</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item1151">[1151]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.09675" title="Abstract">arXiv:2306.09675</a> (replaced) [<a href="/pdf/2306.09675" title="Download PDF">pdf</a>, <a href="/format/2306.09675" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multi-View Class Incremental Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+D">Depeng Li</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+T">Tianqi Wang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Junwei Chen</a>, 
<a href="/search/cs?searchtype=author&query=Kawaguchi%2C+K">Kenji Kawaguchi</a>, 
<a href="/search/cs?searchtype=author&query=Lian%2C+C">Cheng Lian</a>, 
<a href="/search/cs?searchtype=author&query=Zeng%2C+Z">Zhigang Zeng</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 22 pages,4 figures. Preprint submitted to Information Fusion
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV); Multimedia (cs.MM)

</div>
</div>
</dd>
<dt><a name="item1152">[1152]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.09699" title="Abstract">arXiv:2306.09699</a> (replaced) [<a href="/pdf/2306.09699" title="Download PDF">pdf</a>, <a href="/format/2306.09699" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Perturbed Initial Orbit Determination
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/astro-ph?searchtype=author&query=Foss%C3%A0%2C+A">Alberto Foss&#xe0;</a>, 
<a href="/search/astro-ph?searchtype=author&query=Losacco%2C+M">Matteo Losacco</a>, 
<a href="/search/astro-ph?searchtype=author&query=Armellin%2C+R">Roberto Armellin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> accepted for publication on Astrodynamics
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Earth and Planetary Astrophysics (astro-ph.EP)</span>; Instrumentation and Methods for Astrophysics (astro-ph.IM); Numerical Analysis (math.NA)

</div>
</div>
</dd>
<dt><a name="item1153">[1153]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.10006" title="Abstract">arXiv:2306.10006</a> (replaced) [<a href="/pdf/2306.10006" title="Download PDF">pdf</a>, <a href="/format/2306.10006" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Unsupervised Learning of Style-Aware Facial Animation from Real Acting  Performances
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Paier%2C+W">Wolfgang Paier</a>, 
<a href="/search/cs?searchtype=author&query=Hilsmann%2C+A">Anna Hilsmann</a>, 
<a href="/search/cs?searchtype=author&query=Eisert%2C+P">Peter Eisert</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 pages, submitted to Graphical Models (Feb 2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Graphics (cs.GR); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item1154">[1154]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.10076" title="Abstract">arXiv:2306.10076</a> (replaced) [<a href="/pdf/2306.10076" title="Download PDF">pdf</a>, <a href="/format/2306.10076" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> General Spatial Photonic Ising Machine Based on Interaction Matrix  Eigendecomposition Method
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Shaomeng Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+W">Wenjia Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Ye%2C+X">Xin Ye</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+Z">Zuyuan He</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Emerging Technologies (cs.ET)</span>; Optics (physics.optics)

</div>
</div>
</dd>
<dt><a name="item1155">[1155]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.10311" title="Abstract">arXiv:2306.10311</a> (replaced) [<a href="/pdf/2306.10311" title="Download PDF">pdf</a>, <a href="/format/2306.10311" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Efficient HDR Reconstruction From Real-World Raw Images
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Yang%2C+Q">Qirui Yang</a>, 
<a href="/search/eess?searchtype=author&query=Liu%2C+Y">Yihao Liu</a>, 
<a href="/search/eess?searchtype=author&query=Chen%2C+Q">Qihua Chen</a>, 
<a href="/search/eess?searchtype=author&query=Yang%2C+J">Jingyu Yang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item1156">[1156]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.10404" title="Abstract">arXiv:2306.10404</a> (replaced) [<a href="/pdf/2306.10404" title="Download PDF">pdf</a>, <a href="/format/2306.10404" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The RL Perceptron: Generalisation Dynamics of Policy Learning in High  Dimensions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Patel%2C+N">Nishil Patel</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+S">Sebastian Lee</a>, 
<a href="/search/cs?searchtype=author&query=Mannelli%2C+S+S">Stefano Sarao Mannelli</a>, 
<a href="/search/cs?searchtype=author&query=Goldt%2C+S">Sebastian Goldt</a>, 
<a href="/search/cs?searchtype=author&query=Saxe%2C+A">Andrew Saxe</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 7 figures, Preprint
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Disordered Systems and Neural Networks (cond-mat.dis-nn)

</div>
</div>
</dd>
<dt><a name="item1157">[1157]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.11229" title="Abstract">arXiv:2306.11229</a> (replaced) [<a href="/pdf/2306.11229" title="Download PDF">pdf</a>, <a href="/format/2306.11229" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Reasoning over the Air: A Reasoning-based Implicit Semantic-Aware  Communication Framework
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xiao%2C+Y">Yong Xiao</a>, 
<a href="/search/cs?searchtype=author&query=Liao%2C+Y">Yiwei Liao</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yingyu Li</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+G">Guangming Shi</a>, 
<a href="/search/cs?searchtype=author&query=Poor%2C+H+V">H. Vincent Poor</a>, 
<a href="/search/cs?searchtype=author&query=Saad%2C+W">Walid Saad</a>, 
<a href="/search/cs?searchtype=author&query=Debbah%2C+M">Merouane Debbah</a>, 
<a href="/search/cs?searchtype=author&query=Bennis%2C+M">Mehdi Bennis</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> accepted at IEEE Transactions on Wireless Communications
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item1158">[1158]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.11259" title="Abstract">arXiv:2306.11259</a> (replaced) [<a href="/pdf/2306.11259" title="Download PDF">pdf</a>, <a href="/format/2306.11259" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CoNi-MPC: Cooperative Non-inertial Frame Based Model Predictive Control
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+B">Baozhe Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+X">Xinwei Chen</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zhehan Li</a>, 
<a href="/search/cs?searchtype=author&query=Beltrame%2C+G">Giovanni Beltrame</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+C">Chao Xu</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+F">Fei Gao</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+Y">Yanjun Cao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
</div>
</dd>
<dt><a name="item1159">[1159]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.11800" title="Abstract">arXiv:2306.11800</a> (replaced) [<a href="/pdf/2306.11800" title="Download PDF">pdf</a>, <a href="/format/2306.11800" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DynaQuant: Compressing Deep Learning Training Checkpoints via Dynamic  Quantization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Agrawal%2C+A">Amey Agrawal</a>, 
<a href="/search/cs?searchtype=author&query=Reddy%2C+S">Sameer Reddy</a>, 
<a href="/search/cs?searchtype=author&query=Bhattamishra%2C+S">Satwik Bhattamishra</a>, 
<a href="/search/cs?searchtype=author&query=Nookala%2C+V+P+S">Venkata Prabhakara Sarath Nookala</a>, 
<a href="/search/cs?searchtype=author&query=Vashishth%2C+V">Vidushi Vashishth</a>, 
<a href="/search/cs?searchtype=author&query=Rong%2C+K">Kexin Rong</a>, 
<a href="/search/cs?searchtype=author&query=Tumanov%2C+A">Alexey Tumanov</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item1160">[1160]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.11862" title="Abstract">arXiv:2306.11862</a> (replaced) [<a href="/pdf/2306.11862" title="Download PDF">pdf</a>, <a href="/format/2306.11862" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Proactive Human-Robot Co-Assembly: Leveraging Human Intention Prediction  and Robust Safe Control
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+R">Ruixuan Liu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+R">Rui Chen</a>, 
<a href="/search/cs?searchtype=author&query=Abuduweili%2C+A">Abulikemu Abuduweili</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+C">Changliu Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7th IEEE Conference on Control Technology and Applications (CCTA 2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item1161">[1161]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.11963" title="Abstract">arXiv:2306.11963</a> (replaced) [<a href="/pdf/2306.11963" title="Download PDF">pdf</a>, <a href="/format/2306.11963" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multimodality Fusion for Smart Healthcare: a Journey from Data,  Information, Knowledge to Wisdom
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shaik%2C+T">Thanveer Shaik</a>, 
<a href="/search/cs?searchtype=author&query=Tao%2C+X">Xiaohui Tao</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+L">Lin Li</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+H">Haoran Xie</a>, 
<a href="/search/cs?searchtype=author&query=Vel%C3%A1squez%2C+J+D">Juan D. Vel&#xe1;squez</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This work has been submitted to the ELSEVIER for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>

</div>
</div>
</dd>
<dt><a name="item1162">[1162]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.12677" title="Abstract">arXiv:2306.12677</a> (replaced) [<a href="/pdf/2306.12677" title="Download PDF">pdf</a>, <a href="/format/2306.12677" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SoftGPT: Learn Goal-oriented Soft Object Manipulation Skills by  Generative Pre-trained Heterogeneous Graph Transformer
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Junjia Liu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zhihao Li</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+W">Wanyu Lin</a>, 
<a href="/search/cs?searchtype=author&query=Calinon%2C+S">Sylvain Calinon</a>, 
<a href="/search/cs?searchtype=author&query=Tan%2C+K+C">Kay Chen Tan</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+F">Fei Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages, 5 figures, accepted by IROS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item1163">[1163]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.12714" title="Abstract">arXiv:2306.12714</a> (replaced) [<a href="/pdf/2306.12714" title="Download PDF">pdf</a>, <a href="/format/2306.12714" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Toward Leveraging Pre-Trained Self-Supervised Frontends for Automatic  Singing Voice Understanding Tasks: Three Case Studies
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yamamoto%2C+Y">Yuya Yamamoto</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at APSIPA ASC 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Machine Learning (cs.LG); Audio and Speech Processing (eess.AS)

</div>
</div>
</dd>
<dt><a name="item1164">[1164]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.13674" title="Abstract">arXiv:2306.13674</a> (replaced) [<a href="/pdf/2306.13674" title="Download PDF">pdf</a>, <a href="/format/2306.13674" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MeciFace: Mechanomyography and Inertial Fusion based Glasses for Edge  Real-Time Recognition of Facial and Eating Activities
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bello%2C+H">Hymalai Bello</a>, 
<a href="/search/cs?searchtype=author&query=Suh%2C+S">Sungho Suh</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+B">Bo Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Lukowicz%2C+P">Paul Lukowicz</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to Nature Scientific Reports
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG); Image and Video Processing (eess.IV); Signal Processing (eess.SP)

</div>
</div>
</dd>
<dt><a name="item1165">[1165]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.14395" title="Abstract">arXiv:2306.14395</a> (replaced) [<a href="/pdf/2306.14395" title="Download PDF">pdf</a>, <a href="/format/2306.14395" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AirIndex: Versatile Index Tuning Through Data and Storage
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chockchowwat%2C+S">Supawit Chockchowwat</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+W">Wenjie Liu</a>, 
<a href="/search/cs?searchtype=author&query=Park%2C+Y">Yongjoo Park</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, 3 appendices, 19 figures, to appear at SIGMOD 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Databases (cs.DB)</span>

</div>
</div>
</dd>
<dt><a name="item1166">[1166]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.14469" title="Abstract">arXiv:2306.14469</a> (replaced) [<a href="/pdf/2306.14469" title="Download PDF">pdf</a>, <a href="/ps/2306.14469" title="Download PostScript">ps</a>, <a href="/format/2306.14469" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On Adaptive-Gain Control of Replicator Dynamics in Population Games
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Zino%2C+L">Lorenzo Zino</a>, 
<a href="/search/eess?searchtype=author&query=Ye%2C+M">Mengbin Ye</a>, 
<a href="/search/eess?searchtype=author&query=Rizzo%2C+A">Alessandro Rizzo</a>, 
<a href="/search/eess?searchtype=author&query=Calafiore%2C+G+C">Giuseppe Carlo Calafiore</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages, Accepted for presentation at the 2023 IEEE CDC
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Dynamical Systems (math.DS); Optimization and Control (math.OC)

</div>
</div>
</dd>
<dt><a name="item1167">[1167]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.14538" title="Abstract">arXiv:2306.14538</a> (replaced) [<a href="/pdf/2306.14538" title="Download PDF">pdf</a>, <a href="/format/2306.14538" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learnable Differencing Center for Nighttime Depth Perception
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yan%2C+Z">Zhiqiang Yan</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+Y">Yupeng Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+C">Chongyi Li</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jun Li</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+J">Jian Yang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item1168">[1168]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.15907" title="Abstract">arXiv:2306.15907</a> (replaced) [<a href="/pdf/2306.15907" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deep Learning Models for Water Stage Predictions in South Florida
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shi%2C+J">Jimeng Shi</a>, 
<a href="/search/cs?searchtype=author&query=Yin%2C+Z">Zeda Yin</a>, 
<a href="/search/cs?searchtype=author&query=Myana%2C+R">Rukmangadh Myana</a>, 
<a href="/search/cs?searchtype=author&query=Ishtiaq%2C+K">Khandker Ishtiaq</a>, 
<a href="/search/cs?searchtype=author&query=John%2C+A">Anupama John</a>, 
<a href="/search/cs?searchtype=author&query=Obeysekera%2C+J">Jayantha Obeysekera</a>, 
<a href="/search/cs?searchtype=author&query=Leon%2C+A">Arturo Leon</a>, 
<a href="/search/cs?searchtype=author&query=Narasimhan%2C+G">Giri Narasimhan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Atmospheric and Oceanic Physics (physics.ao-ph)

</div>
</div>
</dd>
<dt><a name="item1169">[1169]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.16614" title="Abstract">arXiv:2306.16614</a> (replaced) [<a href="/pdf/2306.16614" title="Download PDF">pdf</a>, <a href="/format/2306.16614" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Group-based Robustness: A General Framework for Customized Robustness in  the Real World
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lin%2C+W">Weiran Lin</a>, 
<a href="/search/cs?searchtype=author&query=Lucas%2C+K">Keane Lucas</a>, 
<a href="/search/cs?searchtype=author&query=Eyal%2C+N">Neo Eyal</a>, 
<a href="/search/cs?searchtype=author&query=Bauer%2C+L">Lujo Bauer</a>, 
<a href="/search/cs?searchtype=author&query=Reiter%2C+M+K">Michael K. Reiter</a>, 
<a href="/search/cs?searchtype=author&query=Sharif%2C+M">Mahmood Sharif</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Cryptography and Security (cs.CR); Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item1170">[1170]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.00206" title="Abstract">arXiv:2307.00206</a> (replaced) [<a href="/pdf/2307.00206" title="Download PDF">pdf</a>, <a href="/format/2307.00206" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Rearrangement Planning for General Part Assembly
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yulong Li</a>, 
<a href="/search/cs?searchtype=author&query=Zeng%2C+A">Andy Zeng</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+S">Shuran Song</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project website: <a href="https://general-part-assembly.github.io/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item1171">[1171]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.00521" title="Abstract">arXiv:2307.00521</a> (replaced) [<a href="/pdf/2307.00521" title="Download PDF">pdf</a>, <a href="/format/2307.00521" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> zkFi: Privacy-Preserving and Regulation Compliant Transactions using  Zero Knowledge Proofs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sahu%2C+N">Naveen Sahu</a>, 
<a href="/search/cs?searchtype=author&query=Gajera%2C+M">Mitul Gajera</a>, 
<a href="/search/cs?searchtype=author&query=Chaudhary%2C+A">Amit Chaudhary</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
</div>
</dd>
<dt><a name="item1172">[1172]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.01928" title="Abstract">arXiv:2307.01928</a> (replaced) [<a href="/pdf/2307.01928" title="Download PDF">pdf</a>, <a href="/format/2307.01928" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Robots That Ask For Help: Uncertainty Alignment for Large Language Model  Planners
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ren%2C+A+Z">Allen Z. Ren</a>, 
<a href="/search/cs?searchtype=author&query=Dixit%2C+A">Anushri Dixit</a>, 
<a href="/search/cs?searchtype=author&query=Bodrova%2C+A">Alexandra Bodrova</a>, 
<a href="/search/cs?searchtype=author&query=Singh%2C+S">Sumeet Singh</a>, 
<a href="/search/cs?searchtype=author&query=Tu%2C+S">Stephen Tu</a>, 
<a href="/search/cs?searchtype=author&query=Brown%2C+N">Noah Brown</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+P">Peng Xu</a>, 
<a href="/search/cs?searchtype=author&query=Takayama%2C+L">Leila Takayama</a>, 
<a href="/search/cs?searchtype=author&query=Xia%2C+F">Fei Xia</a>, 
<a href="/search/cs?searchtype=author&query=Varley%2C+J">Jake Varley</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+Z">Zhenjia Xu</a>, 
<a href="/search/cs?searchtype=author&query=Sadigh%2C+D">Dorsa Sadigh</a>, 
<a href="/search/cs?searchtype=author&query=Zeng%2C+A">Andy Zeng</a>, 
<a href="/search/cs?searchtype=author&query=Majumdar%2C+A">Anirudha Majumdar</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Conference on Robot Learning (CoRL) 2023, Oral Presentation
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI); Applications (stat.AP)

</div>
</div>
</dd>
<dt><a name="item1173">[1173]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.02192" title="Abstract">arXiv:2307.02192</a> (replaced) [<a href="/pdf/2307.02192" title="Download PDF">pdf</a>, <a href="/format/2307.02192" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The FormAI Dataset: Generative AI in Software Security Through the Lens  of Formal Verification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tihanyi%2C+N">Norbert Tihanyi</a>, 
<a href="/search/cs?searchtype=author&query=Bisztray%2C+T">Tamas Bisztray</a>, 
<a href="/search/cs?searchtype=author&query=Jain%2C+R">Ridhi Jain</a>, 
<a href="/search/cs?searchtype=author&query=Ferrag%2C+M+A">Mohamed Amine Ferrag</a>, 
<a href="/search/cs?searchtype=author&query=Cordeiro%2C+L+C">Lucas C. Cordeiro</a>, 
<a href="/search/cs?searchtype=author&query=Mavroeidis%2C+V">Vasileios Mavroeidis</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> <a href="https://github.com/FormAI-Dataset">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Databases (cs.DB)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item1174">[1174]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.02291" title="Abstract">arXiv:2307.02291</a> (replaced) [<a href="/pdf/2307.02291" title="Download PDF">pdf</a>, <a href="/format/2307.02291" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Focusing on what to decode and what to train: Efficient Training with  HOI Split Decoders and Specific Target Guided DeNoising
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Junwen Chen</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yingcheng Wang</a>, 
<a href="/search/cs?searchtype=author&query=Yanai%2C+K">Keiji Yanai</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item1175">[1175]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.02698" title="Abstract">arXiv:2307.02698</a> (replaced) [<a href="/pdf/2307.02698" title="Download PDF">pdf</a>, <a href="/format/2307.02698" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Applying a Color Palette with Local Control using Diffusion Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Vavilala%2C+V">Vaibhav Vavilala</a>, 
<a href="/search/cs?searchtype=author&query=Forsyth%2C+D">David Forsyth</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages, 14 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item1176">[1176]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.03718" title="Abstract">arXiv:2307.03718</a> (replaced) [<a href="/pdf/2307.03718" title="Download PDF">pdf</a>, <a href="/format/2307.03718" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Frontier AI Regulation: Managing Emerging Risks to Public Safety
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Anderljung%2C+M">Markus Anderljung</a>, 
<a href="/search/cs?searchtype=author&query=Barnhart%2C+J">Joslyn Barnhart</a>, 
<a href="/search/cs?searchtype=author&query=Korinek%2C+A">Anton Korinek</a>, 
<a href="/search/cs?searchtype=author&query=Leung%2C+J">Jade Leung</a>, 
<a href="/search/cs?searchtype=author&query=O%27Keefe%2C+C">Cullen O&#x27;Keefe</a>, 
<a href="/search/cs?searchtype=author&query=Whittlestone%2C+J">Jess Whittlestone</a>, 
<a href="/search/cs?searchtype=author&query=Avin%2C+S">Shahar Avin</a>, 
<a href="/search/cs?searchtype=author&query=Brundage%2C+M">Miles Brundage</a>, 
<a href="/search/cs?searchtype=author&query=Bullock%2C+J">Justin Bullock</a>, 
<a href="/search/cs?searchtype=author&query=Cass-Beggs%2C+D">Duncan Cass-Beggs</a>, 
<a href="/search/cs?searchtype=author&query=Chang%2C+B">Ben Chang</a>, 
<a href="/search/cs?searchtype=author&query=Collins%2C+T">Tantum Collins</a>, 
<a href="/search/cs?searchtype=author&query=Fist%2C+T">Tim Fist</a>, 
<a href="/search/cs?searchtype=author&query=Hadfield%2C+G">Gillian Hadfield</a>, 
<a href="/search/cs?searchtype=author&query=Hayes%2C+A">Alan Hayes</a>, 
<a href="/search/cs?searchtype=author&query=Ho%2C+L">Lewis Ho</a>, 
<a href="/search/cs?searchtype=author&query=Hooker%2C+S">Sara Hooker</a>, 
<a href="/search/cs?searchtype=author&query=Horvitz%2C+E">Eric Horvitz</a>, 
<a href="/search/cs?searchtype=author&query=Kolt%2C+N">Noam Kolt</a>, 
<a href="/search/cs?searchtype=author&query=Schuett%2C+J">Jonas Schuett</a>, 
<a href="/search/cs?searchtype=author&query=Shavit%2C+Y">Yonadav Shavit</a>, 
<a href="/search/cs?searchtype=author&query=Siddarth%2C+D">Divya Siddarth</a>, 
<a href="/search/cs?searchtype=author&query=Trager%2C+R">Robert Trager</a>, 
<a href="/search/cs?searchtype=author&query=Wolf%2C+K">Kevin Wolf</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Update July 11th: - Added missing footnote back in. - Adjusted author order (mistakenly non-alphabetical among the first 6 authors) and adjusted affiliations (Jess Whittlestone's affiliation was mistagged and Gillian Hadfield had SRI added to her affiliations) Updated September 4th: Various typos
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item1177">[1177]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.04129" title="Abstract">arXiv:2307.04129</a> (replaced) [<a href="/pdf/2307.04129" title="Download PDF">pdf</a>, <a href="/format/2307.04129" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Cross-modal Orthogonal High-rank Augmentation for RGB-Event  Transformer-trackers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhu%2C+Z">Zhiyu Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Hou%2C+J">Junhui Hou</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+D+O">Dapeng Oliver Wu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> accepted by ICCV
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item1178">[1178]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.04726" title="Abstract">arXiv:2307.04726</a> (replaced) [<a href="/pdf/2307.04726" title="Download PDF">pdf</a>, <a href="/format/2307.04726" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Diffusion Policies for Out-of-Distribution Generalization in Offline  Reinforcement Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ada%2C+S+E">Suzan Ece Ada</a>, 
<a href="/search/cs?searchtype=author&query=Oztop%2C+E">Erhan Oztop</a>, 
<a href="/search/cs?searchtype=author&query=Ugur%2C+E">Emre Ugur</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 7 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Neural and Evolutionary Computing (cs.NE); Robotics (cs.RO)

</div>
</div>
</dd>
<dt><a name="item1179">[1179]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.05074" title="Abstract">arXiv:2307.05074</a> (replaced) [<a href="/pdf/2307.05074" title="Download PDF">pdf</a>, <a href="/format/2307.05074" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Retrieval-augmented GPT-3.5-based Text-to-SQL Framework with  Sample-aware Prompting and Dynamic Revision Chain
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Guo%2C+C">Chunxi Guo</a>, 
<a href="/search/cs?searchtype=author&query=Tian%2C+Z">Zhiliang Tian</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+J">Jintao Tang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+S">Shasha Li</a>, 
<a href="/search/cs?searchtype=author&query=Wen%2C+Z">Zhihua Wen</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+K">Kaixuan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+T">Ting Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Artificial Intelligence (cs.AI); Databases (cs.DB)

</div>
</div>
</dd>
<dt><a name="item1180">[1180]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.06007" title="Abstract">arXiv:2307.06007</a> (replaced) [<a href="/pdf/2307.06007" title="Download PDF">pdf</a>, <a href="/format/2307.06007" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Building Persuasive Robots with Social Power Strategies
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hashemian%2C+M">Mojgan Hashemian</a>, 
<a href="/search/cs?searchtype=author&query=Couto%2C+M">Marta Couto</a>, 
<a href="/search/cs?searchtype=author&query=Mascarenhas%2C+S">Samuel Mascarenhas</a>, 
<a href="/search/cs?searchtype=author&query=Paiva%2C+A">Ana Paiva</a>, 
<a href="/search/cs?searchtype=author&query=Santos%2C+P+A">Pedro A. Santos</a>, 
<a href="/search/cs?searchtype=author&query=Prada%2C+R">Rui Prada</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Robotics (cs.RO)

</div>
</div>
</dd>
<dt><a name="item1181">[1181]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.06555" title="Abstract">arXiv:2307.06555</a> (replaced) [<a href="/pdf/2307.06555" title="Download PDF">pdf</a>, <a href="/format/2307.06555" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deep Network Approximation: Beyond ReLU to Diverse Activation Functions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+S">Shijun Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+J">Jianfeng Lu</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+H">Hongkai Zhao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item1182">[1182]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.06954" title="Abstract">arXiv:2307.06954</a> (replaced) [<a href="/pdf/2307.06954" title="Download PDF">pdf</a>, <a href="/format/2307.06954" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ACTI at EVALITA 2023: Overview of the Conspiracy Theory Identification  Task
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Russo%2C+G">Giuseppe Russo</a>, 
<a href="/search/cs?searchtype=author&query=Stoehr%2C+N">Niklas Stoehr</a>, 
<a href="/search/cs?searchtype=author&query=Ribeiro%2C+M+H">Manoel Horta Ribeiro</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at the Evalita Workshop 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item1183">[1183]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.07362" title="Abstract">arXiv:2307.07362</a> (replaced) [<a href="/pdf/2307.07362" title="Download PDF">pdf</a>, <a href="/format/2307.07362" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A scoping review on multimodal deep learning in biomedical images and  texts
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sun%2C+Z">Zhaoyi Sun</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+M">Mingquan Lin</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+Q">Qingqing Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+Q">Qianqian Xie</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+F">Fei Wang</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+Z">Zhiyong Lu</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+Y">Yifan Peng</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This paper has been accepted by the Journal of Biomedical Informatics
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Computation and Language (cs.CL)

</div>
</div>
</dd>
<dt><a name="item1184">[1184]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.07400" title="Abstract">arXiv:2307.07400</a> (replaced) [<a href="/pdf/2307.07400" title="Download PDF">pdf</a>, <a href="/format/2307.07400" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Contextual Behavioural Metrics (Extended Version)
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lago%2C+U+D">Ugo Dal Lago</a>, 
<a href="/search/cs?searchtype=author&query=Murgia%2C+M">Maurizio Murgia</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Extended version of a paper accepted for publication in proc. CONCUR 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Formal Languages and Automata Theory (cs.FL)</span>; Programming Languages (cs.PL)

</div>
</div>
</dd>
<dt><a name="item1185">[1185]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.08153" title="Abstract">arXiv:2307.08153</a> (replaced) [<a href="/pdf/2307.08153" title="Download PDF">pdf</a>, <a href="/format/2307.08153" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Analyzing Dataset Annotation Quality Management in the Wild
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Klie%2C+J">Jan-Christoph Klie</a>, 
<a href="/search/cs?searchtype=author&query=de+Castilho%2C+R+E">Richard Eckart de Castilho</a>, 
<a href="/search/cs?searchtype=author&query=Gurevych%2C+I">Iryna Gurevych</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item1186">[1186]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.08863" title="Abstract">arXiv:2307.08863</a> (replaced) [<a href="/pdf/2307.08863" title="Download PDF">pdf</a>, <a href="/format/2307.08863" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Meta-Value Learning: a General Framework for Learning with Learning  Awareness
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cooijmans%2C+T">Tim Cooijmans</a>, 
<a href="/search/cs?searchtype=author&query=Aghajohari%2C+M">Milad Aghajohari</a>, 
<a href="/search/cs?searchtype=author&query=Courville%2C+A">Aaron Courville</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Multiagent Systems (cs.MA)

</div>
</div>
</dd>
<dt><a name="item1187">[1187]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.08924" title="Abstract">arXiv:2307.08924</a> (replaced) [<a href="/pdf/2307.08924" title="Download PDF">pdf</a>, <a href="/format/2307.08924" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning to Sample Tasks for Meta Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jingyao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+Z">Zeen Song</a>, 
<a href="/search/cs?searchtype=author&query=Su%2C+X">Xingzhe Su</a>, 
<a href="/search/cs?searchtype=author&query=Si%2C+L">Lingyu Si</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+H">Hongwei Dong</a>, 
<a href="/search/cs?searchtype=author&query=Qiang%2C+W">Wenwen Qiang</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+C">Changwen Zheng</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 7 tables, 3 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item1188">[1188]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.10053" title="Abstract">arXiv:2307.10053</a> (replaced) [<a href="/pdf/2307.10053" title="Download PDF">pdf</a>, <a href="/format/2307.10053" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Convergence Guarantees for Stochastic Subgradient Methods in Nonsmooth  Nonconvex Optimization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Xiao%2C+N">Nachuan Xiao</a>, 
<a href="/search/math?searchtype=author&query=Hu%2C+X">Xiaoyin Hu</a>, 
<a href="/search/math?searchtype=author&query=Toh%2C+K">Kim-Chuan Toh</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 30 pages, the introduction part is modified and some typos are corrected
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item1189">[1189]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.11307" title="Abstract">arXiv:2307.11307</a> (replaced) [<a href="/pdf/2307.11307" title="Download PDF">pdf</a>, <a href="/format/2307.11307" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> EndoSurf: Neural Surface Reconstruction of Deformable Tissues with  Stereo Endoscope Videos
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zha%2C+R">Ruyi Zha</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+X">Xuelian Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Hongdong Li</a>, 
<a href="/search/cs?searchtype=author&query=Harandi%2C+M">Mehrtash Harandi</a>, 
<a href="/search/cs?searchtype=author&query=Ge%2C+Z">Zongyuan Ge</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> MICCAI 2023(Oral, Student Travel Award, Top 3%); Ruyi Zha and Xuelian Cheng made equal contributions. Corresponding author: Ruyi Zha (ruyi.zha@gmail.com)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item1190">[1190]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.11342" title="Abstract">arXiv:2307.11342</a> (replaced) [<a href="/pdf/2307.11342" title="Download PDF">pdf</a>, <a href="/format/2307.11342" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Tuning Pre-trained Model via Moment Probing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gao%2C+M">Mingze Gao</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Q">Qilong Wang</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+Z">Zhenyi Lin</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+P">Pengfei Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+Q">Qinghua Hu</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+J">Jingbo Zhou</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to ICCV 2023; Project Page: <a href="https://github.com/mingzeG/Moment-Probing">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item1191">[1191]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.11729" title="Abstract">arXiv:2307.11729</a> (replaced) [<a href="/pdf/2307.11729" title="Download PDF">pdf</a>, <a href="/format/2307.11729" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> OUTFOX: LLM-generated Essay Detection through In-context Learning with  Adversarially Generated Examples
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Koike%2C+R">Ryuto Koike</a>, 
<a href="/search/cs?searchtype=author&query=Kaneko%2C+M">Masahiro Kaneko</a>, 
<a href="/search/cs?searchtype=author&query=Okazaki%2C+N">Naoaki Okazaki</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item1192">[1192]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.11772" title="Abstract">arXiv:2307.11772</a> (replaced) [<a href="/pdf/2307.11772" title="Download PDF">pdf</a>, <a href="/format/2307.11772" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AutoAlign: Fully Automatic and Effective Knowledge Graph Alignment  enabled by Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+R">Rui Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Su%2C+Y">Yixin Su</a>, 
<a href="/search/cs?searchtype=author&query=Trisedya%2C+B+D">Bayu Distiawan Trisedya</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+X">Xiaoyan Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+M">Min Yang</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+H">Hong Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Qi%2C+J">Jianzhong Qi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages, 5 figures, 4 tables. arXiv admin note: substantial text overlap with <a href="/abs/2210.08540">arXiv:2210.08540</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Computation and Language (cs.CL); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item1193">[1193]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.12762" title="Abstract">arXiv:2307.12762</a> (replaced) [<a href="/pdf/2307.12762" title="Download PDF">pdf</a>, <a href="/ps/2307.12762" title="Download PostScript">ps</a>, <a href="/format/2307.12762" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Two types of narrow-sense negacyclic BCH codes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yanhui Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+L">Li Liu</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+X">Xianhong Xie</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>

</div>
</div>
</dd>
<dt><a name="item1194">[1194]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.13421" title="Abstract">arXiv:2307.13421</a> (replaced) [<a href="/pdf/2307.13421" title="Download PDF">pdf</a>, <a href="/format/2307.13421" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the Learning Dynamics of Attention Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Vashisht%2C+R">Rahul Vashisht</a>, 
<a href="/search/cs?searchtype=author&query=Ramaswamy%2C+H+G">Harish G. Ramaswamy</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Preprint: Accepted at ECAI-2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item1195">[1195]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.13704" title="Abstract">arXiv:2307.13704</a> (replaced) [<a href="/pdf/2307.13704" title="Download PDF">pdf</a>, <a href="/format/2307.13704" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> eXplainable Artificial Intelligence (XAI) in aging clock models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kalyakulina%2C+A">Alena Kalyakulina</a>, 
<a href="/search/cs?searchtype=author&query=Yusipov%2C+I">Igor Yusipov</a>, 
<a href="/search/cs?searchtype=author&query=Bacalini%2C+M+G">Maria Giulia Bacalini</a>, 
<a href="/search/cs?searchtype=author&query=Moskalev%2C+A">Alexey Moskalev</a>, 
<a href="/search/cs?searchtype=author&query=Franceschi%2C+C">Claudio Franceschi</a>, 
<a href="/search/cs?searchtype=author&query=Ivanchenko%2C+M">Mikhail Ivanchenko</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Machine Learning (cs.LG); Image and Video Processing (eess.IV)

</div>
</div>
</dd>
<dt><a name="item1196">[1196]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.15421" title="Abstract">arXiv:2307.15421</a> (replaced) [<a href="/pdf/2307.15421" title="Download PDF">pdf</a>, <a href="/format/2307.15421" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MLIC++: Linear Complexity Multi-Reference Entropy Modeling for Learned  Image Compression
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Jiang%2C+W">Wei Jiang</a>, 
<a href="/search/eess?searchtype=author&query=Wang%2C+R">Ronggang Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at ICML 2023 Neural Compression Workshop. Extension work of our ACMMM 2023 paper MLIC: Multi-Reference Entropy Model for Learned Image Compression
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item1197">[1197]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.15892" title="Abstract">arXiv:2307.15892</a> (replaced) [<a href="/pdf/2307.15892" title="Download PDF">pdf</a>, <a href="/format/2307.15892" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A new Gradient TD Algorithm with only One Step-size: Convergence Rate  Analysis using $L$-$&#x3bb;$ Smoothness
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yao%2C+H">Hengshuai Yao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item1198">[1198]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.16176" title="Abstract">arXiv:2307.16176</a> (replaced) [<a href="/pdf/2307.16176" title="Download PDF">pdf</a>, <a href="/format/2307.16176" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> InvVis: Large-Scale Data Embedding for Invertible Visualization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ye%2C+H">Huayuan Ye</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+C">Chenhui Li</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yang Li</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+C">Changbo Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> IEEE VIS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item1199">[1199]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.16189" title="Abstract">arXiv:2307.16189</a> (replaced) [<a href="/pdf/2307.16189" title="Download PDF">pdf</a>, <a href="/format/2307.16189" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An Efficient Approach to Mitigate Numerical Instability in  Backpropagation for 16-bit Neural Network Training
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yun%2C+J">Juyoung Yun</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item1200">[1200]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.16489" title="Abstract">arXiv:2307.16489</a> (replaced) [<a href="/pdf/2307.16489" title="Download PDF">pdf</a>, <a href="/format/2307.16489" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> BAGM: A Backdoor Attack for Manipulating Text-to-Image Generative Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Vice%2C+J">Jordan Vice</a>, 
<a href="/search/cs?searchtype=author&query=Akhtar%2C+N">Naveed Akhtar</a>, 
<a href="/search/cs?searchtype=author&query=Hartley%2C+R">Richard Hartley</a>, 
<a href="/search/cs?searchtype=author&query=Mian%2C+A">Ajmal Mian</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This research was supported by National Intelligence and Security Discovery Research Grants (project# NS220100007), funded by the Department of Defence Australia
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Cryptography and Security (cs.CR)

</div>
</div>
</dd>
<dt><a name="item1201">[1201]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.16834" title="Abstract">arXiv:2307.16834</a> (replaced) [<a href="/pdf/2307.16834" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Benchmarking Jetson Edge Devices with an End-to-end Video-based Anomaly  Detection System
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pham%2C+H+V">Hoang Viet Pham</a>, 
<a href="/search/cs?searchtype=author&query=Tran%2C+T+G">Thinh Gia Tran</a>, 
<a href="/search/cs?searchtype=author&query=Le%2C+C+D">Chuong Dinh Le</a>, 
<a href="/search/cs?searchtype=author&query=Le%2C+A+D">An Dinh Le</a>, 
<a href="/search/cs?searchtype=author&query=Vo%2C+H+B">Hien Bich Vo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 18 pages, 7 figures, 5 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Image and Video Processing (eess.IV)

</div>
</div>
</dd>
<dt><a name="item1202">[1202]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.00085" title="Abstract">arXiv:2308.00085</a> (replaced) [<a href="/pdf/2308.00085" title="Download PDF">pdf</a>, <a href="/format/2308.00085" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Reasoning before Responding: Integrating Commonsense-based Causality  Explanation for Empathetic Response Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fu%2C+Y">Yahui Fu</a>, 
<a href="/search/cs?searchtype=author&query=Inoue%2C+K">Koji Inoue</a>, 
<a href="/search/cs?searchtype=author&query=Chu%2C+C">Chenhui Chu</a>, 
<a href="/search/cs?searchtype=author&query=Kawahara%2C+T">Tatsuya Kawahara</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by the 24th Meeting of the Special Interest Group on Discourse and Dialogue (SIGDIAL 2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item1203">[1203]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.01011" title="Abstract">arXiv:2308.01011</a> (replaced) [<a href="/pdf/2308.01011" title="Download PDF">pdf</a>, <a href="/format/2308.01011" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Enhancing Representation Learning for Periodic Time Series with Floss: A  Frequency Domain Regularization Approach
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+C">Chunwei Yang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+X">Xiaoxu Chen</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+L">Lijun Sun</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+H">Hongyu Yang</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Y">Yuankai Wu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item1204">[1204]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.01375" title="Abstract">arXiv:2308.01375</a> (replaced) [<a href="/pdf/2308.01375" title="Download PDF">pdf</a>, <a href="/format/2308.01375" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CausalOps -- Towards an Industrial Lifecycle for Causal Probabilistic  Graphical Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Maier%2C+R">Robert Maier</a>, 
<a href="/search/cs?searchtype=author&query=Schlattl%2C+A">Andreas Schlattl</a>, 
<a href="/search/cs?searchtype=author&query=Guess%2C+T">Thomas Guess</a>, 
<a href="/search/cs?searchtype=author&query=Mottok%2C+J">J&#xfc;rgen Mottok</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
</div>
</dd>
<dt><a name="item1205">[1205]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.02001" title="Abstract">arXiv:2308.02001</a> (replaced) [<a href="/pdf/2308.02001" title="Download PDF">pdf</a>, <a href="/ps/2308.02001" title="Download PostScript">ps</a>, <a href="/format/2308.02001" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Memory capacity of two layer neural networks with smooth activations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Madden%2C+L">Liam Madden</a>, 
<a href="/search/cs?searchtype=author&query=Thrampoulidis%2C+C">Christos Thrampoulidis</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Minor changes
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Optimization and Control (math.OC)

</div>
</div>
</dd>
<dt><a name="item1206">[1206]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.02463" title="Abstract">arXiv:2308.02463</a> (replaced) [<a href="/pdf/2308.02463" title="Download PDF">pdf</a>, <a href="/format/2308.02463" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Generalist Foundation Model for Radiology
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+C">Chaoyi Wu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xiaoman Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Ya Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yanfeng Wang</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+W">Weidi Xie</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Computation and Language (cs.CL)

</div>
</div>
</dd>
<dt><a name="item1207">[1207]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.02902" title="Abstract">arXiv:2308.02902</a> (replaced) [<a href="/pdf/2308.02902" title="Download PDF">pdf</a>, <a href="/format/2308.02902" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Edge of stability echo state networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ceni%2C+A">Andrea Ceni</a>, 
<a href="/search/cs?searchtype=author&query=Gallicchio%2C+C">Claudio Gallicchio</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Dynamical Systems (math.DS)

</div>
</div>
</dd>
<dt><a name="item1208">[1208]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.03572" title="Abstract">arXiv:2308.03572</a> (replaced) [<a href="/pdf/2308.03572" title="Download PDF">pdf</a>, <a href="/ps/2308.03572" title="Download PostScript">ps</a>, <a href="/format/2308.03572" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Provably Efficient Learning in Partially Observable Contextual Bandit
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gong%2C+X">Xueping Gong</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jiheng Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 47 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item1209">[1209]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.03791" title="Abstract">arXiv:2308.03791</a> (replaced) [<a href="/pdf/2308.03791" title="Download PDF">pdf</a>, <a href="/format/2308.03791" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Enabling Data Confidentiality with Public Blockchains
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Marangone%2C+E">Edoardo Marangone</a>, 
<a href="/search/cs?searchtype=author&query=Di+Ciccio%2C+C">Claudio Di Ciccio</a>, 
<a href="/search/cs?searchtype=author&query=Friolo%2C+D">Daniele Friolo</a>, 
<a href="/search/cs?searchtype=author&query=Nemmi%2C+E+N">Eugenio Nerio Nemmi</a>, 
<a href="/search/cs?searchtype=author&query=Venturi%2C+D">Daniele Venturi</a>, 
<a href="/search/cs?searchtype=author&query=Weber%2C+I">Ingo Weber</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: substantial text overlap with <a href="/abs/2303.17977">arXiv:2303.17977</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Software Engineering (cs.SE)

</div>
</div>
</dd>
<dt><a name="item1210">[1210]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.03826" title="Abstract">arXiv:2308.03826</a> (replaced) [<a href="/pdf/2308.03826" title="Download PDF">pdf</a>, <a href="/format/2308.03826" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Recurrent Multi-scale Transformer for High-Resolution Salient Object  Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Deng%2C+X">Xinhao Deng</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+P">Pingping Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+W">Wei Liu</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+H">Huchuan Lu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This work is the camera-ready version of ACM MM2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Multimedia (cs.MM)

</div>
</div>
</dd>
<dt><a name="item1211">[1211]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.04032" title="Abstract">arXiv:2308.04032</a> (replaced) [<a href="/pdf/2308.04032" title="Download PDF">pdf</a>, <a href="/format/2308.04032" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Measure of Uncertainty in Human Emotions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Panda%2C+B">Balaram Panda</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> A revised title has been adopted, differing from the original ("Investigating the impact machine emotion classification uncertainty displays have on the human decision making process"), in order to better encapsulate the research findings within the context
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Human-Computer Interaction (cs.HC)

</div>
</div>
</dd>
<dt><a name="item1212">[1212]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.04455" title="Abstract">arXiv:2308.04455</a> (replaced) [<a href="/pdf/2308.04455" title="Download PDF">pdf</a>, <a href="/format/2308.04455" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Anonymizing Speech: Evaluating and Designing Speaker Anonymization  Techniques
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Champion%2C+P">Pierre Champion</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> PhD Thesis Pierre Champion | Universit\'e de Lorraine - INRIA Nancy | for associated source code, see <a href="https://github.com/deep-privacy/SA-toolkit">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Artificial Intelligence (cs.AI); Sound (cs.SD); Audio and Speech Processing (eess.AS)

</div>
</div>
</dd>
<dt><a name="item1213">[1213]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.05967" title="Abstract">arXiv:2308.05967</a> (replaced) [<a href="/pdf/2308.05967" title="Download PDF">pdf</a>, <a href="/format/2308.05967" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> YOLOrtho -- A Unified Framework for Teeth Enumeration and Dental Disease  Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mei%2C+S">Shenxiao Mei</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+C">Chenglong Ma</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+F">Feihong Shen</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+H">Huikai Wu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item1214">[1214]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.05988" title="Abstract">arXiv:2308.05988</a> (replaced) [<a href="/pdf/2308.05988" title="Download PDF">pdf</a>, <a href="/format/2308.05988" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MS3D++: Ensemble of Experts for Multi-Source Unsupervised Domain  Adaptation in 3D Object Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tsai%2C+D">Darren Tsai</a>, 
<a href="/search/cs?searchtype=author&query=Berrio%2C+J+S">Julie Stephany Berrio</a>, 
<a href="/search/cs?searchtype=author&query=Shan%2C+M">Mao Shan</a>, 
<a href="/search/cs?searchtype=author&query=Nebot%2C+E">Eduardo Nebot</a>, 
<a href="/search/cs?searchtype=author&query=Worrall%2C+S">Stewart Worrall</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item1215">[1215]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.06035" title="Abstract">arXiv:2308.06035</a> (replaced) [<a href="/pdf/2308.06035" title="Download PDF">pdf</a>, <a href="/format/2308.06035" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Evidence of Human-Like Visual-Linguistic Integration in Multimodal Large  Language Models During Predictive Language Processing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kewenig%2C+V">Viktor Kewenig</a>, 
<a href="/search/cs?searchtype=author&query=Edwards%2C+C">Christopher Edwards</a>, 
<a href="/search/cs?searchtype=author&query=DEstalenx%2C+Q+L">Quitterie Lacome DEstalenx</a>, 
<a href="/search/cs?searchtype=author&query=Rechardt%2C+A">Akilles Rechardt</a>, 
<a href="/search/cs?searchtype=author&query=Skipper%2C+J+I">Jeremy I Skipper</a>, 
<a href="/search/cs?searchtype=author&query=Vigliocco%2C+G">Gabriella Vigliocco</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, 4 figures, submitted to journal
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computation and Language (cs.CL)

</div>
</div>
</dd>
<dt><a name="item1216">[1216]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.06733" title="Abstract">arXiv:2308.06733</a> (replaced) [<a href="/pdf/2308.06733" title="Download PDF">pdf</a>, <a href="/format/2308.06733" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Precipitation nowcasting with generative diffusion models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Asperti%2C+A">Andrea Asperti</a>, 
<a href="/search/cs?searchtype=author&query=Merizzi%2C+F">Fabio Merizzi</a>, 
<a href="/search/cs?searchtype=author&query=Paparella%2C+A">Alberto Paparella</a>, 
<a href="/search/cs?searchtype=author&query=Pedrazzi%2C+G">Giorgio Pedrazzi</a>, 
<a href="/search/cs?searchtype=author&query=Angelinelli%2C+M">Matteo Angelinelli</a>, 
<a href="/search/cs?searchtype=author&query=Colamonaco%2C+S">Stefano Colamonaco</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 21 pages, 6 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Atmospheric and Oceanic Physics (physics.ao-ph)

</div>
</div>
</dd>
<dt><a name="item1217">[1217]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.06763" title="Abstract">arXiv:2308.06763</a> (replaced) [<a href="/pdf/2308.06763" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Discovering the Symptom Patterns of COVID-19 from Recovered and Deceased  Patients Using Apriori Association Rule Mining
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dehghani%2C+M">Mohammad Dehghani</a>, 
<a href="/search/cs?searchtype=author&query=Yazdanparast%2C+Z">Zahra Yazdanparast</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Databases (cs.DB)

</div>
</div>
</dd>
<dt><a name="item1218">[1218]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.06838" title="Abstract">arXiv:2308.06838</a> (replaced) [<a href="/pdf/2308.06838" title="Download PDF">pdf</a>, <a href="/format/2308.06838" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Generalizing Topological Graph Neural Networks with Paths
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Truong%2C+Q">Quang Truong</a>, 
<a href="/search/cs?searchtype=author&query=Chin%2C+P">Peter Chin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item1219">[1219]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.06879" title="Abstract">arXiv:2308.06879</a> (replaced) [<a href="/pdf/2308.06879" title="Download PDF">pdf</a>, <a href="/format/2308.06879" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Open-Set Test-Time Adaptation Utilizing the Wisdom of Crowds in  Entropy Minimization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lee%2C+J">Jungsoo Lee</a>, 
<a href="/search/cs?searchtype=author&query=Das%2C+D">Debasmit Das</a>, 
<a href="/search/cs?searchtype=author&query=Choo%2C+J">Jaegul Choo</a>, 
<a href="/search/cs?searchtype=author&query=Choi%2C+S">Sungha Choi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to ICCV 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item1220">[1220]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.06912" title="Abstract">arXiv:2308.06912</a> (replaced) [<a href="/pdf/2308.06912" title="Download PDF">pdf</a>, <a href="/format/2308.06912" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CausalLM is not optimal for in-context learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ding%2C+N">Nan Ding</a>, 
<a href="/search/cs?searchtype=author&query=Levinboim%2C+T">Tomer Levinboim</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+J">Jialin Wu</a>, 
<a href="/search/cs?searchtype=author&query=Goodman%2C+S">Sebastian Goodman</a>, 
<a href="/search/cs?searchtype=author&query=Soricut%2C+R">Radu Soricut</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computation and Language (cs.CL)

</div>
</div>
</dd>
<dt><a name="item1221">[1221]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.07741" title="Abstract">arXiv:2308.07741</a> (replaced) [<a href="/pdf/2308.07741" title="Download PDF">pdf</a>, <a href="/format/2308.07741" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Real Robot Challenge 2022: Learning Dexterous Manipulation from Offline  Data in the Real World
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=G%C3%BCrtler%2C+N">Nico G&#xfc;rtler</a>, 
<a href="/search/cs?searchtype=author&query=Widmaier%2C+F">Felix Widmaier</a>, 
<a href="/search/cs?searchtype=author&query=Sancaktar%2C+C">Cansu Sancaktar</a>, 
<a href="/search/cs?searchtype=author&query=Blaes%2C+S">Sebastian Blaes</a>, 
<a href="/search/cs?searchtype=author&query=Kolev%2C+P">Pavel Kolev</a>, 
<a href="/search/cs?searchtype=author&query=Bauer%2C+S">Stefan Bauer</a>, 
<a href="/search/cs?searchtype=author&query=W%C3%BCthrich%2C+M">Manuel W&#xfc;thrich</a>, 
<a href="/search/cs?searchtype=author&query=Wulfmeier%2C+M">Markus Wulfmeier</a>, 
<a href="/search/cs?searchtype=author&query=Riedmiller%2C+M">Martin Riedmiller</a>, 
<a href="/search/cs?searchtype=author&query=Allshire%2C+A">Arthur Allshire</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Q">Qiang Wang</a>, 
<a href="/search/cs?searchtype=author&query=McCarthy%2C+R">Robert McCarthy</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+H">Hangyeol Kim</a>, 
<a href="/search/cs?searchtype=author&query=Pohang%2C+J+B">Jongchan Baek Pohang</a>, 
<a href="/search/cs?searchtype=author&query=Kwon%2C+W">Wookyong Kwon</a>, 
<a href="/search/cs?searchtype=author&query=Qian%2C+S">Shanliang Qian</a>, 
<a href="/search/cs?searchtype=author&query=Toshimitsu%2C+Y">Yasunori Toshimitsu</a>, 
<a href="/search/cs?searchtype=author&query=Michelis%2C+M+Y">Mike Yan Michelis</a>, 
<a href="/search/cs?searchtype=author&query=Kazemipour%2C+A">Amirhossein Kazemipour</a>, 
<a href="/search/cs?searchtype=author&query=Raayatsanati%2C+A">Arman Raayatsanati</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+H">Hehui Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Cangan%2C+B+G">Barnabas Gavin Cangan</a>, 
<a href="/search/cs?searchtype=author&query=Sch%C3%B6lkopf%2C+B">Bernhard Sch&#xf6;lkopf</a>, 
<a href="/search/cs?searchtype=author&query=Martius%2C+G">Georg Martius</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Typo in author list fixed
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item1222">[1222]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.08313" title="Abstract">arXiv:2308.08313</a> (replaced) [<a href="/pdf/2308.08313" title="Download PDF">pdf</a>, <a href="/format/2308.08313" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ECPC-IDS:A benchmark endometrail cancer PET/CT image dataset for  evaluation of semantic segmentation and detection of hypermetabolic regions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Tang%2C+D">Dechao Tang</a>, 
<a href="/search/eess?searchtype=author&query=Du%2C+T">Tianming Du</a>, 
<a href="/search/eess?searchtype=author&query=Ma%2C+D">Deguo Ma</a>, 
<a href="/search/eess?searchtype=author&query=Ma%2C+Z">Zhiyu Ma</a>, 
<a href="/search/eess?searchtype=author&query=Sun%2C+H">Hongzan Sun</a>, 
<a href="/search/eess?searchtype=author&query=Grzegorzek%2C+M">Marcin Grzegorzek</a>, 
<a href="/search/eess?searchtype=author&query=Jiang%2C+H">Huiyan Jiang</a>, 
<a href="/search/eess?searchtype=author&query=Li%2C+C">Chen Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages,6 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item1223">[1223]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.08479" title="Abstract">arXiv:2308.08479</a> (replaced) [<a href="/pdf/2308.08479" title="Download PDF">pdf</a>, <a href="/format/2308.08479" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DeDoDe: Detect, Don&#x27;t Describe -- Describe, Don&#x27;t Detect for Local  Feature Matching
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Edstedt%2C+J">Johan Edstedt</a>, 
<a href="/search/cs?searchtype=author&query=B%C3%B6kman%2C+G">Georg B&#xf6;kman</a>, 
<a href="/search/cs?searchtype=author&query=Wadenb%C3%A4ck%2C+M">M&#xe5;rten Wadenb&#xe4;ck</a>, 
<a href="/search/cs?searchtype=author&query=Felsberg%2C+M">Michael Felsberg</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item1224">[1224]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.08871" title="Abstract">arXiv:2308.08871</a> (replaced) [<a href="/pdf/2308.08871" title="Download PDF">pdf</a>, <a href="/format/2308.08871" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Spatially and Spectrally Consistent Deep Functional Maps
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sun%2C+M">Mingze Sun</a>, 
<a href="/search/cs?searchtype=author&query=Mao%2C+S">Shiwei Mao</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+P">Puhua Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Ovsjanikov%2C+M">Maks Ovsjanikov</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+R">Ruqi Huang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by ICCV2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item1225">[1225]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.08942" title="Abstract">arXiv:2308.08942</a> (replaced) [<a href="/pdf/2308.08942" title="Download PDF">pdf</a>, <a href="/format/2308.08942" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Auxiliary Tasks Benefit 3D Skeleton-based Human Motion Prediction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+C">Chenxin Xu</a>, 
<a href="/search/cs?searchtype=author&query=Tan%2C+R+T">Robby T. Tan</a>, 
<a href="/search/cs?searchtype=author&query=Tan%2C+Y">Yuhong Tan</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+S">Siheng Chen</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xinchao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yanfeng Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accpeted to ICCV2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item1226">[1226]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.08963" title="Abstract">arXiv:2308.08963</a> (replaced) [<a href="/pdf/2308.08963" title="Download PDF">pdf</a>, <a href="/format/2308.08963" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CONVERT:Contrastive Graph Clustering with Reliable Augmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+X">Xihong Yang</a>, 
<a href="/search/cs?searchtype=author&query=Tan%2C+C">Cheng Tan</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yue Liu</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+K">Ke Liang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Siwei Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+S">Sihang Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Xia%2C+J">Jun Xia</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+S+Z">Stan Z. Li</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xinwang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+E">En Zhu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item1227">[1227]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.09000" title="Abstract">arXiv:2308.09000</a> (replaced) [<a href="/pdf/2308.09000" title="Download PDF">pdf</a>, <a href="/format/2308.09000" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DealMVC: Dual Contrastive Calibration for Multi-view Clustering
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+X">Xihong Yang</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+J">Jiaqi Jin</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Siwei Wang</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+K">Ke Liang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yue Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wen%2C+Y">Yi Wen</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+S">Suyuan Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+S">Sihang Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xinwang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+E">En Zhu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item1228">[1228]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.09082" title="Abstract">arXiv:2308.09082</a> (replaced) [<a href="/pdf/2308.09082" title="Download PDF">pdf</a>, <a href="/format/2308.09082" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Over-the-Air Computation Aided Federated Learning with the Aggregation  of Normalized Gradient
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fan%2C+R">Rongfei Fan</a>, 
<a href="/search/cs?searchtype=author&query=An%2C+X">Xuming An</a>, 
<a href="/search/cs?searchtype=author&query=Zuo%2C+S">Shiyuan Zuo</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+H">Han Hu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item1229">[1229]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.09244" title="Abstract">arXiv:2308.09244</a> (replaced) [<a href="/pdf/2308.09244" title="Download PDF">pdf</a>, <a href="/format/2308.09244" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SparseBEV: High-Performance Sparse 3D Object Detection from Multi-Camera  Videos
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+H">Haisong Liu</a>, 
<a href="/search/cs?searchtype=author&query=Teng%2C+Y">Yao Teng</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+T">Tao Lu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Haiguang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+L">Limin Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to ICCV 2023. This version fixes some typos
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item1230">[1230]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.09481" title="Abstract">arXiv:2308.09481</a> (replaced) [<a href="/pdf/2308.09481" title="Download PDF">pdf</a>, <a href="/ps/2308.09481" title="Download PostScript">ps</a>, <a href="/format/2308.09481" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Types, equations, dimensions and the Pi theorem
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Botta%2C+N">Nicola Botta</a>, 
<a href="/search/cs?searchtype=author&query=Jansson%2C+P">Patrik Jansson</a>, 
<a href="/search/cs?searchtype=author&query=Da+Silva%2C+G+H+A">Guilherme Horta Alvares Da Silva</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted for publication in the "Journal of Functional Programming" in August 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Programming Languages (cs.PL)</span>; Logic in Computer Science (cs.LO)

</div>
</div>
</dd>
<dt><a name="item1231">[1231]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.09566" title="Abstract">arXiv:2308.09566</a> (replaced) [<a href="/pdf/2308.09566" title="Download PDF">pdf</a>, <a href="/format/2308.09566" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> 3D Model-free Visual Localization System from Essential Matrix under  Local Planar Motion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jiao%2C+Y">Yanmei Jiao</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+B">Binxin Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+P">Peng Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+C">Chaoqun Wang</a>, 
<a href="/search/cs?searchtype=author&query=Xiong%2C+R">Rong Xiong</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yue Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
</div>
</dd>
<dt><a name="item1232">[1232]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.09732" title="Abstract">arXiv:2308.09732</a> (replaced) [<a href="/pdf/2308.09732" title="Download PDF">pdf</a>, <a href="/format/2308.09732" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Baird Counterexample is Solved: with an example of How to Debug a  Two-time-scale Algorithm
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yao%2C+H">Hengshuai Yao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item1233">[1233]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.09780" title="Abstract">arXiv:2308.09780</a> (replaced) [<a href="/pdf/2308.09780" title="Download PDF">pdf</a>, <a href="/format/2308.09780" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Event-based Dynamic Graph Representation Learning for Patent Application  Trend Prediction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zou%2C+T">Tao Zou</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+L">Le Yu</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+L">Leilei Sun</a>, 
<a href="/search/cs?searchtype=author&query=Du%2C+B">Bowen Du</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+D">Deqing Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhuang%2C+F">Fuzhen Zhuang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by the TKDE journal
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item1234">[1234]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.09830" title="Abstract">arXiv:2308.09830</a> (replaced) [<a href="/pdf/2308.09830" title="Download PDF">pdf</a>, <a href="/format/2308.09830" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Synergistic Integration of Large Language Models and Cognitive  Architectures for Robust AI: An Exploratory Analysis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Romero%2C+O+J">Oscar J. Romero</a>, 
<a href="/search/cs?searchtype=author&query=Zimmerman%2C+J">John Zimmerman</a>, 
<a href="/search/cs?searchtype=author&query=Steinfeld%2C+A">Aaron Steinfeld</a>, 
<a href="/search/cs?searchtype=author&query=Tomasic%2C+A">Anthony Tomasic</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> AAAI 2023 Fall Symposium
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
</div>
</dd>
<dt><a name="item1235">[1235]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.09917" title="Abstract">arXiv:2308.09917</a> (replaced) [<a href="/pdf/2308.09917" title="Download PDF">pdf</a>, <a href="/format/2308.09917" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning Multiscale Consistency for Self-supervised Electron Microscopy  Instance Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yinda Chen</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+W">Wei Huang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xiaoyu Liu</a>, 
<a href="/search/cs?searchtype=author&query=Deng%2C+S">Shiyu Deng</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Q">Qi Chen</a>, 
<a href="/search/cs?searchtype=author&query=Xiong%2C+Z">Zhiwei Xiong</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item1236">[1236]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10154" title="Abstract">arXiv:2308.10154</a> (replaced) [<a href="/pdf/2308.10154" title="Download PDF">pdf</a>, <a href="/ps/2308.10154" title="Download PostScript">ps</a>, <a href="/format/2308.10154" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Resource-Adaptive Newton&#x27;s Method for Distributed Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+S">Shuzhen Chen</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+Y">Yuan Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Tao%2C+Y">Youming Tao</a>, 
<a href="/search/cs?searchtype=author&query=Cai%2C+Z">Zhipeng Cai</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+D">Dongxiao Yu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item1237">[1237]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10187" title="Abstract">arXiv:2308.10187</a> (replaced) [<a href="/pdf/2308.10187" title="Download PDF">pdf</a>, <a href="/format/2308.10187" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Spiking-Diffusion: Vector Quantized Discrete Diffusion Model with  Spiking Neural Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+M">Mingxuan Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wen%2C+R">Rui Wen</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+H">Hong Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Under Review
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neural and Evolutionary Computing (cs.NE)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item1238">[1238]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10294" title="Abstract">arXiv:2308.10294</a> (replaced) [<a href="/pdf/2308.10294" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A review of SolarWinds attack on Orion platform using persistent threat  agents and techniques for gaining unauthorized access
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kruti%2C+A">Antigoni Kruti</a>, 
<a href="/search/cs?searchtype=author&query=Butt%2C+U">Usman Butt</a>, 
<a href="/search/cs?searchtype=author&query=Sulaiman%2C+R+B">Rejwan Bin Sulaiman</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Engineering, Finance, and Science (cs.CE)</span>; Cryptography and Security (cs.CR)

</div>
</div>
</dd>
<dt><a name="item1239">[1239]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10436" title="Abstract">arXiv:2308.10436</a> (replaced) [<a href="/pdf/2308.10436" title="Download PDF">pdf</a>, <a href="/format/2308.10436" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Approximately Equivariant Graph Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Huang%2C+N">Ningyuan Huang</a>, 
<a href="/search/stat?searchtype=author&query=Levie%2C+R">Ron Levie</a>, 
<a href="/search/stat?searchtype=author&query=Villar%2C+S">Soledad Villar</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item1240">[1240]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10517" title="Abstract">arXiv:2308.10517</a> (replaced) [<a href="/pdf/2308.10517" title="Download PDF">pdf</a>, <a href="/format/2308.10517" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Patternshop: Editing Point Patterns by Image Manipulation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+X">Xingchang Huang</a>, 
<a href="/search/cs?searchtype=author&query=Ritschel%2C+T">Tobias Ritschel</a>, 
<a href="/search/cs?searchtype=author&query=Seidel%2C+H">Hans-Peter Seidel</a>, 
<a href="/search/cs?searchtype=author&query=Memari%2C+P">Pooran Memari</a>, 
<a href="/search/cs?searchtype=author&query=Singh%2C+G">Gurprit Singh</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> ACM Transactions on Graphics 2023 Volume 42 Issue 4 Article No.:
  53
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Graphics (cs.GR)</span>

</div>
</div>
</dd>
<dt><a name="item1241">[1241]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10620" title="Abstract">arXiv:2308.10620</a> (replaced) [<a href="/pdf/2308.10620" title="Download PDF">pdf</a>, <a href="/format/2308.10620" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Large Language Models for Software Engineering: A Systematic Literature  Review
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hou%2C+X">Xinyi Hou</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Y">Yanjie Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yue Liu</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Z">Zhou Yang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+K">Kailong Wang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+L">Li Li</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+X">Xiapu Luo</a>, 
<a href="/search/cs?searchtype=author&query=Lo%2C+D">David Lo</a>, 
<a href="/search/cs?searchtype=author&query=Grundy%2C+J">John Grundy</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Haoyu Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item1242">[1242]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10811" title="Abstract">arXiv:2308.10811</a> (replaced) [<a href="/pdf/2308.10811" title="Download PDF">pdf</a>, <a href="/format/2308.10811" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Tree Drawings with Columns
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Klawitter%2C+J">Jonathan Klawitter</a>, 
<a href="/search/cs?searchtype=author&query=Zink%2C+J">Johannes Zink</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Appears in the Proceedings of the 31st International Symposium on Graph Drawing and Network Visualization (GD 2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Geometry (cs.CG)</span>; Discrete Mathematics (cs.DM)

</div>
</div>
</dd>
<dt><a name="item1243">[1243]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.11127" title="Abstract">arXiv:2308.11127</a> (replaced) [<a href="/pdf/2308.11127" title="Download PDF">pdf</a>, <a href="/format/2308.11127" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> How Expressive are Graph Neural Networks in Recommendation?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cai%2C+X">Xuheng Cai</a>, 
<a href="/search/cs?searchtype=author&query=Xia%2C+L">Lianghao Xia</a>, 
<a href="/search/cs?searchtype=author&query=Ren%2C+X">Xubin Ren</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+C">Chao Huang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 32nd ACM International Conference on Information and Knowledge Management (CIKM) 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Machine Learning (cs.LG); Social and Information Networks (cs.SI)

</div>
</div>
</dd>
<dt><a name="item1244">[1244]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.11148" title="Abstract">arXiv:2308.11148</a> (replaced) [<a href="/pdf/2308.11148" title="Download PDF">pdf</a>, <a href="/format/2308.11148" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LLaMA-Reviewer: Advancing Code Review Automation with Large Language  Models through Parameter-Efficient Fine-Tuning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lu%2C+J">Junyi Lu</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+L">Lei Yu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xiaojia Li</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+L">Li Yang</a>, 
<a href="/search/cs?searchtype=author&query=Zuo%2C+C">Chun Zuo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to the 34th IEEE International Symposium on Software Reliability Engineering (ISSRE 2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>; Computation and Language (cs.CL); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item1245">[1245]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.11561" title="Abstract">arXiv:2308.11561</a> (replaced) [<a href="/pdf/2308.11561" title="Download PDF">pdf</a>, <a href="/format/2308.11561" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Target-Grounded Graph-Aware Transformer for Aerial Vision-and-Dialog  Navigation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Su%2C+Y">Yifei Su</a>, 
<a href="/search/cs?searchtype=author&query=An%2C+D">Dong An</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+Y">Yuan Xu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+K">Kehan Chen</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+Y">Yan Huang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item1246">[1246]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.11592" title="Abstract">arXiv:2308.11592</a> (replaced) [<a href="/pdf/2308.11592" title="Download PDF">pdf</a>, <a href="/format/2308.11592" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> UniDoc: A Universal Large Multimodal Model for Simultaneous Text  Detection, Recognition, Spotting and Understanding
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Feng%2C+H">Hao Feng</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zijian Wang</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+J">Jingqun Tang</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+J">Jinghui Lu</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+W">Wengang Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Houqiang Li</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+C">Can Huang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computation and Language (cs.CL)

</div>
</div>
</dd>
<dt><a name="item1247">[1247]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.11676" title="Abstract">arXiv:2308.11676</a> (replaced) [<a href="/pdf/2308.11676" title="Download PDF">pdf</a>, <a href="/format/2308.11676" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Does Misclassifying Non-confounding Covariates as Confounders Affect the  Causal Inference within the Potential Outcomes Framework?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Zhao%2C+Y">Yonghe Zhao</a>, 
<a href="/search/stat?searchtype=author&query=Huang%2C+Q">Qiang Huang</a>, 
<a href="/search/stat?searchtype=author&query=Fu%2C+S">Shuai Fu</a>, 
<a href="/search/stat?searchtype=author&query=Sun%2C+H">Huiyan Sun</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 4 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Methodology (stat.ME)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item1248">[1248]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.11724" title="Abstract">arXiv:2308.11724</a> (replaced) [<a href="/pdf/2308.11724" title="Download PDF">pdf</a>, <a href="/format/2308.11724" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MolSieve: A Progressive Visual Analytics System for Molecular Dynamics  Simulations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Hnatyshyn%2C+R">Rostyslav Hnatyshyn</a>, 
<a href="/search/physics?searchtype=author&query=Zhao%2C+J">Jieqiong Zhao</a>, 
<a href="/search/physics?searchtype=author&query=Perez%2C+D">Danny Perez</a>, 
<a href="/search/physics?searchtype=author&query=Ahrens%2C+J">James Ahrens</a>, 
<a href="/search/physics?searchtype=author&query=Maciejewski%2C+R">Ross Maciejewski</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Updated references to GPCCA
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Physics (physics.comp-ph)</span>; Graphics (cs.GR); Human-Computer Interaction (cs.HC)

</div>
</div>
</dd>
<dt><a name="item1249">[1249]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.11773" title="Abstract">arXiv:2308.11773</a> (replaced) [<a href="/pdf/2308.11773" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Identifying depression-related topics in smartphone-collected  free-response speech recordings using an automatic speech recognition system  and a deep learning topic model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yuezhou Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Folarin%2C+A+A">Amos A Folarin</a>, 
<a href="/search/cs?searchtype=author&query=Dineley%2C+J">Judith Dineley</a>, 
<a href="/search/cs?searchtype=author&query=Conde%2C+P">Pauline Conde</a>, 
<a href="/search/cs?searchtype=author&query=de+Angel%2C+V">Valeria de Angel</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+S">Shaoxiong Sun</a>, 
<a href="/search/cs?searchtype=author&query=Ranjan%2C+Y">Yatharth Ranjan</a>, 
<a href="/search/cs?searchtype=author&query=Rashid%2C+Z">Zulqarnain Rashid</a>, 
<a href="/search/cs?searchtype=author&query=Stewart%2C+C">Callum Stewart</a>, 
<a href="/search/cs?searchtype=author&query=Laiou%2C+P">Petroula Laiou</a>, 
<a href="/search/cs?searchtype=author&query=Sankesara%2C+H">Heet Sankesara</a>, 
<a href="/search/cs?searchtype=author&query=Qian%2C+L">Linglong Qian</a>, 
<a href="/search/cs?searchtype=author&query=Matcham%2C+F">Faith Matcham</a>, 
<a href="/search/cs?searchtype=author&query=White%2C+K+M">Katie M White</a>, 
<a href="/search/cs?searchtype=author&query=Oetzmann%2C+C">Carolin Oetzmann</a>, 
<a href="/search/cs?searchtype=author&query=Lamers%2C+F">Femke Lamers</a>, 
<a href="/search/cs?searchtype=author&query=Siddi%2C+S">Sara Siddi</a>, 
<a href="/search/cs?searchtype=author&query=Simblett%2C+S">Sara Simblett</a>, 
<a href="/search/cs?searchtype=author&query=Schuller%2C+B+W">Bj&#xf6;rn W. Schuller</a>, 
<a href="/search/cs?searchtype=author&query=Vairavan%2C+S">Srinivasan Vairavan</a>, 
<a href="/search/cs?searchtype=author&query=Wykes%2C+T">Til Wykes</a>, 
<a href="/search/cs?searchtype=author&query=Haro%2C+J+M">Josep Maria Haro</a>, 
<a href="/search/cs?searchtype=author&query=Penninx%2C+B+W">Brenda WJH Penninx</a>, 
<a href="/search/cs?searchtype=author&query=Narayan%2C+V+A">Vaibhav A Narayan</a>, 
<a href="/search/cs?searchtype=author&query=Hotopf%2C+M">Matthew Hotopf</a>, 
<a href="/search/cs?searchtype=author&query=Dobson%2C+R+J">Richard JB Dobson</a>, 
<a href="/search/cs?searchtype=author&query=Cummins%2C+N">Nicholas Cummins</a>, 
<a href="/search/cs?searchtype=author&query=consortium%2C+R">RADAR-CNS consortium</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Computers and Society (cs.CY); Sound (cs.SD); Audio and Speech Processing (eess.AS); Quantitative Methods (q-bio.QM)

</div>
</div>
</dd>
<dt><a name="item1250">[1250]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.11817" title="Abstract">arXiv:2308.11817</a> (replaced) [<a href="/pdf/2308.11817" title="Download PDF">pdf</a>, <a href="/format/2308.11817" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Honeypot Allocation for Cyber Deception in Dynamic Tactical Networks: A  Game Theoretic Approach
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sayed%2C+M+A">Md Abu Sayed</a>, 
<a href="/search/cs?searchtype=author&query=Anwar%2C+A+H">Ahmed H. Anwar</a>, 
<a href="/search/cs?searchtype=author&query=Kiekintveld%2C+C">Christopher Kiekintveld</a>, 
<a href="/search/cs?searchtype=author&query=Kamhoua%2C+C">Charles Kamhoua</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This paper accepted in 14th International Conference on Decision and Game Theory for Security, GameSec 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>

</div>
</div>
</dd>
<dt><a name="item1251">[1251]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.11909" title="Abstract">arXiv:2308.11909</a> (replaced) [<a href="/pdf/2308.11909" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Edge-aware Hard Clustering Graph Pooling for Brain Imaging Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhu%2C+C">Cheng Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+J">Jiayi Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+L">Lijuan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+X">Xi Wu</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+S">Shuqi Yang</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+P">Ping Liang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+H">Honghan Chen</a>, 
<a href="/search/cs?searchtype=author&query=Tan%2C+Y">Ying Tan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Graphics (cs.GR)

</div>
</div>
</dd>
<dt><a name="item1252">[1252]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.11914" title="Abstract">arXiv:2308.11914</a> (replaced) [<a href="/pdf/2308.11914" title="Download PDF">pdf</a>, <a href="/format/2308.11914" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards CausalGPT: A Multi-Agent Approach for Faithful Knowledge  Reasoning via Promoting Causal Consistency in LLMs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tang%2C+Z">Ziyi Tang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+R">Ruilin Wang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+W">Weixing Chen</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+K">Keze Wang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+T">Tianshui Chen</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+L">Liang Lin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 3 figures. 4 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Multiagent Systems (cs.MA)

</div>
</div>
</dd>
<dt><a name="item1253">[1253]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.11917" title="Abstract">arXiv:2308.11917</a> (replaced) [<a href="/pdf/2308.11917" title="Download PDF">pdf</a>, <a href="/format/2308.11917" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LFS-GAN: Lifelong Few-Shot Image Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Seo%2C+J">Juwon Seo</a>, 
<a href="/search/cs?searchtype=author&query=Kang%2C+J">Ji-Su Kang</a>, 
<a href="/search/cs?searchtype=author&query=Park%2C+G">Gyeong-Moon Park</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 20 pages, 19 figures, 14 tables, ICCV 2023 Poster
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item1254">[1254]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.12000" title="Abstract">arXiv:2308.12000</a> (replaced) [<a href="/pdf/2308.12000" title="Download PDF">pdf</a>, <a href="/ps/2308.12000" title="Download PostScript">ps</a>, <a href="/format/2308.12000" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On Uniformly Optimal Algorithms for Best Arm Identification in Two-Armed  Bandits with Fixed Budget
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Wang%2C+P">Po-An Wang</a>, 
<a href="/search/stat?searchtype=author&query=Ariu%2C+K">Kaito Ariu</a>, 
<a href="/search/stat?searchtype=author&query=Proutiere%2C+A">Alexandre Proutiere</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item1255">[1255]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.12014" title="Abstract">arXiv:2308.12014</a> (replaced) [<a href="/pdf/2308.12014" title="Download PDF">pdf</a>, <a href="/format/2308.12014" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> From Instructions to Intrinsic Human Values -- A Survey of Alignment  Goals for Big Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yao%2C+J">Jing Yao</a>, 
<a href="/search/cs?searchtype=author&query=Yi%2C+X">Xiaoyuan Yi</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xiting Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jindong Wang</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+X">Xing Xie</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 20 pages, 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computation and Language (cs.CL); Computers and Society (cs.CY)

</div>
</div>
</dd>
<dt><a name="item1256">[1256]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.12016" title="Abstract">arXiv:2308.12016</a> (replaced) [<a href="/pdf/2308.12016" title="Download PDF">pdf</a>, <a href="/ps/2308.12016" title="Download PostScript">ps</a>, <a href="/format/2308.12016" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MKL-$L_{0/1}$-SVM
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Zhu%2C+B">Bin Zhu</a>, 
<a href="/search/stat?searchtype=author&query=Shi%2C+Y">Yijie Shi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 26 pages in the JMLR template, 3 figures, and 2 tables, submitted to the Journal of Machine Learning Research, with minor text overlap with arXiv: <a href="/abs/2303.04445">2303.04445</a> (conference version). arXiv admin note: text overlap with <a href="/abs/2303.04445">arXiv:2303.04445</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item1257">[1257]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.12288" title="Abstract">arXiv:2308.12288</a> (replaced) [<a href="/pdf/2308.12288" title="Download PDF">pdf</a>, <a href="/format/2308.12288" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CHORUS: Learning Canonicalized 3D Human-Object Spatial Relations from  Unbounded Synthesized Images
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Han%2C+S">Sookwan Han</a>, 
<a href="/search/cs?searchtype=author&query=Joo%2C+H">Hanbyul Joo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to ICCV 2023 (Oral Presentation). Project Page: <a href="https://jellyheadandrew.github.io/projects/chorus">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item1258">[1258]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.12554" title="Abstract">arXiv:2308.12554</a> (replaced) [<a href="/pdf/2308.12554" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deep Reinforcement Learning-driven Cross-Community Energy Interaction  Optimal Scheduling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Li%2C+Y">Yang Li</a>, 
<a href="/search/eess?searchtype=author&query=Ma%2C+W">Wenjie Ma</a>, 
<a href="/search/eess?searchtype=author&query=Bu%2C+F">Fanjin Bu</a>, 
<a href="/search/eess?searchtype=author&query=Yang%2C+Z">Zhen Yang</a>, 
<a href="/search/eess?searchtype=author&query=Wang%2C+B">Bin Wang</a>, 
<a href="/search/eess?searchtype=author&query=Han%2C+M">Meng Han</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> in Chinese language, Accepted by Electric Power Construction
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item1259">[1259]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.12621" title="Abstract">arXiv:2308.12621</a> (replaced) [<a href="/pdf/2308.12621" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Hydrogen jet diffusion modeling by using physics-informed graph neural  network and sparsely-distributed sensor data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xinqi Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+J">Jihao Shi</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Junjie Li</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+X">Xinyan Huang</a>, 
<a href="/search/cs?searchtype=author&query=Xiao%2C+F">Fu Xiao</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Q">Qiliang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Usmani%2C+A+S">Asif Sohail Usmani</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+G">Guoming Chen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Engineering, Finance, and Science (cs.CE)</span>

</div>
</div>
</dd>
<dt><a name="item1260">[1260]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.12792" title="Abstract">arXiv:2308.12792</a> (replaced) [<a href="/pdf/2308.12792" title="Download PDF">pdf</a>, <a href="/format/2308.12792" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Sparks of Large Audio Models: A Survey and Outlook
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Latif%2C+S">Siddique Latif</a>, 
<a href="/search/cs?searchtype=author&query=Shoukat%2C+M">Moazzam Shoukat</a>, 
<a href="/search/cs?searchtype=author&query=Shamshad%2C+F">Fahad Shamshad</a>, 
<a href="/search/cs?searchtype=author&query=Usama%2C+M">Muhammad Usama</a>, 
<a href="/search/cs?searchtype=author&query=Ren%2C+Y">Yi Ren</a>, 
<a href="/search/cs?searchtype=author&query=Cuay%C3%A1huitl%2C+H">Heriberto Cuay&#xe1;huitl</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+W">Wenwu Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xulong Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Togneri%2C+R">Roberto Togneri</a>, 
<a href="/search/cs?searchtype=author&query=Schuller%2C+B+W">Bj&#xf6;rn W. Schuller</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> work in progress, Repo URL: <a href="https://github.com/EmulationAI/awesome-large-audio-models">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Audio and Speech Processing (eess.AS)

</div>
</div>
</dd>
<dt><a name="item1261">[1261]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.13315" title="Abstract">arXiv:2308.13315</a> (replaced) [<a href="/pdf/2308.13315" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Construction Grammar and Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Madabushi%2C+H+T">Harish Tayyar Madabushi</a>, 
<a href="/search/cs?searchtype=author&query=Romain%2C+L">Laurence Romain</a>, 
<a href="/search/cs?searchtype=author&query=Milin%2C+P">Petar Milin</a>, 
<a href="/search/cs?searchtype=author&query=Divjak%2C+D">Dagmar Divjak</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted for publication in The Cambridge Handbook of Construction Grammar, edited by Mirjam Fried and Kiki Nikiforidou. To appear in 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item1262">[1262]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.13365" title="Abstract">arXiv:2308.13365</a> (replaced) [<a href="/pdf/2308.13365" title="Download PDF">pdf</a>, <a href="/format/2308.13365" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Expressive paragraph text-to-speech synthesis with multi-step  variational autoencoder
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xuyuan Li</a>, 
<a href="/search/cs?searchtype=author&query=Shang%2C+Z">Zengqiang Shang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jian Liu</a>, 
<a href="/search/cs?searchtype=author&query=Hua%2C+H">Hua Hua</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+P">Peiyang Shi</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+P">Pengyuan Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages, 1 figure, 2 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Audio and Speech Processing (eess.AS)

</div>
</div>
</dd>
<dt><a name="item1263">[1263]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.13387" title="Abstract">arXiv:2308.13387</a> (replaced) [<a href="/pdf/2308.13387" title="Download PDF">pdf</a>, <a href="/format/2308.13387" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Do-Not-Answer: A Dataset for Evaluating Safeguards in LLMs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yuxia Wang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Haonan Li</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+X">Xudong Han</a>, 
<a href="/search/cs?searchtype=author&query=Nakov%2C+P">Preslav Nakov</a>, 
<a href="/search/cs?searchtype=author&query=Baldwin%2C+T">Timothy Baldwin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 18 pages, 9 figures, 11 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item1264">[1264]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.13401" title="Abstract">arXiv:2308.13401</a> (replaced) [<a href="/pdf/2308.13401" title="Download PDF">pdf</a>, <a href="/format/2308.13401" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Min-$k$-planar Drawings of Graphs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Binucci%2C+C">Carla Binucci</a>, 
<a href="/search/cs?searchtype=author&query=B%C3%BCngener%2C+A">Aaron B&#xfc;ngener</a>, 
<a href="/search/cs?searchtype=author&query=Di+Battista%2C+G">Giuseppe Di Battista</a>, 
<a href="/search/cs?searchtype=author&query=Didimo%2C+W">Walter Didimo</a>, 
<a href="/search/cs?searchtype=author&query=Dujmovi%C4%87%2C+V">Vida Dujmovi&#x107;</a>, 
<a href="/search/cs?searchtype=author&query=Hong%2C+S">Seok-Hee Hong</a>, 
<a href="/search/cs?searchtype=author&query=Kaufmann%2C+M">Michael Kaufmann</a>, 
<a href="/search/cs?searchtype=author&query=Liotta%2C+G">Giuseppe Liotta</a>, 
<a href="/search/cs?searchtype=author&query=Morin%2C+P">Pat Morin</a>, 
<a href="/search/cs?searchtype=author&query=Tappini%2C+A">Alessandra Tappini</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Appears in the Proceedings of the 31st International Symposium on Graph Drawing and Network Visualization (GD 2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Geometry (cs.CG)</span>

</div>
</div>
</dd>
<dt><a name="item1265">[1265]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.13551" title="Abstract">arXiv:2308.13551</a> (replaced) [<a href="/pdf/2308.13551" title="Download PDF">pdf</a>, <a href="/format/2308.13551" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Dance with You: The Diversity Controllable Dancer Generation via  Diffusion Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yao%2C+S">Siyue Yao</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+M">Mingjie Sun</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+B">Bingliang Li</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+F">Fengyu Yang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Junle Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+R">Ruimao Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by ACM MM 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Artificial Intelligence (cs.AI); Graphics (cs.GR)

</div>
</div>
</dd>
<dt><a name="item1266">[1266]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.13570" title="Abstract">arXiv:2308.13570</a> (replaced) [<a href="/pdf/2308.13570" title="Download PDF">pdf</a>, <a href="/format/2308.13570" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Stochastic Configuration Machines for Industrial Artificial Intelligence
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+D">Dianhui Wang</a>, 
<a href="/search/cs?searchtype=author&query=Felicetti%2C+M+J">Matthew J. Felicetti</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 23 pages, 7 figures, 12 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Neural and Evolutionary Computing (cs.NE)

</div>
</div>
</dd>
<dt><a name="item1267">[1267]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.13665" title="Abstract">arXiv:2308.13665</a> (replaced) [<a href="/pdf/2308.13665" title="Download PDF">pdf</a>, <a href="/format/2308.13665" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the Parameterized Complexity of Bend-Minimum Orthogonal Planarity
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Didimo%2C+W">Walter Didimo</a>, 
<a href="/search/cs?searchtype=author&query=Di+Giacomo%2C+E">Emilio Di Giacomo</a>, 
<a href="/search/cs?searchtype=author&query=Liotta%2C+G">Giuseppe Liotta</a>, 
<a href="/search/cs?searchtype=author&query=Montecchiani%2C+F">Fabrizio Montecchiani</a>, 
<a href="/search/cs?searchtype=author&query=Ortali%2C+G">Giacomo Ortali</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Appears in the Proceedings of the 31st International Symposium on Graph Drawing and Network Visualization (GD 2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Geometry (cs.CG)</span>; Data Structures and Algorithms (cs.DS)

</div>
</div>
</dd>
<dt><a name="item1268">[1268]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.13679" title="Abstract">arXiv:2308.13679</a> (replaced) [<a href="/pdf/2308.13679" title="Download PDF">pdf</a>, <a href="/format/2308.13679" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An Open Hyperspectral Dataset with Sea-Land-Cloud Ground-Truth from the  HYPSO-1 Satellite
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Justo%2C+J+A">Jon A. Justo</a>, 
<a href="/search/cs?searchtype=author&query=Garrett%2C+J">Joseph Garrett</a>, 
<a href="/search/cs?searchtype=author&query=Langer%2C+D+D">Dennis D. Langer</a>, 
<a href="/search/cs?searchtype=author&query=Henriksen%2C+M+B">Marie B. Henriksen</a>, 
<a href="/search/cs?searchtype=author&query=Ionescu%2C+R+T">Radu T. Ionescu</a>, 
<a href="/search/cs?searchtype=author&query=Johansen%2C+T+A">Tor A. Johansen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Computer Vision, Artificial Intelligence, Remote Sensing, Earth Observation, Hyperspectral Imaging, Classification, Labeled Data
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item1269">[1269]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.13700" title="Abstract">arXiv:2308.13700</a> (replaced) [<a href="/e-print/2308.13700" title="Download source">src</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multipartite Entanglement in Quantum Networks using Subgraph  Complementations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Sen%2C+A">Aniruddha Sen</a>, 
<a href="/search/quant-ph?searchtype=author&query=Goodenough%2C+K">Kenneth Goodenough</a>, 
<a href="/search/quant-ph?searchtype=author&query=Towsley%2C+D">Don Towsley</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Background section is condensed and requires further clarification
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Data Structures and Algorithms (cs.DS); Networking and Internet Architecture (cs.NI)

</div>
</div>
</dd>
<dt><a name="item1270">[1270]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.13976" title="Abstract">arXiv:2308.13976</a> (replaced) [<a href="/pdf/2308.13976" title="Download PDF">pdf</a>, <a href="/format/2308.13976" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Label Denoising through Cross-Model Agreement
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yu Wang</a>, 
<a href="/search/cs?searchtype=author&query=Xin%2C+X">Xin Xin</a>, 
<a href="/search/cs?searchtype=author&query=Meng%2C+Z">Zaiqiao Meng</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+X">Xiangnan He</a>, 
<a href="/search/cs?searchtype=author&query=Jose%2C+J">Joemon Jose</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+F">Fuli Feng</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: substantial text overlap with <a href="/abs/2105.09605">arXiv:2105.09605</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item1271">[1271]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.13992" title="Abstract">arXiv:2308.13992</a> (replaced) [<a href="/pdf/2308.13992" title="Download PDF">pdf</a>, <a href="/ps/2308.13992" title="Download PostScript">ps</a>, <a href="/format/2308.13992" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Testing Junta Truncation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=He%2C+W">William He</a>, 
<a href="/search/cs?searchtype=author&query=Nadimpalli%2C+S">Shivam Nadimpalli</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Complexity (cs.CC)</span>; Data Structures and Algorithms (cs.DS); Probability (math.PR); Statistics Theory (math.ST)

</div>
</div>
</dd>
<dt><a name="item1272">[1272]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.14081" title="Abstract">arXiv:2308.14081</a> (replaced) [<a href="/pdf/2308.14081" title="Download PDF">pdf</a>, <a href="/format/2308.14081" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> U-SEANNet: A Simple, Efficient and Applied U-Shaped Network for  Diagnosis of Nasal Diseases on Nasal Endoscopic Images
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Yue%2C+Y">Yubiao Yue</a>, 
<a href="/search/eess?searchtype=author&query=Xue%2C+J">Jun Xue</a>, 
<a href="/search/eess?searchtype=author&query=Wang%2C+C">Chao Wang</a>, 
<a href="/search/eess?searchtype=author&query=Liang%2C+H">Haihua Liang</a>, 
<a href="/search/eess?searchtype=author&query=Li%2C+Z">Zhenzhang Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This manuscript has been submitted to ICASSP 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item1273">[1273]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.14161" title="Abstract">arXiv:2308.14161</a> (replaced) [<a href="/pdf/2308.14161" title="Download PDF">pdf</a>, <a href="/format/2308.14161" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Intergrated Segmentation and Detection Models for Dentex Challenge 2023
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=He%2C+L">Lanshan He</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yusheng Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+L">Lisheng Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item1274">[1274]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.14177" title="Abstract">arXiv:2308.14177</a> (replaced) [<a href="/pdf/2308.14177" title="Download PDF">pdf</a>, <a href="/format/2308.14177" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AI-generated Content for Various Data Modalities: A Survey
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Foo%2C+L+G">Lin Geng Foo</a>, 
<a href="/search/cs?searchtype=author&query=Rahmani%2C+H">Hossein Rahmani</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jun Liu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item1275">[1275]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.14284" title="Abstract">arXiv:2308.14284</a> (replaced) [<a href="/pdf/2308.14284" title="Download PDF">pdf</a>, <a href="/format/2308.14284" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LLM Powered Sim-to-real Transfer for Traffic Signal Control
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Da%2C+L">Longchao Da</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+M">Minchiuan Gao</a>, 
<a href="/search/cs?searchtype=author&query=Mei%2C+H">Hao Mei</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+H">Hua Wei</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages, 7 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
</div>
</dd>
<dt><a name="item1276">[1276]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.14334" title="Abstract">arXiv:2308.14334</a> (replaced) [<a href="/pdf/2308.14334" title="Download PDF">pdf</a>, <a href="/format/2308.14334" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MetaWeather: Few-Shot Weather-Degraded Image Restoration via Degradation  Pattern Matching
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kim%2C+Y">Youngrae Kim</a>, 
<a href="/search/cs?searchtype=author&query=Cho%2C+Y">Younggeol Cho</a>, 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+T">Thanh-Tung Nguyen</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+D">Dongman Lee</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 6 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item1277">[1277]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.14435" title="Abstract">arXiv:2308.14435</a> (replaced) [<a href="/pdf/2308.14435" title="Download PDF">pdf</a>, <a href="/format/2308.14435" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Do Successful Researchers Reach the Self-Organized Critical Point?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ghosh%2C+A">Asim Ghosh</a>, 
<a href="/search/cs?searchtype=author&query=Chakrabarti%2C+B+K">Bikas K. Chakrabarti</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Invited contribution to Galam Special Issue in Physics (MDPI)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Digital Libraries (cs.DL)</span>; Physics and Society (physics.soc-ph)

</div>
</div>
</dd>
<dt><a name="item1278">[1278]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.14553" title="Abstract">arXiv:2308.14553</a> (replaced) [<a href="/pdf/2308.14553" title="Download PDF">pdf</a>, <a href="/format/2308.14553" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Rep2wav: Noise Robust text-to-speech Using self-supervised  representations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Zhu%2C+Q">Qiushi Zhu</a>, 
<a href="/search/eess?searchtype=author&query=Gu%2C+Y">Yu Gu</a>, 
<a href="/search/eess?searchtype=author&query=Chen%2C+R">Rilin Chen</a>, 
<a href="/search/eess?searchtype=author&query=Weng%2C+C">Chao Weng</a>, 
<a href="/search/eess?searchtype=author&query=Hu%2C+Y">Yuchen Hu</a>, 
<a href="/search/eess?searchtype=author&query=Dai%2C+L">Lirong Dai</a>, 
<a href="/search/eess?searchtype=author&query=Zhang%2C+J">Jie Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages,2 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Sound (cs.SD)

</div>
</div>
</dd>
<dt><a name="item1279">[1279]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.14659" title="Abstract">arXiv:2308.14659</a> (replaced) [<a href="/pdf/2308.14659" title="Download PDF">pdf</a>, <a href="/format/2308.14659" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> RESTORE: Graph Embedding Assessment Through Reconstruction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yip%2C+H+Y">Hong Yung Yip</a>, 
<a href="/search/cs?searchtype=author&query=Ravuru%2C+C">Chidaksh Ravuru</a>, 
<a href="/search/cs?searchtype=author&query=Banerjee%2C+N">Neelabha Banerjee</a>, 
<a href="/search/cs?searchtype=author&query=Jha%2C+S">Shashwat Jha</a>, 
<a href="/search/cs?searchtype=author&query=Sheth%2C+A">Amit Sheth</a>, 
<a href="/search/cs?searchtype=author&query=Chadha%2C+A">Aman Chadha</a>, 
<a href="/search/cs?searchtype=author&query=Das%2C+A">Amitava Das</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item1280">[1280]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.14781" title="Abstract">arXiv:2308.14781</a> (replaced) [<a href="/pdf/2308.14781" title="Download PDF">pdf</a>, <a href="/ps/2308.14781" title="Download PostScript">ps</a>, <a href="/format/2308.14781" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Conflict-Aware Active Automata Learning (Extended Version)
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ferreira%2C+T">Tiago Ferreira</a>, 
<a href="/search/cs?searchtype=author&query=Henry%2C+L">L&#xe9;o Henry</a>, 
<a href="/search/cs?searchtype=author&query=da+Silva%2C+R+F">Raquel Fernandes da Silva</a>, 
<a href="/search/cs?searchtype=author&query=Silva%2C+A">Alexandra Silva</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 37 pages, 11 figures, GandALF 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Formal Languages and Automata Theory (cs.FL)

</div>
</div>
</dd>
<dt><a name="item1281">[1281]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.15012" title="Abstract">arXiv:2308.15012</a> (replaced) [<a href="/pdf/2308.15012" title="Download PDF">pdf</a>, <a href="/format/2308.15012" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SALI: A Scalable Adaptive Learned Index Framework based on Probability  Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ge%2C+J">Jiake Ge</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Huanchen Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+B">Boyu Shi</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+Y">Yuanhui Luo</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+Y">Yunda Guo</a>, 
<a href="/search/cs?searchtype=author&query=Chai%2C+Y">Yunpeng Chai</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yuxing Chen</a>, 
<a href="/search/cs?searchtype=author&query=Pan%2C+A">Anqun Pan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by Conference SIGMOD 24, June 09-15, 2024, Santiago, Chile
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Databases (cs.DB)</span>

</div>
</div>
</dd>
<dt><a name="item1282">[1282]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.15059" title="Abstract">arXiv:2308.15059</a> (replaced) [<a href="/pdf/2308.15059" title="Download PDF">pdf</a>, <a href="/format/2308.15059" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> OEBench: Investigating Open Environment Challenges in Real-World  Relational Data Streams
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Diao%2C+Y">Yiqun Diao</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yutong Yang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Q">Qinbin Li</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+B">Bingsheng He</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+M">Mian Lu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Databases (cs.DB)

</div>
</div>
</dd>
<dt><a name="item1283">[1283]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.15276" title="Abstract">arXiv:2308.15276</a> (replaced) [<a href="/pdf/2308.15276" title="Download PDF">pdf</a>, <a href="/format/2308.15276" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Large Language Models in Fault Localisation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+Y">Yonghao Wu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zheng Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J+M">Jie M. Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Papadakis%2C+M">Mike Papadakis</a>, 
<a href="/search/cs?searchtype=author&query=Harman%2C+M">Mark Harman</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yong Liu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
</div>
</dd>
<dt><a name="item1284">[1284]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.15366" title="Abstract">arXiv:2308.15366</a> (replaced) [<a href="/pdf/2308.15366" title="Download PDF">pdf</a>, <a href="/format/2308.15366" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AnomalyGPT: Detecting Industrial Anomalies using Large Vision-Language  Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gu%2C+Z">Zhaopeng Gu</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+B">Bingke Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+G">Guibo Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yingying Chen</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+M">Ming Tang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jinqiao Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project page: <a href="https://anomalygpt.github.io">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item1285">[1285]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.15442" title="Abstract">arXiv:2308.15442</a> (replaced) [<a href="/pdf/2308.15442" title="Download PDF">pdf</a>, <a href="/format/2308.15442" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Lower Bounds on Number of QAOA Rounds Required for Guaranteed  Approximation Ratios
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Benchasattabuse%2C+N">Naphan Benchasattabuse</a>, 
<a href="/search/quant-ph?searchtype=author&query=B%C3%A4rtschi%2C+A">Andreas B&#xe4;rtschi</a>, 
<a href="/search/quant-ph?searchtype=author&query=Garc%C3%ADa-Pintos%2C+L+P">Luis Pedro Garc&#xed;a-Pintos</a>, 
<a href="/search/quant-ph?searchtype=author&query=Golden%2C+J">John Golden</a>, 
<a href="/search/quant-ph?searchtype=author&query=Lemons%2C+N">Nathan Lemons</a>, 
<a href="/search/quant-ph?searchtype=author&query=Eidenbenz%2C+S">Stephan Eidenbenz</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 24 pages, comments welcome, v3: correct some phrasing; results stay unchanged
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Data Structures and Algorithms (cs.DS)

</div>
</div>
</dd>
<dt><a name="item1286">[1286]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.15459" title="Abstract">arXiv:2308.15459</a> (replaced) [<a href="/pdf/2308.15459" title="Download PDF">pdf</a>, <a href="/format/2308.15459" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ParaGuide: Guided Diffusion Paraphrasers for Plug-and-Play Textual Style  Transfer
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Horvitz%2C+Z">Zachary Horvitz</a>, 
<a href="/search/cs?searchtype=author&query=Patel%2C+A">Ajay Patel</a>, 
<a href="/search/cs?searchtype=author&query=Callison-Burch%2C+C">Chris Callison-Burch</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+Z">Zhou Yu</a>, 
<a href="/search/cs?searchtype=author&query=McKeown%2C+K">Kathleen McKeown</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item1287">[1287]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.15568" title="Abstract">arXiv:2308.15568</a> (replaced) [<a href="/pdf/2308.15568" title="Download PDF">pdf</a>, <a href="/ps/2308.15568" title="Download PostScript">ps</a>, <a href="/format/2308.15568" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Over-Squashing in Graph Neural Networks: A Comprehensive survey
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Akansha%2C+S">Singh Akansha</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
</div>
</dd>
<dt><a name="item1288">[1288]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.15605" title="Abstract">arXiv:2308.15605</a> (replaced) [<a href="/pdf/2308.15605" title="Download PDF">pdf</a>, <a href="/format/2308.15605" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Benchmarks for Detecting Measurement Tampering
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Roger%2C+F">Fabien Roger</a>, 
<a href="/search/cs?searchtype=author&query=Greenblatt%2C+R">Ryan Greenblatt</a>, 
<a href="/search/cs?searchtype=author&query=Nadeau%2C+M">Max Nadeau</a>, 
<a href="/search/cs?searchtype=author&query=Shlegeris%2C+B">Buck Shlegeris</a>, 
<a href="/search/cs?searchtype=author&query=Thomas%2C+N">Nate Thomas</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Edit: extended and improved appendices
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item1289">[1289]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.15670" title="Abstract">arXiv:2308.15670</a> (replaced) [<a href="/pdf/2308.15670" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multimodal Foundation Models For Echocardiogram Interpretation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Christensen%2C+M">Matthew Christensen</a>, 
<a href="/search/cs?searchtype=author&query=Vukadinovic%2C+M">Milos Vukadinovic</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+N">Neal Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Ouyang%2C+D">David Ouyang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item1290">[1290]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.15673" title="Abstract">arXiv:2308.15673</a> (replaced) [<a href="/pdf/2308.15673" title="Download PDF">pdf</a>, <a href="/format/2308.15673" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MDTD: A Multi Domain Trojan Detector for Deep Neural Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rajabi%2C+A">Arezoo Rajabi</a>, 
<a href="/search/cs?searchtype=author&query=Asokraj%2C+S">Surudhi Asokraj</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+F">Fengqing Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Niu%2C+L">Luyao Niu</a>, 
<a href="/search/cs?searchtype=author&query=Ramasubramanian%2C+B">Bhaskar Ramasubramanian</a>, 
<a href="/search/cs?searchtype=author&query=Ritcey%2C+J">Jim Ritcey</a>, 
<a href="/search/cs?searchtype=author&query=Poovendran%2C+R">Radha Poovendran</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to ACM Conference on Computer and Communications Security (ACM CCS) 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item1291">[1291]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.15736" title="Abstract">arXiv:2308.15736</a> (replaced) [<a href="/pdf/2308.15736" title="Download PDF">pdf</a>, <a href="/ps/2308.15736" title="Download PostScript">ps</a>, <a href="/format/2308.15736" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Adaversarial Issue of Machine Learning Approaches Applied in Smart Grid:  A Survey
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zhenyong Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+M">Mengxiang Liu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Systems and Control (eess.SY)

</div>
</div>
</dd>
<dt><a name="item1292">[1292]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.15765" title="Abstract">arXiv:2308.15765</a> (replaced) [<a href="/pdf/2308.15765" title="Download PDF">pdf</a>, <a href="/ps/2308.15765" title="Download PostScript">ps</a>, <a href="/format/2308.15765" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Cryptanalysis of a Cayley Hash Function Based on Affine Maps in one  Variable over a Finite Field
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sosnovski%2C+B">Bianca Sosnovski</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Group Theory (math.GR)

</div>
</div>
</dd>
<dt><a name="item1293">[1293]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.15791" title="Abstract">arXiv:2308.15791</a> (replaced) [<a href="/pdf/2308.15791" title="Download PDF">pdf</a>, <a href="/format/2308.15791" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Neural Video Compression with Temporal Layer-Adaptive Hierarchical  B-frame Coding
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kim%2C+Y">Yeongwoong Kim</a>, 
<a href="/search/cs?searchtype=author&query=Bahk%2C+S">Suyong Bahk</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+S">Seungeon Kim</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+W+H">Won Hee Lee</a>, 
<a href="/search/cs?searchtype=author&query=Oh%2C+D">Dokwan Oh</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+H+Y">Hui Yong Kim</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Image and Video Processing (eess.IV)

</div>
</div>
</dd>
<dt><a name="item1294">[1294]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.15906" title="Abstract">arXiv:2308.15906</a> (replaced) [<a href="/pdf/2308.15906" title="Download PDF">pdf</a>, <a href="/format/2308.15906" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Is the U.S. Legal System Ready for AI&#x27;s Challenges to Human Values?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cheong%2C+I">Inyoung Cheong</a>, 
<a href="/search/cs?searchtype=author&query=Caliskan%2C+A">Aylin Caliskan</a>, 
<a href="/search/cs?searchtype=author&query=Kohno%2C+T">Tadayoshi Kohno</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 25 pages, 7 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL)

</div>
</div>
</dd>
<dt><a name="item1295">[1295]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.15942" title="Abstract">arXiv:2308.15942</a> (replaced) [<a href="/pdf/2308.15942" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Stage-by-stage Wavelet Optimization Refinement Diffusion Model for  Sparse-View CT Reconstruction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Xu%2C+K">Kai Xu</a>, 
<a href="/search/eess?searchtype=author&query=Lu%2C+S">Shiyu Lu</a>, 
<a href="/search/eess?searchtype=author&query=Huang%2C+B">Bin Huang</a>, 
<a href="/search/eess?searchtype=author&query=Wu%2C+W">Weiwen Wu</a>, 
<a href="/search/eess?searchtype=author&query=Liu%2C+Q">Qiegen Liu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item1296">[1296]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.15949" title="Abstract">arXiv:2308.15949</a> (replaced) [<a href="/pdf/2308.15949" title="Download PDF">pdf</a>, <a href="/format/2308.15949" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Latency-aware Unified Dynamic Networks for Efficient Image Recognition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Han%2C+Y">Yizeng Han</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zeyu Liu</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+Z">Zhihang Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Pu%2C+Y">Yifan Pu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+C">Chaofei Wang</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+S">Shiji Song</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+G">Gao Huang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item1297">[1297]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.15979" title="Abstract">arXiv:2308.15979</a> (replaced) [<a href="/pdf/2308.15979" title="Download PDF">pdf</a>, <a href="/format/2308.15979" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fine-Grained Socioeconomic Prediction from Satellite Images with  Distributional Adjustment
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ahn%2C+D">Donghyun Ahn</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+M">Minhyuk Song</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+S">Seungeon Lee</a>, 
<a href="/search/cs?searchtype=author&query=Choi%2C+Y">Yubin Choi</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+J">Jihee Kim</a>, 
<a href="/search/cs?searchtype=author&query=Park%2C+S">Sangyoon Park</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+H">Hyunjoo Yang</a>, 
<a href="/search/cs?searchtype=author&query=Cha%2C+M">Meeyoung Cha</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>

</div>
</div>
</dd>
<dt><a name="item1298">[1298]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.15992" title="Abstract">arXiv:2308.15992</a> (replaced) [<a href="/pdf/2308.15992" title="Download PDF">pdf</a>, <a href="/format/2308.15992" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AI-powered Fraud Detection in Decentralized Finance: A Project Life  Cycle Perspective
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Luo%2C+B">Bingqiao Luo</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zhen Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Q">Qian Wang</a>, 
<a href="/search/cs?searchtype=author&query=Ke%2C+A">Anli Ke</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+S">Shengliang Lu</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+B">Bingsheng He</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 38 pages, update references
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Engineering, Finance, and Science (cs.CE)</span>

</div>
</div>
</dd>
<dt><a name="item1299">[1299]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.16018" title="Abstract">arXiv:2308.16018</a> (replaced) [<a href="/pdf/2308.16018" title="Download PDF">pdf</a>, <a href="/format/2308.16018" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Topology-aware MLP for Skeleton-based Action Recognition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+S">Shaojie Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Yin%2C+J">Jianqin Yin</a>, 
<a href="/search/cs?searchtype=author&query=Dang%2C+Y">Yonghao Dang</a>, 
<a href="/search/cs?searchtype=author&query=Fu%2C+J">Jiajun Fu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 9 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item1300">[1300]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.16137" title="Abstract">arXiv:2308.16137</a> (replaced) [<a href="/pdf/2308.16137" title="Download PDF">pdf</a>, <a href="/format/2308.16137" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LM-Infinite: Simple On-the-Fly Length Generalization for Large Language  Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Han%2C+C">Chi Han</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Q">Qifan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Xiong%2C+W">Wenhan Xiong</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yu Chen</a>, 
<a href="/search/cs?searchtype=author&query=Ji%2C+H">Heng Ji</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Sinong Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages, 4 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item1301">[1301]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.16215" title="Abstract">arXiv:2308.16215</a> (replaced) [<a href="/pdf/2308.16215" title="Download PDF">pdf</a>, <a href="/format/2308.16215" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deep Video Codec Control
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Reich%2C+C">Christoph Reich</a>, 
<a href="/search/eess?searchtype=author&query=Debnath%2C+B">Biplob Debnath</a>, 
<a href="/search/eess?searchtype=author&query=Patel%2C+D">Deep Patel</a>, 
<a href="/search/eess?searchtype=author&query=Prangemeier%2C+T">Tim Prangemeier</a>, 
<a href="/search/eess?searchtype=author&query=Chakradhar%2C+S">Srimat Chakradhar</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 22 pages, 26 figures, 6 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG); Multimedia (cs.MM)

</div>
</div>
</dd>
<dt><a name="item1302">[1302]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.16262" title="Abstract">arXiv:2308.16262</a> (replaced) [<a href="/pdf/2308.16262" title="Download PDF">pdf</a>, <a href="/format/2308.16262" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Causal Strategic Learning with Competitive Selection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Vo%2C+K+Q+H">Kiet Q. H. Vo</a>, 
<a href="/search/cs?searchtype=author&query=Aadil%2C+M">Muneeb Aadil</a>, 
<a href="/search/cs?searchtype=author&query=Chau%2C+S+L">Siu Lun Chau</a>, 
<a href="/search/cs?searchtype=author&query=Muandet%2C+K">Krikamol Muandet</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Corrected some in-text citations
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
</div>
</dd>
<dt><a name="item1303">[1303]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.16298" title="Abstract">arXiv:2308.16298</a> (replaced) [<a href="/pdf/2308.16298" title="Download PDF">pdf</a>, <a href="/format/2308.16298" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Publishing Wikipedia usage data with strong privacy guarantees
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Adeleye%2C+T">Temilola Adeleye</a>, 
<a href="/search/cs?searchtype=author&query=Berghel%2C+S">Skye Berghel</a>, 
<a href="/search/cs?searchtype=author&query=Desfontaines%2C+D">Damien Desfontaines</a>, 
<a href="/search/cs?searchtype=author&query=Hay%2C+M">Michael Hay</a>, 
<a href="/search/cs?searchtype=author&query=Johnson%2C+I">Isaac Johnson</a>, 
<a href="/search/cs?searchtype=author&query=Lemoisson%2C+C">Cl&#xe9;o Lemoisson</a>, 
<a href="/search/cs?searchtype=author&query=Machanavajjhala%2C+A">Ashwin Machanavajjhala</a>, 
<a href="/search/cs?searchtype=author&query=Magerlein%2C+T">Tom Magerlein</a>, 
<a href="/search/cs?searchtype=author&query=Modena%2C+G">Gabriele Modena</a>, 
<a href="/search/cs?searchtype=author&query=Pujol%2C+D">David Pujol</a>, 
<a href="/search/cs?searchtype=author&query=Simmons-Marengo%2C+D">Daniel Simmons-Marengo</a>, 
<a href="/search/cs?searchtype=author&query=Triedman%2C+H">Hal Triedman</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages, 10 figures, Theory and Practice of Differential Privacy (TPDP) 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
</div>
</dd>
<dt><a name="item1304">[1304]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.16389" title="Abstract">arXiv:2308.16389</a> (replaced) [<a href="/pdf/2308.16389" title="Download PDF">pdf</a>, <a href="/format/2308.16389" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Biased Journey of MSD_AUDIO.ZIP
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kim%2C+H">Haven Kim</a>, 
<a href="/search/cs?searchtype=author&query=Choi%2C+K">Keunwoo Choi</a>, 
<a href="/search/cs?searchtype=author&query=Modrzejewski%2C+M">Mateusz Modrzejewski</a>, 
<a href="/search/cs?searchtype=author&query=Liem%2C+C+C+S">Cynthia C. S. Liem</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Computers and Society (cs.CY); Audio and Speech Processing (eess.AS)

</div>
</div>
</dd>
<dt><a name="item1305">[1305]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.16400" title="Abstract">arXiv:2308.16400</a> (replaced) [<a href="/pdf/2308.16400" title="Download PDF">pdf</a>, <a href="/ps/2308.16400" title="Download PostScript">ps</a>, <a href="/format/2308.16400" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Channel Estimation for XL-MIMO Systems with Polar-Domain Multi-Scale  Residual Dense Network
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lei%2C+H">Hao Lei</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jiayi Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Xiao%2C+H">Huahua Xiao</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xiaodan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Ai%2C+B">Bo Ai</a>, 
<a href="/search/cs?searchtype=author&query=Ng%2C+D+W+K">Derrick Wing Kwan Ng</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
</div>
</dd>
<dt><a name="item1306">[1306]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.16403" title="Abstract">arXiv:2308.16403</a> (replaced) [<a href="/pdf/2308.16403" title="Download PDF">pdf</a>, <a href="/format/2308.16403" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Balancing between the Local and Global Structures (LGS) in Graph  Embedding
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Miller%2C+J">Jacob Miller</a>, 
<a href="/search/cs?searchtype=author&query=Huroyan%2C+V">Vahan Huroyan</a>, 
<a href="/search/cs?searchtype=author&query=Kobourov%2C+S">Stephen Kobourov</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Appears in the Proceedings of the 31st International Symposium on Graph Drawing and Network Visualization (GD 2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Computational Geometry (cs.CG); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item1307">[1307]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.16453" title="Abstract">arXiv:2308.16453</a> (replaced) [<a href="/pdf/2308.16453" title="Download PDF">pdf</a>, <a href="/ps/2308.16453" title="Download PostScript">ps</a>, <a href="/format/2308.16453" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Listen to Minority: Encrypted Traffic Classification for Class Imbalance  with Contrastive Pre-Training
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xiang Li</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+J">Juncheng Guo</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+Q">Qige Song</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+J">Jiang Xie</a>, 
<a href="/search/cs?searchtype=author&query=Sang%2C+Y">Yafei Sang</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+S">Shuyuan Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yongzheng Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by 2023 IEEE SECON, 9 pages, 6 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item1308">[1308]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.16458" title="Abstract">arXiv:2308.16458</a> (replaced) [<a href="/pdf/2308.16458" title="Download PDF">pdf</a>, <a href="/format/2308.16458" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> BioCoder: A Benchmark for Bioinformatics Code Generation with Contextual  Pragmatic Knowledge
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tang%2C+X">Xiangru Tang</a>, 
<a href="/search/cs?searchtype=author&query=Qian%2C+B">Bill Qian</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+R">Rick Gao</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Jiakang Chen</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+X">Xinyun Chen</a>, 
<a href="/search/cs?searchtype=author&query=Gerstein%2C+M">Mark Gerstein</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL)

</div>
</div>
</dd>
<dt><a name="item1309">[1309]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.16469" title="Abstract">arXiv:2308.16469</a> (replaced) [<a href="/pdf/2308.16469" title="Download PDF">pdf</a>, <a href="/format/2308.16469" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Link Prediction for Wikipedia Articles as a Natural Language Inference  Task
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Phan%2C+C">Chau-Thang Phan</a>, 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+Q">Quoc-Nam Nguyen</a>, 
<a href="/search/cs?searchtype=author&query=Van+Nguyen%2C+K">Kiet Van Nguyen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at the 10th IEEE International Conference On Data Science And Advanced Analytics (DSAA 2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item1310">[1310]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.16481" title="Abstract">arXiv:2308.16481</a> (replaced) [<a href="/pdf/2308.16481" title="Download PDF">pdf</a>, <a href="/format/2308.16481" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Point-TTA: Test-Time Adaptation for Point Cloud Registration Using  Multitask Meta-Auxiliary Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hatem%2C+A">Ahmed Hatem</a>, 
<a href="/search/cs?searchtype=author&query=Qian%2C+Y">Yiming Qian</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yang Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at ICCV 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item1311">[1311]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.16484" title="Abstract">arXiv:2308.16484</a> (replaced) [<a href="/pdf/2308.16484" title="Download PDF">pdf</a>, <a href="/format/2308.16484" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Test-Time Adaptation for Point Cloud Upsampling Using Meta-Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hatem%2C+A">Ahmed Hatem</a>, 
<a href="/search/cs?searchtype=author&query=Qian%2C+Y">Yiming Qian</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yang Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at IROS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Robotics (cs.RO)

</div>
</div>
</dd>
<dt><a name="item1312">[1312]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.16490" title="Abstract">arXiv:2308.16490</a> (replaced) [<a href="/pdf/2308.16490" title="Download PDF">pdf</a>, <a href="/format/2308.16490" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Latent Painter
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Su%2C+S">Shih-Chieh Su</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item1313">[1313]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.16518" title="Abstract">arXiv:2308.16518</a> (replaced) [<a href="/pdf/2308.16518" title="Download PDF">pdf</a>, <a href="/format/2308.16518" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MS23D: A 3D Object Detection Method Using Multi-Scale Semantic Feature  Points to Construct 3D Feature Layer
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shao%2C+Y">Yongxin Shao</a>, 
<a href="/search/cs?searchtype=author&query=Tan%2C+A">Aihong Tan</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+T">Tianhong Yan</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+Z">Zhetao Sun</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item1314">[1314]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.16545" title="Abstract">arXiv:2308.16545</a> (replaced) [<a href="/pdf/2308.16545" title="Download PDF">pdf</a>, <a href="/format/2308.16545" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Distributed Nonblocking Supervisory Control of Timed Discrete-Event  Systems with Communication Delays and Losses
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Hou%2C+Y">Yunfeng Hou</a>, 
<a href="/search/eess?searchtype=author&query=Li%2C+Q">Qingdu Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
</div>
</dd>
<dt><a name="item1315">[1315]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.16568" title="Abstract">arXiv:2308.16568</a> (replaced) [<a href="/pdf/2308.16568" title="Download PDF">pdf</a>, <a href="/format/2308.16568" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Shape of my heart: Cardiac models through learned signed distance  functions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Verh%C3%BClsdonk%2C+J">Jan Verh&#xfc;lsdonk</a>, 
<a href="/search/eess?searchtype=author&query=Grandits%2C+T">Thomas Grandits</a>, 
<a href="/search/eess?searchtype=author&query=Costabal%2C+F+S">Francisco Sahli Costabal</a>, 
<a href="/search/eess?searchtype=author&query=Krause%2C+R">Rolf Krause</a>, 
<a href="/search/eess?searchtype=author&query=Auricchio%2C+A">Angelo Auricchio</a>, 
<a href="/search/eess?searchtype=author&query=Haase%2C+G">Gundolf Haase</a>, 
<a href="/search/eess?searchtype=author&query=Pezzuto%2C+S">Simone Pezzuto</a>, 
<a href="/search/eess?searchtype=author&query=Effland%2C+A">Alexander Effland</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item1316">[1316]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.16576" title="Abstract">arXiv:2308.16576</a> (replaced) [<a href="/pdf/2308.16576" title="Download PDF">pdf</a>, <a href="/format/2308.16576" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GHuNeRF: Generalizable Human NeRF from a Monocular Video
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+C">Chen Li</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+J">Jiahao Lin</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+G+H">Gim Hee Lee</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Corrected typos
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item1317">[1317]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.16609" title="Abstract">arXiv:2308.16609</a> (replaced) [<a href="/pdf/2308.16609" title="Download PDF">pdf</a>, <a href="/format/2308.16609" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Long-Tailed Recognition for Graph Classification via  Collaborative Experts
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yi%2C+S">Siyu Yi</a>, 
<a href="/search/cs?searchtype=author&query=Mao%2C+Z">Zhengyang Mao</a>, 
<a href="/search/cs?searchtype=author&query=Ju%2C+W">Wei Ju</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Y">Yongdao Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+L">Luchen Liu</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+X">Xiao Luo</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+M">Ming Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by IEEE Transactions on Big Data (TBD 2024)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Information Retrieval (cs.IR); Social and Information Networks (cs.SI)

</div>
</div>
</dd>
<dt><a name="item1318">[1318]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.16684" title="Abstract">arXiv:2308.16684</a> (replaced) [<a href="/pdf/2308.16684" title="Download PDF">pdf</a>, <a href="/format/2308.16684" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Everyone Can Attack: Repurpose Lossy Compression as a Natural Backdoor  Attack
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+S+J">Sze Jue Yang</a>, 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+Q">Quang Nguyen</a>, 
<a href="/search/cs?searchtype=author&query=Chan%2C+C+S">Chee Seng Chan</a>, 
<a href="/search/cs?searchtype=author&query=Doan%2C+K+D">Khoa D. Doan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages. This paper shows everyone can mount a powerful and stealthy backdoor attack with the widely-used lossy image compression
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item1319">[1319]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.16761" title="Abstract">arXiv:2308.16761</a> (replaced) [<a href="/pdf/2308.16761" title="Download PDF">pdf</a>, <a href="/format/2308.16761" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Co-evolving Vector Quantization for ID-based Recommendation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+Q">Qijiong Liu</a>, 
<a href="/search/cs?searchtype=author&query=Xiao%2C+J">Jiaren Xiao</a>, 
<a href="/search/cs?searchtype=author&query=Fan%2C+L">Lu Fan</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+J">Jieming Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+X">Xiao-Ming Wu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>

</div>
</div>
</dd>
<dt><a name="item1320">[1320]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.16769" title="Abstract">arXiv:2308.16769</a> (replaced) [<a href="/pdf/2308.16769" title="Download PDF">pdf</a>, <a href="/format/2308.16769" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Low-Barrier Cybersecurity Research and Education for Industrial  Control Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=McGuan%2C+C">Colman McGuan</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+C">Chansu Yu</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+Q">Qin Lin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> accepted to the 20th Annual IEEE International Conference on Intelligence and Security Informatics (ISI)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item1321">[1321]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.16774" title="Abstract">arXiv:2308.16774</a> (replaced) [<a href="/pdf/2308.16774" title="Download PDF">pdf</a>, <a href="/format/2308.16774" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Toward Automatically Completing GitHub Workflows
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mastropaolo%2C+A">Antonio Mastropaolo</a>, 
<a href="/search/cs?searchtype=author&query=Zampetti%2C+F">Fiorella Zampetti</a>, 
<a href="/search/cs?searchtype=author&query=Bavota%2C+G">Gabriele Bavota</a>, 
<a href="/search/cs?searchtype=author&query=Di+Penta%2C+M">Massimiliano Di Penta</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
</div>
</dd>
<dt><a name="item1322">[1322]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.16781" title="Abstract">arXiv:2308.16781</a> (replaced) [<a href="/pdf/2308.16781" title="Download PDF">pdf</a>, <a href="/format/2308.16781" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> StratMed: Relevance Stratification for Low-resource Medication  Recommendation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xiang Li</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+S">Shunpan Liang</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+T">Tengfei Ma</a>, 
<a href="/search/cs?searchtype=author&query=Hou%2C+Y">Yulei Hou</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item1323">[1323]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.16785" title="Abstract">arXiv:2308.16785</a> (replaced) [<a href="/pdf/2308.16785" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Agent Teaming Situation Awareness (ATSA): A Situation Awareness  Framework for Human-AI Teaming
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gao%2C+Q">Qi Gao</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+W">Wei Xu</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+M">Mowei Shen</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+Z">Zaifeng Gao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 52 pages,5 figures, 1 table
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Human-Computer Interaction (cs.HC)

</div>
</div>
</dd>
<dt><a name="item1324">[1324]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.16824" title="Abstract">arXiv:2308.16824</a> (replaced) [<a href="/pdf/2308.16824" title="Download PDF">pdf</a>, <a href="/format/2308.16824" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Can Programming Languages Boost Each Other via Instruction Tuning?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zan%2C+D">Daoguang Zan</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+A">Ailun Yu</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+B">Bo Shen</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jiaxin Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+T">Taihong Chen</a>, 
<a href="/search/cs?searchtype=author&query=Geng%2C+B">Bing Geng</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+B">Bei Chen</a>, 
<a href="/search/cs?searchtype=author&query=Ji%2C+J">Jichuan Ji</a>, 
<a href="/search/cs?searchtype=author&query=Yao%2C+Y">Yafen Yao</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yongji Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Q">Qianxiang Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Work in progress
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Programming Languages (cs.PL); Software Engineering (cs.SE)

</div>
</div>
</dd>
<dt><a name="item1325">[1325]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.16862" title="Abstract">arXiv:2308.16862</a> (replaced) [<a href="/pdf/2308.16862" title="Download PDF">pdf</a>, <a href="/format/2308.16862" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> UltraLogLog: A Practical and More Space-Efficient Alternative to  HyperLogLog for Approximate Distinct Counting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ertl%2C+O">Otmar Ertl</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>; Databases (cs.DB)

</div>
</div>
</dd>
<dt><a name="item1326">[1326]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.16890" title="Abstract">arXiv:2308.16890</a> (replaced) [<a href="/pdf/2308.16890" title="Download PDF">pdf</a>, <a href="/format/2308.16890" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> TouchStone: Evaluating Vision-Language Models by Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bai%2C+S">Shuai Bai</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+S">Shusheng Yang</a>, 
<a href="/search/cs?searchtype=author&query=Bai%2C+J">Jinze Bai</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+P">Peng Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xingxuan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+J">Junyang Lin</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xinggang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+C">Chang Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+J">Jingren Zhou</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> <a href="https://github.com/OFA-Sys/TouchStone">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Computation and Language (cs.CL)

</div>
</div>
</dd>
<dt><a name="item1327">[1327]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.16899" title="Abstract">arXiv:2308.16899</a> (replaced) [<a href="/pdf/2308.16899" title="Download PDF">pdf</a>, <a href="/format/2308.16899" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Divide and Conquer Approximation Algorithm for Partitioning Rectangles
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Mohammadi%2C+R">Reyhaneh Mohammadi</a>, 
<a href="/search/math?searchtype=author&query=Behroozi%2C+M">Mehdi Behroozi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Computational Geometry (cs.CG)

</div>
</div>
</dd>
<dt><a name="item1328">[1328]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.00007" title="Abstract">arXiv:2309.00007</a> (replaced) [<a href="/pdf/2309.00007" title="Download PDF">pdf</a>, <a href="/format/2309.00007" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> When Measures are Unreliable: Imperceptible Adversarial Perturbations  toward Top-$k$ Multi-Label Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sun%2C+Y">Yuchen Sun</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+Q">Qianqian Xu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zitai Wang</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+Q">Qingming Huang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 22 pages, 7 figures, accepted by ACM MM 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Cryptography and Security (cs.CR); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item1329">[1329]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.00014" title="Abstract">arXiv:2309.00014</a> (replaced) [<a href="/pdf/2309.00014" title="Download PDF">pdf</a>, <a href="/format/2309.00014" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Improving NeRF Quality by Progressive Camera Placement for Unrestricted  Navigation in Complex Environments
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kopanas%2C+G">Georgios Kopanas</a>, 
<a href="/search/cs?searchtype=author&query=Drettakis%2C+G">George Drettakis</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Graphics (cs.GR); Image and Video Processing (eess.IV)

</div>
</div>
</dd>
<dt><a name="item1330">[1330]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.00027" title="Abstract">arXiv:2309.00027</a> (replaced) [<a href="/pdf/2309.00027" title="Download PDF">pdf</a>, <a href="/format/2309.00027" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Sequential Framework for Detection and Classification of Abnormal  Teeth in Panoramic X-rays
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Dascalu%2C+T">Tudor Dascalu</a>, 
<a href="/search/eess?searchtype=author&query=Ramezanzade%2C+S">Shaqayeq Ramezanzade</a>, 
<a href="/search/eess?searchtype=author&query=Bakhshandeh%2C+A">Azam Bakhshandeh</a>, 
<a href="/search/eess?searchtype=author&query=Bjorndal%2C+L">Lars Bjorndal</a>, 
<a href="/search/eess?searchtype=author&query=Ibragimov%2C+B">Bulat Ibragimov</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item1331">[1331]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.00196" title="Abstract">arXiv:2309.00196</a> (replaced) [<a href="/pdf/2309.00196" title="Download PDF">pdf</a>, <a href="/format/2309.00196" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Comparative Study of Reference Reliability in Multiple Language  Editions of Wikipedia
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Baigutanova%2C+A">Aitolkyn Baigutanova</a>, 
<a href="/search/cs?searchtype=author&query=Saez-Trumper%2C+D">Diego Saez-Trumper</a>, 
<a href="/search/cs?searchtype=author&query=Redi%2C+M">Miriam Redi</a>, 
<a href="/search/cs?searchtype=author&query=Cha%2C+M">Meeyoung Cha</a>, 
<a href="/search/cs?searchtype=author&query=Arag%C3%B3n%2C+P">Pablo Arag&#xf3;n</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Conference on Information &amp; Knowledge Management (CIKM '23)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>

</div>
</div>
</dd>
<dt><a name="item1332">[1332]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.00233" title="Abstract">arXiv:2309.00233</a> (replaced) [<a href="/pdf/2309.00233" title="Download PDF">pdf</a>, <a href="/format/2309.00233" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Object-Centric Multiple Object Tracking
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Z">Zixu Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jiaze Wang</a>, 
<a href="/search/cs?searchtype=author&query=Horn%2C+M">Max Horn</a>, 
<a href="/search/cs?searchtype=author&query=Ding%2C+Y">Yizhuo Ding</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+T">Tong He</a>, 
<a href="/search/cs?searchtype=author&query=Bai%2C+Z">Zechen Bai</a>, 
<a href="/search/cs?searchtype=author&query=Zietlow%2C+D">Dominik Zietlow</a>, 
<a href="/search/cs?searchtype=author&query=Simon-Gabriel%2C+C">Carl-Johann Simon-Gabriel</a>, 
<a href="/search/cs?searchtype=author&query=Shuai%2C+B">Bing Shuai</a>, 
<a href="/search/cs?searchtype=author&query=Tu%2C+Z">Zhuowen Tu</a>, 
<a href="/search/cs?searchtype=author&query=Brox%2C+T">Thomas Brox</a>, 
<a href="/search/cs?searchtype=author&query=Schiele%2C+B">Bernt Schiele</a>, 
<a href="/search/cs?searchtype=author&query=Fu%2C+Y">Yanwei Fu</a>, 
<a href="/search/cs?searchtype=author&query=Locatello%2C+F">Francesco Locatello</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zheng Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Xiao%2C+T">Tianjun Xiao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ICCV 2023 camera-ready version
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item1333">[1333]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.00265" title="Abstract">arXiv:2309.00265</a> (replaced) [<a href="/pdf/2309.00265" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Application of Machine Learning in Melanoma Detection and the  Identification of &#x27;Ugly Duckling&#x27; and Suspicious Naevi: A Review
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Zegair%2C+F+A">Fatima Al Zegair</a>, 
<a href="/search/eess?searchtype=author&query=Naranpanawa%2C+N">Nathasha Naranpanawa</a>, 
<a href="/search/eess?searchtype=author&query=Betz-Stablein%2C+B">Brigid Betz-Stablein</a>, 
<a href="/search/eess?searchtype=author&query=Janda%2C+M">Monika Janda</a>, 
<a href="/search/eess?searchtype=author&query=Soyer%2C+H+P">H. Peter Soyer</a>, 
<a href="/search/eess?searchtype=author&query=Chandra%2C+S+S">Shekhar S. Chandra</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item1334">[1334]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.00344" title="Abstract">arXiv:2309.00344</a> (replaced) [<a href="/pdf/2309.00344" title="Download PDF">pdf</a>, <a href="/ps/2309.00344" title="Download PostScript">ps</a>, <a href="/format/2309.00344" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Improving Dependency Tuples for Almost-Sure Innermost Termination of  Probabilistic Term Rewriting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kassing%2C+J">Jan-Christoph Kassing</a>, 
<a href="/search/cs?searchtype=author&query=Giesl%2C+J">J&#xfc;rgen Giesl</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>

</div>
</div>
</dd>
<dt><a name="item1335">[1335]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.00367" title="Abstract">arXiv:2309.00367</a> (replaced) [<a href="/pdf/2309.00367" title="Download PDF">pdf</a>, <a href="/format/2309.00367" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Where Did the Gap Go? Reassessing the Long-Range Graph Benchmark
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=T%C3%B6nshoff%2C+J">Jan T&#xf6;nshoff</a>, 
<a href="/search/cs?searchtype=author&query=Ritzert%2C+M">Martin Ritzert</a>, 
<a href="/search/cs?searchtype=author&query=Rosenbluth%2C+E">Eran Rosenbluth</a>, 
<a href="/search/cs?searchtype=author&query=Grohe%2C+M">Martin Grohe</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item1336">[1336]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.00369" title="Abstract">arXiv:2309.00369</a> (replaced) [<a href="/pdf/2309.00369" title="Download PDF">pdf</a>, <a href="/format/2309.00369" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Bayesian estimation and reconstruction of marine surface contaminant  dispersion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Liu%2C+Y">Yang Liu</a>, 
<a href="/search/eess?searchtype=author&query=Harvey%2C+C+M">Christopher M. Harvey</a>, 
<a href="/search/eess?searchtype=author&query=Hamlyn%2C+F+E">Frederick E. Hamlyn</a>, 
<a href="/search/eess?searchtype=author&query=Liu%2C+C">Cunjia Liu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Computational Engineering, Finance, and Science (cs.CE)

</div>
</div>
</dd>
<dt><a name="item1337">[1337]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.00382" title="Abstract">arXiv:2309.00382</a> (replaced) [<a href="/pdf/2309.00382" title="Download PDF">pdf</a>, <a href="/format/2309.00382" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Cross-Provider Analysis of Transparency Information for Data  Protection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gr%C3%BCnewald%2C+E">Elias Gr&#xfc;newald</a>, 
<a href="/search/cs?searchtype=author&query=Halkenh%C3%A4u%C3%9Fer%2C+J+M">Johannes M. Halkenh&#xe4;u&#xdf;er</a>, 
<a href="/search/cs?searchtype=author&query=Leschke%2C+N">Nicola Leschke</a>, 
<a href="/search/cs?searchtype=author&query=Pallas%2C+F">Frank Pallas</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> technical report
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>; Cryptography and Security (cs.CR); Software Engineering (cs.SE); Social and Information Networks (cs.SI)

</div>
</div>
</dd>
<dt><a name="item1338">[1338]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.00428" title="Abstract">arXiv:2309.00428</a> (replaced) [<a href="/pdf/2309.00428" title="Download PDF">pdf</a>, <a href="/format/2309.00428" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Locality-based Neural Solver for Optical Motion Capture
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pan%2C+X">Xiaoyu Pan</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+B">Bowen Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+X">Xinwei Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+G">Guanglong Xu</a>, 
<a href="/search/cs?searchtype=author&query=Gu%2C+X">Xianli Gu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jingxiang Li</a>, 
<a href="/search/cs?searchtype=author&query=Kou%2C+Q">Qilong Kou</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">He Wang</a>, 
<a href="/search/cs?searchtype=author&query=Shao%2C+T">Tianjia Shao</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+K">Kun Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+X">Xiaogang Jin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Siggraph Asia 2023 Conference Paper
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Graphics (cs.GR)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item1339">[1339]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.00456" title="Abstract">arXiv:2309.00456</a> (replaced) [<a href="/pdf/2309.00456" title="Download PDF">pdf</a>, <a href="/format/2309.00456" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Evaluating Animation Parameters for Morphing Edge Drawings
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Binucci%2C+C">Carla Binucci</a>, 
<a href="/search/cs?searchtype=author&query=F%C3%B6rster%2C+H">Henry F&#xf6;rster</a>, 
<a href="/search/cs?searchtype=author&query=Katheder%2C+J">Julia Katheder</a>, 
<a href="/search/cs?searchtype=author&query=Tappini%2C+A">Alessandra Tappini</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Appears in the Proceedings of the 31st International Symposium on Graph Drawing and Network Visualization (GD 2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
</div>
</dd>
<dt><a name="item1340">[1340]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.00468" title="Abstract">arXiv:2309.00468</a> (replaced) [<a href="/pdf/2309.00468" title="Download PDF">pdf</a>, <a href="/format/2309.00468" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An Improved Encoder-Decoder Framework for Food Energy Estimation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ma%2C+J">Jack Ma</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+J">Jiangpeng He</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+F">Fengqing Zhu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted for Madima'23 in ACM Multimedia
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item1341">[1341]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.00614" title="Abstract">arXiv:2309.00614</a> (replaced) [<a href="/pdf/2309.00614" title="Download PDF">pdf</a>, <a href="/format/2309.00614" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Baseline Defenses for Adversarial Attacks Against Aligned Language  Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jain%2C+N">Neel Jain</a>, 
<a href="/search/cs?searchtype=author&query=Schwarzschild%2C+A">Avi Schwarzschild</a>, 
<a href="/search/cs?searchtype=author&query=Wen%2C+Y">Yuxin Wen</a>, 
<a href="/search/cs?searchtype=author&query=Somepalli%2C+G">Gowthami Somepalli</a>, 
<a href="/search/cs?searchtype=author&query=Kirchenbauer%2C+J">John Kirchenbauer</a>, 
<a href="/search/cs?searchtype=author&query=Chiang%2C+P">Ping-yeh Chiang</a>, 
<a href="/search/cs?searchtype=author&query=Goldblum%2C+M">Micah Goldblum</a>, 
<a href="/search/cs?searchtype=author&query=Saha%2C+A">Aniruddha Saha</a>, 
<a href="/search/cs?searchtype=author&query=Geiping%2C+J">Jonas Geiping</a>, 
<a href="/search/cs?searchtype=author&query=Goldstein%2C+T">Tom Goldstein</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computation and Language (cs.CL); Cryptography and Security (cs.CR)

</div>
</div>
</dd>
<dt><a name="item1342">[1342]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.00616" title="Abstract">arXiv:2309.00616</a> (replaced) [<a href="/pdf/2309.00616" title="Download PDF">pdf</a>, <a href="/format/2309.00616" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> OpenIns3D: Snap and Lookup for 3D Open-vocabulary Instance Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+Z">Zhening Huang</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+X">Xiaoyang Wu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+X">Xi Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+H">Hengshuang Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+L">Lei Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Lasenby%2C+J">Joan Lasenby</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 24 pages, 16 figures, 13 tables. Project page: <a href="https://zheninghuang.github.io/OpenIns3D/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
</dl>
<ul>
<li><a href="/list/cs/new?skip=0&amp;show=2000">New submissions</a></li>
<li><a href="#item742">Cross-lists</a></li>
<li><a href="#item862">Replacements</a></li>
</ul>
<small>[ total of 1342 entries:  <b>1-1342</b>  ]</small><br />
<small>[ showing up to 2000 entries per page:  <a href="/list/cs/new?skip=0&amp;show=1000">fewer</a> |  <font color="#999999">more</font> ]</small><br />
</div>
<br/><small><a id="mathjax_toggle" href="javascript:setMathjaxCookie()">Disable MathJax</a> (<a href="/help/mathjax">What is MathJax?</a>)</small><script type="text/javascript" language="javascript">mathjaxToggle();</script>

<hr />
<p>Links to:
<a href="/" accesskey="a">arXiv</a>,
<a href="/form/cs">form interface</a>,
<a href="/find/cs">find</a>,
<a href="/archive/cs">cs</a>, <a href="/list/cs/recent">recent</a>, <a href="/list/cs/2309">2309</a>,
<a href="/help/contact">contact</a>,
<a href="/help/" accesskey="h"><span class="accesskey">h</span>elp</a>&nbsp;
<small>(<a href="/help/accesskeys">Access key</a> information)</small>
</p>
<hr />
</div>
</div>
 <footer style="clear: both;">
      <div class="columns is-desktop" role="navigation" aria-label="Secondary" style="margin: -0.75em -0.75em 0.75em -0.75em">
        <!-- Macro-Column 1 -->
        <div class="column" style="padding: 0;">
          <div class="columns">
            <div class="column">
              <ul style="list-style: none; line-height: 2;">
                <li><a href="https://arxiv.org/about">About</a></li>
                <li><a href="https://arxiv.org/help">Help</a></li>
              </ul>
            </div>
            <div class="column">
              <ul style="list-style: none; line-height: 2;">
                <li>
                  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon filter-black" role="presentation"><title>contact arXiv</title><desc>Click here to contact arXiv</desc><path d="M502.3 190.8c3.9-3.1 9.7-.2 9.7 4.7V400c0 26.5-21.5 48-48 48H48c-26.5 0-48-21.5-48-48V195.6c0-5 5.7-7.8 9.7-4.7 22.4 17.4 52.1 39.5 154.1 113.6 21.1 15.4 56.7 47.8 92.2 47.6 35.7.3 72-32.8 92.3-47.6 102-74.1 131.6-96.3 154-113.7zM256 320c23.2.4 56.6-29.2 73.4-41.4 132.7-96.3 142.8-104.7 173.4-128.7 5.8-4.5 9.2-11.5 9.2-18.9v-19c0-26.5-21.5-48-48-48H48C21.5 64 0 85.5 0 112v19c0 7.4 3.4 14.3 9.2 18.9 30.6 23.9 40.7 32.4 173.4 128.7 16.8 12.2 50.2 41.8 73.4 41.4z"/></svg>
                  <a href="https://arxiv.org/help/contact"> Contact</a>
                </li>
                <li>
                  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon filter-black" role="presentation"><title>subscribe to arXiv mailings</title><desc>Click here to subscribe</desc><path d="M476 3.2L12.5 270.6c-18.1 10.4-15.8 35.6 2.2 43.2L121 358.4l287.3-253.2c5.5-4.9 13.3 2.6 8.6 8.3L176 407v80.5c0 23.6 28.5 32.9 42.5 15.8L282 426l124.6 52.2c14.2 6 30.4-2.9 33-18.2l72-432C515 7.8 493.3-6.8 476 3.2z"/></svg>
                  <a href="https://arxiv.org/help/subscribe"> Subscribe</a>
                </li>
              </ul>
            </div>
          </div>
        </div>
        <!-- End Macro-Column 1 -->
        <!-- Macro-Column 2 -->
        <div class="column" style="padding: 0;">
          <div class="columns">
            <div class="column">
              <ul style="list-style: none; line-height: 2;">
                <li><a href="https://arxiv.org/help/license">Copyright</a></li>
                <li><a href="https://arxiv.org/help/policies/privacy_policy">Privacy Policy</a></li>
              </ul>
            </div>
            <div class="column sorry-app-links">
              <ul style="list-style: none; line-height: 2;">
                <li><a href="https://arxiv.org/help/web_accessibility">Web Accessibility Assistance</a></li>
                <li>
                  <p class="help">
                    <a class="a11y-main-link" href="https://status.arxiv.org" target="_blank">arXiv Operational Status <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 256 512" class="icon filter-dark_grey" role="presentation"><path d="M224.3 273l-136 136c-9.4 9.4-24.6 9.4-33.9 0l-22.6-22.6c-9.4-9.4-9.4-24.6 0-33.9l96.4-96.4-96.4-96.4c-9.4-9.4-9.4-24.6 0-33.9L54.3 103c9.4-9.4 24.6-9.4 33.9 0l136 136c9.5 9.4 9.5 24.6.1 34z"/></svg></a><br>
                    Get status notifications via
                    <a class="is-link" href="https://subscribe.sorryapp.com/24846f03/email/new" target="_blank"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon filter-black" role="presentation"><path d="M502.3 190.8c3.9-3.1 9.7-.2 9.7 4.7V400c0 26.5-21.5 48-48 48H48c-26.5 0-48-21.5-48-48V195.6c0-5 5.7-7.8 9.7-4.7 22.4 17.4 52.1 39.5 154.1 113.6 21.1 15.4 56.7 47.8 92.2 47.6 35.7.3 72-32.8 92.3-47.6 102-74.1 131.6-96.3 154-113.7zM256 320c23.2.4 56.6-29.2 73.4-41.4 132.7-96.3 142.8-104.7 173.4-128.7 5.8-4.5 9.2-11.5 9.2-18.9v-19c0-26.5-21.5-48-48-48H48C21.5 64 0 85.5 0 112v19c0 7.4 3.4 14.3 9.2 18.9 30.6 23.9 40.7 32.4 173.4 128.7 16.8 12.2 50.2 41.8 73.4 41.4z"/></svg>email</a>
                    or <a class="is-link" href="https://subscribe.sorryapp.com/24846f03/slack/new" target="_blank"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512" class="icon filter-black" role="presentation"><path d="M94.12 315.1c0 25.9-21.16 47.06-47.06 47.06S0 341 0 315.1c0-25.9 21.16-47.06 47.06-47.06h47.06v47.06zm23.72 0c0-25.9 21.16-47.06 47.06-47.06s47.06 21.16 47.06 47.06v117.84c0 25.9-21.16 47.06-47.06 47.06s-47.06-21.16-47.06-47.06V315.1zm47.06-188.98c-25.9 0-47.06-21.16-47.06-47.06S139 32 164.9 32s47.06 21.16 47.06 47.06v47.06H164.9zm0 23.72c25.9 0 47.06 21.16 47.06 47.06s-21.16 47.06-47.06 47.06H47.06C21.16 243.96 0 222.8 0 196.9s21.16-47.06 47.06-47.06H164.9zm188.98 47.06c0-25.9 21.16-47.06 47.06-47.06 25.9 0 47.06 21.16 47.06 47.06s-21.16 47.06-47.06 47.06h-47.06V196.9zm-23.72 0c0 25.9-21.16 47.06-47.06 47.06-25.9 0-47.06-21.16-47.06-47.06V79.06c0-25.9 21.16-47.06 47.06-47.06 25.9 0 47.06 21.16 47.06 47.06V196.9zM283.1 385.88c25.9 0 47.06 21.16 47.06 47.06 0 25.9-21.16 47.06-47.06 47.06-25.9 0-47.06-21.16-47.06-47.06v-47.06h47.06zm0-23.72c-25.9 0-47.06-21.16-47.06-47.06 0-25.9 21.16-47.06 47.06-47.06h117.84c25.9 0 47.06 21.16 47.06 47.06 0 25.9-21.16 47.06-47.06 47.06H283.1z"/></svg>slack</a>
                  </p>
                </li>
              </ul>
            </div>
          </div>
        </div> <!-- end MetaColumn 2 -->
        <!-- End Macro-Column 2 -->
      </div>
    </footer>
</body>
</html>
