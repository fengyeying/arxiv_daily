<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en">
<head>
<title>Computer Science  authors/titles &quot;new&quot;</title>
<link rel="shortcut icon" href="/favicon.ico" type="image/x-icon" />
<link rel="stylesheet" type="text/css" media="screen" href="//static.arxiv.org/static/browse/0.3.2.8/css/arXiv.css?v=20220215" />
<link rel="stylesheet" type="text/css" media="screen" href="/bibex/bibex.css?20181009">
<link rel="stylesheet" type="text/css" media="screen" href="https://static.arxiv.org/static/browse/0.3.8/css/browse_search.css" />
<link rel="alternate" type="application/rss+xml" title="Computer Science " href="http://arxiv.org/rss/cs"/>
<script src="/js/mathjaxToggle.min.js" type="text/javascript"></script>


</head>
<body class="with-cu-identity">

<div id="cu-identity">
<div id="cu-logo">
<a href="https://www.cornell.edu/"><img src="//static.arxiv.org/icons/cu/cornell-reduced-white-SMALL.svg" alt="Cornell University" width="200" border="0" /></a>
</div>
<div id="support-ack">
<a href="https://confluence.cornell.edu/x/ALlRF">We gratefully acknowledge support from<br /> the Simons Foundation and member institutions.</a>
</div>
</div>
<div id="header">
<h1 class="header-breadcrumbs"><a href="/"><img src="//static.arxiv.org/images/arxiv-logo-one-color-white.svg" aria-label="logo" alt="arxiv logo" width="85" style="width:85px;margin-right:8px;"></a> <span>&gt;</span> <a href="/list/cs/recent">cs</a></h1>
<div class="search-block level-right">
<form class="level-item mini-search" method="GET" action="https://arxiv.org/search" _lpchecked="1">
<div class="field has-addons">
<div class="control">
<input class="input is-small" type="text" name="query" placeholder="Search..." aria-label="Search term or terms" data-com.agilebits.onepassword.user-edited="yes">
<p class="help"><a href="https://arxiv.org/help">Help</a> | <a href="https://arxiv.org/search/advanced">Advanced Search</a></p>
</div>
<div class="control">
<div class="select is-small">
<select name="searchtype" aria-label="Field to search">
<option value="all" selected="selected">All fields</option>
<option value="title">Title</option>
<option value="author">Author</option>
<option value="abstract">Abstract</option>
<option value="comments">Comments</option>
<option value="journal_ref">Journal reference</option>
<option value="acm_class">ACM classification</option>
<option value="msc_class">MSC classification</option>
<option value="report_num">Report number</option>
<option value="paper_id">arXiv identifier</option>
<option value="doi">DOI</option>
<option value="orcid">ORCID</option>
<option value="author_id">arXiv author ID</option>
<option value="help">Help pages</option>
<option value="full_text">Full text</option>
</select>
</div>
</div>
<button class="button is-small is-cul-darker">Search</button>
</div>
</form>
</div>
</div>
<div id="content">
<div id="dlpage">
<h1>Computer Science </h1>
<h2>New submissions</h2>
<div class="list-dateline">Submissions received from  Wed 27 Sep 23  to  Thu 28 Sep 23, announced Fri, 29 Sep 23</div>
<ul>
<li><a href="/list/cs/new?skip=0&amp;show=2000">New submissions</a></li>
<li><a href="#item328">Cross-lists</a></li>
<li><a href="#item380">Replacements</a></li>
</ul>
<small>[ total of 582 entries:  <b>1-582</b>  ]</small><br />
<small>[ showing up to 2000 entries per page:  <a href="/list/cs/new?skip=0&amp;show=1000">fewer</a> |  <font color="#999999">more</font> ]</small><br />
<h3>New submissions for Fri, 29 Sep 23</h3>
<dl>
<dt><a name="item1">[1]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15850" title="Abstract">arXiv:2309.15850</a> [<a href="/pdf/2309.15850" title="Download PDF">pdf</a>, <a href="/format/2309.15850" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Reflection Invariance Learning for Few-shot Semantic Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cao%2C+Q">Qinglong Cao</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yuntian Chen</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+C">Chao Ma</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+X">Xiaokang Yang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Image and Video Processing (eess.IV)

</div>
<p class="mathjax">Few-shot semantic segmentation (FSS) aims to segment objects of unseen
classes in query images with only a few annotated support images. Existing FSS
algorithms typically focus on mining category representations from the
single-view support to match semantic objects of the single-view query.
However, the limited annotated samples render the single-view matching struggle
to perceive the reflection invariance of novel objects, which results in a
restricted learning space for novel categories and further induces a biased
segmentation with demoted parsing performance. To address this challenge, this
paper proposes a fresh few-shot segmentation framework to mine the reflection
invariance in a multi-view matching manner. Specifically, original and
reflection support features from different perspectives with the same semantics
are learnable fused to obtain the reflection invariance prototype with a
stronger category representation ability. Simultaneously, aiming at providing
better prior guidance, the Reflection Invariance Prior Mask Generation (RIPMG)
module is proposed to integrate prior knowledge from different perspectives.
Finally, segmentation predictions from varying views are complementarily merged
in the Reflection Invariance Semantic Prediction (RISP) module to yield precise
segmentation predictions. Extensive experiments on both PASCAL-$5^\textit{i}$
and COCO-$20^\textit{i}$ datasets demonstrate the effectiveness of our approach
and show that our method could achieve state-of-the-art performance. Code is
available at \url{https://anonymous.4open.science/r/RILFS-A4D1}
</p>
</div>
</dd>
<dt><a name="item2">[2]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15855" title="Abstract">arXiv:2309.15855</a> [<a href="/pdf/2309.15855" title="Download PDF">pdf</a>, <a href="/format/2309.15855" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Temporally-Evolving Generalised Networks and their Reproducing Kernels
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Filosi%2C+T">Tobia Filosi</a>, 
<a href="/search/cs?searchtype=author&query=Agostinelli%2C+C">Claudio Agostinelli</a>, 
<a href="/search/cs?searchtype=author&query=Porcu%2C+E">Emilio Porcu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 48 pages, 13 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>; Methodology (stat.ME)

</div>
<p class="mathjax">This paper considers generalised network, intended as networks where (a) the
edges connecting the nodes are nonlinear, and (b) stochastic processes are
continuously indexed over both vertices and edges. Such topological structures
are normally represented through special classes of graphs, termed graphs with
Euclidean edges. We build generalised networks in which topology changes over
time instants. That is, vertices and edges can disappear at subsequent time
instants and edges may change in shape and length. We consider both cases of
linear or circular time. For the second case, the generalised network exhibits
a periodic structure. Our findings allow to illustrate pros and cons of each
setting. Generalised networks become semi-metric spaces whenever equipped with
a proper semi-metric. Our approach allows to build proper semi-metrics for the
temporally-evolving topological structures of the networks. Our final effort is
then devoted to guiding the reader through appropriate choice of classes of
functions that allow to build proper reproducing kernels when composed with the
temporally-evolving semi-metrics topological structures.
</p>
</div>
</dd>
<dt><a name="item3">[3]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15857" title="Abstract">arXiv:2309.15857</a> [<a href="/pdf/2309.15857" title="Download PDF">pdf</a>, <a href="/format/2309.15857" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Survey on Image-text Multimodal Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Guo%2C+R">Ruifeng Guo</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+J">Jingxuan Wei</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+L">Linzhuang Sun</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+B">Bihui Yu</a>, 
<a href="/search/cs?searchtype=author&query=Chang%2C+G">Guiyong Chang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+D">Dawei Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+S">Sibo Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Yao%2C+Z">Zhengbing Yao</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+M">Mingjun Xu</a>, 
<a href="/search/cs?searchtype=author&query=Bu%2C+L">Liping Bu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Multimedia (cs.MM)

</div>
<p class="mathjax">Amidst the evolving landscape of artificial intelligence, the convergence of
visual and textual information has surfaced as a crucial frontier, leading to
the advent of image-text multimodal models. This paper provides a comprehensive
review of the evolution and current state of image-text multimodal models,
exploring their application value, challenges, and potential research
trajectories. Initially, we revisit the basic concepts and developmental
milestones of these models, introducing a novel classification that segments
their evolution into three distinct phases, based on their time of introduction
and subsequent impact on the discipline. Furthermore, based on the tasks'
significance and prevalence in the academic landscape, we propose a
categorization of the tasks associated with image-text multimodal models into
five major types, elucidating the recent progress and key technologies within
each category. Despite the remarkable accomplishments of these models, numerous
challenges and issues persist. This paper delves into the inherent challenges
and limitations of image-text multimodal models, fostering the exploration of
prospective research directions. Our objective is to offer an exhaustive
overview of the present research landscape of image-text multimodal models and
to serve as a valuable reference for future scholarly endeavors. We extend an
invitation to the broader community to collaborate in enhancing the image-text
multimodal model community, accessible at:
\href{https://github.com/i2vec/A-survey-on-image-text-multimodal-models}{https://github.com/i2vec/A-survey-on-image-text-multimodal-models}.
</p>
</div>
</dd>
<dt><a name="item4">[4]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15866" title="Abstract">arXiv:2309.15866</a> [<a href="/pdf/2309.15866" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ChatGPT &amp; Mechanical Engineering: Examining performance on the FE  Mechanical Engineering and Undergraduate Exams
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Frenkel%2C+M">Matthew Frenkel</a>, 
<a href="/search/cs?searchtype=author&query=Emara%2C+H">Hebah Emara</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12,000 words, 5 tables, 1 appendix
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">The launch of ChatGPT at the end of 2022 generated large interest into
possible applications of artificial intelligence in STEM education and among
STEM professions. As a result many questions surrounding the capabilities of
generative AI tools inside and outside of the classroom have been raised and
are starting to be explored. This study examines the capabilities of ChatGPT
within the discipline of mechanical engineering. It aims to examine use cases
and pitfalls of such a technology in the classroom and professional settings.
ChatGPT was presented with a set of questions from junior and senior level
mechanical engineering exams provided at a large private university, as well as
a set of practice questions for the Fundamentals of Engineering Exam (FE) in
Mechanical Engineering. The responses of two ChatGPT models, one free to use
and one paid subscription, were analyzed. The paper found that the subscription
model (GPT-4) greatly outperformed the free version (GPT-3.5), achieving 76%
correct vs 51% correct, but the limitation of text only input on both models
makes neither likely to pass the FE exam. The results confirm findings in the
literature with regards to types of errors and pitfalls made by ChatGPT. It was
found that due to its inconsistency and a tendency to confidently produce
incorrect answers the tool is best suited for users with expert knowledge.
</p>
</div>
</dd>
<dt><a name="item5">[5]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15867" title="Abstract">arXiv:2309.15867</a> [<a href="/pdf/2309.15867" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Identifying factors associated with fast visual field progression in  patients with ocular hypertension based on unsupervised machine learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+X">Xiaoqin Huang</a>, 
<a href="/search/cs?searchtype=author&query=Poursoroush%2C+A">Asma Poursoroush</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+J">Jian Sun</a>, 
<a href="/search/cs?searchtype=author&query=Boland%2C+M+V">Michael V. Boland</a>, 
<a href="/search/cs?searchtype=author&query=Johnson%2C+C">Chris Johnson</a>, 
<a href="/search/cs?searchtype=author&query=Yousefi%2C+S">Siamak Yousefi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Image and Video Processing (eess.IV); Quantitative Methods (q-bio.QM)

</div>
<p class="mathjax">Purpose: To identify ocular hypertension (OHT) subtypes with different trends
of visual field (VF) progression based on unsupervised machine learning and to
discover factors associated with fast VF progression. Participants: A total of
3133 eyes of 1568 ocular hypertension treatment study (OHTS) participants with
at least five follow-up VF tests were included in the study. Methods: We used a
latent class mixed model (LCMM) to identify OHT subtypes using standard
automated perimetry (SAP) mean deviation (MD) trajectories. We characterized
the subtypes based on demographic, clinical, ocular, and VF factors at the
baseline. We then identified factors driving fast VF progression using
generalized estimating equation (GEE) and justified findings qualitatively and
quantitatively. Results: The LCMM model discovered four clusters (subtypes) of
eyes with different trajectories of MD worsening. The number of eyes in
clusters were 794 (25%), 1675 (54%), 531 (17%) and 133 (4%). We labelled the
clusters as Improvers, Stables, Slow progressors, and Fast progressors based on
their mean of MD decline, which were 0.08, -0.06, -0.21, and -0.45 dB/year,
respectively. Eyes with fast VF progression had higher baseline age,
intraocular pressure (IOP), pattern standard deviation (PSD) and refractive
error (RE), but lower central corneal thickness (CCT). Fast progression was
associated with calcium channel blockers, being male, heart disease history,
diabetes history, African American race, stroke history, and migraine
headaches.
</p>
</div>
</dd>
<dt><a name="item6">[6]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15869" title="Abstract">arXiv:2309.15869</a> [<a href="/pdf/2309.15869" title="Download PDF">pdf</a>, <a href="/format/2309.15869" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Unsupervised Pre-Training for Vietnamese Automatic Speech Recognition in  the HYKIST Project
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Le-Duc%2C+K">Khai Le-Duc</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Bachelor Thesis
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> FH Aachen University of Applied Sciences (2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Sound (cs.SD); Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">In today's interconnected globe, moving abroad is more and more prevalent,
whether it's for employment, refugee resettlement, or other causes. Language
difficulties between natives and immigrants present a common issue on a daily
basis, especially in medical domain. This can make it difficult for patients
and doctors to communicate during anamnesis or in the emergency room, which
compromises patient care. The goal of the HYKIST Project is to develop a speech
translation system to support patient-doctor communication with ASR and MT.
<br />ASR systems have recently displayed astounding performance on particular
tasks for which enough quantities of training data are available, such as
LibriSpeech. Building a good model is still difficult due to a variety of
speaking styles, acoustic and recording settings, and a lack of in-domain
training data. In this thesis, we describe our efforts to construct ASR systems
for a conversational telephone speech recognition task in the medical domain
for Vietnamese language to assist emergency room contact between doctors and
patients across linguistic barriers. In order to enhance the system's
performance, we investigate various training schedules and data combining
strategies. We also examine how best to make use of the little data that is
available. The use of publicly accessible models like XLSR-53 is compared to
the use of customized pre-trained models, and both supervised and unsupervised
approaches are utilized using wav2vec 2.0 as architecture.
</p>
</div>
</dd>
<dt><a name="item7">[7]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15870" title="Abstract">arXiv:2309.15870</a> [<a href="/pdf/2309.15870" title="Download PDF">pdf</a>, <a href="/ps/2309.15870" title="Download PostScript">ps</a>, <a href="/format/2309.15870" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Nash Equilibria of Two-Player Matrix Games Repeated Until Collision
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Murhekar%2C+A">Aniket Murhekar</a>, 
<a href="/search/cs?searchtype=author&query=Sharma%2C+E">Eklavya Sharma</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to FSTTCS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>

</div>
<p class="mathjax">We introduce and initiate the study of a natural class of repeated two-player
matrix games, called Repeated-Until-Collision (RUC) games. In each round, both
players simultaneously pick an action from a common action set $\{1, 2, \dots,
n\}$. Depending on their chosen actions, they derive payoffs given by $n \times
n$ matrices $A$ and $B$, respectively. If their actions collide (i.e., they
pick the same action), the game ends, otherwise, it proceeds to the next round.
Both players want to maximize their total payoff until the game ends. RUC games
can be interpreted as pursuit-evasion games or repeated hide-and-seek games.
They also generalize hand cricket, a popular game among children in India.
<br />We show that under mild assumptions on the payoff matrices, every RUC game
admits a Nash equilibrium (NE). Moreover, we show the existence of a stationary
NE, where each player chooses their action according to a probability
distribution over the action set that does not change across rounds.
Remarkably, we show that all NE are effectively the same as the stationary NE,
thus showing that RUC games admit an almost unique NE. Lastly, we also show how
to compute (approximate) NE for RUC games.
</p>
</div>
</dd>
<dt><a name="item8">[8]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15871" title="Abstract">arXiv:2309.15871</a> [<a href="/pdf/2309.15871" title="Download PDF">pdf</a>, <a href="/format/2309.15871" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Telescope: An Automated Hybrid Forecasting Approach on a Level-Playing  Field
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bauer%2C+A">Andr&#xe9; Bauer</a>, 
<a href="/search/cs?searchtype=author&query=Leznik%2C+M">Mark Leznik</a>, 
<a href="/search/cs?searchtype=author&query=Stenger%2C+M">Michael Stenger</a>, 
<a href="/search/cs?searchtype=author&query=Leppich%2C+R">Robert Leppich</a>, 
<a href="/search/cs?searchtype=author&query=Herbst%2C+N">Nikolas Herbst</a>, 
<a href="/search/cs?searchtype=author&query=Kounev%2C+S">Samuel Kounev</a>, 
<a href="/search/cs?searchtype=author&query=Foster%2C+I">Ian Foster</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">In many areas of decision-making, forecasting is an essential pillar.
Consequently, many different forecasting methods have been proposed. From our
experience, recently presented forecasting methods are computationally
intensive, poorly automated, tailored to a particular data set, or they lack a
predictable time-to-result. To this end, we introduce Telescope, a novel
machine learning-based forecasting approach that automatically retrieves
relevant information from a given time series and splits it into parts,
handling each of them separately. In contrast to deep learning methods, our
approach doesn't require parameterization or the need to train and fit a
multitude of parameters. It operates with just one time series and provides
forecasts within seconds without any additional setup. Our experiments show
that Telescope outperforms recent methods by providing accurate and reliable
forecasts while making no assumptions about the analyzed time series.
</p>
</div>
</dd>
<dt><a name="item9">[9]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15875" title="Abstract">arXiv:2309.15875</a> [<a href="/pdf/2309.15875" title="Download PDF">pdf</a>, <a href="/format/2309.15875" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> STAG: Enabling Low Latency and Low Staleness of GNN-based Services with  Dynamic Graphs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jiawen Wang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Q">Quan Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zeng%2C+D">Deze Zeng</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+Z">Zhuo Song</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+C">Chen Chen</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+M">Minyi Guo</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Many emerging user-facing services adopt Graph Neural Networks (GNNs) to
improve serving accuracy. When the graph used by a GNN model changes,
representations (embedding) of nodes in the graph should be updated
accordingly. However, the node representation update is too slow, resulting in
either long response latency of user queries (the inference is performed after
the update completes) or high staleness problem (the inference is performed
based on stale data). Our in-depth analysis shows that the slow update is
mainly due to neighbor explosion problem in graphs and duplicated computation.
Based on such findings, we propose STAG, a GNN serving framework that enables
low latency and low staleness of GNN-based services. It comprises a
collaborative serving mechanism and an additivity-based incremental propagation
strategy. With the collaborative serving mechanism, only part of node
representations are updated during the update phase, and the final
representations are calculated in the inference phase. It alleviates the
neighbor explosion problem. The additivity-based incremental propagation
strategy reuses intermediate data during the update phase, eliminating
duplicated computation problem. Experimental results show that STAG accelerates
the update phase by 1.3x~90.1x, and greatly reduces staleness time with a
slight increase in response latency.
</p>
</div>
</dd>
<dt><a name="item10">[10]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15876" title="Abstract">arXiv:2309.15876</a> [<a href="/pdf/2309.15876" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Older LGBT+ and Blockchain in Healthcare: A Value Sensitive Design  Perspective
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Poulsen%2C+A">Adam Poulsen</a>, 
<a href="/search/cs?searchtype=author&query=Fosch-Villaronga%2C+E">Eduard Fosch-Villaronga</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>

</div>
<p class="mathjax">Most algorithms deployed in healthcare do not consider gender and sex despite
the effect they have on individuals' health differences. Missing these
dimensions in healthcare information systems is a point of concern, as
neglecting these aspects will inevitably perpetuate existing biases, produce
far from optimal results, and may generate diagnosis errors. An
often-overlooked community with distinct care values and needs are LGBT+ older
adults, which has traditionally been under-surveyed in healthcare and
technology design. This paper investigates the implications of missing gender
and sex considerations in distributed ledger technologies for LGBT+ older
adults. By using the value sensitive design methodology, our contribution shows
that many value meanings dear to marginalized communities are not considered in
the design of the blockchain, such as LGBT+ older adults' interpretations of
trust, privacy, and security. By highlighting the LGBT+ older population
values, our contribution alerts us to the potential discriminatory implications
of these technologies, which do not consider the gender and sex differences of
marginalized, silent populations. Focusing on one community throughout - LGBT+
older adults - we emphasize the need for a holistic, value sensitive design
approach for the development of ledger technologies for healthcare, including
the values of everyone within the healthcare ecosystem.
</p>
</div>
</dd>
<dt><a name="item11">[11]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15877" title="Abstract">arXiv:2309.15877</a> [<a href="/pdf/2309.15877" title="Download PDF">pdf</a>, <a href="/format/2309.15877" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Neuro-Inspired Hierarchical Multimodal Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xiao%2C+X">Xiongye Xiao</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+G">Gengshuo Liu</a>, 
<a href="/search/cs?searchtype=author&query=Gupta%2C+G">Gaurav Gupta</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+D">Defu Cao</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+S">Shixuan Li</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yaxing Li</a>, 
<a href="/search/cs?searchtype=author&query=Fang%2C+T">Tianqing Fang</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+M">Mingxi Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Bogdan%2C+P">Paul Bogdan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Integrating and processing information from various sources or modalities are
critical for obtaining a comprehensive and accurate perception of the real
world. Drawing inspiration from neuroscience, we develop the
Information-Theoretic Hierarchical Perception (ITHP) model, which utilizes the
concept of information bottleneck. Distinct from most traditional fusion models
that aim to incorporate all modalities as input, our model designates the prime
modality as input, while the remaining modalities act as detectors in the
information pathway. Our proposed perception model focuses on constructing an
effective and compact information flow by achieving a balance between the
minimization of mutual information between the latent state and the input modal
state, and the maximization of mutual information between the latent states and
the remaining modal states. This approach leads to compact latent state
representations that retain relevant information while minimizing redundancy,
thereby substantially enhancing the performance of downstream tasks.
Experimental evaluations on both the MUStARD and CMU-MOSI datasets demonstrate
that our model consistently distills crucial information in multimodal learning
scenarios, outperforming state-of-the-art benchmarks.
</p>
</div>
</dd>
<dt><a name="item12">[12]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15881" title="Abstract">arXiv:2309.15881</a> [<a href="/pdf/2309.15881" title="Download PDF">pdf</a>, <a href="/format/2309.15881" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Enhancing Cross-Category Learning in Recommendation Systems with  Multi-Layer Embedding Training
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Deng%2C+Z">Zihao Deng</a>, 
<a href="/search/cs?searchtype=author&query=Ghaemmaghami%2C+B">Benjamin Ghaemmaghami</a>, 
<a href="/search/cs?searchtype=author&query=Singh%2C+A+K">Ashish Kumar Singh</a>, 
<a href="/search/cs?searchtype=author&query=Cho%2C+B">Benjamin Cho</a>, 
<a href="/search/cs?searchtype=author&query=Orshansky%2C+L">Leo Orshansky</a>, 
<a href="/search/cs?searchtype=author&query=Erez%2C+M">Mattan Erez</a>, 
<a href="/search/cs?searchtype=author&query=Orshansky%2C+M">Michael Orshansky</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This is the preprint of our paper accepted at ACML 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Modern DNN-based recommendation systems rely on training-derived embeddings
of sparse features. Input sparsity makes obtaining high-quality embeddings for
rarely-occurring categories harder as their representations are updated
infrequently. We demonstrate a training-time technique to produce superior
embeddings via effective cross-category learning and theoretically explain its
surprising effectiveness. The scheme, termed the multi-layer embeddings
training (MLET), trains embeddings using factorization of the embedding layer,
with an inner dimension higher than the target embedding dimension. For
inference efficiency, MLET converts the trained two-layer embedding into a
single-layer one thus keeping inference-time model size unchanged.
<br />Empirical superiority of MLET is puzzling as its search space is not larger
than that of the single-layer embedding. The strong dependence of MLET on the
inner dimension is even more surprising. We develop a theory that explains both
of these behaviors by showing that MLET creates an adaptive update mechanism
modulated by the singular vectors of embeddings. When tested on multiple
state-of-the-art recommendation models for click-through rate (CTR) prediction
tasks, MLET consistently produces better models, especially for rare items. At
constant model quality, MLET allows embedding dimension, and model size,
reduction by up to 16x, and 5.8x on average, across the models.
</p>
</div>
</dd>
<dt><a name="item13">[13]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15883" title="Abstract">arXiv:2309.15883</a> [<a href="/pdf/2309.15883" title="Download PDF">pdf</a>, <a href="/format/2309.15883" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Highly Efficient SNNs for High-speed Object Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Qiu%2C+N">Nemin Qiu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zhiguo Li</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yuan Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+C">Chuang Zhu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">The high biological properties and low energy consumption of Spiking Neural
Networks (SNNs) have brought much attention in recent years. However, the
converted SNNs generally need large time steps to achieve satisfactory
performance, which will result in high inference latency and computational
resources increase. In this work, we propose a highly efficient and fast SNN
for object detection. First, we build an initial compact ANN by using
quantization training method of convolution layer fold batch normalization
layer and neural network modification. Second, we theoretically analyze how to
obtain the low complexity SNN correctly. Then, we propose a scale-aware
pseudoquantization scheme to guarantee the correctness of the compact ANN to
SNN. Third, we propose a continuous inference scheme by using a Feed-Forward
Integrate-and-Fire (FewdIF) neuron to realize high-speed object detection.
Experimental results show that our efficient SNN can achieve 118X speedup on
GPU with only 1.5MB parameters for object detection tasks. We further verify
our SNN on FPGA platform and the proposed model can achieve 800+FPS object
detection with extremely low latency.
</p>
</div>
</dd>
<dt><a name="item14">[14]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15884" title="Abstract">arXiv:2309.15884</a> [<a href="/pdf/2309.15884" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The strain on scientific publishing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hanson%2C+M+A">Mark A. Hanson</a>, 
<a href="/search/cs?searchtype=author&query=Barreiro%2C+P+G">Pablo G&#xf3;mez Barreiro</a>, 
<a href="/search/cs?searchtype=author&query=Crosetto%2C+P">Paolo Crosetto</a>, 
<a href="/search/cs?searchtype=author&query=Brockington%2C+D">Dan Brockington</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 figures, 2 tables, 15 pages + references. Full-res figures at <a href="https://doi.org/10.6084/m9.figshare.24203790.v1">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Digital Libraries (cs.DL)</span>

</div>
<p class="mathjax">Scientists are increasingly overwhelmed by the volume of articles being
published. Total articles indexed in Scopus and Web of Science have grown
exponentially in recent years; in 2022 the article total was 47% higher than in
2016, which has outpaced the limited growth, if any, in the number of
practising scientists. Thus, publication workload per scientist (writing,
reviewing, editing) has increased dramatically. We define this problem as the
strain on scientific publishing. To analyse this strain, we present five
data-driven metrics showing publisher growth, processing times, and citation
behaviours. We draw these data from web scrapes, requests for data from
publishers, and material that is freely available through publisher websites.
Our findings are based on millions of papers produced by leading academic
publishers. We find specific groups have disproportionately grown in their
articles published per year, contributing to this strain. Some publishers
enabled this growth by adopting a strategy of hosting special issues, which
publish articles with reduced turnaround times. Given pressures on researchers
to publish or perish to be competitive for funding applications, this strain
was likely amplified by these offers to publish more articles. We also observed
widespread year-over-year inflation of journal impact factors coinciding with
this strain, which risks confusing quality signals. Such exponential growth
cannot be sustained. The metrics we define here should enable this evolving
conversation to reach actionable solutions to address the strain on scientific
publishing.
</p>
</div>
</dd>
<dt><a name="item15">[15]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15886" title="Abstract">arXiv:2309.15886</a> [<a href="/pdf/2309.15886" title="Download PDF">pdf</a>, <a href="/ps/2309.15886" title="Download PostScript">ps</a>, <a href="/format/2309.15886" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Projection based fuzzy least squares twin support vector machine for  class imbalance problems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tanveer%2C+M">M. Tanveer</a>, 
<a href="/search/cs?searchtype=author&query=Mishra%2C+R">Ritik Mishra</a>, 
<a href="/search/cs?searchtype=author&query=Richhariya%2C+B">Bharat Richhariya</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Class imbalance is a major problem in many real world classification tasks.
Due to the imbalance in the number of samples, the support vector machine (SVM)
classifier gets biased toward the majority class. Furthermore, these samples
are often observed with a certain degree of noise. Therefore, to remove these
problems we propose a novel fuzzy based approach to deal with class imbalanced
as well noisy datasets. We propose two approaches to address these problems.
The first approach is based on the intuitionistic fuzzy membership, termed as
robust energy-based intuitionistic fuzzy least squares twin support vector
machine (IF-RELSTSVM). Furthermore, we introduce the concept of
hyperplane-based fuzzy membership in our second approach, where the final
classifier is termed as robust energy-based fuzzy least square twin support
vector machine (F-RELSTSVM). By using this technique, the membership values are
based on a projection based approach, where the data points are projected on
the hyperplanes. The performance of the proposed algorithms is evaluated on
several benchmark and synthetic datasets. The experimental results show that
the proposed IF-RELSTSVM and F-RELSTSVM models outperform the baseline
algorithms. Statistical tests are performed to check the significance of the
proposed algorithms. The results show the applicability of the proposed
algorithms on noisy as well as imbalanced datasets.
</p>
</div>
</dd>
<dt><a name="item16">[16]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15893" title="Abstract">arXiv:2309.15893</a> [<a href="/pdf/2309.15893" title="Download PDF">pdf</a>, <a href="/format/2309.15893" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Breamy: An augmented reality mHealth prototype for surgical  decision-making in breast cancer
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Najafi%2C+N">Niki Najafi</a>, 
<a href="/search/cs?searchtype=author&query=Addie%2C+M">Miranda Addie</a>, 
<a href="/search/cs?searchtype=author&query=Meterissian%2C+S">Sarkis Meterissian</a>, 
<a href="/search/cs?searchtype=author&query=Kersten-Oertel%2C+M">Marta Kersten-Oertel</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">In 2020, according to WHO, breast cancer affected 2.3 million women
worldwide, resulting in 685,000 fatalities. By the end of the year,
approximately 7.8 million women worldwide had survived their breast cancer
making it the most widespread form of cancer globally. Surgical treatment
decisions, including choosing between oncoplastic options, often require quick
decision-making within an 8-week time frame. However, many women lack the
necessary knowledge and preparation for making such complex informed decisions.
Anxiety and unsatisfactory outcomes can result from inadequate decision-making
processes, leading to complications and the need for revision surgeries. Shared
decision-making and personalized decision aids have shown positive effects on
patient satisfaction and treatment outcomes. This paper introduces Breamy, a
prototype mobile health (mHealth) application that utilizes augmented reality
(AR) technology to assist breast cancer patients in making informed decisions.
The app provides 3D visualizations of different oncoplastic procedures, aiming
to improve confidence in surgical decision-making, reduce decisional regret,
and enhance patient well-being after surgery. To determine the perception of
the usefulness of Breamy, we collected data from 166 participants through an
online survey. The results suggest that Breamy has the potential to reduce
patient's anxiety levels and assist them during the decision-making process.
</p>
</div>
</dd>
<dt><a name="item17">[17]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15915" title="Abstract">arXiv:2309.15915</a> [<a href="/pdf/2309.15915" title="Download PDF">pdf</a>, <a href="/format/2309.15915" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Zero-Shot and Few-Shot Video Question Answering with Multi-Modal Prompts
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Engin%2C+D">Deniz Engin</a>, 
<a href="/search/cs?searchtype=author&query=Avrithis%2C+Y">Yannis Avrithis</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ICCV2023 CLVL Workshop (Oral). Project page: <a href="https://engindeniz.github.io/vitis">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Recent vision-language models are driven by large-scale pretrained models.
However, adapting pretrained models on limited data presents challenges such as
overfitting, catastrophic forgetting, and the cross-modal gap between vision
and language. We introduce a parameter-efficient method to address these
challenges, combining multimodal prompt learning and a transformer-based
mapping network, while keeping the pretrained models frozen. Our experiments on
several video question answering benchmarks demonstrate the superiority of our
approach in terms of performance and parameter efficiency on both zero-shot and
few-shot settings. Our code is available at https://engindeniz.github.io/vitis.
</p>
</div>
</dd>
<dt><a name="item18">[18]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15940" title="Abstract">arXiv:2309.15940</a> [<a href="/pdf/2309.15940" title="Download PDF">pdf</a>, <a href="/format/2309.15940" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Context-Aware Entity Grounding with Open-Vocabulary 3D Scene Graphs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chang%2C+H">Haonan Chang</a>, 
<a href="/search/cs?searchtype=author&query=Boyalakuntla%2C+K">Kowndinya Boyalakuntla</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+S">Shiyang Lu</a>, 
<a href="/search/cs?searchtype=author&query=Cai%2C+S">Siwei Cai</a>, 
<a href="/search/cs?searchtype=author&query=Jing%2C+E">Eric Jing</a>, 
<a href="/search/cs?searchtype=author&query=Keskar%2C+S">Shreesh Keskar</a>, 
<a href="/search/cs?searchtype=author&query=Geng%2C+S">Shijie Geng</a>, 
<a href="/search/cs?searchtype=author&query=Abbas%2C+A">Adeeb Abbas</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+L">Lifeng Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Bekris%2C+K">Kostas Bekris</a>, 
<a href="/search/cs?searchtype=author&query=Boularias%2C+A">Abdeslam Boularias</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> The code and dataset used for evaluation can be found at https://github.com/changhaonan/OVSG}{<a href="https://github.com/changhaonan/OVSG.">this https URL</a> This paper has been accepted by CoRL2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">We present an Open-Vocabulary 3D Scene Graph (OVSG), a formal framework for
grounding a variety of entities, such as object instances, agents, and regions,
with free-form text-based queries. Unlike conventional semantic-based object
localization approaches, our system facilitates context-aware entity
localization, allowing for queries such as ``pick up a cup on a kitchen table"
or ``navigate to a sofa on which someone is sitting". In contrast to existing
research on 3D scene graphs, OVSG supports free-form text input and
open-vocabulary querying. Through a series of comparative experiments using the
ScanNet dataset and a self-collected dataset, we demonstrate that our proposed
approach significantly surpasses the performance of previous semantic-based
localization techniques. Moreover, we highlight the practical application of
OVSG in real-world robot navigation and manipulation experiments.
</p>
</div>
</dd>
<dt><a name="item19">[19]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15941" title="Abstract">arXiv:2309.15941</a> [<a href="/pdf/2309.15941" title="Download PDF">pdf</a>, <a href="/format/2309.15941" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AutoEncoding Tree for City Generation and Applications
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Han%2C+W">Wenyu Han</a>, 
<a href="/search/cs?searchtype=author&query=Wen%2C+C">Congcong Wen</a>, 
<a href="/search/cs?searchtype=author&query=Chok%2C+L">Lazarus Chok</a>, 
<a href="/search/cs?searchtype=author&query=Tan%2C+Y+L">Yan Liang Tan</a>, 
<a href="/search/cs?searchtype=author&query=Chan%2C+S+L">Sheung Lung Chan</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+H">Hang Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+C">Chen Feng</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">City modeling and generation have attracted an increased interest in various
applications, including gaming, urban planning, and autonomous driving. Unlike
previous works focused on the generation of single objects or indoor scenes,
the huge volumes of spatial data in cities pose a challenge to the generative
models. Furthermore, few publicly available 3D real-world city datasets also
hinder the development of methods for city generation. In this paper, we first
collect over 3,000,000 geo-referenced objects for the city of New York, Zurich,
Tokyo, Berlin, Boston and several other large cities. Based on this dataset, we
propose AETree, a tree-structured auto-encoder neural network, for city
generation. Specifically, we first propose a novel Spatial-Geometric Distance
(SGD) metric to measure the similarity between building layouts and then
construct a binary tree over the raw geometric data of building based on the
SGD metric. Next, we present a tree-structured network whose encoder learns to
extract and merge spatial information from bottom-up iteratively. The resulting
global representation is reversely decoded for reconstruction or generation. To
address the issue of long-dependency as the level of the tree increases, a Long
Short-Term Memory (LSTM) Cell is employed as a basic network element of the
proposed AETree. Moreover, we introduce a novel metric, Overlapping Area Ratio
(OAR), to quantitatively evaluate the generation results. Experiments on the
collected dataset demonstrate the effectiveness of the proposed model on 2D and
3D city generation. Furthermore, the latent features learned by AETree can
serve downstream urban planning applications.
</p>
</div>
</dd>
<dt><a name="item20">[20]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15942" title="Abstract">arXiv:2309.15942</a> [<a href="/pdf/2309.15942" title="Download PDF">pdf</a>, <a href="/format/2309.15942" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Efficient and Trustworthy AI Through  Hardware-Algorithm-Communication Co-Design
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rajendran%2C+B">Bipin Rajendran</a>, 
<a href="/search/cs?searchtype=author&query=Simeone%2C+O">Osvaldo Simeone</a>, 
<a href="/search/cs?searchtype=author&query=Al-Hashimi%2C+B+M">Bashir M. Al-Hashimi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Emerging Technologies (cs.ET); Information Theory (cs.IT)

</div>
<p class="mathjax">Artificial intelligence (AI) algorithms based on neural networks have been
designed for decades with the goal of maximising some measure of accuracy. This
has led to two undesired effects. First, model complexity has risen
exponentially when measured in terms of computation and memory requirements.
Second, state-of-the-art AI models are largely incapable of providing
trustworthy measures of their uncertainty, possibly `hallucinating' their
answers and discouraging their adoption for decision-making in sensitive
applications.
<br />With the goal of realising efficient and trustworthy AI, in this paper we
highlight research directions at the intersection of hardware and software
design that integrate physical insights into computational substrates,
neuroscientific principles concerning efficient information processing,
information-theoretic results on optimal uncertainty quantification, and
communication-theoretic guidelines for distributed processing. Overall, the
paper advocates for novel design methodologies that target not only accuracy
but also uncertainty quantification, while leveraging emerging computing
hardware architectures that move beyond the traditional von Neumann digital
computing paradigm to embrace in-memory, neuromorphic, and quantum computing
technologies. An important overarching principle of the proposed approach is to
view the stochasticity inherent in the computational substrate and in the
communication channels between processors as a resource to be leveraged for the
purpose of representing and processing classical and quantum uncertainty.
</p>
</div>
</dd>
<dt><a name="item21">[21]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15943" title="Abstract">arXiv:2309.15943</a> [<a href="/pdf/2309.15943" title="Download PDF">pdf</a>, <a href="/format/2309.15943" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Scalable Multi-Robot Collaboration with Large Language Models:  Centralized or Decentralized Systems?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yongchao Chen</a>, 
<a href="/search/cs?searchtype=author&query=Arkin%2C+J">Jacob Arkin</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Roy%2C+N">Nicholas Roy</a>, 
<a href="/search/cs?searchtype=author&query=Fan%2C+C">Chuchu Fan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages, 8 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">A flurry of recent work has demonstrated that pre-trained large language
models (LLMs) can be effective task planners for a variety of single-robot
tasks. The planning performance of LLMs is significantly improved via prompting
techniques, such as in-context learning or re-prompting with state feedback,
placing new importance on the token budget for the context window. An
under-explored but natural next direction is to investigate LLMs as multi-robot
task planners. However, long-horizon, heterogeneous multi-robot planning
introduces new challenges of coordination while also pushing up against the
limits of context window length. It is therefore critical to find
token-efficient LLM planning frameworks that are also able to reason about the
complexities of multi-robot coordination. In this work, we compare the task
success rate and token efficiency of four multi-agent communication frameworks
(centralized, decentralized, and two hybrid) as applied to four
coordination-dependent multi-agent 2D task scenarios for increasing numbers of
agents. We find that a hybrid framework achieves better task success rates
across all four tasks and scales better to more agents. We further demonstrate
the hybrid frameworks in 3D simulations where the vision-to-text problem and
dynamical errors are considered. See our project website
https://yongchao98.github.io/MIT-REALM-Multi-Robot/ for prompts, videos, and
code.
</p>
</div>
</dd>
<dt><a name="item22">[22]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15946" title="Abstract">arXiv:2309.15946</a> [<a href="/pdf/2309.15946" title="Download PDF">pdf</a>, <a href="/format/2309.15946" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Unified Long-Term Time-Series Forecasting Benchmark
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cyranka%2C+J">Jacek Cyranka</a>, 
<a href="/search/cs?searchtype=author&query=Haponiuk%2C+S">Szymon Haponiuk</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Neural and Evolutionary Computing (cs.NE); Dynamical Systems (math.DS)

</div>
<p class="mathjax">In order to support the advancement of machine learning methods for
predicting time-series data, we present a comprehensive dataset designed
explicitly for long-term time-series forecasting. We incorporate a collection
of datasets obtained from diverse, dynamic systems and real-life records. Each
dataset is standardized by dividing it into training and test trajectories with
predetermined lookback lengths. We include trajectories of length up to $2000$
to ensure a reliable evaluation of long-term forecasting capabilities. To
determine the most effective model in diverse scenarios, we conduct an
extensive benchmarking analysis using classical and state-of-the-art models,
namely LSTM, DeepAR, NLinear, N-Hits, PatchTST, and LatentODE. Our findings
reveal intriguing performance comparisons among these models, highlighting the
dataset-dependent nature of model effectiveness. Notably, we introduce a custom
latent NLinear model and enhance DeepAR with a curriculum learning phase. Both
consistently outperform their vanilla counterparts.
</p>
</div>
</dd>
<dt><a name="item23">[23]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15951" title="Abstract">arXiv:2309.15951</a> [<a href="/pdf/2309.15951" title="Download PDF">pdf</a>, <a href="/format/2309.15951" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> IEEE 802.11be Wi-Fi 7: Feature Summary and Performance Evaluation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xiaoqian Liu</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+Y">Yuhan Dong</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yiqing Li</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+Y">Yousi Lin</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+X">Xun Yang</a>, 
<a href="/search/cs?searchtype=author&query=Gan%2C+M">Ming Gan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages, 4 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">While the pace of commercial scale application of Wi-Fi 6 accelerates, the
IEEE 802.11 Working Group is about to complete the development of a new
amendment standard IEEE 802.11be -- Extremely High Throughput (EHT), also known
as Wi-Fi 7, which can be used to meet the demand for the throughput of 4K/8K
videos up to tens of Gbps and low-latency video applications such as virtual
reality (VR) and augmented reality (AR). Wi-Fi 7 not only scales Wi-Fi 6 with
doubled bandwidth, but also supports real-time applications, which brings
revolutionary changes to Wi-Fi. In this article, we start by introducing the
main objectives and timeline of Wi-Fi 7 and then list the latest key techniques
which promote the performance improvement of Wi-Fi 7. Finally, we validate the
most critical objectives of Wi-Fi 7 -- the potential up to 30 Gbps throughput
and lower latency. System-level simulation results suggest that by combining
the new techniques, Wi-Fi 7 achieves 30 Gbps throughput and lower latency than
Wi-Fi 6.
</p>
</div>
</dd>
<dt><a name="item24">[24]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15954" title="Abstract">arXiv:2309.15954</a> [<a href="/pdf/2309.15954" title="Download PDF">pdf</a>, <a href="/format/2309.15954" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Devil is in the Details: A Deep Dive into the Rabbit Hole of Data  Filtering
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yu%2C+H">Haichao Yu</a>, 
<a href="/search/cs?searchtype=author&query=Tian%2C+Y">Yu Tian</a>, 
<a href="/search/cs?searchtype=author&query=Kumar%2C+S">Sateesh Kumar</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+L">Linjie Yang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Heng Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 10 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">The quality of pre-training data plays a critical role in the performance of
foundation models. Popular foundation models often design their own recipe for
data filtering, which makes it hard to analyze and compare different data
filtering approaches. DataComp is a new benchmark dedicated to evaluating
different methods for data filtering. This paper describes our learning and
solution when participating in the DataComp challenge. Our filtering strategy
includes three stages: single-modality filtering, cross-modality filtering, and
data distribution alignment. We integrate existing methods and propose new
solutions, such as computing CLIP score on horizontally flipped images to
mitigate the interference of scene text, using vision and language models to
retrieve training samples for target downstream tasks, rebalancing the data
distribution to improve the efficiency of allocating the computational budget,
etc. We slice and dice our design choices, provide in-depth analysis, and
discuss open questions. Our approach outperforms the best method from the
DataComp paper by over 4% on the average performance of 38 tasks and by over 2%
on ImageNet.
</p>
</div>
</dd>
<dt><a name="item25">[25]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15955" title="Abstract">arXiv:2309.15955</a> [<a href="/pdf/2309.15955" title="Download PDF">pdf</a>, <a href="/format/2309.15955" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Hybrid Volitional Control of a Robotic Transtibial Prosthesis using a  Phase Variable Impedance Controller
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Posh%2C+R+R">Ryan R. Posh</a>, 
<a href="/search/cs?searchtype=author&query=Tittle%2C+J+A">Jonathan A. Tittle</a>, 
<a href="/search/cs?searchtype=author&query=Kelly%2C+D+J">David J. Kelly</a>, 
<a href="/search/cs?searchtype=author&query=Schmiedeler%2C+J+P">James P. Schmiedeler</a>, 
<a href="/search/cs?searchtype=author&query=Wensing%2C+P+M">Patrick M. Wensing</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, 7 figures, submitted to ICRA 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">For robotic transtibial prosthesis control, the global kinematics of the
tibia can be used to monitor the progression of the gait cycle and command
smooth and continuous actuation. In this work, these global tibia kinematics
are used to define a phase variable impedance controller (PVIC), which is then
implemented as the nonvolitional base controller within a hybrid volitional
control framework (PVI-HVC). The gait progression estimation and biomechanic
performance of one able-bodied individual walking on a robotic ankle prosthesis
via a bypass adapter are compared for three control schemes: a passive
benchmark controller, PVIC, and PVI-HVC. The different actuation of each
controller had a direct effect on the global tibia kinematics, but the average
deviation between the estimated and ground truth gait percentage were 1.6%,
1.8%, and 2.1%, respectively, for each controller. Both PVIC and PVI-HVC
produced good agreement with able-bodied kinematic and kinetic references. As
designed, PVI-HVC results were similar to those of PVIC when the user used low
volitional intent, but yielded higher peak plantarflexion, peak torque, and
peak power when the user commanded high volitional input in late stance. This
additional torque and power also allowed the user to volitionally and
continuously achieve activities beyond level walking, such as ascending ramps,
avoiding obstacles, standing on tip-toes, and tapping the foot. In this way,
PVI-HVC offers the kinetic and kinematic performance of the PVIC during level
ground walking, along with the freedom to volitionally pursue alternative
activities.
</p>
</div>
</dd>
<dt><a name="item26">[26]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15963" title="Abstract">arXiv:2309.15963</a> [<a href="/pdf/2309.15963" title="Download PDF">pdf</a>, <a href="/format/2309.15963" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An Uncertainty-Aware Pseudo-Label Selection Framework using Regularized  Conformal Prediction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Moezzi%2C+M">Matin Moezzi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Consistency regularization-based methods are prevalent in semi-supervised
learning (SSL) algorithms due to their exceptional performance. However, they
mainly depend on domain-specific data augmentations, which are not usable in
domains where data augmentations are less practicable. On the other hand,
Pseudo-labeling (PL) is a general and domain-agnostic SSL approach that, unlike
consistency regularization-based methods, does not rely on the domain. PL
underperforms due to the erroneous high-confidence predictions from poorly
calibrated models. This paper proposes an uncertainty-aware pseudo-label
selection framework that employs uncertainty sets yielded by the conformal
regularization algorithm to fix the poor calibration neural networks, reducing
noisy training data. The codes of this work are available at:
https://github.com/matinmoezzi/ups conformal classification
</p>
</div>
</dd>
<dt><a name="item27">[27]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15965" title="Abstract">arXiv:2309.15965</a> [<a href="/pdf/2309.15965" title="Download PDF">pdf</a>, <a href="/format/2309.15965" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> TraCE: Trajectory Counterfactual Explanation Scores
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Clark%2C+J+N">Jeffrey N. Clark</a>, 
<a href="/search/cs?searchtype=author&query=Small%2C+E+A">Edward A. Small</a>, 
<a href="/search/cs?searchtype=author&query=Keshtmand%2C+N">Nawid Keshtmand</a>, 
<a href="/search/cs?searchtype=author&query=Wan%2C+M+W+L">Michelle W.L. Wan</a>, 
<a href="/search/cs?searchtype=author&query=Mayoral%2C+E+F">Elena Fillola Mayoral</a>, 
<a href="/search/cs?searchtype=author&query=Werner%2C+E">Enrico Werner</a>, 
<a href="/search/cs?searchtype=author&query=Bourdeaux%2C+C+P">Christopher P. Bourdeaux</a>, 
<a href="/search/cs?searchtype=author&query=Santos-Rodriguez%2C+R">Raul Santos-Rodriguez</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, 4 figures, appendix
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computers and Society (cs.CY); Metric Geometry (math.MG)

</div>
<p class="mathjax">Counterfactual explanations, and their associated algorithmic recourse, are
typically leveraged to understand, explain, and potentially alter a prediction
coming from a black-box classifier. In this paper, we propose to extend the use
of counterfactuals to evaluate progress in sequential decision making tasks. To
this end, we introduce a model-agnostic modular framework, TraCE (Trajectory
Counterfactual Explanation) scores, which is able to distill and condense
progress in highly complex scenarios into a single value. We demonstrate
TraCE's utility across domains by showcasing its main properties in two case
studies spanning healthcare and climate change.
</p>
</div>
</dd>
<dt><a name="item28">[28]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15968" title="Abstract">arXiv:2309.15968</a> [<a href="/pdf/2309.15968" title="Download PDF">pdf</a>, <a href="/format/2309.15968" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Dynamics of Ideological Biases of Social Media Users
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Modi%2C+M+S">Mohammed Shahid Modi</a>, 
<a href="/search/cs?searchtype=author&query=Flamino%2C+J">James Flamino</a>, 
<a href="/search/cs?searchtype=author&query=Szymanski%2C+B+K">Boleslaw K. Szymanski</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, 4 figures, submitted to IEEE Communications Magazine
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>; Computers and Society (cs.CY)

</div>
<p class="mathjax">Humanity for centuries has perfected skills of interpersonal interactions and
evolved patterns that enable people to detect lies and deceiving behavior of
others in face-to-face settings. Unprecedented growth of people's access to
mobile phones and social media raises an important question: How does this new
technology influence people's interactions and support the use of traditional
patterns? In this paper, we answer this question for homophily driven patterns
in social media. In our previous studies, we found that, on a university
campus, changes in student opinions were driven by the desire to hold popular
opinions. Here, we demonstrate that the evolution of online platform-wide
opinion groups is driven by the same desire. We focus on two social media:
Twitter and Parler, on which we tracked the political biases of their users. On
Parler, an initially stable group of right-biased users evolved into a
permanent right-leaning echo chamber dominating weaker, transient groups of
members with opposing political biases. In contrast, on Twitter, the initial
presence of two large opposing bias groups led to the evolution of a bimodal
bias distribution, with a high degree of polarization. We capture the movement
of users from the initial to final bias groups during the tracking period. We
also show that user choices are influenced by side-effects of homophily. The
users entering the platform attempt to find a sufficiently large group whose
members hold political bias within the range sufficiently close to the new
user's bias. If successful, they stabilize their bias and become a permanent
member of the group. Otherwise, they leave the platform. We believe that the
dynamics of users uncovered in this paper create a foundation for technical
solutions supporting social groups on social media and socially aware networks.
</p>
</div>
</dd>
<dt><a name="item29">[29]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15970" title="Abstract">arXiv:2309.15970</a> [<a href="/pdf/2309.15970" title="Download PDF">pdf</a>, <a href="/format/2309.15970" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Accelerating Motion Planning via Optimal Transport
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Le%2C+A+T">An T. Le</a>, 
<a href="/search/cs?searchtype=author&query=Chalvatzaki%2C+G">Georgia Chalvatzaki</a>, 
<a href="/search/cs?searchtype=author&query=Biess%2C+A">Armin Biess</a>, 
<a href="/search/cs?searchtype=author&query=Peters%2C+J">Jan Peters</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 29 pages, 8 figures, accepted to NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Optimization and Control (math.OC)

</div>
<p class="mathjax">Motion planning is still an open problem for many disciplines, e.g.,
robotics, autonomous driving, due to issues like high planning times that
hinder real-time, efficient decision-making. A class of methods striving to
provide smooth solutions is gradient-based trajectory optimization. However,
those methods might suffer from bad local minima, while for many settings, they
may be inapplicable due to the absence of easy access to objectives-gradients.
In response to these issues, we introduce Motion Planning via Optimal Transport
(MPOT) - a gradient-free method that optimizes a batch of smooth trajectories
over highly nonlinear costs, even for high-dimensional tasks, while imposing
smoothness through a Gaussian Process dynamics prior via planning-as-inference
perspective. To facilitate batch trajectory optimization, we introduce an
original zero-order and highly-parallelizable update rule -- the Sinkhorn Step,
which uses the regular polytope family for its search directions; each regular
polytope, centered on trajectory waypoints, serves as a local neighborhood,
effectively acting as a trust region, where the Sinkhorn Step "transports"
local waypoints toward low-cost regions. We theoretically show that Sinkhorn
Step guides the optimizing parameters toward local minima regions on non-convex
objective functions. We then show the efficiency of MPOT in a range of problems
from low-dimensional point-mass navigation to high-dimensional whole-body robot
motion planning, evincing its superiority compared with popular motion planners
and paving the way for new applications of optimal transport in motion
planning.
</p>
</div>
</dd>
<dt><a name="item30">[30]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15971" title="Abstract">arXiv:2309.15971</a> [<a href="/pdf/2309.15971" title="Download PDF">pdf</a>, <a href="/format/2309.15971" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> OPPO: An Ontology for Describing Fine-Grained Data Practices in Privacy  Policies of Online Social Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gupta%2C+S+D">Sanonda Datta Gupta</a>, 
<a href="/search/cs?searchtype=author&query=Hahmann%2C+T">Torsten Hahmann</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 Pages, 6 figures, Ontology Showcase and Demonstrations Track, 9th Joint Ontology Workshops (JOWO 2023), co-located with FOIS 2023, 19-20 July, 2023, Sherbrooke, Quebec, Canada
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">Privacy policies outline the data practices of Online Social Networks (OSN)
to comply with privacy regulations such as the EU-GDPR and CCPA. Several
ontologies for modeling privacy regulations, policies, and compliance have
emerged in recent years. However, they are limited in various ways: (1) they
specifically model what is required of privacy policies according to one
specific privacy regulation such as GDPR; (2) they provide taxonomies of
concepts but are not sufficiently axiomatized to afford automated reasoning
with them; and (3) they do not model data practices of privacy policies in
sufficient detail to allow assessing the transparency of policies. This paper
presents an OWL Ontology for Privacy Policies of OSNs, OPPO, that aims to fill
these gaps by formalizing detailed data practices from OSNS' privacy policies.
OPPO is grounded in BFO, IAO, OMRSE, and OBI, and its design is guided by the
use case of representing and reasoning over the content of OSNs' privacy
policies and evaluating policies' transparency in greater detail.
</p>
</div>
</dd>
<dt><a name="item31">[31]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15975" title="Abstract">arXiv:2309.15975</a> [<a href="/pdf/2309.15975" title="Download PDF">pdf</a>, <a href="/format/2309.15975" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Enabling Large-scale Heterogeneous Collaboration with Opportunistic  Communications
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cladera%2C+F">Fernando Cladera</a>, 
<a href="/search/cs?searchtype=author&query=Ravichandran%2C+Z">Zachary Ravichandran</a>, 
<a href="/search/cs?searchtype=author&query=Miller%2C+I+D">Ian D. Miller</a>, 
<a href="/search/cs?searchtype=author&query=Hsieh%2C+M+A">M. Ani Hsieh</a>, 
<a href="/search/cs?searchtype=author&query=Taylor%2C+C+J">C. J. Taylor</a>, 
<a href="/search/cs?searchtype=author&query=Kumar%2C+V">Vijay Kumar</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, 8 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Multi-robot collaboration in large-scale environments with limited-sized
teams and without external infrastructure is challenging, since the software
framework required to support complex tasks must be robust to unreliable and
intermittent communication links. In this work, we present MOCHA (Multi-robot
Opportunistic Communication for Heterogeneous Collaboration), a framework for
resilient multi-robot collaboration that enables large-scale exploration in the
absence of continuous communications. MOCHA is based on a gossip communication
protocol that allows robots to interact opportunistically whenever
communication links are available, propagating information on a peer-to-peer
basis. We demonstrate the performance of MOCHA through real-world experiments
with commercial-off-the-shelf (COTS) communication hardware. We further explore
the system's scalability in simulation, evaluating the performance of our
approach as the number of robots increases and communication ranges vary.
Finally, we demonstrate how MOCHA can be tightly integrated with the planning
stack of autonomous robots. We show a communication-aware planning algorithm
for a high-altitude aerial robot executing a collaborative task while
maximizing the amount of information shared with ground robots. The source code
for MOCHA and the high-altitude UAV planning system is available open source:
<a href="http://github.com/KumarRobotics/MOCHA">this http URL</a>,
<a href="http://github.com/KumarRobotics/air_router.">this http URL</a>
</p>
</div>
</dd>
<dt><a name="item32">[32]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15977" title="Abstract">arXiv:2309.15977</a> [<a href="/pdf/2309.15977" title="Download PDF">pdf</a>, <a href="/format/2309.15977" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Neural Acoustic Context Field: Rendering Realistic Room Impulse Response  With Neural Fields
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liang%2C+S">Susan Liang</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+C">Chao Huang</a>, 
<a href="/search/cs?searchtype=author&query=Tian%2C+Y">Yapeng Tian</a>, 
<a href="/search/cs?searchtype=author&query=Kumar%2C+A">Anurag Kumar</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+C">Chenliang Xu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Computer Vision and Pattern Recognition (cs.CV); Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">Room impulse response (RIR), which measures the sound propagation within an
environment, is critical for synthesizing high-fidelity audio for a given
environment. Some prior work has proposed representing RIR as a neural field
function of the sound emitter and receiver positions. However, these methods do
not sufficiently consider the acoustic properties of an audio scene, leading to
unsatisfactory performance. This letter proposes a novel Neural Acoustic
Context Field approach, called NACF, to parameterize an audio scene by
leveraging multiple acoustic contexts, such as geometry, material property, and
spatial information. Driven by the unique properties of RIR, i.e., temporal
un-smoothness and monotonic energy attenuation, we design a temporal
correlation module and multi-scale energy decay criterion. Experimental results
show that NACF outperforms existing field-based methods by a notable margin.
Please visit our project page for more qualitative results.
</p>
</div>
</dd>
<dt><a name="item33">[33]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15978" title="Abstract">arXiv:2309.15978</a> [<a href="/pdf/2309.15978" title="Download PDF">pdf</a>, <a href="/format/2309.15978" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Assessment of Local Climate Zone Products via Simplified Classification  Rule with 3D Building Maps
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Song%2C+H">Hunsoo Song</a>, 
<a href="/search/cs?searchtype=author&query=Cervini%2C+G">Gaia Cervini</a>, 
<a href="/search/cs?searchtype=author&query=Jung%2C+J">Jinha Jung</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Atmospheric and Oceanic Physics (physics.ao-ph)

</div>
<p class="mathjax">This study assesses the performance of a global Local Climate Zone (LCZ)
product. We examined the built-type classes of LCZs in three major metropolitan
areas within the U.S. A reference LCZ was constructed using a simple rule-based
method based on high-resolution 3D building maps. Our evaluation demonstrated
that the global LCZ product struggles to differentiate classes that demand
precise building footprint information (Classes 6 and 9), and classes that
necessitate the identification of subtle differences in building elevation
(Classes 4-6). Additionally, we identified inconsistent tendencies, where the
distribution of classes skews differently across different cities, suggesting
the presence of a data distribution shift problem in the machine learning-based
LCZ classifier. Our findings shed light on the uncertainties in global LCZ
maps, help identify the LCZ classes that are the most challenging to
distinguish, and offer insight into future plans for LCZ development and
validation.
</p>
</div>
</dd>
<dt><a name="item34">[34]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15979" title="Abstract">arXiv:2309.15979</a> [<a href="/pdf/2309.15979" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Clinical Trial Recommendations Using Semantics-Based Inductive Inference  and Knowledge Graph Embeddings
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Devarakonda%2C+M+V">Murthy V. Devarakonda</a>, 
<a href="/search/cs?searchtype=author&query=Mohanty%2C+S">Smita Mohanty</a>, 
<a href="/search/cs?searchtype=author&query=Sunkishala%2C+R+R">Raja Rao Sunkishala</a>, 
<a href="/search/cs?searchtype=author&query=Mallampalli%2C+N">Nag Mallampalli</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xiong Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages (w/o bibliography), 4 Figures, 6 Tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Quantitative Methods (q-bio.QM)

</div>
<p class="mathjax">Designing a new clinical trial entails many decisions, such as defining a
cohort and setting the study objectives to name a few, and therefore can
benefit from recommendations based on exhaustive mining of past clinical trial
records. Here, we propose a novel recommendation methodology, based on neural
embeddings trained on a first-of-a-kind knowledge graph of clinical trials. We
addressed several important research questions in this context, including
designing a knowledge graph (KG) for clinical trial data, effectiveness of
various KG embedding (KGE) methods for it, a novel inductive inference using
KGE, and its use in generating recommendations for clinical trial design. We
used publicly available data from clinicaltrials.gov for the study. Results
show that our recommendations approach achieves relevance scores of 70%-83%,
measured as the text similarity to actual clinical trial elements, and the most
relevant recommendation can be found near the top of list. Our study also
suggests potential improvement in training KGE using node semantics.
</p>
</div>
</dd>
<dt><a name="item35">[35]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15985" title="Abstract">arXiv:2309.15985</a> [<a href="/pdf/2309.15985" title="Download PDF">pdf</a>, <a href="/format/2309.15985" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Open Source Infrastructure for Differentiable Density Functional Theory
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Vidhyadhiraja%2C+A">Advika Vidhyadhiraja</a>, 
<a href="/search/cs?searchtype=author&query=Thiagarajan%2C+A+P">Arun Pa Thiagarajan</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+S">Shang Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Viswanathan%2C+V">Venkat Viswanathan</a>, 
<a href="/search/cs?searchtype=author&query=Ramsundar%2C+B">Bharath Ramsundar</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Learning exchange correlation functionals, used in quantum chemistry
calculations, from data has become increasingly important in recent years, but
training such a functional requires sophisticated software infrastructure. For
this reason, we build open source infrastructure to train neural exchange
correlation functionals. We aim to standardize the processing pipeline by
adapting state-of-the-art techniques from work done by multiple groups. We have
open sourced the model in the DeepChem library to provide a platform for
additional research on differentiable quantum chemistry methods.
</p>
</div>
</dd>
<dt><a name="item36">[36]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15990" title="Abstract">arXiv:2309.15990</a> [<a href="/pdf/2309.15990" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Machine Learning Based Analytics for the Significance of Gait Analysis  in Monitoring and Managing Lower Extremity Injuries
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rezapour%2C+M">Mostafa Rezapour</a>, 
<a href="/search/cs?searchtype=author&query=Seymour%2C+R+B">Rachel B. Seymour</a>, 
<a href="/search/cs?searchtype=author&query=Sims%2C+S+H">Stephen H. Sims</a>, 
<a href="/search/cs?searchtype=author&query=Karunakar%2C+M+A">Madhav A. Karunakar</a>, 
<a href="/search/cs?searchtype=author&query=Habet%2C+N">Nahir Habet</a>, 
<a href="/search/cs?searchtype=author&query=Gurcan%2C+M+N">Metin Nafi Gurcan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, 6 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">This study explored the potential of gait analysis as a tool for assessing
post-injury complications, e.g., infection, malunion, or hardware irritation,
in patients with lower extremity fractures. The research focused on the
proficiency of supervised machine learning models predicting complications
using consecutive gait datasets. We identified patients with lower extremity
fractures at an academic center. Patients underwent gait analysis with a
chest-mounted IMU device. Using software, raw gait data was preprocessed,
emphasizing 12 essential gait variables. Machine learning models including
XGBoost, Logistic Regression, SVM, LightGBM, and Random Forest were trained,
tested, and evaluated. Attention was given to class imbalance, addressed using
SMOTE. We introduced a methodology to compute the Rate of Change (ROC) for gait
variables, independent of the time difference between gait analyses. XGBoost
was the optimal model both before and after applying SMOTE. Prior to SMOTE, the
model achieved an average test AUC of 0.90 (95% CI: [0.79, 1.00]) and test
accuracy of 86% (95% CI: [75%, 97%]). Feature importance analysis attributed
importance to the duration between injury and gait analysis. Data patterns
showed early physiological compensations, followed by stabilization phases,
emphasizing prompt gait analysis. This study underscores the potential of
machine learning, particularly XGBoost, in gait analysis for orthopedic care.
Predicting post-injury complications, early gait assessment becomes vital,
revealing intervention points. The findings support a shift in orthopedics
towards a data-informed approach, enhancing patient outcomes.
</p>
</div>
</dd>
<dt><a name="item37">[37]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15991" title="Abstract">arXiv:2309.15991</a> [<a href="/pdf/2309.15991" title="Download PDF">pdf</a>, <a href="/format/2309.15991" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Targeted Image Data Augmentation Increases Basic Skills Captioning  Robustness
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Barriere%2C+V">Valentin Barriere</a>, 
<a href="/search/cs?searchtype=author&query=del+Rio%2C+F">Felipe del Rio</a>, 
<a href="/search/cs?searchtype=author&query=De+Ferari%2C+A+C">Andres Carvallo De Ferari</a>, 
<a href="/search/cs?searchtype=author&query=Aspillaga%2C+C">Carlos Aspillaga</a>, 
<a href="/search/cs?searchtype=author&query=Herrera-Berg%2C+E">Eugenio Herrera-Berg</a>, 
<a href="/search/cs?searchtype=author&query=Calderon%2C+C+B">Cristian Buc Calderon</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Computation and Language (cs.CL)

</div>
<p class="mathjax">Artificial neural networks typically struggle in generalizing to
out-of-context examples. One reason for this limitation is caused by having
datasets that incorporate only partial information regarding the potential
correlational structure of the world. In this work, we propose TIDA (Targeted
Image-editing Data Augmentation), a targeted data augmentation method focused
on improving models' human-like abilities (e.g., gender recognition) by filling
the correlational structure gap using a text-to-image generative model. More
specifically, TIDA identifies specific skills in captions describing images
(e.g., the presence of a specific gender in the image), changes the caption
(e.g., "woman" to "man"), and then uses a text-to-image model to edit the image
in order to match the novel caption (e.g., uniquely changing a woman to a man
while maintaining the context identical). Based on the Flickr30K benchmark, we
show that, compared with the original data set, a TIDA-enhanced dataset related
to gender, color, and counting abilities induces better performance in several
image captioning metrics. Furthermore, on top of relying on the classical BLEU
metric, we conduct a fine-grained analysis of the improvements of our models
against the baseline in different ways. We compared text-to-image generative
models and found different behaviors of the image captioning models in terms of
encoding visual encoding and textual decoding.
</p>
</div>
</dd>
<dt><a name="item38">[38]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15995" title="Abstract">arXiv:2309.15995</a> [<a href="/pdf/2309.15995" title="Download PDF">pdf</a>, <a href="/format/2309.15995" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Digital Twin-based Anomaly Detection with Curriculum Learning in  Cyber-physical Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+Q">Qinghua Xu</a>, 
<a href="/search/cs?searchtype=author&query=Ali%2C+S">Shaukat Ali</a>, 
<a href="/search/cs?searchtype=author&query=Yue%2C+T">Tao Yue</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> ACM Trans. Softw. Eng. Methodol. 32, 5, Article 113 (July 2023),
  32 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Cryptography and Security (cs.CR); Software Engineering (cs.SE)

</div>
<p class="mathjax">Anomaly detection is critical to ensure the security of cyber-physical
systems (CPS). However, due to the increasing complexity of attacks and CPS
themselves, anomaly detection in CPS is becoming more and more challenging. In
our previous work, we proposed a digital twin-based anomaly detection method,
called ATTAIN, which takes advantage of both historical and real-time data of
CPS. However, such data vary significantly in terms of difficulty. Therefore,
similar to human learning processes, deep learning models (e.g., ATTAIN) can
benefit from an easy-to-difficult curriculum. To this end, in this paper, we
present a novel approach, named digitaL twin-based Anomaly deTecTion wIth
Curriculum lEarning (LATTICE), which extends ATTAIN by introducing curriculum
learning to optimize its learning paradigm. LATTICE attributes each sample with
a difficulty score, before being fed into a training scheduler. The training
scheduler samples batches of training data based on these difficulty scores
such that learning from easy to difficult data can be performed. To evaluate
LATTICE, we use five publicly available datasets collected from five real-world
CPS testbeds. We compare LATTICE with ATTAIN and two other state-of-the-art
anomaly detectors. Evaluation results show that LATTICE outperforms the three
baselines and ATTAIN by 0.906%-2.367% in terms of the F1 score. LATTICE also,
on average, reduces the training time of ATTAIN by 4.2% on the five datasets
and is on par with the baselines in terms of detection delay time.
</p>
</div>
</dd>
<dt><a name="item39">[39]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15996" title="Abstract">arXiv:2309.15996</a> [<a href="/pdf/2309.15996" title="Download PDF">pdf</a>, <a href="/format/2309.15996" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Loupe: Driving the Development of OS Compatibility Layers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lefeuvre%2C+H">Hugo Lefeuvre</a>, 
<a href="/search/cs?searchtype=author&query=Gain%2C+G">Gaulthier Gain</a>, 
<a href="/search/cs?searchtype=author&query=B%C4%83doiu%2C+V">Vlad-Andrei B&#x103;doiu</a>, 
<a href="/search/cs?searchtype=author&query=Dinca%2C+D">Daniel Dinca</a>, 
<a href="/search/cs?searchtype=author&query=Schiller%2C+V">Vlad-Radu Schiller</a>, 
<a href="/search/cs?searchtype=author&query=Raiciu%2C+C">Costin Raiciu</a>, 
<a href="/search/cs?searchtype=author&query=Huici%2C+F">Felipe Huici</a>, 
<a href="/search/cs?searchtype=author&query=Olivier%2C+P">Pierre Olivier</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to appear at ASPLOS'24 (<a href="https://www.asplos-conference.org/asplos2024/">this https URL</a>)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Operating Systems (cs.OS)</span>

</div>
<p class="mathjax">Supporting mainstream applications is fundamental for a new OS to have
impact. It is generally achieved by developing a layer of compatibility
allowing applications developed for a mainstream OS like Linux to run
unmodified on the new OS. Building such a layer, as we show, results in large
engineering inefficiencies due to the lack of efficient methods to precisely
measure the OS features required by a set of applications.
<br />We propose Loupe, a novel method based on dynamic analysis that determines
the OS features that need to be implemented in a prototype OS to bring support
for a target set of applications and workloads. Loupe guides and boosts OS
developers as they build compatibility layers, prioritizing which features to
implement in order to quickly support many applications as early as possible.
We apply our methodology to 100+ applications and several OSes currently under
development, demonstrating high engineering effort savings vs. existing
approaches: for example, for the 62 applications supported by the OSv kernel,
we show that using Loupe, would have required implementing only 37 system calls
vs. 92 for the non-systematic process followed by OSv developers.
<br />We study our measurements and extract novel key insights. Overall, we show
that the burden of building compatibility layers is significantly less than
what previous works suggest: in some cases, only as few as 20% of system calls
reported by static analysis, and 50% of those reported by naive dynamic
analysis need an implementation for an application to successfully run standard
benchmarks.
</p>
</div>
</dd>
<dt><a name="item40">[40]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16002" title="Abstract">arXiv:2309.16002</a> [<a href="/pdf/2309.16002" title="Download PDF">pdf</a>, <a href="/format/2309.16002" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Robust Blockwise Random Pivoting: Fast and Accurate Adaptive  Interpolative Decomposition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Dong%2C+Y">Yijun Dong</a>, 
<a href="/search/math?searchtype=author&query=Chen%2C+C">Chao Chen</a>, 
<a href="/search/math?searchtype=author&query=Martinsson%2C+P">Per-Gunnar Martinsson</a>, 
<a href="/search/math?searchtype=author&query=Pearce%2C+K">Katherine Pearce</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">The interpolative decomposition (ID) aims to construct a low-rank
approximation formed by a basis consisting of row/column skeletons in the
original matrix and a corresponding interpolation matrix. This work explores
fast and accurate ID algorithms from five essential perspectives for empirical
performance: (a) skeleton complexity that measures the minimum possible ID rank
for a given low-rank approximation error, (b) asymptotic complexity in FLOPs,
(c) parallelizability of the computational bottleneck as matrix-matrix
multiplications, (d) error-revealing property that enables automatic rank
detection for given error tolerances without prior knowledge of target ranks,
(e) ID-revealing property that ensures efficient construction of the optimal
interpolation matrix after selecting the skeletons. While a broad spectrum of
algorithms have been developed to optimize parts of the aforementioned
perspectives, practical ID algorithms proficient in all perspectives remain
absent. To fill in the gap, we introduce robust blockwise random pivoting
(RBRP) that is parallelizable, error-revealing, and exact-ID-revealing, with
comparable skeleton and asymptotic complexities to the best existing ID
algorithms in practice. Through extensive numerical experiments on various
synthetic and natural datasets, we empirically demonstrate the appealing
performance of RBRP from the five perspectives above, as well as the robustness
of RBRP to adversarial inputs.
</p>
</div>
</dd>
<dt><a name="item41">[41]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16014" title="Abstract">arXiv:2309.16014</a> [<a href="/pdf/2309.16014" title="Download PDF">pdf</a>, <a href="/format/2309.16014" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Graph-level Representation Learning with Joint-Embedding Predictive  Architectures
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Skenderi%2C+G">Geri Skenderi</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Hang Li</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+J">Jiliang Tang</a>, 
<a href="/search/cs?searchtype=author&query=Cristani%2C+M">Marco Cristani</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Preprint. Under Review
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Joint-Embedding Predictive Architectures (JEPAs) have recently emerged as a
novel and powerful technique for self-supervised representation learning. They
aim to learn an energy-based model by predicting the latent representation of a
target signal $y$ from a context signal $x$. JEPAs bypass the need for data
augmentation and negative samples, which are typically required by contrastive
learning, while avoiding the overfitting issues associated with
generative-based pretraining. In this paper, we show that graph-level
representations can be effectively modeled using this paradigm and propose
Graph-JEPA, the first JEPA for the graph domain. In particular, we employ
masked modeling to learn embeddings for different subgraphs of the input graph.
To endow the representations with the implicit hierarchy that is often present
in graph-level concepts, we devise an alternative training objective that
consists of predicting the coordinates of the encoded subgraphs on the unit
hyperbola in the 2D plane. Extensive validation shows that Graph-JEPA can learn
representations that are expressive and competitive in both graph
classification and regression problems.
</p>
</div>
</dd>
<dt><a name="item42">[42]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16019" title="Abstract">arXiv:2309.16019</a> [<a href="/pdf/2309.16019" title="Download PDF">pdf</a>, <a href="/format/2309.16019" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GasMono: Geometry-Aided Self-Supervised Monocular Depth Estimation for  Indoor Scenes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhao%2C+C">Chaoqiang Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Poggi%2C+M">Matteo Poggi</a>, 
<a href="/search/cs?searchtype=author&query=Tosi%2C+F">Fabio Tosi</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+L">Lei Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+Q">Qiyu Sun</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+Y">Yang Tang</a>, 
<a href="/search/cs?searchtype=author&query=Mattoccia%2C+S">Stefano Mattoccia</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ICCV 2023. Code: <a href="https://github.com/zxcqlf/GasMono">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">This paper tackles the challenges of self-supervised monocular depth
estimation in indoor scenes caused by large rotation between frames and low
texture. We ease the learning process by obtaining coarse camera poses from
monocular sequences through multi-view geometry to deal with the former.
However, we found that limited by the scale ambiguity across different scenes
in the training dataset, a na\"ive introduction of geometric coarse poses
cannot play a positive role in performance improvement, which is
counter-intuitive. To address this problem, we propose to refine those poses
during training through rotation and translation/scale optimization. To soften
the effect of the low texture, we combine the global reasoning of vision
transformers with an overfitting-aware, iterative self-distillation mechanism,
providing more accurate depth guidance coming from the network itself.
Experiments on NYUv2, ScanNet, 7scenes, and KITTI datasets support the
effectiveness of each component in our framework, which sets a new
state-of-the-art for indoor self-supervised monocular depth estimation, as well
as outstanding generalization ability. Code and models are available at
https://github.com/zxcqlf/GasMono
</p>
</div>
</dd>
<dt><a name="item43">[43]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16020" title="Abstract">arXiv:2309.16020</a> [<a href="/pdf/2309.16020" title="Download PDF">pdf</a>, <a href="/format/2309.16020" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GeoCLIP: Clip-Inspired Alignment between Locations and Images for  Effective Worldwide Geo-localization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cepeda%2C+V+V">Vicente Vivanco Cepeda</a>, 
<a href="/search/cs?searchtype=author&query=Nayak%2C+G+K">Gaurav Kumar Nayak</a>, 
<a href="/search/cs?searchtype=author&query=Shah%2C+M">Mubarak Shah</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Worldwide Geo-localization aims to pinpoint the precise location of images
taken anywhere on Earth. This task has considerable challenges due to immense
variation in geographic landscapes. The image-to-image retrieval-based
approaches fail to solve this problem on a global scale as it is not feasible
to construct a large gallery of images covering the entire world. Instead,
existing approaches divide the globe into discrete geographic cells,
transforming the problem into a classification task. However, their performance
is limited by the predefined classes and often results in inaccurate
localizations when an image's location significantly deviates from its class
center. To overcome these limitations, we propose GeoCLIP, a novel
CLIP-inspired Image-to-GPS retrieval approach that enforces alignment between
the image and its corresponding GPS locations. GeoCLIP's location encoder
models the Earth as a continuous function by employing positional encoding
through random Fourier features and constructing a hierarchical representation
that captures information at varying resolutions to yield a semantically rich
high-dimensional feature suitable to use even beyond geo-localization. To the
best of our knowledge, this is the first work employing GPS encoding for
geo-localization. We demonstrate the efficacy of our method via extensive
experiments and ablations on benchmark datasets. We achieve competitive
performance with just 20% of training data, highlighting its effectiveness even
in limited-data settings. Furthermore, we qualitatively demonstrate
geo-localization using a text query by leveraging CLIP backbone of our image
encoder.
</p>
</div>
</dd>
<dt><a name="item44">[44]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16021" title="Abstract">arXiv:2309.16021</a> [<a href="/pdf/2309.16021" title="Download PDF">pdf</a>, <a href="/format/2309.16021" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> HuntGPT: Integrating Machine Learning-Based Anomaly Detection and  Explainable AI with Large Language Models (LLMs)
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ali%2C+T">Tarek Ali</a>, 
<a href="/search/cs?searchtype=author&query=Kostakos%2C+P">Panos Kostakos</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">Machine learning (ML) is crucial in network anomaly detection for proactive
threat hunting, reducing detection and response times significantly. However,
challenges in model training, maintenance, and frequent false positives impact
its acceptance and reliability. Explainable AI (XAI) attempts to mitigate these
issues, allowing cybersecurity teams to assess AI-generated alerts with
confidence, but has seen limited acceptance from incident responders. Large
Language Models (LLMs) present a solution through discerning patterns in
extensive information and adapting to different functional requirements. We
present HuntGPT, a specialized intrusion detection dashboard applying a Random
Forest classifier using the KDD99 dataset, integrating XAI frameworks like SHAP
and Lime for user-friendly and intuitive model interaction, and combined with a
GPT-3.5 Turbo, it delivers threats in an understandable format. The paper
delves into the system's architecture, components, and technical accuracy,
assessed through Certified Information Security Manager (CISM) Practice Exams,
evaluating response quality across six metrics. The results demonstrate that
conversational agents, supported by LLM and integrated with XAI, provide
robust, explainable, and actionable AI solutions in intrusion detection,
enhancing user understanding and interactive experience.
</p>
</div>
</dd>
<dt><a name="item45">[45]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16022" title="Abstract">arXiv:2309.16022</a> [<a href="/pdf/2309.16022" title="Download PDF">pdf</a>, <a href="/format/2309.16022" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GNNHLS: Evaluating Graph Neural Network Inference via High-Level  Synthesis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhao%2C+C">Chenfeng Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+Z">Zehao Dong</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yixin Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xuan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Chamberlain%2C+R+D">Roger D. Chamberlain</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Hardware Architecture (cs.AR); Performance (cs.PF)

</div>
<p class="mathjax">With the ever-growing popularity of Graph Neural Networks (GNNs), efficient
GNN inference is gaining tremendous attention. Field-Programming Gate Arrays
(FPGAs) are a promising execution platform due to their fine-grained
parallelism, low-power consumption, reconfigurability, and concurrent
execution. Even better, High-Level Synthesis (HLS) tools bridge the gap between
the non-trivial FPGA development efforts and rapid emergence of new GNN models.
In this paper, we propose GNNHLS, an open-source framework to comprehensively
evaluate GNN inference acceleration on FPGAs via HLS, containing a software
stack for data generation and baseline deployment, and FPGA implementations of
6 well-tuned GNN HLS kernels. We evaluate GNNHLS on 4 graph datasets with
distinct topologies and scales. The results show that GNNHLS achieves up to
50.8x speedup and 423x energy reduction relative to the CPU baselines. Compared
with the GPU baselines, GNNHLS achieves up to 5.16x speedup and 74.5x energy
reduction.
</p>
</div>
</dd>
<dt><a name="item46">[46]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16023" title="Abstract">arXiv:2309.16023</a> [<a href="/pdf/2309.16023" title="Download PDF">pdf</a>, <a href="/format/2309.16023" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Q-REG: End-to-End Trainable Point Cloud Registration with Surface  Curvature
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jin%2C+S">Shengze Jin</a>, 
<a href="/search/cs?searchtype=author&query=Barath%2C+D">Daniel Barath</a>, 
<a href="/search/cs?searchtype=author&query=Pollefeys%2C+M">Marc Pollefeys</a>, 
<a href="/search/cs?searchtype=author&query=Armeni%2C+I">Iro Armeni</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Point cloud registration has seen recent success with several learning-based
methods that focus on correspondence matching and, as such, optimize only for
this objective. Following the learning step of correspondence matching, they
evaluate the estimated rigid transformation with a RANSAC-like framework. While
it is an indispensable component of these methods, it prevents a fully
end-to-end training, leaving the objective to minimize the pose error
nonserved. We present a novel solution, Q-REG, which utilizes rich geometric
information to estimate the rigid pose from a single correspondence. Q-REG
allows to formalize the robust estimation as an exhaustive search, hence
enabling end-to-end training that optimizes over both objectives of
correspondence matching and rigid pose estimation. We demonstrate in the
experiments that Q-REG is agnostic to the correspondence matching method and
provides consistent improvement both when used only in inference and in
end-to-end training. It sets a new state-of-the-art on the 3DMatch, KITTI, and
ModelNet benchmarks.
</p>
</div>
</dd>
<dt><a name="item47">[47]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16024" title="Abstract">arXiv:2309.16024</a> [<a href="/pdf/2309.16024" title="Download PDF">pdf</a>, <a href="/format/2309.16024" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Model Predictive Planning: Towards Real-Time Multi-Trajectory Planning  Around Obstacles
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Wallace%2C+M+T">Matthew T. Wallace</a>, 
<a href="/search/eess?searchtype=author&query=Streetman%2C+B">Brett Streetman</a>, 
<a href="/search/eess?searchtype=author&query=Lessard%2C+L">Laurent Lessard</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Robotics (cs.RO)

</div>
<p class="mathjax">This paper presents a motion planning scheme we call Model Predictive
Planning (MPP), designed to optimize trajectories through obstacle-laden
environments. The approach involves path planning, trajectory refinement
through the solution of a quadratic program, and real-time selection of optimal
trajectories. The paper highlights three technical innovations: a
raytracing-based path-to-trajectory refinement, the integration of this
technique with a multi-path planner to overcome difficulties due to local
minima, and a method to achieve timescale separation in trajectory
optimization. The scheme is demonstrated through simulations on a 2D
longitudinal aircraft model and shows strong obstacle avoidance performance.
</p>
</div>
</dd>
<dt><a name="item48">[48]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16025" title="Abstract">arXiv:2309.16025</a> [<a href="/pdf/2309.16025" title="Download PDF">pdf</a>, <a href="/format/2309.16025" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Symbolic Imitation Learning: From Black-Box to Explainable Driving  Policies
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sharifi%2C+I">Iman Sharifi</a>, 
<a href="/search/cs?searchtype=author&query=Fallah%2C+S">Saber Fallah</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 2 figures, 2 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Robotics (cs.RO)

</div>
<p class="mathjax">Current methods of imitation learning (IL), primarily based on deep neural
networks, offer efficient means for obtaining driving policies from real-world
data but suffer from significant limitations in interpretability and
generalizability. These shortcomings are particularly concerning in
safety-critical applications like autonomous driving. In this paper, we address
these limitations by introducing Symbolic Imitation Learning (SIL), a
groundbreaking method that employs Inductive Logic Programming (ILP) to learn
driving policies which are transparent, explainable and generalisable from
available datasets. Utilizing the real-world highD dataset, we subject our
method to a rigorous comparative analysis against prevailing
neural-network-based IL methods. Our results demonstrate that SIL not only
enhances the interpretability of driving policies but also significantly
improves their applicability across varied driving situations. Hence, this work
offers a novel pathway to more reliable and safer autonomous driving systems,
underscoring the potential of integrating ILP into the domain of IL.
</p>
</div>
</dd>
<dt><a name="item49">[49]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16026" title="Abstract">arXiv:2309.16026</a> [<a href="/pdf/2309.16026" title="Download PDF">pdf</a>, <a href="/format/2309.16026" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Statistical CSI Based Beamforming for Reconfigurable Intelligent Surface  Aided MISO Systems with Channel Correlation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Haochen Li</a>, 
<a href="/search/cs?searchtype=author&query=Pan%2C+Z">Zhiwen Pan</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+B">Bin Wang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+N">Nan Liu</a>, 
<a href="/search/cs?searchtype=author&query=You%2C+X">Xiaohu You</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 9 figures,
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">Reconfigurable intelligent surface (RIS) is a promising candidate technology
of the upcoming Sixth Generation (6G) communication system for its ability to
provide unprecedented spectral and energy efficiency increment through passive
beamforming. However, it is challenging to obtain instantaneous channel state
information (I-CSI) for RIS, which obliges us to use statistical channel state
information (S-CSI) to achieve passive beamforming. In this paper, RIS-aided
multiple-input single-output (MISO) multi-user downlink communication system
with correlated channels is investigated. Then, we formulate the problem of
joint beamforming design at the AP and RIS to maximize the sum ergodic spectral
efficiency (ESE) of all users to improve the network capacity. Since it is too
hard to compute sum ESE, an ESE approximation is adopted to reformulate the
problem into a more tractable form. Then, we present two joint beamforming
algorithms, namely the singular value decomposition-gradient descent (SVD-GD)
algorithm and the fractional programming-gradient descent (FP-GD) algorithm.
Simulation results show the effectiveness of our proposed algorithms and
validate that 2-bits quantizer is enough for RIS phase shifts implementation.
</p>
</div>
</dd>
<dt><a name="item50">[50]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16027" title="Abstract">arXiv:2309.16027</a> [<a href="/pdf/2309.16027" title="Download PDF">pdf</a>, <a href="/format/2309.16027" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Bridging the complexity gap in Tbps-achieving THz-band baseband  processing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sarieddeen%2C+H">Hadi Sarieddeen</a>, 
<a href="/search/cs?searchtype=author&query=Jemaa%2C+H">Hakim Jemaa</a>, 
<a href="/search/cs?searchtype=author&query=Tarboush%2C+S">Simon Tarboush</a>, 
<a href="/search/cs?searchtype=author&query=Studer%2C+C">Christoph Studer</a>, 
<a href="/search/cs?searchtype=author&query=Alouini%2C+M">Mohamed-Slim Alouini</a>, 
<a href="/search/cs?searchtype=author&query=Al-Naffouri%2C+T+Y">Tareq Y. Al-Naffouri</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">Recent advances in electronic and photonic technologies have allowed
efficient signal generation and transmission at terahertz (THz) frequencies.
However, as the gap in THz-operating devices narrows, the demand for
terabit-per-second (Tbps)-achieving circuits is increasing. Translating the
available hundreds of gigahertz (GHz) of bandwidth into a Tbps data rate
requires processing thousands of information bits per clock cycle at
state-of-the-art clock frequencies of digital baseband processing circuitry of
a few GHz. This paper addresses these constraints and emphasizes the importance
of parallelization in signal processing, particularly for channel code
decoding. By leveraging structured sub-spaces of THz channels, we propose
mapping bits to transmission resources using shorter code words, extending
parallelizability across all baseband processing blocks. THz channels exhibit
quasi-deterministic frequency, time, and space structures that enable efficient
parallel bit mapping at the source and provide pseudo-soft bit reliability
information for efficient detection and decoding at the receiver.
</p>
</div>
</dd>
<dt><a name="item51">[51]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16029" title="Abstract">arXiv:2309.16029</a> [<a href="/pdf/2309.16029" title="Download PDF">pdf</a>, <a href="/format/2309.16029" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Channel Estimation for Reconfigurable Intelligent Surface-Aided  Multiuser Communication Systems Exploiting Statistical CSI of Correlated  RIS-User Channels
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Haochen Li</a>, 
<a href="/search/cs?searchtype=author&query=Pan%2C+Z">Zhiwen Pan</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+B">Bin Wang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+N">Nan Liu</a>, 
<a href="/search/cs?searchtype=author&query=You%2C+X">Xiaohu You</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 11 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">Reconfigurable intelligent surface (RIS) is a promising candidate technology
for the upcoming Sixth Generation (6G) communication system for its ability to
manipulate the wireless communication environment by controlling the
coefficients of reflection elements (REs). However, since the RIS usually
consists of a large number of passive REs, the pilot overhead for channel
estimation in the RIS-aided system is prohibitively high. In this paper, the
channel estimation problem for a RIS-aided multi-user
multiple-input-single-output (MISO) communication system with clustered users
is investigated. First, to describe the correlated feature for RIS-user
channels, a beam domain channel model is developed for RIS-user channels. Then,
a pilot reuse strategy is put forward to reduce the pilot overhead and
decompose the channel estimation problem into several subproblems. Finally, by
leveraging the correlated nature of RIS-user channels, an eigenspace projection
(EP) algorithm is proposed to solve each subproblem respectively. Simulation
results show that the proposed EP channel estimation scheme can achieve
accurate channel estimation with lower pilot overhead than existing schemes.
</p>
</div>
</dd>
<dt><a name="item52">[52]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16031" title="Abstract">arXiv:2309.16031</a> [<a href="/pdf/2309.16031" title="Download PDF">pdf</a>, <a href="/format/2309.16031" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DynaCon: Dynamic Robot Planner with Contextual Awareness via LLMs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kim%2C+G">Gyeongmin Kim</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+T">Taehyeon Kim</a>, 
<a href="/search/cs?searchtype=author&query=Kannan%2C+S+S">Shyam Sundar Kannan</a>, 
<a href="/search/cs?searchtype=author&query=Venkatesh%2C+V+L+N">Vishnunandan L. N. Venkatesh</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+D">Donghan Kim</a>, 
<a href="/search/cs?searchtype=author&query=Min%2C+B">Byung-Cheol Min</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to ICRA 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Mobile robots often rely on pre-existing maps for effective path planning and
navigation. However, when these maps are unavailable, particularly in
unfamiliar environments, a different approach become essential. This paper
introduces DynaCon, a novel system designed to provide mobile robots with
contextual awareness and dynamic adaptability during navigation, eliminating
the reliance of traditional maps. DynaCon integrates real-time feedback with an
object server, prompt engineering, and navigation modules. By harnessing the
capabilities of Large Language Models (LLMs), DynaCon not only understands
patterns within given numeric series but also excels at categorizing objects
into matched spaces. This facilitates dynamic path planner imbued with
contextual awareness. We validated the effectiveness of DynaCon through an
experiment where a robot successfully navigated to its goal using reasoning.
Source code and experiment videos for this work can be found at:
https://sites.google.com/view/dynacon.
</p>
</div>
</dd>
<dt><a name="item53">[53]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16032" title="Abstract">arXiv:2309.16032</a> [<a href="/pdf/2309.16032" title="Download PDF">pdf</a>, <a href="/ps/2309.16032" title="Download PostScript">ps</a>, <a href="/format/2309.16032" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning Dissipative Neural Dynamical Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+Y">Yuezhu Xu</a>, 
<a href="/search/cs?searchtype=author&query=Sivaranjani%2C+S">S. Sivaranjani</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Systems and Control (eess.SY); Optimization and Control (math.OC)

</div>
<p class="mathjax">Consider an unknown nonlinear dynamical system that is known to be
dissipative. The objective of this paper is to learn a neural dynamical model
that approximates this system, while preserving the dissipativity property in
the model. In general, imposing dissipativity constraints during neural network
training is a hard problem for which no known techniques exist. In this work,
we address the problem of learning a dissipative neural dynamical system model
in two stages. First, we learn an unconstrained neural dynamical model that
closely approximates the system dynamics. Next, we derive sufficient conditions
to perturb the weights of the neural dynamical model to ensure dissipativity,
followed by perturbation of the biases to retain the fit of the model to the
trajectories of the nonlinear system. We show that these two perturbation
problems can be solved independently to obtain a neural dynamical model that is
guaranteed to be dissipative while closely approximating the nonlinear system.
</p>
</div>
</dd>
<dt><a name="item54">[54]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16034" title="Abstract">arXiv:2309.16034</a> [<a href="/pdf/2309.16034" title="Download PDF">pdf</a>, <a href="/format/2309.16034" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Analytical Modelling of Raw Data for Flow-Guided In-body Nanoscale  Localization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pascual%2C+G">Guillem Pascual</a>, 
<a href="/search/cs?searchtype=author&query=Lemic%2C+F">Filip Lemic</a>, 
<a href="/search/cs?searchtype=author&query=Delgado%2C+C">Carmen Delgado</a>, 
<a href="/search/cs?searchtype=author&query=Costa-Perez%2C+X">Xavier Costa-Perez</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages, 7 figures, 4 tables, 16 references
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Emerging Technologies (cs.ET)</span>; Information Retrieval (cs.IR); Machine Learning (cs.LG); Networking and Internet Architecture (cs.NI); Signal Processing (eess.SP)

</div>
<p class="mathjax">Advancements in nanotechnology and material science are paving the way toward
nanoscale devices that combine sensing, computing, data and energy storage, and
wireless communication. In precision medicine, these nanodevices show promise
for disease diagnostics, treatment, and monitoring from within the patients'
bloodstreams. Assigning the location of a sensed biological event with the
event itself, which is the main proposition of flow-guided in-body nanoscale
localization, would be immensely beneficial from the perspective of precision
medicine. The nanoscale nature of the nanodevices and the challenging
environment that the bloodstream represents, result in current flow-guided
localization approaches being constrained in their communication and
energy-related capabilities. The communication and energy constraints of the
nanodevices result in different features of raw data for flow-guided
localization, in turn affecting its performance. An analytical modeling of the
effects of imperfect communication and constrained energy causing intermittent
operation of the nanodevices on the raw data produced by the nanodevices would
be beneficial. Hence, we propose an analytical model of raw data for
flow-guided localization, where the raw data is modeled as a function of
communication and energy-related capabilities of the nanodevice. We evaluate
the model by comparing its output with the one obtained through the utilization
of a simulator for objective evaluation of flow-guided localization, featuring
comparably higher level of realism. Our results across a number of scenarios
and heterogeneous performance metrics indicate high similarity between the
model and simulator-generated raw datasets.
</p>
</div>
</dd>
<dt><a name="item55">[55]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16035" title="Abstract">arXiv:2309.16035</a> [<a href="/pdf/2309.16035" title="Download PDF">pdf</a>, <a href="/format/2309.16035" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MedEdit: Model Editing for Medical Question Answering with External  Knowledge Bases
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shi%2C+Y">Yucheng Shi</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+S">Shaochen Xu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zhengliang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+T">Tianming Liu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xiang Li</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+N">Ninghao Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Large Language Models (LLMs), although powerful in general domains, often
perform poorly on domain-specific tasks like medical question answering (QA).
Moreover, they tend to function as "black-boxes," making it challenging to
modify their behavior. Addressing this, our study delves into model editing
utilizing in-context learning, aiming to improve LLM responses without the need
for fine-tuning or retraining. Specifically, we propose a comprehensive
retrieval strategy to extract medical facts from an external knowledge base,
and then we incorporate them into the query prompt for the LLM. Focusing on
medical QA using the MedQA-SMILE dataset, we evaluate the impact of different
retrieval models and the number of facts provided to the LLM. Notably, our
edited Vicuna model exhibited an accuracy improvement from 44.46% to 48.54%.
This work underscores the potential of model editing to enhance LLM
performance, offering a practical approach to mitigate the challenges of
black-box LLMs.
</p>
</div>
</dd>
<dt><a name="item56">[56]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16039" title="Abstract">arXiv:2309.16039</a> [<a href="/pdf/2309.16039" title="Download PDF">pdf</a>, <a href="/format/2309.16039" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Effective Long-Context Scaling of Foundation Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xiong%2C+W">Wenhan Xiong</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jingyu Liu</a>, 
<a href="/search/cs?searchtype=author&query=Molybog%2C+I">Igor Molybog</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Hejia Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Bhargava%2C+P">Prajjwal Bhargava</a>, 
<a href="/search/cs?searchtype=author&query=Hou%2C+R">Rui Hou</a>, 
<a href="/search/cs?searchtype=author&query=Martin%2C+L">Louis Martin</a>, 
<a href="/search/cs?searchtype=author&query=Rungta%2C+R">Rashi Rungta</a>, 
<a href="/search/cs?searchtype=author&query=Sankararaman%2C+K+A">Karthik Abinav Sankararaman</a>, 
<a href="/search/cs?searchtype=author&query=Oguz%2C+B">Barlas Oguz</a>, 
<a href="/search/cs?searchtype=author&query=Khabsa%2C+M">Madian Khabsa</a>, 
<a href="/search/cs?searchtype=author&query=Fang%2C+H">Han Fang</a>, 
<a href="/search/cs?searchtype=author&query=Mehdad%2C+Y">Yashar Mehdad</a>, 
<a href="/search/cs?searchtype=author&query=Narang%2C+S">Sharan Narang</a>, 
<a href="/search/cs?searchtype=author&query=Malik%2C+K">Kshitiz Malik</a>, 
<a href="/search/cs?searchtype=author&query=Fan%2C+A">Angela Fan</a>, 
<a href="/search/cs?searchtype=author&query=Bhosale%2C+S">Shruti Bhosale</a>, 
<a href="/search/cs?searchtype=author&query=Edunov%2C+S">Sergey Edunov</a>, 
<a href="/search/cs?searchtype=author&query=Lewis%2C+M">Mike Lewis</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Sinong Wang</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+H">Hao Ma</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">We present a series of long-context LLMs that support effective context
windows of up to 32,768 tokens. Our model series are built through continual
pretraining from Llama 2 with longer training sequences and on a dataset where
long texts are upsampled. We perform extensive evaluation on language modeling,
synthetic context probing tasks, and a wide range of research benchmarks. On
research benchmarks, our models achieve consistent improvements on most regular
tasks and significant improvements on long-context tasks over Llama 2. Notably,
with a cost-effective instruction tuning procedure that does not require
human-annotated long instruction data, the 70B variant can already surpass
gpt-3.5-turbo-16k's overall performance on a suite of long-context tasks.
Alongside these results, we provide an in-depth analysis on the individual
components of our method. We delve into Llama's position encodings and discuss
its limitation in modeling long dependencies. We also examine the impact of
various design choices in the pretraining process, including the data mix and
the training curriculum of sequence lengths -- our ablation experiments suggest
that having abundant long texts in the pretrain dataset is not the key to
achieving strong performance, and we empirically verify that long context
continual pretraining is more efficient and similarly effective compared to
pretraining from scratch with long sequences.
</p>
</div>
</dd>
<dt><a name="item57">[57]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16040" title="Abstract">arXiv:2309.16040</a> [<a href="/pdf/2309.16040" title="Download PDF">pdf</a>, <a href="/format/2309.16040" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Handbook on Leveraging Lines for Two-View Relative Pose Estimation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hruby%2C+P">Petr Hruby</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+S">Shaohui Liu</a>, 
<a href="/search/cs?searchtype=author&query=Pautrat%2C+R">R&#xe9;mi Pautrat</a>, 
<a href="/search/cs?searchtype=author&query=Pollefeys%2C+M">Marc Pollefeys</a>, 
<a href="/search/cs?searchtype=author&query=Barath%2C+D">Daniel Barath</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 2 view relative pose from special configurations of line
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">We propose an approach for estimating the relative pose between calibrated
image pairs by jointly exploiting points, lines, and their coincidences in a
hybrid manner. We investigate all possible configurations where these data
modalities can be used together and review the minimal solvers available in the
literature. Our hybrid framework combines the advantages of all configurations,
enabling robust and accurate estimation in challenging environments. In
addition, we design a method for jointly estimating multiple vanishing point
correspondences in two images, and a bundle adjustment that considers all
relevant data modalities. Experiments on various indoor and outdoor datasets
show that our approach outperforms point-based methods, improving
AUC@10$^\circ$ by 1-7 points while running at comparable speeds. The source
code of the solvers and hybrid framework will be made public.
</p>
</div>
</dd>
<dt><a name="item58">[58]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16042" title="Abstract">arXiv:2309.16042</a> [<a href="/pdf/2309.16042" title="Download PDF">pdf</a>, <a href="/format/2309.16042" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Best Practices of Activation Patching in Language Models:  Metrics and Methods
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+F">Fred Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Nanda%2C+N">Neel Nanda</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 27 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL)

</div>
<p class="mathjax">Mechanistic interpretability seeks to understand the internal mechanisms of
machine learning models, where localization -- identifying the important model
components -- is a key step. Activation patching, also known as causal tracing
or interchange intervention, is a standard technique for this task (Vig et al.,
2020), but the literature contains many variants with little consensus on the
choice of hyperparameters or methodology. In this work, we systematically
examine the impact of methodological details in activation patching, including
evaluation metrics and corruption methods. In several settings of localization
and circuit discovery in language models, we find that varying these
hyperparameters could lead to disparate interpretability results. Backed by
empirical observations, we give conceptual arguments for why certain metrics or
methods may be preferred. Finally, we provide recommendations for the best
practices of activation patching going forwards.
</p>
</div>
</dd>
<dt><a name="item59">[59]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16044" title="Abstract">arXiv:2309.16044</a> [<a href="/pdf/2309.16044" title="Download PDF">pdf</a>, <a href="/ps/2309.16044" title="Download PostScript">ps</a>, <a href="/format/2309.16044" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Improving Adaptive Online Learning Using Refined Discretization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zhiyu Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+H">Heng Yang</a>, 
<a href="/search/cs?searchtype=author&query=Cutkosky%2C+A">Ashok Cutkosky</a>, 
<a href="/search/cs?searchtype=author&query=Paschalidis%2C+I+C">Ioannis Ch. Paschalidis</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
<p class="mathjax">We study unconstrained Online Linear Optimization with Lipschitz losses. The
goal is to simultaneously achieve ($i$) second order gradient adaptivity; and
($ii$) comparator norm adaptivity also known as "parameter freeness" in the
literature. Existing regret bounds (Cutkosky and Orabona, 2018; Mhammedi and
Koolen, 2020; Jacobsen and Cutkosky, 2022) have the suboptimal $O(\sqrt{V_T\log
V_T})$ dependence on the gradient variance $V_T$, while the present work
improves it to the optimal rate $O(\sqrt{V_T})$ using a novel
continuous-time-inspired algorithm, without any impractical doubling trick.
This result can be extended to the setting with unknown Lipschitz constant,
eliminating the range ratio problem from prior works (Mhammedi and Koolen,
2020).
<br />Concretely, we first show that the aimed simultaneous adaptivity can be
achieved fairly easily in a continuous time analogue of the problem, where the
environment is modeled by an arbitrary continuous semimartingale. Then, our key
innovation is a new discretization argument that preserves such adaptivity in
the discrete time adversarial setting. This refines a non-gradient-adaptive
discretization argument from (Harvey et al., 2023), both algorithmically and
analytically, which could be of independent interest.
</p>
</div>
</dd>
<dt><a name="item60">[60]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16045" title="Abstract">arXiv:2309.16045</a> [<a href="/pdf/2309.16045" title="Download PDF">pdf</a>, <a href="/format/2309.16045" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Minimum Monotone Tree Decomposition of Density Functions Defined on  Graphs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Magee%2C+L">Lucas Magee</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yusu Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>; Computational Complexity (cs.CC); Computational Geometry (cs.CG)

</div>
<p class="mathjax">Monotone trees - trees with a function defined on their vertices that
decreases the further away from a root node one travels, are a natural model
for a process that weakens the further one gets from its source. Given an
aggregation of monotone trees, one may wish to reconstruct the individual
monotone components. A natural representation of such an aggregation would be a
graph. While many methods have been developed for extracting hidden graph
structure from datasets, which makes obtaining such an aggregation possible,
decomposing such graphs into the original monotone trees is algorithmically
challenging.
<br />Recently, a polynomial time algorithm has been developed to extract a minimum
cardinality collection of monotone trees (M-Tree Set) from a given density tree
- but no such algorithm exists for density graphs that may contain cycles. In
this work, we prove that extracting such minimum M-Tree Sets of density graphs
is NP-Complete. We additionally prove three additional variations of the
problem - such as the minimum M-Tree Set such that the intersection between any
two monotone trees is either empty or contractible (SM-Tree Set) - are also
NP-Complete. We conclude by providing some approximation algorithms,
highlighted by a 3-approximation algorithm for computing the minimum SM-Tree
Set for density cactus graphs.
</p>
</div>
</dd>
<dt><a name="item61">[61]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16052" title="Abstract">arXiv:2309.16052</a> [<a href="/pdf/2309.16052" title="Download PDF">pdf</a>, <a href="/format/2309.16052" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> OceanChat: Piloting Autonomous Underwater Vehicles in Natural Language
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+R">Ruochu Yang</a>, 
<a href="/search/cs?searchtype=author&query=Hou%2C+M">Mengxue Hou</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Junkai Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+F">Fumin Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">In the trending research of fusing Large Language Models (LLMs) and robotics,
we aim to pave the way for innovative development of AI systems that can enable
Autonomous Underwater Vehicles (AUVs) to seamlessly interact with humans in an
intuitive manner. We propose OceanChat, a system that leverages a closed-loop
LLM-guided task and motion planning framework to tackle AUV missions in the
wild. LLMs translate an abstract human command into a high-level goal, while a
task planner further grounds the goal into a task sequence with logical
constraints. To assist the AUV with understanding the task sequence, we utilize
a motion planner to incorporate real-time Lagrangian data streams received by
the AUV, thus mapping the task sequence into an executable motion plan.
Considering the highly dynamic and partially known nature of the underwater
environment, an event-triggered replanning scheme is developed to enhance the
system's robustness towards uncertainty. We also build a simulation platform
HoloEco that generates photo-realistic simulation for a wide range of AUV
applications. Experimental evaluation verifies that the proposed system can
achieve improved performance in terms of both success rate and computation
time. Project website: \url{https://sites.google.com/view/oceanchat}
</p>
</div>
</dd>
<dt><a name="item62">[62]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16055" title="Abstract">arXiv:2309.16055</a> [<a href="/pdf/2309.16055" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Identifying Risk Factors for Post-COVID-19 Mental Health Disorders: A  Machine Learning Perspective
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yousif%2C+M+G">Maitham G. Yousif</a>, 
<a href="/search/cs?searchtype=author&query=Al-Amran%2C+F+G">Fadhil G. Al-Amran</a>, 
<a href="/search/cs?searchtype=author&query=Castro%2C+H+J">Hector J. Castro</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computers and Society (cs.CY); Biomolecules (q-bio.BM)

</div>
<p class="mathjax">In this study, we leveraged machine learning techniques to identify risk
factors associated with post-COVID-19 mental health disorders. Our analysis,
based on data collected from 669 patients across various provinces in Iraq,
yielded valuable insights. We found that age, gender, and geographical region
of residence were significant demographic factors influencing the likelihood of
developing mental health disorders in post-COVID-19 patients. Additionally,
comorbidities and the severity of COVID-19 illness were important clinical
predictors. Psychosocial factors, such as social support, coping strategies,
and perceived stress levels, also played a substantial role. Our findings
emphasize the complex interplay of multiple factors in the development of
mental health disorders following COVID-19 recovery. Healthcare providers and
policymakers should consider these risk factors when designing targeted
interventions and support systems for individuals at risk. Machine
learning-based approaches can provide a valuable tool for predicting and
preventing adverse mental health outcomes in post-COVID-19 patients. Further
research and prospective studies are needed to validate these findings and
enhance our understanding of the long-term psychological impact of the COVID-19
pandemic. This study contributes to the growing body of knowledge regarding the
mental health consequences of the COVID-19 pandemic and underscores the
importance of a multidisciplinary approach to address the diverse needs of
individuals on the path to recovery. Keywords: COVID-19, mental health, risk
factors, machine learning, Iraq
</p>
</div>
</dd>
<dt><a name="item63">[63]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16057" title="Abstract">arXiv:2309.16057</a> [<a href="/pdf/2309.16057" title="Download PDF">pdf</a>, <a href="/format/2309.16057" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> WiDEVIEW: An UltraWideBand and Vision Dataset for Deciphering  Pedestrian-Vehicle Interactions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+J">Jia Huang</a>, 
<a href="/search/cs?searchtype=author&query=Gautam%2C+A">Alvika Gautam</a>, 
<a href="/search/cs?searchtype=author&query=Choi%2C+J">Junghun Choi</a>, 
<a href="/search/cs?searchtype=author&query=Saripalli%2C+S">Srikanth Saripalli</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Robust and accurate tracking and localization of road users like pedestrians
and cyclists is crucial to ensure safe and effective navigation of Autonomous
Vehicles (AVs), particularly so in urban driving scenarios with complex
vehicle-pedestrian interactions. Existing datasets that are useful to
investigate vehicle-pedestrian interactions are mostly image-centric and thus
vulnerable to vision failures. In this paper, we investigate Ultra-wideband
(UWB) as an additional modality for road users' localization to enable a better
understanding of vehicle-pedestrian interactions. We present WiDEVIEW, the
first multimodal dataset that integrates LiDAR, three RGB cameras, GPS/IMU, and
UWB sensors for capturing vehicle-pedestrian interactions in an urban
autonomous driving scenario. Ground truth image annotations are provided in the
form of 2D bounding boxes and the dataset is evaluated on standard 2D object
detection and tracking algorithms. The feasibility of UWB is evaluated for
typical traffic scenarios in both line-of-sight and non-line-of-sight
conditions using LiDAR as ground truth. We establish that UWB range data has
comparable accuracy with LiDAR with an error of 0.19 meters and reliable
anchor-tag range data for up to 40 meters in line-of-sight conditions. UWB
performance for non-line-of-sight conditions is subjective to the nature of the
obstruction (trees vs. buildings). Further, we provide a qualitative analysis
of UWB performance for scenarios susceptible to intermittent vision failures.
The dataset can be downloaded via https://github.com/unmannedlab/UWB_Dataset.
</p>
</div>
</dd>
<dt><a name="item64">[64]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16058" title="Abstract">arXiv:2309.16058</a> [<a href="/pdf/2309.16058" title="Download PDF">pdf</a>, <a href="/format/2309.16058" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AnyMAL: An Efficient and Scalable Any-Modality Augmented Language Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Moon%2C+S">Seungwhan Moon</a>, 
<a href="/search/cs?searchtype=author&query=Madotto%2C+A">Andrea Madotto</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+Z">Zhaojiang Lin</a>, 
<a href="/search/cs?searchtype=author&query=Nagarajan%2C+T">Tushar Nagarajan</a>, 
<a href="/search/cs?searchtype=author&query=Smith%2C+M">Matt Smith</a>, 
<a href="/search/cs?searchtype=author&query=Jain%2C+S">Shashank Jain</a>, 
<a href="/search/cs?searchtype=author&query=Yeh%2C+C">Chun-Fu Yeh</a>, 
<a href="/search/cs?searchtype=author&query=Murugesan%2C+P">Prakash Murugesan</a>, 
<a href="/search/cs?searchtype=author&query=Heidari%2C+P">Peyman Heidari</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yue Liu</a>, 
<a href="/search/cs?searchtype=author&query=Srinet%2C+K">Kavya Srinet</a>, 
<a href="/search/cs?searchtype=author&query=Damavandi%2C+B">Babak Damavandi</a>, 
<a href="/search/cs?searchtype=author&query=Kumar%2C+A">Anuj Kumar</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computation and Language (cs.CL); Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">We present Any-Modality Augmented Language Model (AnyMAL), a unified model
that reasons over diverse input modality signals (i.e. text, image, video,
audio, IMU motion sensor), and generates textual responses. AnyMAL inherits the
powerful text-based reasoning abilities of the state-of-the-art LLMs including
LLaMA-2 (70B), and converts modality-specific signals to the joint textual
space through a pre-trained aligner module. To further strengthen the
multimodal LLM's capabilities, we fine-tune the model with a multimodal
instruction set manually collected to cover diverse topics and tasks beyond
simple QAs. We conduct comprehensive empirical analysis comprising both human
and automatic evaluations, and demonstrate state-of-the-art performance on
various multimodal tasks.
</p>
</div>
</dd>
<dt><a name="item65">[65]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16059" title="Abstract">arXiv:2309.16059</a> [<a href="/pdf/2309.16059" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Predicting Cardiovascular Complications in Post-COVID-19 Patients Using  Data-Driven Machine Learning Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yousif%2C+M+G">Maitham G. Yousif</a>, 
<a href="/search/cs?searchtype=author&query=Castro%2C+H+J">Hector J. Castro</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Biomolecules (q-bio.BM); Quantitative Methods (q-bio.QM); Applications (stat.AP)

</div>
<p class="mathjax">The COVID-19 pandemic has globally posed numerous health challenges, notably
the emergence of post-COVID-19 cardiovascular complications. This study
addresses this by utilizing data-driven machine learning models to predict such
complications in 352 post-COVID-19 patients from Iraq. Clinical data, including
demographics, comorbidities, lab results, and imaging, were collected and used
to construct predictive models. These models, leveraging various machine
learning algorithms, demonstrated commendable performance in identifying
patients at risk. Early detection through these models promises timely
interventions and improved outcomes. In conclusion, this research underscores
the potential of data-driven machine learning for predicting post-COVID-19
cardiovascular complications, emphasizing the need for continued validation and
research in diverse clinical settings.
</p>
</div>
</dd>
<dt><a name="item66">[66]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16062" title="Abstract">arXiv:2309.16062</a> [<a href="/pdf/2309.16062" title="Download PDF">pdf</a>, <a href="/format/2309.16062" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Multiscale Finite Element Method for an Elliptic Distributed Optimal  Control Problem with Rough Coefficients and Control Constraints
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Brenner%2C+S+C">Susanne C. Brenner</a>, 
<a href="/search/math?searchtype=author&query=Garay%2C+J+C">Jose C. Garay</a>, 
<a href="/search/math?searchtype=author&query=Sung%2C+L">Li-yeng Sung</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 26 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">We construct and analyze a multiscale finite element method for an elliptic
distributed optimal control problem with pointwise control constraints, where
the state equation has rough coefficients. We show that the performance of the
multiscale finite element method is similar to the performance of standard
finite element methods for smooth problems and present corroborating numerical
results.
</p>
</div>
</dd>
<dt><a name="item67">[67]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16064" title="Abstract">arXiv:2309.16064</a> [<a href="/pdf/2309.16064" title="Download PDF">pdf</a>, <a href="/format/2309.16064" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Masked autoencoders are scalable learners of cellular morphology
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kraus%2C+O">Oren Kraus</a>, 
<a href="/search/cs?searchtype=author&query=Kenyon-Dean%2C+K">Kian Kenyon-Dean</a>, 
<a href="/search/cs?searchtype=author&query=Saberian%2C+S">Saber Saberian</a>, 
<a href="/search/cs?searchtype=author&query=Fallah%2C+M">Maryam Fallah</a>, 
<a href="/search/cs?searchtype=author&query=McLean%2C+P">Peter McLean</a>, 
<a href="/search/cs?searchtype=author&query=Leung%2C+J">Jess Leung</a>, 
<a href="/search/cs?searchtype=author&query=Sharma%2C+V">Vasudev Sharma</a>, 
<a href="/search/cs?searchtype=author&query=Khan%2C+A">Ayla Khan</a>, 
<a href="/search/cs?searchtype=author&query=Balakrishnan%2C+J">Jia Balakrishnan</a>, 
<a href="/search/cs?searchtype=author&query=Celik%2C+S">Safiye Celik</a>, 
<a href="/search/cs?searchtype=author&query=Sypetkowski%2C+M">Maciej Sypetkowski</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+C+V">Chi Vicky Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Morse%2C+K">Kristen Morse</a>, 
<a href="/search/cs?searchtype=author&query=Makes%2C+M">Maureen Makes</a>, 
<a href="/search/cs?searchtype=author&query=Mabey%2C+B">Ben Mabey</a>, 
<a href="/search/cs?searchtype=author&query=Earnshaw%2C+B">Berton Earnshaw</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 4 pages, 4 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Inferring biological relationships from cellular phenotypes in high-content
microscopy screens provides significant opportunity and challenge in biological
research. Prior results have shown that deep vision models can capture
biological signal better than hand-crafted features. This work explores how
weakly supervised and self-supervised deep learning approaches scale when
training larger models on larger datasets. Our results show that both CNN- and
ViT-based masked autoencoders significantly outperform weakly supervised
models. At the high-end of our scale, a ViT-L/8 trained on over 3.5-billion
unique crops sampled from 95-million microscopy images achieves relative
improvements as high as 28% over our best weakly supervised models at inferring
known biological relationships curated from public databases.
</p>
</div>
</dd>
<dt><a name="item68">[68]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16066" title="Abstract">arXiv:2309.16066</a> [<a href="/pdf/2309.16066" title="Download PDF">pdf</a>, <a href="/format/2309.16066" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Label Augmentation Method for Medical Landmark Detection in Hip  Radiograph Images
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Suh%2C+Y">Yehyun Suh</a>, 
<a href="/search/cs?searchtype=author&query=Chan%2C+P">Peter Chan</a>, 
<a href="/search/cs?searchtype=author&query=Martin%2C+J+R">J.Ryan Martin</a>, 
<a href="/search/cs?searchtype=author&query=Moyer%2C+D">Daniel Moyer</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">This work reports the empirical performance of an automated medical landmark
detection method for predict clinical markers in hip radiograph images.
Notably, the detection method was trained using a label-only augmentation
scheme; our results indicate that this form of augmentation outperforms
traditional data augmentation and produces highly sample efficient estimators.
We train a generic U-Net-based architecture under a curriculum consisting of
two phases: initially relaxing the landmarking task by enlarging the label
points to regions, then gradually eroding these label regions back to the base
task. We measure the benefits of this approach on six datasets of radiographs
with gold-standard expert annotations.
</p>
</div>
</dd>
<dt><a name="item69">[69]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16068" title="Abstract">arXiv:2309.16068</a> [<a href="/pdf/2309.16068" title="Download PDF">pdf</a>, <a href="/format/2309.16068" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Analytic regularity of strong solutions for the complexified stochastic  non-linear Poisson Boltzmann Equation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Choi%2C+B">Brian Choi</a>, 
<a href="/search/math?searchtype=author&query=Xu%2C+J">Jie Xu</a>, 
<a href="/search/math?searchtype=author&query=Norton%2C+T">Trevor Norton</a>, 
<a href="/search/math?searchtype=author&query=Kon%2C+M">Mark Kon</a>, 
<a href="/search/math?searchtype=author&query=Castrillon-Candas%2C+J+E">Julio Enrique Castrillon-Candas</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: substantial text overlap with <a href="/abs/2106.05811">arXiv:2106.05811</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">Semi-linear elliptic Partial Differential Equations (PDEs) such as the
non-linear Poisson Boltzmann Equation (nPBE) is highly relevant for non-linear
electrostatics in computational biology and chemistry. It is of particular
importance for modeling potential fields from molecules in solvents or plasmas
with stochastic fluctuations. The extensive applications include ones in
condensed matter and solid state physics, chemical physics, electrochemistry,
biochemistry, thermodynamics, statistical mechanics, and materials science,
among others. In this paper we study the complex analytic properties of
semi-linear elliptic Partial Differential Equations with respect to random
fluctuations on the domain. We first prove the existence and uniqueness of the
nPBE on a bounded domain in $\mathbb{R}^3$. This proof relies on the
application of a contraction mapping reasoning, as the standard convex
optimization argument for the deterministic nPBE no longer applies. Using the
existence and uniqueness result we subsequently show that solution to the nPBE
admits an analytic extension onto a well defined region in the complex
hyperplane with respect to the number of stochastic variables. Due to the
analytic extension, stochastic collocation theory for sparse grids predict
algebraic to sub-exponential convergence rates with respect to the number of
knots. A series of numerical experiments with sparse grids is consistent with
this prediction and the analyticity result. Finally, this approach readily
extends to a wide class of semi-linear elliptic PDEs.
</p>
</div>
</dd>
<dt><a name="item70">[70]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16071" title="Abstract">arXiv:2309.16071</a> [<a href="/pdf/2309.16071" title="Download PDF">pdf</a>, <a href="/format/2309.16071" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Influence Pathway Discovery on Social Media
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xinyi Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+R">Ruijie Wang</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+D">Dachun Sun</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jinning Li</a>, 
<a href="/search/cs?searchtype=author&query=Youn%2C+C">Christina Youn</a>, 
<a href="/search/cs?searchtype=author&query=Lyu%2C+Y">You Lyu</a>, 
<a href="/search/cs?searchtype=author&query=Zhan%2C+J">Jianyuan Zhan</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+D">Dayou Wu</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+X">Xinhe Xu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+M">Mingjun Liu</a>, 
<a href="/search/cs?searchtype=author&query=Lei%2C+X">Xinshuo Lei</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+Z">Zhihao Xu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yutong Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zehao Li</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Q">Qikai Yang</a>, 
<a href="/search/cs?searchtype=author&query=Abdelzaher%2C+T">Tarek Abdelzaher</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This paper is accepted by IEEE CIC as an invited vision paper
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>

</div>
<p class="mathjax">This paper addresses influence pathway discovery, a key emerging problem in
today's online media. We propose a discovery algorithm that leverages recently
published work on unsupervised interpretable ideological embedding, a mapping
of ideological beliefs (done in a self-supervised fashion) into interpretable
low-dimensional spaces. Computing the ideological embedding at scale allows one
to analyze correlations between the ideological positions of leaders,
influencers, news portals, or population segments, deriving potential influence
pathways. The work is motivated by the importance of social media as the
preeminent means for global interactions and collaborations on today's
Internet, as well as their frequent (mis-)use to wield influence that targets
social beliefs and attitudes of selected populations. Tools that enable the
understanding and mapping of influence propagation through population segments
on social media are therefore increasingly important. In this paper, influence
is measured by the perceived ideological shift over time that is correlated
with influencers' activity. Correlated shifts in ideological embeddings
indicate changes, such as swings/switching (among competing ideologies),
polarization (depletion of neutral ideological positions),
escalation/radicalization (shifts to more extreme versions of the ideology), or
unification/cooldown (shifts towards more neutral stances). Case-studies are
presented to explore selected influence pathways (i) in a recent French
election, (ii) during political discussions in the Philippines, and (iii) for
some Russian messaging during the Russia/Ukraine conflict.
</p>
</div>
</dd>
<dt><a name="item71">[71]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16074" title="Abstract">arXiv:2309.16074</a> [<a href="/pdf/2309.16074" title="Download PDF">pdf</a>, <a href="/format/2309.16074" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Infer and Adapt: Bipedal Locomotion Reward Learning from Demonstrations  via Inverse Reinforcement Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+F">Feiyang Wu</a>, 
<a href="/search/cs?searchtype=author&query=Gu%2C+Z">Zhaoyuan Gu</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+H">Hanran Wu</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+A">Anqi Wu</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Y">Ye Zhao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Enabling bipedal walking robots to learn how to maneuver over highly uneven,
dynamically changing terrains is challenging due to the complexity of robot
dynamics and interacted environments. Recent advancements in learning from
demonstrations have shown promising results for robot learning in complex
environments. While imitation learning of expert policies has been
well-explored, the study of learning expert reward functions is largely
under-explored in legged locomotion. This paper brings state-of-the-art Inverse
Reinforcement Learning (IRL) techniques to solving bipedal locomotion problems
over complex terrains. We propose algorithms for learning expert reward
functions, and we subsequently analyze the learned functions. Through nonlinear
function approximation, we uncover meaningful insights into the expert's
locomotion strategies. Furthermore, we empirically demonstrate that training a
bipedal locomotion policy with the inferred reward functions enhances its
walking performance on unseen terrains, highlighting the adaptability offered
by reward learning.
</p>
</div>
</dd>
<dt><a name="item72">[72]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16075" title="Abstract">arXiv:2309.16075</a> [<a href="/pdf/2309.16075" title="Download PDF">pdf</a>, <a href="/format/2309.16075" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A review of variable-pitch propellers and their control strategies in  aerospace systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Jiang%2C+H">Hanjie Jiang</a>, 
<a href="/search/eess?searchtype=author&query=Zhou%2C+Y">Ye Zhou</a>, 
<a href="/search/eess?searchtype=author&query=Ho%2C+H+W">Hann Woei Ho</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">The relentless pursuit of aircraft flight efficiency has thrust
variable-pitch propeller technology into the forefront of aviation innovation.
This technology, rooted in the ancient power unit of propellers, has found
renewed significance, particularly in the realms of unmanned aerial vehicles
and urban air mobility. This underscores the profound interplay between
visionary aviation concepts and the enduring utility of propellers.
Variable-pitch propellers are poised to be pivotal in shaping the future of
human aviation, offering benefits such as extended endurance, enhanced
maneuverability, improved fuel economy, and prolonged engine life. However,
with additional capabilities come new technical challenges. The development of
an online adaptive control of variable-pitch propellers that does not depend on
an accurate dynamic model stands as a critical imperative. Therefore, a
comprehensive review and forward-looking analysis of this technology is
warranted. This paper introduces the development background of variable-pitch
aviation propeller technology, encompassing diverse pitch angle adjustment
schemes and their integration with various engine types. It places a central
focus on the latest research frontiers and emerging directions in pitch control
strategies. Lastly, it delves into the research domain of constant speed pitch
control, articulating the three main challenges confronting this technology:
inadequacies in system modeling, the intricacies of propeller-engine
compatibility, and the impact of external, time-varying factors. By shedding
light on these multifaceted aspects of variable-pitch propeller technology,
this paper serves as a resource for aviation professionals and researchers
navigating the intricate landscape of future aircraft development.
</p>
</div>
</dd>
<dt><a name="item73">[73]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16077" title="Abstract">arXiv:2309.16077</a> [<a href="/pdf/2309.16077" title="Download PDF">pdf</a>, <a href="/format/2309.16077" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Task-Oriented Koopman-Based Control with Contrastive Encoder
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lyu%2C+X">Xubo Lyu</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+H">Hanyang Hu</a>, 
<a href="/search/cs?searchtype=author&query=Siriya%2C+S">Seth Siriya</a>, 
<a href="/search/cs?searchtype=author&query=Pu%2C+Y">Ye Pu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+M">Mo Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by the 7th Annual Conference on Robot Learning (CoRL), 2023 (oral spotlight)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Machine Learning (cs.LG); Systems and Control (eess.SY)

</div>
<p class="mathjax">We present task-oriented Koopman-based control that utilizes end-to-end
reinforcement learning and contrastive encoder to simultaneously learn the
Koopman latent embedding, operator and associated linear controller within an
iterative loop. By prioritizing the task cost as main objective for controller
learning, we reduce the reliance of controller design on a well-identified
model, which extends Koopman control beyond low-dimensional systems to
high-dimensional, complex nonlinear systems, including pixel-based scenarios.
</p>
</div>
</dd>
<dt><a name="item74">[74]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16081" title="Abstract">arXiv:2309.16081</a> [<a href="/pdf/2309.16081" title="Download PDF">pdf</a>, <a href="/format/2309.16081" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Modular Bio-inspired Robotic Hand with High Sensitivity
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+C">Chao Liu</a>, 
<a href="/search/cs?searchtype=author&query=Moncada%2C+A">Andrea Moncada</a>, 
<a href="/search/cs?searchtype=author&query=Matusik%2C+H">Hanna Matusik</a>, 
<a href="/search/cs?searchtype=author&query=Erus%2C+D+I">Deniz Irem Erus</a>, 
<a href="/search/cs?searchtype=author&query=Rus%2C+D">Daniela Rus</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, 13 figures, IEEE RoboSoft 2023
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> 2023 IEEE International Conference on Soft Robotics (RoboSoft),
  Singapore, Singapore, 2023, pp. 1-7
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">While parallel grippers and multi-fingered robotic hands are well developed
and commonly used in structured settings, it remains a challenge in robotics to
design a highly articulated robotic hand that can be comparable to human hands
to handle various daily manipulation and grasping tasks. Dexterity usually
requires more actuators but also leads to a more sophisticated mechanism design
and is more expensive to fabricate and maintain. Soft materials are able to
provide compliance and safety when interacting with the physical world but are
hard to model. This work presents a hybrid bio-inspired robotic hand that
combines soft matters and rigid elements. Sensing is integrated into the rigid
bodies resulting in a simple way for pose estimation with high sensitivity. The
proposed hand is in a modular structure allowing for rapid fabrication and
programming. The fabrication process is carefully designed so that a full hand
can be made with low-cost materials and assembled in an efficient manner. We
demonstrate the dexterity of the hand by successfully performing human grasp
types.
</p>
</div>
</dd>
<dt><a name="item75">[75]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16082" title="Abstract">arXiv:2309.16082</a> [<a href="/pdf/2309.16082" title="Download PDF">pdf</a>, <a href="/ps/2309.16082" title="Download PostScript">ps</a>, <a href="/format/2309.16082" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Forgetting Private Textual Sequences in Language Models via  Leave-One-Out Ensemble
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zhe Liu</a>, 
<a href="/search/cs?searchtype=author&query=Kalinli%2C+O">Ozlem Kalinli</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Recent research has shown that language models have a tendency to memorize
rare or unique token sequences in the training corpus. After deploying a model,
practitioners might be asked to delete any personal information from the model
by individuals' requests. Re-training the underlying model every time
individuals would like to practice their rights to be forgotten is
computationally expensive. We employ a teacher-student framework and propose a
novel leave-one-out ensemble method to unlearn the targeted textual sequences
that need to be forgotten from the model. In our approach, multiple teachers
are trained on disjoint sets; for each targeted sequence to be removed, we
exclude the teacher trained on the set containing this sequence and aggregate
the predictions from remaining teachers to provide supervision during
fine-tuning. Experiments on LibriSpeech and WikiText-103 datasets show that the
proposed method achieves superior privacy-utility trade-offs than other
counterparts.
</p>
</div>
</dd>
<dt><a name="item76">[76]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16084" title="Abstract">arXiv:2309.16084</a> [<a href="/pdf/2309.16084" title="Download PDF">pdf</a>, <a href="/format/2309.16084" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A priori and a posteriori error analysis for a VEM discretization of the  convection-diffusion eigenvalue problem
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Amigo%2C+D">Danilo Amigo</a>, 
<a href="/search/math?searchtype=author&query=Lepe%2C+F">Felipe Lepe</a>, 
<a href="/search/math?searchtype=author&query=Rivera%2C+G">Gonzalo Rivera</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">In this paper we propose and analyze a virtual element method for the two
dimensional non-symmetric diffusion-convection eigenvalue problem in order to
derive a priori and a posteriori error estimates. Under the classic assumptions
of the meshes, and with the aid of the classic theory of compact operators, we
prove error estimates for the eigenvalues and eigenfunctions. Also, we develop
an a posteriori error estimator which, in one hand, results to be reliable and
on the other, with standard bubble functions arguments, also results to be
efficient. We test our method on domains where the complex eigenfunctions are
not sufficiently regular, in order to assess the performance of the estimator
that we compare with the uniform refinement given by the a priori analysis
</p>
</div>
</dd>
<dt><a name="item77">[77]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16085" title="Abstract">arXiv:2309.16085</a> [<a href="/pdf/2309.16085" title="Download PDF">pdf</a>, <a href="/format/2309.16085" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Differentiable Robot Neural Distance Function for Adaptive Grasp  Synthesis on a Unified Robotic Arm-Hand System
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yiting Chen</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+X">Xiao Gao</a>, 
<a href="/search/cs?searchtype=author&query=Yao%2C+K">Kunpeng Yao</a>, 
<a href="/search/cs?searchtype=author&query=Niederhauser%2C+L">Lo&#xef;c Niederhauser</a>, 
<a href="/search/cs?searchtype=author&query=Bekiroglu%2C+Y">Yasemin Bekiroglu</a>, 
<a href="/search/cs?searchtype=author&query=Billard%2C+A">Aude Billard</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Under review
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Grasping is a fundamental skill for robots to interact with their
environment. While grasp execution requires coordinated movement of the hand
and arm to achieve a collision-free and secure grip, many grasp synthesis
studies address arm and hand motion planning independently, leading to
potentially unreachable grasps in practical settings. The challenge of
determining integrated arm-hand configurations arises from its computational
complexity and high-dimensional nature. We address this challenge by presenting
a novel differentiable robot neural distance function. Our approach excels in
capturing intricate geometry across various joint configurations while
preserving differentiability. This innovative representation proves
instrumental in efficiently addressing downstream tasks with stringent contact
constraints. Leveraging this, we introduce an adaptive grasp synthesis
framework that exploits the full potential of the unified arm-hand system for
diverse grasping tasks. Our neural joint space distance function achieves an
84.7% error reduction compared to baseline methods. We validated our approaches
on a unified robotic arm-hand system that consists of a 7-DoF robot arm and a
16-DoF multi-fingered robotic hand. Results demonstrate that our approach
empowers this high-DoF system to generate and execute various arm-hand grasp
configurations that adapt to the size of the target objects while ensuring
whole-body movements to be collision-free.
</p>
</div>
</dd>
<dt><a name="item78">[78]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16090" title="Abstract">arXiv:2309.16090</a> [<a href="/pdf/2309.16090" title="Download PDF">pdf</a>, <a href="/format/2309.16090" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> TPE: Towards Better Compositional Reasoning over Conceptual Tools with  Multi-persona Collaboration
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Hongru Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Huimin Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+L">Lingzhi Wang</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+M">Minda Hu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+R">Rui Wang</a>, 
<a href="/search/cs?searchtype=author&query=Xue%2C+B">Boyang Xue</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+H">Hongyuan Lu</a>, 
<a href="/search/cs?searchtype=author&query=Mi%2C+F">Fei Mi</a>, 
<a href="/search/cs?searchtype=author&query=Wong%2C+K">Kam-Fai Wong</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computation and Language (cs.CL)

</div>
<p class="mathjax">Large language models (LLMs) have demonstrated exceptional performance in
planning the use of various functional tools, such as calculators and
retrievers, particularly in question-answering tasks. In this paper, we expand
the definition of these tools, centering on conceptual tools within the context
of dialogue systems. A conceptual tool specifies a cognitive concept that aids
systematic or investigative thought. These conceptual tools play important
roles in practice, such as multiple psychological or tutoring strategies being
dynamically applied in a single turn to compose helpful responses. To further
enhance the reasoning and planning capability of LLMs with these conceptual
tools, we introduce a multi-persona collaboration framework: Think-Plan-Execute
(TPE). This framework decouples the response generation process into three
distinct roles: Thinker, Planner, and Executor. Specifically, the Thinker
analyzes the internal status exhibited in the dialogue context, such as user
emotions and preferences, to formulate a global guideline. The Planner then
generates executable plans to call different conceptual tools (e.g., sources or
strategies), while the Executor compiles all intermediate results into a
coherent response. This structured approach not only enhances the
explainability and controllability of responses but also reduces token
redundancy. We demonstrate the effectiveness of TPE across various dialogue
response generation tasks, including multi-source (FoCus) and multi-strategy
interactions (CIMA and PsyQA). This reveals its potential to handle real-world
dialogue interactions that require more complicated tool learning beyond just
functional tools. The full code and data will be released for reproduction.
</p>
</div>
</dd>
<dt><a name="item79">[79]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16096" title="Abstract">arXiv:2309.16096</a> [<a href="/pdf/2309.16096" title="Download PDF">pdf</a>, <a href="/format/2309.16096" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Adversarial Examples Might be Avoidable: The Role of Data Concentration  in Adversarial Robustness
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pal%2C+A">Ambar Pal</a>, 
<a href="/search/cs?searchtype=author&query=Sulam%2C+J">Jeremias Sulam</a>, 
<a href="/search/cs?searchtype=author&query=Vidal%2C+R">Ren&#xe9; Vidal</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to Neural Information Processing Systems (NeurIPS) 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">The susceptibility of modern machine learning classifiers to adversarial
examples has motivated theoretical results suggesting that these might be
unavoidable. However, these results can be too general to be applicable to
natural data distributions. Indeed, humans are quite robust for tasks involving
vision. This apparent conflict motivates a deeper dive into the question: Are
adversarial examples truly unavoidable? In this work, we theoretically
demonstrate that a key property of the data distribution -- concentration on
small-volume subsets of the input space -- determines whether a robust
classifier exists. We further demonstrate that, for a data distribution
concentrated on a union of low-dimensional linear subspaces, exploiting data
structure naturally leads to classifiers that enjoy good robustness guarantees,
improving upon methods for provable certification in certain regimes.
</p>
</div>
</dd>
<dt><a name="item80">[80]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16098" title="Abstract">arXiv:2309.16098</a> [<a href="/pdf/2309.16098" title="Download PDF">pdf</a>, <a href="/format/2309.16098" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Stackelberg Game-Theoretic Trajectory Guidance for Multi-Robot Systems  with Koopman Operator
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Y">Yuhan Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+Q">Quanyan Zhu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Guided trajectory planning involves a leader robotic agent strategically
directing a follower robotic agent to collaboratively reach a designated
destination. However, this task becomes notably challenging when the leader
lacks complete knowledge of the follower's decision-making model. There is a
need for learning-based methods to effectively design the cooperative plan. To
this end, we develop a Stackelberg game-theoretic approach based on Koopman
operator to address the challenge. We first formulate the guided trajectory
planning problem through the lens of a dynamic Stackelberg game. We then
leverage Koopman operator theory to acquire a learning-based linear system
model that approximates the follower's feedback dynamics. Based on this learned
model, the leader devises a collision-free trajectory to guide the follower,
employing receding horizon planning. We use simulations to elaborate the
effectiveness of our approach in generating learning models that accurately
predict the follower's multi-step behavior when compared to alternative
learning techniques. Moreover, our approach successfully accomplishes the
guidance task and notably reduces the leader's planning time to nearly half
when contrasted with the model-based baseline method.
</p>
</div>
</dd>
<dt><a name="item81">[81]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16102" title="Abstract">arXiv:2309.16102</a> [<a href="/pdf/2309.16102" title="Download PDF">pdf</a>, <a href="/format/2309.16102" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Discovering Utility-driven Interval Rules
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+C">Chunkai Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Lyu%2C+M">Maohua Lyu</a>, 
<a href="/search/cs?searchtype=author&query=Hao%2C+H">Huaijin Hao</a>, 
<a href="/search/cs?searchtype=author&query=Gan%2C+W">Wensheng Gan</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+P+S">Philip S. Yu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Preprint. 11 figures, 5 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Databases (cs.DB)

</div>
<p class="mathjax">For artificial intelligence, high-utility sequential rule mining (HUSRM) is a
knowledge discovery method that can reveal the associations between events in
the sequences. Recently, abundant methods have been proposed to discover
high-utility sequence rules. However, the existing methods are all related to
point-based sequences. Interval events that persist for some time are common.
Traditional interval-event sequence knowledge discovery tasks mainly focus on
pattern discovery, but patterns cannot reveal the correlation between interval
events well. Moreover, the existing HUSRM algorithms cannot be directly applied
to interval-event sequences since the relation in interval-event sequences is
much more intricate than those in point-based sequences. In this work, we
propose a utility-driven interval rule mining (UIRMiner) algorithm that can
extract all utility-driven interval rules (UIRs) from the interval-event
sequence database to solve the problem. In UIRMiner, we first introduce a
numeric encoding relation representation, which can save much time on relation
computation and storage on relation representation. Furthermore, to shrink the
search space, we also propose a complement pruning strategy, which incorporates
the utility upper bound with the relation. Finally, plentiful experiments
implemented on both real-world and synthetic datasets verify that UIRMiner is
an effective and efficient algorithm.
</p>
</div>
</dd>
<dt><a name="item82">[82]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16105" title="Abstract">arXiv:2309.16105</a> [<a href="/pdf/2309.16105" title="Download PDF">pdf</a>, <a href="/format/2309.16105" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Differentially Private Secure Multiplication: Hiding Information in the  Rubble of Noise
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cadambe%2C+V+R">Viveck R. Cadambe</a>, 
<a href="/search/cs?searchtype=author&query=Devulapalli%2C+A">Ateet Devulapalli</a>, 
<a href="/search/cs?searchtype=author&query=Jeong%2C+H">Haewon Jeong</a>, 
<a href="/search/cs?searchtype=author&query=Calmon%2C+F+P">Flavio P. Calmon</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Extended version of papers presented in IEEE ISIT 2022, IEEE ISIT 2023 and TPDP 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Cryptography and Security (cs.CR); Distributed, Parallel, and Cluster Computing (cs.DC); Machine Learning (cs.LG)

</div>
<p class="mathjax">We consider the problem of private distributed multi-party multiplication. It
is well-established that Shamir secret-sharing coding strategies can enable
perfect information-theoretic privacy in distributed computation via the
celebrated algorithm of Ben Or, Goldwasser and Wigderson (the "BGW algorithm").
However, perfect privacy and accuracy require an honest majority, that is, $N
\geq 2t+1$ compute nodes are required to ensure privacy against any $t$
colluding adversarial nodes. By allowing for some controlled amount of
information leakage and approximate multiplication instead of exact
multiplication, we study coding schemes for the setting where the number of
honest nodes can be a minority, that is $N&lt; 2t+1.$ We develop a tight
characterization privacy-accuracy trade-off for cases where $N &lt; 2t+1$ by
measuring information leakage using {differential} privacy instead of perfect
privacy, and using the mean squared error metric for accuracy. A novel
technical aspect is an intricately layered noise distribution that merges ideas
from differential privacy and Shamir secret-sharing at different layers.
</p>
</div>
</dd>
<dt><a name="item83">[83]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16108" title="Abstract">arXiv:2309.16108</a> [<a href="/pdf/2309.16108" title="Download PDF">pdf</a>, <a href="/format/2309.16108" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Channel Vision Transformers: An Image Is Worth C x 16 x 16 Words
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bao%2C+Y">Yujia Bao</a>, 
<a href="/search/cs?searchtype=author&query=Sivanandan%2C+S">Srinivasan Sivanandan</a>, 
<a href="/search/cs?searchtype=author&query=Karaletsos%2C+T">Theofanis Karaletsos</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Vision Transformer (ViT) has emerged as a powerful architecture in the realm
of modern computer vision. However, its application in certain imaging fields,
such as microscopy and satellite imaging, presents unique challenges. In these
domains, images often contain multiple channels, each carrying semantically
distinct and independent information. Furthermore, the model must demonstrate
robustness to sparsity in input channels, as they may not be densely available
during training or testing. In this paper, we propose a modification to the ViT
architecture that enhances reasoning across the input channels and introduce
Hierarchical Channel Sampling (HCS) as an additional regularization technique
to ensure robustness when only partial channels are presented during test time.
Our proposed model, ChannelViT, constructs patch tokens independently from each
input channel and utilizes a learnable channel embedding that is added to the
patch tokens, similar to positional embeddings. We evaluate the performance of
ChannelViT on ImageNet, JUMP-CP (microscopy cell imaging), and So2Sat
(satellite imaging). Our results show that ChannelViT outperforms ViT on
classification tasks and generalizes well, even when a subset of input channels
is used during testing. Across our experiments, HCS proves to be a powerful
regularizer, independent of the architecture employed, suggesting itself as a
straightforward technique for robust ViT training. Lastly, we find that
ChannelViT generalizes effectively even when there is limited access to all
channels during training, highlighting its potential for multi-channel imaging
under real-world conditions with sparse sensors.
</p>
</div>
</dd>
<dt><a name="item84">[84]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16109" title="Abstract">arXiv:2309.16109</a> [<a href="/pdf/2309.16109" title="Download PDF">pdf</a>, <a href="/format/2309.16109" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Feature Normalization Prevents Collapse of Non-contrastive Learning  Dynamics
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bao%2C+H">Han Bao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
<p class="mathjax">Contrastive learning is a self-supervised representation learning framework,
where two positive views generated through data augmentation are made similar
by an attraction force in a data representation space, while a repulsive force
makes them far from negative examples. Non-contrastive learning, represented by
BYOL and SimSiam, further gets rid of negative examples and improves
computational efficiency. While learned representations may collapse into a
single point due to the lack of the repulsive force at first sight, Tian et al.
(2021) revealed through the learning dynamics analysis that the representations
can avoid collapse if data augmentation is sufficiently stronger than
regularization. However, their analysis does not take into account
commonly-used feature normalization, a normalizer before measuring the
similarity of representations, and hence excessively strong regularization may
collapse the dynamics, which is an unnatural behavior under the presence of
feature normalization. Therefore, we extend the previous theory based on the L2
loss by considering the cosine loss, which involves feature normalization. We
show that the cosine loss induces sixth-order dynamics (while the L2 loss
induces a third-order one), in which a stable equilibrium dynamically emerges
even if there are only collapsed solutions with given initial parameters. Thus,
we offer a new understanding that feature normalization plays an important role
in robustly preventing the dynamics collapse.
</p>
</div>
</dd>
<dt><a name="item85">[85]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16110" title="Abstract">arXiv:2309.16110</a> [<a href="/pdf/2309.16110" title="Download PDF">pdf</a>, <a href="/format/2309.16110" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning Effective NeRFs and SDFs Representations with 3D Generative  Adversarial Networks for 3D Object Generation: Technical Report for ICCV 2023  OmniObject3D Challenge
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+Z">Zheyuan Yang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yibo Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+G">Guile Wu</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+T">Tongtong Cao</a>, 
<a href="/search/cs?searchtype=author&query=Ren%2C+Y">Yuan Ren</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+B">Bingbing Liu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">In this technical report, we present a solution for 3D object generation of
ICCV 2023 OmniObject3D Challenge. In recent years, 3D object generation has
made great process and achieved promising results, but it remains a challenging
task due to the difficulty of generating complex, textured and high-fidelity
results. To resolve this problem, we study learning effective NeRFs and SDFs
representations with 3D Generative Adversarial Networks (GANs) for 3D object
generation. Specifically, inspired by recent works, we use the efficient
geometry-aware 3D GANs as the backbone incorporating with label embedding and
color mapping, which enables to train the model on different taxonomies
simultaneously. Then, through a decoder, we aggregate the resulting features to
generate Neural Radiance Fields (NeRFs) based representations for rendering
high-fidelity synthetic images. Meanwhile, we optimize Signed Distance
Functions (SDFs) to effectively represent objects with 3D meshes. Besides, we
observe that this model can be effectively trained with only a few images of
each object from a variety of classes, instead of using a great number of
images per object or training one model per class. With this pipeline, we can
optimize an effective model for 3D object generation. This solution is one of
the final top-3-place solutions in the ICCV 2023 OmniObject3D Challenge.
</p>
</div>
</dd>
<dt><a name="item86">[86]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16114" title="Abstract">arXiv:2309.16114</a> [<a href="/pdf/2309.16114" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Comparing Active Learning Performance Driven by Gaussian Processes or  Bayesian Neural Networks for Constrained Trajectory Exploration
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Akins%2C+S">Sapphira Akins</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+F">Frances Zhu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> AIAA ASCEND 2023, 15 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Robots with increasing autonomy progress our space exploration capabilities,
particularly for in-situ exploration and sampling to stand in for human
explorers. Currently, humans drive robots to meet scientific objectives, but
depending on the robot's location, the exchange of information and driving
commands between the human operator and robot may cause undue delays in mission
fulfillment. An autonomous robot encoded with a scientific objective and an
exploration strategy incurs no communication delays and can fulfill missions
more quickly. Active learning algorithms offer this capability of intelligent
exploration, but the underlying model structure varies the performance of the
active learning algorithm in accurately forming an understanding of the
environment. In this paper, we investigate the performance differences between
active learning algorithms driven by Gaussian processes or Bayesian neural
networks for exploration strategies encoded on agents that are constrained in
their trajectories, like planetary surface rovers. These two active learning
strategies were tested in a simulation environment against science-blind
strategies to predict the spatial distribution of a variable of interest along
multiple datasets. The performance metrics of interest are model accuracy in
root mean squared (RMS) error, training time, model convergence, total distance
traveled until convergence, and total samples until convergence. Active
learning strategies encoded with Gaussian processes require less computation to
train, converge to an accurate model more quickly, and propose trajectories of
shorter distance, except in a few complex environments in which Bayesian neural
networks achieve a more accurate model in the large data regime due to their
more expressive functional bases. The paper concludes with advice on when and
how to implement either exploration strategy for future space missions.
</p>
</div>
</dd>
<dt><a name="item87">[87]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16115" title="Abstract">arXiv:2309.16115</a> [<a href="/pdf/2309.16115" title="Download PDF">pdf</a>, <a href="/format/2309.16115" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Compositional Sculpting of Iterative Generative Processes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Garipov%2C+T">Timur Garipov</a>, 
<a href="/search/cs?searchtype=author&query=De+Peuter%2C+S">Sebastiaan De Peuter</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+G">Ge Yang</a>, 
<a href="/search/cs?searchtype=author&query=Garg%2C+V">Vikas Garg</a>, 
<a href="/search/cs?searchtype=author&query=Kaski%2C+S">Samuel Kaski</a>, 
<a href="/search/cs?searchtype=author&query=Jaakkola%2C+T">Tommi Jaakkola</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Extended version of NeurIPS 2023 paper
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">High training costs of generative models and the need to fine-tune them for
specific tasks have created a strong interest in model reuse and composition. A
key challenge in composing iterative generative processes, such as GFlowNets
and diffusion models, is that to realize the desired target distribution, all
steps of the generative process need to be coordinated, and satisfy delicate
balance conditions. In this work, we propose Compositional Sculpting: a general
approach for defining compositions of iterative generative processes. We then
introduce a method for sampling from these compositions built on classifier
guidance. We showcase ways to accomplish compositional sculpting in both
GFlowNets and diffusion models. We highlight two binary operations
$\unicode{x2014}$ the harmonic mean ($p_1 \otimes p_2$) and the contrast ($p_1
\unicode{x25D1}\,p_2$) between pairs, and the generalization of these
operations to multiple component distributions. We offer empirical results on
image and molecular generation tasks.
</p>
</div>
</dd>
<dt><a name="item88">[88]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16116" title="Abstract">arXiv:2309.16116</a> [<a href="/pdf/2309.16116" title="Download PDF">pdf</a>, <a href="/ps/2309.16116" title="Download PostScript">ps</a>, <a href="/format/2309.16116" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On well-posed boundary conditions and energy stable finite volume method  for the linear shallow water wave equation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Prihandoko%2C+R">Rudi Prihandoko</a>, 
<a href="/search/math?searchtype=author&query=Duru%2C+K">Kenneth Duru</a>, 
<a href="/search/math?searchtype=author&query=Roberts%2C+S">Stephen Roberts</a>, 
<a href="/search/math?searchtype=author&query=Zoppou%2C+C">Christopher Zoppou</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 23 pages, 4 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">We derive and analyse well-posed boundary conditions for the linear shallow
water wave equation. The analysis is based on the energy method and it
identifies the number, location and form of the boundary conditions so that the
initial boundary value problem is well-posed. A finite volume method is
developed based on the summation-by-parts framework with the boundary
conditions implemented weakly using penalties. Stability is proven by deriving
a discrete energy estimate analogous to the continuous estimate. The continuous
and discrete analysis covers all flow regimes. Numerical experiments are
presented verifying the analysis.
</p>
</div>
</dd>
<dt><a name="item89">[89]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16117" title="Abstract">arXiv:2309.16117</a> [<a href="/pdf/2309.16117" title="Download PDF">pdf</a>, <a href="/format/2309.16117" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> E2Net: Resource-Efficient Continual Learning with Elastic Expansion  Network
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+R">RuiQi Liu</a>, 
<a href="/search/cs?searchtype=author&query=Diao%2C+B">Boyu Diao</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+L">Libo Huang</a>, 
<a href="/search/cs?searchtype=author&query=An%2C+Z">Zhulin An</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+Y">Yongjun Xu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Continual Learning methods are designed to learn new tasks without erasing
previous knowledge. However, Continual Learning often requires massive
computational power and storage capacity for satisfactory performance. In this
paper, we propose a resource-efficient continual learning method called the
Elastic Expansion Network (E2Net). Leveraging core subnet distillation and
precise replay sample selection, E2Net achieves superior average accuracy and
diminished forgetting within the same computational and storage constraints,
all while minimizing processing time. In E2Net, we propose Representative
Network Distillation to identify the representative core subnet by assessing
parameter quantity and output similarity with the working network, distilling
analogous subnets within the working network to mitigate reliance on rehearsal
buffers and facilitating knowledge transfer across previous tasks. To enhance
storage resource utilization, we then propose Subnet Constraint Experience
Replay to optimize rehearsal efficiency through a sample storage strategy based
on the structures of representative networks. Extensive experiments conducted
predominantly on cloud environments with diverse datasets and also spanning the
edge environment demonstrate that E2Net consistently outperforms
state-of-the-art methods. In addition, our method outperforms competitors in
terms of both storage and computational requirements.
</p>
</div>
</dd>
<dt><a name="item90">[90]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16118" title="Abstract">arXiv:2309.16118</a> [<a href="/pdf/2309.16118" title="Download PDF">pdf</a>, <a href="/format/2309.16118" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> D$^3$Fields: Dynamic 3D Descriptor Fields for Zero-Shot Generalizable  Robotic Manipulation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yixuan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zhuoran Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+M">Mingtong Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Driggs-Campbell%2C+K">Katherine Driggs-Campbell</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+J">Jiajun Wu</a>, 
<a href="/search/cs?searchtype=author&query=Fei-Fei%2C+L">Li Fei-Fei</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yunzhu Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
<p class="mathjax">Scene representation has been a crucial design choice in robotic manipulation
systems. An ideal representation should be 3D, dynamic, and semantic to meet
the demands of diverse manipulation tasks. However, previous works often lack
all three properties simultaneously. In this work, we introduce D$^3$Fields -
dynamic 3D descriptor fields. These fields capture the dynamics of the
underlying 3D environment and encode both semantic features and instance masks.
Specifically, we project arbitrary 3D points in the workspace onto multi-view
2D visual observations and interpolate features derived from foundational
models. The resulting fused descriptor fields allow for flexible goal
specifications using 2D images with varied contexts, styles, and instances. To
evaluate the effectiveness of these descriptor fields, we apply our
representation to a wide range of robotic manipulation tasks in a zero-shot
manner. Through extensive evaluation in both real-world scenarios and
simulations, we demonstrate that D$^3$Fields are both generalizable and
effective for zero-shot robotic manipulation tasks. In quantitative comparisons
with state-of-the-art dense descriptors, such as Dense Object Nets and DINO,
D$^3$Fields exhibit significantly better generalization abilities and
manipulation accuracy.
</p>
</div>
</dd>
<dt><a name="item91">[91]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16119" title="Abstract">arXiv:2309.16119</a> [<a href="/pdf/2309.16119" title="Download PDF">pdf</a>, <a href="/ps/2309.16119" title="Download PostScript">ps</a>, <a href="/format/2309.16119" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ModuLoRA: Finetuning 3-Bit LLMs on Consumer GPUs by Integrating with  Modular Quantizers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yin%2C+J">Junjie Yin</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+J">Jiahao Dong</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yingheng Wang</a>, 
<a href="/search/cs?searchtype=author&query=De+Sa%2C+C">Christopher De Sa</a>, 
<a href="/search/cs?searchtype=author&query=Kuleshov%2C+V">Volodymyr Kuleshov</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">We propose a memory-efficient finetuning algorithm for large language models
(LLMs) that supports finetuning LLMs with 65B parameters in 3-bit or 4-bit
precision on as little as one 48GB GPU. Our method, modular low-rank adaptation
(ModuLoRA), integrates any user-specified weight quantizer with finetuning via
low-rank adapters (LoRAs). Our approach relies on a simple
quantization-agnostic backward pass that adaptively materializes low-precision
LLM weights from a custom black-box quantization module. This approach enables
finetuning 3-bit LLMs for the first time--leveraging state-of-the-art 3-bit
OPTQ quantization often outperforms finetuning that relies on less
sophisticated 4-bit and 8-bit methods. In our experiments, ModuLoRA attains
competitive performance on text classification, natural language infernece, and
instruction following tasks using significantly less memory than existing
approaches, and we also surpass the state-of-the-art ROUGE score on a popular
summarization task. We release ModuLoRA together with a series of low-precision
models--including the first family of 3-bit instruction following Alpaca
LLMs--as part of LLMTOOLS, a user-friendly library for quantizing, running, and
finetuning LLMs on consumer GPUs.
</p>
</div>
</dd>
<dt><a name="item92">[92]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16120" title="Abstract">arXiv:2309.16120</a> [<a href="/pdf/2309.16120" title="Download PDF">pdf</a>, <a href="/format/2309.16120" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Test-Case-Driven Programming Understanding in Large Language Models for  Better Code Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tian%2C+Z">Zhao Tian</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Junjie Chen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
<p class="mathjax">Code generation is to automatically generate source code conforming to a
given programming specification, which has received extensive attention
especially with the development of large language models (LLMs). Due to the
inherent difficulty of code generation, the code generated by LLMs may be also
not aligned with the specification. To improve the perfor mance of LLMs in code
generation, some Chain of Thought (CoT) techniques have been proposed to guide
LLMs for programming understanding before code generation. However, they are
still hard to figure out complicated programming logic according to the
(concise) specification, leadingto unsatisfactory code generation performance.
In this work, we propose the first test-case-driven CoT technique, called TCoT,
to further enhance the ability of LLMs in code generation. It understands the
programming specification from the novel perspective of test cases, which is
aligned with human practice by using examples to understand complicated
problems. Due to the existence of the expected output specified in a test case,
TCoT can instantly check the correctness of the programming understanding and
then refine it to be as correct as possible before code generation. In this
way, it is more likely to generate correct code. Our evaluation on 6 datasets
and 14 baselines demonstrates the effectiveness of TCoT. For example, TCoT
improves ChatGPT by 13.93%~69.44% in terms of Pass@1 (measuring the ratio of
programming problems for which the generated code passes all test cases), and
outperforms the existing CoT technique with the improvement of 12.14%~53.72% in
terms of Pass@1.
</p>
</div>
</dd>
<dt><a name="item93">[93]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16126" title="Abstract">arXiv:2309.16126</a> [<a href="/pdf/2309.16126" title="Download PDF">pdf</a>, <a href="/format/2309.16126" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> UVL: A Unified Framework for Video Tampering Localization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pei%2C+P">Pengfei Pei</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+X">Xianfeng Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jinchuan Li</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+Y">Yun Cao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Cryptography and Security (cs.CR)

</div>
<p class="mathjax">With the development of deep learning technology, various forgery methods
emerge endlessly. Meanwhile, methods to detect these fake videos have also
achieved excellent performance on some datasets. However, these methods suffer
from poor generalization to unknown videos and are inefficient for new forgery
methods. To address this challenging problem, we propose UVL, a novel unified
video tampering localization framework for synthesizing forgeries.
Specifically, UVL extracts common features of synthetic forgeries: boundary
artifacts of synthetic edges, unnatural distribution of generated pixels, and
noncorrelation between the forgery region and the original. These features are
widely present in different types of synthetic forgeries and help improve
generalization for detecting unknown videos. Extensive experiments on three
types of synthetic forgery: video inpainting, video splicing and DeepFake show
that the proposed UVL achieves state-of-the-art performance on various
benchmarks and outperforms existing methods by a large margin on cross-dataset.
</p>
</div>
</dd>
<dt><a name="item94">[94]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16127" title="Abstract">arXiv:2309.16127</a> [<a href="/pdf/2309.16127" title="Download PDF">pdf</a>, <a href="/format/2309.16127" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Open Compound Domain Adaptation with Object Style Compensation for  Semantic Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Feng%2C+T">Tingliang Feng</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+H">Hao Shi</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xueyang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+W">Wei Feng</a>, 
<a href="/search/cs?searchtype=author&query=Wan%2C+L">Liang Wan</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Y">Yanlin Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+D">Di Lin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by NeurlPS2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Many methods of semantic image segmentation have borrowed the success of open
compound domain adaptation. They minimize the style gap between the images of
source and target domains, more easily predicting the accurate pseudo
annotations for target domain's images that train segmentation network. The
existing methods globally adapt the scene style of the images, whereas the
object styles of different categories or instances are adapted improperly. This
paper proposes the Object Style Compensation, where we construct the
Object-Level Discrepancy Memory with multiple sets of discrepancy features. The
discrepancy features in a set capture the style changes of the same category's
object instances adapted from target to source domains. We learn the
discrepancy features from the images of source and target domains, storing the
discrepancy features in memory. With this memory, we select appropriate
discrepancy features for compensating the style information of the object
instances of various categories, adapting the object styles to a unified style
of source domain. Our method enables a more accurate computation of the pseudo
annotations for target domain's images, thus yielding state-of-the-art results
on different datasets.
</p>
</div>
</dd>
<dt><a name="item95">[95]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16128" title="Abstract">arXiv:2309.16128</a> [<a href="/pdf/2309.16128" title="Download PDF">pdf</a>, <a href="/format/2309.16128" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Joint Correcting and Refinement for Balanced Low-Light Image Enhancement
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yu%2C+N">Nana Yu</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+H">Hong Shi</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jie Wang</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+Y">Yahong Han</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Image and Video Processing (eess.IV)

</div>
<p class="mathjax">Low-light image enhancement tasks demand an appropriate balance among
brightness, color, and illumination. While existing methods often focus on one
aspect of the image without considering how to pay attention to this balance,
which will cause problems of color distortion and overexposure etc. This
seriously affects both human visual perception and the performance of
high-level visual models. In this work, a novel synergistic structure is
proposed which can balance brightness, color, and illumination more
effectively. Specifically, the proposed method, so-called Joint Correcting and
Refinement Network (JCRNet), which mainly consists of three stages to balance
brightness, color, and illumination of enhancement. Stage 1: we utilize a basic
encoder-decoder and local supervision mechanism to extract local information
and more comprehensive details for enhancement. Stage 2: cross-stage feature
transmission and spatial feature transformation further facilitate color
correction and feature refinement. Stage 3: we employ a dynamic illumination
adjustment approach to embed residuals between predicted and ground truth
images into the model, adaptively adjusting illumination balance. Extensive
experiments demonstrate that the proposed method exhibits comprehensive
performance advantages over 21 state-of-the-art methods on 9 benchmark
datasets. Furthermore, a more persuasive experiment has been conducted to
validate our approach the effectiveness in downstream visual tasks (e.g.,
saliency detection). Compared to several enhancement models, the proposed
method effectively improves the segmentation results and quantitative metrics
of saliency detection. The source code will be available at
https://github.com/woshiyll/JCRNet.
</p>
</div>
</dd>
<dt><a name="item96">[96]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16131" title="Abstract">arXiv:2309.16131</a> [<a href="/pdf/2309.16131" title="Download PDF">pdf</a>, <a href="/ps/2309.16131" title="Download PostScript">ps</a>, <a href="/format/2309.16131" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Spectral Approach for Learning Spatiotemporal Neural Differential  Equations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xia%2C+M">Mingtao Xia</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xiangting Li</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+Q">Qijing Shen</a>, 
<a href="/search/cs?searchtype=author&query=Chou%2C+T">Tom Chou</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 21 pages, 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Neural and Evolutionary Computing (cs.NE); Spectral Theory (math.SP)

</div>
<p class="mathjax">Rapidly developing machine learning methods has stimulated research interest
in computationally reconstructing differential equations (DEs) from
observational data which may provide additional insight into underlying
causative mechanisms. In this paper, we propose a novel neural-ODE based method
that uses spectral expansions in space to learn spatiotemporal DEs. The major
advantage of our spectral neural DE learning approach is that it does not rely
on spatial discretization, thus allowing the target spatiotemporal equations to
contain long range, nonlocal spatial interactions that act on unbounded spatial
domains. Our spectral approach is shown to be as accurate as some of the latest
machine learning approaches for learning PDEs operating on bounded domains. By
developing a spectral framework for learning both PDEs and integro-differential
equations, we extend machine learning methods to apply to unbounded DEs and a
larger class of problems.
</p>
</div>
</dd>
<dt><a name="item97">[97]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16133" title="Abstract">arXiv:2309.16133</a> [<a href="/pdf/2309.16133" title="Download PDF">pdf</a>, <a href="/format/2309.16133" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MASK4D: Mask Transformer for 4D Panoptic Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yilmaz%2C+K">Kadir Yilmaz</a>, 
<a href="/search/cs?searchtype=author&query=Schult%2C+J">Jonas Schult</a>, 
<a href="/search/cs?searchtype=author&query=Nekrasov%2C+A">Alexey Nekrasov</a>, 
<a href="/search/cs?searchtype=author&query=Leibe%2C+B">Bastian Leibe</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project page: <a href="https://vision.rwth-aachen.de/mask4d">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Accurately perceiving and tracking instances over time is essential for the
decision-making processes of autonomous agents interacting safely in dynamic
environments. With this intention, we propose Mask4D for the challenging task
of 4D panoptic segmentation of LiDAR point clouds. Mask4D is the first
transformer-based approach unifying semantic instance segmentation and tracking
of sparse and irregular sequences of 3D point clouds into a single joint model.
Our model directly predicts semantic instances and their temporal associations
without relying on any hand-crafted non-learned association strategies such as
probabilistic clustering or voting-based center prediction. Instead, Mask4D
introduces spatio-temporal instance queries which encode the semantic and
geometric properties of each semantic tracklet in the sequence. In an in-depth
study, we find that it is critical to promote spatially compact instance
predictions as spatio-temporal instance queries tend to merge multiple
semantically similar instances, even if they are spatially distant. To this
end, we regress 6-DOF bounding box parameters from spatio-temporal instance
queries, which is used as an auxiliary task to foster spatially compact
predictions. Mask4D achieves a new state-of-the-art on the SemanticKITTI test
set with a score of 68.4 LSTQ, improving upon published top-performing methods
by at least +4.5%.
</p>
</div>
</dd>
<dt><a name="item98">[98]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16134" title="Abstract">arXiv:2309.16134</a> [<a href="/pdf/2309.16134" title="Download PDF">pdf</a>, <a href="/format/2309.16134" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Let&#x27;s Chat to Find the APIs: Connecting Human, LLM and Knowledge Graph  through AI Chain
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+Q">Qing Huang</a>, 
<a href="/search/cs?searchtype=author&query=Wan%2C+Z">Zhenyu Wan</a>, 
<a href="/search/cs?searchtype=author&query=Xing%2C+Z">Zhenchang Xing</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+C">Changjing Wang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Jieshan Chen</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+X">Xiwei Xu</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+Q">Qinghua Lu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted on ASE'2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
<p class="mathjax">API recommendation methods have evolved from literal and semantic keyword
matching to query expansion and query clarification. The latest query
clarification method is knowledge graph (KG)-based, but limitations include
out-of-vocabulary (OOV) failures and rigid question templates. To address these
limitations, we propose a novel knowledge-guided query clarification approach
for API recommendation that leverages a large language model (LLM) guided by
KG. We utilize the LLM as a neural knowledge base to overcome OOV failures,
generating fluent and appropriate clarification questions and options. We also
leverage the structured API knowledge and entity relationships stored in the KG
to filter out noise, and transfer the optimal clarification path from KG to the
LLM, increasing the efficiency of the clarification process. Our approach is
designed as an AI chain that consists of five steps, each handled by a separate
LLM call, to improve accuracy, efficiency, and fluency for query clarification
in API recommendation. We verify the usefulness of each unit in our AI chain,
which all received high scores close to a perfect 5. When compared to the
baselines, our approach shows a significant improvement in MRR, with a maximum
increase of 63.9% higher when the query statement is covered in KG and 37.2%
when it is not. Ablation experiments reveal that the guidance of knowledge in
the KG and the knowledge-guided pathfinding strategy are crucial for our
approach's performance, resulting in a 19.0% and 22.2% increase in MAP,
respectively. Our approach demonstrates a way to bridge the gap between KG and
LLM, effectively compensating for the strengths and weaknesses of both.
</p>
</div>
</dd>
<dt><a name="item99">[99]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16135" title="Abstract">arXiv:2309.16135</a> [<a href="/pdf/2309.16135" title="Download PDF">pdf</a>, <a href="/format/2309.16135" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A dual-branch model with inter- and intra-branch contrastive loss for  long-tailed recognition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+Q">Qiong Chen</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+T">Tianlin Huang</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+G">Geren Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+E">Enlu Lin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Published at Neural Networks
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Neural Networks 168, 214-222 (2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Real-world data often exhibits a long-tailed distribution, in which head
classes occupy most of the data, while tail classes only have very few samples.
Models trained on long-tailed datasets have poor adaptability to tail classes
and the decision boundaries are ambiguous. Therefore, in this paper, we propose
a simple yet effective model, named Dual-Branch Long-Tailed Recognition
(DB-LTR), which includes an imbalanced learning branch and a Contrastive
Learning Branch (CoLB). The imbalanced learning branch, which consists of a
shared backbone and a linear classifier, leverages common imbalanced learning
approaches to tackle the data imbalance issue. In CoLB, we learn a prototype
for each tail class, and calculate an inter-branch contrastive loss, an
intra-branch contrastive loss and a metric loss. CoLB can improve the
capability of the model in adapting to tail classes and assist the imbalanced
learning branch to learn a well-represented feature space and discriminative
decision boundary. Extensive experiments on three long-tailed benchmark
datasets, i.e., CIFAR100-LT, ImageNet-LT and Places-LT, show that our DB-LTR is
competitive and superior to the comparative methods.
</p>
</div>
</dd>
<dt><a name="item100">[100]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16137" title="Abstract">arXiv:2309.16137</a> [<a href="/pdf/2309.16137" title="Download PDF">pdf</a>, <a href="/format/2309.16137" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Context-I2W: Mapping Images to Context-dependent Words for Accurate  Zero-Shot Composed Image Retrieval
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tang%2C+Y">Yuanmin Tang</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+J">Jing Yu</a>, 
<a href="/search/cs?searchtype=author&query=Gai%2C+K">Keke Gai</a>, 
<a href="/search/cs?searchtype=author&query=Jiamin%2C+Z">Zhuang Jiamin</a>, 
<a href="/search/cs?searchtype=author&query=Xiong%2C+G">Gang Xiong</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+Y">Yue Hu</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Q">Qi Wu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Different from Composed Image Retrieval task that requires expensive labels
for training task-specific models, Zero-Shot Composed Image Retrieval (ZS-CIR)
involves diverse tasks with a broad range of visual content manipulation intent
that could be related to domain, scene, object, and attribute. The key
challenge for ZS-CIR tasks is to learn a more accurate image representation
that has adaptive attention to the reference image for various manipulation
descriptions. In this paper, we propose a novel context-dependent mapping
network, named Context-I2W, for adaptively converting description-relevant
Image information into a pseudo-word token composed of the description for
accurate ZS-CIR. Specifically, an Intent View Selector first dynamically learns
a rotation rule to map the identical image to a task-specific manipulation
view. Then a Visual Target Extractor further captures local information
covering the main targets in ZS-CIR tasks under the guidance of multiple
learnable queries. The two complementary modules work together to map an image
to a context-dependent pseudo-word token without extra supervision. Our model
shows strong generalization ability on four ZS-CIR tasks, including domain
conversion, object composition, object manipulation, and attribute
manipulation. It obtains consistent and significant performance boosts ranging
from 1.88% to 3.60% over the best methods and achieves new state-of-the-art
results on ZS-CIR. Our code is available at
https://github.com/Pter61/context_i2w.
</p>
</div>
</dd>
<dt><a name="item101">[101]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16139" title="Abstract">arXiv:2309.16139</a> [<a href="/pdf/2309.16139" title="Download PDF">pdf</a>, <a href="/format/2309.16139" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Two-Step Active Learning for Instance Segmentation with Uncertainty and  Diversity Sampling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yu%2C+K">Ke Yu</a>, 
<a href="/search/cs?searchtype=author&query=Albro%2C+S">Stephen Albro</a>, 
<a href="/search/cs?searchtype=author&query=DeSalvo%2C+G">Giulia DeSalvo</a>, 
<a href="/search/cs?searchtype=author&query=Kothawade%2C+S">Suraj Kothawade</a>, 
<a href="/search/cs?searchtype=author&query=Rashwan%2C+A">Abdullah Rashwan</a>, 
<a href="/search/cs?searchtype=author&query=Tavakkol%2C+S">Sasan Tavakkol</a>, 
<a href="/search/cs?searchtype=author&query=Batmanghelich%2C+K">Kayhan Batmanghelich</a>, 
<a href="/search/cs?searchtype=author&query=Yin%2C+X">Xiaoqi Yin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> UNCV ICCV 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Training high-quality instance segmentation models requires an abundance of
labeled images with instance masks and classifications, which is often
expensive to procure. Active learning addresses this challenge by striving for
optimum performance with minimal labeling cost by selecting the most
informative and representative images for labeling. Despite its potential,
active learning has been less explored in instance segmentation compared to
other tasks like image classification, which require less labeling. In this
study, we propose a post-hoc active learning algorithm that integrates
uncertainty-based sampling with diversity-based sampling. Our proposed
algorithm is not only simple and easy to implement, but it also delivers
superior performance on various datasets. Its practical application is
demonstrated on a real-world overhead imagery dataset, where it increases the
labeling efficiency fivefold.
</p>
</div>
</dd>
<dt><a name="item102">[102]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16140" title="Abstract">arXiv:2309.16140</a> [<a href="/pdf/2309.16140" title="Download PDF">pdf</a>, <a href="/format/2309.16140" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CLIP-Hand3D: Exploiting 3D Hand Pose Estimation via Context-Aware  Prompting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Guo%2C+S">Shaoxiang Guo</a>, 
<a href="/search/cs?searchtype=author&query=Cai%2C+Q">Qing Cai</a>, 
<a href="/search/cs?searchtype=author&query=Qi%2C+L">Lin Qi</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+J">Junyu Dong</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted In Proceedings of the 31st ACM International Conference on Multimedia (MM' 23)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Multimedia (cs.MM)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Contrastive Language-Image Pre-training (CLIP) starts to emerge in many
computer vision tasks and has achieved promising performance. However, it
remains underexplored whether CLIP can be generalized to 3D hand pose
estimation, as bridging text prompts with pose-aware features presents
significant challenges due to the discrete nature of joint positions in 3D
space. In this paper, we make one of the first attempts to propose a novel 3D
hand pose estimator from monocular images, dubbed as CLIP-Hand3D, which
successfully bridges the gap between text prompts and irregular detailed pose
distribution. In particular, the distribution order of hand joints in various
3D space directions is derived from pose labels, forming corresponding text
prompts that are subsequently encoded into text representations.
Simultaneously, 21 hand joints in the 3D space are retrieved, and their spatial
distribution (in x, y, and z axes) is encoded to form pose-aware features.
Subsequently, we maximize semantic consistency for a pair of pose-text features
following a CLIP-based contrastive learning paradigm. Furthermore, a
coarse-to-fine mesh regressor is designed, which is capable of effectively
querying joint-aware cues from the feature pyramid. Extensive experiments on
several public hand benchmarks show that the proposed model attains a
significantly faster inference speed while achieving state-of-the-art
performance compared to methods utilizing the similar scale backbone.
</p>
</div>
</dd>
<dt><a name="item103">[103]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16141" title="Abstract">arXiv:2309.16141</a> [<a href="/pdf/2309.16141" title="Download PDF">pdf</a>, <a href="/format/2309.16141" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Align before Search: Aligning Ads Image to Text for Accurate Cross-Modal  Sponsored Search
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tang%2C+Y">Yuanmin Tang</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+J">Jing Yu</a>, 
<a href="/search/cs?searchtype=author&query=Gai%2C+K">Keke Gai</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yujing Wang</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+Y">Yue Hu</a>, 
<a href="/search/cs?searchtype=author&query=Xiong%2C+G">Gang Xiong</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Q">Qi Wu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Cross-Modal sponsored search displays multi-modal advertisements (ads) when
consumers look for desired products by natural language queries in search
engines. Since multi-modal ads bring complementary details for query-ads
matching, the ability to align ads-specific information in both images and
texts is crucial for accurate and flexible sponsored search. Conventional
research mainly studies from the view of modeling the implicit correlations
between images and texts for query-ads matching, ignoring the alignment of
detailed product information and resulting in suboptimal search performance.In
this work, we propose a simple alignment network for explicitly mapping
fine-grained visual parts in ads images to the corresponding text, which
leverages the co-occurrence structure consistency between vision and language
spaces without requiring expensive labeled training data. Moreover, we propose
a novel model for cross-modal sponsored search that effectively conducts the
cross-modal alignment and query-ads matching in two separate processes. In this
way, the model matches the multi-modal input in the same language space,
resulting in a superior performance with merely half of the training data. Our
model outperforms the state-of-the-art models by 2.57% on a large commercial
dataset. Besides sponsored search, our alignment method is applicable for
general cross-modal search. We study a typical cross-modal retrieval task on
the MSCOCO dataset, which achieves consistent performance improvement and
proves the generalization ability of our method. Our code is available at
https://github.com/Pter61/AlignCMSS/
</p>
</div>
</dd>
<dt><a name="item104">[104]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16143" title="Abstract">arXiv:2309.16143</a> [<a href="/pdf/2309.16143" title="Download PDF">pdf</a>, <a href="/format/2309.16143" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Generative Semi-supervised Learning with Meta-Optimized Synthetic  Samples
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yamaguchi%2C+S">Shin&#x27;ya Yamaguchi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to the 15th Asian Conference on Machine Learning (ACML2023); a preprint of the camera-ready version
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV); Machine Learning (stat.ML)

</div>
<p class="mathjax">Semi-supervised learning (SSL) is a promising approach for training deep
classification models using labeled and unlabeled datasets. However, existing
SSL methods rely on a large unlabeled dataset, which may not always be
available in many real-world applications due to legal constraints (e.g.,
GDPR). In this paper, we investigate the research question: Can we train SSL
models without real unlabeled datasets? Instead of using real unlabeled
datasets, we propose an SSL method using synthetic datasets generated from
generative foundation models trained on datasets containing millions of samples
in diverse domains (e.g., ImageNet). Our main concepts are identifying
synthetic samples that emulate unlabeled samples from generative foundation
models and training classifiers using these synthetic samples. To achieve this,
our method is formulated as an alternating optimization problem: (i)
meta-learning of generative foundation models and (ii) SSL of classifiers using
real labeled and synthetic unlabeled samples. For (i), we propose a
meta-learning objective that optimizes latent variables to generate samples
that resemble real labeled samples and minimize the validation loss. For (ii),
we propose a simple unsupervised loss function that regularizes the feature
extractors of classifiers to maximize the performance improvement obtained from
synthetic samples. We confirm that our method outperforms baselines using
generative foundation models on SSL. We also demonstrate that our methods
outperform SSL using real unlabeled datasets in scenarios with extremely small
amounts of labeled datasets. This suggests that synthetic samples have the
potential to provide improvement gains more efficiently than real unlabeled
data.
</p>
</div>
</dd>
<dt><a name="item105">[105]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16144" title="Abstract">arXiv:2309.16144</a> [<a href="/pdf/2309.16144" title="Download PDF">pdf</a>, <a href="/format/2309.16144" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Scalable Exact Output Synchronization of Discrete-Time Multi-Agent  Systems in the Presence of Disturbances and Measurement Noise With Known  Frequencies
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Liu%2C+Z">Zhenwei Liu</a>, 
<a href="/search/eess?searchtype=author&query=Zhang%2C+M">Meirong Zhang</a>, 
<a href="/search/eess?searchtype=author&query=Saberi%2C+A">Ali Saberi</a>, 
<a href="/search/eess?searchtype=author&query=Stoorvogel%2C+A+A">Anton A. Stoorvogel</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This paper was submitted to International Journal of Robust and Nonlinear Control at Feb. 19, 2023, and obtained the recommendation of "resubmitting" at Aug. 23, 2023. Now, the authors are in the process of revising based on comments from the Referees
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">This paper aims to achieve scalable exact output and regulated output
synchronization for discrete-time multi-agent systems in presence of
disturbances and measurement noise with known frequencies. Both homogeneous and
heterogeneous multi-agent systems are considered, with parts of agents' states
accessible in the latter case. The key contribution of this paper is on the
distributed protocol that only uses the information of agent models, rather
than the communication network information and the agent number, so as to
achieve the scalable exact synchronization under disturbances and measurement
noise. The validity of the protocol is verified by numerical simulations with
arbitrarily chosen number of agents.
</p>
</div>
</dd>
<dt><a name="item106">[106]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16145" title="Abstract">arXiv:2309.16145</a> [<a href="/pdf/2309.16145" title="Download PDF">pdf</a>, <a href="/format/2309.16145" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Confidence-Competence Gap in Large Language Models: A Cognitive  Study
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Singh%2C+A+K">Aniket Kumar Singh</a>, 
<a href="/search/cs?searchtype=author&query=Devkota%2C+S">Suman Devkota</a>, 
<a href="/search/cs?searchtype=author&query=Lamichhane%2C+B">Bishal Lamichhane</a>, 
<a href="/search/cs?searchtype=author&query=Dhakal%2C+U">Uttam Dhakal</a>, 
<a href="/search/cs?searchtype=author&query=Dhakal%2C+C">Chandra Dhakal</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 19 pages, 8 Figures, to be published in a journal (Journal TBD), All Authors contributed equally and were Supervised by Chandra Dhakal
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Computers and Society (cs.CY); Human-Computer Interaction (cs.HC)

</div>
<p class="mathjax">Large Language Models (LLMs) have acquired ubiquitous attention for their
performances across diverse domains. Our study here searches through LLMs'
cognitive abilities and confidence dynamics. We dive deep into understanding
the alignment between their self-assessed confidence and actual performance. We
exploit these models with diverse sets of questionnaires and real-world
scenarios and extract how LLMs exhibit confidence in their responses. Our
findings reveal intriguing instances where models demonstrate high confidence
even when they answer incorrectly. This is reminiscent of the Dunning-Kruger
effect observed in human psychology. In contrast, there are cases where models
exhibit low confidence with correct answers revealing potential underestimation
biases. Our results underscore the need for a deeper understanding of their
cognitive processes. By examining the nuances of LLMs' self-assessment
mechanism, this investigation provides noteworthy revelations that serve to
advance the functionalities and broaden the potential applications of these
formidable language models.
</p>
</div>
</dd>
<dt><a name="item107">[107]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16146" title="Abstract">arXiv:2309.16146</a> [<a href="/pdf/2309.16146" title="Download PDF">pdf</a>, <a href="/format/2309.16146" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> T-COL: Generating Counterfactual Explanations for General User  Preferences on Variable Machine Learning Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+M">Ming Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+D">Daling Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+W">Wenfang Wu</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+S">Shi Feng</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yifei Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
<p class="mathjax">Machine learning (ML) based systems have been suffering a lack of
interpretability. To address this problem, counterfactual explanations (CEs)
have been proposed. CEs are unique as they provide workable suggestions to
users, in addition to explaining why a certain outcome was predicted. However,
the application of CEs has been hindered by two main challenges, namely general
user preferences and variable ML systems. User preferences, in particular, tend
to be general rather than specific feature values. Additionally, CEs need to be
customized to suit the variability of ML models, while also maintaining
robustness even when these validation models change. To overcome these
challenges, we propose several possible general user preferences that have been
validated by user research and map them to the properties of CEs. We also
introduce a new method called \uline{T}ree-based \uline{C}onditions
\uline{O}ptional \uline{L}inks (T-COL), which has two optional structures and
several groups of conditions for generating CEs that can be adapted to general
user preferences. Meanwhile, a group of conditions lead T-COL to generate more
robust CEs that have higher validity when the ML model is replaced. We compared
the properties of CEs generated by T-COL experimentally under different user
preferences and demonstrated that T-COL is better suited for accommodating user
preferences and variable ML systems compared to baseline methods including
Large Language Models.
</p>
</div>
</dd>
<dt><a name="item108">[108]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16148" title="Abstract">arXiv:2309.16148</a> [<a href="/pdf/2309.16148" title="Download PDF">pdf</a>, <a href="/format/2309.16148" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> OSM-Net: One-to-Many One-shot Talking Head Generation with Spontaneous  Head Motions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jin Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xi Wang</a>, 
<a href="/search/cs?searchtype=author&query=Fu%2C+X">Xiaomeng Fu</a>, 
<a href="/search/cs?searchtype=author&query=Chai%2C+Y">Yesheng Chai</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+C">Cai Yu</a>, 
<a href="/search/cs?searchtype=author&query=Dai%2C+J">Jiao Dai</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+J">Jizhong Han</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Paper Under Review
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">One-shot talking head generation has no explicit head movement reference,
thus it is difficult to generate talking heads with head motions. Some existing
works only edit the mouth area and generate still talking heads, leading to
unreal talking head performance. Other works construct one-to-one mapping
between audio signal and head motion sequences, introducing ambiguity
correspondences into the mapping since people can behave differently in head
motions when speaking the same content. This unreasonable mapping form fails to
model the diversity and produces either nearly static or even exaggerated head
motions, which are unnatural and strange. Therefore, the one-shot talking head
generation task is actually a one-to-many ill-posed problem and people present
diverse head motions when speaking. Based on the above observation, we propose
OSM-Net, a \textit{one-to-many} one-shot talking head generation network with
natural head motions. OSM-Net constructs a motion space that contains rich and
various clip-level head motion features. Each basis of the space represents a
feature of meaningful head motion in a clip rather than just a frame, thus
providing more coherent and natural motion changes in talking heads. The
driving audio is mapped into the motion space, around which various motion
features can be sampled within a reasonable range to achieve the one-to-many
mapping. Besides, the landmark constraint and time window feature input improve
the accurate expression feature extraction and video generation. Extensive
experiments show that OSM-Net generates more natural realistic head motions
under reasonable one-to-many mapping paradigm compared with other methods.
</p>
</div>
</dd>
<dt><a name="item109">[109]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16150" title="Abstract">arXiv:2309.16150</a> [<a href="/pdf/2309.16150" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AE-GPT: Using Large Language Models to Extract Adverse Events from  Surveillance Reports-A Use Case with Influenza Vaccine Adverse Events
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yiming Li</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jianfu Li</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+J">Jianping He</a>, 
<a href="/search/cs?searchtype=author&query=Tao%2C+C">Cui Tao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Though Vaccines are instrumental in global health, mitigating infectious
diseases and pandemic outbreaks, they can occasionally lead to adverse events
(AEs). Recently, Large Language Models (LLMs) have shown promise in effectively
identifying and cataloging AEs within clinical reports. Utilizing data from the
Vaccine Adverse Event Reporting System (VAERS) from 1990 to 2016, this study
particularly focuses on AEs to evaluate LLMs' capability for AE extraction. A
variety of prevalent LLMs, including GPT-2, GPT-3 variants, GPT-4, and Llama 2,
were evaluated using Influenza vaccine as a use case. The fine-tuned GPT 3.5
model (AE-GPT) stood out with a 0.704 averaged micro F1 score for strict match
and 0.816 for relaxed match. The encouraging performance of the AE-GPT
underscores LLMs' potential in processing medical data, indicating a
significant stride towards advanced AE detection, thus presumably generalizable
to other AE extraction tasks.
</p>
</div>
</dd>
<dt><a name="item110">[110]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16155" title="Abstract">arXiv:2309.16155</a> [<a href="/pdf/2309.16155" title="Download PDF">pdf</a>, <a href="/format/2309.16155" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Trickle-down Impact of Reward (In-)consistency on RLHF
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shen%2C+L">Lingfeng Shen</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+S">Sihao Chen</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+L">Linfeng Song</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+L">Lifeng Jin</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+B">Baolin Peng</a>, 
<a href="/search/cs?searchtype=author&query=Mi%2C+H">Haitao Mi</a>, 
<a href="/search/cs?searchtype=author&query=Khashabi%2C+D">Daniel Khashabi</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+D">Dong Yu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Standard practice within Reinforcement Learning from Human Feedback (RLHF)
involves optimizing against a Reward Model (RM), which itself is trained to
reflect human preferences for desirable generations. A notable subject that is
understudied is the (in-)consistency of RMs -- whether they can recognize the
semantic changes to different prompts and appropriately adapt their reward
assignments -- and their impact on the downstream RLHF model.
<br />In this paper, we visit a series of research questions relevant to RM
inconsistency: (1) How can we measure the consistency of reward models? (2) How
consistent are the existing RMs and how can we improve them? (3) In what ways
does reward inconsistency influence the chatbots resulting from the RLHF model
training?
<br />We propose Contrast Instructions -- a benchmarking strategy for the
consistency of RM. Each example in Contrast Instructions features a pair of
lexically similar instructions with different ground truth responses. A
consistent RM is expected to rank the corresponding instruction and response
higher than other combinations. We observe that current RMs trained with the
standard ranking objective fail miserably on Contrast Instructions compared to
average humans. To show that RM consistency can be improved efficiently without
using extra training budget, we propose two techniques ConvexDA and
RewardFusion, which enhance reward consistency through extrapolation during the
RM training and inference stage, respectively. We show that RLHF models trained
with a more consistent RM yield more useful responses, suggesting that reward
inconsistency exhibits a trickle-down effect on the downstream RLHF process.
</p>
</div>
</dd>
<dt><a name="item111">[111]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16157" title="Abstract">arXiv:2309.16157</a> [<a href="/pdf/2309.16157" title="Download PDF">pdf</a>, <a href="/format/2309.16157" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Sampling Methods for Inner Product Sketching
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Daliri%2C+M">Majid Daliri</a>, 
<a href="/search/cs?searchtype=author&query=Freire%2C+J">Juliana Freire</a>, 
<a href="/search/cs?searchtype=author&query=Musco%2C+C">Christopher Musco</a>, 
<a href="/search/cs?searchtype=author&query=Santos%2C+A">A&#xe9;cio Santos</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Haoxiang Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Databases (cs.DB)</span>; Data Structures and Algorithms (cs.DS)

</div>
<p class="mathjax">Recently, Bessa et al. (PODS 2023) showed that sketches based on coordinated
weighted sampling theoretically and empirically outperform popular linear
sketching methods like Johnson-Lindentrauss projection and CountSketch for the
ubiquitous problem of inner product estimation. Despite decades of literature
on such sampling methods, this observation seems to have been overlooked. We
further develop the finding by presenting and analyzing two alternative
sampling-based inner product sketching methods. In contrast to the
computationally expensive algorithm in Bessa et al., our methods run in linear
time (to compute the sketch) and perform better in practice, significantly
beating linear sketching on a variety of tasks. For example, they provide
state-of-the-art results for estimating the correlation between columns in
unjoined tables, a problem that we show how to reduce to inner product
estimation in a black-box way. While based on known sampling techniques
(threshold and priority sampling) we introduce significant new theoretical
analysis to prove approximation guarantees for our methods.
</p>
</div>
</dd>
<dt><a name="item112">[112]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16158" title="Abstract">arXiv:2309.16158</a> [<a href="/pdf/2309.16158" title="Download PDF">pdf</a>, <a href="/format/2309.16158" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FireFly v2: Advancing Hardware Support for High-Performance Spiking  Neural Network with a Spatiotemporal FPGA Accelerator
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jindong Li</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+G">Guobin Shen</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+D">Dongcheng Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Q">Qian Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zeng%2C+Y">Yi Zeng</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neural and Evolutionary Computing (cs.NE)</span>; Hardware Architecture (cs.AR)

</div>
<p class="mathjax">Spiking Neural Networks (SNNs) are expected to be a promising alternative to
Artificial Neural Networks (ANNs) due to their strong biological
interpretability and high energy efficiency. Specialized SNN hardware offers
clear advantages over general-purpose devices in terms of power and
performance. However, there's still room to advance hardware support for
state-of-the-art (SOTA) SNN algorithms and improve computation and memory
efficiency. As a further step in supporting high-performance SNNs on
specialized hardware, we introduce FireFly v2, an FPGA SNN accelerator that can
address the issue of non-spike operation in current SOTA SNN algorithms, which
presents an obstacle in the end-to-end deployment onto existing SNN hardware.
To more effectively align with the SNN characteristics, we design a
spatiotemporal dataflow that allows four dimensions of parallelism and
eliminates the need for membrane potential storage, enabling on-the-fly spike
processing and spike generation. To further improve hardware acceleration
performance, we develop a high-performance spike computing engine as a backend
based on a systolic array operating at 500-600MHz. To the best of our
knowledge, FireFly v2 achieves the highest clock frequency among all FPGA-based
implementations. Furthermore, it stands as the first SNN accelerator capable of
supporting non-spike operations, which are commonly used in advanced SNN
algorithms. FireFly v2 has doubled the throughput and DSP efficiency when
compared to our previous version of FireFly and it exhibits 1.33 times the DSP
efficiency and 1.42 times the power efficiency compared to the current most
advanced FPGA accelerators.
</p>
</div>
</dd>
<dt><a name="item113">[113]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16159" title="Abstract">arXiv:2309.16159</a> [<a href="/pdf/2309.16159" title="Download PDF">pdf</a>, <a href="/format/2309.16159" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Adaptive Real-Time Numerical Differentiation with Variable-Rate  Forgetting and Exponential Resetting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Verma%2C+S">Shashank Verma</a>, 
<a href="/search/eess?searchtype=author&query=Lai%2C+B">Brian Lai</a>, 
<a href="/search/eess?searchtype=author&query=Bernstein%2C+D+S">Dennis S. Bernstein</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">Digital PID control requires a differencing operation to implement the D
gain. In order to suppress the effects of noisy data, the traditional approach
is to filter the data, where the frequency response of the filter is adjusted
manually based on the characteristics of the sensor noise. The present paper
considers the case where the characteristics of the sensor noise change over
time in an unknown way. This problem is addressed by applying adaptive
real-time numerical differentiation based on adaptive input and state
estimation (AISE). The contribution of this paper is to extend AISE to include
variable-rate forgetting with exponential resetting, which allows AISE to more
rapidly respond to changing noise characteristics while enforcing the
boundedness of the covariance matrix used in recursive least squares.
</p>
</div>
</dd>
<dt><a name="item114">[114]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16161" title="Abstract">arXiv:2309.16161</a> [<a href="/pdf/2309.16161" title="Download PDF">pdf</a>, <a href="/format/2309.16161" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Leveraging Untrustworthy Commands for Multi-Robot Coordination in  Unpredictable Environments: A Bandit Submodular Maximization Approach
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Xu%2C+Z">Zirui Xu</a>, 
<a href="/search/eess?searchtype=author&query=Lin%2C+X">Xiaofeng Lin</a>, 
<a href="/search/eess?searchtype=author&query=Tzoumas%2C+V">Vasileios Tzoumas</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: text overlap with <a href="/abs/2305.12795">arXiv:2305.12795</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Artificial Intelligence (cs.AI); Multiagent Systems (cs.MA); Robotics (cs.RO); Optimization and Control (math.OC)

</div>
<p class="mathjax">We study the problem of multi-agent coordination in unpredictable and
partially-observable environments with untrustworthy external commands. The
commands are actions suggested to the robots, and are untrustworthy in that
their performance guarantees, if any, are unknown. Such commands may be
generated by human operators or machine learning algorithms and, although
untrustworthy, can often increase the robots' performance in complex
multi-robot tasks. We are motivated by complex multi-robot tasks such as target
tracking, environmental mapping, and area monitoring. Such tasks are often
modeled as submodular maximization problems due to the information overlap
among the robots. We provide an algorithm, Meta Bandit Sequential Greedy
(MetaBSG), which enjoys performance guarantees even when the external commands
are arbitrarily bad. MetaBSG leverages a meta-algorithm to learn whether the
robots should follow the commands or a recently developed submodular
coordination algorithm, Bandit Sequential Greedy (BSG) [1], which has
performance guarantees even in unpredictable and partially-observable
environments. Particularly, MetaBSG asymptotically can achieve the better
performance out of the commands and the BSG algorithm, quantifying its
suboptimality against the optimal time-varying multi-robot actions in
hindsight. Thus, MetaBSG can be interpreted as robustifying the untrustworthy
commands. We validate our algorithm in simulated scenarios of multi-target
tracking.
</p>
</div>
</dd>
<dt><a name="item115">[115]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16162" title="Abstract">arXiv:2309.16162</a> [<a href="/pdf/2309.16162" title="Download PDF">pdf</a>, <a href="/format/2309.16162" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ACT2G: Attention-based Contrastive Learning for Text-to-Gesture  Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Teshima%2C+H">Hitoshi Teshima</a>, 
<a href="/search/cs?searchtype=author&query=Wake%2C+N">Naoki Wake</a>, 
<a href="/search/cs?searchtype=author&query=Thomas%2C+D">Diego Thomas</a>, 
<a href="/search/cs?searchtype=author&query=Nakashima%2C+Y">Yuta Nakashima</a>, 
<a href="/search/cs?searchtype=author&query=Kawasaki%2C+H">Hiroshi Kawasaki</a>, 
<a href="/search/cs?searchtype=author&query=Ikeuchi%2C+K">Katsushi Ikeuchi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">Recent increase of remote-work, online meeting and tele-operation task makes
people find that gesture for avatars and communication robots is more important
than we have thought. It is one of the key factors to achieve smooth and
natural communication between humans and AI systems and has been intensively
researched. Current gesture generation methods are mostly based on deep neural
network using text, audio and other information as the input, however, they
generate gestures mainly based on audio, which is called a beat gesture.
Although the ratio of the beat gesture is more than 70% of actual human
gestures, content based gestures sometimes play an important role to make
avatars more realistic and human-like. In this paper, we propose a
attention-based contrastive learning for text-to-gesture (ACT2G), where
generated gestures represent content of the text by estimating attention weight
for each word from the input text. In the method, since text and gesture
features calculated by the attention weight are mapped to the same latent space
by contrastive learning, once text is given as input, the network outputs a
feature vector which can be used to generate gestures related to the content.
User study confirmed that the gestures generated by ACT2G were better than
existing methods. In addition, it was demonstrated that wide variation of
gestures were generated from the same text by changing attention weights by
creators.
</p>
</div>
</dd>
<dt><a name="item116">[116]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16163" title="Abstract">arXiv:2309.16163</a> [<a href="/pdf/2309.16163" title="Download PDF">pdf</a>, <a href="/format/2309.16163" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Doppler Time-of-Flight Rendering
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kim%2C+J">Juhyeon Kim</a>, 
<a href="/search/cs?searchtype=author&query=Jarosz%2C+W">Wojciech Jarosz</a>, 
<a href="/search/cs?searchtype=author&query=Gkioulekas%2C+I">Ioannis Gkioulekas</a>, 
<a href="/search/cs?searchtype=author&query=Pediredla%2C+A">Adithya Pediredla</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 18 pages, 28 Figures, SIGGRAPH Asia 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Graphics (cs.GR)</span>

</div>
<p class="mathjax">We introduce Doppler time-of-flight (D-ToF) rendering, an extension of ToF
rendering for dynamic scenes, with applications in simulating D-ToF cameras.
D-ToF cameras use high-frequency modulation of illumination and exposure, and
measure the Doppler frequency shift to compute the radial velocity of dynamic
objects. The time-varying scene geometry and high-frequency modulation
functions used in such cameras make it challenging to accurately and
efficiently simulate their measurements with existing ToF rendering algorithms.
We overcome these challenges in a twofold manner: To achieve accuracy, we
derive path integral expressions for D-ToF measurements under global
illumination and form unbiased Monte Carlo estimates of these integrals. To
achieve efficiency, we develop a tailored time-path sampling technique that
combines antithetic time sampling with correlated path sampling. We show
experimentally that our sampling technique achieves up to two orders of
magnitude lower variance compared to naive time-path sampling. We provide an
open-source simulator that serves as a digital twin for D-ToF imaging systems,
allowing imaging researchers, for the first time, to investigate the impact of
modulation functions, material properties, and global illumination on D-ToF
imaging performance.
</p>
</div>
</dd>
<dt><a name="item117">[117]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16164" title="Abstract">arXiv:2309.16164</a> [<a href="/pdf/2309.16164" title="Download PDF">pdf</a>, <a href="/format/2309.16164" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning to Terminate in Object Navigation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Song%2C+Y">Yuhang Song</a>, 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+A">Anh Nguyen</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+C">Chun-Yi Lee</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">This paper tackles the critical challenge of object navigation in autonomous
navigation systems, particularly focusing on the problem of target approach and
episode termination in environments with long optimal episode length in Deep
Reinforcement Learning (DRL) based methods. While effective in environment
exploration and object localization, conventional DRL methods often struggle
with optimal path planning and termination recognition due to a lack of depth
information. To overcome these limitations, we propose a novel approach, namely
the Depth-Inference Termination Agent (DITA), which incorporates a supervised
model called the Judge Model to implicitly infer object-wise depth and decide
termination jointly with reinforcement learning. We train our judge model along
with reinforcement learning in parallel and supervise the former efficiently by
reward signal. Our evaluation shows the method is demonstrating superior
performance, we achieve a 9.3% gain on success rate than our baseline method
across all room types and gain 51.2% improvements on long episodes environment
while maintaining slightly better Success Weighted by Path Length (SPL). Code
and resources, visualization are available at:
https://github.com/HuskyKingdom/DITA_acml2023
</p>
</div>
</dd>
<dt><a name="item118">[118]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16166" title="Abstract">arXiv:2309.16166</a> [<a href="/pdf/2309.16166" title="Download PDF">pdf</a>, <a href="/format/2309.16166" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CoinRun: Solving Goal Misgeneralisation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Armstrong%2C+S">Stuart Armstrong</a>, 
<a href="/search/cs?searchtype=author&query=Maranh%C3%A3o%2C+A">Alexandre Maranh&#xe3;o</a>, 
<a href="/search/cs?searchtype=author&query=Daniels-Koch%2C+O">Oliver Daniels-Koch</a>, 
<a href="/search/cs?searchtype=author&query=Leask%2C+P">Patrick Leask</a>, 
<a href="/search/cs?searchtype=author&query=Gorman%2C+R">Rebecca Gorman</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
<p class="mathjax">Goal misgeneralisation is a key challenge in AI alignment -- the task of
getting powerful Artificial Intelligences to align their goals with human
intentions and human morality. In this paper, we show how the ACE (Algorithm
for Concept Extrapolation) agent can solve one of the key standard challenges
in goal misgeneralisation: the CoinRun challenge. It uses no new reward
information in the new environment. This points to how autonomous agents could
be trusted to act in human interests, even in novel and critical situations.
</p>
</div>
</dd>
<dt><a name="item119">[119]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16167" title="Abstract">arXiv:2309.16167</a> [<a href="/pdf/2309.16167" title="Download PDF">pdf</a>, <a href="/format/2309.16167" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Large Language Model Soft Ideologization via AI-Self-Consciousness
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhou%2C+X">Xiaotian Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Q">Qian Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xiaofeng Wang</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+H">Haixu Tang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xiaozhong Liu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Large language models (LLMs) have demonstrated human-level performance on a
vast spectrum of natural language tasks. However, few studies have addressed
the LLM threat and vulnerability from an ideology perspective, especially when
they are increasingly being deployed in sensitive domains, e.g., elections and
education. In this study, we explore the implications of GPT soft
ideologization through the use of AI-self-consciousness. By utilizing GPT
self-conversations, AI can be granted a vision to "comprehend" the intended
ideology, and subsequently generate finetuning data for LLM ideology injection.
When compared to traditional government ideology manipulation techniques, such
as information censorship, LLM ideologization proves advantageous; it is easy
to implement, cost-effective, and powerful, thus brimming with risks.
</p>
</div>
</dd>
<dt><a name="item120">[120]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16170" title="Abstract">arXiv:2309.16170</a> [<a href="/pdf/2309.16170" title="Download PDF">pdf</a>, <a href="/format/2309.16170" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Laboratory Automation: Precision Insertion with Adaptive Fingers  utilizing Contact through Sliding with Tactile-based Pose Estimation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pai%2C+S">Sameer Pai</a>, 
<a href="/search/cs?searchtype=author&query=Takahashi%2C+K">Kuniyuki Takahashi</a>, 
<a href="/search/cs?searchtype=author&query=Masuda%2C+S">Shimpei Masuda</a>, 
<a href="/search/cs?searchtype=author&query=Fukaya%2C+N">Naoki Fukaya</a>, 
<a href="/search/cs?searchtype=author&query=Yamane%2C+K">Koki Yamane</a>, 
<a href="/search/cs?searchtype=author&query=Ummadisingu%2C+A">Avinash Ummadisingu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Micro well-plates are commonly used apparatus in chemical and biological
experiments that are a few centimeters in thickness with wells in them. The
task we aim to solve is to place (insert) them onto a well-plate holder with
grooves a few millimeters in height. Our insertion task has the following
facets: 1) There is uncertainty in the detection of the position and pose of
the well-plate and well-plate holder, 2) the accuracy required is in the order
of millimeter to sub-millimeter, 3) the well-plate holder is not fastened, and
moves with external force, 4) the groove is shallow, and 5) the width of the
groove is small. Addressing these challenges, we developed a) an adaptive
finger gripper with accurate detection of finger position (for (1)), b) grasped
object pose estimation using tactile sensors (for (1)), c) a method to insert
the well-plate into the target holder by sliding the well-plate while
maintaining contact with the edge of the holder (for (2-4)), and d) estimating
the orientation of the edge and aligning the well-plate so that the holder does
not move when maintaining contact with the edge (for (5)). We show a
significantly high success rate on the insertion task of the well-plate, even
though under added noise.
<br />An accompanying video is available at the following link:
https://drive.google.com/file/d/1UxyJ3XIxqXPnHcpfw-PYs5T5oYQxoc6i/view?usp=sharing
</p>
</div>
</dd>
<dt><a name="item121">[121]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16172" title="Abstract">arXiv:2309.16172</a> [<a href="/pdf/2309.16172" title="Download PDF">pdf</a>, <a href="/format/2309.16172" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Random and Safe Cache Architecture to Defeat Cache Timing Attacks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hu%2C+G">Guangyuan Hu</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+R+B">Ruby B. Lee</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Hardware Architecture (cs.AR)

</div>
<p class="mathjax">Caches have been exploited to leak secret information due to the different
times they take to handle memory accesses. Cache timing attacks include
non-speculative cache side and covert channel attacks and cache-based
speculative execution attacks. We first present a systematic view of the attack
and defense space and show that no existing defense has addressed both
speculative and non-speculative cache timing attack families, which we do in
this paper. We propose Random and Safe (RaS) cache architectures to decorrelate
the cache state changes from memory requests. RaS fills the cache with ``safe''
cache lines that are likely to be used in the future, rather than with
demand-fetched, security-sensitive lines. RaS captures a group of safe
addresses during runtime and fetches addresses randomly displaced from these
addresses. Our proposed RaS architecture is flexible to allow
security-performance trade-offs. We show different designs of RaS architectures
that can defeat cache side-channel attacks and cache-based speculative
execution attacks. The RaS variant against cache-based speculative execution
attacks has 4.2% average performance overhead and other RaS variants against
both attack families have 7.9% to 45.2% average overhead. For some benchmarks,
RaS defenses improve the performance while providing security.
</p>
</div>
</dd>
<dt><a name="item122">[122]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16173" title="Abstract">arXiv:2309.16173</a> [<a href="/pdf/2309.16173" title="Download PDF">pdf</a>, <a href="/format/2309.16173" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Distill to Delete: Unlearning in Graph Networks with Knowledge  Distillation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sinha%2C+Y">Yash Sinha</a>, 
<a href="/search/cs?searchtype=author&query=Mandal%2C+M">Murari Mandal</a>, 
<a href="/search/cs?searchtype=author&query=Kankanhalli%2C+M">Mohan Kankanhalli</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Graph unlearning has emerged as a pivotal method to delete information from a
pre-trained graph neural network (GNN). One may delete nodes, a class of nodes,
edges, or a class of edges. An unlearning method enables the GNN model to
comply with data protection regulations (i.e., the right to be forgotten),
adapt to evolving data distributions, and reduce the GPU-hours carbon footprint
by avoiding repetitive retraining. Existing partitioning and aggregation-based
methods have limitations due to their poor handling of local graph dependencies
and additional overhead costs. More recently, GNNDelete offered a
model-agnostic approach that alleviates some of these issues. Our work takes a
novel approach to address these challenges in graph unlearning through
knowledge distillation, as it distills to delete in GNN (D2DGN). It is a
model-agnostic distillation framework where the complete graph knowledge is
divided and marked for retention and deletion. It performs distillation with
response-based soft targets and feature-based node embedding while minimizing
KL divergence. The unlearned model effectively removes the influence of deleted
graph elements while preserving knowledge about the retained graph elements.
D2DGN surpasses the performance of existing methods when evaluated on various
real-world graph datasets by up to $43.1\%$ (AUC) in edge and node unlearning
tasks. Other notable advantages include better efficiency, better performance
in removing target elements, preservation of performance for the retained
elements, and zero overhead costs. Notably, our D2DGN surpasses the
state-of-the-art GNNDelete in AUC by $2.4\%$, improves membership inference
ratio by $+1.3$, requires $10.2\times10^6$ fewer FLOPs per forward pass and up
to $\mathbf{3.2}\times$ faster.
</p>
</div>
</dd>
<dt><a name="item123">[123]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16175" title="Abstract">arXiv:2309.16175</a> [<a href="/pdf/2309.16175" title="Download PDF">pdf</a>, <a href="/format/2309.16175" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Using Weak Supervision and Data Augmentation in Question Answering
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Basu%2C+C">Chumki Basu</a>, 
<a href="/search/cs?searchtype=author&query=Garg%2C+H">Himanshu Garg</a>, 
<a href="/search/cs?searchtype=author&query=McIntosh%2C+A">Allen McIntosh</a>, 
<a href="/search/cs?searchtype=author&query=Sablak%2C+S">Sezai Sablak</a>, 
<a href="/search/cs?searchtype=author&query=Wullert%2C+J+R">John R. Wullert II</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">The onset of the COVID-19 pandemic accentuated the need for access to
biomedical literature to answer timely and disease-specific questions. During
the early days of the pandemic, one of the biggest challenges we faced was the
lack of peer-reviewed biomedical articles on COVID-19 that could be used to
train machine learning models for question answering (QA). In this paper, we
explore the roles weak supervision and data augmentation play in training deep
neural network QA models. First, we investigate whether labels generated
automatically from the structured abstracts of scholarly papers using an
information retrieval algorithm, BM25, provide a weak supervision signal to
train an extractive QA model. We also curate new QA pairs using information
retrieval techniques, guided by the clinicaltrials.gov schema and the
structured abstracts of articles, in the absence of annotated data from
biomedical domain experts. Furthermore, we explore augmenting the training data
of a deep neural network model with linguistic features from external sources
such as lexical databases to account for variations in word morphology and
meaning. To better utilize our training data, we apply curriculum learning to
domain adaptation, fine-tuning our QA model in stages based on characteristics
of the QA pairs. We evaluate our methods in the context of QA models at the
core of a system to answer questions about COVID-19.
</p>
</div>
</dd>
<dt><a name="item124">[124]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16176" title="Abstract">arXiv:2309.16176</a> [<a href="/pdf/2309.16176" title="Download PDF">pdf</a>, <a href="/format/2309.16176" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Matrix Multiplication Verification Using Coding Theory
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bennett%2C+H">Huck Bennett</a>, 
<a href="/search/cs?searchtype=author&query=Gajulapalli%2C+K">Karthik Gajulapalli</a>, 
<a href="/search/cs?searchtype=author&query=Golovnev%2C+A">Alexander Golovnev</a>, 
<a href="/search/cs?searchtype=author&query=Warton%2C+P+G">Philip G. Warton</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>

</div>
<p class="mathjax">We study the Matrix Multiplication Verification Problem (MMV) where the goal
is, given three $n \times n$ matrices $A$, $B$, and $C$ as input, to decide
whether $AB = C$. A classic randomized algorithm by Freivalds (MFCS, 1979)
solves MMV in $\widetilde{O}(n^2)$ time, and a longstanding challenge is to
(partially) derandomize it while still running in faster than matrix
multiplication time (i.e., in $o(n^{\omega})$ time).
<br />To that end, we give two algorithms for MMV in the case where $AB - C$ is
sparse. Specifically, when $AB - C$ has at most $O(n^{\delta})$ non-zero
entries for a constant $0 \leq \delta &lt; 2$, we give (1) a deterministic
$O(n^{\omega - \varepsilon})$-time algorithm for constant $\varepsilon =
\varepsilon(\delta) &gt; 0$, and (2) a randomized $\widetilde{O}(n^2)$-time
algorithm using $\delta/2 \cdot \log_2 n + O(1)$ random bits. The former
algorithm is faster than the deterministic algorithm of K\"{u}nnemann (ESA,
2018) when $\delta \geq 1.056$, and the latter algorithm uses fewer random bits
than the algorithm of Kimbrel and Sinha (IPL, 1993), which runs in the same
time and uses $\log_2 n + O(1)$ random bits (in turn fewer than Freivalds's
algorithm).
<br />We additionally study the complexity of MMV. We first show that all
algorithms in a natural class of deterministic linear algebraic algorithms for
MMV (including ours) require $\Omega(n^{\omega})$ time. We also show a barrier
to proving a super-quadratic running time lower bound for matrix multiplication
(and hence MMV) under the Strong Exponential Time Hypothesis (SETH). Finally,
we study relationships between natural variants and special cases of MMV (with
respect to deterministic $\widetilde{O}(n^2)$-time reductions).
</p>
</div>
</dd>
<dt><a name="item125">[125]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16178" title="Abstract">arXiv:2309.16178</a> [<a href="/pdf/2309.16178" title="Download PDF">pdf</a>, <a href="/format/2309.16178" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LAE-ST-MoE: Boosted Language-Aware Encoder Using Speech Translation  Auxiliary Task for E2E Code-switching ASR
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ma%2C+G">Guodong Ma</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+W">Wenxuan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yuke Li</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yuting Yang</a>, 
<a href="/search/cs?searchtype=author&query=Du%2C+B">Binbin Du</a>, 
<a href="/search/cs?searchtype=author&query=Fu%2C+H">Haoran Fu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to IEEE ASRU 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">Recently, to mitigate the confusion between different languages in
code-switching (CS) automatic speech recognition (ASR), the conditionally
factorized models, such as the language-aware encoder (LAE), explicitly
disregard the contextual information between different languages. However, this
information may be helpful for ASR modeling. To alleviate this issue, we
propose the LAE-ST-MoE framework. It incorporates speech translation (ST) tasks
into LAE and utilizes ST to learn the contextual information between different
languages. It introduces a task-based mixture of expert modules, employing
separate feed-forward networks for the ASR and ST tasks. Experimental results
on the ASRU 2019 Mandarin-English CS challenge dataset demonstrate that,
compared to the LAE-based CTC, the LAE-ST-MoE model achieves a 9.26% mix error
reduction on the CS test with the same decoding parameter. Moreover, the
well-trained LAE-ST-MoE model can perform ST tasks from CS speech to Mandarin
or English text.
</p>
</div>
</dd>
<dt><a name="item126">[126]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16179" title="Abstract">arXiv:2309.16179</a> [<a href="/pdf/2309.16179" title="Download PDF">pdf</a>, <a href="/format/2309.16179" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> BEVHeight++: Toward Robust Visual Centric 3D Object Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+L">Lei Yang</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+T">Tao Tang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jun Li</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+P">Peng Chen</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+K">Kun Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+L">Li Wang</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+Y">Yi Huang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xinyu Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+K">Kaicheng Yu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: substantial text overlap with <a href="/abs/2303.08498">arXiv:2303.08498</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">While most recent autonomous driving system focuses on developing perception
methods on ego-vehicle sensors, people tend to overlook an alternative approach
to leverage intelligent roadside cameras to extend the perception ability
beyond the visual range. We discover that the state-of-the-art vision-centric
bird's eye view detection methods have inferior performances on roadside
cameras. This is because these methods mainly focus on recovering the depth
regarding the camera center, where the depth difference between the car and the
ground quickly shrinks while the distance increases. In this paper, we propose
a simple yet effective approach, dubbed BEVHeight++, to address this issue. In
essence, we regress the height to the ground to achieve a distance-agnostic
formulation to ease the optimization process of camera-only perception methods.
By incorporating both height and depth encoding techniques, we achieve a more
accurate and robust projection from 2D to BEV spaces. On popular 3D detection
benchmarks of roadside cameras, our method surpasses all previous
vision-centric methods by a significant margin. In terms of the ego-vehicle
scenario, our BEVHeight++ possesses superior over depth-only methods.
Specifically, it yields a notable improvement of +1.9% NDS and +1.1% mAP over
BEVDepth when evaluated on the nuScenes validation set. Moreover, on the
nuScenes test set, our method achieves substantial advancements, with an
increase of +2.8% NDS and +1.7% mAP, respectively.
</p>
</div>
</dd>
<dt><a name="item127">[127]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16180" title="Abstract">arXiv:2309.16180</a> [<a href="/pdf/2309.16180" title="Download PDF">pdf</a>, <a href="/format/2309.16180" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A More General Theory of Diagnosis from First Principles
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Grastien%2C+A">Alban Grastien</a>, 
<a href="/search/cs?searchtype=author&query=Haslum%2C+P">Patrik Haslum</a>, 
<a href="/search/cs?searchtype=author&query=Thi%C3%A9baux%2C+S">Sylvie Thi&#xe9;baux</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
<p class="mathjax">Model-based diagnosis has been an active research topic in different
communities including artificial intelligence, formal methods, and control.
This has led to a set of disparate approaches addressing different classes of
systems and seeking different forms of diagnoses. In this paper, we resolve
such disparities by generalising Reiter's theory to be agnostic to the types of
systems and diagnoses considered. This more general theory of diagnosis from
first principles defines the minimal diagnosis as the set of preferred
diagnosis candidates in a search space of hypotheses. Computing the minimal
diagnosis is achieved by exploring the space of diagnosis hypotheses, testing
sets of hypotheses for consistency with the system's model and the observation,
and generating conflicts that rule out successors and other portions of the
search space. Under relatively mild assumptions, our algorithms correctly
compute the set of preferred diagnosis candidates. The main difficulty here is
that the search space is no longer a powerset as in Reiter's theory, and that,
as consequence, many of the implicit properties (such as finiteness of the
search space) no longer hold. The notion of conflict also needs to be
generalised and we present such a more general notion. We present two
implementations of these algorithms, using test solvers based on satisfiability
and heuristic search, respectively, which we evaluate on instances from two
real world discrete event problems. Despite the greater generality of our
theory, these implementations surpass the special purpose algorithms designed
for discrete event systems, and enable solving instances that were out of reach
of existing diagnosis approaches.
</p>
</div>
</dd>
<dt><a name="item128">[128]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16181" title="Abstract">arXiv:2309.16181</a> [<a href="/pdf/2309.16181" title="Download PDF">pdf</a>, <a href="/format/2309.16181" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MSF-Model: Modeling Metastable Failures in Replicated Storage Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Habibi%2C+F">Farzad Habibi</a>, 
<a href="/search/cs?searchtype=author&query=Lorido-Botran%2C+T">Tania Lorido-Botran</a>, 
<a href="/search/cs?searchtype=author&query=Showail%2C+A">Ahmad Showail</a>, 
<a href="/search/cs?searchtype=author&query=Sturman%2C+D+C">Daniel C. Sturman</a>, 
<a href="/search/cs?searchtype=author&query=Nawab%2C+F">Faisal Nawab</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>; Databases (cs.DB)

</div>
<p class="mathjax">Metastable failure is a recent abstraction of a pattern of failures that
occurs frequently in real-world distributed storage systems. In this paper, we
propose a formal analysis and modeling of metastable failures in replicated
storage systems. We focus on a foundational problem in distributed systems --
the problem of consensus -- to have an impact on a large class of systems. Our
main contribution is the development of a queuing-based analytical model,
MSF-Model, that can be used to characterize and predict metastable failures.
MSF-Model integrates novel modeling concepts that allow modeling metastable
failures which was interactable to model prior to our work. We also perform
real experiments to reproduce and validate our model. Our real experiments show
that MSF-Model predicts metastable failures with high accuracy by comparing the
real experiment with the predictions from the queuing-based model.
</p>
</div>
</dd>
<dt><a name="item129">[129]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16189" title="Abstract">arXiv:2309.16189</a> [<a href="/pdf/2309.16189" title="Download PDF">pdf</a>, <a href="/format/2309.16189" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Cloth2Body: Generating 3D Human Body Mesh from 2D Clothing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dai%2C+L">Lu Dai</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+L">Liqian Ma</a>, 
<a href="/search/cs?searchtype=author&query=Qian%2C+S">Shenhan Qian</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+H">Hao Liu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Ziwei Liu</a>, 
<a href="/search/cs?searchtype=author&query=Xiong%2C+H">Hui Xiong</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ICCV 2023 Poster
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">In this paper, we define and study a new Cloth2Body problem which has a goal
of generating 3D human body meshes from a 2D clothing image. Unlike the
existing human mesh recovery problem, Cloth2Body needs to address new and
emerging challenges raised by the partial observation of the input and the high
diversity of the output. Indeed, there are three specific challenges. First,
how to locate and pose human bodies into the clothes. Second, how to
effectively estimate body shapes out of various clothing types. Finally, how to
generate diverse and plausible results from a 2D clothing image. To this end,
we propose an end-to-end framework that can accurately estimate 3D body mesh
parameterized by pose and shape from a 2D clothing image. Along this line, we
first utilize Kinematics-aware Pose Estimation to estimate body pose
parameters. 3D skeleton is employed as a proxy followed by an inverse
kinematics module to boost the estimation accuracy. We additionally design an
adaptive depth trick to align the re-projected 3D mesh better with 2D clothing
image by disentangling the effects of object size and camera extrinsic. Next,
we propose Physics-informed Shape Estimation to estimate body shape parameters.
3D shape parameters are predicted based on partial body measurements estimated
from RGB image, which not only improves pixel-wise human-cloth alignment, but
also enables flexible user editing. Finally, we design Evolution-based pose
generation method, a skeleton transplanting method inspired by genetic
algorithms to generate diverse reasonable poses during inference. As shown by
experimental results on both synthetic and real-world data, the proposed
framework achieves state-of-the-art performance and can effectively recover
natural and diverse 3D body meshes from 2D images that align well with
clothing.
</p>
</div>
</dd>
<dt><a name="item130">[130]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16197" title="Abstract">arXiv:2309.16197</a> [<a href="/pdf/2309.16197" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Neighborhood-based Bridge Node Centrality Tuple for Preferential  Vaccination of Nodes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Meghanathan%2C+N">Natarajan Meghanathan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages, 6 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>; Physics and Society (physics.soc-ph)

</div>
<p class="mathjax">We investigate the use of a recently proposed centrality tuple called the
Neighborhood-based Bridge Node Centrality (NBNC) tuple to choose nodes for
preferential vaccination so that such vaccinated nodes could provide herd
immunity and reduce the spreading rate of infections in a complex real-world
network. The NBNC tuple ranks nodes on the basis of the extent they play the
role of bridge nodes in a network. A node is a bridge node, if when removed its
neighbors are either disconnected or at least sparsely connected. We
hypothesize that preferentially vaccinating such bridge nodes would block an
infection to spread from a neighbor of the bridge node to an another neighbor
that are otherwise not reachable to each other. We evaluate the effectiveness
of using NBNC to reduce the spread of infections by conducting simulations of
the spread of infections per the SIS (Susceptible-Infected-Susceptible) model
on a collection of 10 complex real-world social networks. We observe the
average fraction of infected nodes per round of the SIS simulations based on
NBNC for preferential vaccination to be lower than that of the degree
centrality-based preferential vaccination.
</p>
</div>
</dd>
<dt><a name="item131">[131]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16200" title="Abstract">arXiv:2309.16200</a> [<a href="/pdf/2309.16200" title="Download PDF">pdf</a>, <a href="/format/2309.16200" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Max-Sliced Mutual Information
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tsur%2C+D">Dor Tsur</a>, 
<a href="/search/cs?searchtype=author&query=Goldfeld%2C+Z">Ziv Goldfeld</a>, 
<a href="/search/cs?searchtype=author&query=Greenewald%2C+K">Kristjan Greenewald</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Information Theory (cs.IT)

</div>
<p class="mathjax">Quantifying the dependence between high-dimensional random variables is
central to statistical learning and inference. Two classical methods are
canonical correlation analysis (CCA), which identifies maximally correlated
projected versions of the original variables, and Shannon's mutual information,
which is a universal dependence measure that also captures high-order
dependencies. However, CCA only accounts for linear dependence, which may be
insufficient for certain applications, while mutual information is often
infeasible to compute/estimate in high dimensions. This work proposes a middle
ground in the form of a scalable information-theoretic generalization of CCA,
termed max-sliced mutual information (mSMI). mSMI equals the maximal mutual
information between low-dimensional projections of the high-dimensional
variables, which reduces back to CCA in the Gaussian case. It enjoys the best
of both worlds: capturing intricate dependencies in the data while being
amenable to fast computation and scalable estimation from samples. We show that
mSMI retains favorable structural properties of Shannon's mutual information,
like variational forms and identification of independence. We then study
statistical estimation of mSMI, propose an efficiently computable neural
estimator, and couple it with formal non-asymptotic error bounds. We present
experiments that demonstrate the utility of mSMI for several tasks,
encompassing independence testing, multi-view representation learning,
algorithmic fairness, and generative modeling. We observe that mSMI
consistently outperforms competing methods with little-to-no computational
overhead.
</p>
</div>
</dd>
<dt><a name="item132">[132]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16201" title="Abstract">arXiv:2309.16201</a> [<a href="/pdf/2309.16201" title="Download PDF">pdf</a>, <a href="/format/2309.16201" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MOON: Assisting Students in Completing Educational Notebook Scenarios
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Casseau%2C+C">Christophe Casseau</a> (LaBRI), 
<a href="/search/cs?searchtype=author&query=Falleri%2C+J">Jean-R&#xe9;my Falleri</a> (LaBRI, IUF), 
<a href="/search/cs?searchtype=author&query=Degueule%2C+T">Thomas Degueule</a> (LaBRI), 
<a href="/search/cs?searchtype=author&query=Blanc%2C+X">Xavier Blanc</a> (LaBRI)
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> 2023 IEEE Symposium on Visual Languages and Human-Centric
  Computing (VL/HCC), Oct 2023, Washington DC, United States
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>; Software Engineering (cs.SE)

</div>
<p class="mathjax">Jupyter notebooks are increasingly being adopted by teachers to deliver
interactive practical sessions to their students. Notebooks come with many
attractive features, such as the ability to combine textual explanations,
multimedia content, and executable code alongside a flexible execution model
which encourages experimentation and exploration. However, this execution model
can quickly become an issue when students do not follow the intended execution
order of the teacher, leading to errors or misleading results that hinder their
learning. To counter this adverse effect, teachers usually write detailed
instructions about how students are expected to use the notebooks. Yet, the use
of digital media is known to decrease reading efficiency and compliance with
written instructions, resulting in frequent notebook misuse and students
getting lost during practical sessions. In this article, we present a novel
approach, MOON, designed to remedy this problem. The central idea is to provide
teachers with a language that enables them to formalize the expected usage of
their notebooks in the form of a script and to interpret this script to guide
students with visual indications in real time while they interact with the
notebooks. We evaluate our approach using a randomized controlled experiment
involving 21 students, which shows that MOON helps students comply better with
the intended scenario without hindering their ability to progress. Our
follow-up user study shows that about 75% of the surveyed students perceived
MOON as rather useful or very useful.
</p>
</div>
</dd>
<dt><a name="item133">[133]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16202" title="Abstract">arXiv:2309.16202</a> [<a href="/pdf/2309.16202" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Marathi-English Code-mixed Text Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Amin%2C+D">Dhiraj Amin</a>, 
<a href="/search/cs?searchtype=author&query=Govilkar%2C+S">Sharvari Govilkar</a>, 
<a href="/search/cs?searchtype=author&query=Kulkarni%2C+S">Sagar Kulkarni</a>, 
<a href="/search/cs?searchtype=author&query=Lalit%2C+Y+S">Yash Shashikant Lalit</a>, 
<a href="/search/cs?searchtype=author&query=Khwaja%2C+A+A">Arshi Ajaz Khwaja</a>, 
<a href="/search/cs?searchtype=author&query=Xavier%2C+D">Daries Xavier</a>, 
<a href="/search/cs?searchtype=author&query=Gupta%2C+S+G">Sahil Girijashankar Gupta</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Code-mixing, the blending of linguistic elements from distinct languages to
form meaningful sentences, is common in multilingual settings, yielding hybrid
languages like Hinglish and Minglish. Marathi, India's third most spoken
language, often integrates English for precision and formality. Developing
code-mixed language systems, like Marathi-English (Minglish), faces resource
constraints. This research introduces a Marathi-English code-mixed text
generation algorithm, assessed with Code Mixing Index (CMI) and Degree of Code
Mixing (DCM) metrics. Across 2987 code-mixed questions, it achieved an average
CMI of 0.2 and an average DCM of 7.4, indicating effective and comprehensible
code-mixed sentences. These results offer potential for enhanced NLP tools,
bridging linguistic gaps in multilingual societies.
</p>
</div>
</dd>
<dt><a name="item134">[134]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16203" title="Abstract">arXiv:2309.16203</a> [<a href="/pdf/2309.16203" title="Download PDF">pdf</a>, <a href="/format/2309.16203" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Cloud Strikes Back: Investigating the Decentralization of IPFS
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Balduf%2C+L">Leonhard Balduf</a>, 
<a href="/search/cs?searchtype=author&query=Korczy%C5%84ski%2C+M">Maciej Korczy&#x144;ski</a>, 
<a href="/search/cs?searchtype=author&query=Ascigil%2C+O">Onur Ascigil</a>, 
<a href="/search/cs?searchtype=author&query=Keizer%2C+N+V">Navin V. Keizer</a>, 
<a href="/search/cs?searchtype=author&query=Pavlou%2C+G">George Pavlou</a>, 
<a href="/search/cs?searchtype=author&query=Scheuermann%2C+B">Bj&#xf6;rn Scheuermann</a>, 
<a href="/search/cs?searchtype=author&query=Kr%C3%B3l%2C+M">Micha&#x142; Kr&#xf3;l</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To be presented at IMC'23
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>

</div>
<p class="mathjax">Interplanetary Filesystem (IPFS) is one of the largest peer-to-peer
filesystems in operation. The network is the default storage layer for Web3 and
is being presented as a solution to the centralization of the web. In this
paper, we present a large-scale, multi-modal measurement study of the IPFS
network. We analyze the topology, the traffic, the content providers and the
entry points from the classical Internet.
<br />Our measurements show significant centralization in the IPFS network and a
high share of nodes hosted in the cloud. We also shed light on the main
stakeholders in the ecosystem. We discuss key challenges that might disrupt
continuing efforts to decentralize the Web and highlight multiple properties
that are creating pressures toward centralization.
</p>
</div>
</dd>
<dt><a name="item135">[135]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16204" title="Abstract">arXiv:2309.16204</a> [<a href="/pdf/2309.16204" title="Download PDF">pdf</a>, <a href="/format/2309.16204" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Hybrid Digital-Wave Domain Channel Estimator for Stacked Intelligent  Metasurface Enabled Multi-User MISO Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nadeem%2C+Q">Qurrat-Ul-Ain Nadeem</a>, 
<a href="/search/cs?searchtype=author&query=An%2C+J">Jiancheng An</a>, 
<a href="/search/cs?searchtype=author&query=Chaaban%2C+A">Anas Chaaban</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">Stacked intelligent metasurface (SIM) is an emerging programmable metasurface
architecture that can implement signal processing directly in the
electromagnetic wave domain, thereby enabling efficient implementation of
ultra-massive multiple-input multiple-output (MIMO) transceivers with a limited
number of radio frequency (RF) chains. Channel estimation (CE) is challenging
for SIM-enabled communication systems due to the multi-layer architecture of
SIM, and because we need to estimate large dimensional channels between the SIM
and users with a limited number of RF chains. To efficiently solve this
problem, we develop a novel hybrid digital-wave domain channel estimator, in
which the received training symbols are first processed in the wave domain
within the SIM layers, and then processed in the digital domain. The wave
domain channel estimator, parametrized by the phase shifts applied by the
meta-atoms in all layers, is optimized to minimize the mean squared error (MSE)
using a gradient descent algorithm, within which the digital part is optimally
updated. For an SIM-enabled multi-user system equipped with 4 RF chains and a
6-layer SIM with 64 meta-atoms each, the proposed estimator yields an MSE that
is very close to that achieved by fully digital CE in a massive MIMO system
employing 64 RF chains. This high CE accuracy is achieved at the cost of a
training overhead that can be reduced by exploiting the potential low rank of
channel correlation matrices.
</p>
</div>
</dd>
<dt><a name="item136">[136]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16205" title="Abstract">arXiv:2309.16205</a> [<a href="/pdf/2309.16205" title="Download PDF">pdf</a>, <a href="/format/2309.16205" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DiffGAN-F2S: Symmetric and Efficient Denoising Diffusion GANs for  Structural Connectivity Prediction from Brain fMRI
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zuo%2C+Q">Qiankun Zuo</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+R">Ruiheng Li</a>, 
<a href="/search/cs?searchtype=author&query=Di%2C+Y">Yi Di</a>, 
<a href="/search/cs?searchtype=author&query=Tian%2C+H">Hao Tian</a>, 
<a href="/search/cs?searchtype=author&query=Jing%2C+C">Changhong Jing</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+X">Xuhang Chen</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Shuqiang Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Image and Video Processing (eess.IV)

</div>
<p class="mathjax">Mapping from functional connectivity (FC) to structural connectivity (SC) can
facilitate multimodal brain network fusion and discover potential biomarkers
for clinical implications. However, it is challenging to directly bridge the
reliable non-linear mapping relations between SC and functional magnetic
resonance imaging (fMRI). In this paper, a novel diffusision generative
adversarial network-based fMRI-to-SC (DiffGAN-F2S) model is proposed to predict
SC from brain fMRI in an end-to-end manner. To be specific, the proposed
DiffGAN-F2S leverages denoising diffusion probabilistic models (DDPMs) and
adversarial learning to efficiently generate high-fidelity SC through a few
steps from fMRI. By designing the dual-channel multi-head spatial attention
(DMSA) and graph convolutional modules, the symmetric graph generator first
captures global relations among direct and indirect connected brain regions,
then models the local brain region interactions. It can uncover the complex
mapping relations between fMRI and structural connectivity. Furthermore, the
spatially connected consistency loss is devised to constrain the generator to
preserve global-local topological information for accurate intrinsic SC
prediction. Testing on the public Alzheimer's Disease Neuroimaging Initiative
(ADNI) dataset, the proposed model can effectively generate empirical
SC-preserved connectivity from four-dimensional imaging data and shows superior
performance in SC prediction compared with other related models. Furthermore,
the proposed model can identify the vast majority of important brain regions
and connections derived from the empirical method, providing an alternative way
to fuse multimodal brain networks and analyze clinical disease.
</p>
</div>
</dd>
<dt><a name="item137">[137]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16207" title="Abstract">arXiv:2309.16207</a> [<a href="/pdf/2309.16207" title="Download PDF">pdf</a>, <a href="/format/2309.16207" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Parameter-Saving Adversarial Training: Reinforcing Multi-Perturbation  Robustness via Hypernetworks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gong%2C+H">Huihui Gong</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+M">Minjing Dong</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+S">Siqi Ma</a>, 
<a href="/search/cs?searchtype=author&query=Camtepe%2C+S">Seyit Camtepe</a>, 
<a href="/search/cs?searchtype=author&query=Nepal%2C+S">Surya Nepal</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+C">Chang Xu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages, 2 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Adversarial training serves as one of the most popular and effective methods
to defend against adversarial perturbations. However, most defense mechanisms
only consider a single type of perturbation while various attack methods might
be adopted to perform stronger adversarial attacks against the deployed model
in real-world scenarios, e.g., $\ell_2$ or $\ell_\infty$. Defending against
various attacks can be a challenging problem since multi-perturbation
adversarial training and its variants only achieve suboptimal robustness
trade-offs, due to the theoretical limit to multi-perturbation robustness for a
single model. Besides, it is impractical to deploy large models in some
storage-efficient scenarios. To settle down these drawbacks, in this paper we
propose a novel multi-perturbation adversarial training framework,
parameter-saving adversarial training (PSAT), to reinforce multi-perturbation
robustness with an advantageous side effect of saving parameters, which
leverages hypernetworks to train specialized models against a single
perturbation and aggregate these specialized models to defend against multiple
perturbations. Eventually, we extensively evaluate and compare our proposed
method with state-of-the-art single/multi-perturbation robust methods against
various latest attack methods on different datasets, showing the robustness
superiority and parameter efficiency of our proposed method, e.g., for the
CIFAR-10 dataset with ResNet-50 as the backbone, PSAT saves approximately 80\%
of parameters with achieving the state-of-the-art robustness trade-off
accuracy.
</p>
</div>
</dd>
<dt><a name="item138">[138]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16208" title="Abstract">arXiv:2309.16208</a> [<a href="/pdf/2309.16208" title="Download PDF">pdf</a>, <a href="/format/2309.16208" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Nonconvex third-order Tensor Recovery Based on Logarithmic Minimax  Function
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Hongbing Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Recent researches have shown that low-rank tensor recovery based non-convex
relaxation has gained extensive attention. In this context, we propose a new
Logarithmic Minimax (LM) function. The comparative analysis between the LM
function and the Logarithmic, Minimax concave penalty (MCP), and Minimax
Logarithmic concave penalty (MLCP) functions reveals that the proposed function
can protect large singular values while imposing stronger penalization on small
singular values. Based on this, we define a weighted tensor LM norm as a
non-convex relaxation for tensor tubal rank. Subsequently, we propose the
TLM-based low-rank tensor completion (LRTC) model and the TLM-based tensor
robust principal component analysis (TRPCA) model respectively. Furthermore, we
provide theoretical convergence guarantees for the proposed methods.
Comprehensive experiments were conducted on various real datasets, and a
comparison analysis was made with the similar EMLCP method. The results
demonstrate that the proposed method outperforms the state-of-the-art methods.
</p>
</div>
</dd>
<dt><a name="item139">[139]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16211" title="Abstract">arXiv:2309.16211</a> [<a href="/pdf/2309.16211" title="Download PDF">pdf</a>, <a href="/format/2309.16211" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> VDC: Versatile Data Cleanser for Detecting Dirty Samples via  Visual-Linguistic Inconsistency
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhu%2C+Z">Zihao Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+M">Mingda Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+S">Shaokui Wei</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+B">Bingzhe Wu</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+B">Baoyuan Wu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 22 pages,5 figures,17 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">The role of data in building AI systems has recently been emphasized by the
emerging concept of data-centric AI. Unfortunately, in the real-world, datasets
may contain dirty samples, such as poisoned samples from backdoor attack, noisy
labels in crowdsourcing, and even hybrids of them. The presence of such dirty
samples makes the DNNs vunerable and unreliable.Hence, it is critical to detect
dirty samples to improve the quality and realiability of dataset. Existing
detectors only focus on detecting poisoned samples or noisy labels, that are
often prone to weak generalization when dealing with dirty samples from other
domains.In this paper, we find a commonality of various dirty samples is
visual-linguistic inconsistency between images and associated labels. To
capture the semantic inconsistency between modalities, we propose versatile
data cleanser (VDC) leveraging the surpassing capabilities of multimodal large
language models (MLLM) in cross-modal alignment and reasoning.It consists of
three consecutive modules: the visual question generation module to generate
insightful questions about the image; the visual question answering module to
acquire the semantics of the visual content by answering the questions with
MLLM; followed by the visual answer evaluation module to evaluate the
inconsistency.Extensive experiments demonstrate its superior performance and
generalization to various categories and types of dirty samples.
</p>
</div>
</dd>
<dt><a name="item140">[140]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16212" title="Abstract">arXiv:2309.16212</a> [<a href="/pdf/2309.16212" title="Download PDF">pdf</a>, <a href="/ps/2309.16212" title="Download PostScript">ps</a>, <a href="/format/2309.16212" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Cut a Numeric String into Required Pieces
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cai%2C+Y">Yinqi Cai</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>

</div>
<p class="mathjax">We study the problem of cutting a length-$n$ string of positive real numbers
into $k$ pieces so that every piece has sum at least $b$. The problem can also
be phrased as transforming such a string into a new one by merging adjacent
numbers. We discuss connections with other problems and present several
algorithms in connection with the problem: an $O(n)$-time greedy algorithm, an
$O(kn\log n)$-time dynamic programming algorithm, and an $O(n+ k \log n +
2^kk)$-time FPT algorithm for $n-k$ pieces.
</p>
</div>
</dd>
<dt><a name="item141">[141]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16214" title="Abstract">arXiv:2309.16214</a> [<a href="/pdf/2309.16214" title="Download PDF">pdf</a>, <a href="/format/2309.16214" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Canary: Congestion-Aware In-Network Allreduce Using Dynamic Trees
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=De+Sensi%2C+D">Daniele De Sensi</a>, 
<a href="/search/cs?searchtype=author&query=Molero%2C+E+C">Edgar Costa Molero</a>, 
<a href="/search/cs?searchtype=author&query=Di+Girolamo%2C+S">Salvatore Di Girolamo</a>, 
<a href="/search/cs?searchtype=author&query=Vanbever%2C+L">Laurent Vanbever</a>, 
<a href="/search/cs?searchtype=author&query=Hoefler%2C+T">Torsten Hoefler</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>; Networking and Internet Architecture (cs.NI)

</div>
<p class="mathjax">The allreduce operation is an essential building block for many distributed
applications, ranging from the training of deep learning models to scientific
computing. In an allreduce operation, data from multiple hosts is aggregated
together and then broadcasted to each host participating in the operation.
Allreduce performance can be improved by a factor of two by aggregating the
data directly in the network. Switches aggregate data coming from multiple
ports before forwarding the partially aggregated result to the next hop. In all
existing solutions, each switch needs to know the ports from which it will
receive the data to aggregate. However, this forces packets to traverse a
predefined set of switches, making these solutions prone to congestion. For
this reason, we design Canary, the first congestion-aware in-network allreduce
algorithm. Canary uses load balancing algorithms to forward packets on the
least congested paths. Because switches do not know from which ports they will
receive the data to aggregate, they use timeouts to aggregate the data in a
best-effort way. We develop a P4 Canary prototype and evaluate it on a Tofino
switch. We then validate Canary through simulations on large networks, showing
performance improvements up to 40% compared to the state-of-the-art.
</p>
</div>
</dd>
<dt><a name="item142">[142]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16217" title="Abstract">arXiv:2309.16217</a> [<a href="/pdf/2309.16217" title="Download PDF">pdf</a>, <a href="/format/2309.16217" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GAFlow: Incorporating Gaussian Attention into Optical Flow
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Luo%2C+A">Ao Luo</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+F">Fan Yang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xin Li</a>, 
<a href="/search/cs?searchtype=author&query=Nie%2C+L">Lang Nie</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+C">Chunyu Lin</a>, 
<a href="/search/cs?searchtype=author&query=Fan%2C+H">Haoqiang Fan</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+S">Shuaicheng Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To appear in ICCV-2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Optical flow, or the estimation of motion fields from image sequences, is one
of the fundamental problems in computer vision. Unlike most pixel-wise tasks
that aim at achieving consistent representations of the same category, optical
flow raises extra demands for obtaining local discrimination and smoothness,
which yet is not fully explored by existing approaches. In this paper, we push
Gaussian Attention (GA) into the optical flow models to accentuate local
properties during representation learning and enforce the motion affinity
during matching. Specifically, we introduce a novel Gaussian-Constrained Layer
(GCL) which can be easily plugged into existing Transformer blocks to highlight
the local neighborhood that contains fine-grained structural information.
Moreover, for reliable motion analysis, we provide a new Gaussian-Guided
Attention Module (GGAM) which not only inherits properties from Gaussian
distribution to instinctively revolve around the neighbor fields of each point
but also is empowered to put the emphasis on contextually related regions
during matching. Our fully-equipped model, namely Gaussian Attention Flow
network (GAFlow), naturally incorporates a series of novel Gaussian-based
modules into the conventional optical flow framework for reliable motion
analysis. Extensive experiments on standard optical flow datasets consistently
demonstrate the exceptional performance of the proposed approach in terms of
both generalization ability evaluation and online benchmark testing. Code is
available at https://github.com/LA30/GAFlow.
</p>
</div>
</dd>
<dt><a name="item143">[143]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16219" title="Abstract">arXiv:2309.16219</a> [<a href="/pdf/2309.16219" title="Download PDF">pdf</a>, <a href="/format/2309.16219" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Sensorless Physical Human-robot Interaction Using Deep-Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shan%2C+S">Shilin Shan</a>, 
<a href="/search/cs?searchtype=author&query=Pham%2C+Q">Quang-Cuong Pham</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, ICRA 2024 Submission
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Physical human-robot interaction has been an area of interest for decades.
Collaborative tasks, such as joint compliance, demand high-quality joint torque
sensing. While external torque sensors are reliable, they come with the
drawbacks of being expensive and vulnerable to impacts. To address these
issues, studies have been conducted to estimate external torques using only
internal signals, such as joint states and current measurements. However,
insufficient attention has been given to friction hysteresis approximation,
which is crucial for tasks involving extensive dynamic to static state
transitions. In this paper, we propose a deep-learning-based method that
leverages a novel long-term memory scheme to achieve dynamics identification,
accurately approximating the static hysteresis. We also introduce modifications
to the well-known Residual Learning architecture, retaining high accuracy while
reducing inference time. The robustness of the proposed method is illustrated
through a joint compliance and task compliance experiment.
</p>
</div>
</dd>
<dt><a name="item144">[144]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16220" title="Abstract">arXiv:2309.16220</a> [<a href="/pdf/2309.16220" title="Download PDF">pdf</a>, <a href="/format/2309.16220" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Unmasking the Chameleons: A Benchmark for Out-of-Distribution Detection  in Medical Tabular Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Azizmalayeri%2C+M">Mohammad Azizmalayeri</a>, 
<a href="/search/cs?searchtype=author&query=Abu-Hanna%2C+A">Ameen Abu-Hanna</a>, 
<a href="/search/cs?searchtype=author&query=Cin%C3%A1%2C+G">Giovanni Cin&#xe1;</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Despite their success, Machine Learning (ML) models do not generalize
effectively to data not originating from the training distribution. To reliably
employ ML models in real-world healthcare systems and avoid inaccurate
predictions on out-of-distribution (OOD) data, it is crucial to detect OOD
samples. Numerous OOD detection approaches have been suggested in other fields
- especially in computer vision - but it remains unclear whether the challenge
is resolved when dealing with medical tabular data. To answer this pressing
need, we propose an extensive reproducible benchmark to compare different
methods across a suite of tests including both near and far OODs. Our benchmark
leverages the latest versions of eICU and MIMIC-IV, two public datasets
encompassing tens of thousands of ICU patients in several hospitals. We
consider a wide array of density-based methods and SOTA post-hoc detectors
across diverse predictive architectures, including MLP, ResNet, and
Transformer. Our findings show that i) the problem appears to be solved for
far-OODs, but remains open for near-OODs; ii) post-hoc methods alone perform
poorly, but improve substantially when coupled with distance-based mechanisms;
iii) the transformer architecture is far less overconfident compared to MLP and
ResNet.
</p>
</div>
</dd>
<dt><a name="item145">[145]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16221" title="Abstract">arXiv:2309.16221</a> [<a href="/pdf/2309.16221" title="Download PDF">pdf</a>, <a href="/format/2309.16221" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Off-the-shelf bin picking workcell with visual pose estimation: A case  study on the world robot summit 2018 kitting task
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hagelskj%C3%A6r%2C+F">Frederik Hagelskj&#xe6;r</a>, 
<a href="/search/cs?searchtype=author&query=Lorenzen%2C+K+H">Kasper H&#xf8;j Lorenzen</a>, 
<a href="/search/cs?searchtype=author&query=Kraft%2C+D">Dirk Kraft</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, 7 figures, 2 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">The World Robot Summit 2018 Assembly Challenge included four different tasks.
The kitting task, which required bin-picking, was the task in which the fewest
points were obtained. However, bin-picking is a vital skill that can
significantly increase the flexibility of robotic set-ups, and is, therefore,
an important research field. In recent years advancements have been made in
sensor technology and pose estimation algorithms. These advancements allow for
better performance when performing visual pose estimation.
<br />This paper shows that by utilizing new vision sensors and pose estimation
algorithms pose estimation in bins can be performed successfully. We also
implement a workcell for bin picking along with a force based grasping approach
to perform the complete bin picking. Our set-up is tested on the World Robot
Summit 2018 Assembly Challenge and successfully obtains a higher score compared
with all teams at the competition. This demonstrate that current technology can
perform bin-picking at a much higher level compared with previous results.
</p>
</div>
</dd>
<dt><a name="item146">[146]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16223" title="Abstract">arXiv:2309.16223</a> [<a href="/pdf/2309.16223" title="Download PDF">pdf</a>, <a href="/format/2309.16223" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GInX-Eval: Towards In-Distribution Evaluation of Graph Neural Network  Explanations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Amara%2C+K">Kenza Amara</a>, 
<a href="/search/cs?searchtype=author&query=El-Assady%2C+M">Mennatallah El-Assady</a>, 
<a href="/search/cs?searchtype=author&query=Ying%2C+R">Rex Ying</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Preprint, Submitted to ICLR2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Diverse explainability methods of graph neural networks (GNN) have recently
been developed to highlight the edges and nodes in the graph that contribute
the most to the model predictions. However, it is not clear yet how to evaluate
the correctness of those explanations, whether it is from a human or a model
perspective. One unaddressed bottleneck in the current evaluation procedure is
the problem of out-of-distribution explanations, whose distribution differs
from those of the training data. This important issue affects existing
evaluation metrics such as the popular faithfulness or fidelity score. In this
paper, we show the limitations of faithfulness metrics. We propose GInX-Eval
(Graph In-distribution eXplanation Evaluation), an evaluation procedure of
graph explanations that overcomes the pitfalls of faithfulness and offers new
insights on explainability methods. Using a retraining strategy, the GInX score
measures how informative removed edges are for the model and the EdgeRank score
evaluates if explanatory edges are correctly ordered by their importance.
GInX-Eval verifies if ground-truth explanations are instructive to the GNN
model. In addition, it shows that many popular methods, including
gradient-based methods, produce explanations that are not better than a random
designation of edges as important subgraphs, challenging the findings of
current works in the area. Results with GInX-Eval are consistent across
multiple datasets and align with human evaluation.
</p>
</div>
</dd>
<dt><a name="item147">[147]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16224" title="Abstract">arXiv:2309.16224</a> [<a href="/pdf/2309.16224" title="Download PDF">pdf</a>, <a href="/ps/2309.16224" title="Download PostScript">ps</a>, <a href="/format/2309.16224" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Automatic Proof Checking and Proof Construction by Tactics
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dowek%2C+G">Gilles Dowek</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>

</div>
<p class="mathjax">In this note we compare two kinds of systems that verify the correctness of
mathematical developments: roof checking and proof construction by tactics and
we propose to merge them in a single system.
</p>
</div>
</dd>
<dt><a name="item148">[148]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16228" title="Abstract">arXiv:2309.16228</a> [<a href="/pdf/2309.16228" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Brand Network Booster: A New System for Improving Brand Connectivity
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cancellieri%2C+J">J. Cancellieri</a>, 
<a href="/search/cs?searchtype=author&query=Didimo%2C+W">W. Didimo</a>, 
<a href="/search/cs?searchtype=author&query=Colladon%2C+A+F">A. Fronzetti Colladon</a>, 
<a href="/search/cs?searchtype=author&query=Montecchiani%2C+F">F. Montecchiani</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>; Computation and Language (cs.CL); Software Engineering (cs.SE); Physics and Society (physics.soc-ph)

</div>
<p class="mathjax">This paper presents a new decision support system offered for an in-depth
analysis of semantic networks, which can provide insights for a better
exploration of a brand's image and the improvement of its connectivity. In
terms of network analysis, we show that this goal is achieved by solving an
extended version of the Maximum Betweenness Improvement problem, which includes
the possibility of considering adversarial nodes, constrained budgets, and
weighted networks - where connectivity improvement can be obtained by adding
links or increasing the weight of existing connections. We present this new
system together with two case studies, also discussing its performance. Our
tool and approach are useful both for network scholars and for supporting the
strategic decision-making processes of marketing and communication managers.
</p>
</div>
</dd>
<dt><a name="item149">[149]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16231" title="Abstract">arXiv:2309.16231</a> [<a href="/pdf/2309.16231" title="Download PDF">pdf</a>, <a href="/format/2309.16231" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Controllable Text Generation with Residual Memory Transformer
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Hanqing Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Si%2C+S">Sun Si</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+H">Haiming Wu</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+D">Dawei Song</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> github:<a href="https://github.com/littlehacker26/Residual_Memory_Transformer">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Large-scale Causal Language Models (CLMs), e.g., GPT3 and ChatGPT, have
brought great success in text generation. However, it is still an open
challenge to control the generation process of CLM while balancing flexibility,
control granularity, and generation efficiency. In this paper, we provide a new
alternative for controllable text generation (CTG), by designing a
non-intrusive, lightweight control plugin to accompany the generation of CLM at
arbitrary time steps. The proposed control plugin, namely Residual Memory
Transformer (RMT), has an encoder-decoder setup, which can accept any types of
control conditions and cooperate with CLM through a residual learning paradigm,
to achieve a more flexible, general, and efficient CTG. Extensive experiments
are carried out on various control tasks, in the form of both automatic and
human evaluations. The results show the superiority of RMT over a range of
state-of-the-art approaches, proving the effectiveness and versatility of our
approach.
</p>
</div>
</dd>
<dt><a name="item150">[150]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16234" title="Abstract">arXiv:2309.16234</a> [<a href="/pdf/2309.16234" title="Download PDF">pdf</a>, <a href="/format/2309.16234" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Analyzing Political Figures in Real-Time: Leveraging YouTube Metadata  for Sentiment Analysis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Putra%2C+D+A+H">Danendra Athallariq Harya Putra</a>, 
<a href="/search/cs?searchtype=author&query=Muharram%2C+A+P">Arief Purnama Muharram</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Sentiment analysis using big data from YouTube videos metadata can be
conducted to analyze public opinions on various political figures who represent
political parties. This is possible because YouTube has become one of the
platforms for people to express themselves, including their opinions on various
political figures. The resulting sentiment analysis can be useful for political
executives to gain an understanding of public sentiment and develop appropriate
and effective political strategies. This study aimed to build a sentiment
analysis system leveraging YouTube videos metadata. The sentiment analysis
system was built using Apache Kafka, Apache PySpark, and Hadoop for big data
handling; TensorFlow for deep learning handling; and FastAPI for deployment on
the server. The YouTube videos metadata used in this study is the video
description. The sentiment analysis model was built using LSTM algorithm and
produces two types of sentiments: positive and negative sentiments. The
sentiment analysis results are then visualized in the form a simple web-based
dashboard.
</p>
</div>
</dd>
<dt><a name="item151">[151]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16237" title="Abstract">arXiv:2309.16237</a> [<a href="/pdf/2309.16237" title="Download PDF">pdf</a>, <a href="/format/2309.16237" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Object Motion Guided Human Motion Synthesis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jiaman Li</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+J">Jiajun Wu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+C+K">C. Karen Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> SIGGRAPH Asia 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Modeling human behaviors in contextual environments has a wide range of
applications in character animation, embodied AI, VR/AR, and robotics. In
real-world scenarios, humans frequently interact with the environment and
manipulate various objects to complete daily tasks. In this work, we study the
problem of full-body human motion synthesis for the manipulation of large-sized
objects. We propose Object MOtion guided human MOtion synthesis (OMOMO), a
conditional diffusion framework that can generate full-body manipulation
behaviors from only the object motion. Since naively applying diffusion models
fails to precisely enforce contact constraints between the hands and the
object, OMOMO learns two separate denoising processes to first predict hand
positions from object motion and subsequently synthesize full-body poses based
on the predicted hand positions. By employing the hand positions as an
intermediate representation between the two denoising processes, we can
explicitly enforce contact constraints, resulting in more physically plausible
manipulation motions. With the learned model, we develop a novel system that
captures full-body human manipulation motions by simply attaching a smartphone
to the object being manipulated. Through extensive experiments, we demonstrate
the effectiveness of our proposed pipeline and its ability to generalize to
unseen objects. Additionally, as high-quality human-object interaction datasets
are scarce, we collect a large-scale dataset consisting of 3D object geometry,
object motion, and human motion. Our dataset contains human-object interaction
motion for 15 objects, with a total duration of approximately 10 hours.
</p>
</div>
</dd>
<dt><a name="item152">[152]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16240" title="Abstract">arXiv:2309.16240</a> [<a href="/pdf/2309.16240" title="Download PDF">pdf</a>, <a href="/format/2309.16240" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Beyond Reverse KL: Generalizing Direct Preference Optimization with  Diverse Divergence Constraints
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+C">Chaoqi Wang</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+Y">Yibo Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+C">Chenghao Yang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+H">Han Liu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yuxin Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Preprint
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Machine Learning (stat.ML)

</div>
<p class="mathjax">The increasing capabilities of large language models (LLMs) raise
opportunities for artificial general intelligence but concurrently amplify
safety concerns, such as potential misuse of AI systems, necessitating
effective AI alignment. Reinforcement Learning from Human Feedback (RLHF) has
emerged as a promising pathway towards AI alignment but brings forth challenges
due to its complexity and dependence on a separate reward model. Direct
Preference Optimization (DPO) has been proposed as an alternative, and it
remains equivalent to RLHF under the reverse KL regularization constraint. This
paper presents $f$-DPO, a generalized approach to DPO by incorporating diverse
divergence constraints. We show that under certain $f$-divergences, including
Jensen-Shannon divergence, forward KL divergences and $\alpha$-divergences, the
complex relationship between the reward and optimal policy can also be
simplified by addressing the Karush-Kuhn-Tucker conditions. This eliminates the
need for estimating the normalizing constant in the Bradley-Terry model and
enables a tractable mapping between the reward function and the optimal policy.
Our approach optimizes LLMs to align with human preferences in a more efficient
and supervised manner under a broad set of divergence constraints. Empirically,
adopting these divergences ensures a balance between alignment performance and
generation diversity. Importantly, $f$-DPO outperforms PPO-based methods in
divergence efficiency, and divergence constraints directly influence expected
calibration error (ECE).
</p>
</div>
</dd>
<dt><a name="item153">[153]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16243" title="Abstract">arXiv:2309.16243</a> [<a href="/pdf/2309.16243" title="Download PDF">pdf</a>, <a href="/ps/2309.16243" title="Download PostScript">ps</a>, <a href="/format/2309.16243" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Construction of Smooth Isogeometric Function Spaces on Singularly  Parameterized Domains
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Takacs%2C+T">Thomas Takacs</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> J.-D. Boissonnat et al. (EDS.): Curves and Surfaces 2014, LNCS
  9213, pp. 433-451, 2015, Springer
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">We aim at constructing a smooth basis for isogeometric function spaces on
domains of reduced geometric regularity. In this context an isogeometric
function is the composition of a piecewise rational function with the inverse
of a piecewise rational geometry parameterization. We consider two types of
singular parameterizations, domains where a part of the boundary is mapped onto
one point and domains where parameter lines are mapped collinearly at the
boundary.
<br />We locally map a singular tensor-product patch of arbitrary degree onto a
triangular patch, thus splitting the parameterization into a singular bilinear
mapping and a regular mapping on a triangular domain. This construction yields
an isogeometric function space of prescribed smoothness. Generalizations to
higher dimensions are also possible and are briefly discussed in the final
section.
</p>
</div>
</dd>
<dt><a name="item154">[154]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16248" title="Abstract">arXiv:2309.16248</a> [<a href="/pdf/2309.16248" title="Download PDF">pdf</a>, <a href="/format/2309.16248" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Spider4SPARQL: A Complex Benchmark for Evaluating Knowledge Graph  Question Answering Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kosten%2C+C">Catherine Kosten</a>, 
<a href="/search/cs?searchtype=author&query=Cudr%C3%A9-Mauroux%2C+P">Philippe Cudr&#xe9;-Mauroux</a>, 
<a href="/search/cs?searchtype=author&query=Stockinger%2C+K">Kurt Stockinger</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">With the recent spike in the number and availability of Large Language Models
(LLMs), it has become increasingly important to provide large and realistic
benchmarks for evaluating Knowledge Graph Question Answering (KBQA) systems. So
far the majority of benchmarks rely on pattern-based SPARQL query generation
approaches. The subsequent natural language (NL) question generation is
conducted through crowdsourcing or other automated methods, such as rule-based
paraphrasing or NL question templates. Although some of these datasets are of
considerable size, their pitfall lies in their pattern-based generation
approaches, which do not always generalize well to the vague and linguistically
diverse questions asked by humans in real-world contexts.
<br />In this paper, we introduce Spider4SPARQL - a new SPARQL benchmark dataset
featuring 9,693 previously existing manually generated NL questions and 4,721
unique, novel, and complex SPARQL queries of varying complexity. In addition to
the NL/SPARQL pairs, we also provide their corresponding 166 knowledge graphs
and ontologies, which cover 138 different domains. Our complex benchmark
enables novel ways of evaluating the strengths and weaknesses of modern KGQA
systems. We evaluate the system with state-of-the-art KGQA systems as well as
LLMs, which achieve only up to 45\% execution accuracy, demonstrating that
Spider4SPARQL is a challenging benchmark for future research.
</p>
</div>
</dd>
<dt><a name="item155">[155]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16249" title="Abstract">arXiv:2309.16249</a> [<a href="/pdf/2309.16249" title="Download PDF">pdf</a>, <a href="/format/2309.16249" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FORB: A Flat Object Retrieval Benchmark for Universal Image Embedding
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+P">Pengxiang Wu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Siman Wang</a>, 
<a href="/search/cs?searchtype=author&query=Rosa%2C+K+D">Kevin Dela Rosa</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+D+H">Derek Hao Hu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> NeurIPS 2023 Datasets and Benchmarks Track
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Image retrieval is a fundamental task in computer vision. Despite recent
advances in this field, many techniques have been evaluated on a limited number
of domains, with a small number of instance categories. Notably, most existing
works only consider domains like 3D landmarks, making it difficult to
generalize the conclusions made by these works to other domains, e.g., logo and
other 2D flat objects. To bridge this gap, we introduce a new dataset for
benchmarking visual search methods on flat images with diverse patterns. Our
flat object retrieval benchmark (FORB) supplements the commonly adopted 3D
object domain, and more importantly, it serves as a testbed for assessing the
image embedding quality on out-of-distribution domains. In this benchmark we
investigate the retrieval accuracy of representative methods in terms of
candidate ranks, as well as matching score margin, a viewpoint which is largely
ignored by many works. Our experiments not only highlight the challenges and
rich heterogeneity of FORB, but also reveal the hidden properties of different
retrieval strategies. The proposed benchmark is a growing project and we expect
to expand in both quantity and variety of objects. The dataset and supporting
codes are available at https://github.com/pxiangwu/FORB/.
</p>
</div>
</dd>
<dt><a name="item156">[156]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16251" title="Abstract">arXiv:2309.16251</a> [<a href="/pdf/2309.16251" title="Download PDF">pdf</a>, <a href="/format/2309.16251" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The effect of 3D stereopsis and hand-tool alignment on learning  effectiveness and skill transfer of a VR-based simulator for dental training
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kaluschke%2C+M">Maximilian Kaluschke</a>, 
<a href="/search/cs?searchtype=author&query=Yin%2C+M+S">Myat Su Yin</a>, 
<a href="/search/cs?searchtype=author&query=Haddawy%2C+P">Peter Haddawy</a>, 
<a href="/search/cs?searchtype=author&query=Suebnukarn%2C+S">Siriwan Suebnukarn</a>, 
<a href="/search/cs?searchtype=author&query=Zachmann%2C+G">Gabriel Zachmann</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 26 pages, 15 figures, Accepted at online journal PLoS ONE
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">Dental simulators gained prevalence in recent years. Important aspects
distinguishing VR hardware configurations are 3D stereoscopic rendering and
visual alignment of the user's hands with the virtual tools. New dental
simulators are often evaluated without analysing the impact of these simulation
aspects. In this paper, we seek to determine the impact of 3D stereoscopic
rendering and of hand-tool alignment on the teaching effectiveness and skill
assessment accuracy of a VR dental simulator. We developed a bimanual simulator
using an HMD and two haptic devices that provides an immersive environment with
both 3D stereoscopic rendering and hand-tool alignment. We then independently
controlled for each of the two aspects of the simulation. We trained four
groups of students in root canal access opening using the simulator and
measured the virtual and real learning gains. We quantified the real learning
gains by pre- and post-testing using realistic plastic teeth and the virtual
learning gains by scoring the training outcomes inside the simulator. We
developed a scoring metric to automatically score the training outcomes that
strongly correlates with experts' scoring of those outcomes. We found that
hand-tool alignment has a positive impact on virtual and real learning gains,
and improves the accuracy of skill assessment. We found that stereoscopic 3D
had a negative impact on virtual and real learning gains, however it improves
the accuracy of skill assessment. This finding is counter-intuitive, and we
found eye-tooth distance to be a confounding variable of stereoscopic 3D, as it
was significantly lower for the monoscopic 3D condition and negatively
correlates with real learning gain. The results of our study provide valuable
information for the future design of dental simulators, as well as simulators
for other high-precision psycho-motor tasks.
</p>
</div>
</dd>
<dt><a name="item157">[157]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16254" title="Abstract">arXiv:2309.16254</a> [<a href="/pdf/2309.16254" title="Download PDF">pdf</a>, <a href="/format/2309.16254" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the Challenges of Fully Incremental Neural Dependency Parsing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ezquerro%2C+A">Ana Ezquerro</a>, 
<a href="/search/cs?searchtype=author&query=G%C3%B3mez-Rodr%C3%ADguez%2C+C">Carlos G&#xf3;mez-Rodr&#xed;guez</a>, 
<a href="/search/cs?searchtype=author&query=Vilares%2C+D">David Vilares</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at IJCNLP-AACL 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Since the popularization of BiLSTMs and Transformer-based bidirectional
encoders, state-of-the-art syntactic parsers have lacked incrementality,
requiring access to the whole sentence and deviating from human language
processing. This paper explores whether fully incremental dependency parsing
with modern architectures can be competitive. We build parsers combining
strictly left-to-right neural encoders with fully incremental sequence-labeling
and transition-based decoders. The results show that fully incremental parsing
with modern architectures considerably lags behind bidirectional parsing,
noting the challenges of psycholinguistically plausible parsing.
</p>
</div>
</dd>
<dt><a name="item158">[158]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16257" title="Abstract">arXiv:2309.16257</a> [<a href="/pdf/2309.16257" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Nondestructive chicken egg fertility detection using CNN-transfer  learning algorithms
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Saifullah%2C+S">Shoffan Saifullah</a>, 
<a href="/search/cs?searchtype=author&query=Drezewski%2C+R">Rafal Drezewski</a>, 
<a href="/search/cs?searchtype=author&query=Yudhana%2C+A">Anton Yudhana</a>, 
<a href="/search/cs?searchtype=author&query=Pranolo%2C+A">Andri Pranolo</a>, 
<a href="/search/cs?searchtype=author&query=Kaswijanti%2C+W">Wilis Kaswijanti</a>, 
<a href="/search/cs?searchtype=author&query=Suryotomo%2C+A+P">Andiko Putro Suryotomo</a>, 
<a href="/search/cs?searchtype=author&query=Putra%2C+S+A">Seno Aji Putra</a>, 
<a href="/search/cs?searchtype=author&query=Khaliduzzaman%2C+A">Alin Khaliduzzaman</a>, 
<a href="/search/cs?searchtype=author&query=Prabuwono%2C+A+S">Anton Satria Prabuwono</a>, 
<a href="/search/cs?searchtype=author&query=Japkowicz%2C+N">Nathalie Japkowicz</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 18 pages, 9 figures, 1 table, journal article published
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Jurnal Ilmiah Teknik Elektro Komputer dan Informatika (JITEKI),
  Vol 9, No 3 (2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Image and Video Processing (eess.IV)

</div>
<p class="mathjax">This study explored the application of CNN-Transfer Learning for
nondestructive chicken egg fertility detection for precision poultry hatchery
practices. Four models, VGG16, ResNet50, InceptionNet, and MobileNet, were
trained and evaluated on a dataset (200 single egg images) using augmented
images (rotation, flip, scale, translation, and reflection). Although the
training results demonstrated that all models achieved high accuracy,
indicating their ability to accurately learn and classify chicken eggs'
fertility state, when evaluated on the testing set, variations in accuracy and
performance were observed. InceptionNet exhibited the best overall performance,
accurately classifying fertile and non-fertile eggs. It demonstrated excellent
performance in both training and testing sets in all parameters of the
evaluation metrics. In testing set, it achieved an accuracy of 0.98, a
sensitivity of 1 for detecting fertile eggs, and a specificity of 0.96 for
identifying non-fertile eggs. The higher performance is attributed to its
unique architecture efficiently capturing features at different scales leading
to improved accuracy and robustness. Further optimization and fine-tuning of
the models might necessary to address the limitations in accurately detecting
fertile and non-fertile eggs in case of other models. This study highlighted
the potential of CNN-Transfer Learning for nondestructive fertility detection
and emphasizes the need for further research to enhance the models'
capabilities and ensure accurate classification.
</p>
</div>
</dd>
<dt><a name="item159">[159]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16263" title="Abstract">arXiv:2309.16263</a> [<a href="/pdf/2309.16263" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Cooperation Dynamics in Multi-Agent Systems: Exploring Game-Theoretic  Scenarios with Mean-Field Equilibria
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sathi%2C+V">Vaigarai Sathi</a>, 
<a href="/search/cs?searchtype=author&query=Shaik%2C+S">Sabahat Shaik</a>, 
<a href="/search/cs?searchtype=author&query=Nidamanuri%2C+J">Jaswanth Nidamanuri</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to MADGames: Multi-Agent Dynamic Games Workshop at IROS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Cooperation is fundamental in Multi-Agent Systems (MAS) and Multi-Agent
Reinforcement Learning (MARL), often requiring agents to balance individual
gains with collective rewards. In this regard, this paper aims to investigate
strategies to invoke cooperation in game-theoretic scenarios, namely the
Iterated Prisoner's Dilemma, where agents must optimize both individual and
group outcomes. Existing cooperative strategies are analyzed for their
effectiveness in promoting group-oriented behavior in repeated games.
Modifications are proposed where encouraging group rewards will also result in
a higher individual gain, addressing real-world dilemmas seen in distributed
systems. The study extends to scenarios with exponentially growing agent
populations ($N \longrightarrow +\infty$), where traditional computation and
equilibrium determination are challenging. Leveraging mean-field game theory,
equilibrium solutions and reward structures are established for infinitely
large agent sets in repeated games. Finally, practical insights are offered
through simulations using the Multi Agent-Posthumous Credit Assignment trainer,
and the paper explores adapting simulation algorithms to create scenarios
favoring cooperation for group rewards. These practical implementations bridge
theoretical concepts with real-world applications.
</p>
</div>
</dd>
<dt><a name="item160">[160]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16264" title="Abstract">arXiv:2309.16264</a> [<a href="/pdf/2309.16264" title="Download PDF">pdf</a>, <a href="/format/2309.16264" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GAMMA: Generalizable Articulation Modeling and Manipulation for  Articulated Objects
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yu%2C+Q">Qiaojun Yu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Junbo Wang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+W">Wenhai Liu</a>, 
<a href="/search/cs?searchtype=author&query=Hao%2C+C">Ce Hao</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+L">Liu Liu</a>, 
<a href="/search/cs?searchtype=author&query=Shao%2C+L">Lin Shao</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+W">Weiming Wang</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+C">Cewu Lu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 5 figures, submitted to ICRA 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Articulated objects like cabinets and doors are widespread in daily life.
However, directly manipulating 3D articulated objects is challenging because
they have diverse geometrical shapes, semantic categories, and kinetic
constraints. Prior works mostly focused on recognizing and manipulating
articulated objects with specific joint types. They can either estimate the
joint parameters or distinguish suitable grasp poses to facilitate trajectory
planning. Although these approaches have succeeded in certain types of
articulated objects, they lack generalizability to unseen objects, which
significantly impedes their application in broader scenarios. In this paper, we
propose a novel framework of Generalizable Articulation Modeling and
Manipulating for Articulated Objects (GAMMA), which learns both articulation
modeling and grasp pose affordance from diverse articulated objects with
different categories. In addition, GAMMA adopts adaptive manipulation to
iteratively reduce the modeling errors and enhance manipulation performance. We
train GAMMA with the PartNet-Mobility dataset and evaluate with comprehensive
experiments in SAPIEN simulation and real-world Franka robot arms. Results show
that GAMMA significantly outperforms SOTA articulation modeling and
manipulation algorithms in unseen and cross-category articulated objects. We
will open-source all codes and datasets in both simulation and real robots for
reproduction in the final version. Images and videos are published on the
project website at: <a href="http://sites.google.com/view/gamma-articulation">this http URL</a>
</p>
</div>
</dd>
<dt><a name="item161">[161]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16265" title="Abstract">arXiv:2309.16265</a> [<a href="/pdf/2309.16265" title="Download PDF">pdf</a>, <a href="/format/2309.16265" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Semantic Proximity Alignment: Towards Human Perception-consistent Audio  Tagging by Aligning with Label Text Description
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+W">Wuyang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Ren%2C+Y">Yanzhen Ren</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages, 3 figures. Submitted to ICASSP 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">Most audio tagging models are trained with one-hot labels as supervised
information. However, one-hot labels treat all sound events equally, ignoring
the semantic hierarchy and proximity relationships between sound events. In
contrast, the event descriptions contains richer information, describing the
distance between different sound events with semantic proximity. In this paper,
we explore the impact of training audio tagging models with auxiliary text
descriptions of sound events. By aligning the audio features with the text
features of corresponding labels, we inject the hierarchy and proximity
information of sound events into audio encoders, improving the performance
while making the prediction more consistent with human perception. We refer to
this approach as Semantic Proximity Alignment (SPA). We use Ontology-aware mean
Average Precision (OmAP) as the main evaluation metric for the models. OmAP
reweights the false positives based on Audioset ontology distance and is more
consistent with human perception compared to mAP. Experimental results show
that the audio tagging models trained with SPA achieve higher OmAP compared to
models trained with one-hot labels solely (+1.8 OmAP). Human evaluations also
demonstrate that the predictions of SPA models are more consistent with human
perception.
</p>
</div>
</dd>
<dt><a name="item162">[162]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16267" title="Abstract">arXiv:2309.16267</a> [<a href="/pdf/2309.16267" title="Download PDF">pdf</a>, <a href="/format/2309.16267" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Hyper-reduction for Petrov-Galerkin reduced order models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=de+Parga%2C+S+A">S. Ares de Parga</a>, 
<a href="/search/cs?searchtype=author&query=Bravo%2C+J+R">J.R. Bravo</a>, 
<a href="/search/cs?searchtype=author&query=Hernandez%2C+J+A">J.A. Hernandez</a>, 
<a href="/search/cs?searchtype=author&query=Zorrilla%2C+R">R. Zorrilla</a>, 
<a href="/search/cs?searchtype=author&query=Rossi%2C+R">R. Rossi</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Computer Methods in Applied Mechanics and Engineering, vol. 416,
  pp. 116298, 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Engineering, Finance, and Science (cs.CE)</span>

</div>
<p class="mathjax">Projection-based Reduced Order Models minimize the discrete residual of a
"full order model" (FOM) while constraining the unknowns to a reduced dimension
space. For problems with symmetric positive definite (SPD) Jacobians, this is
optimally achieved by projecting the full order residual onto the approximation
basis (Galerkin Projection). This is sub-optimal for non-SPD Jacobians as it
only minimizes the projection of the residual, not the residual itself. An
alternative is to directly minimize the 2-norm of the residual, achievable
using QR factorization or the method of the normal equations (LSPG). The first
approach involves constructing and factorizing a large matrix, while LSPG
avoids this but requires constructing a product element by element,
necessitating a complementary mesh and adding complexity to the hyper-reduction
process. This work proposes an alternative based on Petrov-Galerkin
minimization. We choose a left basis for a least-squares minimization on a
reduced problem, ensuring the discrete full order residual is minimized. This
is applicable to both SPD and non-SPD Jacobians, allowing element-by-element
assembly, avoiding the use of a complementary mesh, and simplifying finite
element implementation. The technique is suitable for hyper-reduction using the
Empirical Cubature Method and is applicable in nonlinear reduction procedures.
</p>
</div>
</dd>
<dt><a name="item163">[163]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16269" title="Abstract">arXiv:2309.16269</a> [<a href="/pdf/2309.16269" title="Download PDF">pdf</a>, <a href="/ps/2309.16269" title="Download PostScript">ps</a>, <a href="/format/2309.16269" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Hierarchical Network Data Analytics Framework for B5G Network  Automation: Design and Implementation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jeon%2C+Y">Youbin Jeon</a>, 
<a href="/search/cs?searchtype=author&query=Pack%2C+S">Sangheon Pack</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>; Machine Learning (cs.LG); Performance (cs.PF)

</div>
<p class="mathjax">5G introduced modularized network functions (NFs) to support emerging
services in a more flexible and elastic manner. To mitigate the complexity in
such modularized NF management, automated network operation and management are
indispensable, and thus the 3rd generation partnership project (3GPP) has
introduced a network data analytics function (NWDAF). However, a conventional
NWDAF needs to conduct both inference and training tasks, and thus it is
difficult to provide the analytics results to NFs in a timely manner for an
increased number of analytics requests. In this article, we propose a
hierarchical network data analytics framework (H-NDAF) where inference tasks
are distributed to multiple leaf NWDAFs and training tasks are conducted at the
root NWDAF. Extensive simulation results using open-source software (i.e.,
free5GC) demonstrate that H-NDAF can provide sufficiently accurate analytics
and faster analytics provision time compared to the conventional NWDAF.
</p>
</div>
</dd>
<dt><a name="item164">[164]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16270" title="Abstract">arXiv:2309.16270</a> [<a href="/pdf/2309.16270" title="Download PDF">pdf</a>, <a href="/format/2309.16270" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Social Media Fashion Knowledge Extraction as Captioning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yuan%2C+Y">Yifei Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+W">Wenxuan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Deng%2C+Y">Yang Deng</a>, 
<a href="/search/cs?searchtype=author&query=Lam%2C+W">Wai Lam</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by SIGIR-AP 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Social media plays a significant role in boosting the fashion industry, where
a massive amount of fashion-related posts are generated every day. In order to
obtain the rich fashion information from the posts, we study the task of social
media fashion knowledge extraction. Fashion knowledge, which typically consists
of the occasion, person attributes, and fashion item information, can be
effectively represented as a set of tuples. Most previous studies on fashion
knowledge extraction are based on the fashion product images without
considering the rich text information in social media posts. Existing work on
fashion knowledge extraction in social media is classification-based and
requires to manually determine a set of fashion knowledge categories in
advance. In our work, we propose to cast the task as a captioning problem to
capture the interplay of the multimodal post information. Specifically, we
transform the fashion knowledge tuples into a natural language caption with a
sentence transformation method. Our framework then aims to generate the
sentence-based fashion knowledge directly from the social media post. Inspired
by the big success of pre-trained models, we build our model based on a
multimodal pre-trained generative model and design several auxiliary tasks for
enhancing the knowledge extraction. Since there is no existing dataset which
can be directly borrowed to our task, we introduce a dataset consisting of
social media posts with manual fashion knowledge annotation. Extensive
experiments are conducted to demonstrate the effectiveness of our model.
</p>
</div>
</dd>
<dt><a name="item165">[165]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16273" title="Abstract">arXiv:2309.16273</a> [<a href="/pdf/2309.16273" title="Download PDF">pdf</a>, <a href="/ps/2309.16273" title="Download PostScript">ps</a>, <a href="/format/2309.16273" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A harmonic framework for the identification of linear time-periodic  systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Vernerey%2C+F">Flora Vernerey</a> (CRAN), 
<a href="/search/eess?searchtype=author&query=Riedinger%2C+P">Pierre Riedinger</a> (CRAN), 
<a href="/search/eess?searchtype=author&query=Iannelli%2C+A">Andrea Iannelli</a>, 
<a href="/search/eess?searchtype=author&query=Daafouz%2C+J">Jamal Daafouz</a> (CRAN)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">This paper presents a novel approach for the identification of linear
time-periodic (LTP) systems in continuous time. This method is based on
harmonic modeling and consists in converting any LTP system into an equivalent
LTI system with infinite dimension. Leveraging specific harmonic properties, we
demonstrate that solving this infinite-dimensional identification problem can
be reduced to solving a finitedimensional linear least-squares problem. The
result is an approximation of the original solution with an arbitrarily small
error. Our approach offers several significant advantages. The first one is
closely tied to the harmonic system's inherent LTI characteristic, along with
the Toeplitz structure exhibited by its elements. The second advantage is
related to the regularization property achieved through the integral action
when computing the phasors from input and state trajectories. Finally, our
method avoids the computation of signals' derivative. This sets our approach
apart from existing methods that rely on such computations, which can be a
notable drawback, especially in continuous-time settings. We provide numerical
simulations that convincingly demonstrate the effectiveness of the proposed
method, even in scenarios where signals are corrupted by noise.
</p>
</div>
</dd>
<dt><a name="item166">[166]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16275" title="Abstract">arXiv:2309.16275</a> [<a href="/pdf/2309.16275" title="Download PDF">pdf</a>, <a href="/format/2309.16275" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> UPB @ ACTI: Detecting Conspiracies using fine tuned Sentence  Transformers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Paraschiv%2C+A">Andrei Paraschiv</a>, 
<a href="/search/cs?searchtype=author&query=Dascalu%2C+M">Mihai Dascalu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Conspiracy theories have become a prominent and concerning aspect of online
discourse, posing challenges to information integrity and societal trust. As
such, we address conspiracy theory detection as proposed by the ACTI @ EVALITA
2023 shared task. The combination of pre-trained sentence Transformer models
and data augmentation techniques enabled us to secure first place in the final
leaderboard of both sub-tasks. Our methodology attained F1 scores of 85.71% in
the binary classification and 91.23% for the fine-grained conspiracy topic
classification, surpassing other competing systems.
</p>
</div>
</dd>
<dt><a name="item167">[167]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16279" title="Abstract">arXiv:2309.16279</a> [<a href="/pdf/2309.16279" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Using Integer Constraint Solving in Reuse Based Requirements Engineering
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Salinesi%2C+C">Camille Salinesi</a> (CRI), 
<a href="/search/cs?searchtype=author&query=Mazo%2C+R">Raul Mazo</a> (CRI), 
<a href="/search/cs?searchtype=author&query=Diaz%2C+D">Daniel Diaz</a> (CRI), 
<a href="/search/cs?searchtype=author&query=Djebbi%2C+O">Olfa Djebbi</a> (CRI)
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> 18th IEEE International Requirements Engineering Conference (RE),
  2010, Sep 2010, Sydney, Australia. pp.243-251
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
<p class="mathjax">Product Lines (PL) have proved an effective approach to reuse-based systems
development. Several modeling languages were proposed so far to specify PL.
Although they can be very different, these languages show two common features:
they emphasize (a) variability, and (b) the specification of constraints to
define acceptable configurations. It is now widely acknowledged that
configuring a product can be considered as a constraint satisfaction problem.
It is thus natural to consider constraint programming as a first choice
candidate to specify constraints on PL. For instance, the different constraints
that can be specified using the FODA language can easily be expressed using
boolean constraints, which enables automated calculation and configuration
using a SAT solver. But constraint programming proposes other domains than the
boolean domain: for instance integers, real, or sets. The integer domain was,
for instance, proposed by Benavides to specify constraints on feature
attributes. This paper proposes to further explore the use of integer
constraint programming to specify PL constraints. The approach was implemented
in a prototype tool. Its use in a real case showed that constraint programming
encompasses different PL modeling languages (such as FORE, OVM, or else), and
allows specifying complex constraints that are difficult to specify with these
languages.
</p>
</div>
</dd>
<dt><a name="item168">[168]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16282" title="Abstract">arXiv:2309.16282</a> [<a href="/pdf/2309.16282" title="Download PDF">pdf</a>, <a href="/format/2309.16282" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AgEncID: Aggregate Encryption Individual Decryption of Key for FPGA  Bitstream IP Cores in Cloud
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Debnath%2C+M">Mukta Debnath</a>, 
<a href="/search/cs?searchtype=author&query=Guha%2C+K">Krishnendu Guha</a>, 
<a href="/search/cs?searchtype=author&query=Saha%2C+D">Debasri Saha</a>, 
<a href="/search/cs?searchtype=author&query=Sur-Kolay%2C+S">Susmita Sur-Kolay</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 21 pages, 7 figures, 5 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">Cloud computing platforms are progressively adopting Field Programmable Gate
Arrays to deploy specialized hardware accelerators for specific computational
tasks. However, the security of FPGA-based bitstream for Intellectual Property,
IP cores from unauthorized interception in cloud environments remains a
prominent concern. Existing methodologies for protection of such bitstreams
possess several limitations, such as requiring a large number of keys, tying
bitstreams to specific FPGAs, and relying on trusted third parties. This paper
proposes Aggregate Encryption and Individual Decryption, a cryptosystem based
on key aggregation to enhance the security of FPGA-based bitstream for IP cores
and to address the pitfalls of previous related works. In our proposed scheme,
IP providers can encrypt their bitstreams with a single key for a set S of FPGA
boards, with which the bitstreams can directly be decrypted on any of the FPGA
boards in S. Aggregate encryption of the key is performed in a way which
ensures that the key can solely be obtained onboard through individual
decryption employing the board's private key, thus facilitating secure key
provisioning. The proposed cryptosystem is evaluated mainly on Zynq FPGAs. The
outcomes demonstrate that our cryptosystem not only outperforms existing
techniques with respect to resource, time and energy significantly but also
upholds robust security assurances.
</p>
</div>
</dd>
<dt><a name="item169">[169]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16283" title="Abstract">arXiv:2309.16283</a> [<a href="/pdf/2309.16283" title="Download PDF">pdf</a>, <a href="/format/2309.16283" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Self-supervised Cross-view Representation Reconstruction for Change  Captioning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tu%2C+Y">Yunbin Tu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+L">Liang Li</a>, 
<a href="/search/cs?searchtype=author&query=Su%2C+L">Li Su</a>, 
<a href="/search/cs?searchtype=author&query=Zha%2C+Z">Zheng-Jun Zha</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+C">Chenggang Yan</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+Q">Qingming Huang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by ICCV 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Computation and Language (cs.CL)

</div>
<p class="mathjax">Change captioning aims to describe the difference between a pair of similar
images. Its key challenge is how to learn a stable difference representation
under pseudo changes caused by viewpoint change. In this paper, we address this
by proposing a self-supervised cross-view representation reconstruction
(SCORER) network. Concretely, we first design a multi-head token-wise matching
to model relationships between cross-view features from similar/dissimilar
images. Then, by maximizing cross-view contrastive alignment of two similar
images, SCORER learns two view-invariant image representations in a
self-supervised way. Based on these, we reconstruct the representations of
unchanged objects by cross-attention, thus learning a stable difference
representation for caption generation. Further, we devise a cross-modal
backward reasoning to improve the quality of caption. This module reversely
models a ``hallucination'' representation with the caption and ``before''
representation. By pushing it closer to the ``after'' representation, we
enforce the caption to be informative about the difference in a self-supervised
manner. Extensive experiments show our method achieves the state-of-the-art
results on four datasets. The code is available at
https://github.com/tuyunbin/SCORER.
</p>
</div>
</dd>
<dt><a name="item170">[170]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16284" title="Abstract">arXiv:2309.16284</a> [<a href="/pdf/2309.16284" title="Download PDF">pdf</a>, <a href="/format/2309.16284" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> NOMAD: Unsupervised Learning of Perceptual Embeddings for Speech  Enhancement and Non-matching Reference Audio Quality Assessment
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ragano%2C+A">Alessandro Ragano</a>, 
<a href="/search/cs?searchtype=author&query=Skoglund%2C+J">Jan Skoglund</a>, 
<a href="/search/cs?searchtype=author&query=Hines%2C+A">Andrew Hines</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">This paper presents NOMAD (Non-Matching Audio Distance), a differentiable
perceptual similarity metric that measures the distance of a degraded signal
against non-matching references. The proposed method is based on learning deep
feature embeddings via a triplet loss guided by the Neurogram Similarity Index
Measure (NSIM) to capture degradation intensity. During inference, the
similarity score between any two audio samples is computed through Euclidean
distance of their embeddings. NOMAD is fully unsupervised and can be used in
general perceptual audio tasks for audio analysis e.g. quality assessment and
generative tasks such as speech enhancement and speech synthesis. The proposed
method is evaluated with 3 tasks. Ranking degradation intensity, predicting
speech quality, and as a loss function for speech enhancement. Results indicate
NOMAD outperforms other non-matching reference approaches in both ranking
degradation intensity and quality assessment, exhibiting competitive
performance with full-reference audio metrics. NOMAD demonstrates a promising
technique that mimics human capabilities in assessing audio quality with
non-matching references to learn perceptual embeddings without the need for
human-generated labels.
</p>
</div>
</dd>
<dt><a name="item171">[171]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16285" title="Abstract">arXiv:2309.16285</a> [<a href="/pdf/2309.16285" title="Download PDF">pdf</a>, <a href="/format/2309.16285" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Framework to Assess Knowledge Graphs Accountability
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Andersen%2C+J">Jennie Andersen</a>, 
<a href="/search/cs?searchtype=author&query=Cazalens%2C+S">Sylvie Cazalens</a>, 
<a href="/search/cs?searchtype=author&query=Lamarre%2C+P">Philippe Lamarre</a>, 
<a href="/search/cs?searchtype=author&query=Maillot%2C+P">Pierre Maillot</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, to be published in: 2023 IEEE International Conference on Web Intelligence and Intelligent Agent Technology (WI-IAT)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Databases (cs.DB)</span>

</div>
<p class="mathjax">Knowledge Graphs (KGs), and Linked Open Data in particular, enable the
generation and exchange of more and more information on the Web. In order to
use and reuse these data properly, the presence of accountability information
is essential. Accountability requires specific and accurate information about
people's responsibilities and actions. In this article, we define KGAcc, a
framework dedicated to the assessment of RDF graphs accountability. It consists
of accountability requirements and a measure of accountability for KGs. Then,
we evaluate KGs from the LOD cloud and describe the results obtained. Finally,
we compare our approach with data quality and FAIR assessment frameworks to
highlight the differences.
</p>
</div>
</dd>
<dt><a name="item172">[172]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16286" title="Abstract">arXiv:2309.16286</a> [<a href="/pdf/2309.16286" title="Download PDF">pdf</a>, <a href="/format/2309.16286" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Generalizable Heterogeneous Federated Cross-Correlation and Instance  Similarity Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+W">Wenke Huang</a>, 
<a href="/search/cs?searchtype=author&query=Ye%2C+M">Mang Ye</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+Z">Zekun Shi</a>, 
<a href="/search/cs?searchtype=author&query=Du%2C+B">Bo Du</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Federated learning is an important privacy-preserving multi-party learning
paradigm, involving collaborative learning with others and local updating on
private data. Model heterogeneity and catastrophic forgetting are two crucial
challenges, which greatly limit the applicability and generalizability. This
paper presents a novel FCCL+, federated correlation and similarity learning
with non-target distillation, facilitating the both intra-domain
discriminability and inter-domain generalization. For heterogeneity issue, we
leverage irrelevant unlabeled public data for communication between the
heterogeneous participants. We construct cross-correlation matrix and align
instance similarity distribution on both logits and feature levels, which
effectively overcomes the communication barrier and improves the generalizable
ability. For catastrophic forgetting in local updating stage, FCCL+ introduces
Federated Non Target Distillation, which retains inter-domain knowledge while
avoiding the optimization conflict issue, fulling distilling privileged
inter-domain information through depicting posterior classes relation.
Considering that there is no standard benchmark for evaluating existing
heterogeneous federated learning under the same setting, we present a
comprehensive benchmark with extensive representative methods under four domain
shift scenarios, supporting both heterogeneous and homogeneous federated
settings. Empirical results demonstrate the superiority of our method and the
efficiency of modules on various scenarios.
</p>
</div>
</dd>
<dt><a name="item173">[173]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16287" title="Abstract">arXiv:2309.16287</a> [<a href="/pdf/2309.16287" title="Download PDF">pdf</a>, <a href="/format/2309.16287" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Predicting performance difficulty from piano sheet music images
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ramoneda%2C+P">Pedro Ramoneda</a>, 
<a href="/search/cs?searchtype=author&query=Valero-Mas%2C+J+J">Jose J. Valero-Mas</a>, 
<a href="/search/cs?searchtype=author&query=Jeong%2C+D">Dasaem Jeong</a>, 
<a href="/search/cs?searchtype=author&query=Serra%2C+X">Xavier Serra</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Digital Libraries (cs.DL); Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">Estimating the performance difficulty of a musical score is crucial in music
education for adequately designing the learning curriculum of the students.
Although the Music Information Retrieval community has recently shown interest
in this task, existing approaches mainly use machine-readable scores, leaving
the broader case of sheet music images unaddressed. Based on previous works
involving sheet music images, we use a mid-level representation, bootleg score,
describing notehead positions relative to staff lines coupled with a
transformer model. This architecture is adapted to our task by introducing an
encoding scheme that reduces the encoded sequence length to one-eighth of the
original size. In terms of evaluation, we consider five datasets -- more than
7500 scores with up to 9 difficulty levels -- , two of them particularly
compiled for this work. The results obtained when pretraining the scheme on the
IMSLP corpus and fine-tuning it on the considered datasets prove the proposal's
validity, achieving the best-performing model with a balanced accuracy of
40.34\% and a mean square error of 1.33. Finally, we provide access to our
code, data, and models for transparency and reproducibility.
</p>
</div>
</dd>
<dt><a name="item174">[174]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16289" title="Abstract">arXiv:2309.16289</a> [<a href="/pdf/2309.16289" title="Download PDF">pdf</a>, <a href="/format/2309.16289" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LawBench: Benchmarking Legal Knowledge of Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fei%2C+Z">Zhiwei Fei</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+X">Xiaoyu Shen</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+D">Dawei Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+F">Fengzhe Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+Z">Zhuo Han</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+S">Songyang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+K">Kai Chen</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+Z">Zongwen Shen</a>, 
<a href="/search/cs?searchtype=author&query=Ge%2C+J">Jidong Ge</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Large language models (LLMs) have demonstrated strong capabilities in various
aspects. However, when applying them to the highly specialized, safe-critical
legal domain, it is unclear how much legal knowledge they possess and whether
they can reliably perform legal-related tasks. To address this gap, we propose
a comprehensive evaluation benchmark LawBench. LawBench has been meticulously
crafted to have precise assessment of the LLMs' legal capabilities from three
cognitive levels: (1) Legal knowledge memorization: whether LLMs can memorize
needed legal concepts, articles and facts; (2) Legal knowledge understanding:
whether LLMs can comprehend entities, events and relationships within legal
text; (3) Legal knowledge applying: whether LLMs can properly utilize their
legal knowledge and make necessary reasoning steps to solve realistic legal
tasks. LawBench contains 20 diverse tasks covering 5 task types: single-label
classification (SLC), multi-label classification (MLC), regression, extraction
and generation. We perform extensive evaluations of 51 LLMs on LawBench,
including 20 multilingual LLMs, 22 Chinese-oriented LLMs and 9 legal specific
LLMs. The results show that GPT-4 remains the best-performing LLM in the legal
domain, surpassing the others by a significant margin. While fine-tuning LLMs
on legal specific text brings certain improvements, we are still a long way
from obtaining usable and reliable LLMs in legal tasks. All data, model
predictions and evaluation code are released in
https://github.com/open-compass/LawBench/. We hope this benchmark provides
in-depth understanding of the LLMs' domain-specified capabilities and speed up
the development of LLMs in the legal domain.
</p>
</div>
</dd>
<dt><a name="item175">[175]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16291" title="Abstract">arXiv:2309.16291</a> [<a href="/pdf/2309.16291" title="Download PDF">pdf</a>, <a href="/format/2309.16291" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Efficiency Separation between RL Methods: Model-Free, Model-Based and  Goal-Conditioned
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pinon%2C+B">Brieuc Pinon</a>, 
<a href="/search/cs?searchtype=author&query=Jungers%2C+R">Rapha&#xeb;l Jungers</a>, 
<a href="/search/cs?searchtype=author&query=Delvenne%2C+J">Jean-Charles Delvenne</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">We prove a fundamental limitation on the efficiency of a wide class of
Reinforcement Learning (RL) algorithms. This limitation applies to model-free
RL methods as well as a broad range of model-based methods, such as planning
with tree search.
<br />Under an abstract definition of this class, we provide a family of RL
problems for which these methods suffer a lower bound exponential in the
horizon for their interactions with the environment to find an optimal
behavior. However, there exists a method, not tailored to this specific family
of problems, which can efficiently solve the problems in the family.
<br />In contrast, our limitation does not apply to several types of methods
proposed in the literature, for instance, goal-conditioned methods or other
algorithms that construct an inverse dynamics model.
</p>
</div>
</dd>
<dt><a name="item176">[176]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16292" title="Abstract">arXiv:2309.16292</a> [<a href="/pdf/2309.16292" title="Download PDF">pdf</a>, <a href="/format/2309.16292" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DiLu: A Knowledge-Driven Approach to Autonomous Driving with Large  Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wen%2C+L">Licheng Wen</a>, 
<a href="/search/cs?searchtype=author&query=Fu%2C+D">Daocheng Fu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xin Li</a>, 
<a href="/search/cs?searchtype=author&query=Cai%2C+X">Xinyu Cai</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+T">Tao Ma</a>, 
<a href="/search/cs?searchtype=author&query=Cai%2C+P">Pinlong Cai</a>, 
<a href="/search/cs?searchtype=author&query=Dou%2C+M">Min Dou</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+B">Botian Shi</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+L">Liang He</a>, 
<a href="/search/cs?searchtype=author&query=Qiao%2C+Y">Yu Qiao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Computation and Language (cs.CL)

</div>
<p class="mathjax">Recent advancements in autonomous driving have relied on data-driven
approaches, which are widely adopted but face challenges including dataset
bias, overfitting, and uninterpretability. Drawing inspiration from the
knowledge-driven nature of human driving, we explore the question of how to
instill similar capabilities into autonomous driving systems and summarize a
paradigm that integrates an interactive environment, a driver agent, as well as
a memory component to address this question. Leveraging large language models
with emergent abilities, we propose the DiLu framework, which combines a
Reasoning and a Reflection module to enable the system to perform
decision-making based on common-sense knowledge and evolve continuously.
Extensive experiments prove DiLu's capability to accumulate experience and
demonstrate a significant advantage in generalization ability over
reinforcement learning-based methods. Moreover, DiLu is able to directly
acquire experiences from real-world datasets which highlights its potential to
be deployed on practical autonomous driving systems. To the best of our
knowledge, we are the first to instill knowledge-driven capability into
autonomous driving systems from the perspective of how humans drive.
</p>
</div>
</dd>
<dt><a name="item177">[177]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16298" title="Abstract">arXiv:2309.16298</a> [<a href="/pdf/2309.16298" title="Download PDF">pdf</a>, <a href="/format/2309.16298" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> At Which Training Stage Does Cocde Data Help LLMs Reasoning?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ma%2C+Y">Yingwei Ma</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yue Liu</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+Y">Yue Yu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yuanliang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+Y">Yu Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+C">Changjian Wang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+S">Shanshan Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Large Language Models (LLMs) have exhibited remarkable reasoning capabilities
and become the foundation of language technologies. Inspired by the great
success of code data in training LLMs, we naturally wonder at which training
stage introducing code data can really help LLMs reasoning. To this end, this
paper systematically explores the impact of code data on LLMs at different
stages. Concretely, we introduce the code data at the pre-training stage,
instruction-tuning stage, and both of them, respectively. Then, the reasoning
capability of LLMs is comprehensively and fairly evaluated via six reasoning
tasks in five domains. We critically analyze the experimental results and
provide conclusions with insights. First, pre-training LLMs with the mixture of
code and text can significantly enhance LLMs' general reasoning capability
almost without negative transfer on other tasks. Besides, at the
instruction-tuning stage, code data endows LLMs the task-specific reasoning
capability. Moreover, the dynamic mixing strategy of code and text data assists
LLMs to learn reasoning capability step-by-step during training. These insights
deepen the understanding of LLMs regarding reasoning ability for their
application, such as scientific question answering, legal support, etc. The
source code and model parameters are released at the
link:~\url{https://github.com/yingweima2022/CodeLLM}.
</p>
</div>
</dd>
<dt><a name="item178">[178]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16299" title="Abstract">arXiv:2309.16299</a> [<a href="/pdf/2309.16299" title="Download PDF">pdf</a>, <a href="/format/2309.16299" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CasIL: Cognizing and Imitating Skills via a Dual Cognition-Action  Architecture
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+Z">Zixuan Chen</a>, 
<a href="/search/cs?searchtype=author&query=Ji%2C+Z">Ze Ji</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+S">Shuyang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Huo%2C+J">Jing Huo</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yiyu Chen</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+Y">Yang Gao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Human-Computer Interaction (cs.HC); Machine Learning (cs.LG)

</div>
<p class="mathjax">Enabling robots to effectively imitate expert skills in longhorizon tasks
such as locomotion, manipulation, and more, poses a long-standing challenge.
Existing imitation learning (IL) approaches for robots still grapple with
sub-optimal performance in complex tasks. In this paper, we consider how this
challenge can be addressed within the human cognitive priors. Heuristically, we
extend the usual notion of action to a dual Cognition (high-level)-Action
(low-level) architecture by introducing intuitive human cognitive priors, and
propose a novel skill IL framework through human-robot interaction, called
Cognition-Action-based Skill Imitation Learning (CasIL), for the robotic agent
to effectively cognize and imitate the critical skills from raw visual
demonstrations. CasIL enables both cognition and action imitation, while
high-level skill cognition explicitly guides low-level primitive actions,
providing robustness and reliability to the entire skill IL process. We
evaluated our method on MuJoCo and RLBench benchmarks, as well as on the
obstacle avoidance and point-goal navigation tasks for quadrupedal robot
locomotion. Experimental results show that our CasIL consistently achieves
competitive and robust skill imitation capability compared to other
counterparts in a variety of long-horizon robotic tasks.
</p>
</div>
</dd>
<dt><a name="item179">[179]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16301" title="Abstract">arXiv:2309.16301</a> [<a href="/pdf/2309.16301" title="Download PDF">pdf</a>, <a href="/format/2309.16301" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multi-scale Recurrent LSTM and Transformer Network for Depth Completion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jia%2C+X">Xiaogang Jia</a>, 
<a href="/search/cs?searchtype=author&query=Tan%2C+Y">Yusong Tan</a>, 
<a href="/search/cs?searchtype=author&query=Jian%2C+S">Songlei Jian</a>, 
<a href="/search/cs?searchtype=author&query=Che%2C+Y">Yonggang Che</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Lidar depth completion is a new and hot topic of depth estimation. In this
task, it is the key and difficult point to fuse the features of color space and
depth space. In this paper, we migrate the classic LSTM and Transformer modules
from NLP to depth completion and redesign them appropriately. Specifically, we
use Forget gate, Update gate, Output gate, and Skip gate to achieve the
efficient fusion of color and depth features and perform loop optimization at
multiple scales. Finally, we further fuse the deep features through the
Transformer multi-head attention mechanism. Experimental results show that
without repetitive network structure and post-processing steps, our method can
achieve state-of-the-art performance by adding our modules to a simple
encoder-decoder network structure. Our method ranks first on the current
mainstream autonomous driving KITTI benchmark dataset. It can also be regarded
as a backbone network for other methods, which likewise achieves
state-of-the-art performance.
</p>
</div>
</dd>
<dt><a name="item180">[180]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16304" title="Abstract">arXiv:2309.16304</a> [<a href="/pdf/2309.16304" title="Download PDF">pdf</a>, <a href="/format/2309.16304" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Single-Shot Lossy Compression for Joint Inference and Reconstruction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=%C3%9Clger%2C+O+K">O&#x11f;uzhan Kubilay &#xdc;lger</a>, 
<a href="/search/cs?searchtype=author&query=Erkip%2C+E">Elza Erkip</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>

</div>
<p class="mathjax">In the classical source coding problem, the compressed source is
reconstructed at the decoder with respect to some distortion metric. Motivated
by settings in which we are interested in more than simply reconstructing the
compressed source, we investigate a single-shot compression problem where the
decoder is tasked with reconstructing the original data as well as making
inferences from it. Quality of inference and reconstruction is determined by a
distortion criteria for each task. Given allowable distortion levels, we are
interested in characterizing the probability of excess distortion. Modeling the
joint inference and reconstruction problem as direct-indirect source coding
one, we obtain lower and upper bounds for excess distortion probability. We
specialize the converse bound and present a new easily computable achievability
bound for the case where the distortion metric for reconstruction is
logarithmic loss.
</p>
</div>
</dd>
<dt><a name="item181">[181]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16305" title="Abstract">arXiv:2309.16305</a> [<a href="/pdf/2309.16305" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Does Explanation Matter? An Exploratory Study on the Effects of Covid 19  Misinformation Warning Flags on Social Media
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Barman%2C+D">Dipto Barman</a>, 
<a href="/search/cs?searchtype=author&query=Conlan%2C+O">Owen Conlan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Social and Information Networks (cs.SI); Physics and Society (physics.soc-ph)

</div>
<p class="mathjax">We investigate whether adding specific explanations from fact checking
websites enhances trust in these flags. We experimented with 348 American
participants, exposing them to a randomised order of true and false news
headlines related to COVID 19, with and without warning flags and explanation
text. Our findings suggest that warning flags, whether alone or accompanied by
explanatory text, effectively reduce the perceived accuracy of fake news and
the intent to share such headlines. Interestingly, our study also suggests that
incorporating explanatory text in misinformation warning systems could
significantly enhance their trustworthiness, emphasising the importance of
transparency and user comprehension in combating fake news on social media.
</p>
</div>
</dd>
<dt><a name="item182">[182]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16306" title="Abstract">arXiv:2309.16306</a> [<a href="/pdf/2309.16306" title="Download PDF">pdf</a>, <a href="/format/2309.16306" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Can the Query-based Object Detector Be Designed with Fewer Stages?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jialin Li</a>, 
<a href="/search/cs?searchtype=author&query=Fu%2C+W">Weifu Fu</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+Y">Yuhuan Lin</a>, 
<a href="/search/cs?searchtype=author&query=Nie%2C+Q">Qiang Nie</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yong Liu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Query-based object detectors have made significant advancements since the
publication of DETR. However, most existing methods still rely on multi-stage
encoders and decoders, or a combination of both. Despite achieving high
accuracy, the multi-stage paradigm (typically consisting of 6 stages) suffers
from issues such as heavy computational burden, prompting us to reconsider its
necessity. In this paper, we explore multiple techniques to enhance query-based
detectors and, based on these findings, propose a novel model called GOLO
(Global Once and Local Once), which follows a two-stage decoding paradigm.
Compared to other mainstream query-based models with multi-stage decoders, our
model employs fewer decoder stages while still achieving considerable
performance. Experimental results on the COCO dataset demonstrate the
effectiveness of our approach.
</p>
</div>
</dd>
<dt><a name="item183">[183]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16307" title="Abstract">arXiv:2309.16307</a> [<a href="/pdf/2309.16307" title="Download PDF">pdf</a>, <a href="/format/2309.16307" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> TaxAI: A Dynamic Economic Simulator and Benchmark for Multi-Agent  Reinforcement Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mi%2C+Q">Qirui Mi</a>, 
<a href="/search/cs?searchtype=author&query=Xia%2C+S">Siyu Xia</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+Y">Yan Song</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Haifeng Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+S">Shenghao Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jun Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 26 pages, 8 figures, 12 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Engineering, Finance, and Science (cs.CE)</span>

</div>
<p class="mathjax">Taxation and government spending are crucial tools for governments to promote
economic growth and maintain social equity. However, the difficulty in
accurately predicting the dynamic strategies of diverse self-interested
households presents a challenge for governments to implement effective tax
policies. Given its proficiency in modeling other agents in partially
observable environments and adaptively learning to find optimal policies,
Multi-Agent Reinforcement Learning (MARL) is highly suitable for solving
dynamic games between the government and numerous households. Although MARL
shows more potential than traditional methods such as the genetic algorithm and
dynamic programming, there is a lack of large-scale multi-agent reinforcement
learning economic simulators. Therefore, we propose a MARL environment, named
\textbf{TaxAI}, for dynamic games involving $N$ households, government, firms,
and financial intermediaries based on the Bewley-Aiyagari economic model. Our
study benchmarks 2 traditional economic methods with 7 MARL methods on TaxAI,
demonstrating the effectiveness and superiority of MARL algorithms. Moreover,
TaxAI's scalability in simulating dynamic interactions between the government
and 10,000 households, coupled with real-data calibration, grants it a
substantial improvement in scale and reality over existing simulators.
Therefore, TaxAI is the most realistic economic simulator, which aims to
generate feasible recommendations for governments and individuals.
</p>
</div>
</dd>
<dt><a name="item184">[184]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16308" title="Abstract">arXiv:2309.16308</a> [<a href="/pdf/2309.16308" title="Download PDF">pdf</a>, <a href="/format/2309.16308" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Audio Visual Speaker Localization from EgoCentric Views
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhao%2C+J">Jinzheng Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+Y">Yong Xu</a>, 
<a href="/search/cs?searchtype=author&query=Qian%2C+X">Xinyuan Qian</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+W">Wenwu Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Multimedia (cs.MM)</span>; Sound (cs.SD); Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">The use of audio and visual modality for speaker localization has been well
studied in the literature by exploiting their complementary characteristics.
However, most previous works employ the setting of static sensors mounted at
fixed positions. Unlike them, in this work, we explore the ego-centric setting,
where the heterogeneous sensors are embodied and could be moving with a human
to facilitate speaker localization. Compared to the static scenario, the
ego-centric setting is more realistic for smart-home applications e.g., a
service robot. However, this also brings new challenges such as blurred images,
frequent speaker disappearance from the field of view of the wearer, and
occlusions. In this paper, we study egocentric audio-visual speaker DOA
estimation and deal with the challenges mentioned above. Specifically, we
propose a transformer-based audio-visual fusion method to estimate the relative
DOA of the speaker to the wearer, and design a training strategy to mitigate
the problem of the speaker disappearing from the camera's view. We also develop
a new dataset for simulating the out-of-view scenarios, by creating a scene
with a camera wearer walking around while a speaker is moving at the same time.
The experimental results show that our proposed method offers promising
performance in this new dataset in terms of tracking accuracy. Finally, we
adapt the proposed method for the multi-speaker scenario. Experiments on
EasyCom show the effectiveness of the proposed model for multiple speakers in
real scenarios, which achieves state-of-the-art results in the sphere active
speaker detection task and the wearer activity prediction task. The simulated
dataset and related code are available at
https://github.com/KawhiZhao/Egocentric-Audio-Visual-Speaker-Localization.
</p>
</div>
</dd>
<dt><a name="item185">[185]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16309" title="Abstract">arXiv:2309.16309</a> [<a href="/pdf/2309.16309" title="Download PDF">pdf</a>, <a href="/format/2309.16309" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Weakly-Supervised Video Anomaly Detection with Snippet Anomalous  Attention
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fan%2C+Y">Yidan Fan</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+Y">Yongxin Yu</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+W">Wenhuan Lu</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+Y">Yahong Han</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">With a focus on abnormal events contained within untrimmed videos, there is
increasing interest among researchers in video anomaly detection. Among
different video anomaly detection scenarios, weakly-supervised video anomaly
detection poses a significant challenge as it lacks frame-wise labels during
the training stage, only relying on video-level labels as coarse supervision.
Previous methods have made attempts to either learn discriminative features in
an end-to-end manner or employ a twostage self-training strategy to generate
snippet-level pseudo labels. However, both approaches have certain limitations.
The former tends to overlook informative features at the snippet level, while
the latter can be susceptible to noises. In this paper, we propose an Anomalous
Attention mechanism for weakly-supervised anomaly detection to tackle the
aforementioned problems. Our approach takes into account snippet-level encoded
features without the supervision of pseudo labels. Specifically, our approach
first generates snippet-level anomalous attention and then feeds it together
with original anomaly scores into a Multi-branch Supervision Module. The module
learns different areas of the video, including areas that are challenging to
detect, and also assists the attention optimization. Experiments on benchmark
datasets XDViolence and UCF-Crime verify the effectiveness of our method.
Besides, thanks to the proposed snippet-level attention, we obtain a more
precise anomaly localization.
</p>
</div>
</dd>
<dt><a name="item186">[186]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16318" title="Abstract">arXiv:2309.16318</a> [<a href="/pdf/2309.16318" title="Download PDF">pdf</a>, <a href="/format/2309.16318" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DeepPCR: Parallelizing Sequential Operations in Neural Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Danieli%2C+F">Federico Danieli</a>, 
<a href="/search/cs?searchtype=author&query=Sarabia%2C+M">Miguel Sarabia</a>, 
<a href="/search/cs?searchtype=author&query=Suau%2C+X">Xavier Suau</a>, 
<a href="/search/cs?searchtype=author&query=Rodr%C3%ADguez%2C+P">Pau Rodr&#xed;guez</a>, 
<a href="/search/cs?searchtype=author&query=Zappella%2C+L">Luca Zappella</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Parallelization techniques have become ubiquitous for accelerating inference
and training of deep neural networks. Despite this, several operations are
still performed in a sequential manner. For instance, the forward and backward
passes are executed layer-by-layer, and the output of diffusion models is
produced by applying a sequence of denoising steps. This sequential approach
results in a computational cost proportional to the number of steps involved,
presenting a potential bottleneck as the number of steps increases. In this
work, we introduce DeepPCR, a novel algorithm which parallelizes typically
sequential operations used in inference and training of neural networks.
DeepPCR is based on interpreting a sequence of $L$ steps as the solution of a
specific system of equations, which we recover using the Parallel Cyclic
Reduction algorithm. This reduces the complexity of computing the sequential
operations from $\mathcal{O}(L)$ to $\mathcal{O}(\log_2L)$, thus yielding a
speedup for large $L$. To verify the theoretical lower complexity of the
algorithm, and to identify regimes for speedup, we test the effectiveness of
DeepPCR in parallelizing the forward and backward pass in multi-layer
perceptrons, and reach speedups of up to $30\times$ for forward and $200\times$
for backward pass. We additionally showcase the flexibility of DeepPCR by
parallelizing training of ResNets with as many as 1024 layers, and generation
in diffusion models, enabling up to $7\times$ faster training and $11\times$
faster generation, respectively, when compared to the sequential approach.
</p>
</div>
</dd>
<dt><a name="item187">[187]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16319" title="Abstract">arXiv:2309.16319</a> [<a href="/pdf/2309.16319" title="Download PDF">pdf</a>, <a href="/format/2309.16319" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Augmenting transformers with recursively composed multi-grained  representations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hu%2C+X">Xiang Hu</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+Q">Qingyang Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Tu%2C+K">Kewei Tu</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+W">Wei Wu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> preprint
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">We present ReCAT, a recursive composition augmented Transformer that is able
to explicitly model hierarchical syntactic structures of raw texts without
relying on gold trees during both learning and inference. Existing research
along this line restricts data to follow a hierarchical tree structure and thus
lacks inter-span communications. To overcome the problem, we propose a novel
contextual inside-outside (CIO) layer that learns contextualized
representations of spans through bottom-up and top-down passes, where a
bottom-up pass forms representations of high-level spans by composing low-level
spans, while a top-down pass combines information inside and outside a span. By
stacking several CIO layers between the embedding layer and the attention
layers in Transformer, the ReCAT model can perform both deep intra-span and
deep inter-span interactions, and thus generate multi-grained representations
fully contextualized with other spans. Moreover, the CIO layers can be jointly
pre-trained with Transformers, making ReCAT enjoy scaling ability, strong
performance, and interpretability at the same time. We conduct experiments on
various sentence-level and span-level tasks. Evaluation results indicate that
ReCAT can significantly outperform vanilla Transformer models on all span-level
tasks and baselines that combine recursive networks with Transformers on
natural language inference tasks. More interestingly, the hierarchical
structures induced by ReCAT exhibit strong consistency with human-annotated
syntactic trees, indicating good interpretability brought by the CIO layers.
</p>
</div>
</dd>
<dt><a name="item188">[188]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16322" title="Abstract">arXiv:2309.16322</a> [<a href="/pdf/2309.16322" title="Download PDF">pdf</a>, <a href="/format/2309.16322" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multi-Granularity Click Confidence Learning via Self-Distillation in  Recommendation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+C">Chong Liu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xiaoyang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+L">Lixin Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Xia%2C+F">Feng Xia</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+L">Leyu Lin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>

</div>
<p class="mathjax">Recommendation systems rely on historical clicks to learn user interests and
provide appropriate items. However, current studies tend to treat clicks
equally, which may ignore the assorted intensities of user interests in
different clicks. In this paper, we aim to achieve multi-granularity Click
confidence Learning via Self-Distillation in recommendation (CLSD). Due to the
lack of supervised signals in click confidence, we first apply self-supervised
learning to obtain click confidence scores via a global self-distillation
method. After that, we define a local confidence function to adapt confidence
scores at the user group level, since the confidence distributions can be
varied among user groups. With the combination of multi-granularity confidence
learning, we can distinguish the quality of clicks and model user interests
more accurately without involving extra data and model structures. The
significant improvements over different backbones on industrial offline and
online experiments in a real-world recommender system prove the effectiveness
of our model. Recently, CLSD has been deployed on a large-scale recommender
system, affecting over 400 million users.
</p>
</div>
</dd>
<dt><a name="item189">[189]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16326" title="Abstract">arXiv:2309.16326</a> [<a href="/pdf/2309.16326" title="Download PDF">pdf</a>, <a href="/format/2309.16326" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Numerical schemes for a multi-species quantum BGK model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Bae%2C+G">Gi-Chan Bae</a>, 
<a href="/search/math?searchtype=author&query=Pirner%2C+M">Marlies Pirner</a>, 
<a href="/search/math?searchtype=author&query=Warnecke%2C+S">Sandra Warnecke</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: text overlap with <a href="/abs/2202.05652">arXiv:2202.05652</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">We consider a kinetic model of an N-species gas mixture modeled with quantum
Bhatnagar-Gross-Krook (BGK) collision operators. The collision operators
consist of a relaxation to a Maxwell distribution in the classical case, a
Fermi distribution for fermions and a Bose-Einstein distribution for bosons. In
this paper we present a numerical method for simulating this model, which uses
an Implicit-Explicit (IMEX) scheme to minimize a certain potential function.
This is motivated by theoretical considerations coming from entropy
minimization. We show that theoretical properties such as conservation of mass,
total momentum and total energy as well as positivity of the distribution
functions are preserved by the numerical method presented in this paper, and
illustrate its usefulness and effectiveness with numerical examples
</p>
</div>
</dd>
<dt><a name="item190">[190]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16329" title="Abstract">arXiv:2309.16329</a> [<a href="/pdf/2309.16329" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Decoding the Workplace &amp; EOR: An Employee Survey Analysis by Data  Science Techniques and Visualization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bhimani%2C+K">Kishankumar Bhimani</a>, 
<a href="/search/cs?searchtype=author&query=Saradva%2C+K">Khushbu Saradva</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted in XXV INTERNATIONAL CONFERENCE "Data Analytics and Management in Data Intensive Domains" (DAMDID/RCDL 2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Human-Computer Interaction (cs.HC); Numerical Analysis (math.NA)

</div>
<p class="mathjax">This research study explores the new dynamics of employee-organi-zation
relationships (EOR) [6] using advanced data science methodologies and presents
findings through accessible visualizations. Leveraging a dataset pro-cured from
a comprehensive nationwide big employee survey, this study employs innovative
strategy for theoretical researcher by using our state-of-the-art
visual-ization. The results present insightful visualizations encapsulating
demographic analysis, workforce satisfaction, work environment scrutiny, and
the employee's view via word cloud interpretations and burnout predictions.
<br />The study underscores the profound implications of data science across
various management sectors, enhancing understanding of workplace dynamics and
pro-moting mutual growth and satisfaction. This multifaceted approach caters to
a diverse array of readers, from researchers in sociology and management to
firms seeking detailed understanding of their workforce's satisfaction,
emphasizing on practicality and interpretability.
<br />The research encourages proactive measures to improve workplace
environ-ments, boost employee satisfaction, and foster healthier, more
productive organ-izations. It serves as a resourceful tool for those committed
to these objectives, manifesting the transformative potential of data science
in driving insightful nar-ratives about workplace dynamics and
employee-organization relationships. In essence, this research unearths
valuable insights to aid management, HR profes-sionals, and companies
</p>
</div>
</dd>
<dt><a name="item191">[191]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16333" title="Abstract">arXiv:2309.16333</a> [<a href="/pdf/2309.16333" title="Download PDF">pdf</a>, <a href="/format/2309.16333" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CloudProphet: A Machine Learning-Based Performance Prediction for Public  Clouds
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+D">Darong Huang</a>, 
<a href="/search/cs?searchtype=author&query=Costero%2C+L">Luis Costero</a>, 
<a href="/search/cs?searchtype=author&query=Pahlevan%2C+A">Ali Pahlevan</a>, 
<a href="/search/cs?searchtype=author&query=Zapater%2C+M">Marina Zapater</a>, 
<a href="/search/cs?searchtype=author&query=Atienza%2C+D">David Atienza</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 15 pages, 11 figures, summited to IEEE Transactions on Sustainable Computing
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>

</div>
<p class="mathjax">Computing servers have played a key role in developing and processing
emerging compute-intensive applications in recent years. Consolidating multiple
virtual machines (VMs) inside one server to run various applications introduces
severe competence for limited resources among VMs. Many techniques such as VM
scheduling and resource provisioning are proposed to maximize the
cost-efficiency of the computing servers while alleviating the performance
inference between VMs. However, these management techniques require accurate
performance prediction of the application running inside the VM, which is
challenging to get in the public cloud due to the black-box nature of the VMs.
From this perspective, this paper proposes a novel machine learning-based
performance prediction approach for applications running in the cloud. To
achieve high accuracy predictions for black-box VMs, the proposed method first
identifies the running application inside the virtual machine. It then selects
highly-correlated runtime metrics as the input of the machine learning approach
to accurately predict the performance level of the cloud application.
Experimental results with state-of-the-art cloud benchmarks demonstrate that
our proposed method outperforms the existing prediction methods by more than 2x
in terms of worst prediction error. In addition, we successfully tackle the
challenge in performance prediction for applications with variable workloads by
introducing the performance degradation index, which other comparison methods
fail to consider. The workflow versatility of the proposed approach has been
verified with different modern servers and VM configurations.
</p>
</div>
</dd>
<dt><a name="item192">[192]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16335" title="Abstract">arXiv:2309.16335</a> [<a href="/pdf/2309.16335" title="Download PDF">pdf</a>, <a href="/format/2309.16335" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> End-to-end Risk Prediction of Atrial Fibrillation from the 12-Lead ECG  by Deep Neural Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Habineza%2C+T">Theogene Habineza</a>, 
<a href="/search/cs?searchtype=author&query=Ribeiro%2C+A+H">Ant&#xf4;nio H. Ribeiro</a>, 
<a href="/search/cs?searchtype=author&query=Gedon%2C+D">Daniel Gedon</a>, 
<a href="/search/cs?searchtype=author&query=Behar%2C+J+A">Joachim A. Behar</a>, 
<a href="/search/cs?searchtype=author&query=Ribeiro%2C+A+L+P">Antonio Luiz P. Ribeiro</a>, 
<a href="/search/cs?searchtype=author&query=Sch%C3%B6n%2C+T+B">Thomas B. Sch&#xf6;n</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 pages with 7 figures
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> @article{HABINEZA2023193, journal = {Journal of
  Electrocardiology}, volume = {81}, pages = {193-200}, year = {2023}, issn =
  {0022-0736}}
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Quantitative Methods (q-bio.QM); Applications (stat.AP)

</div>
<p class="mathjax">Background: Atrial fibrillation (AF) is one of the most common cardiac
arrhythmias that affects millions of people each year worldwide and it is
closely linked to increased risk of cardiovascular diseases such as stroke and
heart failure. Machine learning methods have shown promising results in
evaluating the risk of developing atrial fibrillation from the
electrocardiogram. We aim to develop and evaluate one such algorithm on a large
CODE dataset collected in Brazil.
<br />Results: The deep neural network model identified patients without indication
of AF in the presented ECG but who will develop AF in the future with an AUC
score of 0.845. From our survival model, we obtain that patients in the
high-risk group (i.e. with the probability of a future AF case being greater
than 0.7) are 50% more likely to develop AF within 40 weeks, while patients
belonging to the minimal-risk group (i.e. with the probability of a future AF
case being less than or equal to 0.1) have more than 85% chance of remaining AF
free up until after seven years.
<br />Conclusion: We developed and validated a model for AF risk prediction. If
applied in clinical practice, the model possesses the potential of providing
valuable and useful information in decision-making and patient management
processes.
</p>
</div>
</dd>
<dt><a name="item193">[193]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16337" title="Abstract">arXiv:2309.16337</a> [<a href="/pdf/2309.16337" title="Download PDF">pdf</a>, <a href="/format/2309.16337" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Logarithm-transform aided Gaussian Sampling for Few-Shot Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ganatra%2C+V">Vaibhav Ganatra</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Few-shot image classification has recently witnessed the rise of
representation learning being utilised for models to adapt to new classes using
only a few training examples. Therefore, the properties of the representations,
such as their underlying probability distributions, assume vital importance.
Representations sampled from Gaussian distributions have been used in recent
works, [19] to train classifiers for few-shot classification. These methods
rely on transforming the distributions of experimental data to approximate
Gaussian distributions for their functioning. In this paper, I propose a novel
Gaussian transform, that outperforms existing methods on transforming
experimental data into Gaussian-like distributions. I then utilise this novel
transformation for few-shot image classification and show significant gains in
performance, while sampling lesser data.
</p>
</div>
</dd>
<dt><a name="item194">[194]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16338" title="Abstract">arXiv:2309.16338</a> [<a href="/pdf/2309.16338" title="Download PDF">pdf</a>, <a href="/format/2309.16338" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> EFFL: Egalitarian Fairness in Federated Learning for Mitigating Matthew  Effect
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gao%2C+J">Jiashi Gao</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+C">Changwu Huang</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+M">Ming Tang</a>, 
<a href="/search/cs?searchtype=author&query=Tan%2C+S+H">Shin Hwei Tan</a>, 
<a href="/search/cs?searchtype=author&query=Yao%2C+X">Xin Yao</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+X">Xuetao Wei</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Recent advances in federated learning (FL) enable collaborative training of
machine learning (ML) models from large-scale and widely dispersed clients
while protecting their privacy. However, when different clients' datasets are
heterogeneous, traditional FL mechanisms produce a global model that does not
adequately represent the poorer clients with limited data resources, resulting
in lower accuracy and higher bias on their local data. According to the Matthew
effect, which describes how the advantaged gain more advantage and the
disadvantaged lose more over time, deploying such a global model in client
applications may worsen the resource disparity among the clients and harm the
principles of social welfare and fairness. To mitigate the Matthew effect, we
propose Egalitarian Fairness Federated Learning (EFFL), where egalitarian
fairness refers to the global model learned from FL has: (1) equal accuracy
among clients; (2) equal decision bias among clients. Besides achieving
egalitarian fairness among the clients, EFFL also aims for performance
optimality, minimizing the empirical risk loss and the bias for each client;
both are essential for any ML model training, whether centralized or
decentralized. We formulate EFFL as a constrained multi-constrained
multi-objectives optimization (MCMOO) problem, with the decision bias and
egalitarian fairness as constraints and the minimization of the empirical risk
losses on all clients as multiple objectives to be optimized. We propose a
gradient-based three-stage algorithm to obtain the Pareto optimal solutions
within the constraint space. Extensive experiments demonstrate that EFFL
outperforms other state-of-the-art FL algorithms in achieving a
high-performance global model with enhanced egalitarian fairness among all
clients.
</p>
</div>
</dd>
<dt><a name="item195">[195]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16342" title="Abstract">arXiv:2309.16342</a> [<a href="/pdf/2309.16342" title="Download PDF">pdf</a>, <a href="/format/2309.16342" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LagrangeBench: A Lagrangian Fluid Mechanics Benchmarking Suite
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Toshev%2C+A+P">Artur P. Toshev</a>, 
<a href="/search/cs?searchtype=author&query=Galletti%2C+G">Gianluca Galletti</a>, 
<a href="/search/cs?searchtype=author&query=Fritz%2C+F">Fabian Fritz</a>, 
<a href="/search/cs?searchtype=author&query=Adami%2C+S">Stefan Adami</a>, 
<a href="/search/cs?searchtype=author&query=Adams%2C+N+A">Nikolaus A. Adams</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at 37th Conference on Neural Information Processing Systems (NeurIPS 2023) Track on Datasets and Benchmarks
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Fluid Dynamics (physics.flu-dyn)

</div>
<p class="mathjax">Machine learning has been successfully applied to grid-based PDE modeling in
various scientific applications. However, learned PDE solvers based on
Lagrangian particle discretizations, which are the preferred approach to
problems with free surfaces or complex physics, remain largely unexplored. We
present LagrangeBench, the first benchmarking suite for Lagrangian particle
problems, focusing on temporal coarse-graining. In particular, our contribution
is: (a) seven new fluid mechanics datasets (four in 2D and three in 3D)
generated with the Smoothed Particle Hydrodynamics (SPH) method including the
Taylor-Green vortex, lid-driven cavity, reverse Poiseuille flow, and dam break,
each of which includes different physics like solid wall interactions or free
surface, (b) efficient JAX-based API with various recent training strategies
and neighbors search routine, and (c) JAX implementation of established Graph
Neural Networks (GNNs) like GNS and SEGNN with baseline results. Finally, to
measure the performance of learned surrogates we go beyond established position
errors and introduce physical metrics like kinetic energy MSE and Sinkhorn
distance for the particle distribution. Our codebase is available under the
URL: https://github.com/tumaer/lagrangebench
</p>
</div>
</dd>
<dt><a name="item196">[196]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16343" title="Abstract">arXiv:2309.16343</a> [<a href="/pdf/2309.16343" title="Download PDF">pdf</a>, <a href="/format/2309.16343" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Online Estimation of Articulated Objects with Factor Graphs using Vision  and Proprioceptive Sensing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Buchanan%2C+R">Russell Buchanan</a>, 
<a href="/search/cs?searchtype=author&query=R%C3%B6fer%2C+A">Adrian R&#xf6;fer</a>, 
<a href="/search/cs?searchtype=author&query=Moura%2C+J">Jo&#xe3;o Moura</a>, 
<a href="/search/cs?searchtype=author&query=Valada%2C+A">Abhinav Valada</a>, 
<a href="/search/cs?searchtype=author&query=Vijayakumar%2C+S">Sethu Vijayakumar</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">From dishwashers to cabinets, humans interact with articulated objects every
day, and for a robot to assist in common manipulation tasks, it must learn a
representation of articulation. Recent deep learning learning methods can
provide powerful vision-based priors on the affordance of articulated objects
from previous, possibly simulated, experiences. In contrast, many works
estimate articulation by observing the object in motion, requiring the robot to
already be interacting with the object. In this work, we propose to use the
best of both worlds by introducing an online estimation method that merges
vision-based affordance predictions from a neural network with interactive
kinematic sensing in an analytical model. Our work has the benefit of using
vision to predict an articulation model before touching the object, while also
being able to update the model quickly from kinematic sensing during the
interaction. In this paper, we implement a full system using shared autonomy
for robotic opening of articulated objects, in particular objects in which the
articulation is not apparent from vision alone. We implemented our system on a
real robot and performed several autonomous closed-loop experiments in which
the robot had to open a door with unknown joint while estimating the
articulation online. Our system achieved an 80% success rate for autonomous
opening of unknown articulated objects.
</p>
</div>
</dd>
<dt><a name="item197">[197]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16344" title="Abstract">arXiv:2309.16344</a> [<a href="/pdf/2309.16344" title="Download PDF">pdf</a>, <a href="/ps/2309.16344" title="Download PostScript">ps</a>, <a href="/format/2309.16344" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Epistemic Logic Programs: a study of some properties
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Costantini%2C+S">Stefania Costantini</a>, 
<a href="/search/cs?searchtype=author&query=Formisano%2C+A">Andrea Formisano</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Under consideration in Theory and Practice of Logic Programming (TPLP)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
<p class="mathjax">Epistemic Logic Programs (ELPs), extend Answer Set Programming (ASP) with
epistemic operators. The semantics of such programs is provided in terms of
world views, which are sets of belief sets, i.e., syntactically, sets of sets
of atoms. Different semantic approaches propose different characterizations of
world views. Recent work has introduced semantic properties that should be met
by any semantics for ELPs, like the Epistemic Splitting Property, that, if
satisfied, allows to modularly compute world views in a bottom-up fashion,
analogously to ``traditional'' ASP. We analyze the possibility of changing the
perspective, shifting from a bottom-up to a top-down approach to splitting. We
propose a basic top-down approach, which we prove to be equivalent to the
bottom-up one. We then propose an extended approach, where our new definition:
(i) is provably applicable to many of the existing semantics; (ii) operates
similarly to ``traditional'' ASP; (iii) provably coincides under any semantics
with the bottom-up notion of splitting at least on the class of Epistemically
Stratified Programs (which are, intuitively, those where the use of epistemic
operators is stratified); (iv) better adheres to common ASP programming
methodology.
</p>
</div>
</dd>
<dt><a name="item198">[198]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16347" title="Abstract">arXiv:2309.16347</a> [<a href="/pdf/2309.16347" title="Download PDF">pdf</a>, <a href="/format/2309.16347" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Intrinsic Language-Guided Exploration for Complex Long-Horizon Robotic  Manipulation Tasks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Triantafyllidis%2C+E">Eleftherios Triantafyllidis</a>, 
<a href="/search/cs?searchtype=author&query=Christianos%2C+F">Filippos Christianos</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zhibin Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 3 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Computation and Language (cs.CL); Machine Learning (cs.LG)

</div>
<p class="mathjax">Current reinforcement learning algorithms struggle in sparse and complex
environments, most notably in long-horizon manipulation tasks entailing a
plethora of different sequences. In this work, we propose the Intrinsically
Guided Exploration from Large Language Models (IGE-LLMs) framework. By
leveraging LLMs as an assistive intrinsic reward, IGE-LLMs guides the
exploratory process in reinforcement learning to address intricate long-horizon
with sparse rewards robotic manipulation tasks. We evaluate our framework and
related intrinsic learning methods in an environment challenged with
exploration, and a complex robotic manipulation task challenged by both
exploration and long-horizons. Results show IGE-LLMs (i) exhibit notably higher
performance over related intrinsic methods and the direct use of LLMs in
decision-making, (ii) can be combined and complement existing learning methods
highlighting its modularity, (iii) are fairly insensitive to different
intrinsic scaling parameters, and (iv) maintain robustness against increased
levels of uncertainty and horizons.
</p>
</div>
</dd>
<dt><a name="item199">[199]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16349" title="Abstract">arXiv:2309.16349</a> [<a href="/pdf/2309.16349" title="Download PDF">pdf</a>, <a href="/format/2309.16349" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Human Feedback is not Gold Standard
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hosking%2C+T">Tom Hosking</a>, 
<a href="/search/cs?searchtype=author&query=Blunsom%2C+P">Phil Blunsom</a>, 
<a href="/search/cs?searchtype=author&query=Bartolo%2C+M">Max Bartolo</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Human feedback has become the de facto standard for evaluating the
performance of Large Language Models, and is increasingly being used as a
training objective. However, it is not clear which properties of a generated
output this single `preference' score captures. We hypothesise that preference
scores are subjective and open to undesirable biases. We critically analyse the
use of human feedback for both training and evaluation, to verify whether it
fully captures a range of crucial error criteria. We find that while preference
scores have fairly good coverage, they under-represent important aspects like
factuality. We further hypothesise that both preference scores and error
annotation may be affected by confounders, and leverage instruction-tuned
models to generate outputs that vary along two possible confounding dimensions:
assertiveness and complexity. We find that the assertiveness of an output skews
the perceived rate of factuality errors, indicating that human annotations are
not a fully reliable evaluation metric or training objective. Finally, we offer
preliminary evidence that using human feedback as a training objective
disproportionately increases the assertiveness of model outputs. We encourage
future work to carefully consider whether preference scores are well aligned
with the desired objective.
</p>
</div>
</dd>
<dt><a name="item200">[200]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16351" title="Abstract">arXiv:2309.16351</a> [<a href="/pdf/2309.16351" title="Download PDF">pdf</a>, <a href="/format/2309.16351" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Dark Side Augmentation: Generating Diverse Night Examples for Metric  Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mohwald%2C+A">Albert Mohwald</a>, 
<a href="/search/cs?searchtype=author&query=Jenicek%2C+T">Tomas Jenicek</a>, 
<a href="/search/cs?searchtype=author&query=Chum%2C+O">Ond&#x159;ej Chum</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages, 4 figures, 8 tables
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Proceedings of the IEEE/CVF International Conference on Computer
  Vision (ICCV), 2023, pp. 11153-11163
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Image retrieval methods based on CNN descriptors rely on metric learning from
a large number of diverse examples of positive and negative image pairs.
Domains, such as night-time images, with limited availability and variability
of training data suffer from poor retrieval performance even with methods
performing well on standard benchmarks. We propose to train a GAN-based
synthetic-image generator, translating available day-time image examples into
night images. Such a generator is used in metric learning as a form of
augmentation, supplying training data to the scarce domain. Various types of
generators are evaluated and analyzed. We contribute with a novel light-weight
GAN architecture that enforces the consistency between the original and
translated image through edge consistency. The proposed architecture also
allows a simultaneous training of an edge detector that operates on both night
and day images. To further increase the variability in the training examples
and to maximize the generalization of the trained model, we propose a novel
method of diverse anchor mining.
<br />The proposed method improves over the state-of-the-art results on a standard
Tokyo 24/7 day-night retrieval benchmark while preserving the performance on
Oxford and Paris datasets. This is achieved without the need of training image
pairs of matching day and night images. The source code is available at
https://github.com/mohwald/gandtr .
</p>
</div>
</dd>
<dt><a name="item201">[201]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16353" title="Abstract">arXiv:2309.16353</a> [<a href="/pdf/2309.16353" title="Download PDF">pdf</a>, <a href="/format/2309.16353" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ShapeDBA: Generating Effective Time Series Prototypes using ShapeDTW  Barycenter Averaging
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ismail-Fawaz%2C+A">Ali Ismail-Fawaz</a>, 
<a href="/search/cs?searchtype=author&query=Fawaz%2C+H+I">Hassan Ismail Fawaz</a>, 
<a href="/search/cs?searchtype=author&query=Petitjean%2C+F">Fran&#xe7;ois Petitjean</a>, 
<a href="/search/cs?searchtype=author&query=Devanne%2C+M">Maxime Devanne</a>, 
<a href="/search/cs?searchtype=author&query=Weber%2C+J">Jonathan Weber</a>, 
<a href="/search/cs?searchtype=author&query=Berretti%2C+S">Stefano Berretti</a>, 
<a href="/search/cs?searchtype=author&query=Webb%2C+G+I">Geoffrey I. Webb</a>, 
<a href="/search/cs?searchtype=author&query=Forestier%2C+G">Germain Forestier</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Published in AALTD workshop at ECML/PKDD 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Time series data can be found in almost every domain, ranging from the
medical field to manufacturing and wireless communication. Generating realistic
and useful exemplars and prototypes is a fundamental data analysis task. In
this paper, we investigate a novel approach to generating realistic and useful
exemplars and prototypes for time series data. Our approach uses a new form of
time series average, the ShapeDTW Barycentric Average. We therefore turn our
attention to accurately generating time series prototypes with a novel
approach. The existing time series prototyping approaches rely on the Dynamic
Time Warping (DTW) similarity measure such as DTW Barycentering Average (DBA)
and SoftDBA. These last approaches suffer from a common problem of generating
out-of-distribution artifacts in their prototypes. This is mostly caused by the
DTW variant used and its incapability of detecting neighborhood similarities,
instead it detects absolute similarities. Our proposed method, ShapeDBA, uses
the ShapeDTW variant of DTW, that overcomes this issue. We chose time series
clustering, a popular form of time series analysis to evaluate the outcome of
ShapeDBA compared to the other prototyping approaches. Coupled with the k-means
clustering algorithm, and evaluated on a total of 123 datasets from the UCR
archive, our proposed averaging approach is able to achieve new
state-of-the-art results in terms of Adjusted Rand Index.
</p>
</div>
</dd>
<dt><a name="item202">[202]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16354" title="Abstract">arXiv:2309.16354</a> [<a href="/pdf/2309.16354" title="Download PDF">pdf</a>, <a href="/format/2309.16354" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Transformer-VQ: Linear-Time Transformers via Vector Quantization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lingle%2C+L+D">Lucas D. Lingle</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Under review as a conference paper at ICLR 2024. Please do not distribute
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computation and Language (cs.CL); Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">We introduce Transformer-VQ, a decoder-only transformer computing
softmax-based dense self-attention in linear time. Transformer-VQ's efficient
attention is enabled by vector-quantized keys and a novel caching mechanism. In
large-scale experiments, Transformer-VQ is shown highly competitive in quality,
with strong results on Enwik8 (0.99 bpb), PG-19 (26.6 ppl), and ImageNet64
(3.16 bpb). Code: https://github.com/transformer-vq/transformer_vq
</p>
</div>
</dd>
<dt><a name="item203">[203]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16357" title="Abstract">arXiv:2309.16357</a> [<a href="/pdf/2309.16357" title="Download PDF">pdf</a>, <a href="/format/2309.16357" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Leveraging Pre-trained Language Models for Time Interval Prediction in  Text-Enhanced Temporal Knowledge Graphs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Islakoglu%2C+D+S">Duygu Sezen Islakoglu</a>, 
<a href="/search/cs?searchtype=author&query=Chekol%2C+M">Mel Chekol</a>, 
<a href="/search/cs?searchtype=author&query=Velegrakis%2C+Y">Yannis Velegrakis</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 3 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Most knowledge graph completion (KGC) methods learn latent representations of
entities and relations of a given graph by mapping them into a vector space.
Although the majority of these methods focus on static knowledge graphs, a
large number of publicly available KGs contain temporal information stating the
time instant/period over which a certain fact has been true. Such graphs are
often known as temporal knowledge graphs. Furthermore, knowledge graphs may
also contain textual descriptions of entities and relations. Both temporal
information and textual descriptions are not taken into account during
representation learning by static KGC methods, and only structural information
of the graph is leveraged. Recently, some studies have used temporal
information to improve link prediction, yet they do not exploit textual
descriptions and do not support inductive inference (prediction on entities
that have not been seen in training).
<br />We propose a novel framework called TEMT that exploits the power of
pre-trained language models (PLMs) for text-enhanced temporal knowledge graph
completion. The knowledge stored in the parameters of a PLM allows TEMT to
produce rich semantic representations of facts and to generalize on previously
unseen entities. TEMT leverages textual and temporal information available in a
KG, treats them separately, and fuses them to get plausibility scores of facts.
Unlike previous approaches, TEMT effectively captures dependencies across
different time points and enables predictions on unseen entities. To assess the
performance of TEMT, we carried out several experiments including time interval
prediction, both in transductive and inductive settings, and triple
classification. The experimental results show that TEMT is competitive with the
state-of-the-art.
</p>
</div>
</dd>
<dt><a name="item204">[204]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16359" title="Abstract">arXiv:2309.16359</a> [<a href="/pdf/2309.16359" title="Download PDF">pdf</a>, <a href="/ps/2309.16359" title="Download PostScript">ps</a>, <a href="/format/2309.16359" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Byzantine Resilient Computing with the Cloud
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Augustine%2C+J">John Augustine</a>, 
<a href="/search/cs?searchtype=author&query=Biju%2C+J">Jeffin Biju</a>, 
<a href="/search/cs?searchtype=author&query=Meir%2C+S">Shachar Meir</a>, 
<a href="/search/cs?searchtype=author&query=Peleg%2C+D">David Peleg</a>, 
<a href="/search/cs?searchtype=author&query=Ramachandran%2C+S">Srikkanth Ramachandran</a>, 
<a href="/search/cs?searchtype=author&query=Thiruvengadam%2C+A">Aishwarya Thiruvengadam</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 54 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>

</div>
<p class="mathjax">We study a framework for modeling distributed network systems assisted by a
reliable and powerful cloud service. Our framework aims at capturing hybrid
systems based on a point to point message passing network of machines, with the
additional capability of being able to access the services of a trusted
high-performance external entity (the cloud). We focus on one concrete aspect
that was not studied before, namely, ways of utilizing the cloud assistance in
order to attain increased resilience against Byzantine behavior of machines in
the network. Our network is modeled as a congested clique comprising $k$
machines that are completely connected to form a clique and can communicate
with each other by passing small messages. In every execution, up to $\beta k$
machines (for suitable values of $\beta \in [0, 1)$) are allowed to be
Byzantine, i.e., behave maliciously including colluding with each other, with
the remaining $\gamma k$ or more machines being \emph{honest} (for
$\gamma=1-\beta$). Additionally, the machines in our congested clique can
access data through a trusted cloud via queries. This externality of the data
captures many real-world distributed computing scenarios and provides a natural
context for exploring Byzantine resilience for essentially all conceivable
problems. Moreover, we are no longer bound by the usual limits of $\beta &lt; 1/3$
or even $\beta &lt; 1/2$ that are typically seen in Byzantine Agreement. We focus
on a few fundamental problems. We start with the ${\textsf{Download}}$ problem,
wherein the cloud stores $n$ bits and these $n$ bits must be downloaded to all
of the $k$ machines. In addition to ${\textsf{Download}}$, we also consider the
problem of computing the ${\textsf{Disjunction}}$ and ${\textsf{Parity}}$ of
the bits in the cloud. We study these problems under several settings
comprising various $\beta$ values and adversarial capabilities.
</p>
</div>
</dd>
<dt><a name="item205">[205]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16364" title="Abstract">arXiv:2309.16364</a> [<a href="/pdf/2309.16364" title="Download PDF">pdf</a>, <a href="/format/2309.16364" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FG-NeRF: Flow-GAN based Probabilistic Neural Radiance Field for  Independence-Assumption-Free Uncertainty Estimation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wei%2C+S">Songlin Wei</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jiazhao Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Xiang%2C+F">Fanbo Xiang</a>, 
<a href="/search/cs?searchtype=author&query=Su%2C+H">Hao Su</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">He Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Neural radiance fields with stochasticity have garnered significant interest
by enabling the sampling of plausible radiance fields and quantifying
uncertainty for downstream tasks. Existing works rely on the independence
assumption of points in the radiance field or the pixels in input views to
obtain tractable forms of the probability density function. However, this
assumption inadvertently impacts performance when dealing with intricate
geometry and texture. In this work, we propose an independence-assumption-free
probabilistic neural radiance field based on Flow-GAN. By combining the
generative capability of adversarial learning and the powerful expressivity of
normalizing flow, our method explicitly models the density-radiance
distribution of the whole scene. We represent our probabilistic NeRF as a
mean-shifted probabilistic residual neural model. Our model is trained without
an explicit likelihood function, thereby avoiding the independence assumption.
Specifically, We downsample the training images with different strides and
centers to form fixed-size patches which are used to train the generator with
patch-based adversarial learning. Through extensive experiments, our method
demonstrates state-of-the-art performance by predicting lower rendering errors
and more reliable uncertainty on both synthetic and real-world datasets.
</p>
</div>
</dd>
<dt><a name="item206">[206]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16365" title="Abstract">arXiv:2309.16365</a> [<a href="/pdf/2309.16365" title="Download PDF">pdf</a>, <a href="/format/2309.16365" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Libertas: Privacy-Preserving Computation for Decentralised Personal Data  Stores
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhao%2C+R">Rui Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Goel%2C+N">Naman Goel</a>, 
<a href="/search/cs?searchtype=author&query=Agrawal%2C+N">Nitin Agrawal</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+J">Jun Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Stein%2C+J">Jake Stein</a>, 
<a href="/search/cs?searchtype=author&query=Verborgh%2C+R">Ruben Verborgh</a>, 
<a href="/search/cs?searchtype=author&query=Binns%2C+R">Reuben Binns</a>, 
<a href="/search/cs?searchtype=author&query=Berners-Lee%2C+T">Tim Berners-Lee</a>, 
<a href="/search/cs?searchtype=author&query=Shadbolt%2C+N">Nigel Shadbolt</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>; Cryptography and Security (cs.CR); Distributed, Parallel, and Cluster Computing (cs.DC)

</div>
<p class="mathjax">Data-driven decision-making and AI applications present exciting new
opportunities delivering widespread benefits. The rapid adoption of such
applications triggers legitimate concerns about loss of privacy and misuse of
personal data. This leads to a growing and pervasive tension between harvesting
ubiquitous data on the Web and the need to protect individuals. Decentralised
personal data stores (PDS) such as Solid are frameworks designed to give
individuals ultimate control over their personal data. But current PDS
approaches have limited support for ensuring privacy when computations combine
data spread across users. Secure Multi-Party Computation (MPC) is a well-known
subfield of cryptography, enabling multiple autonomous parties to
collaboratively compute a function while ensuring the secrecy of inputs (input
privacy). These two technologies complement each other, but existing practices
fall short in addressing the requirements and challenges of introducing MPC in
a PDS environment. For the first time, we propose a modular design for
integrating MPC with Solid while respecting the requirements of
decentralisation in this context. Our architecture, Libertas, requires no
protocol level changes in the underlying design of Solid, and can be adapted to
other PDS. We further show how this can be combined with existing differential
privacy techniques to also ensure output privacy. We use empirical benchmarks
to inform and evaluate our implementation and design choices. We show the
technical feasibility and scalability pattern of the proposed system in two
novel scenarios -- 1) empowering gig workers with aggregate computations on
their earnings data; and 2) generating high-quality differentially-private
synthetic data without requiring a trusted centre. With this, we demonstrate
the linear scalability of Libertas, and gained insights about compute
optimisations under such an architecture.
</p>
</div>
</dd>
<dt><a name="item207">[207]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16369" title="Abstract">arXiv:2309.16369</a> [<a href="/pdf/2309.16369" title="Download PDF">pdf</a>, <a href="/format/2309.16369" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Bringing the Discussion of Minima Sharpness to the Audio Domain: a  Filter-Normalised Evaluation for Acoustic Scene Classification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Milling%2C+M">Manuel Milling</a>, 
<a href="/search/cs?searchtype=author&query=Triantafyllopoulos%2C+A">Andreas Triantafyllopoulos</a>, 
<a href="/search/cs?searchtype=author&query=Tsangko%2C+I">Iosif Tsangko</a>, 
<a href="/search/cs?searchtype=author&query=Rampp%2C+S+D+N">Simon David Noel Rampp</a>, 
<a href="/search/cs?searchtype=author&query=Schuller%2C+B+W">Bj&#xf6;rn Wolfgang Schuller</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This work has been submitted to the IEEE for possible publication
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Machine Learning (cs.LG); Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">The correlation between the sharpness of loss minima and generalisation in
the context of deep neural networks has been subject to discussion for a long
time. Whilst mostly investigated in the context of selected benchmark data sets
in the area of computer vision, we explore this aspect for the audio scene
classification task of the DCASE2020 challenge data. Our analysis is based on
twodimensional filter-normalised visualisations and a derived sharpness
measure. Our exploratory analysis shows that sharper minima tend to show better
generalisation than flat minima -even more so for out-of-domain data, recorded
from previously unseen devices-, thus adding to the dispute about better
generalisation capabilities of flat minima. We further find that, in
particular, the choice of optimisers is a main driver of the sharpness of
minima and we discuss resulting limitations with respect to comparability. Our
code, trained model states and loss landscape visualisations are publicly
available.
</p>
</div>
</dd>
<dt><a name="item208">[208]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16372" title="Abstract">arXiv:2309.16372</a> [<a href="/pdf/2309.16372" title="Download PDF">pdf</a>, <a href="/format/2309.16372" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Aperture Diffraction for Compact Snapshot Spectral Imaging
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lv%2C+T">Tao Lv</a>, 
<a href="/search/cs?searchtype=author&query=Ye%2C+H">Hao Ye</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+Q">Quan Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+Z">Zhan Shi</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yibo Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Shuming Wang</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+X">Xun Cao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> accepted by International Conference on Computer Vision (ICCV) 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Image and Video Processing (eess.IV)

</div>
<p class="mathjax">We demonstrate a compact, cost-effective snapshot spectral imaging system
named Aperture Diffraction Imaging Spectrometer (ADIS), which consists only of
an imaging lens with an ultra-thin orthogonal aperture mask and a mosaic filter
sensor, requiring no additional physical footprint compared to common RGB
cameras. Then we introduce a new optical design that each point in the object
space is multiplexed to discrete encoding locations on the mosaic filter sensor
by diffraction-based spatial-spectral projection engineering generated from the
orthogonal mask. The orthogonal projection is uniformly accepted to obtain a
weakly calibration-dependent data form to enhance modulation robustness.
Meanwhile, the Cascade Shift-Shuffle Spectral Transformer (CSST) with strong
perception of the diffraction degeneration is designed to solve a
sparsity-constrained inverse problem, realizing the volume reconstruction from
2D measurements with Large amount of aliasing. Our system is evaluated by
elaborating the imaging optical theory and reconstruction algorithm with
demonstrating the experimental imaging under a single exposure. Ultimately, we
achieve the sub-super-pixel spatial resolution and high spectral resolution
imaging. The code will be available at: https://github.com/Krito-ex/CSST.
</p>
</div>
</dd>
<dt><a name="item209">[209]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16374" title="Abstract">arXiv:2309.16374</a> [<a href="/pdf/2309.16374" title="Download PDF">pdf</a>, <a href="/format/2309.16374" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MHG-GNN: Combination of Molecular Hypergraph Grammar with Graph Neural  Network
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kishimoto%2C+A">Akihiro Kishimoto</a>, 
<a href="/search/cs?searchtype=author&query=Kajino%2C+H">Hiroshi Kajino</a>, 
<a href="/search/cs?searchtype=author&query=Hirose%2C+M">Masataka Hirose</a>, 
<a href="/search/cs?searchtype=author&query=Fuchiwaki%2C+J">Junta Fuchiwaki</a>, 
<a href="/search/cs?searchtype=author&query=Priyadarsini%2C+I">Indra Priyadarsini</a>, 
<a href="/search/cs?searchtype=author&query=Hamada%2C+L">Lisa Hamada</a>, 
<a href="/search/cs?searchtype=author&query=Shinohara%2C+H">Hajime Shinohara</a>, 
<a href="/search/cs?searchtype=author&query=Nakano%2C+D">Daiju Nakano</a>, 
<a href="/search/cs?searchtype=author&query=Takeda%2C+S">Seiji Takeda</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 1 figure
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Property prediction plays an important role in material discovery. As an
initial step to eventually develop a foundation model for material science, we
introduce a new autoencoder called the MHG-GNN, which combines graph neural
network (GNN) with Molecular Hypergraph Grammar (MHG). Results on a variety of
property prediction tasks with diverse materials show that MHG-GNN is
promising.
</p>
</div>
</dd>
<dt><a name="item210">[210]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16375" title="Abstract">arXiv:2309.16375</a> [<a href="/pdf/2309.16375" title="Download PDF">pdf</a>, <a href="/format/2309.16375" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Comprehensive Review on Tree Detection Methods Using Point Cloud and  Aerial Imagery from Unmanned Aerial Vehicles
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kuang%2C+W">Weijie Kuang</a>, 
<a href="/search/cs?searchtype=author&query=Ho%2C+H+W">Hann Woei Ho</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Y">Ye Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Suandi%2C+S+A">Shahrel Azmin Suandi</a>, 
<a href="/search/cs?searchtype=author&query=Ismail%2C+F">Farzad Ismail</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Robotics (cs.RO)

</div>
<p class="mathjax">Unmanned Aerial Vehicles (UAVs) are considered cutting-edge technology with
highly cost-effective and flexible usage scenarios. Although many papers have
reviewed the application of UAVs in agriculture, the review of the application
for tree detection is still insufficient. This paper focuses on tree detection
methods applied to UAV data collected by UAVs. There are two kinds of data, the
point cloud and the images, which are acquired by the Light Detection and
Ranging (LiDAR) sensor and camera, respectively. Among the detection methods
using point-cloud data, this paper mainly classifies these methods according to
LiDAR and Digital Aerial Photography (DAP). For the detection methods using
images directly, this paper reviews these methods by whether or not to use the
Deep Learning (DL) method. Our review concludes and analyses the comparison and
combination between the application of LiDAR-based and DAP-based point cloud
data. The performance, relative merits, and application fields of the methods
are also introduced. Meanwhile, this review counts the number of tree detection
studies using different methods in recent years. From our statics, the
detection task using DL methods on the image has become a mainstream trend as
the number of DL-based detection researches increases to 45% of the total
number of tree detection studies up to 2022. As a result, this review could
help and guide researchers who want to carry out tree detection on specific
forests and for farmers to use UAVs in managing agriculture production.
</p>
</div>
</dd>
<dt><a name="item211">[211]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16378" title="Abstract">arXiv:2309.16378</a> [<a href="/pdf/2309.16378" title="Download PDF">pdf</a>, <a href="/format/2309.16378" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Meshless interface tracking for the simulation of dendrite envelope  growth
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Jan%C4%8Di%C4%8D%2C+M">Mitja Jan&#x10d;i&#x10d;</a>, 
<a href="/search/math?searchtype=author&query=Zalo%C5%BEnik%2C+M">Miha Zalo&#x17e;nik</a>, 
<a href="/search/math?searchtype=author&query=Kosec%2C+G">Gregor Kosec</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Preprint submitted to Journal of Computational Physics
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">The growth of dendritic grains during solidification is often modelled using
the Grain Envelope Model (GEM), in which the envelope of the dendrite is an
interface tracked by the Phase Field Interface Capturing (PFIC) method. In the
PFIC method, an phase-field equation is solved on a fixed mesh to track the
position of the envelope. While being versatile and robust, PFIC introduces
certain numerical artefacts. In this work, we present an alternative approach
for the solution of the GEM that employs a Meshless (sharp) Interface Tracking
(MIT) formulation, which uses direct, artefact-free interface tracking. In the
MIT, the envelope (interface) is defined as a moving domain boundary and the
interface-tracking nodes are boundary nodes for the diffusion problem solved in
the domain. To increase the accuracy of the method for the diffusion-controlled
moving-boundary problem, an \h-adaptive spatial discretization is used, thus,
the node spacing is refined in the vicinity of the envelope. MIT combines a
parametric surface reconstruction, a mesh-free discretization of the parametric
surfaces and the space enclosed by them, and a high-order approximation of the
partial differential operators and of the solute concentration field using
radial basis functions augmented with monomials. The proposed method is
demonstrated on a two-dimensional \h-adaptive solution of the diffusive growth
of dendrite and evaluated by comparing the results to the PFIC approach. It is
shown that MIT can reproduce the results calculated with PFIC, that it is
convergent and that it can capture more details in the envelope shape than PFIC
with a similar spatial discretization.
</p>
</div>
</dd>
<dt><a name="item212">[212]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16381" title="Abstract">arXiv:2309.16381</a> [<a href="/pdf/2309.16381" title="Download PDF">pdf</a>, <a href="/format/2309.16381" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Nek5000/RS Performance on Advanced GPU Architectures
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Min%2C+M">Misun Min</a>, 
<a href="/search/cs?searchtype=author&query=Lan%2C+Y">Yu-Hsiang Lan</a>, 
<a href="/search/cs?searchtype=author&query=Fischer%2C+P">Paul Fischer</a>, 
<a href="/search/cs?searchtype=author&query=Rathnayake%2C+T">Thilina Rathnayake</a>, 
<a href="/search/cs?searchtype=author&query=Holmen%2C+J">John Holmen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 24 pages, 13 figures, 2 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>; Performance (cs.PF)

</div>
<p class="mathjax">We demonstrate NekRS performance results on various advanced GPU
architectures. NekRS is a GPU-accelerated version of Nek5000 that targets high
performance on exascale platforms. It is being developed in DOE's Center of
Efficient Exascale Discretizations, which is one of the co-design centers under
the Exascale Computing Project. In this paper, we consider Frontier, Crusher,
Spock, Polaris, Perlmutter, ThetaGPU, and Summit. Simulations are performed
with 17x17 rod-bundle geometries from small modular reactor applications. We
discuss strong-scaling performance and analysis.
</p>
</div>
</dd>
<dt><a name="item213">[213]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16382" title="Abstract">arXiv:2309.16382</a> [<a href="/pdf/2309.16382" title="Download PDF">pdf</a>, <a href="/format/2309.16382" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> RLLTE: Long-Term Evolution Project of Reinforcement Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yuan%2C+M">Mingqi Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zequn Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+Y">Yang Xu</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+S">Shihao Luo</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+B">Bo Li</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+X">Xin Jin</a>, 
<a href="/search/cs?searchtype=author&query=Zeng%2C+W">Wenjun Zeng</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 22 pages, 15 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">We present RLLTE: a long-term evolution, extremely modular, and open-source
framework for reinforcement learning (RL) research and application. Beyond
delivering top-notch algorithm implementations, RLLTE also serves as a toolkit
for developing algorithms. More specifically, RLLTE decouples the RL algorithms
completely from the exploitation-exploration perspective, providing a large
number of components to accelerate algorithm development and evolution. In
particular, RLLTE is the first RL framework to build a complete and luxuriant
ecosystem, which includes model training, evaluation, deployment, benchmark
hub, and large language model (LLM)-empowered copilot. RLLTE is expected to set
standards for RL engineering practice and be highly stimulative for industry
and academia.
</p>
</div>
</dd>
<dt><a name="item214">[214]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16384" title="Abstract">arXiv:2309.16384</a> [<a href="/pdf/2309.16384" title="Download PDF">pdf</a>, <a href="/format/2309.16384" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multi-Swap $k$-Means++
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Beretta%2C+L">Lorenzo Beretta</a>, 
<a href="/search/cs?searchtype=author&query=Cohen-Addad%2C+V">Vincent Cohen-Addad</a>, 
<a href="/search/cs?searchtype=author&query=Lattanzi%2C+S">Silvio Lattanzi</a>, 
<a href="/search/cs?searchtype=author&query=Parotsidis%2C+N">Nikos Parotsidis</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Geometry (cs.CG)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">The $k$-means++ algorithm of Arthur and Vassilvitskii (SODA 2007) is often
the practitioners' choice algorithm for optimizing the popular $k$-means
clustering objective and is known to give an $O(\log k)$-approximation in
expectation. To obtain higher quality solutions, Lattanzi and Sohler (ICML
2019) proposed augmenting $k$-means++ with $O(k \log \log k)$ local search
steps obtained through the $k$-means++ sampling distribution to yield a
$c$-approximation to the $k$-means clustering problem, where $c$ is a large
absolute constant. Here we generalize and extend their local search algorithm
by considering larger and more sophisticated local search neighborhoods hence
allowing to swap multiple centers at the same time. Our algorithm achieves a $9
+ \varepsilon$ approximation ratio, which is the best possible for local
search. Importantly we show that our approach yields substantial practical
improvements, we show significant quality improvements over the approach of
Lattanzi and Sohler (ICML 2019) on several datasets.
</p>
</div>
</dd>
<dt><a name="item215">[215]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16388" title="Abstract">arXiv:2309.16388</a> [<a href="/pdf/2309.16388" title="Download PDF">pdf</a>, <a href="/format/2309.16388" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Biomedical Image Splicing Detection using Uncertainty-Guided Refinement
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lin%2C+X">Xun Lin</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+W">Wenzhong Tang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Shuai Wang</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+Z">Zitong Yu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yizhong Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Haoran Wang</a>, 
<a href="/search/cs?searchtype=author&query=Fu%2C+Y">Ying Fu</a>, 
<a href="/search/cs?searchtype=author&query=Kot%2C+A">Alex Kot</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Recently, a surge in biomedical academic publications suspected of image
manipulation has led to numerous retractions, turning biomedical image
forensics into a research hotspot. While manipulation detectors are concerning,
the specific detection of splicing traces in biomedical images remains
underexplored. The disruptive factors within biomedical images, such as
artifacts, abnormal patterns, and noises, show misleading features like the
splicing traces, greatly increasing the challenge for this task. Moreover, the
scarcity of high-quality spliced biomedical images also limits potential
advancements in this field. In this work, we propose an Uncertainty-guided
Refinement Network (URN) to mitigate the effects of these disruptive factors.
Our URN can explicitly suppress the propagation of unreliable information flow
caused by disruptive factors among regions, thereby obtaining robust features.
Moreover, URN enables a concentration on the refinement of uncertainly
predicted regions during the decoding phase. Besides, we construct a dataset
for Biomedical image Splicing (BioSp) detection, which consists of 1,290
spliced images. Compared with existing datasets, BioSp comprises the largest
number of spliced images and the most diverse sources. Comprehensive
experiments on three benchmark datasets demonstrate the superiority of the
proposed method. Meanwhile, we verify the generalizability of URN when against
cross-dataset domain shifts and its robustness to resist post-processing
approaches. Our BioSp dataset will be released upon acceptance.
</p>
</div>
</dd>
<dt><a name="item216">[216]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16389" title="Abstract">arXiv:2309.16389</a> [<a href="/pdf/2309.16389" title="Download PDF">pdf</a>, <a href="/format/2309.16389" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Universal Framework for Holographic MIMO Sensing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Vanwynsberghe%2C+C">Charles Vanwynsberghe</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+J">Jiguang He</a>, 
<a href="/search/cs?searchtype=author&query=Debbah%2C+M">M&#xe9;rouane Debbah</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">This paper addresses the sensing space identification of arbitrarily shaped
continuous antennas. In the context of holographic multiple-input
multiple-output (MIMO), a.k.a. large intelligent surfaces, these antennas offer
benefits such as super-directivity and near-field operability. The sensing
space reveals two key aspects: (a) its dimension specifies the maximally
achievable spatial degrees of freedom (DoFs), and (b) the finite basis spanning
this space accurately describes the sampled field. Earlier studies focus on
specific geometries, bringing forth the need for extendable analysis to
real-world conformal antennas. Thus, we introduce a universal framework to
determine the antenna sensing space, regardless of its shape. The findings
underscore both spatial and spectral concentration of sampled fields to define
a generic eigenvalue problem of Slepian concentration. Results show that this
approach precisely estimates the DoFs of well-known geometries, and verify its
flexible extension to conformal antennas.
</p>
</div>
</dd>
<dt><a name="item217">[217]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16390" title="Abstract">arXiv:2309.16390</a> [<a href="/pdf/2309.16390" title="Download PDF">pdf</a>, <a href="/format/2309.16390" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An Enhanced Low-Resolution Image Recognition Method for Traffic  Environments
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tan%2C+Z">Zongcai Tan</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+Z">Zhenhai Gao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Robotics (cs.RO); Image and Video Processing (eess.IV)

</div>
<p class="mathjax">Currently, low-resolution image recognition is confronted with a significant
challenge in the field of intelligent traffic perception. Compared to
high-resolution images, low-resolution images suffer from small size, low
quality, and lack of detail, leading to a notable decrease in the accuracy of
traditional neural network recognition algorithms. The key to low-resolution
image recognition lies in effective feature extraction. Therefore, this paper
delves into the fundamental dimensions of residual modules and their impact on
feature extraction and computational efficiency. Based on experiments, we
introduce a dual-branch residual network structure that leverages the basic
architecture of residual networks and a common feature subspace algorithm.
Additionally, it incorporates the utilization of intermediate-layer features to
enhance the accuracy of low-resolution image recognition. Furthermore, we
employ knowledge distillation to reduce network parameters and computational
overhead. Experimental results validate the effectiveness of this algorithm for
low-resolution image recognition in traffic environments.
</p>
</div>
</dd>
<dt><a name="item218">[218]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16391" title="Abstract">arXiv:2309.16391</a> [<a href="/pdf/2309.16391" title="Download PDF">pdf</a>, <a href="/format/2309.16391" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Differential 2D Copula Approximating Transforms via Sobolev Training:  2-Cats Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Figueiredo%2C+F">Flavio Figueiredo</a>, 
<a href="/search/cs?searchtype=author&query=Fernandes%2C+J+G">Jos&#xe9; Geraldo Fernandes</a>, 
<a href="/search/cs?searchtype=author&query=Silva%2C+J">Jackson Silva</a>, 
<a href="/search/cs?searchtype=author&query=Assun%C3%A7%C3%A3o%2C+R+M">Renato M. Assun&#xe7;&#xe3;o</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Copulas are a powerful statistical tool that captures dependencies across
data dimensions. When applying Copulas, we can estimate multivariate
distribution functions by initially estimating independent marginals, an easy
task, and then a single copulating function, $C$, to connect the marginals, a
hard task. For two-dimensional data, a copula is a two-increasing function of
the form $C: (u,v)\in \mathbf{I}^2 \rightarrow \mathbf{I}$, where $\mathbf{I} =
[0, 1]$. In this paper, we show how Neural Networks (NNs) can approximate any
two-dimensional copula non-parametrically. Our approach, denoted as 2-Cats, is
inspired by the Physics-Informed Neural Networks and Sobolev Training
literature. Not only do we show that we can estimate the output of a 2d Copula
better than the state-of-the-art, our approach is non-parametric and respects
the mathematical properties of a Copula $C$.
</p>
</div>
</dd>
<dt><a name="item219">[219]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16393" title="Abstract">arXiv:2309.16393</a> [<a href="/pdf/2309.16393" title="Download PDF">pdf</a>, <a href="/format/2309.16393" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> HIC-YOLOv5: Improved YOLOv5 For Small Object Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tang%2C+S">Shiyi Tang</a>, 
<a href="/search/cs?searchtype=author&query=Fang%2C+Y">Yini Fang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+S">Shu Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages,10 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Small object detection has been a challenging problem in the field of object
detection. There has been some works that proposes improvements for this task,
such as adding several attention blocks or changing the whole structure of
feature fusion networks. However, the computation cost of these models is
large, which makes deploying a real-time object detection system unfeasible,
while leaving room for improvement. To this end, an improved YOLOv5 model:
HIC-YOLOv5 is proposed to address the aforementioned problems. Firstly, an
additional prediction head specific to small objects is added to provide a
higher-resolution feature map for better prediction. Secondly, an involution
block is adopted between the backbone and neck to increase channel information
of the feature map. Moreover, an attention mechanism named CBAM is applied at
the end of the backbone, thus not only decreasing the computation cost compared
with previous works but also emphasizing the important information in both
channel and spatial domain. Our result shows that HIC-YOLOv5 has improved
mAP@[.5:.95] by 6.42% and mAP@0.5 by 9.38% on VisDrone-2019-DET dataset.
</p>
</div>
</dd>
<dt><a name="item220">[220]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16395" title="Abstract">arXiv:2309.16395</a> [<a href="/pdf/2309.16395" title="Download PDF">pdf</a>, <a href="/format/2309.16395" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> QUIC on the Highway: Evaluating Performance on High-rate Links
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jaeger%2C+B">Benedikt Jaeger</a>, 
<a href="/search/cs?searchtype=author&query=Zirngibl%2C+J">Johannes Zirngibl</a>, 
<a href="/search/cs?searchtype=author&query=Kempf%2C+M">Marcel Kempf</a>, 
<a href="/search/cs?searchtype=author&query=Ploch%2C+K">Kevin Ploch</a>, 
<a href="/search/cs?searchtype=author&query=Carle%2C+G">Georg Carle</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Presented at the 2023 IFIP Networking Conference (IFIP Networking)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>

</div>
<p class="mathjax">QUIC is a new protocol standardized in 2021 designed to improve on the widely
used TCP / TLS stack. The main goal is to speed up web traffic via HTTP, but it
is also used in other areas like tunneling. Based on UDP it offers features
like reliable in-order delivery, flow and congestion control, streambased
multiplexing, and always-on encryption using TLS 1.3. Other than with TCP, QUIC
implements all these features in user space, only requiring kernel interaction
for UDP. While running in user space provides more flexibility, it profits less
from efficiency and optimization within the kernel. Multiple implementations
exist, differing in programming language, architecture, and design choices.
<br />This paper presents an extension to the QUIC Interop Runner, a framework for
testing interoperability of QUIC implementations. Our contribution enables
reproducible QUIC benchmarks on dedicated hardware. We provide baseline results
on 10G links, including multiple implementations, evaluate how OS features like
buffer sizes and NIC offloading impact QUIC performance, and show which data
rates can be achieved with QUIC compared to TCP. Our results show that QUIC
performance varies widely between client and server implementations from 90
Mbit/s to 4900 Mbit/s. We show that the OS generally sets the default buffer
size too small, which should be increased by at least an order of magnitude
based on our findings. Furthermore, QUIC benefits less from NIC offloading and
AES NI hardware acceleration while both features improve the goodput of TCP to
around 8000 Mbit/s. Our framework can be applied to evaluate the effects of
future improvements to the protocol or the OS.
</p>
</div>
</dd>
<dt><a name="item221">[221]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16396" title="Abstract">arXiv:2309.16396</a> [<a href="/pdf/2309.16396" title="Download PDF">pdf</a>, <a href="/format/2309.16396" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Comprehensive Survey of Document-level Relation Extraction (2016-2022)
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Delaunay%2C+J">Julien Delaunay</a>, 
<a href="/search/cs?searchtype=author&query=Tran%2C+T+H+H">Thi Hong Hanh Tran</a>, 
<a href="/search/cs?searchtype=author&query=Gonz%C3%A1lez-Gallardo%2C+C">Carlos-Emiliano Gonz&#xe1;lez-Gallardo</a>, 
<a href="/search/cs?searchtype=author&query=Bordea%2C+G">Georgeta Bordea</a>, 
<a href="/search/cs?searchtype=author&query=Sidere%2C+N">Nicolas Sidere</a>, 
<a href="/search/cs?searchtype=author&query=Doucet%2C+A">Antoine Doucet</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Document-level relation extraction (DocRE) is an active area of research in
natural language processing (NLP) concerned with identifying and extracting
relationships between entities beyond sentence boundaries. Compared to the more
traditional sentence-level relation extraction, DocRE provides a broader
context for analysis and is more challenging because it involves identifying
relationships that may span multiple sentences or paragraphs. This task has
gained increased interest as a viable solution to build and populate knowledge
bases automatically from unstructured large-scale documents (e.g., scientific
papers, legal contracts, or news articles), in order to have a better
understanding of relationships between entities. This paper aims to provide a
comprehensive overview of recent advances in this field, highlighting its
different applications in comparison to sentence-level relation extraction.
</p>
</div>
</dd>
<dt><a name="item222">[222]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16397" title="Abstract">arXiv:2309.16397</a> [<a href="/pdf/2309.16397" title="Download PDF">pdf</a>, <a href="/format/2309.16397" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Uncertainty-Aware Decision Transformer for Stochastic Driving  Environments
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zenan Li</a>, 
<a href="/search/cs?searchtype=author&query=Nie%2C+F">Fan Nie</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+Q">Qiao Sun</a>, 
<a href="/search/cs?searchtype=author&query=Da%2C+F">Fang Da</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+H">Hang Zhao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Offline Reinforcement Learning (RL) has emerged as a promising framework for
learning policies without active interactions, making it especially appealing
for autonomous driving tasks. Recent successes of Transformers inspire casting
offline RL as sequence modeling, which performs well in long-horizon tasks.
However, they are overly optimistic in stochastic environments with incorrect
assumptions that the same goal can be consistently achieved by identical
actions. In this paper, we introduce an UNcertainty-awaRE deciSion Transformer
(UNREST) for planning in stochastic driving environments without introducing
additional transition or complex generative models. Specifically, UNREST
estimates state uncertainties by the conditional mutual information between
transitions and returns, and segments sequences accordingly. Discovering the
`uncertainty accumulation' and `temporal locality' properties of driving
environments, UNREST replaces the global returns in decision transformers with
less uncertain truncated returns, to learn from true outcomes of agent actions
rather than environment transitions. We also dynamically evaluate environmental
uncertainty during inference for cautious planning. Extensive experimental
results demonstrate UNREST's superior performance in various driving scenarios
and the power of our uncertainty estimation strategy.
</p>
</div>
</dd>
<dt><a name="item223">[223]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16398" title="Abstract">arXiv:2309.16398</a> [<a href="/pdf/2309.16398" title="Download PDF">pdf</a>, <a href="/format/2309.16398" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Recent Advances of Differential Privacy in Centralized Deep Learning: A  Systematic Survey
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Demelius%2C+L">Lea Demelius</a>, 
<a href="/search/cs?searchtype=author&query=Kern%2C+R">Roman Kern</a>, 
<a href="/search/cs?searchtype=author&query=Tr%C3%BCgler%2C+A">Andreas Tr&#xfc;gler</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 35 pages, 2 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Differential Privacy has become a widely popular method for data protection
in machine learning, especially since it allows formulating strict mathematical
privacy guarantees. This survey provides an overview of the state-of-the-art of
differentially private centralized deep learning, thorough analyses of recent
advances and open problems, as well as a discussion of potential future
developments in the field. Based on a systematic literature review, the
following topics are addressed: auditing and evaluation methods for private
models, improvements of privacy-utility trade-offs, protection against a broad
range of threats and attacks, differentially private generative models, and
emerging application domains.
</p>
</div>
</dd>
<dt><a name="item224">[224]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16405" title="Abstract">arXiv:2309.16405</a> [<a href="/pdf/2309.16405" title="Download PDF">pdf</a>, <a href="/format/2309.16405" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> gSPICE: Model-Based Event Shedding in Complex Event Processing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Slo%2C+A">Ahmad Slo</a>, 
<a href="/search/cs?searchtype=author&query=Bhowmik%2C+S">Sukanya Bhowmik</a>, 
<a href="/search/cs?searchtype=author&query=Rothermel%2C+K">Kurt Rothermel</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>

</div>
<p class="mathjax">Overload situations, in the presence of resource limitations, in complex
event processing (CEP) systems are typically handled using load shedding to
maintain a given latency bound. However, load shedding might negatively impact
the quality of results (QoR). To minimize the shedding impact on QoR, CEP
researchers propose shedding approaches that drop events/internal state with
the lowest importances/utilities. In both black-box and white-box shedding
approaches, different features are used to predict these utilities. In this
work, we propose a novel black-box shedding approach that uses a new set of
features to drop events from the input event stream to maintain a given latency
bound. Our approach uses a probabilistic model to predict these event
utilities. Moreover, our approach uses Zobrist hashing and well-known machine
learning models, e.g., decision trees and random forests, to handle the
predicted event utilities. Through extensive evaluations on several synthetic
and two real-world datasets and a representative set of CEP queries, we show
that, in the majority of cases, our load shedding approach outperforms
state-of-the-art black-box load shedding approaches, w.r.t. QoR.
</p>
</div>
</dd>
<dt><a name="item225">[225]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16411" title="Abstract">arXiv:2309.16411</a> [<a href="/pdf/2309.16411" title="Download PDF">pdf</a>, <a href="/format/2309.16411" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On combinatorial structures in linear codes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Baspin%2C+N">Nou&#xe9;dyn Baspin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Quantum Physics (quant-ph)

</div>
<p class="mathjax">In this work we show that given a connectivity graph $G$ of a $[[n,k,d]]$
quantum code, there exists $\{K_i\}_i, K_i \subset G$, such that $\sum_i
|K_i|\in \Omega(k), \ |K_i| \in \Omega(d)$, and the $K_i$'s are
$\tilde{\Omega}( \sqrt{{k}/{n}})$-expander. If the codes are classical we show
instead that the $K_i$'s are $\tilde{\Omega}\left({{k}/{n}}\right)$-expander.
We also show converses to these bounds. In particular, we show that the BPT
bound for classical codes is tight in all Euclidean dimensions. Finally, we
prove structural theorems for graphs with no "dense" subgraphs which might be
of independent interest.
</p>
</div>
</dd>
<dt><a name="item226">[226]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16413" title="Abstract">arXiv:2309.16413</a> [<a href="/pdf/2309.16413" title="Download PDF">pdf</a>, <a href="/format/2309.16413" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Genetic Engineering Algorithm (GEA): An Efficient Metaheuristic  Algorithm for Solving Combinatorial Optimization Problems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sohrabi%2C+M">Majid Sohrabi</a>, 
<a href="/search/cs?searchtype=author&query=Fathollahi-Fard%2C+A+M">Amir M. Fathollahi-Fard</a>, 
<a href="/search/cs?searchtype=author&query=Gromov%2C+V+A">Vasilii A. Gromov</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted in Data Analytics and Management in Data Intensive Domains (DAMDID/RCDL 2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neural and Evolutionary Computing (cs.NE)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Genetic Algorithms (GAs) are known for their efficiency in solving
combinatorial optimization problems, thanks to their ability to explore diverse
solution spaces, handle various representations, exploit parallelism, preserve
good solutions, adapt to changing dynamics, handle combinatorial diversity, and
provide heuristic search. However, limitations such as premature convergence,
lack of problem-specific knowledge, and randomness of crossover and mutation
operators make GAs generally inefficient in finding an optimal solution. To
address these limitations, this paper proposes a new metaheuristic algorithm
called the Genetic Engineering Algorithm (GEA) that draws inspiration from
genetic engineering concepts. GEA redesigns the traditional GA while
incorporating new search methods to isolate, purify, insert, and express new
genes based on existing ones, leading to the emergence of desired traits and
the production of specific chromosomes based on the selected genes. Comparative
evaluations against state-of-the-art algorithms on benchmark instances
demonstrate the superior performance of GEA, showcasing its potential as an
innovative and efficient solution for combinatorial optimization problems.
</p>
</div>
</dd>
<dt><a name="item227">[227]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16414" title="Abstract">arXiv:2309.16414</a> [<a href="/pdf/2309.16414" title="Download PDF">pdf</a>, <a href="/format/2309.16414" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AutoCLIP: Auto-tuning Zero-Shot Classifiers for Vision-Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Metzen%2C+J+H">Jan Hendrik Metzen</a>, 
<a href="/search/cs?searchtype=author&query=Saranrittichai%2C+P">Piyapat Saranrittichai</a>, 
<a href="/search/cs?searchtype=author&query=Mummadi%2C+C+K">Chaithanya Kumar Mummadi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Classifiers built upon vision-language models such as CLIP have shown
remarkable zero-shot performance across a broad range of image classification
tasks. Prior work has studied different ways of automatically creating
descriptor sets for every class based on prompt templates, ranging from
manually engineered templates over templates obtained from a large language
model to templates built from random words and characters. In contrast,
deriving zero-shot classifiers from the respective encoded class descriptors
has remained nearly unchanged, that is: classify to the class that maximizes
the cosine similarity between its averaged encoded class descriptors and the
encoded image. However, weighting all class descriptors equally can be
suboptimal when certain descriptors match visual clues on a given image better
than others. In this work, we propose AutoCLIP, a method for auto-tuning
zero-shot classifiers. AutoCLIP assigns to each prompt template per-image
weights, which are derived from statistics of class descriptor-image
similarities at inference time. AutoCLIP is fully unsupervised, has very low
overhead, and can be easily implemented in few lines of code. We show that for
a broad range of vision-language models, datasets, and prompt templates,
AutoCLIP outperforms baselines consistently and by up to 3 percent point
accuracy.
</p>
</div>
</dd>
<dt><a name="item228">[228]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16418" title="Abstract">arXiv:2309.16418</a> [<a href="/pdf/2309.16418" title="Download PDF">pdf</a>, <a href="/format/2309.16418" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Efficient Supervised Training of Audio Transformers for Music  Representation Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Alonso-Jim%C3%A9nez%2C+P">Pablo Alonso-Jim&#xe9;nez</a>, 
<a href="/search/cs?searchtype=author&query=Serra%2C+X">Xavier Serra</a>, 
<a href="/search/cs?searchtype=author&query=Bogdanov%2C+D">Dmitry Bogdanov</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at the 2023 International Society for Music Information Retrieval Conference (ISMIR'23)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">In this work, we address music representation learning using convolution-free
transformers. We build on top of existing spectrogram-based audio transformers
such as AST and train our models on a supervised task using patchout training
similar to PaSST. In contrast to previous works, we study how specific design
decisions affect downstream music tagging tasks instead of focusing on the
training task. We assess the impact of initializing the models with different
pre-trained weights, using various input audio segment lengths, using learned
representations from different blocks and tokens of the transformer for
downstream tasks, and applying patchout at inference to speed up feature
extraction. We find that 1) initializing the model from ImageNet or AudioSet
weights and using longer input segments are beneficial both for the training
and downstream tasks, 2) the best representations for the considered downstream
tasks are located in the middle blocks of the transformer, and 3) using
patchout at inference allows faster processing than our convolutional baselines
while maintaining superior performance. The resulting models, MAEST, are
publicly available and obtain the best performance among open models in music
tagging tasks.
</p>
</div>
</dd>
<dt><a name="item229">[229]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16421" title="Abstract">arXiv:2309.16421</a> [<a href="/pdf/2309.16421" title="Download PDF">pdf</a>, <a href="/format/2309.16421" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Distilling ODE Solvers of Diffusion Models into Smaller Steps
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kim%2C+S">Sanghwan Kim</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+H">Hao Tang</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+F">Fisher Yu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Distillation techniques have substantially improved the sampling speed of
diffusion models, allowing of the generation within only one step or a few
steps. However, these distillation methods require extensive training for each
dataset, sampler, and network, which limits their practical applicability. To
address this limitation, we propose a straightforward distillation approach,
Distilled-ODE solvers (D-ODE solvers), that optimizes the ODE solver rather
than training the denoising network. D-ODE solvers are formulated by simply
applying a single parameter adjustment to existing ODE solvers. Subsequently,
D-ODE solvers with smaller steps are optimized by ODE solvers with larger steps
through distillation over a batch of samples. Our comprehensive experiments
indicate that D-ODE solvers outperform existing ODE solvers, including DDIM,
PNDM, DPM-Solver, DEIS, and EDM, especially when generating samples with fewer
steps. Our method incur negligible computational overhead compared to previous
distillation techniques, enabling simple and rapid integration with previous
samplers. Qualitative analysis further shows that D-ODE solvers enhance image
quality while preserving the sampling trajectory of ODE solvers.
</p>
</div>
</dd>
<dt><a name="item230">[230]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16422" title="Abstract">arXiv:2309.16422</a> [<a href="/pdf/2309.16422" title="Download PDF">pdf</a>, <a href="/format/2309.16422" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Cyber Sentinel: Exploring Conversational Agents in Streamlining Security  Tasks with GPT-4
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kaheh%2C+M">Mehrdad Kaheh</a>, 
<a href="/search/cs?searchtype=author&query=Kholgh%2C+D+K">Danial Khosh Kholgh</a>, 
<a href="/search/cs?searchtype=author&query=Kostakos%2C+P">Panos Kostakos</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">In an era where cyberspace is both a battleground and a backbone of modern
society, the urgency of safeguarding digital assets against ever-evolving
threats is paramount. This paper introduces Cyber Sentinel, an innovative
task-oriented cybersecurity dialogue system that is effectively capable of
managing two core functions: explaining potential cyber threats within an
organization to the user, and taking proactive/reactive security actions when
instructed by the user. Cyber Sentinel embodies the fusion of artificial
intelligence, cybersecurity domain expertise, and real-time data analysis to
combat the multifaceted challenges posed by cyber adversaries. This article
delves into the process of creating such a system and how it can interact with
other components typically found in cybersecurity organizations. Our work is a
novel approach to task-oriented dialogue systems, leveraging the power of
chaining GPT-4 models combined with prompt engineering across all sub-tasks. We
also highlight its pivotal role in enhancing cybersecurity communication and
interaction, concluding that not only does this framework enhance the system's
transparency (Explainable AI) but also streamlines the decision-making process
and responding to threats (Actionable AI), therefore marking a significant
advancement in the realm of cybersecurity communication.
</p>
</div>
</dd>
<dt><a name="item231">[231]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16424" title="Abstract">arXiv:2309.16424</a> [<a href="/pdf/2309.16424" title="Download PDF">pdf</a>, <a href="/format/2309.16424" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Prompt-and-Align: Prompt-Based Social Alignment for Few-Shot Fake News  Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+J">Jiaying Wu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+S">Shen Li</a>, 
<a href="/search/cs?searchtype=author&query=Deng%2C+A">Ailin Deng</a>, 
<a href="/search/cs?searchtype=author&query=Xiong%2C+M">Miao Xiong</a>, 
<a href="/search/cs?searchtype=author&query=Hooi%2C+B">Bryan Hooi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to CIKM 2023 (Full Paper)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Social and Information Networks (cs.SI)

</div>
<p class="mathjax">Despite considerable advances in automated fake news detection, due to the
timely nature of news, it remains a critical open question how to effectively
predict the veracity of news articles based on limited fact-checks. Existing
approaches typically follow a "Train-from-Scratch" paradigm, which is
fundamentally bounded by the availability of large-scale annotated data. While
expressive pre-trained language models (PLMs) have been adapted in a
"Pre-Train-and-Fine-Tune" manner, the inconsistency between pre-training and
downstream objectives also requires costly task-specific supervision. In this
paper, we propose "Prompt-and-Align" (P&amp;A), a novel prompt-based paradigm for
few-shot fake news detection that jointly leverages the pre-trained knowledge
in PLMs and the social context topology. Our approach mitigates label scarcity
by wrapping the news article in a task-related textual prompt, which is then
processed by the PLM to directly elicit task-specific knowledge. To supplement
the PLM with social context without inducing additional training overheads,
motivated by empirical observation on user veracity consistency (i.e., social
users tend to consume news of the same veracity type), we further construct a
news proximity graph among news articles to capture the veracity-consistent
signals in shared readerships, and align the prompting predictions along the
graph edges in a confidence-informed manner. Extensive experiments on three
real-world benchmarks demonstrate that P&amp;A sets new states-of-the-art for
few-shot fake news detection performance by significant margins.
</p>
</div>
</dd>
<dt><a name="item232">[232]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16426" title="Abstract">arXiv:2309.16426</a> [<a href="/pdf/2309.16426" title="Download PDF">pdf</a>, <a href="/format/2309.16426" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> QwenGrasp: A Usage of Large Vision Language Model for Target-oriented  Grasping
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+X">Xinyu Chen</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+J">Jian Yang</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+Z">Zonghan He</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+H">Haobin Yang</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Q">Qi Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+Y">Yuhui Shi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">The ability for robotic systems to understand human language and execute
grasping actions is a pivotal challenge in the field of robotics. In
target-oriented grasping, prior researches achieve matching human textual
commands with images of target objects. However, these works are hard to
understand complex or flexible instructions. Moreover, these works lack the
capability to autonomously assess the feasibility of instructions, leading to
blindly execute grasping tasks even there is no target object. In this paper,
we introduce a combination model called QwenGrasp, which combines a large
vision language model with a 6-DoF grasp network. By leveraging a pre-trained
large vision language model, our approach is capable of working in open-world
with natural human language environments, accepting complex and flexible
instructions. Furthermore, the specialized grasp network ensures the
effectiveness of the generated grasp pose. A series of experiments conducted in
real world environment show that our method exhibits a superior ability to
comprehend human intent. Additionally, when accepting erroneous instructions,
our approach has the capability to suspend task execution and provide feedback
to humans, improving safety.
</p>
</div>
</dd>
<dt><a name="item233">[233]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16427" title="Abstract">arXiv:2309.16427</a> [<a href="/pdf/2309.16427" title="Download PDF">pdf</a>, <a href="/format/2309.16427" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Klever: Verification Framework for Critical Industrial C Programs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zakharov%2C+I">Ilja Zakharov</a>, 
<a href="/search/cs?searchtype=author&query=Novikov%2C+E">Evgeny Novikov</a>, 
<a href="/search/cs?searchtype=author&query=Shchepetkov%2C+I">Ilya Shchepetkov</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 53 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
<p class="mathjax">Automatic software verification tools help to find hard-to-detect faults in
programs checked against specified requirements non-interactively. Besides,
they can prove program correctness formally under certain assumptions. These
capabilities are vital for verification of critical industrial programs like
operating system kernels and embedded software. However, such programs can
contain hundreds or thousands of KLOC that prevent obtaining valuable
verification results in any reasonable time when checking non-trivial
requirements. Also, existing tools do not provide widely adopted means for
environment modeling, specification of requirements, verification of many
versions and configurations of target programs, and expert assessment of
verification results. In this paper, we present the Klever software
verification framework, designed to reduce the effort of applying automatic
software verification tools to large and critical industrial C programs.
</p>
</div>
</dd>
<dt><a name="item234">[234]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16428" title="Abstract">arXiv:2309.16428</a> [<a href="/pdf/2309.16428" title="Download PDF">pdf</a>, <a href="/format/2309.16428" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Nonlinear MPC design for incrementally ISS systems with application to  GRU networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Bonassi%2C+F">Fabio Bonassi</a>, 
<a href="/search/eess?searchtype=author&query=La+Bella%2C+A">Alessio La Bella</a>, 
<a href="/search/eess?searchtype=author&query=Farina%2C+M">Marcello Farina</a>, 
<a href="/search/eess?searchtype=author&query=Scattolini%2C+R">Riccardo Scattolini</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> {\copyright} 2023. This manuscript version is made available under the CC-BY-NC-ND 4.0 license (<a href="https://creativecommons.org/licenses/by-nc-nd/4.0/">this https URL</a>). This manuscript has been accepted for publication at Elsevier Automatica. Please cite the published article instead of this manuscript. DOI will be included as soon as available
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">This brief addresses the design of a Nonlinear Model Predictive Control
(NMPC) strategy for exponentially incremental Input-to-State Stable (ISS)
systems. In particular, a novel formulation is devised, which does not
necessitate the onerous computation of terminal ingredients, but rather relies
on the explicit definition of a minimum prediction horizon ensuring closed-loop
stability. The designed methodology is particularly suited for the control of
systems learned by Recurrent Neural Networks (RNNs), which are known for their
enhanced modeling capabilities and for which the incremental ISS properties can
be studied thanks to simple algebraic conditions. The approach is applied to
Gated Recurrent Unit (GRU) networks, providing also a method for the design of
a tailored state observer with convergence guarantees. The resulting control
architecture is tested on a benchmark system, demonstrating its good control
performances and efficient applicability.
</p>
</div>
</dd>
<dt><a name="item235">[235]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16429" title="Abstract">arXiv:2309.16429</a> [<a href="/pdf/2309.16429" title="Download PDF">pdf</a>, <a href="/format/2309.16429" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Diverse and Aligned Audio-to-Video Generation via Text-to-Video Model  Adaptation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yariv%2C+G">Guy Yariv</a>, 
<a href="/search/cs?searchtype=author&query=Gat%2C+I">Itai Gat</a>, 
<a href="/search/cs?searchtype=author&query=Benaim%2C+S">Sagie Benaim</a>, 
<a href="/search/cs?searchtype=author&query=Wolf%2C+L">Lior Wolf</a>, 
<a href="/search/cs?searchtype=author&query=Schwartz%2C+I">Idan Schwartz</a>, 
<a href="/search/cs?searchtype=author&query=Adi%2C+Y">Yossi Adi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages, 6 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">We consider the task of generating diverse and realistic videos guided by
natural audio samples from a wide variety of semantic classes. For this task,
the videos are required to be aligned both globally and temporally with the
input audio: globally, the input audio is semantically associated with the
entire output video, and temporally, each segment of the input audio is
associated with a corresponding segment of that video. We utilize an existing
text-conditioned video generation model and a pre-trained audio encoder model.
The proposed method is based on a lightweight adaptor network, which learns to
map the audio-based representation to the input representation expected by the
text-to-video generation model. As such, it also enables video generation
conditioned on text, audio, and, for the first time as far as we can ascertain,
on both text and audio. We validate our method extensively on three datasets
demonstrating significant semantic diversity of audio-video samples and further
propose a novel evaluation metric (AV-Align) to assess the alignment of
generated videos with input audio samples. AV-Align is based on the detection
and comparison of energy peaks in both modalities. In comparison to recent
state-of-the-art approaches, our method generates videos that are better
aligned with the input sound, both with respect to content and temporal axis.
We also show that videos produced by our method present higher visual quality
and are more diverse.
</p>
</div>
</dd>
<dt><a name="item236">[236]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16435" title="Abstract">arXiv:2309.16435</a> [<a href="/pdf/2309.16435" title="Download PDF">pdf</a>, <a href="/format/2309.16435" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Radar Instance Transformer: Reliable Moving Instance Segmentation in  Sparse Radar Point Clouds
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zeller%2C+M">Matthias Zeller</a>, 
<a href="/search/cs?searchtype=author&query=Sandhu%2C+V+S">Vardeep S. Sandhu</a>, 
<a href="/search/cs?searchtype=author&query=Mersch%2C+B">Benedikt Mersch</a>, 
<a href="/search/cs?searchtype=author&query=Behley%2C+J">Jens Behley</a>, 
<a href="/search/cs?searchtype=author&query=Heidingsfeld%2C+M">Michael Heidingsfeld</a>, 
<a href="/search/cs?searchtype=author&query=Stachniss%2C+C">Cyrill Stachniss</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> UNDER Review
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">The perception of moving objects is crucial for autonomous robots performing
collision avoidance in dynamic environments. LiDARs and cameras tremendously
enhance scene interpretation but do not provide direct motion information and
face limitations under adverse weather. Radar sensors overcome these
limitations and provide Doppler velocities, delivering direct information on
dynamic objects. In this paper, we address the problem of moving instance
segmentation in radar point clouds to enhance scene interpretation for
safety-critical tasks. Our Radar Instance Transformer enriches the current
radar scan with temporal information without passing aggregated scans through a
neural network. We propose a full-resolution backbone to prevent information
loss in sparse point cloud processing. Our instance transformer head
incorporates essential information to enhance segmentation but also enables
reliable, class-agnostic instance assignments. In sum, our approach shows
superior performance on the new moving instance segmentation benchmarks,
including diverse environments, and provides model-agnostic modules to enhance
scene interpretation. The benchmark is based on the RadarScenes dataset and
will be made available upon acceptance.
</p>
</div>
</dd>
<dt><a name="item237">[237]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16436" title="Abstract">arXiv:2309.16436</a> [<a href="/pdf/2309.16436" title="Download PDF">pdf</a>, <a href="/format/2309.16436" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Neuro Symbolic Reasoning for Planning: Counterexample Guided Inductive  Synthesis using Large Language Models and Satisfiability Solving
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jha%2C+S+K">Sumit Kumar Jha</a>, 
<a href="/search/cs?searchtype=author&query=Jha%2C+S">Susmit Jha</a>, 
<a href="/search/cs?searchtype=author&query=Lincoln%2C+P">Patrick Lincoln</a>, 
<a href="/search/cs?searchtype=author&query=Bastian%2C+N+D">Nathaniel D. Bastian</a>, 
<a href="/search/cs?searchtype=author&query=Velasquez%2C+A">Alvaro Velasquez</a>, 
<a href="/search/cs?searchtype=author&query=Ewetz%2C+R">Rickard Ewetz</a>, 
<a href="/search/cs?searchtype=author&query=Neema%2C+S">Sandeep Neema</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 25 pages, 7 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Logic in Computer Science (cs.LO)

</div>
<p class="mathjax">Generative large language models (LLMs) with instruct training such as GPT-4
can follow human-provided instruction prompts and generate human-like responses
to these prompts. Apart from natural language responses, they have also been
found to be effective at generating formal artifacts such as code, plans, and
logical specifications from natural language prompts. Despite their remarkably
improved accuracy, these models are still known to produce factually incorrect
or contextually inappropriate results despite their syntactic coherence - a
phenomenon often referred to as hallucination. This limitation makes it
difficult to use these models to synthesize formal artifacts that are used in
safety-critical applications. Unlike tasks such as text summarization and
question-answering, bugs in code, plan, and other formal artifacts produced by
LLMs can be catastrophic. We posit that we can use the satisfiability modulo
theory (SMT) solvers as deductive reasoning engines to analyze the generated
solutions from the LLMs, produce counterexamples when the solutions are
incorrect, and provide that feedback to the LLMs exploiting the dialog
capability of instruct-trained LLMs. This interaction between inductive LLMs
and deductive SMT solvers can iteratively steer the LLM to generate the correct
response. In our experiments, we use planning over the domain of blocks as our
synthesis task for evaluating our approach. We use GPT-4, GPT3.5 Turbo,
Davinci, Curie, Babbage, and Ada as the LLMs and Z3 as the SMT solver. Our
method allows the user to communicate the planning problem in natural language;
even the formulation of queries to SMT solvers is automatically generated from
natural language. Thus, the proposed technique can enable non-expert users to
describe their problems in natural language, and the combination of LLMs and
SMT solvers can produce provably correct solutions.
</p>
</div>
</dd>
<dt><a name="item238">[238]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16439" title="Abstract">arXiv:2309.16439</a> [<a href="/pdf/2309.16439" title="Download PDF">pdf</a>, <a href="/format/2309.16439" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Uncertainty quantification and complex analyticity of the nonlinear  Poisson-Boltzmann equation for the interface problem with random domains
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Norton%2C+T">Trevor Norton</a>, 
<a href="/search/math?searchtype=author&query=Xu%2C+J">Jie Xu</a>, 
<a href="/search/math?searchtype=author&query=Choi%2C+B">Brian Choi</a>, 
<a href="/search/math?searchtype=author&query=Kon%2C+M">Mark Kon</a>, 
<a href="/search/math?searchtype=author&query=Castrill%C3%B3n-Cand%C3%A1s%2C+J+E">Julio Enrique Castrill&#xf3;n-Cand&#xe1;s</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 28 pages,4 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">The nonlinear Poisson-Boltzmann equation (NPBE) is an elliptic partial
differential equation used in applications such as protein interactions and
biophysical chemistry (among many others). It describes the nonlinear
electrostatic potential of charged bodies submerged in an ionic solution. The
kinetic presence of the solvent molecules introduces randomness to the shape of
a protein, and thus a more accurate model that incorporates these random
perturbations of the domain is analyzed to compute the statistics of quantities
of interest of the solution. When the parameterization of the random
perturbations is high-dimensional, this calculation is intractable as it is
subject to the curse of dimensionality. However, if the solution of the NPBE
varies analytically with respect to the random parameters, the problem becomes
amenable to techniques such as sparse grids and deep neural networks. In this
paper, we show analyticity of the solution of the NPBE with respect to analytic
perturbations of the domain by using the analytic implicit function theorem and
the domain mapping method. Previous works have shown analyticity of solutions
to linear elliptic equations but not for nonlinear problems. We further show
how to derive \emph{a priori} bounds on the size of the region of analyticity.
This method is applied to the trypsin molecule to demonstrate that the
convergence rates of the quantity of interest are consistent with the
analyticity result. Furthermore, the approach developed here is sufficiently
general enough to be applied to other nonlinear problems in uncertainty
quantification.
</p>
</div>
</dd>
<dt><a name="item239">[239]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16442" title="Abstract">arXiv:2309.16442</a> [<a href="/pdf/2309.16442" title="Download PDF">pdf</a>, <a href="/format/2309.16442" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Small World of Bad Guys: Investigating the Behavior of Hacker Groups  in Cyber-Attacks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Giacomello%2C+G">Giampiero Giacomello</a>, 
<a href="/search/cs?searchtype=author&query=Iovanella%2C+A">Antonio Iovanella</a>, 
<a href="/search/cs?searchtype=author&query=Martino%2C+L">Luigi Martino</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>

</div>
<p class="mathjax">This paper explores the behaviour of malicious hacker groups operating in
cyberspace and how they organize themselves in structured networks. To better
understand these groups, the paper uses Social Network Analysis (SNA) to
analyse the interactions and relationships among several malicious hacker
groups. The study uses a tested dataset as its primary source, providing an
empirical analysis of the cooperative behaviours exhibited by these groups. The
study found that malicious hacker groups tend to form close-knit networks where
they consult, coordinate with, and assist each other in carrying out their
attacks. The study also identified a "small world" phenomenon within the
population of malicious actors, which suggests that these groups establish
interconnected relationships to facilitate their malicious operations. The
small world phenomenon indicates that the actor-groups are densely connected,
but they also have a small number of connections to other groups, allowing for
efficient communication and coordination of their activities.
</p>
</div>
</dd>
<dt><a name="item240">[240]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16445" title="Abstract">arXiv:2309.16445</a> [<a href="/pdf/2309.16445" title="Download PDF">pdf</a>, <a href="/format/2309.16445" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> db-CBS: Discontinuity-Bounded Conflict-Based Search for Multi-Robot  Kinodynamic Motion Planning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Moldagalieva%2C+A">Akmaral Moldagalieva</a>, 
<a href="/search/cs?searchtype=author&query=Ortiz-Haro%2C+J">Joaquim Ortiz-Haro</a>, 
<a href="/search/cs?searchtype=author&query=Toussaint%2C+M">Marc Toussaint</a>, 
<a href="/search/cs?searchtype=author&query=H%C3%B6nig%2C+W">Wolfgang H&#xf6;nig</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> submitted to ICRA 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">This paper presents a multi-robot kinodynamic motion planner that enables a
team of robots with different dynamics, actuation limits, and shapes to reach
their goals in challenging environments. We solve this problem by combining
Conflict-Based Search (CBS), a multi-agent path finding method, and
discontinuity-bounded A*, a single-robot kinodynamic motion planner. Our
method, db-CBS, operates in three levels. Initially, we compute trajectories
for individual robots using a graph search that allows bounded discontinuities
between precomputed motion primitives. The second level identifies inter-robot
collisions and resolves them by imposing constraints on the first level. The
third and final level uses the resulting solution with discontinuities as an
initial guess for a joint space trajectory optimization. The procedure is
repeated with a reduced discontinuity bound. Our approach is anytime,
probabilistically complete, asymptotically optimal, and finds near-optimal
solutions quickly. Experimental results with robot dynamics such as unicycle,
double integrator, and car with trailer in different settings show that our
method is capable of solving challenging tasks with a higher success rate and
lower cost than the existing state-of-the-art.
</p>
</div>
</dd>
<dt><a name="item241">[241]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16451" title="Abstract">arXiv:2309.16451</a> [<a href="/pdf/2309.16451" title="Download PDF">pdf</a>, <a href="/format/2309.16451" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Novel Class Discovery: A Study in Novel Skin Lesions Clustering
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Feng%2C+W">Wei Feng</a>, 
<a href="/search/cs?searchtype=author&query=Ju%2C+L">Lie Ju</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+L">Lin Wang</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+K">Kaimin Song</a>, 
<a href="/search/cs?searchtype=author&query=Ge%2C+Z">Zongyuan Ge</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 1 figure,Accepted by miccai 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Existing deep learning models have achieved promising performance in
recognizing skin diseases from dermoscopic images. However, these models can
only recognize samples from predefined categories, when they are deployed in
the clinic, data from new unknown categories are constantly emerging.
Therefore, it is crucial to automatically discover and identify new semantic
categories from new data. In this paper, we propose a new novel class discovery
framework for automatically discovering new semantic classes from dermoscopy
image datasets based on the knowledge of known classes. Specifically, we first
use contrastive learning to learn a robust and unbiased feature representation
based on all data from known and unknown categories. We then propose an
uncertainty-aware multi-view cross pseudo-supervision strategy, which is
trained jointly on all categories of data using pseudo labels generated by a
self-labeling strategy. Finally, we further refine the pseudo label by
aggregating neighborhood information through local sample similarity to improve
the clustering performance of the model for unknown categories. We conducted
extensive experiments on the dermatology dataset ISIC 2019, and the
experimental results show that our approach can effectively leverage knowledge
from known categories to discover new semantic categories. We also further
validated the effectiveness of the different modules through extensive ablation
experiments. Our code will be released soon.
</p>
</div>
</dd>
<dt><a name="item242">[242]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16452" title="Abstract">arXiv:2309.16452</a> [<a href="/pdf/2309.16452" title="Download PDF">pdf</a>, <a href="/format/2309.16452" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the Trade-offs between Adversarial Robustness and Actionable  Explanations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Krishna%2C+S">Satyapriya Krishna</a>, 
<a href="/search/cs?searchtype=author&query=Agarwal%2C+C">Chirag Agarwal</a>, 
<a href="/search/cs?searchtype=author&query=Lakkaraju%2C+H">Himabindu Lakkaraju</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">As machine learning models are increasingly being employed in various
high-stakes settings, it becomes important to ensure that predictions of these
models are not only adversarially robust, but also readily explainable to
relevant stakeholders. However, it is unclear if these two notions can be
simultaneously achieved or if there exist trade-offs between them. In this
work, we make one of the first attempts at studying the impact of adversarially
robust models on actionable explanations which provide end users with a means
for recourse. We theoretically and empirically analyze the cost (ease of
implementation) and validity (probability of obtaining a positive model
prediction) of recourses output by state-of-the-art algorithms when the
underlying models are adversarially robust vs. non-robust. More specifically,
we derive theoretical bounds on the differences between the cost and the
validity of the recourses generated by state-of-the-art algorithms for
adversarially robust vs. non-robust linear and non-linear models. Our empirical
results with multiple real-world datasets validate our theoretical results and
show the impact of varying degrees of model robustness on the cost and validity
of the resulting recourses. Our analyses demonstrate that adversarially robust
models significantly increase the cost and reduce the validity of the resulting
recourses, thus shedding light on the inherent trade-offs between adversarial
robustness and actionable explanations
</p>
</div>
</dd>
<dt><a name="item243">[243]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16456" title="Abstract">arXiv:2309.16456</a> [<a href="/pdf/2309.16456" title="Download PDF">pdf</a>, <a href="/format/2309.16456" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Resisting Backdoor Attacks in Federated Learning via Bidirectional  Elections and Individual Perspective
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Qin%2C+Z">Zhen Qin</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+F">Feiyi Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhi%2C+C">Chen Zhi</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+X">Xueqiang Yan</a>, 
<a href="/search/cs?searchtype=author&query=Deng%2C+S">Shuiguang Deng</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Existing approaches defend against backdoor attacks in federated learning
(FL) mainly through a) mitigating the impact of infected models, or b)
excluding infected models. The former negatively impacts model accuracy, while
the latter usually relies on globally clear boundaries between benign and
infected model updates. However, model updates are easy to be mixed and
scattered throughout in reality due to the diverse distributions of local data.
This work focuses on excluding infected models in FL. Unlike previous
perspectives from a global view, we propose Snowball, a novel anti-backdoor FL
framework through bidirectional elections from an individual perspective
inspired by one principle deduced by us and two principles in FL and deep
learning. It is characterized by a) bottom-up election, where each candidate
model update votes to several peer ones such that a few model updates are
elected as selectees for aggregation; and b) top-down election, where selectees
progressively enlarge themselves through picking up from the candidates. We
compare Snowball with state-of-the-art defenses to backdoor attacks in FL on
five real-world datasets, demonstrating its superior resistance to backdoor
attacks and slight impact on the accuracy of the global model.
</p>
</div>
</dd>
<dt><a name="item244">[244]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16457" title="Abstract">arXiv:2309.16457</a> [<a href="/pdf/2309.16457" title="Download PDF">pdf</a>, <a href="/format/2309.16457" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Universal Sleep Decoder: Aligning awake and sleep neural representation  across subjects
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zheng%2C+H">Hui Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Z">Zhongtao Chen</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Haiteng Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+J">Jianyang Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+L">Lin Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yunzhe Liu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Signal Processing (eess.SP); Neurons and Cognition (q-bio.NC)

</div>
<p class="mathjax">Decoding memory content from brain activity during sleep has long been a goal
in neuroscience. While spontaneous reactivation of memories during sleep in
rodents is known to support memory consolidation and offline learning,
capturing memory replay in humans is challenging due to the absence of
well-annotated sleep datasets and the substantial differences in neural
patterns between wakefulness and sleep. To address these challenges, we
designed a novel cognitive neuroscience experiment and collected a
comprehensive, well-annotated electroencephalography (EEG) dataset from 52
subjects during both wakefulness and sleep. Leveraging this benchmark dataset,
we developed the Universal Sleep Decoder (USD) to align neural representations
between wakefulness and sleep across subjects. Our model achieves up to 16.6%
top-1 zero-shot accuracy on unseen subjects, comparable to decoding
performances using individual sleep data. Furthermore, fine-tuning USD on test
subjects enhances decoding accuracy to 25.9% top-1 accuracy, a substantial
improvement over the baseline chance of 6.7%. Model comparison and ablation
analyses reveal that our design choices, including the use of (i) an additional
contrastive objective to integrate awake and sleep neural signals and (ii) the
pretrain-finetune paradigm to incorporate different subjects, significantly
contribute to these performances. Collectively, our findings and methodologies
represent a significant advancement in the field of sleep decoding.
</p>
</div>
</dd>
<dt><a name="item245">[245]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16459" title="Abstract">arXiv:2309.16459</a> [<a href="/pdf/2309.16459" title="Download PDF">pdf</a>, <a href="/format/2309.16459" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Augmenting LLMs with Knowledge: A survey on hallucination prevention
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Andriopoulos%2C+K">Konstantinos Andriopoulos</a>, 
<a href="/search/cs?searchtype=author&query=Pouwelse%2C+J">Johan Pouwelse</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Large pre-trained language models have demonstrated their proficiency in
storing factual knowledge within their parameters and achieving remarkable
results when fine-tuned for downstream natural language processing tasks.
Nonetheless, their capacity to access and manipulate knowledge with precision
remains constrained, resulting in performance disparities on
knowledge-intensive tasks when compared to task-specific architectures.
Additionally, the challenges of providing provenance for model decisions and
maintaining up-to-date world knowledge persist as open research frontiers. To
address these limitations, the integration of pre-trained models with
differentiable access mechanisms to explicit non-parametric memory emerges as a
promising solution. This survey delves into the realm of language models (LMs)
augmented with the ability to tap into external knowledge sources, including
external knowledge bases and search engines. While adhering to the standard
objective of predicting missing tokens, these augmented LMs leverage diverse,
possibly non-parametric external modules to augment their contextual processing
capabilities, departing from the conventional language modeling paradigm.
Through an exploration of current advancements in augmenting large language
models with knowledge, this work concludes that this emerging research
direction holds the potential to address prevalent issues in traditional LMs,
such as hallucinations, un-grounded responses, and scalability challenges.
</p>
</div>
</dd>
<dt><a name="item246">[246]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16460" title="Abstract">arXiv:2309.16460</a> [<a href="/pdf/2309.16460" title="Download PDF">pdf</a>, <a href="/format/2309.16460" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Diverse Target and Contribution Scheduling for Domain Generalization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Long%2C+S">Shaocong Long</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Q">Qianyu Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Ying%2C+C">Chenhao Ying</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+L">Lizhuang Ma</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+Y">Yuan Luo</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Generalization under the distribution shift has been a great challenge in
computer vision. The prevailing practice of directly employing the one-hot
labels as the training targets in domain generalization~(DG) can lead to
gradient conflicts, making it insufficient for capturing the intrinsic class
characteristics and hard to increase the intra-class variation. Besides,
existing methods in DG mostly overlook the distinct contributions of source
(seen) domains, resulting in uneven learning from these domains. To address
these issues, we firstly present a theoretical and empirical analysis of the
existence of gradient conflicts in DG, unveiling the previously unexplored
relationship between distribution shifts and gradient conflicts during the
optimization process. In this paper, we present a novel perspective of DG from
the empirical source domain's risk and propose a new paradigm for DG called
Diverse Target and Contribution Scheduling (DTCS). DTCS comprises two
innovative modules: Diverse Target Supervision (DTS) and Diverse Contribution
Balance (DCB), with the aim of addressing the limitations associated with the
common utilization of one-hot labels and equal contributions for source domains
in DG. In specific, DTS employs distinct soft labels as training targets to
account for various feature distributions across domains and thereby mitigates
the gradient conflicts, and DCB dynamically balances the contributions of
source domains by ensuring a fair decline in losses of different source
domains. Extensive experiments with analysis on four benchmark datasets show
that the proposed method achieves a competitive performance in comparison with
the state-of-the-art approaches, demonstrating the effectiveness and advantages
of the proposed DTCS.
</p>
</div>
</dd>
<dt><a name="item247">[247]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16467" title="Abstract">arXiv:2309.16467</a> [<a href="/pdf/2309.16467" title="Download PDF">pdf</a>, <a href="/format/2309.16467" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Compositional Program Generation for Systematic Generalization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Klinger%2C+T">Tim Klinger</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+L">Luke Liu</a>, 
<a href="/search/cs?searchtype=author&query=Dan%2C+S">Soham Dan</a>, 
<a href="/search/cs?searchtype=author&query=Crouse%2C+M">Maxwell Crouse</a>, 
<a href="/search/cs?searchtype=author&query=Ram%2C+P">Parikshit Ram</a>, 
<a href="/search/cs?searchtype=author&query=Gray%2C+A">Alexander Gray</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages of text with 1 page of references
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Compositional generalization is a key ability of humans that enables us to
learn new concepts from only a handful examples. Machine learning models,
including the now ubiquitous transformers, struggle to generalize in this way,
and typically require thousands of examples of a concept during training in
order to generalize meaningfully. This difference in ability between humans and
artificial neural architectures, motivates this study on a neuro-symbolic
architecture called the Compositional Program Generator (CPG). CPG has three
key features: modularity, type abstraction, and recursive composition, that
enable it to generalize both systematically to new concepts in a few-shot
manner, as well as productively by length on various sequence-to-sequence
language tasks. For each input, CPG uses a grammar of the input domain and a
parser to generate a type hierarchy in which each grammar rule is assigned its
own unique semantic module, a probabilistic copy or substitution program.
Instances with the same hierarchy are processed with the same composed program,
while those with different hierarchies may be processed with different
programs. CPG learns parameters for the semantic modules and is able to learn
the semantics for new types incrementally. Given a context-free grammar of the
input language and a dictionary mapping each word in the source language to its
interpretation in the output language, CPG can achieve perfect generalization
on the SCAN and COGS benchmarks, in both standard and extreme few-shot
settings.
</p>
</div>
</dd>
<dt><a name="item248">[248]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16471" title="Abstract">arXiv:2309.16471</a> [<a href="/pdf/2309.16471" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Hadoop-Oriented SVM-LRU (H-SVM-LRU): An Intelligent Cache Replacement  Algorithm to Improve MapReduce Performance
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ghazali%2C+R">Rana Ghazali</a>, 
<a href="/search/cs?searchtype=author&query=Adabi%2C+S">Sahar Adabi</a>, 
<a href="/search/cs?searchtype=author&query=Rezaee%2C+A">Ali Rezaee</a>, 
<a href="/search/cs?searchtype=author&query=Down%2C+D+G">Douglas G.Down</a>, 
<a href="/search/cs?searchtype=author&query=Movaghar%2C+A">Ali Movaghar</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>

</div>
<p class="mathjax">Modern applications can generate a large amount of data from different
sources with high velocity, a combination that is difficult to store and
process via traditional tools. Hadoop is one framework that is used for the
parallel processing of a large amount of data in a distributed environment,
however, various challenges can lead to poor performance. Two particular issues
that can limit performance are the high access time for I/O operations and the
recomputation of intermediate data. The combination of these two issues can
result in resource wastage. In recent years, there have been attempts to
overcome these problems by using caching mechanisms. Due to cache space
limitations, it is crucial to use this space efficiently and avoid cache
pollution (the cache contains data that is not used in the future). We propose
Hadoop-oriented SVM-LRU (HSVM- LRU) to improve Hadoop performance. For this
purpose, we use an intelligent cache replacement algorithm, SVM-LRU, that
combines the well-known LRU mechanism with a machine learning algorithm, SVM,
to classify cached data into two groups based on their future usage.
Experimental results show a significant decrease in execution time as a result
of an increased cache hit ratio, leading to a positive impact on Hadoop
performance.
</p>
</div>
</dd>
<dt><a name="item249">[249]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16483" title="Abstract">arXiv:2309.16483</a> [<a href="/pdf/2309.16483" title="Download PDF">pdf</a>, <a href="/format/2309.16483" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Rethinking Domain Generalization: Discriminability and Generalizability
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Long%2C+S">Shaocong Long</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Q">Qianyu Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Ying%2C+C">Chenhao Ying</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+L">Lizhuang Ma</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+Y">Yuan Luo</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Domain generalization (DG) endeavors to develop robust models that possess
strong generalizability while preserving excellent discriminability.
Nonetheless, pivotal DG techniques tend to improve the feature generalizability
by learning domain-invariant representations, inadvertently overlooking the
feature discriminability. On the one hand, the simultaneous attainment of
generalizability and discriminability of features presents a complex challenge,
often entailing inherent contradictions. This challenge becomes particularly
pronounced when domain-invariant features manifest reduced discriminability
owing to the inclusion of unstable factors, \emph{i.e.,} spurious correlations.
On the other hand, prevailing domain-invariant methods can be categorized as
category-level alignment, susceptible to discarding indispensable features
possessing substantial generalizability and narrowing intra-class variations.
To surmount these obstacles, we rethink DG from a new perspective that
concurrently imbues features with formidable discriminability and robust
generalizability, and present a novel framework, namely, Discriminative
Microscopic Distribution Alignment (DMDA). DMDA incorporates two core
components: Selective Channel Pruning~(SCP) and Micro-level Distribution
Alignment (MDA). Concretely, SCP attempts to curtail redundancy within neural
networks, prioritizing stable attributes conducive to accurate classification.
This approach alleviates the adverse effect of spurious domain invariance and
amplifies the feature discriminability. Besides, MDA accentuates micro-level
alignment within each class, going beyond mere category-level alignment. This
strategy accommodates sufficient generalizable features and facilitates
within-class variations. Extensive experiments on four benchmark datasets
corroborate the efficacy of our method.
</p>
</div>
</dd>
<dt><a name="item250">[250]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16486" title="Abstract">arXiv:2309.16486</a> [<a href="/pdf/2309.16486" title="Download PDF">pdf</a>, <a href="/format/2309.16486" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> HTC-DC Net: Monocular Height Estimation from Single Remote Sensing  Images
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+S">Sining Chen</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+Y">Yilei Shi</a>, 
<a href="/search/cs?searchtype=author&query=Xiong%2C+Z">Zhitong Xiong</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+X+X">Xiao Xiang Zhu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 18 pages, 10 figures, submitted to IEEE Transactions on Geoscience and Remote Sensing
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">3D geo-information is of great significance for understanding the living
environment; however, 3D perception from remote sensing data, especially on a
large scale, is restricted. To tackle this problem, we propose a method for
monocular height estimation from optical imagery, which is currently one of the
richest sources of remote sensing data. As an ill-posed problem, monocular
height estimation requires well-designed networks for enhanced representations
to improve performance. Moreover, the distribution of height values is
long-tailed with the low-height pixels, e.g., the background, as the head, and
thus trained networks are usually biased and tend to underestimate building
heights. To solve the problems, instead of formalizing the problem as a
regression task, we propose HTC-DC Net following the classification-regression
paradigm, with the head-tail cut (HTC) and the distribution-based constraints
(DCs) as the main contributions. HTC-DC Net is composed of the backbone network
as the feature extractor, the HTC-AdaBins module, and the hybrid regression
process. The HTC-AdaBins module serves as the classification phase to determine
bins adaptive to each input image. It is equipped with a vision transformer
encoder to incorporate local context with holistic information and involves an
HTC to address the long-tailed problem in monocular height estimation for
balancing the performances of foreground and background pixels. The hybrid
regression process does the regression via the smoothing of bins from the
classification phase, which is trained via DCs. The proposed network is tested
on three datasets of different resolutions, namely ISPRS Vaihingen (0.09 m),
DFC19 (1.3 m) and GBH (3 m). Experimental results show the superiority of the
proposed network over existing methods by large margins. Extensive ablation
studies demonstrate the effectiveness of each design component.
</p>
</div>
</dd>
<dt><a name="item251">[251]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16487" title="Abstract">arXiv:2309.16487</a> [<a href="/pdf/2309.16487" title="Download PDF">pdf</a>, <a href="/format/2309.16487" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Poisoning Fair Representations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+T">Tianci Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Haoyu Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+F">Feijie Wu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Hengtong Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+P">Pan Li</a>, 
<a href="/search/cs?searchtype=author&query=Su%2C+L">Lu Su</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+J">Jing Gao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Fair machine learning seeks to mitigate model prediction bias against certain
demographic subgroups such as elder and female. Recently, fair representation
learning (FRL) trained by deep neural networks has demonstrated superior
performance, whereby representations containing no demographic information are
inferred from the data and then used as the input to classification or other
downstream tasks. Despite the development of FRL methods, their vulnerability
under data poisoning attack, a popular protocol to benchmark model robustness
under adversarial scenarios, is under-explored. Data poisoning attacks have
been developed for classical fair machine learning methods which incorporate
fairness constraints into shallow-model classifiers. Nonetheless, these attacks
fall short in FRL due to notably different fairness goals and model
architectures. This work proposes the first data poisoning framework attacking
FRL. We induce the model to output unfair representations that contain as much
demographic information as possible by injecting carefully crafted poisoning
samples into the training data. This attack entails a prohibitive bilevel
optimization, wherefore an effective approximated solution is proposed. A
theoretical analysis on the needed number of poisoning samples is derived and
sheds light on defending against the attack. Experiments on benchmark fairness
datasets and state-of-the-art fair representation learning models demonstrate
the superiority of our attack.
</p>
</div>
</dd>
<dt><a name="item252">[252]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16490" title="Abstract">arXiv:2309.16490</a> [<a href="/pdf/2309.16490" title="Download PDF">pdf</a>, <a href="/format/2309.16490" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Active SLAM Utility Function Exploiting Path Entropy
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ahmed%2C+M+F">Muhammad Farhan Ahmed</a>, 
<a href="/search/cs?searchtype=author&query=Fr%C3%A9mont%2C+V">Vincent Fr&#xe9;mont</a>, 
<a href="/search/cs?searchtype=author&query=Fantoni%2C+I">Isabelle Fantoni</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, 8 figures, Submitted to IEEE SOLI Conference. arXiv admin note: text overlap with <a href="/abs/2212.11654">arXiv:2212.11654</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">In this article we present a utility function for Active SLAM (A-SLAM) which
utilizes map entropy along with D-Optimality criterion metrices for weighting
goal frontier candidates. We propose a utility function for frontier goal
selection that exploits the occupancy grid map by utilizing the path entropy
and favors unknown map locations for maximum area coverage while maintaining a
low localization and mapping uncertainties. We quantify the efficiency of our
method using various graph connectivity matrices and map efficiency indexes for
an environment exploration task. Using simulation and experimental results
against similar approaches we achieve an average of 32\% more coverage using
publicly available data sets.
</p>
</div>
</dd>
<dt><a name="item253">[253]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16493" title="Abstract">arXiv:2309.16493</a> [<a href="/pdf/2309.16493" title="Download PDF">pdf</a>, <a href="/format/2309.16493" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Efficient Hardware Implementation of Constant Time Sampling for HQC
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sch%C3%B6ffel%2C+M">Maximilian Sch&#xf6;ffel</a>, 
<a href="/search/cs?searchtype=author&query=Feldmann%2C+J">Johannes Feldmann</a>, 
<a href="/search/cs?searchtype=author&query=Wehn%2C+N">Norbert Wehn</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">HQC is one of the code-based finalists in the last round of the NIST post
quantum cryptography standardization process. In this process, security and
implementation efficiency are key metrics for the selection of the candidates.
A critical compute kernel with respect to efficient hardware implementations
and security in HQC is the sampling method used to derive random numbers. Due
to its security criticality, recently an updated sampling algorithm was
presented to increase its robustness against side-channel attacks.
<br />In this paper, we pursue a cross layer approach to optimize this new sampling
algorithm to enable an efficient hardware implementation without comprising the
original algorithmic security and side-channel attack robustness.
<br />We compare our cross layer based implementation to a direct hardware
implementation of the original algorithm and to optimized implementations of
the previous sampler version. All implementations are evaluated using the
Xilinx Artix 7 FPGA. Our results show that our approach reduces the latency by
a factor of 24 compared to the original algorithm and by a factor of 28
compared to the previously used sampler with significantly less resources.
</p>
</div>
</dd>
<dt><a name="item254">[254]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16494" title="Abstract">arXiv:2309.16494</a> [<a href="/pdf/2309.16494" title="Download PDF">pdf</a>, <a href="/format/2309.16494" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Accurate and lightweight dehazing via multi-receptive-field non-local  network and novel contrastive regularization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=He%2C+Z">Zewei He</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Z">Zixuan Chen</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+Z">Ziqian Lu</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+X">Xuecheng Sun</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+Z">Zhe-Ming Lu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> submitted to IEEE TCYB for possible publication
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Recently, deep learning-based methods have dominated image dehazing domain.
Although very competitive dehazing performance has been achieved with
sophisticated models, effective solutions for extracting useful features are
still under-explored. In addition, non-local network, which has made a
breakthrough in many vision tasks, has not been appropriately applied to image
dehazing. Thus, a multi-receptive-field non-local network (MRFNLN) consisting
of the multi-stream feature attention block (MSFAB) and cross non-local block
(CNLB) is presented in this paper. We start with extracting richer features for
dehazing. Specifically, we design a multi-stream feature extraction (MSFE)
sub-block, which contains three parallel convolutions with different receptive
fields (i.e., $1\times 1$, $3\times 3$, $5\times 5$) for extracting multi-scale
features. Following MSFE, we employ an attention sub-block to make the model
adaptively focus on important channels/regions. The MSFE and attention
sub-blocks constitute our MSFAB. Then, we design a cross non-local block
(CNLB), which can capture long-range dependencies beyond the query. Instead of
the same input source of query branch, the key and value branches are enhanced
by fusing more preceding features. CNLB is computation-friendly by leveraging a
spatial pyramid down-sampling (SPDS) strategy to reduce the computation and
memory consumption without sacrificing the performance. Last but not least, a
novel detail-focused contrastive regularization (DFCR) is presented by
emphasizing the low-level details and ignoring the high-level semantic
information in the representation space. Comprehensive experimental results
demonstrate that the proposed MRFNLN model outperforms recent state-of-the-art
dehazing methods with less than 1.5 Million parameters.
</p>
</div>
</dd>
<dt><a name="item255">[255]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16495" title="Abstract">arXiv:2309.16495</a> [<a href="/pdf/2309.16495" title="Download PDF">pdf</a>, <a href="/format/2309.16495" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deep Single Models vs. Ensembles: Insights for a Fast Deployment of  Parking Monitoring Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hochuli%2C+A+G">Andre Gustavo Hochuli</a>, 
<a href="/search/cs?searchtype=author&query=Barddal%2C+J+P">Jean Paul Barddal</a>, 
<a href="/search/cs?searchtype=author&query=Palhano%2C+G+C">Gillian Cezar Palhano</a>, 
<a href="/search/cs?searchtype=author&query=Mendes%2C+L+M">Leonardo Matheus Mendes</a>, 
<a href="/search/cs?searchtype=author&query=de+Almeida%2C+P+R+L">Paulo Ricardo Lisboa de Almeida</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> An improved version of this manuscript was submitted to IEEE ICMLA 2023 (Dec/23)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Searching for available parking spots in high-density urban centers is a
stressful task for drivers that can be mitigated by systems that know in
advance the nearest parking space available.
<br />To this end, image-based systems offer cost advantages over other
sensor-based alternatives (e.g., ultrasonic sensors), requiring less physical
infrastructure for installation and maintenance.
<br />Despite recent deep learning advances, deploying intelligent parking
monitoring is still a challenge since most approaches involve collecting and
labeling large amounts of data, which is laborious and time-consuming. Our
study aims to uncover the challenges in creating a global framework, trained
using publicly available labeled parking lot images, that performs accurately
across diverse scenarios, enabling the parking space monitoring as a
ready-to-use system to deploy in a new environment. Through exhaustive
experiments involving different datasets and deep learning architectures,
including fusion strategies and ensemble methods, we found that models trained
on diverse datasets can achieve 95\% accuracy without the burden of data
annotation and model training on the target parking lot
</p>
</div>
</dd>
<dt><a name="item256">[256]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16496" title="Abstract">arXiv:2309.16496</a> [<a href="/pdf/2309.16496" title="Download PDF">pdf</a>, <a href="/format/2309.16496" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CCEdit: Creative and Controllable Video Editing via Diffusion Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Feng%2C+R">Ruoyu Feng</a>, 
<a href="/search/cs?searchtype=author&query=Weng%2C+W">Wenming Weng</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yanhui Wang</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+Y">Yuhui Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Bao%2C+J">Jianmin Bao</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+C">Chong Luo</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Z">Zhibo Chen</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+B">Baining Guo</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">In this work, we present CCEdit, a versatile framework designed to address
the challenges of creative and controllable video editing. CCEdit accommodates
a wide spectrum of user editing requirements and enables enhanced creative
control through an innovative approach that decouples video structure and
appearance. We leverage the foundational ControlNet architecture to preserve
structural integrity, while seamlessly integrating adaptable temporal modules
compatible with state-of-the-art personalization techniques for text-to-image
generation, such as DreamBooth and LoRA.Furthermore, we introduce
reference-conditioned video editing, empowering users to exercise precise
creative control over video editing through the more manageable process of
editing key frames. Our extensive experimental evaluations confirm the
exceptional functionality and editing capabilities of the proposed CCEdit
framework. Demo video is available at
https://www.youtube.com/watch?v=UQw4jq-igN4.
</p>
</div>
</dd>
<dt><a name="item257">[257]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16499" title="Abstract">arXiv:2309.16499</a> [<a href="/pdf/2309.16499" title="Download PDF">pdf</a>, <a href="/format/2309.16499" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Cross-City Matters: A Multimodal Remote Sensing Benchmark Dataset for  Cross-City Semantic Segmentation using High-Resolution Domain Adaptation  Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hong%2C+D">Danfeng Hong</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+B">Bing Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Hao Li</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yuxuan Li</a>, 
<a href="/search/cs?searchtype=author&query=Yao%2C+J">Jing Yao</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+C">Chenyu Li</a>, 
<a href="/search/cs?searchtype=author&query=Werner%2C+M">Martin Werner</a>, 
<a href="/search/cs?searchtype=author&query=Chanussote%2C+J">Jocelyn Chanussote</a>, 
<a href="/search/cs?searchtype=author&query=Zipf%2C+A">Alexander Zipf</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+X+X">Xiao Xiang Zhu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Image and Video Processing (eess.IV)

</div>
<p class="mathjax">Artificial intelligence (AI) approaches nowadays have gained remarkable
success in single-modality-dominated remote sensing (RS) applications,
especially with an emphasis on individual urban environments (e.g., single
cities or regions). Yet these AI models tend to meet the performance bottleneck
in the case studies across cities or regions, due to the lack of diverse RS
information and cutting-edge solutions with high generalization ability. To
this end, we build a new set of multimodal remote sensing benchmark datasets
(including hyperspectral, multispectral, SAR) for the study purpose of the
cross-city semantic segmentation task (called C2Seg dataset), which consists of
two cross-city scenes, i.e., Berlin-Augsburg (in Germany) and Beijing-Wuhan (in
China). Beyond the single city, we propose a high-resolution domain adaptation
network, HighDAN for short, to promote the AI model's generalization ability
from the multi-city environments. HighDAN is capable of retaining the spatially
topological structure of the studied urban scene well in a parallel high-to-low
resolution fusion fashion but also closing the gap derived from enormous
differences of RS image representations between different cities by means of
adversarial learning. In addition, the Dice loss is considered in HighDAN to
alleviate the class imbalance issue caused by factors across cities. Extensive
experiments conducted on the C2Seg dataset show the superiority of our HighDAN
in terms of segmentation performance and generalization ability, compared to
state-of-the-art competitors. The C2Seg dataset and the semantic segmentation
toolbox (involving the proposed HighDAN) will be available publicly at
https://github.com/danfenghong.
</p>
</div>
</dd>
<dt><a name="item258">[258]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16500" title="Abstract">arXiv:2309.16500</a> [<a href="/pdf/2309.16500" title="Download PDF">pdf</a>, <a href="/format/2309.16500" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Capturing Requirements for a Data Annotation Tool for Intensive Care:  Experimental User-Centered Design Study
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wac%2C+M">Marceli Wac</a>, 
<a href="/search/cs?searchtype=author&query=Santos-Rodriguez%2C+R">Raul Santos-Rodriguez</a>, 
<a href="/search/cs?searchtype=author&query=McWilliams%2C+C">Chris McWilliams</a>, 
<a href="/search/cs?searchtype=author&query=Bourdeaux%2C+C">Christopher Bourdeaux</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">Intensive care units (ICUs) are complex and data-rich environments. Data
routinely collected in the ICUs provides tremendous opportunities for machine
learning, but their use comes with significant challenges. Complex problems may
require additional input from humans which can be provided through a process of
data annotation. Annotation is a complex, time-consuming process that requires
domain expertise and technical proficiency. Existing data annotation tools fail
to provide an effective solution to this problem. In this study, we
investigated clinicians' approach to the annotation task. We focused on
establishing the characteristics of the annotation process in the context of
clinical data and identifying differences in the annotation workflow between
different staff roles. The overall goal was to elicit requirements for a
software tool that could facilitate an effective and time-efficient data
annotation. We conducted an experiment involving clinicians from the ICUs
annotating printed sheets of data. The participants were observed during the
task and their actions were analysed in the context of Norman's Interaction
Cycle to establish the requirements for the digital tool. The annotation
process followed a constant loop of annotation and evaluation, during which
participants incrementally analysed and annotated the data. No distinguishable
differences were identified between how different staff roles annotate data. We
observed preferences towards different methods for applying annotation which
varied between different participants and admissions. We established 11
requirements for the digital data annotation tool for the healthcare setting.
We conducted a manual data annotation activity to establish the requirements
for a digital data annotation tool, characterised the clinicians' approach to
annotation and elicited 11 key requirements for effective data annotation
software.
</p>
</div>
</dd>
<dt><a name="item259">[259]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16507" title="Abstract">arXiv:2309.16507</a> [<a href="/pdf/2309.16507" title="Download PDF">pdf</a>, <a href="/format/2309.16507" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Innovation Modeling Grid
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Klemp%2C+O">Oliver Klemp</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ~170p, many figures, technical document
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>; Software Engineering (cs.SE)

</div>
<p class="mathjax">This technical document presents the committee driven innovation modeling
methodology "Innovation Modeling Grid" in detail. This document is the
successor of three publications on IMoG and focuses on presenting all details
of the methodology
</p>
</div>
</dd>
<dt><a name="item260">[260]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16509" title="Abstract">arXiv:2309.16509</a> [<a href="/pdf/2309.16509" title="Download PDF">pdf</a>, <a href="/format/2309.16509" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SIMD Everywhere Optimization from ARM NEON to RISC-V Vector Extensions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Ju-Hung Li</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+J">Jhih-Kuan Lin</a>, 
<a href="/search/cs?searchtype=author&query=Su%2C+Y">Yung-Cheng Su</a>, 
<a href="/search/cs?searchtype=author&query=Chu%2C+C">Chi-Wei Chu</a>, 
<a href="/search/cs?searchtype=author&query=Kuok%2C+L">Lai-Tak Kuok</a>, 
<a href="/search/cs?searchtype=author&query=Lai%2C+H">Hung-Ming Lai</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+C">Chao-Lin Lee</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+J">Jenq-Kuen Lee</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>; Programming Languages (cs.PL)

</div>
<p class="mathjax">Many libraries, such as OpenCV, FFmpeg, XNNPACK, and Eigen, utilize Arm or
x86 SIMD Intrinsics to optimize programs for performance. With the emergence of
RISC-V Vector Extensions (RVV), there is a need to migrate these performance
legacy codes for RVV. Currently, the migration of NEON code to RVV code
requires manual rewriting, which is a time-consuming and error-prone process.
In this work, we use the open source tool, "SIMD Everywhere" (SIMDe), to
automate the migration. Our primary task is to enhance SIMDe to enable the
conversion of ARM NEON Intrinsics types and functions to their corresponding
RVV Intrinsics types and functions. For type conversion, we devise strategies
to convert Neon Intrinsics types to RVV Intrinsics by considering the vector
length agnostic (vla) architectures. With function conversions, we analyze
commonly used conversion methods in SIMDe and develop customized conversions
for each function based on the results of RVV code generations. In our
experiments with Google XNNPACK library, our enhanced SIMDe achieves speedup
ranging from 1.51x to 5.13x compared to the original SIMDe, which does not
utilize customized RVV implementations for the conversions.
</p>
</div>
</dd>
<dt><a name="item261">[261]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16511" title="Abstract">arXiv:2309.16511</a> [<a href="/pdf/2309.16511" title="Download PDF">pdf</a>, <a href="/format/2309.16511" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Toloka Visual Question Answering Benchmark
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ustalov%2C+D">Dmitry Ustalov</a>, 
<a href="/search/cs?searchtype=author&query=Pavlichenko%2C+N">Nikita Pavlichenko</a>, 
<a href="/search/cs?searchtype=author&query=Koshelev%2C+S">Sergey Koshelev</a>, 
<a href="/search/cs?searchtype=author&query=Likhobaba%2C+D">Daniil Likhobaba</a>, 
<a href="/search/cs?searchtype=author&query=Smirnova%2C+A">Alisa Smirnova</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 pages; see <a href="https://toloka.ai/challenges/wsdm2023/">this https URL</a> for more details
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Human-Computer Interaction (cs.HC)

</div>
<p class="mathjax">In this paper, we present Toloka Visual Question Answering, a new
crowdsourced dataset allowing comparing performance of machine learning systems
against human level of expertise in the grounding visual question answering
task. In this task, given an image and a textual question, one has to draw the
bounding box around the object correctly responding to that question. Every
image-question pair contains the response, with only one correct response per
image. Our dataset contains 45,199 pairs of images and questions in English,
provided with ground truth bounding boxes, split into train and two test
subsets. Besides describing the dataset and releasing it under a CC BY license,
we conducted a series of experiments on open source zero-shot baseline models
and organized a multi-phase competition at WSDM Cup that attracted 48
participants worldwide. However, by the time of paper submission, no machine
learning model outperformed the non-expert crowdsourcing baseline according to
the intersection over union evaluation score.
</p>
</div>
</dd>
<dt><a name="item262">[262]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16512" title="Abstract">arXiv:2309.16512</a> [<a href="/pdf/2309.16512" title="Download PDF">pdf</a>, <a href="/format/2309.16512" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> From Complexity to Clarity: Analytical Expressions of Deep Neural  Network Weights via Clifford&#x27;s Geometric Algebra and Convexity
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pilanci%2C+M">Mert Pilanci</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Neural and Evolutionary Computing (cs.NE); Optimization and Control (math.OC); Machine Learning (stat.ML)

</div>
<p class="mathjax">In this paper, we introduce a novel analysis of neural networks based on
geometric (Clifford) algebra and convex optimization. We show that optimal
weights of deep ReLU neural networks are given by the wedge product of training
samples when trained with standard regularized loss. Furthermore, the training
problem reduces to convex optimization over wedge product features, which
encode the geometric structure of the training dataset. This structure is given
in terms of signed volumes of triangles and parallelotopes generated by data
vectors. The convex problem finds a small subset of samples via $\ell_1$
regularization to discover only relevant wedge product features. Our analysis
provides a novel perspective on the inner workings of deep neural networks and
sheds light on the role of the hidden layers.
</p>
</div>
</dd>
<dt><a name="item263">[263]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16515" title="Abstract">arXiv:2309.16515</a> [<a href="/pdf/2309.16515" title="Download PDF">pdf</a>, <a href="/format/2309.16515" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Latent Noise Segmentation: How Neural Noise Leads to the Emergence of  Segmentation and Grouping
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lonnqvist%2C+B">Ben Lonnqvist</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Z">Zhengqing Wu</a>, 
<a href="/search/cs?searchtype=author&query=Herzog%2C+M+H">Michael H. Herzog</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Deep Neural Networks (DNNs) that achieve human-level performance in general
tasks like object segmentation typically require supervised labels. In
contrast, humans are able to perform these tasks effortlessly without
supervision. To accomplish this, the human visual system makes use of
perceptual grouping. Understanding how perceptual grouping arises in an
unsupervised manner is critical for improving both models of the visual system,
and computer vision models. In this work, we propose a counterintuitive
approach to unsupervised perceptual grouping and segmentation: that they arise
because of neural noise, rather than in spite of it. We (1) mathematically
demonstrate that under realistic assumptions, neural noise can be used to
separate objects from each other, and (2) show that adding noise in a DNN
enables the network to segment images even though it was never trained on any
segmentation labels. Interestingly, we find that (3) segmenting objects using
noise results in segmentation performance that aligns with the perceptual
grouping phenomena observed in humans. We introduce the Good Gestalt (GG)
datasets -- six datasets designed to specifically test perceptual grouping, and
show that our DNN models reproduce many important phenomena in human
perception, such as illusory contours, closure, continuity, proximity, and
occlusion. Finally, we (4) demonstrate the ecological plausibility of the
method by analyzing the sensitivity of the DNN to different magnitudes of
noise. We find that some model variants consistently succeed with remarkably
low levels of neural noise ($\sigma&lt;0.001$), and surprisingly, that segmenting
this way requires as few as a handful of samples. Together, our results suggest
a novel unsupervised segmentation method requiring few assumptions, a new
explanation for the formation of perceptual grouping, and a potential benefit
of neural noise in the visual system.
</p>
</div>
</dd>
<dt><a name="item264">[264]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16519" title="Abstract">arXiv:2309.16519</a> [<a href="/pdf/2309.16519" title="Download PDF">pdf</a>, <a href="/format/2309.16519" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AtomSurf : Surface Representation for Learning on Protein Structures
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mallet%2C+V">Vincent Mallet</a>, 
<a href="/search/cs?searchtype=author&query=Attaiki%2C+S">Souhaib Attaiki</a>, 
<a href="/search/cs?searchtype=author&query=Ovsjanikov%2C+M">Maks Ovsjanikov</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Biomolecules (q-bio.BM)

</div>
<p class="mathjax">Recent advancements in Cryo-EM and protein structure prediction algorithms
have made large-scale protein structures accessible, paving the way for machine
learning-based functional annotations.The field of geometric deep learning
focuses on creating methods working on geometric data. An essential aspect of
learning from protein structures is representing these structures as a
geometric object (be it a grid, graph, or surface) and applying a learning
method tailored to this representation. The performance of a given approach
will then depend on both the representation and its corresponding learning
method.
<br />In this paper, we investigate representing proteins as $\textit{3D mesh
surfaces}$ and incorporate them into an established representation benchmark.
Our first finding is that despite promising preliminary results, the surface
representation alone does not seem competitive with 3D grids. Building on this,
we introduce a synergistic approach, combining surface representations with
graph-based methods, resulting in a general framework that incorporates both
representations in learning. We show that using this combination, we are able
to obtain state-of-the-art results across $\textit{all tested tasks}$. Our code
and data can be found online: https://github.com/Vincentx15/atom2D .
</p>
</div>
</dd>
<dt><a name="item265">[265]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16520" title="Abstract">arXiv:2309.16520</a> [<a href="/pdf/2309.16520" title="Download PDF">pdf</a>, <a href="/format/2309.16520" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SwiftSpatial: Spatial Joins on Modern Hardware
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jiang%2C+W">Wenqi Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Parvanov%2C+M">Martin Parvanov</a>, 
<a href="/search/cs?searchtype=author&query=Alonso%2C+G">Gustavo Alonso</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Databases (cs.DB)</span>; Hardware Architecture (cs.AR)

</div>
<p class="mathjax">Spatial joins are among the most time-consuming queries in spatial data
management systems. In this paper, we propose SwiftSpatial, a specialized
accelerator architecture tailored for spatial joins. SwiftSpatial contains
multiple high-performance join units with innovative hybrid parallelism,
several efficient memory management units, and an integrated on-chip join
scheduler. We prototype SwiftSpatial on an FPGA and incorporate the R-tree
synchronous traversal algorithm as the control flow. Benchmarked against
various CPU and GPU-based spatial data processing systems, SwiftSpatial
demonstrates a latency reduction of up to 5.36x relative to the best-performing
baseline, while requiring 6.16x less power. The remarkable performance and
energy efficiency of SwiftSpatial lay a solid foundation for its future
integration into spatial data management systems, both in data centers and at
the edge.
</p>
</div>
</dd>
<dt><a name="item266">[266]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16524" title="Abstract">arXiv:2309.16524</a> [<a href="/pdf/2309.16524" title="Download PDF">pdf</a>, <a href="/format/2309.16524" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> HOI4ABOT: Human-Object Interaction Anticipation for Human Intention  Reading Collaborative roBOTs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mascaro%2C+E+V">Esteve Valls Mascaro</a>, 
<a href="/search/cs?searchtype=author&query=Sliwowski%2C+D">Daniel Sliwowski</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+D">Dongheui Lee</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Proceedings in Conference on Robot Learning 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Robotics (cs.RO)

</div>
<p class="mathjax">Robots are becoming increasingly integrated into our lives, assisting us in
various tasks. To ensure effective collaboration between humans and robots, it
is essential that they understand our intentions and anticipate our actions. In
this paper, we propose a Human-Object Interaction (HOI) anticipation framework
for collaborative robots. We propose an efficient and robust transformer-based
model to detect and anticipate HOIs from videos. This enhanced anticipation
empowers robots to proactively assist humans, resulting in more efficient and
intuitive collaborations. Our model outperforms state-of-the-art results in HOI
detection and anticipation in VidHOI dataset with an increase of 1.76% and
1.04% in mAP respectively while being 15.4 times faster. We showcase the
effectiveness of our approach through experimental results in a real robot,
demonstrating that the robot's ability to anticipate HOIs is key for better
Human-Robot Interaction. More information can be found on our project webpage:
https://evm7.github.io/HOI4ABOT_page/
</p>
</div>
</dd>
<dt><a name="item267">[267]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16527" title="Abstract">arXiv:2309.16527</a> [<a href="/pdf/2309.16527" title="Download PDF">pdf</a>, <a href="/ps/2309.16527" title="Download PostScript">ps</a>, <a href="/format/2309.16527" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Structural Risk Minimization for Learning Nonlinear Dynamics
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Stamouli%2C+C">Charis Stamouli</a>, 
<a href="/search/eess?searchtype=author&query=Chatzipantazis%2C+E">Evangelos Chatzipantazis</a>, 
<a href="/search/eess?searchtype=author&query=Pappas%2C+G+J">George J. Pappas</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">Recent advances in learning or identification of nonlinear dynamics focus on
learning a suitable model within a pre-specified model class. However, a key
difficulty that remains is the choice of the model class from which the
dynamics will be learned. The fundamental challenge is trading the richness of
the model class with the learnability within the model class. Toward addressing
the so-called model selection problem, we introduce a novel notion of
Structural Risk Minimization (SRM) for learning nonlinear dynamics. Inspired by
classical SRM for classification, we minimize a bound on the true prediction
error over hierarchies of model classes. The class selected by our SRM scheme
is shown to achieve a nearly optimal learning guarantee among all model classes
contained in the hierarchy. Employing the proposed scheme along with computable
model class complexity bounds, we derive explicit SRM schemes for learning
nonlinear dynamics under hierarchies of: i) norm-constrained Reproducing Kernel
Hilbert Spaces, and ii) norm-constrained Neural Network classes. We empirically
show that even though too loose to be used as absolute estimates, our SRM
bounds on the true prediction error are able to track its relative behavior
across different model classes of the hierarchy.
</p>
</div>
</dd>
<dt><a name="item268">[268]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16533" title="Abstract">arXiv:2309.16533</a> [<a href="/pdf/2309.16533" title="Download PDF">pdf</a>, <a href="/format/2309.16533" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Further results on the Hunters and Rabbit game through monotonicity
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dissaux%2C+T">Thomas Dissaux</a>, 
<a href="/search/cs?searchtype=author&query=Fioravantes%2C+F">Foivos Fioravantes</a>, 
<a href="/search/cs?searchtype=author&query=Gahlawat%2C+H">Harmender Gahlawat</a>, 
<a href="/search/cs?searchtype=author&query=Nisse%2C+N">Nicolas Nisse</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> A preliminary version appeared in MFCS 2023. Abstract shortened due to Arxiv submission requirements
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Discrete Mathematics (cs.DM)</span>; Combinatorics (math.CO)

</div>
<p class="mathjax">Hunters and Rabbit game is played on a graph $G$ where the Hunter player
shoots at $k$ vertices in every round while the Rabbit player occupies an
unknown vertex and, if not shot, must move to a neighbouring vertex after each
round. The Rabbit player wins if it can ensure that its position is never shot.
The Hunter player wins otherwise. The hunter number $h(G)$ of a graph $G$ is
the minimum integer $k$ such that the Hunter player has a winning strategy
(i.e., allowing him to win whatever be the strategy of the Rabbit player). This
game has been studied in several graph classes, in particular in bipartite
graphs (grids, trees, hypercubes...), but the computational complexity of
computing $h(G)$ remains open in general graphs and even in trees. To progress
further, we propose a notion of monotonicity for the Hunters and Rabbit game
imposing that, roughly, a vertex that has already been shot ``must not host the
rabbit anymore''. This allows us to obtain new results in various graph
classes.
<br />Let the monotone hunter number be denoted by $mh(G)$. We show that $pw(G)
\leq mh(G) \leq pw(G)+1$ for any graph $G$ with pathwidth $pw(G)$, implying
that computing $mh(G)$, or even approximating $mh(G)$ up to an additive
constant, is NP-hard. Then, we show that $mh(G)$ can be computed in polynomial
time in split graphs, interval graphs, cographs and trees. These results go
through structural characterisations which allow us to relate the monotone
hunter number with the pathwidth in some of these graph classes. In all cases,
this allows us to specify the hunter number or to show that there may be an
arbitrary gap between $h$ and $mh$, i.e., that monotonicity does not help. In
particular, we show that, for every $k\geq 3$, there exists a tree $T$ with
$h(T)=2$ and $mh(T)=k$. We conclude by proving that computing $h$ (resp., $mh$)
is FPT parameterised by the minimum size of a vertex cover.
</p>
</div>
</dd>
<dt><a name="item269">[269]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16534" title="Abstract">arXiv:2309.16534</a> [<a href="/pdf/2309.16534" title="Download PDF">pdf</a>, <a href="/format/2309.16534" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MotionLM: Multi-Agent Motion Forecasting as Language Modeling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Seff%2C+A">Ari Seff</a>, 
<a href="/search/cs?searchtype=author&query=Cera%2C+B">Brian Cera</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+D">Dian Chen</a>, 
<a href="/search/cs?searchtype=author&query=Ng%2C+M">Mason Ng</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+A">Aurick Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Nayakanti%2C+N">Nigamaa Nayakanti</a>, 
<a href="/search/cs?searchtype=author&query=Refaat%2C+K+S">Khaled S. Refaat</a>, 
<a href="/search/cs?searchtype=author&query=Al-Rfou%2C+R">Rami Al-Rfou</a>, 
<a href="/search/cs?searchtype=author&query=Sapp%2C+B">Benjamin Sapp</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To appear at the International Conference on Computer Vision (ICCV) 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Robotics (cs.RO)

</div>
<p class="mathjax">Reliable forecasting of the future behavior of road agents is a critical
component to safe planning in autonomous vehicles. Here, we represent
continuous trajectories as sequences of discrete motion tokens and cast
multi-agent motion prediction as a language modeling task over this domain. Our
model, MotionLM, provides several advantages: First, it does not require
anchors or explicit latent variable optimization to learn multimodal
distributions. Instead, we leverage a single standard language modeling
objective, maximizing the average log probability over sequence tokens. Second,
our approach bypasses post-hoc interaction heuristics where individual agent
trajectory generation is conducted prior to interactive scoring. Instead,
MotionLM produces joint distributions over interactive agent futures in a
single autoregressive decoding process. In addition, the model's sequential
factorization enables temporally causal conditional rollouts. The proposed
approach establishes new state-of-the-art performance for multi-agent motion
prediction on the Waymo Open Motion Dataset, ranking 1st on the interactive
challenge leaderboard.
</p>
</div>
</dd>
<dt><a name="item270">[270]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16535" title="Abstract">arXiv:2309.16535</a> [<a href="/pdf/2309.16535" title="Download PDF">pdf</a>, <a href="/format/2309.16535" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> KLoB: a Benchmark for Assessing Knowledge Locating Methods in Language  Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ju%2C+Y">Yiming Ju</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zheng Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Recently, Locate-Then-Edit paradigm has emerged as one of the main approaches
in changing factual knowledge stored in the Language models. However, there is
a lack of research on whether present locating methods can pinpoint the exact
parameters embedding the desired knowledge. Moreover, although many researchers
have questioned the validity of locality hypothesis of factual knowledge, no
method is provided to test the a hypothesis for more in-depth discussion and
research. Therefore, we introduce KLoB, a benchmark examining three essential
properties that a reliable knowledge locating method should satisfy. KLoB can
serve as a benchmark for evaluating existing locating methods in language
models, and can contributes a method to reassessing the validity of locality
hypothesis of factual knowledge. Our is publicly available at
\url{https://github.com/juyiming/KLoB}.
</p>
</div>
</dd>
<dt><a name="item271">[271]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16540" title="Abstract">arXiv:2309.16540</a> [<a href="/pdf/2309.16540" title="Download PDF">pdf</a>, <a href="/format/2309.16540" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Unsupervised Fact Verification by Language Model Distillation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bazaga%2C+A">Adri&#xe1;n Bazaga</a>, 
<a href="/search/cs?searchtype=author&query=Li%C3%B2%2C+P">Pietro Li&#xf2;</a>, 
<a href="/search/cs?searchtype=author&query=Micklem%2C+G">Gos Micklem</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Machine Learning (cs.LG); Machine Learning (stat.ML)

</div>
<p class="mathjax">Unsupervised fact verification aims to verify a claim using evidence from a
trustworthy knowledge base without any kind of data annotation. To address this
challenge, algorithms must produce features for every claim that are both
semantically meaningful, and compact enough to find a semantic alignment with
the source information. In contrast to previous work, which tackled the
alignment problem by learning over annotated corpora of claims and their
corresponding labels, we propose SFAVEL (Self-supervised Fact Verification via
Language Model Distillation), a novel unsupervised framework that leverages
pre-trained language models to distil self-supervised features into
high-quality claim-fact alignments without the need for annotations. This is
enabled by a novel contrastive loss function that encourages features to attain
high-quality claim and evidence alignments whilst preserving the semantic
relationships across the corpora. Notably, we present results that achieve a
new state-of-the-art on the standard FEVER fact verification benchmark (+8%
accuracy) with linear evaluation.
</p>
</div>
</dd>
<dt><a name="item272">[272]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16544" title="Abstract">arXiv:2309.16544</a> [<a href="/pdf/2309.16544" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The DEVStone Metric: Performance Analysis of DEVS Simulation Engines
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=C%C3%A1rdenas%2C+R">Rom&#xe1;n C&#xe1;rdenas</a>, 
<a href="/search/cs?searchtype=author&query=Henares%2C+K">Kevin Henares</a>, 
<a href="/search/cs?searchtype=author&query=Arroba%2C+P">Patricia Arroba</a>, 
<a href="/search/cs?searchtype=author&query=Risco-Mart%C3%ADn%2C+J+L">Jos&#xe9; L. Risco-Mart&#xed;n</a>, 
<a href="/search/cs?searchtype=author&query=Wainer%2C+G+A">Gabriel A. Wainer</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> ACM Transactions on Modeling and Computer Simulation, 32(3), pp.
  1-20, 2022
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>; Performance (cs.PF)

</div>
<p class="mathjax">The DEVStone benchmark allows us to evaluate the performance of
discrete-event simulators based on the DEVS formalism. It provides model sets
with different characteristics, enabling the analysis of specific issues of
simulation engines. However, this heterogeneity hinders the comparison of the
results among studies, as the results obtained on each research work depend on
the chosen subset of DEVStone models. We define the DEVStone metric based on
the DEVStone synthetic benchmark and provide a mechanism for specifying
objective ratings for DEVS-based simulators. This metric corresponds to the
average number of times that a simulator can execute a selection of 12 DEVStone
models in one minute. The variety of the chosen models ensures we measure
different particularities provided by DEVStone. The proposed metric allows us
to compare various simulators and to assess the impact of new features on their
performance. We use the DEVStone metric to compare some popular DEVS-based
simulators.
</p>
</div>
</dd>
<dt><a name="item273">[273]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16546" title="Abstract">arXiv:2309.16546</a> [<a href="/pdf/2309.16546" title="Download PDF">pdf</a>, <a href="/format/2309.16546" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Correcting for heterogeneity in real-time epidemiological indicators
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rumack%2C+A">Aaron Rumack</a>, 
<a href="/search/cs?searchtype=author&query=Rosenfeld%2C+R">Roni Rosenfeld</a>, 
<a href="/search/cs?searchtype=author&query=Townes%2C+F+W">F. William Townes</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Auxiliary data sources have become increasingly important in epidemiological
surveillance, as they are often available at a finer spatial and temporal
resolution, larger coverage, and lower latency than traditional surveillance
signals. We describe the problem of spatial and temporal heterogeneity in these
signals derived from these data sources, where spatial and/or temporal biases
are present. We present a method to use a ``guiding'' signal to correct for
these biases and produce a more reliable signal that can be used for modeling
and forecasting. The method assumes that the heterogeneity can be approximated
by a low-rank matrix and that the temporal heterogeneity is smooth over time.
We also present a hyperparameter selection algorithm to choose the parameters
representing the matrix rank and degree of temporal smoothness of the
corrections. In the absence of ground truth, we use maps and plots to argue
that this method does indeed reduce heterogeneity. Reducing heterogeneity from
auxiliary data sources greatly increases their utility in modeling and
forecasting epidemics.
</p>
</div>
</dd>
<dt><a name="item274">[274]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16552" title="Abstract">arXiv:2309.16552</a> [<a href="/pdf/2309.16552" title="Download PDF">pdf</a>, <a href="/format/2309.16552" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Semantic Scene Difference Detection in Daily Life Patroling by Mobile  Robots using Pre-Trained Large-Scale Vision-Language Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Obinata%2C+Y">Yoshiki Obinata</a>, 
<a href="/search/cs?searchtype=author&query=Kawaharazuka%2C+K">Kento Kawaharazuka</a>, 
<a href="/search/cs?searchtype=author&query=Kanazawa%2C+N">Naoaki Kanazawa</a>, 
<a href="/search/cs?searchtype=author&query=Yamaguchi%2C+N">Naoya Yamaguchi</a>, 
<a href="/search/cs?searchtype=author&query=Tsukamoto%2C+N">Naoto Tsukamoto</a>, 
<a href="/search/cs?searchtype=author&query=Yanokura%2C+I">Iori Yanokura</a>, 
<a href="/search/cs?searchtype=author&query=Kitagawa%2C+S">Shingo Kitagawa</a>, 
<a href="/search/cs?searchtype=author&query=Shinjo%2C+K">Koki Shinjo</a>, 
<a href="/search/cs?searchtype=author&query=Okada%2C+K">Kei Okada</a>, 
<a href="/search/cs?searchtype=author&query=Inaba%2C+M">Masayuki Inaba</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to 2023 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS 2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">It is important for daily life support robots to detect changes in their
environment and perform tasks. In the field of anomaly detection in computer
vision, probabilistic and deep learning methods have been used to calculate the
image distance. These methods calculate distances by focusing on image pixels.
In contrast, this study aims to detect semantic changes in the daily life
environment using the current development of large-scale vision-language
models. Using its Visual Question Answering (VQA) model, we propose a method to
detect semantic changes by applying multiple questions to a reference image and
a current image and obtaining answers in the form of sentences. Unlike deep
learning-based methods in anomaly detection, this method does not require any
training or fine-tuning, is not affected by noise, and is sensitive to semantic
state changes in the real world. In our experiments, we demonstrated the
effectiveness of this method by applying it to a patrol task in a real-life
environment using a mobile robot, Fetch Mobile Manipulator. In the future, it
may be possible to add explanatory power to changes in the daily life
environment through spoken language.
</p>
</div>
</dd>
<dt><a name="item275">[275]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16553" title="Abstract">arXiv:2309.16553</a> [<a href="/pdf/2309.16553" title="Download PDF">pdf</a>, <a href="/format/2309.16553" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MatrixCity: A Large-scale City Dataset for City-scale Neural Rendering  and Beyond
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yixuan Li</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+L">Lihan Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+L">Linning Xu</a>, 
<a href="/search/cs?searchtype=author&query=Xiangli%2C+Y">Yuanbo Xiangli</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zhenzhi Wang</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+D">Dahua Lin</a>, 
<a href="/search/cs?searchtype=author&query=Dai%2C+B">Bo Dai</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to ICCV 2023. Project page: $\href{<a href="https://city-super.github.io/matrixcity/">this https URL</a>}{this\, https\, URL}$
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Neural radiance fields (NeRF) and its subsequent variants have led to
remarkable progress in neural rendering. While most of recent neural rendering
works focus on objects and small-scale scenes, developing neural rendering
methods for city-scale scenes is of great potential in many real-world
applications. However, this line of research is impeded by the absence of a
comprehensive and high-quality dataset, yet collecting such a dataset over real
city-scale scenes is costly, sensitive, and technically difficult. To this end,
we build a large-scale, comprehensive, and high-quality synthetic dataset for
city-scale neural rendering researches. Leveraging the Unreal Engine 5 City
Sample project, we develop a pipeline to easily collect aerial and street city
views, accompanied by ground-truth camera poses and a range of additional data
modalities. Flexible controls over environmental factors like light, weather,
human and car crowd are also available in our pipeline, supporting the need of
various tasks covering city-scale neural rendering and beyond. The resulting
pilot dataset, MatrixCity, contains 67k aerial images and 452k street images
from two city maps of total size $28km^2$. On top of MatrixCity, a thorough
benchmark is also conducted, which not only reveals unique challenges of the
task of city-scale neural rendering, but also highlights potential improvements
for future works. The dataset and code will be publicly available at our
project page: https://city-super.github.io/matrixcity/.
</p>
</div>
</dd>
<dt><a name="item276">[276]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16561" title="Abstract">arXiv:2309.16561</a> [<a href="/pdf/2309.16561" title="Download PDF">pdf</a>, <a href="/format/2309.16561" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Voting Network for Contour Levee Farmland Segmentation and  Classification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Meyarian%2C+A">Abolfazl Meyarian</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+X">Xiaohui Yuan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">High-resolution aerial imagery allows fine details in the segmentation of
farmlands. However, small objects and features introduce distortions to the
delineation of object boundaries, and larger contextual views are needed to
mitigate class confusion. In this work, we present an end-to-end trainable
network for segmenting farmlands with contour levees from high-resolution
aerial imagery. A fusion block is devised that includes multiple voting blocks
to achieve image segmentation and classification. We integrate the fusion block
with a backbone and produce both semantic predictions and segmentation slices.
The segmentation slices are used to perform majority voting on the predictions.
The network is trained to assign the most likely class label of a segment to
its pixels, learning the concept of farmlands rather than analyzing
constitutive pixels separately. We evaluate our method using images from the
National Agriculture Imagery Program. Our method achieved an average accuracy
of 94.34\%. Compared to the state-of-the-art methods, the proposed method
obtains an improvement of 6.96% and 2.63% in the F1 score on average.
</p>
</div>
</dd>
<dt><a name="item277">[277]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16564" title="Abstract">arXiv:2309.16564</a> [<a href="/pdf/2309.16564" title="Download PDF">pdf</a>, <a href="/format/2309.16564" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Augment to Interpret: Unsupervised and Inherently Interpretable Graph  Embeddings
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Scafarto%2C+G">Gregory Scafarto</a>, 
<a href="/search/cs?searchtype=author&query=Ciortan%2C+M">Madalina Ciortan</a>, 
<a href="/search/cs?searchtype=author&query=Tihon%2C+S">Simon Tihon</a>, 
<a href="/search/cs?searchtype=author&query=Ferre%2C+Q">Quentin Ferre</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Unsupervised learning allows us to leverage unlabelled data, which has become
abundantly available, and to create embeddings that are usable on a variety of
downstream tasks. However, the typical lack of interpretability of unsupervised
representation learning has become a limiting factor with regard to recent
transparent-AI regulations. In this paper, we study graph representation
learning and we show that data augmentation that preserves semantics can be
learned and used to produce interpretations. Our framework, which we named
INGENIOUS, creates inherently interpretable embeddings and eliminates the need
for costly additional post-hoc analysis. We also introduce additional metrics
addressing the lack of formalism and metrics in the understudied area of
unsupervised-representation learning interpretability. Our results are
supported by an experimental study applied to both graph-level and node-level
tasks and show that interpretable embeddings provide state-of-the-art
performance on subsequent downstream tasks.
</p>
</div>
</dd>
<dt><a name="item278">[278]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16569" title="Abstract">arXiv:2309.16569</a> [<a href="/pdf/2309.16569" title="Download PDF">pdf</a>, <a href="/format/2309.16569" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Audio-Visual Speaker Verification via Joint Cross-Attention
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Praveen%2C+R+G">R. Gnana Praveen</a>, 
<a href="/search/cs?searchtype=author&query=Alam%2C+J">Jahangir Alam</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Computer Vision and Pattern Recognition (cs.CV); Multimedia (cs.MM); Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">Speaker verification has been widely explored using speech signals, which has
shown significant improvement using deep models. Recently, there has been a
surge in exploring faces and voices as they can offer more complementary and
comprehensive information than relying only on a single modality of speech
signals. Though current methods in the literature on the fusion of faces and
voices have shown improvement over that of individual face or voice modalities,
the potential of audio-visual fusion is not fully explored for speaker
verification. Most of the existing methods based on audio-visual fusion either
rely on score-level fusion or simple feature concatenation. In this work, we
have explored cross-modal joint attention to fully leverage the inter-modal
complementary information and the intra-modal information for speaker
verification. Specifically, we estimate the cross-attention weights based on
the correlation between the joint feature presentation and that of the
individual feature representations in order to effectively capture both
intra-modal as well inter-modal relationships among the faces and voices. We
have shown that efficiently leveraging the intra- and inter-modal relationships
significantly improves the performance of audio-visual fusion for speaker
verification. The performance of the proposed approach has been evaluated on
the Voxceleb1 dataset. Results show that the proposed approach can
significantly outperform the state-of-the-art methods of audio-visual fusion
for speaker verification.
</p>
</div>
</dd>
<dt><a name="item279">[279]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16571" title="Abstract">arXiv:2309.16571</a> [<a href="/pdf/2309.16571" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Review of Machine Learning Methods for Additive Manufacturing of  Functionally Graded Materials
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Karimzadeh%2C+M">Mohammad Karimzadeh</a>, 
<a href="/search/cs?searchtype=author&query=Vakanski%2C+A">Aleksandar Vakanski</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+F">Fei Xu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xinchang Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Additive manufacturing has revolutionized the manufacturing of complex parts
by enabling direct material joining and offers several advantages such as
cost-effective manufacturing of complex parts, reducing manufacturing waste,
and opening new possibilities for manufacturing automation. One group of
materials for which additive manufacturing holds great potential for enhancing
component performance and properties is Functionally Graded Materials (FGMs).
FGMs are advanced composite materials that exhibit smoothly varying properties
making them desirable for applications in aerospace, automobile, biomedical,
and defense industries. Such composition differs from traditional composite
materials, since the location-dependent composition changes gradually in FGMs,
leading to enhanced properties. Recently, machine learning techniques have
emerged as a promising means for fabrication of FGMs through optimizing
processing parameters, improving product quality, and detecting manufacturing
defects. This paper first provides a brief literature review of works related
to FGM fabrication, followed by reviewing works on employing machine learning
in additive manufacturing, Afterward, we provide an overview of published works
in the literature related to the application of machine learning methods in
Directed Energy Deposition and for fabrication of FGMs.
</p>
</div>
</dd>
<dt><a name="item280">[280]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16573" title="Abstract">arXiv:2309.16573</a> [<a href="/pdf/2309.16573" title="Download PDF">pdf</a>, <a href="/format/2309.16573" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The ARRT of Language-Models-as-a-Service: Overview of a New Paradigm and  its Challenges
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=La+Malfa%2C+E">Emanuele La Malfa</a>, 
<a href="/search/cs?searchtype=author&query=Petrov%2C+A">Aleksandar Petrov</a>, 
<a href="/search/cs?searchtype=author&query=Frieder%2C+S">Simon Frieder</a>, 
<a href="/search/cs?searchtype=author&query=Weinhuber%2C+C">Christoph Weinhuber</a>, 
<a href="/search/cs?searchtype=author&query=Burnell%2C+R">Ryan Burnell</a>, 
<a href="/search/cs?searchtype=author&query=Cohn%2C+A+G">Anthony G. Cohn</a>, 
<a href="/search/cs?searchtype=author&query=Shadbolt%2C+N">Nigel Shadbolt</a>, 
<a href="/search/cs?searchtype=author&query=Wooldridge%2C+M">Michael Wooldridge</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computation and Language (cs.CL); Computers and Society (cs.CY)

</div>
<p class="mathjax">Some of the most powerful language models currently are proprietary systems,
accessible only via (typically restrictive) web or software programming
interfaces. This is the Language-Models-as-a-Service (LMaaS) paradigm.
Contrasting with scenarios where full model access is available, as in the case
of open-source models, such closed-off language models create specific
challenges for evaluating, benchmarking, and testing them. This paper has two
goals: on the one hand, we delineate how the aforementioned challenges act as
impediments to the accessibility, replicability, reliability, and
trustworthiness (ARRT) of LMaaS. We systematically examine the issues that
arise from a lack of information about language models for each of these four
aspects. We shed light on current solutions, provide some recommendations, and
highlight the directions for future advancements. On the other hand, it serves
as a one-stop-shop for the extant knowledge about current, major LMaaS,
offering a synthesized overview of the licences and capabilities their
interfaces offer.
</p>
</div>
</dd>
<dt><a name="item281">[281]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16575" title="Abstract">arXiv:2309.16575</a> [<a href="/pdf/2309.16575" title="Download PDF">pdf</a>, <a href="/ps/2309.16575" title="Download PostScript">ps</a>, <a href="/format/2309.16575" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Benchmark for Learning to Translate a New Language from One Grammar  Book
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tanzer%2C+G">Garrett Tanzer</a>, 
<a href="/search/cs?searchtype=author&query=Suzgun%2C+M">Mirac Suzgun</a>, 
<a href="/search/cs?searchtype=author&query=Visser%2C+E">Eline Visser</a>, 
<a href="/search/cs?searchtype=author&query=Jurafsky%2C+D">Dan Jurafsky</a>, 
<a href="/search/cs?searchtype=author&query=Melas-Kyriazi%2C+L">Luke Melas-Kyriazi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Large language models (LLMs) can perform impressive feats with in-context
learning or lightweight finetuning. It is natural to wonder how well these
models adapt to genuinely new tasks, but how does one find tasks that are
unseen in internet-scale training sets? We turn to a field that is explicitly
motivated and bottlenecked by a scarcity of web data: low-resource languages.
In this paper, we introduce MTOB (Machine Translation from One Book), a
benchmark for learning to translate between English and Kalamang -- a language
with less than 200 speakers and therefore virtually no presence on the web --
using several hundred pages of field linguistics reference materials. This task
framing is novel in that it asks a model to learn a language from a single
human-readable book of grammar explanations, rather than a large mined corpus
of in-domain data, more akin to L2 learning than L1 acquisition. We demonstrate
that baselines using current LLMs are promising but fall short of human
performance, achieving 44.7 chrF on Kalamang to English translation and 45.8
chrF on English to Kalamang translation, compared to 51.6 and 57.0 chrF by a
human who learned Kalamang from the same reference materials. We hope that MTOB
will help measure LLM capabilities along a new dimension, and that the methods
developed to solve it could help expand access to language technology for
underserved communities by leveraging qualitatively different kinds of data
than traditional machine translation.
</p>
</div>
</dd>
<dt><a name="item282">[282]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16577" title="Abstract">arXiv:2309.16577</a> [<a href="/pdf/2309.16577" title="Download PDF">pdf</a>, <a href="/format/2309.16577" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Compilation as a Defense: Enhancing DL Model Attack Robustness via  Tensor Optimization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Trawicki%2C+S">Stefan Trawicki</a>, 
<a href="/search/cs?searchtype=author&query=Hackett%2C+W">William Hackett</a>, 
<a href="/search/cs?searchtype=author&query=Birch%2C+L">Lewis Birch</a>, 
<a href="/search/cs?searchtype=author&query=Suri%2C+N">Neeraj Suri</a>, 
<a href="/search/cs?searchtype=author&query=Garraghan%2C+P">Peter Garraghan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 2 pages, 1 figure, CAMLIS 2023 Fast Abstract
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Cryptography and Security (cs.CR)

</div>
<p class="mathjax">Adversarial Machine Learning (AML) is a rapidly growing field of security
research, with an often overlooked area being model attacks through
side-channels. Previous works show such attacks to be serious threats, though
little progress has been made on efficient remediation strategies that avoid
costly model re-engineering. This work demonstrates a new defense against AML
side-channel attacks using model compilation techniques, namely tensor
optimization. We show relative model attack effectiveness decreases of up to
43% using tensor optimization, discuss the implications, and direction of
future work.
</p>
</div>
</dd>
<dt><a name="item283">[283]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16579" title="Abstract">arXiv:2309.16579</a> [<a href="/pdf/2309.16579" title="Download PDF">pdf</a>, <a href="/format/2309.16579" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Physics Informed Machine Learning Method for Power System Model  Parameter Optimization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Kordowich%2C+G">Georg Kordowich</a>, 
<a href="/search/eess?searchtype=author&query=Jaeger%2C+J">Johann Jaeger</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, 8 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">This paper proposes a gradient descent based optimization method that relies
on automatic differentiation for the computation of gradients. The method uses
tools and techniques originally developed in the field of artificial neural
networks and applies them to power system simulations. It can be used as a
one-shot physics informed machine learning approach for the identification of
uncertain power system simulation parameters. Additionally, it can optimize
parameters with respect to a desired system behavior. The paper focuses on
presenting the theoretical background and showing exemplary use-cases for both
parameter identification and optimization using a single machine infinite
busbar system. The results imply a generic applicability for a wide range of
problems.
</p>
</div>
</dd>
<dt><a name="item284">[284]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16583" title="Abstract">arXiv:2309.16583</a> [<a href="/pdf/2309.16583" title="Download PDF">pdf</a>, <a href="/format/2309.16583" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GPT-Fathom: Benchmarking Large Language Models to Decipher the  Evolutionary Path towards GPT-4 and Beyond
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zheng%2C+S">Shen Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yuyu Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+Y">Yijie Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Xi%2C+C">Chenguang Xi</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+P">Pengyang Gao</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+X">Xun Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Chang%2C+K+C">Kevin Chen-Chuan Chang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">With the rapid advancement of large language models (LLMs), there is a
pressing need for a comprehensive evaluation suite to assess their capabilities
and limitations. Existing LLM leaderboards often reference scores reported in
other papers without consistent settings and prompts, which may inadvertently
encourage cherry-picking favored settings and prompts for better results. In
this work, we introduce GPT-Fathom, an open-source and reproducible LLM
evaluation suite built on top of OpenAI Evals. We systematically evaluate 10+
leading LLMs as well as OpenAI's legacy models on 20+ curated benchmarks across
7 capability categories, all under aligned settings. Our retrospective study on
OpenAI's earlier models offers valuable insights into the evolutionary path
from GPT-3 to GPT-4. Currently, the community is eager to know how GPT-3
progressively improves to GPT-4, including technical details like whether
adding code data improves LLM's reasoning capability, which aspects of LLM
capability can be improved by SFT and RLHF, how much is the alignment tax, etc.
Our analysis sheds light on many of these questions, aiming to improve the
transparency of advanced LLMs.
</p>
</div>
</dd>
<dt><a name="item285">[285]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16584" title="Abstract">arXiv:2309.16584</a> [<a href="/pdf/2309.16584" title="Download PDF">pdf</a>, <a href="/format/2309.16584" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Design Toolbox for the Development of Collaborative Distributed  Machine Learning Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jin%2C+D">David Jin</a>, 
<a href="/search/cs?searchtype=author&query=Kannengie%C3%9Fer%2C+N">Niclas Kannengie&#xdf;er</a>, 
<a href="/search/cs?searchtype=author&query=Rank%2C+S">Sascha Rank</a>, 
<a href="/search/cs?searchtype=author&query=Sunyaev%2C+A">Ali Sunyaev</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Multiagent Systems (cs.MA)</span>; Emerging Technologies (cs.ET); Machine Learning (cs.LG); Software Engineering (cs.SE)

</div>
<p class="mathjax">To leverage training data for the sufficient training of ML models from
multiple parties in a confidentiality-preserving way, various collaborative
distributed machine learning (CDML) system designs have been developed, for
example, to perform assisted learning, federated learning, and split learning.
CDML system designs show different traits, for example, high agent autonomy,
machine learning (ML) model confidentiality, and fault tolerance. Facing a wide
variety of CDML system designs with different traits, it is difficult for
developers to design CDML systems with traits that match use case requirements
in a targeted way. However, inappropriate CDML system designs may result in
CDML systems failing their envisioned purposes. We developed a CDML design
toolbox that can guide the development of CDML systems. Based on the CDML
design toolbox, we present CDML system archetypes with distinct key traits that
can support the design of CDML systems to meet use case requirements.
</p>
</div>
</dd>
<dt><a name="item286">[286]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16585" title="Abstract">arXiv:2309.16585</a> [<a href="/pdf/2309.16585" title="Download PDF">pdf</a>, <a href="/format/2309.16585" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Text-to-3D using Gaussian Splatting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+Z">Zilong Chen</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+F">Feng Wang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+H">Huaping Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project page: <a href="https://gsgen3d.github.io.">this https URL</a> Code: <a href="https://github.com/gsgen3d/gsgen">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">In this paper, we present Gaussian Splatting based text-to-3D generation
(GSGEN), a novel approach for generating high-quality 3D objects. Previous
methods suffer from inaccurate geometry and limited fidelity due to the absence
of 3D prior and proper representation. We leverage 3D Gaussian Splatting, a
recent state-of-the-art representation, to address existing shortcomings by
exploiting the explicit nature that enables the incorporation of 3D prior.
Specifically, our method adopts a progressive optimization strategy, which
includes a geometry optimization stage and an appearance refinement stage. In
geometry optimization, a coarse representation is established under a 3D
geometry prior along with the ordinary 2D SDS loss, ensuring a sensible and
3D-consistent rough shape. Subsequently, the obtained Gaussians undergo an
iterative refinement to enrich details. In this stage, we increase the number
of Gaussians by compactness-based densification to enhance continuity and
improve fidelity. With these designs, our approach can generate 3D content with
delicate details and more accurate geometry. Extensive evaluations demonstrate
the effectiveness of our method, especially for capturing high-frequency
components. Video results are provided at https://gsgen3d.github.io. Our code
is available at https://github.com/gsgen3d/gsgen
</p>
</div>
</dd>
<dt><a name="item287">[287]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16588" title="Abstract">arXiv:2309.16588</a> [<a href="/pdf/2309.16588" title="Download PDF">pdf</a>, <a href="/format/2309.16588" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Vision Transformers Need Registers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Darcet%2C+T">Timoth&#xe9;e Darcet</a>, 
<a href="/search/cs?searchtype=author&query=Oquab%2C+M">Maxime Oquab</a>, 
<a href="/search/cs?searchtype=author&query=Mairal%2C+J">Julien Mairal</a>, 
<a href="/search/cs?searchtype=author&query=Bojanowski%2C+P">Piotr Bojanowski</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Transformers have recently emerged as a powerful tool for learning visual
representations. In this paper, we identify and characterize artifacts in
feature maps of both supervised and self-supervised ViT networks. The artifacts
correspond to high-norm tokens appearing during inference primarily in
low-informative background areas of images, that are repurposed for internal
computations. We propose a simple yet effective solution based on providing
additional tokens to the input sequence of the Vision Transformer to fill that
role. We show that this solution fixes that problem entirely for both
supervised and self-supervised models, sets a new state of the art for
self-supervised visual models on dense visual prediction tasks, enables object
discovery methods with larger models, and most importantly leads to smoother
feature maps and attention maps for downstream visual processing.
</p>
</div>
</dd>
<dt><a name="item288">[288]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16589" title="Abstract">arXiv:2309.16589</a> [<a href="/pdf/2309.16589" title="Download PDF">pdf</a>, <a href="/format/2309.16589" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Connecting Space Missions From NGSO Constellations: Feasibility Study
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Chougrani%2C+H">Houcine Chougrani</a>, 
<a href="/search/eess?searchtype=author&query=Kodheli%2C+O">Oltjon Kodheli</a>, 
<a href="/search/eess?searchtype=author&query=Georganaki%2C+A">Ali Georganaki</a>, 
<a href="/search/eess?searchtype=author&query=Thoemel%2C+J">Jan Thoemel</a>, 
<a href="/search/eess?searchtype=author&query=Turtoro%2C+C+V">Chiara Vittoria Turtoro</a>, 
<a href="/search/eess?searchtype=author&query=Zeppenfeldt%2C+F">Frank Zeppenfeldt</a>, 
<a href="/search/eess?searchtype=author&query=Pissias%2C+P">Petros Pissias</a>, 
<a href="/search/eess?searchtype=author&query=Hofmann%2C+M">Mahulena Hofmann</a>, 
<a href="/search/eess?searchtype=author&query=Chatzinotas%2C+S">Symeon Chatzinotas</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">A space-based internet system (e.g., Starlink, OneWeb, o3b mPower), despite
possessing the capability to provide internet services to on-ground users in a
global scale, can dramatically change the way space missions are designed and
operated in the foreseeable future. Assuming a scenario where space mission
satellites can access the internet via a space internet system, the satellite
can be connected to the network permanently (24x7) and act as mere terminal
independently from its location. The ability to communicate with the satellite
on-demand has the potential to improve aspects such as real-time tasking,
outage minimization, operation cost, and dependency on the ground. This paper
performs a feasibility study on the concept of connecting space missions using
space-based internet systems. This study includes a review of existing and
near-future space internet systems, identification of candidate space missions
for the proposed concept, a necessary adaptation of existing Commercial
off-the-shelf (COTS) terminals to be plugged into space mission satellites,
assessment of communication performance, and investigation of the legal aspects
of the radio frequency (RF) spectrum usage. The paper evidences that the
concept is practically possible to implement in the near future. Among the
studied space internet systems (i.e. Starlink, OneWeb, o3b mPower), O3b mPower
stands out as the best system allowing permanent coverage of low earth orbit
(LEO) space missions with data rates that can reach up to 21 Mbps per
satellite. Although the concept is very promising and can be implemented in
near future, our investigations show that some regulation aspects regarding the
RF usage should be solved for future deployment.
</p>
</div>
</dd>
<dt><a name="item289">[289]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16592" title="Abstract">arXiv:2309.16592</a> [<a href="/pdf/2309.16592" title="Download PDF">pdf</a>, <a href="/format/2309.16592" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Tensor Factorization for Leveraging Cross-Modal Knowledge in  Data-Constrained Infrared Object Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sharma%2C+M">Manish Sharma</a>, 
<a href="/search/cs?searchtype=author&query=Chatterjee%2C+M">Moitreya Chatterjee</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+K">Kuan-Chuan Peng</a>, 
<a href="/search/cs?searchtype=author&query=Lohit%2C+S">Suhas Lohit</a>, 
<a href="/search/cs?searchtype=author&query=Jones%2C+M">Michael Jones</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to ICCV 2023, LIMIT Workshop. The first two authors contributed equally
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">The primary bottleneck towards obtaining good recognition performance in IR
images is the lack of sufficient labeled training data, owing to the cost of
acquiring such data. Realizing that object detection methods for the RGB
modality are quite robust (at least for some commonplace classes, like person,
car, etc.), thanks to the giant training sets that exist, in this work we seek
to leverage cues from the RGB modality to scale object detectors to the IR
modality, while preserving model performance in the RGB modality. At the core
of our method, is a novel tensor decomposition method called TensorFact which
splits the convolution kernels of a layer of a Convolutional Neural Network
(CNN) into low-rank factor matrices, with fewer parameters than the original
CNN. We first pretrain these factor matrices on the RGB modality, for which
plenty of training data are assumed to exist and then augment only a few
trainable parameters for training on the IR modality to avoid over-fitting,
while encouraging them to capture complementary cues from those trained only on
the RGB modality. We validate our approach empirically by first assessing how
well our TensorFact decomposed network performs at the task of detecting
objects in RGB images vis-a-vis the original network and then look at how well
it adapts to IR images of the FLIR ADAS v1 dataset. For the latter, we train
models under scenarios that pose challenges stemming from data paucity. From
the experiments, we observe that: (i) TensorFact shows performance gains on RGB
images; (ii) further, this pre-trained model, when fine-tuned, outperforms a
standard state-of-the-art object detector on the FLIR ADAS v1 dataset by about
4% in terms of mAP 50 score.
</p>
</div>
</dd>
<dt><a name="item290">[290]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16593" title="Abstract">arXiv:2309.16593</a> [<a href="/pdf/2309.16593" title="Download PDF">pdf</a>, <a href="/ps/2309.16593" title="Download PostScript">ps</a>, <a href="/format/2309.16593" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Navigating Healthcare Insights: A Birds Eye View of Explainability with  Knowledge Graphs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Garg%2C+S">Satvik Garg</a>, 
<a href="/search/cs?searchtype=author&query=Parikh%2C+S">Shivam Parikh</a>, 
<a href="/search/cs?searchtype=author&query=Garg%2C+S">Somya Garg</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> IEEE AIKE 2023, 8 Pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Knowledge graphs (KGs) are gaining prominence in Healthcare AI, especially in
drug discovery and pharmaceutical research as they provide a structured way to
integrate diverse information sources, enhancing AI system interpretability.
This interpretability is crucial in healthcare, where trust and transparency
matter, and eXplainable AI (XAI) supports decision making for healthcare
professionals. This overview summarizes recent literature on the impact of KGs
in healthcare and their role in developing explainable AI models. We cover KG
workflow, including construction, relationship extraction, reasoning, and their
applications in areas like Drug-Drug Interactions (DDI), Drug Target
Interactions (DTI), Drug Development (DD), Adverse Drug Reactions (ADR), and
bioinformatics. We emphasize the importance of making KGs more interpretable
through knowledge-infused learning in healthcare. Finally, we highlight
research challenges and provide insights for future directions.
</p>
</div>
</dd>
<dt><a name="item291">[291]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16594" title="Abstract">arXiv:2309.16594</a> [<a href="/pdf/2309.16594" title="Download PDF">pdf</a>, <a href="/ps/2309.16594" title="Download PostScript">ps</a>, <a href="/format/2309.16594" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deterministic Fully Dynamic SSSP and More
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=van+den+Brand%2C+J">Jan van den Brand</a>, 
<a href="/search/cs?searchtype=author&query=Karczmarz%2C+A">Adam Karczmarz</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Extended abstract to appear in FOCS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>

</div>
<p class="mathjax">We present the first non-trivial fully dynamic algorithm maintaining exact
single-source distances in unweighted graphs. This resolves an open problem
stated by Sankowski [COCOON 2005] and van den Brand and Nanongkai [FOCS 2019].
Previous fully dynamic single-source distances data structures were all
approximate, but so far, non-trivial dynamic algorithms for the exact setting
could only be ruled out for polynomially weighted graphs (Abboud and
Vassilevska Williams, [FOCS 2014]). The exact unweighted case remained the main
case for which neither a subquadratic dynamic algorithm nor a quadratic lower
bound was known.
<br />Our dynamic algorithm works on directed graphs, is deterministic, and can
report a single-source shortest paths tree in subquadratic time as well. Thus
we also obtain the first deterministic fully dynamic data structure for
reachability (transitive closure) with subquadratic update and query time. This
answers an open problem of van den Brand, Nanongkai, and Saranurak [FOCS 2019].
<br />Finally, using the same framework we obtain the first fully dynamic data
structure maintaining all-pairs $(1+\epsilon)$-approximate distances within
non-trivial sub-$n^\omega$ worst-case update time while supporting optimal-time
approximate shortest path reporting at the same time. This data structure is
also deterministic and therefore implies the first known non-trivial
deterministic worst-case bound for recomputing the transitive closure of a
digraph.
</p>
</div>
</dd>
<dt><a name="item292">[292]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16595" title="Abstract">arXiv:2309.16595</a> [<a href="/pdf/2309.16595" title="Download PDF">pdf</a>, <a href="/format/2309.16595" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Can LLMs Effectively Leverage Structural Information for Graph Learning:  When and Why
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+J">Jin Huang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xingjian Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Mei%2C+Q">Qiaozhu Mei</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+J">Jiaqi Ma</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">This paper studies Large Language Models (LLMs) for structured
data--particularly graphs--a crucial data modality that remains underexplored
in the LLM literature. We aim to understand when and why the incorporation of
structural information inherent in graph data can improve the prediction
performance of LLMs on node classification tasks. To address the ``when''
question, we examine a variety of prompting methods for encoding structural
information, in settings where textual node features are either rich or scarce.
For the ``why'' questions, we probe into two potential contributing factors to
the LLM performance: data leakage and homophily. Our exploration of these
questions reveals that (i) LLMs can benefit from structural information,
especially when textual node features are scarce; (ii) there is no substantial
evidence indicating that the performance of LLMs is significantly attributed to
data leakage; and (iii) the performance of LLMs on a target node is strongly
positively related to the local homophily ratio of the node.
</p>
</div>
</dd>
<dt><a name="item293">[293]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16597" title="Abstract">arXiv:2309.16597</a> [<a href="/pdf/2309.16597" title="Download PDF">pdf</a>, <a href="/format/2309.16597" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Transfer Learning for Bayesian Optimization on Heterogeneous Search  Spaces
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fan%2C+Z">Zhou Fan</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+X">Xinran Han</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zi Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Machine Learning (stat.ML)

</div>
<p class="mathjax">Bayesian optimization (BO) is a popular black-box function optimization
method, which makes sequential decisions based on a Bayesian model, typically a
Gaussian process (GP), of the function. To ensure the quality of the model,
transfer learning approaches have been developed to automatically design GP
priors by learning from observations on "training" functions. These training
functions are typically required to have the same domain as the "test" function
(black-box function to be optimized). In this paper, we introduce MPHD, a model
pre-training method on heterogeneous domains, which uses a neural net mapping
from domain-specific contexts to specifications of hierarchical GPs. MPHD can
be seamlessly integrated with BO to transfer knowledge across heterogeneous
search spaces. Our theoretical and empirical results demonstrate the validity
of MPHD and its superior performance on challenging black-box function
optimization tasks.
</p>
</div>
</dd>
<dt><a name="item294">[294]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16599" title="Abstract">arXiv:2309.16599</a> [<a href="/pdf/2309.16599" title="Download PDF">pdf</a>, <a href="/format/2309.16599" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Unlikelihood Tuning on Negative Samples Amazingly Improves Zero-Shot  Translation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zan%2C+C">Changtong Zan</a>, 
<a href="/search/cs?searchtype=author&query=Ding%2C+L">Liang Ding</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+L">Li Shen</a>, 
<a href="/search/cs?searchtype=author&query=Lei%2C+Y">Yibin Lei</a>, 
<a href="/search/cs?searchtype=author&query=Zhan%2C+Y">Yibing Zhan</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+W">Weifeng Liu</a>, 
<a href="/search/cs?searchtype=author&query=Tao%2C+D">Dacheng Tao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Zero-shot translation (ZST), which is generally based on a multilingual
neural machine translation model, aims to translate between unseen language
pairs in training data. The common practice to guide the zero-shot language
mapping during inference is to deliberately insert the source and target
language IDs, e.g., &lt;EN&gt; for English and &lt;DE&gt; for German. Recent studies have
shown that language IDs sometimes fail to navigate the ZST task, making them
suffer from the off-target problem (non-target language words exist in the
generated translation) and, therefore, difficult to apply the current
multilingual translation model to a broad range of zero-shot language
scenarios. To understand when and why the navigation capabilities of language
IDs are weakened, we compare two extreme decoder input cases in the ZST
directions: Off-Target (OFF) and On-Target (ON) cases. By contrastively
visualizing the contextual word representations (CWRs) of these cases with
teacher forcing, we show that 1) the CWRs of different languages are
effectively distributed in separate regions when the sentence and ID are
matched (ON setting), and 2) if the sentence and ID are unmatched (OFF
setting), the CWRs of different languages are chaotically distributed. Our
analyses suggest that although they work well in ideal ON settings, language
IDs become fragile and lose their navigation ability when faced with off-target
tokens, which commonly exist during inference but are rare in training
scenarios. In response, we employ unlikelihood tuning on the negative (OFF)
samples to minimize their probability such that the language IDs can
discriminate between the on- and off-target tokens during training. Experiments
spanning 40 ZST directions show that our method reduces the off-target ratio by
-48.0% on average, leading to a +9.1 BLEU improvement with only an extra +0.3%
tuning cost.
</p>
</div>
</dd>
<dt><a name="item295">[295]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16603" title="Abstract">arXiv:2309.16603</a> [<a href="/pdf/2309.16603" title="Download PDF">pdf</a>, <a href="/ps/2309.16603" title="Download PostScript">ps</a>, <a href="/format/2309.16603" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deep Learning Based Uplink Multi-User SIMO Beamforming Design
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Vahapoglu%2C+C">Cemil Vahapoglu</a>, 
<a href="/search/cs?searchtype=author&query=O%27Shea%2C+T+J">Timothy J. O&#x27;Shea</a>, 
<a href="/search/cs?searchtype=author&query=Roy%2C+T">Tamoghna Roy</a>, 
<a href="/search/cs?searchtype=author&query=Ulukus%2C+S">Sennur Ulukus</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Machine Learning (cs.LG); Signal Processing (eess.SP)

</div>
<p class="mathjax">The advancement of fifth generation (5G) wireless communication networks has
created a greater demand for wireless resource management solutions that offer
high data rates, extensive coverage, minimal latency and energy-efficient
performance. Nonetheless, traditional approaches have shortcomings when it
comes to computational complexity and their ability to adapt to dynamic
conditions, creating a gap between theoretical analysis and the practical
execution of algorithmic solutions for managing wireless resources. Deep
learning-based techniques offer promising solutions for bridging this gap with
their substantial representation capabilities. We propose a novel unsupervised
deep learning framework, which is called NNBF, for the design of uplink receive
multi-user single input multiple output (MU-SIMO) beamforming. The primary
objective is to enhance the throughput by focusing on maximizing the sum-rate
while also offering computationally efficient solution, in contrast to
established conventional methods. We conduct experiments for several antenna
configurations. Our experimental results demonstrate that NNBF exhibits
superior performance compared to our baseline methods, namely, zero-forcing
beamforming (ZFBF) and minimum mean square error (MMSE) equalizer.
Additionally, NNBF is scalable to the number of single-antenna user equipments
(UEs) while baseline methods have significant computational burden due to
matrix pseudo-inverse operation.
</p>
</div>
</dd>
<dt><a name="item296">[296]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16606" title="Abstract">arXiv:2309.16606</a> [<a href="/pdf/2309.16606" title="Download PDF">pdf</a>, <a href="/format/2309.16606" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> &quot;AI enhances our performance, I have no doubt this one will do the  same&quot;: The Placebo effect is robust to negative descriptions of AI
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kloft%2C+A+M">Agnes M. Kloft</a>, 
<a href="/search/cs?searchtype=author&query=Welsch%2C+R">Robin Welsch</a>, 
<a href="/search/cs?searchtype=author&query=Kosch%2C+T">Thomas Kosch</a>, 
<a href="/search/cs?searchtype=author&query=Villa%2C+S">Steeven Villa</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Heightened AI expectations facilitate performance in human-AI interactions
through placebo effects. While lowering expectations to control for placebo
effects is advisable, overly negative expectations could induce nocebo effects.
In a letter discrimination task, we informed participants that an AI would
either increase or decrease their performance by adapting the interface, but in
reality, no AI was present in any condition. A Bayesian analysis showed that
participants had high expectations and performed descriptively better
irrespective of the AI description when a sham-AI was present. Using cognitive
modeling, we could trace this advantage back to participants gathering more
information. A replication study verified that negative AI descriptions do not
alter expectations, suggesting that performance expectations with AI are biased
and robust to negative verbal descriptions. We discuss the impact of user
expectations on AI interactions and evaluation and provide a behavioral placebo
marker for human-AI interaction
</p>
</div>
</dd>
<dt><a name="item297">[297]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16608" title="Abstract">arXiv:2309.16608</a> [<a href="/pdf/2309.16608" title="Download PDF">pdf</a>, <a href="/format/2309.16608" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> KV Inversion: KV Embeddings Learning for Text-Conditioned Real Image  Action Editing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+J">Jiancheng Huang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yifan Liu</a>, 
<a href="/search/cs?searchtype=author&query=Qin%2C+J">Jin Qin</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+S">Shifeng Chen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Text-conditioned image editing is a recently emerged and highly practical
task, and its potential is immeasurable. However, most of the concurrent
methods are unable to perform action editing, i.e. they can not produce results
that conform to the action semantics of the editing prompt and preserve the
content of the original image. To solve the problem of action editing, we
propose KV Inversion, a method that can achieve satisfactory reconstruction
performance and action editing, which can solve two major problems: 1) the
edited result can match the corresponding action, and 2) the edited object can
retain the texture and identity of the original real image. In addition, our
method does not require training the Stable Diffusion model itself, nor does it
require scanning a large-scale dataset to perform time-consuming training.
</p>
</div>
</dd>
<dt><a name="item298">[298]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16609" title="Abstract">arXiv:2309.16609</a> [<a href="/pdf/2309.16609" title="Download PDF">pdf</a>, <a href="/format/2309.16609" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Qwen Technical Report
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bai%2C+J">Jinze Bai</a>, 
<a href="/search/cs?searchtype=author&query=Bai%2C+S">Shuai Bai</a>, 
<a href="/search/cs?searchtype=author&query=Chu%2C+Y">Yunfei Chu</a>, 
<a href="/search/cs?searchtype=author&query=Cui%2C+Z">Zeyu Cui</a>, 
<a href="/search/cs?searchtype=author&query=Dang%2C+K">Kai Dang</a>, 
<a href="/search/cs?searchtype=author&query=Deng%2C+X">Xiaodong Deng</a>, 
<a href="/search/cs?searchtype=author&query=Fan%2C+Y">Yang Fan</a>, 
<a href="/search/cs?searchtype=author&query=Ge%2C+W">Wenbin Ge</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+Y">Yu Han</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+F">Fei Huang</a>, 
<a href="/search/cs?searchtype=author&query=Hui%2C+B">Binyuan Hui</a>, 
<a href="/search/cs?searchtype=author&query=Ji%2C+L">Luo Ji</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+M">Mei Li</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+J">Junyang Lin</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+R">Runji Lin</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+D">Dayiheng Liu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+G">Gao Liu</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+C">Chengqiang Lu</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+K">Keming Lu</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+J">Jianxin Ma</a>, 
<a href="/search/cs?searchtype=author&query=Men%2C+R">Rui Men</a>, 
<a href="/search/cs?searchtype=author&query=Ren%2C+X">Xingzhang Ren</a>, 
<a href="/search/cs?searchtype=author&query=Ren%2C+X">Xuancheng Ren</a>, 
<a href="/search/cs?searchtype=author&query=Tan%2C+C">Chuanqi Tan</a>, 
<a href="/search/cs?searchtype=author&query=Tan%2C+S">Sinan Tan</a>, 
<a href="/search/cs?searchtype=author&query=Tu%2C+J">Jianhong Tu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+P">Peng Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Shijie Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+W">Wei Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+S">Shengguang Wu</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+B">Benfeng Xu</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+J">Jin Xu</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+A">An Yang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+H">Hao Yang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+J">Jian Yang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+S">Shusheng Yang</a>, 
<a href="/search/cs?searchtype=author&query=Yao%2C+Y">Yang Yao</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+B">Bowen Yu</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+H">Hongyi Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+Z">Zheng Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jianwei Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xingxuan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yichang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zhenru Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+C">Chang Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+J">Jingren Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+X">Xiaohuan Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+T">Tianhang Zhu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 59 pages, 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Large language models (LLMs) have revolutionized the field of artificial
intelligence, enabling natural language processing tasks that were previously
thought to be exclusive to humans. In this work, we introduce Qwen, the first
installment of our large language model series. Qwen is a comprehensive
language model series that encompasses distinct models with varying parameter
counts. It includes Qwen, the base pretrained language models, and Qwen-Chat,
the chat models finetuned with human alignment techniques. The base language
models consistently demonstrate superior performance across a multitude of
downstream tasks, and the chat models, particularly those trained using
Reinforcement Learning from Human Feedback (RLHF), are highly competitive. The
chat models possess advanced tool-use and planning capabilities for creating
agent applications, showcasing impressive performance even when compared to
bigger models on complex tasks like utilizing a code interpreter. Furthermore,
we have developed coding-specialized models, Code-Qwen and Code-Qwen-Chat, as
well as mathematics-focused models, Math-Qwen-Chat, which are built upon base
language models. These models demonstrate significantly improved performance in
comparison with open-source models, and slightly fall behind the proprietary
models.
</p>
</div>
</dd>
<dt><a name="item299">[299]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16617" title="Abstract">arXiv:2309.16617</a> [<a href="/pdf/2309.16617" title="Download PDF">pdf</a>, <a href="/format/2309.16617" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Adaptive Output-Feedback Model Predictive Control of Hammerstein Systems  with Unknown Linear Dynamics
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Kamaldar%2C+M">Mohammadreza Kamaldar</a>, 
<a href="/search/eess?searchtype=author&query=Bernstein%2C+D+S">Dennis S. Bernstein</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: text overlap with <a href="/abs/2309.11589">arXiv:2309.11589</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Dynamical Systems (math.DS); Optimization and Control (math.OC)

</div>
<p class="mathjax">This paper considers model predictive control of Hammerstein systems, where
the linear dynamics are a priori unknown and the input nonlinearity is known.
Predictive cost adaptive control (PCAC) is applied to this system using
recursive least squares for online, closed-loop system identification with
optimization over a receding horizon performed by quadratic programming (QP).
In order to account for the input nonlinearity, the input matrix is defined to
be control dependent, and the optimization is performed iteratively. This
technique is applied to output stabilization of a chain of integrators with
unknown dynamics under control saturation and deadzone input nonlinearity.
</p>
</div>
</dd>
<dt><a name="item300">[300]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16618" title="Abstract">arXiv:2309.16618</a> [<a href="/pdf/2309.16618" title="Download PDF">pdf</a>, <a href="/format/2309.16618" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Revisiting Neural Program Smoothing for Fuzzing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nicolae%2C+M">Maria-Irina Nicolae</a>, 
<a href="/search/cs?searchtype=author&query=Eisele%2C+M">Max Eisele</a>, 
<a href="/search/cs?searchtype=author&query=Zeller%2C+A">Andreas Zeller</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted as conference paper at ESEC/FSE 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>; Artificial Intelligence (cs.AI); Cryptography and Security (cs.CR)

</div>
<p class="mathjax">Testing with randomly generated inputs (fuzzing) has gained significant
traction due to its capacity to expose program vulnerabilities automatically.
Fuzz testing campaigns generate large amounts of data, making them ideal for
the application of machine learning (ML). Neural program smoothing (NPS), a
specific family of ML-guided fuzzers, aims to use a neural network as a smooth
approximation of the program target for new test case generation.
<br />In this paper, we conduct the most extensive evaluation of NPS fuzzers
against standard gray-box fuzzers (&gt;11 CPU years and &gt;5.5 GPU years), and make
the following contributions: (1) We find that the original performance claims
for NPS fuzzers do not hold; a gap we relate to fundamental, implementation,
and experimental limitations of prior works. (2) We contribute the first
in-depth analysis of the contribution of machine learning and gradient-based
mutations in NPS. (3) We implement Neuzz++, which shows that addressing the
practical limitations of NPS fuzzers improves performance, but that standard
gray-box fuzzers almost always surpass NPS-based fuzzers. (4) As a consequence,
we propose new guidelines targeted at benchmarking fuzzing based on machine
learning, and present MLFuzz, a platform with GPU access for easy and
reproducible evaluation of ML-based fuzzers. Neuzz++, MLFuzz, and all our data
are public.
</p>
</div>
</dd>
<dt><a name="item301">[301]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16621" title="Abstract">arXiv:2309.16621</a> [<a href="/pdf/2309.16621" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Stress Testing Chain-of-Thought Prompting for Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mishra%2C+A">Aayush Mishra</a>, 
<a href="/search/cs?searchtype=author&query=Thakkar%2C+K">Karan Thakkar</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">This report examines the effectiveness of Chain-of-Thought (CoT) prompting in
improving the multi-step reasoning abilities of large language models (LLMs).
Inspired by previous studies \cite{Min2022RethinkingWork}, we analyze the
impact of three types of CoT prompt perturbations, namely CoT order, CoT
values, and CoT operators on the performance of GPT-3 on various tasks. Our
findings show that incorrect CoT prompting leads to poor performance on
accuracy metrics. Correct values in the CoT is crucial for predicting correct
answers. Moreover, incorrect demonstrations, where the CoT operators or the CoT
order are wrong, do not affect the performance as drastically when compared to
the value based perturbations. This research deepens our understanding of CoT
prompting and opens some new questions regarding the capability of LLMs to
learn reasoning in context.
</p>
</div>
</dd>
<dt><a name="item302">[302]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16628" title="Abstract">arXiv:2309.16628</a> [<a href="/pdf/2309.16628" title="Download PDF">pdf</a>, <a href="/format/2309.16628" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the Role of 5G and Beyond Sidelink Communication in Multi-Hop  Tactical Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Thornton%2C+C+E">Charles E. Thornton</a>, 
<a href="/search/cs?searchtype=author&query=Allen%2C+E">Evan Allen</a>, 
<a href="/search/cs?searchtype=author&query=Jones%2C+E">Evar Jones</a>, 
<a href="/search/cs?searchtype=author&query=Jakubisin%2C+D">Daniel Jakubisin</a>, 
<a href="/search/cs?searchtype=author&query=Templin%2C+F">Fred Templin</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+L">Lingjia Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages, 4 figures. To be presented at 2023 IEEE MILCOM Workshops, Boston, MA
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">This work investigates the potential of 5G and beyond sidelink (SL)
communication to support multi-hop tactical networks. We first provide a
technical and historical overview of 3GPP SL standardization activities, and
then consider applications to current problems of interest in tactical
networking. We consider a number of multi-hop routing techniques which are
expected to be of interest for SL-enabled multi-hop tactical networking and
examine open-source tools useful for network emulation. Finally, we discuss
relevant research directions which may be of interest for 5G SL-enabled
tactical communications, namely the integration of RF sensing and positioning,
as well as emerging machine learning tools such as federated and decentralized
learning, which may be of great interest for resource allocation and routing
problems that arise in tactical applications. We conclude by summarizing recent
developments in the 5G SL literature and provide guidelines for future
research.
</p>
</div>
</dd>
<dt><a name="item303">[303]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16629" title="Abstract">arXiv:2309.16629</a> [<a href="/pdf/2309.16629" title="Download PDF">pdf</a>, <a href="/format/2309.16629" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Deterministic Almost-Linear Time Algorithm for Minimum-Cost Flow
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=van+den+Brand%2C+J">Jan van den Brand</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+L">Li Chen</a>, 
<a href="/search/cs?searchtype=author&query=Kyng%2C+R">Rasmus Kyng</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y+P">Yang P. Liu</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+R">Richard Peng</a>, 
<a href="/search/cs?searchtype=author&query=Gutenberg%2C+M+P">Maximilian Probst Gutenberg</a>, 
<a href="/search/cs?searchtype=author&query=Sachdeva%2C+S">Sushant Sachdeva</a>, 
<a href="/search/cs?searchtype=author&query=Sidford%2C+A">Aaron Sidford</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to FOCS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>; Optimization and Control (math.OC)

</div>
<p class="mathjax">We give a deterministic $m^{1+o(1)}$ time algorithm that computes exact
maximum flows and minimum-cost flows on directed graphs with $m$ edges and
polynomially bounded integral demands, costs, and capacities. As a consequence,
we obtain the first running time improvement for deterministic algorithms that
compute maximum-flow in graphs with polynomial bounded capacities since the
work of Goldberg-Rao [J.ACM '98].
<br />Our algorithm builds on the framework of
Chen-Kyng-Liu-Peng-Gutenberg-Sachdeva [FOCS '22] that computes an optimal flow
by computing a sequence of $m^{1+o(1)}$-approximate undirected minimum-ratio
cycles. We develop a deterministic dynamic graph data-structure to compute such
a sequence of minimum-ratio cycles in an amortized $m^{o(1)}$ time per edge
update. Our key technical contributions are deterministic analogues of the
vertex sparsification and edge sparsification components of the data-structure
from Chen et al. For the vertex sparsification component, we give a method to
avoid the randomness in Chen et al. which involved sampling random trees to
recurse on. For the edge sparsification component, we design a deterministic
algorithm that maintains an embedding of a dynamic graph into a sparse spanner.
We also show how our dynamic spanner can be applied to give a deterministic
data structure that maintains a fully dynamic low-stretch spanning tree on
graphs with polynomially bounded edge lengths, with subpolynomial average
stretch and subpolynomial amortized time per edge update.
</p>
</div>
</dd>
<dt><a name="item304">[304]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16630" title="Abstract">arXiv:2309.16630</a> [<a href="/pdf/2309.16630" title="Download PDF">pdf</a>, <a href="/format/2309.16630" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On Learning with LAD
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jothishwaran%2C+C+A">C. A. Jothishwaran</a>, 
<a href="/search/cs?searchtype=author&query=Srivastava%2C+B">Biplav Srivastava</a>, 
<a href="/search/cs?searchtype=author&query=Singla%2C+J">Jitin Singla</a>, 
<a href="/search/cs?searchtype=author&query=Gangopadhyay%2C+S">Sugata Gangopadhyay</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">The logical analysis of data, LAD, is a technique that yields two-class
classifiers based on Boolean functions having disjunctive normal form (DNF)
representation. Although LAD algorithms employ optimization techniques, the
resulting binary classifiers or binary rules do not lead to overfitting. We
propose a theoretical justification for the absence of overfitting by
estimating the Vapnik-Chervonenkis dimension (VC dimension) for LAD models
where hypothesis sets consist of DNFs with a small number of cubic monomials.
We illustrate and confirm our observations empirically.
</p>
</div>
</dd>
<dt><a name="item305">[305]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16631" title="Abstract">arXiv:2309.16631</a> [<a href="/pdf/2309.16631" title="Download PDF">pdf</a>, <a href="/format/2309.16631" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Robust Offline Reinforcement Learning -- Certify the Confidence Interval
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yao%2C+J">Jiarui Yao</a>, 
<a href="/search/cs?searchtype=author&query=Du%2C+S+S">Simon Shaolei Du</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Currently, reinforcement learning (RL), especially deep RL, has received more
and more attention in the research area. However, the security of RL has been
an obvious problem due to the attack manners becoming mature. In order to
defend against such adversarial attacks, several practical approaches are
developed, such as adversarial training, data filtering, etc. However, these
methods are mostly based on empirical algorithms and experiments, without
rigorous theoretical analysis of the robustness of the algorithms. In this
paper, we develop an algorithm to certify the robustness of a given policy
offline with random smoothing, which could be proven and conducted as
efficiently as ones without random smoothing. Experiments on different
environments confirm the correctness of our algorithm.
</p>
</div>
</dd>
<dt><a name="item306">[306]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16632" title="Abstract">arXiv:2309.16632</a> [<a href="/pdf/2309.16632" title="Download PDF">pdf</a>, <a href="/ps/2309.16632" title="Download PostScript">ps</a>, <a href="/format/2309.16632" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Sparse Submodular Function Minimization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Graur%2C+A">Andrei Graur</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+H">Haotian Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Sidford%2C+A">Aaron Sidford</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to FOCS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>; Optimization and Control (math.OC)

</div>
<p class="mathjax">In this paper we study the problem of minimizing a submodular function $f :
2^V \rightarrow \mathbb{R}$ that is guaranteed to have a $k$-sparse minimizer.
We give a deterministic algorithm that computes an additive
$\epsilon$-approximate minimizer of such $f$ in $\widetilde{O}(\mathsf{poly}(k)
\log(|f|/\epsilon))$ parallel depth using a polynomial number of queries to an
evaluation oracle of $f$, where $|f| = \max_{S \subseteq V} |f(S)|$. Further,
we give a randomized algorithm that computes an exact minimizer of $f$ with
high probability using $\widetilde{O}(|V| \cdot \mathsf{poly}(k))$ queries and
polynomial time. When $k = \widetilde{O}(1)$, our algorithms use either
nearly-constant parallel depth or a nearly-linear number of evaluation oracle
queries. All previous algorithms for this problem either use $\Omega(|V|)$
parallel depth or $\Omega(|V|^2)$ queries.
<br />In contrast to state-of-the-art weakly-polynomial and strongly-polynomial
time algorithms for SFM, our algorithms use first-order optimization methods,
e.g., mirror descent and follow the regularized leader. We introduce what we
call {\em sparse dual certificates}, which encode information on the structure
of sparse minimizers, and both our parallel and sequential algorithms provide
new algorithmic tools for allowing first-order optimization methods to
efficiently compute them. Correspondingly, our algorithm does not invoke fast
matrix multiplication or general linear system solvers and in this sense is
more combinatorial than previous state-of-the-art methods.
</p>
</div>
</dd>
<dt><a name="item307">[307]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16633" title="Abstract">arXiv:2309.16633</a> [<a href="/pdf/2309.16633" title="Download PDF">pdf</a>, <a href="/ps/2309.16633" title="Download PostScript">ps</a>, <a href="/format/2309.16633" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Mixup Your Own Pairs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+Y">Yilei Wu</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+Z">Zijian Dong</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+C">Chongyao Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+W">Wangchunshu Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+J+H">Juan Helen Zhou</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> The first two authors equally contributed to this work
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">In representation learning, regression has traditionally received less
attention than classification. Directly applying representation learning
techniques designed for classification to regression often results in
fragmented representations in the latent space, yielding sub-optimal
performance. In this paper, we argue that the potential of contrastive learning
for regression has been overshadowed due to the neglect of two crucial aspects:
ordinality-awareness and hardness. To address these challenges, we advocate
"mixup your own contrastive pairs for supervised contrastive regression",
instead of relying solely on real/augmented samples. Specifically, we propose
Supervised Contrastive Learning for Regression with Mixup (SupReMix). It takes
anchor-inclusive mixtures (mixup of the anchor and a distinct negative sample)
as hard negative pairs and anchor-exclusive mixtures (mixup of two distinct
negative samples) as hard positive pairs at the embedding level. This strategy
formulates harder contrastive pairs by integrating richer ordinal information.
Through extensive experiments on six regression datasets including 2D images,
volumetric images, text, tabular data, and time-series signals, coupled with
theoretical analysis, we demonstrate that SupReMix pre-training fosters
continuous ordered representations of regression data, resulting in significant
improvement in regression performance. Furthermore, SupReMix is superior to
other approaches in a range of regression challenges including transfer
learning, imbalanced training data, and scenarios with fewer training samples.
</p>
</div>
</dd>
<dt><a name="item308">[308]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16634" title="Abstract">arXiv:2309.16634</a> [<a href="/pdf/2309.16634" title="Download PDF">pdf</a>, <a href="/format/2309.16634" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> End-to-End (Instance)-Image Goal Navigation through Correspondence as an  Emergent Phenomenon
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bono%2C+G">Guillaume Bono</a>, 
<a href="/search/cs?searchtype=author&query=Antsfeld%2C+L">Leonid Antsfeld</a>, 
<a href="/search/cs?searchtype=author&query=Chidlovskii%2C+B">Boris Chidlovskii</a>, 
<a href="/search/cs?searchtype=author&query=Weinzaepfel%2C+P">Philippe Weinzaepfel</a>, 
<a href="/search/cs?searchtype=author&query=Wolf%2C+C">Christian Wolf</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Most recent work in goal oriented visual navigation resorts to large-scale
machine learning in simulated environments. The main challenge lies in learning
compact representations generalizable to unseen environments and in learning
high-capacity perception modules capable of reasoning on high-dimensional
input. The latter is particularly difficult when the goal is not given as a
category ("ObjectNav") but as an exemplar image ("ImageNav"), as the perception
module needs to learn a comparison strategy requiring to solve an underlying
visual correspondence problem. This has been shown to be difficult from reward
alone or with standard auxiliary tasks. We address this problem through a
sequence of two pretext tasks, which serve as a prior for what we argue is one
of the main bottleneck in perception, extremely wide-baseline relative pose
estimation and visibility prediction in complex scenes. The first pretext task,
cross-view completion is a proxy for the underlying visual correspondence
problem, while the second task addresses goal detection and finding directly.
We propose a new dual encoder with a large-capacity binocular ViT model and
show that correspondence solutions naturally emerge from the training signals.
Experiments show significant improvements and SOTA performance on the two
benchmarks, ImageNav and the Instance-ImageNav variant, where camera intrinsics
and height differ between observation and goal.
</p>
</div>
</dd>
<dt><a name="item309">[309]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16635" title="Abstract">arXiv:2309.16635</a> [<a href="/pdf/2309.16635" title="Download PDF">pdf</a>, <a href="/format/2309.16635" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Analysis of the Usability of Automatically Enriched Cultural Heritage  Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Raemy%2C+J+A">Julien Antoine Raemy</a>, 
<a href="/search/cs?searchtype=author&query=Sanderson%2C+R">Robert Sanderson</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This is the preprint version of a chapter submitted to be included in the book "Decoding Cultural Heritage: a critical dissection and taxonomy of human creativity through digital tools", to be published by Springer Nature. The chapter is currently undergoing peer review for potential inclusion in the book
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Digital Libraries (cs.DL)</span>

</div>
<p class="mathjax">This chapter presents the potential of interoperability and standardised data
publication for cultural heritage resources, with a focus on community-driven
approaches and web standards for usability. The Linked Open Usable Data (LOUD)
design principles, which rely on JSON-LD as lingua franca, serve as the
foundation.
<br />We begin by exploring the significant advances made by the International
Image Interoperability Framework (IIIF) in promoting interoperability for
image-based resources. The principles and practices of IIIF have paved the way
for Linked Art, which expands the use of linked data by demonstrating how it
can easily facilitate the integration and sharing of semantic cultural heritage
data across portals and institutions.
<br />To provide a practical demonstration of the concepts discussed, the chapter
highlights the implementation of LUX, the Yale Collections Discovery platform.
LUX serves as a compelling case study for the use of linked data at scale,
demonstrating the real-world application of automated enrichment in the
cultural heritage domain.
<br />Rooted in empirical study, the analysis presented in this chapter delves into
the broader context of community practices and semantic interoperability. By
examining the collaborative efforts and integration of diverse cultural
heritage resources, the research sheds light on the potential benefits and
challenges associated with LOUD.
</p>
</div>
</dd>
<dt><a name="item310">[310]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16639" title="Abstract">arXiv:2309.16639</a> [<a href="/pdf/2309.16639" title="Download PDF">pdf</a>, <a href="/format/2309.16639" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MindShift: Leveraging Large Language Models for Mental-States-Based  Problematic Smartphone Use Intervention
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+R">Ruolan Wu</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+C">Chun Yu</a>, 
<a href="/search/cs?searchtype=author&query=Pan%2C+X">Xiaole Pan</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yujia Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+N">Ningning Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Fu%2C+Y">Yue Fu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yuhan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+Z">Zhi Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+L">Li Chen</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+Q">Qiaolei Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+X">Xuhai Xu</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+Y">Yuanchun Shi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Human-Computer Interaction (cs.HC)

</div>
<p class="mathjax">Problematic smartphone use negatively affects physical and mental health.
Despite the wide range of prior research, existing persuasive techniques are
not flexible enough to provide dynamic persuasion content based on users'
physical contexts and mental states. We first conduct a Wizard-of-Oz study
(N=12) and an interview study (N=10) to summarize the mental states behind
problematic smartphone use: boredom, stress, and inertia. This informs our
design of four persuasion strategies: understanding, comforting, evoking, and
scaffolding habits. We leverage large language models (LLMs) to enable the
automatic and dynamic generation of effective persuasion content. We develop
MindShift, a novel LLM-powered problematic smartphone use intervention
technique. MindShift takes users' in-the-moment physical contexts, mental
states, app usage behaviors, users' goals &amp; habits as input, and generates
high-quality and flexible persuasive content with appropriate persuasion
strategies. We conduct a 5-week field experiment (N=25) to compare MindShift
with baseline techniques. The results show that MindShift significantly
improves intervention acceptance rates by 17.8-22.5% and reduces smartphone use
frequency by 12.1-14.4%. Moreover, users have a significant drop in smartphone
addiction scale scores and a rise in self-efficacy. Our study sheds light on
the potential of leveraging LLMs for context-aware persuasion in other behavior
change domains.
</p>
</div>
</dd>
<dt><a name="item311">[311]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16643" title="Abstract">arXiv:2309.16643</a> [<a href="/pdf/2309.16643" title="Download PDF">pdf</a>, <a href="/format/2309.16643" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deep Geometrized Cartoon Line Inbetweening
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Siyao%2C+L">Li Siyao</a>, 
<a href="/search/cs?searchtype=author&query=Gu%2C+T">Tianpei Gu</a>, 
<a href="/search/cs?searchtype=author&query=Xiao%2C+W">Weiye Xiao</a>, 
<a href="/search/cs?searchtype=author&query=Ding%2C+H">Henghui Ding</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Ziwei Liu</a>, 
<a href="/search/cs?searchtype=author&query=Loy%2C+C+C">Chen Change Loy</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ICCV 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">We aim to address a significant but understudied problem in the anime
industry, namely the inbetweening of cartoon line drawings. Inbetweening
involves generating intermediate frames between two black-and-white line
drawings and is a time-consuming and expensive process that can benefit from
automation. However, existing frame interpolation methods that rely on matching
and warping whole raster images are unsuitable for line inbetweening and often
produce blurring artifacts that damage the intricate line structures. To
preserve the precision and detail of the line drawings, we propose a new
approach, AnimeInbet, which geometrizes raster line drawings into graphs of
endpoints and reframes the inbetweening task as a graph fusion problem with
vertex repositioning. Our method can effectively capture the sparsity and
unique structure of line drawings while preserving the details during
inbetweening. This is made possible via our novel modules, i.e., vertex
geometric embedding, a vertex correspondence Transformer, an effective
mechanism for vertex repositioning and a visibility predictor. To train our
method, we introduce MixamoLine240, a new dataset of line drawings with ground
truth vectorization and matching labels. Our experiments demonstrate that
AnimeInbet synthesizes high-quality, clean, and complete intermediate line
drawings, outperforming existing methods quantitatively and qualitatively,
especially in cases with large motions. Data and code are available at
https://github.com/lisiyao21/AnimeInbet.
</p>
</div>
</dd>
<dt><a name="item312">[312]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16645" title="Abstract">arXiv:2309.16645</a> [<a href="/pdf/2309.16645" title="Download PDF">pdf</a>, <a href="/format/2309.16645" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Reusability report: Prostate cancer stratification with diverse  biologically-informed neural architectures
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pedersen%2C+C">Christian Pedersen</a>, 
<a href="/search/cs?searchtype=author&query=Tesileanu%2C+T">Tiberiu Tesileanu</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+T">Tinghui Wu</a>, 
<a href="/search/cs?searchtype=author&query=Golkar%2C+S">Siavash Golkar</a>, 
<a href="/search/cs?searchtype=author&query=Cranmer%2C+M">Miles Cranmer</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zijun Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Ho%2C+S">Shirley Ho</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages, 3 figures. Submitted to Nature Machine Intelligence: Matters Arising
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">In, Elmarakeby et al., "Biologically informed deep neural network for
prostate cancer discovery", a feedforward neural network with biologically
informed, sparse connections (P-NET) was presented to model the state of
prostate cancer. We verified the reproducibility of the study conducted by
Elmarakeby et al., using both their original codebase, and our own
re-implementation using more up-to-date libraries. We quantified the
contribution of network sparsification by Reactome biological pathways, and
confirmed its importance to P-NET's superior performance. Furthermore, we
explored alternative neural architectures and approaches to incorporating
biological information into the networks. We experimented with three types of
graph neural networks on the same training data, and investigated the clinical
prediction agreement between different models. Our analyses demonstrated that
deep neural networks with distinct architectures make incorrect predictions for
individual patient that are persistent across different initializations of a
specific neural architecture. This suggests that different neural architectures
are sensitive to different aspects of the data, an important yet under-explored
challenge for clinical prediction tasks.
</p>
</div>
</dd>
<dt><a name="item313">[313]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16646" title="Abstract">arXiv:2309.16646</a> [<a href="/pdf/2309.16646" title="Download PDF">pdf</a>, <a href="/format/2309.16646" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Improving Equivariance in State-of-the-Art Supervised Depth and Normal  Predictors
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhong%2C+Y">Yuanyi Zhong</a>, 
<a href="/search/cs?searchtype=author&query=Bhattad%2C+A">Anand Bhattad</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yu-Xiong Wang</a>, 
<a href="/search/cs?searchtype=author&query=Forsyth%2C+D">David Forsyth</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ICCV 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Dense depth and surface normal predictors should possess the equivariant
property to cropping-and-resizing -- cropping the input image should result in
cropping the same output image. However, we find that state-of-the-art depth
and normal predictors, despite having strong performances, surprisingly do not
respect equivariance. The problem exists even when crop-and-resize data
augmentation is employed during training. To remedy this, we propose an
equivariant regularization technique, consisting of an averaging procedure and
a self-consistency loss, to explicitly promote cropping-and-resizing
equivariance in depth and normal networks. Our approach can be applied to both
CNN and Transformer architectures, does not incur extra cost during testing,
and notably improves the supervised and semi-supervised learning performance of
dense predictors on Taskonomy tasks. Finally, finetuning with our loss on
unlabeled images improves not only equivariance but also accuracy of
state-of-the-art depth and normal predictors when evaluated on NYU-v2. GitHub
link: https://github.com/mikuhatsune/equivariance
</p>
</div>
</dd>
<dt><a name="item314">[314]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16649" title="Abstract">arXiv:2309.16649</a> [<a href="/pdf/2309.16649" title="Download PDF">pdf</a>, <a href="/format/2309.16649" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FLIP: Cross-domain Face Anti-spoofing with Language Guidance
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Srivatsan%2C+K">Koushik Srivatsan</a>, 
<a href="/search/cs?searchtype=author&query=Naseer%2C+M">Muzammal Naseer</a>, 
<a href="/search/cs?searchtype=author&query=Nandakumar%2C+K">Karthik Nandakumar</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to ICCV-2023. Project Page: <a href="https://koushiksrivats.github.io/FLIP/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Face anti-spoofing (FAS) or presentation attack detection is an essential
component of face recognition systems deployed in security-critical
applications. Existing FAS methods have poor generalizability to unseen spoof
types, camera sensors, and environmental conditions. Recently, vision
transformer (ViT) models have been shown to be effective for the FAS task due
to their ability to capture long-range dependencies among image patches.
However, adaptive modules or auxiliary loss functions are often required to
adapt pre-trained ViT weights learned on large-scale datasets such as ImageNet.
In this work, we first show that initializing ViTs with multimodal (e.g., CLIP)
pre-trained weights improves generalizability for the FAS task, which is in
line with the zero-shot transfer capabilities of vision-language pre-trained
(VLP) models. We then propose a novel approach for robust cross-domain FAS by
grounding visual representations with the help of natural language.
Specifically, we show that aligning the image representation with an ensemble
of class descriptions (based on natural language semantics) improves FAS
generalizability in low-data regimes. Finally, we propose a multimodal
contrastive learning strategy to boost feature generalization further and
bridge the gap between source and target domains. Extensive experiments on
three standard protocols demonstrate that our method significantly outperforms
the state-of-the-art methods, achieving better zero-shot transfer performance
than five-shot transfer of adaptive ViTs. Code:
https://github.com/koushiksrivats/FLIP
</p>
</div>
</dd>
<dt><a name="item315">[315]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16650" title="Abstract">arXiv:2309.16650</a> [<a href="/pdf/2309.16650" title="Download PDF">pdf</a>, <a href="/format/2309.16650" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ConceptGraphs: Open-Vocabulary 3D Scene Graphs for Perception and  Planning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gu%2C+Q">Qiao Gu</a>, 
<a href="/search/cs?searchtype=author&query=Kuwajerwala%2C+A">Alihusein Kuwajerwala</a>, 
<a href="/search/cs?searchtype=author&query=Morin%2C+S">Sacha Morin</a>, 
<a href="/search/cs?searchtype=author&query=Jatavallabhula%2C+K+M">Krishna Murthy Jatavallabhula</a>, 
<a href="/search/cs?searchtype=author&query=Sen%2C+B">Bipasha Sen</a>, 
<a href="/search/cs?searchtype=author&query=Agarwal%2C+A">Aditya Agarwal</a>, 
<a href="/search/cs?searchtype=author&query=Rivera%2C+C">Corban Rivera</a>, 
<a href="/search/cs?searchtype=author&query=Paul%2C+W">William Paul</a>, 
<a href="/search/cs?searchtype=author&query=Ellis%2C+K">Kirsty Ellis</a>, 
<a href="/search/cs?searchtype=author&query=Chellappa%2C+R">Rama Chellappa</a>, 
<a href="/search/cs?searchtype=author&query=Gan%2C+C">Chuang Gan</a>, 
<a href="/search/cs?searchtype=author&query=de+Melo%2C+C+M">Celso Miguel de Melo</a>, 
<a href="/search/cs?searchtype=author&query=Tenenbaum%2C+J+B">Joshua B. Tenenbaum</a>, 
<a href="/search/cs?searchtype=author&query=Torralba%2C+A">Antonio Torralba</a>, 
<a href="/search/cs?searchtype=author&query=Shkurti%2C+F">Florian Shkurti</a>, 
<a href="/search/cs?searchtype=author&query=Paull%2C+L">Liam Paull</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project page: <a href="https://concept-graphs.github.io/">this https URL</a> Explainer video: <a href="https://youtu.be/mRhNkQwRYnc">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">For robots to perform a wide variety of tasks, they require a 3D
representation of the world that is semantically rich, yet compact and
efficient for task-driven perception and planning. Recent approaches have
attempted to leverage features from large vision-language models to encode
semantics in 3D representations. However, these approaches tend to produce maps
with per-point feature vectors, which do not scale well in larger environments,
nor do they contain semantic spatial relationships between entities in the
environment, which are useful for downstream planning. In this work, we propose
ConceptGraphs, an open-vocabulary graph-structured representation for 3D
scenes. ConceptGraphs is built by leveraging 2D foundation models and fusing
their output to 3D by multi-view association. The resulting representations
generalize to novel semantic classes, without the need to collect large 3D
datasets or finetune models. We demonstrate the utility of this representation
through a number of downstream planning tasks that are specified through
abstract (language) prompts and require complex reasoning over spatial and
semantic concepts. (Project page: https://concept-graphs.github.io/ Explainer
video: https://youtu.be/mRhNkQwRYnc )
</p>
</div>
</dd>
<dt><a name="item316">[316]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16652" title="Abstract">arXiv:2309.16652</a> [<a href="/pdf/2309.16652" title="Download PDF">pdf</a>, <a href="/format/2309.16652" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Perceiving Extrinsic Contacts from Touch Improves Learning Insertion  Policies
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Higuera%2C+C">Carolina Higuera</a>, 
<a href="/search/cs?searchtype=author&query=Ortiz%2C+J">Joseph Ortiz</a>, 
<a href="/search/cs?searchtype=author&query=Qi%2C+H">Haozhi Qi</a>, 
<a href="/search/cs?searchtype=author&query=Pineda%2C+L">Luis Pineda</a>, 
<a href="/search/cs?searchtype=author&query=Boots%2C+B">Byron Boots</a>, 
<a href="/search/cs?searchtype=author&query=Mukadam%2C+M">Mustafa Mukadam</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Under review
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Robotic manipulation tasks such as object insertion typically involve
interactions between object and environment, namely extrinsic contacts. Prior
work on Neural Contact Fields (NCF) use intrinsic tactile sensing between
gripper and object to estimate extrinsic contacts in simulation. However, its
effectiveness and utility in real-world tasks remains unknown.
<br />In this work, we improve NCF to enable sim-to-real transfer and use it to
train policies for mug-in-cupholder and bowl-in-dishrack insertion tasks. We
find our model NCF-v2, is capable of estimating extrinsic contacts in the
real-world. Furthermore, our insertion policy with NCF-v2 outperforms policies
without it, achieving 33% higher success and 1.36x faster execution on
mug-in-cupholder, and 13% higher success and 1.27x faster execution on
bowl-in-dishrack.
</p>
</div>
</dd>
<dt><a name="item317">[317]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16653" title="Abstract">arXiv:2309.16653</a> [<a href="/pdf/2309.16653" title="Download PDF">pdf</a>, <a href="/format/2309.16653" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DreamGaussian: Generative Gaussian Splatting for Efficient 3D Content  Creation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tang%2C+J">Jiaxiang Tang</a>, 
<a href="/search/cs?searchtype=author&query=Ren%2C+J">Jiawei Ren</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+H">Hang Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Ziwei Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zeng%2C+G">Gang Zeng</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> project page: <a href="https://dreamgaussian.github.io/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Recent advances in 3D content creation mostly leverage optimization-based 3D
generation via score distillation sampling (SDS). Though promising results have
been exhibited, these methods often suffer from slow per-sample optimization,
limiting their practical usage. In this paper, we propose DreamGaussian, a
novel 3D content generation framework that achieves both efficiency and quality
simultaneously. Our key insight is to design a generative 3D Gaussian Splatting
model with companioned mesh extraction and texture refinement in UV space. In
contrast to the occupancy pruning used in Neural Radiance Fields, we
demonstrate that the progressive densification of 3D Gaussians converges
significantly faster for 3D generative tasks. To further enhance the texture
quality and facilitate downstream applications, we introduce an efficient
algorithm to convert 3D Gaussians into textured meshes and apply a fine-tuning
stage to refine the details. Extensive experiments demonstrate the superior
efficiency and competitive generation quality of our proposed approach.
Notably, DreamGaussian produces high-quality textured meshes in just 2 minutes
from a single-view image, achieving approximately 10 times acceleration
compared to existing methods.
</p>
</div>
</dd>
<dt><a name="item318">[318]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16654" title="Abstract">arXiv:2309.16654</a> [<a href="/pdf/2309.16654" title="Download PDF">pdf</a>, <a href="/format/2309.16654" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Novel Deep Learning Pipeline for Automatic Weapon Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sivakumar%2C+H">Haribharathi Sivakumar</a>, 
<a href="/search/cs?searchtype=author&query=R%2C+V+A">Vijay Arvind.R</a>, 
<a href="/search/cs?searchtype=author&query=V%2C+P+R">Pawan Ragavendhar V</a>, 
<a href="/search/cs?searchtype=author&query=Balamurugan%2C+G">G.Balamurugan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted for presentation at the IEEE 2nd International Conference on Automation, Robotics and Computer Engineering
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Weapon and gun violence have recently become a pressing issue today. The
degree of these crimes and activities has risen to the point of being termed as
an epidemic. This prevalent misuse of weapons calls for an automatic system
that detects weapons in real-time. Real-time surveillance video is captured and
recorded in almost all public forums and places. These videos contain abundant
raw data which can be extracted and processed into meaningful information. This
paper proposes a novel pipeline consisting of an ensemble of convolutional
neural networks with distinct architectures. Each neural network is trained
with a unique mini-batch with little to no overlap in the training samples.
This paper will present several promising results using multiple datasets
associated with comparing the proposed architecture and state-of-the-art (SoA)
models. The proposed pipeline produced an average increase of 5% in accuracy,
specificity, and recall compared to the SoA systems.
</p>
</div>
</dd>
<dt><a name="item319">[319]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16656" title="Abstract">arXiv:2309.16656</a> [<a href="/pdf/2309.16656" title="Download PDF">pdf</a>, <a href="/format/2309.16656" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Visual In-Context Learning for Few-Shot Eczema Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kumar%2C+N">Neelesh Kumar</a>, 
<a href="/search/cs?searchtype=author&query=Aran%2C+O">Oya Aran</a>, 
<a href="/search/cs?searchtype=author&query=Vasudevan%2C+V">Venugopal Vasudevan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Automated diagnosis of eczema from digital camera images is crucial for
developing applications that allow patients to self-monitor their recovery. An
important component of this is the segmentation of eczema region from such
images. Current methods for eczema segmentation rely on deep neural networks
such as convolutional (CNN)-based U-Net or transformer-based Swin U-Net. While
effective, these methods require high volume of annotated data, which can be
difficult to obtain. Here, we investigate the capabilities of visual in-context
learning that can perform few-shot eczema segmentation with just a handful of
examples and without any need for retraining models. Specifically, we propose a
strategy for applying in-context learning for eczema segmentation with a
generalist vision model called SegGPT. When benchmarked on a dataset of
annotated eczema images, we show that SegGPT with just 2 representative example
images from the training dataset performs better (mIoU: 36.69) than a CNN U-Net
trained on 428 images (mIoU: 32.60). We also discover that using more number of
examples for SegGPT may in fact be harmful to its performance. Our result
highlights the importance of visual in-context learning in developing faster
and better solutions to skin imaging tasks. Our result also paves the way for
developing inclusive solutions that can cater to minorities in the demographics
who are typically heavily under-represented in the training data.
</p>
</div>
</dd>
<dt><a name="item320">[320]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16661" title="Abstract">arXiv:2309.16661</a> [<a href="/pdf/2309.16661" title="Download PDF">pdf</a>, <a href="/format/2309.16661" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SA2-Net: Scale-aware Attention Network for Microscopic Image  Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fiaz%2C+M">Mustansar Fiaz</a>, 
<a href="/search/cs?searchtype=author&query=Heidari%2C+M">Moein Heidari</a>, 
<a href="/search/cs?searchtype=author&query=Anwer%2C+R+M">Rao Muhammad Anwer</a>, 
<a href="/search/cs?searchtype=author&query=Cholakkal%2C+H">Hisham Cholakkal</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> BMVC 2023 accepted as oral
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Microscopic image segmentation is a challenging task, wherein the objective
is to assign semantic labels to each pixel in a given microscopic image. While
convolutional neural networks (CNNs) form the foundation of many existing
frameworks, they often struggle to explicitly capture long-range dependencies.
Although transformers were initially devised to address this issue using
self-attention, it has been proven that both local and global features are
crucial for addressing diverse challenges in microscopic images, including
variations in shape, size, appearance, and target region density. In this
paper, we introduce SA2-Net, an attention-guided method that leverages
multi-scale feature learning to effectively handle diverse structures within
microscopic images. Specifically, we propose scale-aware attention (SA2) module
designed to capture inherent variations in scales and shapes of microscopic
regions, such as cells, for accurate segmentation. This module incorporates
local attention at each level of multi-stage features, as well as global
attention across multiple resolutions. Furthermore, we address the issue of
blurred region boundaries (e.g., cell boundaries) by introducing a novel
upsampling strategy called the Adaptive Up-Attention (AuA) module. This module
enhances the discriminative ability for improved localization of microscopic
regions using an explicit attention mechanism. Extensive experiments on five
challenging datasets demonstrate the benefits of our SA2-Net model. Our source
code is publicly available at \url{https://github.com/mustansarfiaz/SA2-Net}.
</p>
</div>
</dd>
<dt><a name="item321">[321]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16662" title="Abstract">arXiv:2309.16662</a> [<a href="/pdf/2309.16662" title="Download PDF">pdf</a>, <a href="/format/2309.16662" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Geodesic Regression Characterizes 3D Shape Changes in the Female Brain  During Menstruation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Myers%2C+A">Adele Myers</a>, 
<a href="/search/cs?searchtype=author&query=Taylor%2C+C">Caitlin Taylor</a>, 
<a href="/search/cs?searchtype=author&query=Jacobs%2C+E">Emily Jacobs</a>, 
<a href="/search/cs?searchtype=author&query=Miolane%2C+N">Nina Miolane</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> In Proceedings of the ICCV Conference Workshop: Computer Vision for Automated Medical Diagnosis. Institute of Electrical and Electronics Engineers Inc. (2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Women are at higher risk of Alzheimer's and other neurological diseases after
menopause, and yet research connecting female brain health to sex hormone
fluctuations is limited. We seek to investigate this connection by developing
tools that quantify 3D shape changes that occur in the brain during sex hormone
fluctuations. Geodesic regression on the space of 3D discrete surfaces offers a
principled way to characterize the evolution of a brain's shape. However, in
its current form, this approach is too computationally expensive for practical
use. In this paper, we propose approximation schemes that accelerate geodesic
regression on shape spaces of 3D discrete surfaces. We also provide rules of
thumb for when each approximation can be used. We test our approach on
synthetic data to quantify the speed-accuracy trade-off of these approximations
and show that practitioners can expect very significant speed-up while only
sacrificing little accuracy. Finally, we apply the method to real brain shape
data and produce the first characterization of how the female hippocampus
changes shape during the menstrual cycle as a function of progesterone: a
characterization made (practically) possible by our approximation schemes. Our
work paves the way for comprehensive, practical shape analyses in the fields of
bio-medicine and computer vision. Our implementation is publicly available on
GitHub: https://github.com/bioshape-lab/my28brains.
</p>
</div>
</dd>
<dt><a name="item322">[322]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16663" title="Abstract">arXiv:2309.16663</a> [<a href="/pdf/2309.16663" title="Download PDF">pdf</a>, <a href="/format/2309.16663" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> HyperPPO: A scalable method for finding small policies for robotic  control
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hegde%2C+S">Shashank Hegde</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+Z">Zhehui Huang</a>, 
<a href="/search/cs?searchtype=author&query=Sukhatme%2C+G+S">Gaurav S. Sukhatme</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Website: <a href="https://sites.google.com/usc.edu/hyperppo">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Models with fewer parameters are necessary for the neural control of
memory-limited, performant robots. Finding these smaller neural network
architectures can be time-consuming. We propose HyperPPO, an on-policy
reinforcement learning algorithm that utilizes graph hypernetworks to estimate
the weights of multiple neural architectures simultaneously. Our method
estimates weights for networks that are much smaller than those in common-use
networks yet encode highly performant policies. We obtain multiple trained
policies at the same time while maintaining sample efficiency and provide the
user the choice of picking a network architecture that satisfies their
computational constraints. We show that our method scales well - more training
resources produce faster convergence to higher-performing architectures. We
demonstrate that the neural policies estimated by HyperPPO are capable of
decentralized control of a Crazyflie2.1 quadrotor. Website:
https://sites.google.com/usc.edu/hyperppo
</p>
</div>
</dd>
<dt><a name="item323">[323]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16668" title="Abstract">arXiv:2309.16668</a> [<a href="/pdf/2309.16668" title="Download PDF">pdf</a>, <a href="/format/2309.16668" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> RealFill: Reference-Driven Generation for Authentic Image Completion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tang%2C+L">Luming Tang</a>, 
<a href="/search/cs?searchtype=author&query=Ruiz%2C+N">Nataniel Ruiz</a>, 
<a href="/search/cs?searchtype=author&query=Chu%2C+Q">Qinghao Chu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yuanzhen Li</a>, 
<a href="/search/cs?searchtype=author&query=Holynski%2C+A">Aleksander Holynski</a>, 
<a href="/search/cs?searchtype=author&query=Jacobs%2C+D+E">David E. Jacobs</a>, 
<a href="/search/cs?searchtype=author&query=Hariharan%2C+B">Bharath Hariharan</a>, 
<a href="/search/cs?searchtype=author&query=Pritch%2C+Y">Yael Pritch</a>, 
<a href="/search/cs?searchtype=author&query=Wadhwa%2C+N">Neal Wadhwa</a>, 
<a href="/search/cs?searchtype=author&query=Aberman%2C+K">Kfir Aberman</a>, 
<a href="/search/cs?searchtype=author&query=Rubinstein%2C+M">Michael Rubinstein</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project page: <a href="https://realfill.github.io">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Graphics (cs.GR); Machine Learning (cs.LG)

</div>
<p class="mathjax">Recent advances in generative imagery have brought forth outpainting and
inpainting models that can produce high-quality, plausible image content in
unknown regions, but the content these models hallucinate is necessarily
inauthentic, since the models lack sufficient context about the true scene. In
this work, we propose RealFill, a novel generative approach for image
completion that fills in missing regions of an image with the content that
should have been there. RealFill is a generative inpainting model that is
personalized using only a few reference images of a scene. These reference
images do not have to be aligned with the target image, and can be taken with
drastically varying viewpoints, lighting conditions, camera apertures, or image
styles. Once personalized, RealFill is able to complete a target image with
visually compelling contents that are faithful to the original scene. We
evaluate RealFill on a new image completion benchmark that covers a set of
diverse and challenging scenarios, and find that it outperforms existing
approaches by a large margin. See more results on our project page:
https://realfill.github.io
</p>
</div>
</dd>
<dt><a name="item324">[324]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16669" title="Abstract">arXiv:2309.16669</a> [<a href="/pdf/2309.16669" title="Download PDF">pdf</a>, <a href="/format/2309.16669" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Training a Large Video Model on a Single Machine in a Day
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Y">Yue Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Kr%C3%A4henb%C3%BChl%2C+P">Philipp Kr&#xe4;henb&#xfc;hl</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Tech report. Code is available at <a href="https://github.com/zhaoyue-zephyrus/AVION">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Videos are big, complex to pre-process, and slow to train on.
State-of-the-art large-scale video models are trained on clusters of 32 or more
GPUs for several days. As a consequence, academia largely ceded the training of
large video models to industry. In this paper, we show how to still train a
state-of-the-art video model on a single machine with eight consumer-grade GPUs
in a day. We identify three bottlenecks, IO, CPU, and GPU computation, and
optimize each. The result is a highly efficient video training pipeline. For
comparable architectures, our pipeline achieves higher accuracies with
$\frac{1}{8}$ of the computation compared to prior work. Code is available at
https://github.com/zhaoyue-zephyrus/AVION.
</p>
</div>
</dd>
<dt><a name="item325">[325]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16670" title="Abstract">arXiv:2309.16670</a> [<a href="/pdf/2309.16670" title="Download PDF">pdf</a>, <a href="/format/2309.16670" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Decaf: Monocular Deformation Capture for Face and Hand Interactions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shimada%2C+S">Soshi Shimada</a>, 
<a href="/search/cs?searchtype=author&query=Golyanik%2C+V">Vladislav Golyanik</a>, 
<a href="/search/cs?searchtype=author&query=P%C3%A9rez%2C+P">Patrick P&#xe9;rez</a>, 
<a href="/search/cs?searchtype=author&query=Theobalt%2C+C">Christian Theobalt</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Graphics (cs.GR); Human-Computer Interaction (cs.HC)

</div>
<p class="mathjax">Existing methods for 3D tracking from monocular RGB videos predominantly
consider articulated and rigid objects. Modelling dense non-rigid object
deformations in this setting remained largely unaddressed so far, although such
effects can improve the realism of the downstream applications such as AR/VR
and avatar communications. This is due to the severe ill-posedness of the
monocular view setting and the associated challenges. While it is possible to
naively track multiple non-rigid objects independently using 3D templates or
parametric 3D models, such an approach would suffer from multiple artefacts in
the resulting 3D estimates such as depth ambiguity, unnatural intra-object
collisions and missing or implausible deformations. Hence, this paper
introduces the first method that addresses the fundamental challenges depicted
above and that allows tracking human hands interacting with human faces in 3D
from single monocular RGB videos. We model hands as articulated objects
inducing non-rigid face deformations during an active interaction. Our method
relies on a new hand-face motion and interaction capture dataset with realistic
face deformations acquired with a markerless multi-view camera system. As a
pivotal step in its creation, we process the reconstructed raw 3D shapes with
position-based dynamics and an approach for non-uniform stiffness estimation of
the head tissues, which results in plausible annotations of the surface
deformations, hand-face contact regions and head-hand positions. At the core of
our neural approach are a variational auto-encoder supplying the hand-face
depth prior and modules that guide the 3D tracking by estimating the contacts
and the deformations. Our final 3D hand and face reconstructions are realistic
and more plausible compared to several baselines applicable in our setting,
both quantitatively and qualitatively.
https://vcai.mpi-inf.mpg.de/projects/Decaf
</p>
</div>
</dd>
<dt><a name="item326">[326]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16671" title="Abstract">arXiv:2309.16671</a> [<a href="/pdf/2309.16671" title="Download PDF">pdf</a>, <a href="/format/2309.16671" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Demystifying CLIP Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+H">Hu Xu</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+S">Saining Xie</a>, 
<a href="/search/cs?searchtype=author&query=Tan%2C+X+E">Xiaoqing Ellen Tan</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+P">Po-Yao Huang</a>, 
<a href="/search/cs?searchtype=author&query=Howes%2C+R">Russell Howes</a>, 
<a href="/search/cs?searchtype=author&query=Sharma%2C+V">Vasu Sharma</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+S">Shang-Wen Li</a>, 
<a href="/search/cs?searchtype=author&query=Ghosh%2C+G">Gargi Ghosh</a>, 
<a href="/search/cs?searchtype=author&query=Zettlemoyer%2C+L">Luke Zettlemoyer</a>, 
<a href="/search/cs?searchtype=author&query=Feichtenhofer%2C+C">Christoph Feichtenhofer</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 17 pages. arXiv admin note: text overlap with <a href="/abs/2103.00020">arXiv:2103.00020</a> by other authors
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Computation and Language (cs.CL)

</div>
<p class="mathjax">Contrastive Language-Image Pre-training (CLIP) is an approach that has
advanced research and applications in computer vision, fueling modern
recognition systems and generative models. We believe that the main ingredient
to the success of CLIP is its data and not the model architecture or
pre-training objective. However, CLIP only provides very limited information
about its data and how it has been collected, leading to works that aim to
reproduce CLIP's data by filtering with its model parameters. In this work, we
intend to reveal CLIP's data curation approach and in our pursuit of making it
open to the community introduce Metadata-Curated Language-Image Pre-training
(MetaCLIP). MetaCLIP takes a raw data pool and metadata (derived from CLIP's
concepts) and yields a balanced subset over the metadata distribution. Our
experimental study rigorously isolates the model and training settings,
concentrating solely on data. MetaCLIP applied to CommonCrawl with 400M
image-text data pairs outperforms CLIP's data on multiple standard benchmarks.
In zero-shot ImageNet classification, MetaCLIP achieves 70.8% accuracy,
surpassing CLIP's 68.3% on ViT-B models. Scaling to 1B data, while maintaining
the same training budget, attains 72.4%. Our observations hold across various
model sizes, exemplified by ViT-H achieving 80.5%, without any
bells-and-whistles. Curation code and training data distribution on metadata is
made available at https://github.com/facebookresearch/MetaCLIP.
</p>
</div>
</dd>
<dt><a name="item327">[327]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16672" title="Abstract">arXiv:2309.16672</a> [<a href="/pdf/2309.16672" title="Download PDF">pdf</a>, <a href="/format/2309.16672" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning to Transform for Generalizable Instance-wise Invariance
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Singhal%2C+U">Utkarsh Singhal</a>, 
<a href="/search/cs?searchtype=author&query=Esteves%2C+C">Carlos Esteves</a>, 
<a href="/search/cs?searchtype=author&query=Makadia%2C+A">Ameesh Makadia</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+S+X">Stella X. Yu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to ICCV 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Computer vision research has long aimed to build systems that are robust to
spatial transformations found in natural data. Traditionally, this is done
using data augmentation or hard-coding invariances into the architecture.
However, too much or too little invariance can hurt, and the correct amount is
unknown a priori and dependent on the instance. Ideally, the appropriate
invariance would be learned from data and inferred at test-time.
<br />We treat invariance as a prediction problem. Given any image, we use a
normalizing flow to predict a distribution over transformations and average the
predictions over them. Since this distribution only depends on the instance, we
can align instances before classifying them and generalize invariance across
classes. The same distribution can also be used to adapt to out-of-distribution
poses. This normalizing flow is trained end-to-end and can learn a much larger
range of transformations than Augerino and InstaAug. When used as data
augmentation, our method shows accuracy and robustness gains on CIFAR 10,
CIFAR10-LT, and TinyImageNet.
</p>
</div>
</dd>
</dl>
<h3>Cross-lists for Fri, 29 Sep 23</h3>
<dl>
<dt><a name="item328">[328]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15856" title="Abstract">arXiv:2309.15856</a> (cross-list from quant-ph) [<a href="/pdf/2309.15856" title="Download PDF">pdf</a>, <a href="/format/2309.15856" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Secure and Efficient Two-party Quantum Scalar Product Protocol With  Application to Privacy-preserving Matrix Multiplication
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Liu%2C+W">Wen-Jie Liu</a>, 
<a href="/search/quant-ph?searchtype=author&query=Li%2C+Z">Zi-Xian Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 15 pages, 4 figures
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> IEEE Transactions on Circuits and Systems I: Regular Papers, 2023:
  online
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Cryptography and Security (cs.CR); Emerging Technologies (cs.ET)

</div>
<p class="mathjax">Secure two-party scalar product (S2SP) is a promising research area within
secure multiparty computation (SMC), which can solve a range of SMC problems,
such as intrusion detection, data analysis, and geometric computations.
However, existing quantum S2SP protocols are not efficient enough, and the
complexity is usually close to exponential level. In this paper, a novel secure
two-party quantum scalar product (S2QSP) protocol based on Fourier entangled
states is proposed to achieve higher efficiency. Firstly, the definition of
unconditional security under malicious models is given. And then, an honesty
verification method called Entanglement Bondage is proposed, which is used in
conjunction with the modular summation gate to resist malicious attacks. The
property of Fourier entangled states is used to calculate the scalar product
with polynomial complexity. The unconditional security of our protocol is
proved, which guarantees the privacy of all parties. In addition, we design a
privacy-preserving quantum matrix multiplication protocol based on S2QSP
protocol. By transforming matrix multiplication into a series of scalar product
processes, the product of two private matrices is calculated without revealing
any privacy. Finally, we show our protocol's feasibility in IBM Qiskit
simulator.
</p>
</div>
</dd>
<dt><a name="item329">[329]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15889" title="Abstract">arXiv:2309.15889</a> (cross-list from eess.IV) [<a href="/pdf/2309.15889" title="Download PDF">pdf</a>, <a href="/format/2309.15889" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> High Perceptual Quality Wireless Image Delivery with Denoising Diffusion  Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Yilmaz%2C+S+F">Selim F. Yilmaz</a>, 
<a href="/search/eess?searchtype=author&query=Niu%2C+X">Xueyan Niu</a>, 
<a href="/search/eess?searchtype=author&query=Bai%2C+B">Bo Bai</a>, 
<a href="/search/eess?searchtype=author&query=Han%2C+W">Wei Han</a>, 
<a href="/search/eess?searchtype=author&query=Deng%2C+L">Lei Deng</a>, 
<a href="/search/eess?searchtype=author&query=Gunduz%2C+D">Deniz Gunduz</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages, 4 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG); Multimedia (cs.MM)

</div>
<p class="mathjax">We consider the image transmission problem over a noisy wireless channel via
deep learning-based joint source-channel coding (DeepJSCC) along with a
denoising diffusion probabilistic model (DDPM) at the receiver. Specifically,
we are interested in the perception-distortion trade-off in the practical
finite block length regime, in which separate source and channel coding can be
highly suboptimal. We introduce a novel scheme that utilizes the range-null
space decomposition of the target image. We transmit the range-space of the
image after encoding and employ DDPM to progressively refine its null space
contents. Through extensive experiments, we demonstrate significant
improvements in distortion and perceptual quality of reconstructed images
compared to standard DeepJSCC and the state-of-the-art generative
learning-based method. We will publicly share our source code to facilitate
further research and reproducibility.
</p>
</div>
</dd>
<dt><a name="item330">[330]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15908" title="Abstract">arXiv:2309.15908</a> (cross-list from physics.ed-ph) [<a href="/pdf/2309.15908" title="Download PDF">pdf</a>, <a href="/format/2309.15908" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> QuCS: A Lecture Series on Quantum Computer Software and System
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Liang%2C+Z">Zhiding Liang</a>, 
<a href="/search/physics?searchtype=author&query=Wang%2C+H">Hanrui Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Physics Education (physics.ed-ph)</span>; Hardware Architecture (cs.AR); Quantum Physics (quant-ph)

</div>
<p class="mathjax">In this era of incessant advancements in quantum computing, bridging the gap
between quantum algorithms' hardware requisites and available devices has
become crucial. A prime focus in this context is the Software and System Level
support for quantum computers, which has shown promising potential in
significantly decreasing this gap. However, a noteworthy deficit of quantum
software and system level-focused courses has been observed in academia
worldwide. Addressing this deficiency, this paper proposes the Quantum Computer
Systems (QuCS) Lecture Series. The QuCS Lecture Series aims to enhance the
visibility of quantum computing software and system level and foster diverse
participation in quantum computing research across multiple universities
worldwide. It is envisioned as an inclusive platform to bring together
individuals of diverse backgrounds, catalyzing cross-cultural collaboration and
innovation in this burgeoning field. The lecture series begins with an
introductory session elucidating the core concepts and fundamentals of quantum
computing. This foundational knowledge will be built upon in subsequent
sessions, highlighting cutting-edge research trends and recent findings in
quantum software and system level. This paper provides a comprehensive overview
of the QuCS Lecture Series, detailing the format, the gamut of topics to be
covered, and their significance. It emphasizes the potential impact of the
series on accelerating progress towards quantum supremacy and fostering a
diverse, global community of quantum computing researchers and practitioners.
The QuCS Lecture Series has already hosted nearly 40 lectures with over 40
confirmed speakers from more than eight different countries and from both
academia and industry, QuCS also attracted more than 1000 subscribers from all
over the world.
</p>
</div>
</dd>
<dt><a name="item331">[331]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15919" title="Abstract">arXiv:2309.15919</a> (cross-list from quant-ph) [<a href="/pdf/2309.15919" title="Download PDF">pdf</a>, <a href="/ps/2309.15919" title="Download PostScript">ps</a>, <a href="/format/2309.15919" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Efficient Computation of the Quantum Rate-Distortion Function
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=He%2C+K">Kerry He</a>, 
<a href="/search/quant-ph?searchtype=author&query=Saunderson%2C+J">James Saunderson</a>, 
<a href="/search/quant-ph?searchtype=author&query=Fawzi%2C+H">Hamza Fawzi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 37 pages, 2 figures, 2 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Information Theory (cs.IT); Optimization and Control (math.OC)

</div>
<p class="mathjax">The quantum rate-distortion function plays a fundamental role in quantum
information theory, however there is currently no practical algorithm which can
efficiently compute this function to high accuracy for moderate channel
dimensions. In this paper, we show how symmetry reduction can significantly
simplify common instances of the entanglement-assisted quantum rate-distortion
problems, allowing for more efficient computation regardless of the numerical
algorithm being used. For some of these problem instances, symmetry reduction
allows us to derive closed-form expressions for the quantum rate-distortion
function. Additionally, we propose an inexact variant of the mirror descent
algorithm to compute the quantum rate-distortion function with provable
sublinear convergence rates. We show how this mirror descent algorithm is
related to Blahut-Arimoto and expectation-maximization methods previously used
to solve similar problems in information theory. Using these techniques, we
present the first numerical experiments to compute a multi-qubit quantum
rate-distortion function, and show that our proposed algorithm solves faster
and to higher accuracy when compared to existing methods.
</p>
</div>
</dd>
<dt><a name="item332">[332]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15938" title="Abstract">arXiv:2309.15938</a> (cross-list from eess.AS) [<a href="/pdf/2309.15938" title="Download PDF">pdf</a>, <a href="/format/2309.15938" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exploring Self-Supervised Contrastive Learning of Spatial Sound Event  Representation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Jiang%2C+X">Xilin Jiang</a>, 
<a href="/search/eess?searchtype=author&query=Han%2C+C">Cong Han</a>, 
<a href="/search/eess?searchtype=author&query=Li%2C+Y+A">Yinghao Aaron Li</a>, 
<a href="/search/eess?searchtype=author&query=Mesgarani%2C+N">Nima Mesgarani</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Machine Learning (cs.LG); Sound (cs.SD)

</div>
<p class="mathjax">In this study, we present a simple multi-channel framework for contrastive
learning (MC-SimCLR) to encode 'what' and 'where' of spatial audios. MC-SimCLR
learns joint spectral and spatial representations from unlabeled spatial
audios, thereby enhancing both event classification and sound localization in
downstream tasks. At its core, we propose a multi-level data augmentation
pipeline that augments different levels of audio features, including waveforms,
Mel spectrograms, and generalized cross-correlation (GCC) features. In
addition, we introduce simple yet effective channel-wise augmentation methods
to randomly swap the order of the microphones and mask Mel and GCC channels. By
using these augmentations, we find that linear layers on top of the learned
representation significantly outperform supervised models in terms of both
event classification accuracy and localization error. We also perform a
comprehensive analysis of the effect of each augmentation method and a
comparison of the fine-tuning performance using different amounts of labeled
data.
</p>
</div>
</dd>
<dt><a name="item333">[333]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16036" title="Abstract">arXiv:2309.16036</a> (cross-list from eess.AS) [<a href="/pdf/2309.16036" title="Download PDF">pdf</a>, <a href="/format/2309.16036" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multichannel Voice Trigger Detection Based on  Transform-average-concatenate
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Higuchi%2C+T">Takuya Higuchi</a>, 
<a href="/search/eess?searchtype=author&query=Brueggeman%2C+A">Avamarie Brueggeman</a>, 
<a href="/search/eess?searchtype=author&query=Delfarah%2C+M">Masood Delfarah</a>, 
<a href="/search/eess?searchtype=author&query=Shum%2C+S">Stephen Shum</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Sound (cs.SD)

</div>
<p class="mathjax">Voice triggering (VT) enables users to activate their devices by just
speaking a trigger phrase. A front-end system is typically used to perform
speech enhancement and/or separation, and produces multiple enhanced and/or
separated signals. Since conventional VT systems take only single-channel audio
as input, channel selection is performed. A drawback of this approach is that
unselected channels are discarded, even if the discarded channels could contain
useful information for VT. In this work, we propose multichannel acoustic
models for VT, where the multichannel output from the frond-end is fed directly
into a VT model. We adopt a transform-average-concatenate (TAC) block and
modify the TAC block by incorporating the channel from the conventional channel
selection so that the model can attend to a target speaker when multiple
speakers are present. The proposed approach achieves up to 30% reduction in the
false rejection rate compared to the baseline channel selection approach.
</p>
</div>
</dd>
<dt><a name="item334">[334]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16046" title="Abstract">arXiv:2309.16046</a> (cross-list from q-bio.NC) [<a href="/pdf/2309.16046" title="Download PDF">pdf</a>, <a href="/format/2309.16046" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Precision estimation and second-order prediction errors in cortical  circuits
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-bio?searchtype=author&query=Granier%2C+A">Arno Granier</a>, 
<a href="/search/q-bio?searchtype=author&query=Petrovici%2C+M+A">Mihai A. Petrovici</a>, 
<a href="/search/q-bio?searchtype=author&query=Senn%2C+W">Walter Senn</a>, 
<a href="/search/q-bio?searchtype=author&query=Wilmes%2C+K+A">Katharina A. Wilmes</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neurons and Cognition (q-bio.NC)</span>; Neural and Evolutionary Computing (cs.NE)

</div>
<p class="mathjax">Minimization of cortical prediction errors is believed to be a key canonical
computation of the cerebral cortex underlying perception, action and learning.
However, it is still unclear how the cortex should form and use knowledge about
uncertainty in this process of prediction error minimization. Here we derive
neural dynamics minimizing prediction errors under the assumption that cortical
areas must not only predict the activity in other areas and sensory streams,
but also jointly estimate the precision of their predictions. This leads to a
dynamic modulatory balancing of cortical streams based on context-dependent
precision estimates. Moreover, the theory predicts the existence of
second-order prediction errors, i.e. errors on precision estimates, computed
and propagated through the cortical hierarchy alongside classical prediction
errors. These second-order errors are used to learn weights of synapses
responsible for precision estimation through an error-correcting synaptic
learning rule. Finally, we propose a mapping of the theory to cortical
circuitry.
</p>
</div>
</dd>
<dt><a name="item335">[335]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16048" title="Abstract">arXiv:2309.16048</a> (cross-list from eess.AS) [<a href="/pdf/2309.16048" title="Download PDF">pdf</a>, <a href="/format/2309.16048" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Advancing Acoustic Howling Suppression through Recursive Training of  Neural Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Zhang%2C+H">Hao Zhang</a>, 
<a href="/search/eess?searchtype=author&query=Zhang%2C+Y">Yixuan Zhang</a>, 
<a href="/search/eess?searchtype=author&query=Yu%2C+M">Meng Yu</a>, 
<a href="/search/eess?searchtype=author&query=Yu%2C+D">Dong Yu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Paper in submission
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Sound (cs.SD); Signal Processing (eess.SP)

</div>
<p class="mathjax">In this paper, we introduce a novel training framework designed to
comprehensively address the acoustic howling issue by examining its fundamental
formation process. This framework integrates a neural network (NN) module into
the closed-loop system during training with signals generated recursively on
the fly to closely mimic the streaming process of acoustic howling suppression
(AHS). The proposed recursive training strategy bridges the gap between
training and real-world inference scenarios, marking a departure from previous
NN-based methods that typically approach AHS as either noise suppression or
acoustic echo cancellation. Within this framework, we explore two
methodologies: one exclusively relying on NN and the other combining NN with
the traditional Kalman filter. Additionally, we propose strategies, including
howling detection and initialization using pre-trained offline models, to
bolster trainability and expedite the training process. Experimental results
validate that this framework offers a substantial improvement over previous
methodologies for acoustic howling suppression.
</p>
</div>
</dd>
<dt><a name="item336">[336]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16049" title="Abstract">arXiv:2309.16049</a> (cross-list from eess.AS) [<a href="/pdf/2309.16049" title="Download PDF">pdf</a>, <a href="/format/2309.16049" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Neural Network Augmented Kalman Filter for Robust Acoustic Howling  Suppression
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Zhang%2C+Y">Yixuan Zhang</a>, 
<a href="/search/eess?searchtype=author&query=Zhang%2C+H">Hao Zhang</a>, 
<a href="/search/eess?searchtype=author&query=Yu%2C+M">Meng Yu</a>, 
<a href="/search/eess?searchtype=author&query=Yu%2C+D">Dong Yu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Paper in submission
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Sound (cs.SD); Signal Processing (eess.SP)

</div>
<p class="mathjax">Acoustic howling suppression (AHS) is a critical challenge in audio
communication systems. In this paper, we propose a novel approach that
leverages the power of neural networks (NN) to enhance the performance of
traditional Kalman filter algorithms for AHS. Specifically, our method involves
the integration of NN modules into the Kalman filter, enabling refining
reference signal, a key factor in effective adaptive filtering, and estimating
covariance metrics for the filter which are crucial for adaptability in dynamic
conditions, thereby obtaining improved AHS performance. As a result, the
proposed method achieves improved AHS performance compared to both standalone
NN and Kalman filter methods. Experimental evaluations validate the
effectiveness of our approach.
</p>
</div>
</dd>
<dt><a name="item337">[337]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16053" title="Abstract">arXiv:2309.16053</a> (cross-list from eess.IV) [<a href="/pdf/2309.16053" title="Download PDF">pdf</a>, <a href="/format/2309.16053" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Diagnosis of Helicobacter pylori using AutoEncoders for the Detection of  Anomalous Staining Patterns in Immunohistochemistry Images
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Cano%2C+P">Pau Cano</a>, 
<a href="/search/eess?searchtype=author&query=Caravaca%2C+%C3%81">&#xc1;lvaro Caravaca</a>, 
<a href="/search/eess?searchtype=author&query=Gil%2C+D">Debora Gil</a>, 
<a href="/search/eess?searchtype=author&query=Musulen%2C+E">Eva Musulen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">This work addresses the detection of Helicobacter pylori a bacterium
classified since 1994 as class 1 carcinogen to humans. By its highest
specificity and sensitivity, the preferred diagnosis technique is the analysis
of histological images with immunohistochemical staining, a process in which
certain stained antibodies bind to antigens of the biological element of
interest. This analysis is a time demanding task, which is currently done by an
expert pathologist that visually inspects the digitized samples.
<br />We propose to use autoencoders to learn latent patterns of healthy tissue and
detect H. pylori as an anomaly in image staining. Unlike existing
classification approaches, an autoencoder is able to learn patterns in an
unsupervised manner (without the need of image annotations) with high
performance. In particular, our model has an overall 91% of accuracy with 86\%
sensitivity, 96% specificity and 0.97 AUC in the detection of H. pylori.
</p>
</div>
</dd>
<dt><a name="item338">[338]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16060" title="Abstract">arXiv:2309.16060</a> (cross-list from eess.AS) [<a href="/pdf/2309.16060" title="Download PDF">pdf</a>, <a href="/format/2309.16060" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Does Single-channel Speech Enhancement Improve Keyword Spotting  Accuracy? A Case Study
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Brueggeman%2C+A">Avamarie Brueggeman</a>, 
<a href="/search/eess?searchtype=author&query=Higuchi%2C+T">Takuya Higuchi</a>, 
<a href="/search/eess?searchtype=author&query=Delfarah%2C+M">Masood Delfarah</a>, 
<a href="/search/eess?searchtype=author&query=Shum%2C+S">Stephen Shum</a>, 
<a href="/search/eess?searchtype=author&query=Garg%2C+V">Vineet Garg</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Sound (cs.SD)

</div>
<p class="mathjax">Noise robustness is a key aspect of successful speech applications. Speech
enhancement (SE) has been investigated to improve automatic speech recognition
accuracy; however, its effectiveness for keyword spotting (KWS) is still
under-investigated. In this paper, we conduct a comprehensive study on
single-channel speech enhancement for keyword spotting on the Google Speech
Command (GSC) dataset. To investigate robustness to noise, the GSC dataset is
augmented with noise signals from the WSJ0 Hipster Ambient Mixtures (WHAM!)
noise dataset. Our investigation includes not only applying SE before KWS but
also performing joint training of the SE frontend and KWS backend models.
Moreover, we explore audio injection, a common approach to reduce distortions
by using a weighted average of the enhanced and original signals. Audio
injection is then further optimized by using another model that predicts the
weight for each utterance. Our investigation reveals that SE can improve KWS
accuracy on noisy speech when the backend model is trained on clean speech;
however, despite our extensive exploration, it is difficult to improve the KWS
accuracy with SE when the backend is trained on noisy speech.
</p>
</div>
</dd>
<dt><a name="item339">[339]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16093" title="Abstract">arXiv:2309.16093</a> (cross-list from eess.AS) [<a href="/pdf/2309.16093" title="Download PDF">pdf</a>, <a href="/ps/2309.16093" title="Download PostScript">ps</a>, <a href="/format/2309.16093" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Hierarchical Cross-Modality Knowledge Transfer with Sinkhorn Attention  for CTC-based ASR
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Lu%2C+X">Xugang Lu</a>, 
<a href="/search/eess?searchtype=author&query=Shen%2C+P">Peng Shen</a>, 
<a href="/search/eess?searchtype=author&query=Tsao%2C+Y">Yu Tsao</a>, 
<a href="/search/eess?searchtype=author&query=Kawai%2C+H">Hisashi Kawai</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to ICASSP 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Sound (cs.SD)

</div>
<p class="mathjax">Due to the modality discrepancy between textual and acoustic modeling,
efficiently transferring linguistic knowledge from a pretrained language model
(PLM) to acoustic encoding for automatic speech recognition (ASR) still remains
a challenging task. In this study, we propose a cross-modality knowledge
transfer (CMKT) learning framework in a temporal connectionist temporal
classification (CTC) based ASR system where hierarchical acoustic alignments
with the linguistic representation are applied. Additionally, we propose the
use of Sinkhorn attention in cross-modality alignment process, where the
transformer attention is a special case of this Sinkhorn attention process. The
CMKT learning is supposed to compel the acoustic encoder to encode rich
linguistic knowledge for ASR. On the AISHELL-1 dataset, with CTC greedy
decoding for inference (without using any language model), we achieved
state-of-the-art performance with 3.64% and 3.94% character error rates (CERs)
for the development and test sets, which corresponding to relative improvements
of 34.18% and 34.88% compared to the baseline CTC-ASR system, respectively.
</p>
</div>
</dd>
<dt><a name="item340">[340]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16138" title="Abstract">arXiv:2309.16138</a> (cross-list from math.NT) [<a href="/pdf/2309.16138" title="Download PDF">pdf</a>, <a href="/ps/2309.16138" title="Download PostScript">ps</a>, <a href="/format/2309.16138" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An algorithm for $g$-invariant on unary Hermitian lattices over  imaginary quadratic fields
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Liu%2C+J">Jingbo Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: text overlap with <a href="/abs/2111.10825">arXiv:2111.10825</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Number Theory (math.NT)</span>; Data Structures and Algorithms (cs.DS)

</div>
<p class="mathjax">Let $E=\mathbb{Q}\big(\sqrt{-d}\big)$ be an imaginary quadratic field for a
square-free positive integer $d$, and let $\mathcal{O}$ be its ring of
integers. For each positive integer $m$, let $I_m$ be the free Hermitian
lattice over $\mathcal{O}$ with an orthonormal basis, let $\mathfrak{S}_d(1)$
be the set consisting of all positive definite integral unary Hermitian
lattices over $\mathcal{O}$ that can be represented by some $I_m$, and let
$g_d(1)$ be the least positive integer such that all Hermitian lattices in
$\mathfrak{S}_d(1)$ can be uniformly represented by $I_{g_d(1)}$. The main
results of this work provide an algorithm to calculate the explicit form of
$\mathfrak{S}_d(1)$ and the exact value of $g_d(1)$ for every imaginary
quadratic field $E$, which can be viewed as a natural extension of the
Pythagoras number in the lattice setting.
</p>
</div>
</dd>
<dt><a name="item341">[341]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16177" title="Abstract">arXiv:2309.16177</a> (cross-list from physics.ao-ph) [<a href="/pdf/2309.16177" title="Download PDF">pdf</a>, <a href="/format/2309.16177" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Systematic Sampling and Validation of Machine Learning-Parameterizations  in Climate Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Lin%2C+J">Jerry Lin</a>, 
<a href="/search/physics?searchtype=author&query=Yu%2C+S">Sungduk Yu</a>, 
<a href="/search/physics?searchtype=author&query=Beucler%2C+T">Tom Beucler</a>, 
<a href="/search/physics?searchtype=author&query=Gentine%2C+P">Pierre Gentine</a>, 
<a href="/search/physics?searchtype=author&query=Walling%2C+D">David Walling</a>, 
<a href="/search/physics?searchtype=author&query=Pritchard%2C+M">Mike Pritchard</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, 4 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Atmospheric and Oceanic Physics (physics.ao-ph)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Progress in hybrid physics-machine learning (ML) climate simulations has been
limited by the difficulty of obtaining performant coupled (i.e. online)
simulations. While evaluating hundreds of ML parameterizations of subgrid
closures (here of convection and radiation) offline is straightforward, online
evaluation at the same scale is technically challenging. Our software
automation achieves an order-of-magnitude larger sampling of online modeling
errors than has previously been examined. Using this, we evaluate the hybrid
climate model performance and define strategies to improve it. We show that
model online performance improves when incorporating memory, a relative
humidity input feature transformation, and additional input variables. We also
reveal substantial variation in online error and inconsistencies between
offline vs. online error statistics. The implication is that hundreds of
candidate ML models should be evaluated online to detect the effects of
parameterization design choices. This is considerably more sampling than tends
to be reported in the current literature.
</p>
</div>
</dd>
<dt><a name="item342">[342]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16188" title="Abstract">arXiv:2309.16188</a> (cross-list from stat.ML) [<a href="/pdf/2309.16188" title="Download PDF">pdf</a>, <a href="/format/2309.16188" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Stackelberg Batch Policy Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Zhou%2C+W">Wenzhuo Zhou</a>, 
<a href="/search/stat?searchtype=author&query=Qu%2C+A">Annie Qu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Batch reinforcement learning (RL) defines the task of learning from a fixed
batch of data lacking exhaustive exploration. Worst-case optimality algorithms,
which calibrate a value-function model class from logged experience and perform
some type of pessimistic evaluation under the learned model, have emerged as a
promising paradigm for batch RL. However, contemporary works on this stream
have commonly overlooked the hierarchical decision-making structure hidden in
the optimization landscape. In this paper, we adopt a game-theoretical
viewpoint and model the policy learning diagram as a two-player general-sum
game with a leader-follower structure. We propose a novel stochastic
gradient-based learning algorithm: StackelbergLearner, in which the leader
player updates according to the total derivative of its objective instead of
the usual individual gradient, and the follower player makes individual updates
and ensures transition-consistent pessimistic reasoning. The derived learning
dynamic naturally lends StackelbergLearner to a game-theoretic interpretation
and provides a convergence guarantee to differentiable Stackelberg equilibria.
From a theoretical standpoint, we provide instance-dependent regret bounds with
general function approximation, which shows that our algorithm can learn a
best-effort policy that is able to compete against any comparator policy that
is covered by batch data. Notably, our theoretical regret guarantees only
require realizability without any data coverage and strong function
approximation conditions, e.g., Bellman closedness, which is in contrast to
prior works lacking such guarantees. Through comprehensive experiments, we find
that our algorithm consistently performs as well or better as compared to
state-of-the-art methods in batch RL benchmark and real-world datasets.
</p>
</div>
</dd>
<dt><a name="item343">[343]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16192" title="Abstract">arXiv:2309.16192</a> (cross-list from nlin.AO) [<a href="/pdf/2309.16192" title="Download PDF">pdf</a>, <a href="/format/2309.16192" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Phase-Amplitude Reduction and Optimal Phase Locking of Collectively  Oscillating Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/nlin?searchtype=author&query=Mircheski%2C+P">Petar Mircheski</a>, 
<a href="/search/nlin?searchtype=author&query=Zhu%2C+J">Jinjie Zhu</a>, 
<a href="/search/nlin?searchtype=author&query=Nakao%2C+H">Hiroya Nakao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 19 pages, 8 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Adaptation and Self-Organizing Systems (nlin.AO)</span>; Systems and Control (eess.SY)

</div>
<p class="mathjax">We present a phase-amplitude reduction framework for analyzing collective
oscillations in networked dynamical systems. The framework, which builds on the
phase reduction method, takes into account not only the collective dynamics on
the limit cycle but also deviations from it by introducing amplitude variables
and using them with the phase variable. The framework allows us to study how
networks react to applied inputs or coupling, including their synchronization
and phase-locking, while capturing the deviations of the network states from
the unperturbed dynamics. Numerical simulations are used to demonstrate the
effectiveness of the framework for networks composed of FitzHugh-Nagumo
elements. The resulting phase-amplitude equation can be used in deriving
optimal periodic waveforms or introducing feedback control for achieving fast
phase locking while stabilizing the collective oscillations.
</p>
</div>
</dd>
<dt><a name="item344">[344]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16206" title="Abstract">arXiv:2309.16206</a> (cross-list from eess.IV) [<a href="/pdf/2309.16206" title="Download PDF">pdf</a>, <a href="/format/2309.16206" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Cross-Modal Transformer GAN: Brain Structural-Functional Deep Fusing  Network for Alzheimer&#x27;s Disease Analysis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Zuo%2C+Q">Qiankun Zuo</a>, 
<a href="/search/eess?searchtype=author&query=Pan%2C+J">Junren Pan</a>, 
<a href="/search/eess?searchtype=author&query=Wang%2C+S">Shuqiang Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Fusing structural-functional images of the brain has shown great potential to
analyze the deterioration of Alzheimer's disease (AD). However, it is a big
challenge to effectively fuse the correlated and complementary information from
multimodal neuroimages. In this paper, a novel model termed cross-modal
transformer generative adversarial network (CT-GAN) is proposed to effectively
fuse the functional and structural information contained in functional magnetic
resonance imaging (fMRI) and diffusion tensor imaging (DTI). The CT-GAN can
learn topological features and generate multimodal connectivity from multimodal
imaging data in an efficient end-to-end manner. Moreover, the swapping
bi-attention mechanism is designed to gradually align common features and
effectively enhance the complementary features between modalities. By analyzing
the generated connectivity features, the proposed model can identify AD-related
brain connections. Evaluations on the public ADNI dataset show that the
proposed CT-GAN can dramatically improve prediction performance and detect
AD-related brain regions effectively. The proposed model also provides new
insights for detecting AD-related abnormal neural circuits.
</p>
</div>
</dd>
<dt><a name="item345">[345]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16210" title="Abstract">arXiv:2309.16210</a> (cross-list from eess.IV) [<a href="/pdf/2309.16210" title="Download PDF">pdf</a>, <a href="/format/2309.16210" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Abdominal multi-organ segmentation in CT using Swinunter
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Chen%2C+M">Mingjin Chen</a>, 
<a href="/search/eess?searchtype=author&query=He%2C+Y">Yongkang He</a>, 
<a href="/search/eess?searchtype=author&query=Lu%2C+Y">Yongyi Lu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8pages. arXiv admin note: text overlap with <a href="/abs/2201.01266">arXiv:2201.01266</a> by other authors
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
<p class="mathjax">Abdominal multi-organ segmentation in computed tomography (CT) is crucial for
many clinical applications including disease detection and treatment planning.
Deep learning methods have shown unprecedented performance in this perspective.
However, it is still quite challenging to accurately segment different organs
utilizing a single network due to the vague boundaries of organs, the complex
background, and the substantially different organ size scales. In this work we
used make transformer-based model for training. It was found through previous
years' competitions that basically all of the top 5 methods used CNN-based
methods, which is likely due to the lack of data volume that prevents
transformer-based methods from taking full advantage. The thousands of samples
in this competition may enable the transformer-based model to have more
excellent results. The results on the public validation set also show that the
transformer-based model can achieve an acceptable result and inference time.
</p>
</div>
</dd>
<dt><a name="item346">[346]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16235" title="Abstract">arXiv:2309.16235</a> (cross-list from physics.chem-ph) [<a href="/pdf/2309.16235" title="Download PDF">pdf</a>, <a href="/format/2309.16235" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Language models in molecular discovery
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Janakarajan%2C+N">Nikita Janakarajan</a>, 
<a href="/search/physics?searchtype=author&query=Erdmann%2C+T">Tim Erdmann</a>, 
<a href="/search/physics?searchtype=author&query=Swaminathan%2C+S">Sarath Swaminathan</a>, 
<a href="/search/physics?searchtype=author&query=Laino%2C+T">Teodoro Laino</a>, 
<a href="/search/physics?searchtype=author&query=Born%2C+J">Jannis Born</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Under review
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Chemical Physics (physics.chem-ph)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Machine Learning (cs.LG); Biomolecules (q-bio.BM)

</div>
<p class="mathjax">The success of language models, especially transformer-based architectures,
has trickled into other domains giving rise to "scientific language models"
that operate on small molecules, proteins or polymers. In chemistry, language
models contribute to accelerating the molecule discovery cycle as evidenced by
promising recent findings in early-stage drug discovery. Here, we review the
role of language models in molecular discovery, underlining their strength in
de novo drug design, property prediction and reaction chemistry. We highlight
valuable open-source software assets thus lowering the entry barrier to the
field of scientific language modeling. Last, we sketch a vision for future
molecular design that combines a chatbot interface with access to computational
chemistry tools. Our contribution serves as a valuable resource for
researchers, chemists, and AI enthusiasts interested in understanding how
language models can and will be used to accelerate chemical discovery.
</p>
</div>
</dd>
<dt><a name="item347">[347]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16242" title="Abstract">arXiv:2309.16242</a> (cross-list from math.AP) [<a href="/pdf/2309.16242" title="Download PDF">pdf</a>, <a href="/format/2309.16242" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Long time behavior of the field-road diffusion model: an entropy method  and a finite volume scheme
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Alfaro%2C+M">Matthieu Alfaro</a> (LMRS), 
<a href="/search/math?searchtype=author&query=Chainais-Hillairet%2C+C">Claire Chainais-Hillairet</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Analysis of PDEs (math.AP)</span>; Numerical Analysis (math.NA)

</div>
<p class="mathjax">We consider the so-called field-road diffusion model in a bounded domain,
consisting of two parabolic PDEs posed on sets of different dimensions (a {\it
field} and a {\it road} in a population dynamics context) and coupled through
exchange terms on the road, which makes its analysis quite involved. We propose
a TPFA finite volume scheme. In both the continuous and the discrete settings,
we prove theexponential decay of an entropy, and thus the long time convergence
to the stationary state selected by the total mass of the initial data. To deal
with the problem of different dimensions, we artificially \lq\lq thicken'' the
road and, then, establish a rather unconventional Poincar{\'e}-Wirtinger
inequality. Numerical simulations confirm and complete the analysis, and raise
new issues.
</p>
</div>
</dd>
<dt><a name="item348">[348]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16247" title="Abstract">arXiv:2309.16247</a> (cross-list from eess.AS) [<a href="/pdf/2309.16247" title="Download PDF">pdf</a>, <a href="/format/2309.16247" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PP-MeT: a Real-world Personalized Prompt based Meeting Transcription  System
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Lyu%2C+X">Xiang Lyu</a>, 
<a href="/search/eess?searchtype=author&query=Cao%2C+Y">Yuhang Cao</a>, 
<a href="/search/eess?searchtype=author&query=Wang%2C+Q">Qing Wang</a>, 
<a href="/search/eess?searchtype=author&query=Yin%2C+J">Jingjing Yin</a>, 
<a href="/search/eess?searchtype=author&query=Yang%2C+Y">Yuguang Yang</a>, 
<a href="/search/eess?searchtype=author&query=Zou%2C+P">Pengpeng Zou</a>, 
<a href="/search/eess?searchtype=author&query=Hu%2C+Y">Yanni Hu</a>, 
<a href="/search/eess?searchtype=author&query=Lu%2C+H">Heng Lu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Sound (cs.SD)

</div>
<p class="mathjax">Speaker-attributed automatic speech recognition (SA-ASR) improves the
accuracy and applicability of multi-speaker ASR systems in real-world scenarios
by assigning speaker labels to transcribed texts. However, SA-ASR poses unique
challenges due to factors such as speaker overlap, speaker variability,
background noise, and reverberation. In this study, we propose PP-MeT system, a
real-world personalized prompt based meeting transcription system, which
consists of a clustering system, target-speaker voice activity detection
(TS-VAD), and TS-ASR. Specifically, we utilize target-speaker embedding as a
prompt in TS-VAD and TS-ASR modules in our proposed system. In constrast with
previous system, we fully leverage pre-trained models for system
initialization, thereby bestowing our approach with heightened generalizability
and precision. Experiments on M2MeT2.0 Challenge dataset show that our system
achieves a cp-CER of 11.27% on the test set, ranking first in both fixed and
open training conditions.
</p>
</div>
</dd>
<dt><a name="item349">[349]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16253" title="Abstract">arXiv:2309.16253</a> (cross-list from cond-mat.dis-nn) [<a href="/pdf/2309.16253" title="Download PDF">pdf</a>, <a href="/format/2309.16253" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Where do hard problems really exist?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cond-mat?searchtype=author&query=Marino%2C+R">Raffaele Marino</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Disordered Systems and Neural Networks (cond-mat.dis-nn)</span>; Statistical Mechanics (cond-mat.stat-mech); Computational Complexity (cs.CC)

</div>
<p class="mathjax">This chapter delves into the realm of computational complexity, exploring the
world of challenging combinatorial problems and their ties with statistical
physics. Our exploration starts by delving deep into the foundations of
combinatorial challenges, emphasizing their nature. We will traverse the class
P, which comprises problems solvable in polynomial time using deterministic
algorithms, contrasting it with the class NP, where finding efficient solutions
remains an enigmatic endeavor, understanding the intricacies of algorithmic
transitions and thresholds demarcating the boundary between tractable and
intractable problems. We will discuss the implications of the P versus NP
problem, representing one of the profoundest unsolved enigmas of computer
science and mathematics, bearing a tantalizing reward for its resolution.
Drawing parallels between combinatorics and statistical physics, we will
uncover intriguing interconnections that shed light on the nature of
challenging problems. Statistical physics unveils profound analogies with
complexities witnessed in combinatorial landscapes. Throughout this chapter, we
will discuss the interplay between computational complexity theory and
statistical physics. By unveiling the mysteries surrounding challenging
problems, we aim to deepen understanding of the very essence of computation and
its boundaries. Through this interdisciplinary approach, we aspire to
illuminate the intricate tapestry of complexity underpinning the mathematical
and physical facets of hard problems.
</p>
</div>
</dd>
<dt><a name="item350">[350]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16256" title="Abstract">arXiv:2309.16256</a> (cross-list from quant-ph) [<a href="/pdf/2309.16256" title="Download PDF">pdf</a>, <a href="/format/2309.16256" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On finding dense sub-lattices as low energy states of a quantum  Hamiltonian
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Rodr%C3%ADguez%2C+J+B">J&#xfa;lia Barber&#xe0; Rodr&#xed;guez</a>, 
<a href="/search/quant-ph?searchtype=author&query=Gama%2C+N">Nicolas Gama</a>, 
<a href="/search/quant-ph?searchtype=author&query=Narayanan%2C+A+K">Anand Kumar Narayanan</a>, 
<a href="/search/quant-ph?searchtype=author&query=Joseph%2C+D">David Joseph</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Computational Complexity (cs.CC); Cryptography and Security (cs.CR)

</div>
<p class="mathjax">Lattice-based cryptography has emerged as one of the most prominent
candidates for post-quantum cryptography, projected to be secure against the
imminent threat of large-scale fault-tolerant quantum computers. The Shortest
Vector Problem (SVP) is to find the shortest non-zero vector in a given
lattice. It is fundamental to lattice-based cryptography and believed to be
hard even for quantum computers. We study a natural generalization of the SVP
known as the $K$-Densest Sub-lattice Problem ($K$-DSP): to find the densest
$K$-dimensional sub-lattice of a given lattice. We formulate $K$-DSP as finding
the first excited state of a Z-basis Hamiltonian, making $K$-DSP amenable to
investigation via an array of quantum algorithms, including Grover search,
quantum Gibbs sampling, adiabatic, and Variational Quantum Algorithms. The
complexity of the algorithms depends on the basis through which the input
lattice is presented. We present a classical polynomial-time algorithm that
takes an arbitrary input basis and preprocesses it into inputs suited to
quantum algorithms. With preprocessing, we prove that $O(KN^2)$ qubits suffice
for solving $K$-DSP for $N$ dimensional input lattices. We empirically
demonstrate the performance of a Quantum Approximate Optimization Algorithm
$K$-DSP solver for low dimensions, highlighting the influence of a good
preprocessed input basis. We then discuss the hardness of $K$-DSP in relation
to the SVP, to see if there is reason to build post-quantum cryptography on
$K$-DSP. We devise a quantum algorithm that solves $K$-DSP with run-time
exponent $(5KN\log{N})/2$. Therefore, for fixed $K$, $K$-DSP is no more than
polynomially harder than the SVP.
</p>
</div>
</dd>
<dt><a name="item351">[351]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16258" title="Abstract">arXiv:2309.16258</a> (cross-list from quant-ph) [<a href="/pdf/2309.16258" title="Download PDF">pdf</a>, <a href="/format/2309.16258" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> QonFusion -- Quantum Approaches to Gaussian Random Variables:  Applications in Stable Diffusion and Brownian Motion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Kashani%2C+S">Shlomo Kashani</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">In the present study, we delineate a strategy focused on non-parametric
quantum circuits for the generation of Gaussian random variables (GRVs). This
quantum-centric approach serves as a substitute for conventional pseudorandom
number generators (PRNGs), such as the \textbf{torch.rand} function in PyTorch.
The principal theme of our research is the incorporation of Quantum Random
Number Generators (QRNGs) into classical models of diffusion. Notably, our
Quantum Gaussian Random Variable Generator fulfills dual roles, facilitating
simulations in both Stable Diffusion (SD) and Brownian Motion (BM). This
diverges markedly from prevailing methods that utilize parametric quantum
circuits (PQCs), often in conjunction with variational quantum eigensolvers
(VQEs). Although conventional techniques can accurately approximate ground
states in complex systems or model elaborate probability distributions, they
require a computationally demanding optimization process to tune parameters.
Our non-parametric strategy obviates this necessity. To facilitate assimilating
our methodology into existing computational frameworks, we put forward
QonFusion, a Python library congruent with both PyTorch and PennyLane,
functioning as a bridge between classical and quantum computational paradigms.
We validate QonFusion through extensive statistical testing, including tests
which confirm the statistical equivalence of the Gaussian samples from our
quantum approach to classical counterparts within defined significance limits.
QonFusion is available at
\url{https://boltzmannentropy.github.io/qonfusion.github.io/} to reproduce all
findings here.
</p>
</div>
</dd>
<dt><a name="item352">[352]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16274" title="Abstract">arXiv:2309.16274</a> (cross-list from stat.ML) [<a href="/pdf/2309.16274" title="Download PDF">pdf</a>, <a href="/format/2309.16274" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A framework for paired-sample hypothesis testing for high-dimensional  data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Bargiotas%2C+I">Ioannis Bargiotas</a>, 
<a href="/search/stat?searchtype=author&query=Kalogeratos%2C+A">Argyris Kalogeratos</a>, 
<a href="/search/stat?searchtype=author&query=Vayatis%2C+N">Nicolas Vayatis</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 35th IEEE International Conference on Tools with Artificial Intelligence (ICTAI). 6 pages, 3 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG); Methodology (stat.ME)

</div>
<p class="mathjax">The standard paired-sample testing approach in the multidimensional setting
applies multiple univariate tests on the individual features, followed by
p-value adjustments. Such an approach suffers when the data carry numerous
features. A number of studies have shown that classification accuracy can be
seen as a proxy for two-sample testing. However, neither theoretical
foundations nor practical recipes have been proposed so far on how this
strategy could be extended to multidimensional paired-sample testing. In this
work, we put forward the idea that scoring functions can be produced by the
decision rules defined by the perpendicular bisecting hyperplanes of the line
segments connecting each pair of instances. Then, the optimal scoring function
can be obtained by the pseudomedian of those rules, which we estimate by
extending naturally the Hodges-Lehmann estimator. We accordingly propose a
framework of a two-step testing procedure. First, we estimate the bisecting
hyperplanes for each pair of instances and an aggregated rule derived through
the Hodges-Lehmann estimator. The paired samples are scored by this aggregated
rule to produce a unidimensional representation. Second, we perform a Wilcoxon
signed-rank test on the obtained representation. Our experiments indicate that
our approach has substantial performance gains in testing accuracy compared to
the traditional multivariate and multiple testing, while at the same time
estimates each feature's contribution to the final result.
</p>
</div>
</dd>
<dt><a name="item353">[353]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16314" title="Abstract">arXiv:2309.16314</a> (cross-list from stat.ML) [<a href="/pdf/2309.16314" title="Download PDF">pdf</a>, <a href="/format/2309.16314" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Primer on Bayesian Neural Networks: Review and Debates
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Arbel%2C+J">Julyan Arbel</a>, 
<a href="/search/stat?searchtype=author&query=Pitas%2C+K">Konstantinos Pitas</a>, 
<a href="/search/stat?searchtype=author&query=Vladimirova%2C+M">Mariia Vladimirova</a>, 
<a href="/search/stat?searchtype=author&query=Fortuin%2C+V">Vincent Fortuin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 65 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG); Statistics Theory (math.ST); Computation (stat.CO)

</div>
<p class="mathjax">Neural networks have achieved remarkable performance across various problem
domains, but their widespread applicability is hindered by inherent limitations
such as overconfidence in predictions, lack of interpretability, and
vulnerability to adversarial attacks. To address these challenges, Bayesian
neural networks (BNNs) have emerged as a compelling extension of conventional
neural networks, integrating uncertainty estimation into their predictive
capabilities.
<br />This comprehensive primer presents a systematic introduction to the
fundamental concepts of neural networks and Bayesian inference, elucidating
their synergistic integration for the development of BNNs. The target audience
comprises statisticians with a potential background in Bayesian methods but
lacking deep learning expertise, as well as machine learners proficient in deep
neural networks but with limited exposure to Bayesian statistics. We provide an
overview of commonly employed priors, examining their impact on model behavior
and performance. Additionally, we delve into the practical considerations
associated with training and inference in BNNs.
<br />Furthermore, we explore advanced topics within the realm of BNN research,
acknowledging the existence of ongoing debates and controversies. By offering
insights into cutting-edge developments, this primer not only equips
researchers and practitioners with a solid foundation in BNNs, but also
illuminates the potential applications of this dynamic field. As a valuable
resource, it fosters an understanding of BNNs and their promising prospects,
facilitating further advancements in the pursuit of knowledge and innovation.
</p>
</div>
</dd>
<dt><a name="item354">[354]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16316" title="Abstract">arXiv:2309.16316</a> (cross-list from astro-ph.SR) [<a href="/pdf/2309.16316" title="Download PDF">pdf</a>, <a href="/format/2309.16316" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Astroconformer: The Prospects of Analyzing Stellar Light Curves with  Transformer-Based Deep Learning Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/astro-ph?searchtype=author&query=Pan%2C+J">Jia-Shu Pan</a>, 
<a href="/search/astro-ph?searchtype=author&query=Ting%2C+Y">Yuan-Sen Ting</a>, 
<a href="/search/astro-ph?searchtype=author&query=Yu%2C+J">Jie Yu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, 9 figures, Submitted to MNRAS
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Solar and Stellar Astrophysics (astro-ph.SR)</span>; Earth and Planetary Astrophysics (astro-ph.EP); Instrumentation and Methods for Astrophysics (astro-ph.IM); Machine Learning (cs.LG)

</div>
<p class="mathjax">Light curves of stars encapsulate a wealth of information about stellar
oscillations and granulation, thereby offering key insights into the internal
structure and evolutionary state of stars. Conventional asteroseismic
techniques have been largely confined to power spectral analysis, neglecting
the valuable phase information contained within light curves. While recent
machine learning applications in asteroseismology utilizing Convolutional
Neural Networks (CNNs) have successfully inferred stellar attributes from light
curves, they are often limited by the local feature extraction inherent in
convolutional operations. To circumvent these constraints, we present
$\textit{Astroconformer}$, a Transformer-based deep learning framework designed
to capture long-range dependencies in stellar light curves. Our empirical
analysis, which focuses on estimating surface gravity ($\log g$), is grounded
in a carefully curated dataset derived from $\textit{Kepler}$ light curves.
These light curves feature asteroseismic $\log g$ values spanning from 0.2 to
4.4. Our results underscore that, in the regime where the training data is
abundant, $\textit{Astroconformer}$ attains a root-mean-square-error (RMSE) of
0.017 dex around $\log g \approx 3 $. Even in regions where training data are
sparse, the RMSE can reach 0.1 dex. It outperforms not only the K-nearest
neighbor-based model ($\textit{The SWAN}$) but also state-of-the-art CNNs.
Ablation studies confirm that the efficacy of the models in this particular
task is strongly influenced by the size of their receptive fields, with larger
receptive fields correlating with enhanced performance. Moreover, we find that
the attention mechanisms within $\textit{Astroconformer}$ are well-aligned with
the inherent characteristics of stellar oscillations and granulation present in
the light curves.
</p>
</div>
</dd>
<dt><a name="item355">[355]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16380" title="Abstract">arXiv:2309.16380</a> (cross-list from astro-ph.HE) [<a href="/pdf/2309.16380" title="Download PDF">pdf</a>, <a href="/format/2309.16380" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Conditional normalizing flows for IceCube event reconstruction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/astro-ph?searchtype=author&query=Gl%C3%BCsenkamp%2C+T">Thorsten Gl&#xfc;senkamp</a> (for the IceCube collaboration)
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Presented at the 38th International Cosmic Ray Conference (ICRC2023). See <a href="/abs/2307.13047">arXiv:2307.13047</a> for all IceCube contributions
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">High Energy Astrophysical Phenomena (astro-ph.HE)</span>; Instrumentation and Methods for Astrophysics (astro-ph.IM); Artificial Intelligence (cs.AI); High Energy Physics - Experiment (hep-ex)

</div>
<p class="mathjax">The IceCube Neutrino Observatory is a cubic-kilometer high-energy neutrino
detector deployed in the Antarctic ice. Two major event classes are
charged-current electron and muon neutrino interactions. In this contribution,
we discuss the inference of direction and energy for these classes using
conditional normalizing flows. They allow to derive a posterior distribution
for each individual event based on the raw data that can include systematic
uncertainties, which makes them very promising for next-generation
reconstructions. For each normalizing flow we use the differential entropy and
the KL-divergence to its maximum entropy approximation to interpret the
results. The normalizing flows correctly incorporate complex optical properties
of the Antarctic ice and their relation to the embedded detector. For showers,
the differential entropy increases in regions of high photon absorption and
decreases in clear ice. For muons, the differential entropy strongly correlates
with the contained track length. Coverage is maintained, even for low photon
counts and highly asymmetrical contour shapes. For high-photon counts, the
distributions get narrower and become more symmetrical, as expected from the
asymptotic theorem of Bernstein-von-Mises. For shower directional
reconstruction, we find the region between 1 TeV and 100 TeV to potentially
benefit the most from normalizing flows because of azimuth-zenith asymmetries
which have been neglected in previous analyses by assuming symmetrical
contours. Events in this energy range play a vital role in the recent discovery
of the galactic plane diffuse neutrino emission.
</p>
</div>
</dd>
<dt><a name="item356">[356]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16400" title="Abstract">arXiv:2309.16400</a> (cross-list from physics.comp-ph) [<a href="/pdf/2309.16400" title="Download PDF">pdf</a>, <a href="/format/2309.16400" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Physics-Preserving AI-Accelerated Simulations of Plasma Turbulence
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Greif%2C+R">Robin Greif</a>, 
<a href="/search/physics?searchtype=author&query=Jenko%2C+F">Frank Jenko</a>, 
<a href="/search/physics?searchtype=author&query=Thuerey%2C+N">Nils Thuerey</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Physics (physics.comp-ph)</span>; Artificial Intelligence (cs.AI); Plasma Physics (physics.plasm-ph)

</div>
<p class="mathjax">Turbulence in fluids, gases, and plasmas remains an open problem of both
practical and fundamental importance. Its irreducible complexity usually cannot
be tackled computationally in a brute-force style. Here, we combine Large Eddy
Simulation (LES) techniques with Machine Learning (ML) to retain only the
largest dynamics explicitly, while small-scale dynamics are described by an
ML-based sub-grid-scale model. Applying this novel approach to self-driven
plasma turbulence allows us to remove large parts of the inertial range,
reducing the computational effort by about three orders of magnitude, while
retaining the statistical physical properties of the turbulent system.
</p>
</div>
</dd>
<dt><a name="item357">[357]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16401" title="Abstract">arXiv:2309.16401</a> (cross-list from astro-ph.HE) [<a href="/pdf/2309.16401" title="Download PDF">pdf</a>, <a href="/format/2309.16401" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> VAE-based latent-space classification of RNO-G data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/astro-ph?searchtype=author&query=Gl%C3%BCsenkamp%2C+T">Thorsten Gl&#xfc;senkamp</a> (for the RNO-G collaboration)
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Presented at the 38th International Cosmic Ray Conference (ICRC2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">High Energy Astrophysical Phenomena (astro-ph.HE)</span>; Instrumentation and Methods for Astrophysics (astro-ph.IM); Machine Learning (cs.LG)

</div>
<p class="mathjax">The Radio Neutrino Observatory in Greenland (RNO-G) is a radio-based
ultra-high energy neutrino detector located at Summit Station, Greenland. It is
still being constructed, with 7 stations currently operational. Neutrino
detection works by measuring Askaryan radiation produced by neutrino-nucleon
interactions. A neutrino candidate must be found amidst other backgrounds which
are recorded at much higher rates -- including cosmic-rays and anthropogenic
noise -- the origins of which are sometimes unknown. Here we describe a method
to classify different noise classes using the latent space of a variational
autoencoder. The latent space forms a compact representation that makes
classification tractable. We analyze data from a noisy and a silent station.
The method automatically detects and allows us to qualitatively separate
multiple event classes, including physical wind-induced signals, for both the
noisy and the quiet station.
</p>
</div>
</dd>
<dt><a name="item358">[358]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16408" title="Abstract">arXiv:2309.16408</a> (cross-list from q-fin.GN) [<a href="/pdf/2309.16408" title="Download PDF">pdf</a>, <a href="/format/2309.16408" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Assessing the Solvency of Virtual Asset Service Providers: Are Current  Standards Sufficient?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-fin?searchtype=author&query=Saggese%2C+P">Pietro Saggese</a>, 
<a href="/search/q-fin?searchtype=author&query=Segalla%2C+E">Esther Segalla</a>, 
<a href="/search/q-fin?searchtype=author&query=Sigmund%2C+M">Michael Sigmund</a>, 
<a href="/search/q-fin?searchtype=author&query=Raunig%2C+B">Burkhard Raunig</a>, 
<a href="/search/q-fin?searchtype=author&query=Zangerl%2C+F">Felix Zangerl</a>, 
<a href="/search/q-fin?searchtype=author&query=Haslhofer%2C+B">Bernhard Haslhofer</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">General Finance (q-fin.GN)</span>; Cryptography and Security (cs.CR)

</div>
<p class="mathjax">Entities like centralized cryptocurrency exchanges fall under the business
category of virtual asset service providers (VASPs). As any other enterprise,
they can become insolvent. VASPs enable the exchange, custody, and transfer of
cryptoassets organized in wallets across distributed ledger technologies
(DLTs). Despite the public availability of DLT transactions, the cryptoasset
holdings of VASPs are not yet subject to systematic auditing procedures. In
this paper, we propose an approach to assess the solvency of a VASP by
cross-referencing data from three distinct sources: cryptoasset wallets,
balance sheets from the commercial register, and data from supervisory
entities. We investigate 24 VASPs registered with the Financial Market
Authority in Austria and provide regulatory data insights such as who are the
customers and where do they come from. Their yearly incoming and outgoing
transaction volume amount to 2 billion EUR for around 1.8 million users. We
describe what financial services they provide and find that they are most
similar to traditional intermediaries such as brokers, money exchanges, and
funds, rather than banks. Next, we empirically measure DLT transaction flows of
four VASPs and compare their cryptoasset holdings to balance sheet entries.
Data are consistent for two VASPs only. This enables us to identify gaps in the
data collection and propose strategies to address them. We remark that any
entity in charge of auditing requires proof that a VASP actually controls the
funds associated with its on-chain wallets. It is also important to report fiat
and cryptoasset and liability positions broken down by asset types at a
reasonable frequency.
</p>
</div>
</dd>
<dt><a name="item359">[359]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16409" title="Abstract">arXiv:2309.16409</a> (cross-list from stat.ML) [<a href="/pdf/2309.16409" title="Download PDF">pdf</a>, <a href="/format/2309.16409" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Constructing Synthetic Treatment Groups without the Mean Exchangeability  Assumption
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Zhang%2C+Y">Yuhang Zhang</a>, 
<a href="/search/stat?searchtype=author&query=Liu%2C+Y">Yue Liu</a>, 
<a href="/search/stat?searchtype=author&query=Zhang%2C+Z">Zhihua Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">The purpose of this work is to transport the information from multiple
randomized controlled trials to the target population where we only have the
control group data. Previous works rely critically on the mean exchangeability
assumption. However, as pointed out by many current studies, the mean
exchangeability assumption might be violated. Motivated by the synthetic
control method, we construct a synthetic treatment group for the target
population by a weighted mixture of treatment groups of source populations. We
estimate the weights by minimizing the conditional maximum mean discrepancy
between the weighted control groups of source populations and the target
population. We establish the asymptotic normality of the synthetic treatment
group estimator based on the sieve semiparametric theory. Our method can serve
as a novel complementary approach when the mean exchangeability assumption is
violated. Experiments are conducted on synthetic and real-world datasets to
demonstrate the effectiveness of our methods.
</p>
</div>
</dd>
<dt><a name="item360">[360]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16412" title="Abstract">arXiv:2309.16412</a> (cross-list from stat.ML) [<a href="/pdf/2309.16412" title="Download PDF">pdf</a>, <a href="/format/2309.16412" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Selective Nonparametric Regression via Testing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Noskov%2C+F">Fedor Noskov</a>, 
<a href="/search/stat?searchtype=author&query=Fishkov%2C+A">Alexander Fishkov</a>, 
<a href="/search/stat?searchtype=author&query=Panov%2C+M">Maxim Panov</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Prediction with the possibility of abstention (or selective prediction) is an
important problem for error-critical machine learning applications. While
well-studied in the classification setup, selective approaches to regression
are much less developed. In this work, we consider the nonparametric
heteroskedastic regression problem and develop an abstention procedure via
testing the hypothesis on the value of the conditional variance at a given
point. Unlike existing methods, the proposed one allows to account not only for
the value of the variance itself but also for the uncertainty of the
corresponding variance predictor. We prove non-asymptotic bounds on the risk of
the resulting estimator and show the existence of several different convergence
regimes. Theoretical analysis is illustrated with a series of experiments on
simulated and real-world data.
</p>
</div>
</dd>
<dt><a name="item361">[361]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16431" title="Abstract">arXiv:2309.16431</a> (cross-list from quant-ph) [<a href="/pdf/2309.16431" title="Download PDF">pdf</a>, <a href="/ps/2309.16431" title="Download PostScript">ps</a>, <a href="/format/2309.16431" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> QSETH strikes again: finer quantum lower bounds for lattice problem,  strong simulation, hitting set problem, and more
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Chen%2C+Y">Yanlin Chen</a>, 
<a href="/search/quant-ph?searchtype=author&query=Chen%2C+Y">Yilei Chen</a>, 
<a href="/search/quant-ph?searchtype=author&query=Kumar%2C+R">Rajendra Kumar</a>, 
<a href="/search/quant-ph?searchtype=author&query=Patro%2C+S">Subhasree Patro</a>, 
<a href="/search/quant-ph?searchtype=author&query=Speelman%2C+F">Florian Speelman</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 34 pages, 2 tables, 2 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Computational Complexity (cs.CC)

</div>
<p class="mathjax">While seemingly undesirable, it is not a surprising fact that there are
certain problems for which quantum computers offer no computational advantage
over their respective classical counterparts. Moreover, there are problems for
which there is no `useful' computational advantage possible with the current
quantum hardware. This situation however can be beneficial if we don't want
quantum computers to solve certain problems fast - say problems relevant to
post-quantum cryptography. In such a situation, we would like to have evidence
that it is difficult to solve those problems on quantum computers; but what is
their exact complexity?
<br />To do so one has to prove lower bounds, but proving unconditional time lower
bounds has never been easy. As a result, resorting to conditional lower bounds
has been quite popular in the classical community and is gaining momentum in
the quantum community. In this paper, by the use of the QSETH framework
[Buhrman-Patro-Speelman 2021], we are able to understand the quantum complexity
of a few natural variants of CNFSAT, such as parity-CNFSAT or counting-CNFSAT,
and also are able to comment on the non-trivial complexity of
approximate-#CNFSAT; both of these have interesting implications about the
complexity of (variations of) lattice problems, strong simulation and hitting
set problem, and more.
<br />In the process, we explore the QSETH framework in greater detail than was
(required and) discussed in the original paper, thus also serving as a useful
guide on how to effectively use the QSETH framework.
</p>
</div>
</dd>
<dt><a name="item362">[362]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16448" title="Abstract">arXiv:2309.16448</a> (cross-list from stat.ML) [<a href="/pdf/2309.16448" title="Download PDF">pdf</a>, <a href="/ps/2309.16448" title="Download PostScript">ps</a>, <a href="/format/2309.16448" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A parsimonious, computationally efficient machine learning method for  spatial regression
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=%C5%BDukovi%C4%8D%2C+M">Milan &#x17d;ukovi&#x10d;</a>, 
<a href="/search/stat?searchtype=author&query=Hristopulos%2C+D+T">Dionissios T. Hristopulos</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 42 pages, 15 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">We introduce the modified planar rotator method (MPRS), a physically inspired
machine learning method for spatial/temporal regression. MPRS is a
non-parametric model which incorporates spatial or temporal correlations via
short-range, distance-dependent ``interactions'' without assuming a specific
form for the underlying probability distribution. Predictions are obtained by
means of a fully autonomous learning algorithm which employs equilibrium
conditional Monte Carlo simulations. MPRS is able to handle scattered data and
arbitrary spatial dimensions. We report tests on various synthetic and
real-word data in one, two and three dimensions which demonstrate that the MPRS
prediction performance (without parameter tuning) is competitive with standard
interpolation methods such as ordinary kriging and inverse distance weighting.
In particular, MPRS is a particularly effective gap-filling method for rough
and non-Gaussian data (e.g., daily precipitation time series). MPRS shows
superior computational efficiency and scalability for large samples. Massive
data sets involving millions of nodes can be processed in a few seconds on a
standard personal computer.
</p>
</div>
</dd>
<dt><a name="item363">[363]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16465" title="Abstract">arXiv:2309.16465</a> (cross-list from q-bio.QM) [<a href="/pdf/2309.16465" title="Download PDF">pdf</a>, <a href="/format/2309.16465" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Metaheuristic for Amortized Search in High-Dimensional Parameter  Spaces
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-bio?searchtype=author&query=Boutet%2C+D">Dominic Boutet</a>, 
<a href="/search/q-bio?searchtype=author&query=Baillet%2C+S">Sylvain Baillet</a> (Montreal Neurological Institute, McGill University, Montreal QC, Canada)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantitative Methods (q-bio.QM)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Parameter inference for dynamical models of (bio)physical systems remains a
challenging problem. Intractable gradients, high-dimensional spaces, and
non-linear model functions are typically problematic without large
computational budgets. A recent body of work in that area has focused on
Bayesian inference methods, which consider parameters under their statistical
distributions and therefore, do not derive point estimates of optimal parameter
values. Here we propose a new metaheuristic that drives dimensionality
reductions from feature-informed transformations (DR-FFIT) to address these
bottlenecks. DR-FFIT implements an efficient sampling strategy that facilitates
a gradient-free parameter search in high-dimensional spaces. We use artificial
neural networks to obtain differentiable proxies for the model's features of
interest. The resulting gradients enable the estimation of a local active
subspace of the model within a defined sampling region. This approach enables
efficient dimensionality reductions of highly non-linear search spaces at a low
computational cost. Our test data show that DR-FFIT boosts the performances of
random-search and simulated-annealing against well-established metaheuristics,
and improves the goodness-of-fit of the model, all within contained run-time
costs.
</p>
</div>
</dd>
<dt><a name="item364">[364]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16475" title="Abstract">arXiv:2309.16475</a> (cross-list from quant-ph) [<a href="/pdf/2309.16475" title="Download PDF">pdf</a>, <a href="/format/2309.16475" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Circuit-to-Hamiltonian from tensor networks and fault tolerance
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Anshu%2C+A">Anurag Anshu</a>, 
<a href="/search/quant-ph?searchtype=author&query=Breuckmann%2C+N+P">Nikolas P. Breuckmann</a>, 
<a href="/search/quant-ph?searchtype=author&query=Nguyen%2C+Q+T">Quynh T. Nguyen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Computational Complexity (cs.CC)

</div>
<p class="mathjax">We define a map from an arbitrary quantum circuit to a local Hamiltonian
whose ground state encodes the quantum computation. All previous maps relied on
the Feynman-Kitaev construction, which introduces an ancillary `clock register'
to track the computational steps. Our construction, on the other hand, relies
on injective tensor networks with associated parent Hamiltonians, avoiding the
introduction of a clock register. This comes at the cost of the ground state
containing only a noisy version of the quantum computation, with independent
stochastic noise. We can remedy this - making our construction robust - by
using quantum fault tolerance. In addition to the stochastic noise, we show
that any state with energy density exponentially small in the circuit depth
encodes a noisy version of the quantum computation with adversarial noise. We
also show that any `combinatorial state' with energy density polynomially small
in depth encodes the quantum computation with adversarial noise. This serves as
evidence that any state with energy density polynomially small in depth has a
similar property. As an application, we show that contracting injective tensor
networks to additive error is BQP-hard. We also discuss the implication of our
construction to the quantum PCP conjecture, combining with an observation that
QMA verification can be done in logarithmic depth.
</p>
</div>
</dd>
<dt><a name="item365">[365]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16476" title="Abstract">arXiv:2309.16476</a> (cross-list from math.ST) [<a href="/pdf/2309.16476" title="Download PDF">pdf</a>, <a href="/format/2309.16476" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> High-dimensional robust regression under heavy-tailed data: Asymptotics  and Universality
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Adomaityte%2C+U">Urte Adomaityte</a>, 
<a href="/search/math?searchtype=author&query=Defilippis%2C+L">Leonardo Defilippis</a>, 
<a href="/search/math?searchtype=author&query=Loureiro%2C+B">Bruno Loureiro</a>, 
<a href="/search/math?searchtype=author&query=Sicuro%2C+G">Gabriele Sicuro</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages + Supplementary information
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Statistics Theory (math.ST)</span>; Disordered Systems and Neural Networks (cond-mat.dis-nn); Machine Learning (cs.LG); Machine Learning (stat.ML)

</div>
<p class="mathjax">We investigate the high-dimensional properties of robust regression
estimators in the presence of heavy-tailed contamination of both the covariates
and response functions. In particular, we provide a sharp asymptotic
characterisation of M-estimators trained on a family of elliptical covariate
and noise data distributions including cases where second and higher moments do
not exist. We show that, despite being consistent, the Huber loss with
optimally tuned location parameter $\delta$ is suboptimal in the
high-dimensional regime in the presence of heavy-tailed noise, highlighting the
necessity of further regularisation to achieve optimal performance. This result
also uncovers the existence of a curious transition in $\delta$ as a function
of the sample complexity and contamination. Moreover, we derive the decay rates
for the excess risk of ridge regression. We show that, while it is both optimal
and universal for noise distributions with finite second moment, its decay rate
can be considerably faster when the covariates' second moment does not exist.
Finally, we show that our formulas readily generalise to a richer family of
models and data distributions, such as generalised linear estimation with
arbitrary convex regularisation trained on mixture models.
</p>
</div>
</dd>
<dt><a name="item366">[366]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16482" title="Abstract">arXiv:2309.16482</a> (cross-list from eess.AS) [<a href="/pdf/2309.16482" title="Download PDF">pdf</a>, <a href="/format/2309.16482" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Meeting Recognition with Continuous Speech Separation and  Transcription-Supported Diarization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=von+Neumann%2C+T">Thilo von Neumann</a>, 
<a href="/search/eess?searchtype=author&query=Boeddeker%2C+C">Christoph Boeddeker</a>, 
<a href="/search/eess?searchtype=author&query=Cord-Landwehr%2C+T">Tobias Cord-Landwehr</a>, 
<a href="/search/eess?searchtype=author&query=Delcroix%2C+M">Marc Delcroix</a>, 
<a href="/search/eess?searchtype=author&query=Haeb-Umbach%2C+R">Reinhold Haeb-Umbach</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to ICASSP 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Sound (cs.SD)

</div>
<p class="mathjax">We propose a modular pipeline for the single-channel separation, recognition,
and diarization of meeting-style recordings and evaluate it on the Libri-CSS
dataset. Using a Continuous Speech Separation (CSS) system with a TF-GridNet
separation architecture, followed by a speaker-agnostic speech recognizer, we
achieve state-of-the-art recognition performance in terms of Optimal Reference
Combination Word Error Rate (ORC WER). Then, a d-vector-based diarization
module is employed to extract speaker embeddings from the enhanced signals and
to assign the CSS outputs to the correct speaker. Here, we propose a
syntactically informed diarization using sentence- and word-level boundaries of
the ASR module to support speaker turn detection. This results in a
state-of-the-art Concatenated minimum-Permutation Word Error Rate (cpWER) for
the full meeting recognition pipeline.
</p>
</div>
</dd>
<dt><a name="item367">[367]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16489" title="Abstract">arXiv:2309.16489</a> (cross-list from math.PR) [<a href="/pdf/2309.16489" title="Download PDF">pdf</a>, <a href="/ps/2309.16489" title="Download PostScript">ps</a>, <a href="/format/2309.16489" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Pathwise convergence of the Euler scheme for rough and stochastic  differential equations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Allan%2C+A+L">Andrew L. Allan</a>, 
<a href="/search/math?searchtype=author&query=Kwossek%2C+A+P">Anna P. Kwossek</a>, 
<a href="/search/math?searchtype=author&query=Liu%2C+C">Chong Liu</a>, 
<a href="/search/math?searchtype=author&query=Pr%C3%B6mel%2C+D+J">David J. Pr&#xf6;mel</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 43 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Probability (math.PR)</span>; Numerical Analysis (math.NA)

</div>
<p class="mathjax">The convergence of the first order Euler scheme and an approximative variant
thereof, along with convergence rates, are established for rough differential
equations driven by c\`adl\`ag paths satisfying a suitable criterion, namely
the so-called Property (RIE), along time discretizations with vanishing mesh
size. This property is then verified for almost all sample paths of Brownian
motion, It\^o processes, L\'evy processes and general c\`adl\`ag
semimartingales, as well as the driving signals of both mixed and rough
stochastic differential equations, relative to various time discretizations.
Consequently, we obtain pathwise convergence in p-variation of the
Euler--Maruyama scheme for stochastic differential equations driven by these
processes.
</p>
</div>
</dd>
<dt><a name="item368">[368]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16492" title="Abstract">arXiv:2309.16492</a> (cross-list from stat.ME) [<a href="/pdf/2309.16492" title="Download PDF">pdf</a>, <a href="/format/2309.16492" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Asset Bundling for Wind Power Forecasting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Zhang%2C+H">Hanyu Zhang</a>, 
<a href="/search/stat?searchtype=author&query=Tanneau%2C+M">Mathieu Tanneau</a>, 
<a href="/search/stat?searchtype=author&query=Huang%2C+C">Chaofan Huang</a>, 
<a href="/search/stat?searchtype=author&query=Joseph%2C+V+R">V. Roshan Joseph</a>, 
<a href="/search/stat?searchtype=author&query=Wang%2C+S">Shangkun Wang</a>, 
<a href="/search/stat?searchtype=author&query=Van+Hentenryck%2C+P">Pascal Van Hentenryck</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Methodology (stat.ME)</span>; Artificial Intelligence (cs.AI); Applications (stat.AP); Machine Learning (stat.ML)

</div>
<p class="mathjax">The growing penetration of intermittent, renewable generation in US power
grids, especially wind and solar generation, results in increased operational
uncertainty. In that context, accurate forecasts are critical, especially for
wind generation, which exhibits large variability and is historically harder to
predict. To overcome this challenge, this work proposes a novel
Bundle-Predict-Reconcile (BPR) framework that integrates asset bundling,
machine learning, and forecast reconciliation techniques. The BPR framework
first learns an intermediate hierarchy level (the bundles), then predicts wind
power at the asset, bundle, and fleet level, and finally reconciles all
forecasts to ensure consistency. This approach effectively introduces an
auxiliary learning task (predicting the bundle-level time series) to help the
main learning tasks. The paper also introduces new asset-bundling criteria that
capture the spatio-temporal dynamics of wind power time series. Extensive
numerical experiments are conducted on an industry-size dataset of 283 wind
farms in the MISO footprint. The experiments consider short-term and day-ahead
forecasts, and evaluates a large variety of forecasting models that include
weather predictions as covariates. The results demonstrate the benefits of BPR,
which consistently and significantly improves forecast accuracy over baselines,
especially at the fleet level.
</p>
</div>
</dd>
<dt><a name="item369">[369]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16508" title="Abstract">arXiv:2309.16508</a> (cross-list from math.OC) [<a href="/pdf/2309.16508" title="Download PDF">pdf</a>, <a href="/format/2309.16508" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Computationally efficient solution of mixed integer model predictive  control problems via machine learning aided Benders Decomposition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Mitrai%2C+I">Ilias Mitrai</a>, 
<a href="/search/math?searchtype=author&query=Daoutidis%2C+P">Prodromos Daoutidis</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Systems and Control (eess.SY)

</div>
<p class="mathjax">Mixed integer Model Predictive Control (MPC) problems arise in the operation
of systems where discrete and continuous decisions must be taken simultaneously
to compensate for disturbances. The efficient solution of mixed integer MPC
problems requires the computationally efficient and robust online solution of
mixed integer optimization problems, which are generally difficult to solve. In
this paper, we propose a machine learning-based branch and check Generalized
Benders Decomposition algorithm for the efficient solution of such problems. We
use machine learning to approximate the effect of the complicating variables on
the subproblem by approximating the Benders cuts without solving the
subproblem, therefore, alleviating the need to solve the subproblem multiple
times. The proposed approach is applied to a mixed integer economic MPC case
study on the operation of chemical processes. We show that the proposed
algorithm always finds feasible solutions to the optimization problem, given
that the mixed integer MPC problem is feasible, and leads to a significant
reduction in solution time (up to 97% or 50x) while incurring small error (in
the order of 1%) compared to the application of standard and accelerated
Generalized Benders Decomposition.
</p>
</div>
</dd>
<dt><a name="item370">[370]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16521" title="Abstract">arXiv:2309.16521</a> (cross-list from stat.ML) [<a href="/pdf/2309.16521" title="Download PDF">pdf</a>, <a href="/format/2309.16521" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Generating Personalized Insulin Treatments Strategies with Deep  Conditional Generative Time Series Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Sch%C3%BCrch%2C+M">Manuel Sch&#xfc;rch</a>, 
<a href="/search/stat?searchtype=author&query=Li%2C+X">Xiang Li</a>, 
<a href="/search/stat?searchtype=author&query=Allam%2C+A">Ahmed Allam</a>, 
<a href="/search/stat?searchtype=author&query=Rathmes%2C+G">Giulia Rathmes</a>, 
<a href="/search/stat?searchtype=author&query=Mollaysa%2C+A">Amina Mollaysa</a>, 
<a href="/search/stat?searchtype=author&query=Cavelti-Weder%2C+C">Claudia Cavelti-Weder</a>, 
<a href="/search/stat?searchtype=author&query=Krauthammer%2C+M">Michael Krauthammer</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">We propose a novel framework that combines deep generative time series models
with decision theory for generating personalized treatment strategies. It
leverages historical patient trajectory data to jointly learn the generation of
realistic personalized treatment and future outcome trajectories through deep
generative time series models. In particular, our framework enables the
generation of novel multivariate treatment strategies tailored to the
personalized patient history and trained for optimal expected future outcomes
based on conditional expected utility maximization. We demonstrate our
framework by generating personalized insulin treatment strategies and blood
glucose predictions for hospitalized diabetes patients, showcasing the
potential of our approach for generating improved personalized treatment
strategies. Keywords: deep generative model, probabilistic decision support,
personalized treatment generation, insulin and blood glucose prediction
</p>
</div>
</dd>
<dt><a name="item371">[371]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16536" title="Abstract">arXiv:2309.16536</a> (cross-list from eess.IV) [<a href="/pdf/2309.16536" title="Download PDF">pdf</a>, <a href="/format/2309.16536" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Uncertainty Quantification for Eosinophil Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Lin%2C+K">Kevin Lin</a>, 
<a href="/search/eess?searchtype=author&query=Brown%2C+D">Donald Brown</a>, 
<a href="/search/eess?searchtype=author&query=Syed%2C+S">Sana Syed</a>, 
<a href="/search/eess?searchtype=author&query=Greene%2C+A">Adam Greene</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Preprint, Final Article Submitted to ICBRA 2023 and will be published in the International Conference Proceedings by ACM, Association for Computing Machinery (ISBN: 979-8-4007-0815-2), which will be archived in ACM Digital Library, indexed by Ei Compendex and Scopus
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
<p class="mathjax">Eosinophilic Esophagitis (EoE) is an allergic condition increasing in
prevalence. To diagnose EoE, pathologists must find 15 or more eosinophils
within a single high-power field (400X magnification). Determining whether or
not a patient has EoE can be an arduous process and any medical imaging
approaches used to assist diagnosis must consider both efficiency and
precision. We propose an improvement of Adorno et al's approach for quantifying
eosinphils using deep image segmentation. Our new approach leverages Monte
Carlo Dropout, a common approach in deep learning to reduce overfitting, to
provide uncertainty quantification on current deep learning models. The
uncertainty can be visualized in an output image to evaluate model performance,
provide insight to how deep learning algorithms function, and assist
pathologists in identifying eosinophils.
</p>
</div>
</dd>
<dt><a name="item372">[372]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16549" title="Abstract">arXiv:2309.16549</a> (cross-list from math.RA) [<a href="/pdf/2309.16549" title="Download PDF">pdf</a>, <a href="/format/2309.16549" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The subpower membership problem of 2-nilpotent algebras
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Kompatscher%2C+M">Michael Kompatscher</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 17 pages (including appendix)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Rings and Algebras (math.RA)</span>; Computational Complexity (cs.CC)

</div>
<p class="mathjax">The subpower membership problem SMP(A) of a finite algebraic structure A asks
whether a given partial function from A^k to A can be interpolated by a term
operation of A, or not. While this problem can be EXPTIME-complete in general,
Willard asked whether it is always solvable in polynomial time if A is a
Mal'tsev algebras. In particular, this includes many important structures
studied in abstract algebra, such as groups, quasigroups, rings, Boolean
algebras. In this paper we give an affirmative answer to Willard's question for
a big class of 2-nilpotent Mal'tsev algebras. We furthermore develop tools that
might be essential in answering the question for general nilpotent Mal'tsev
algebras in the future.
</p>
</div>
</dd>
<dt><a name="item373">[373]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16563" title="Abstract">arXiv:2309.16563</a> (cross-list from stat.ML) [<a href="/pdf/2309.16563" title="Download PDF">pdf</a>, <a href="/format/2309.16563" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CRIMED: Lower and Upper Bounds on Regret for Bandits with Unbounded  Stochastic Corruption
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Agrawal%2C+S">Shubhada Agrawal</a>, 
<a href="/search/stat?searchtype=author&query=Mathieu%2C+T">Timoth&#xe9;e Mathieu</a>, 
<a href="/search/stat?searchtype=author&query=Basu%2C+D">Debabrota Basu</a>, 
<a href="/search/stat?searchtype=author&query=Maillard%2C+O">Odalric-Ambrym Maillard</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 50 pages; 4 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">We investigate the regret-minimisation problem in a multi-armed bandit
setting with arbitrary corruptions. Similar to the classical setup, the agent
receives rewards generated independently from the distribution of the arm
chosen at each time. However, these rewards are not directly observed. Instead,
with a fixed $\varepsilon\in (0,\frac{1}{2})$, the agent observes a sample from
the chosen arm's distribution with probability $1-\varepsilon$, or from an
arbitrary corruption distribution with probability $\varepsilon$. Importantly,
we impose no assumptions on these corruption distributions, which can be
unbounded. In this setting, accommodating potentially unbounded corruptions, we
establish a problem-dependent lower bound on regret for a given family of arm
distributions. We introduce CRIMED, an asymptotically-optimal algorithm that
achieves the exact lower bound on regret for bandits with Gaussian
distributions with known variance. Additionally, we provide a finite-sample
analysis of CRIMED's regret performance. Notably, CRIMED can effectively handle
corruptions with $\varepsilon$ values as high as $\frac{1}{2}$. Furthermore, we
develop a tight concentration result for medians in the presence of arbitrary
corruptions, even with $\varepsilon$ values up to $\frac{1}{2}$, which may be
of independent interest. We also discuss an extension of the algorithm for
handling misspecification in Gaussian model.
</p>
</div>
</dd>
<dt><a name="item374">[374]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16578" title="Abstract">arXiv:2309.16578</a> (cross-list from stat.ML) [<a href="/pdf/2309.16578" title="Download PDF">pdf</a>, <a href="/format/2309.16578" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> M-OFDFT: Overcoming the Barrier of Orbital-Free Density Functional  Theory for Molecular Systems Using Deep Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Zhang%2C+H">He Zhang</a>, 
<a href="/search/stat?searchtype=author&query=Liu%2C+S">Siyuan Liu</a>, 
<a href="/search/stat?searchtype=author&query=You%2C+J">Jiacheng You</a>, 
<a href="/search/stat?searchtype=author&query=Liu%2C+C">Chang Liu</a>, 
<a href="/search/stat?searchtype=author&query=Zheng%2C+S">Shuxin Zheng</a>, 
<a href="/search/stat?searchtype=author&query=Lu%2C+Z">Ziheng Lu</a>, 
<a href="/search/stat?searchtype=author&query=Wang%2C+T">Tong Wang</a>, 
<a href="/search/stat?searchtype=author&query=Zheng%2C+N">Nanning Zheng</a>, 
<a href="/search/stat?searchtype=author&query=Shao%2C+B">Bin Shao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG); Chemical Physics (physics.chem-ph)

</div>
<p class="mathjax">Orbital-free density functional theory (OFDFT) is a quantum chemistry
formulation that has a lower cost scaling than the prevailing Kohn-Sham DFT,
which is increasingly desired for contemporary molecular research. However, its
accuracy is limited by the kinetic energy density functional, which is
notoriously hard to approximate for non-periodic molecular systems. In this
work, we propose M-OFDFT, an OFDFT approach capable of solving molecular
systems using a deep-learning functional model. We build the essential
nonlocality into the model, which is made affordable by the concise density
representation as expansion coefficients under an atomic basis. With techniques
to address unconventional learning challenges therein, M-OFDFT achieves a
comparable accuracy with Kohn-Sham DFT on a wide range of molecules untouched
by OFDFT before. More attractively, M-OFDFT extrapolates well to molecules much
larger than those in training, which unleashes the appealing scaling for
studying large molecules including proteins, representing an advancement of the
accuracy-efficiency trade-off frontier in quantum chemistry.
</p>
</div>
</dd>
<dt><a name="item375">[375]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16596" title="Abstract">arXiv:2309.16596</a> (cross-list from quant-ph) [<a href="/pdf/2309.16596" title="Download PDF">pdf</a>, <a href="/format/2309.16596" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Local minima in quantum systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Chen%2C+C">Chi-Fang Chen</a>, 
<a href="/search/quant-ph?searchtype=author&query=Huang%2C+H">Hsin-Yuan Huang</a>, 
<a href="/search/quant-ph?searchtype=author&query=Preskill%2C+J">John Preskill</a>, 
<a href="/search/quant-ph?searchtype=author&query=Zhou%2C+L">Leo Zhou</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9+80 pages, 4 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Disordered Systems and Neural Networks (cond-mat.dis-nn); Computational Complexity (cs.CC); Mathematical Physics (math-ph); Optimization and Control (math.OC)

</div>
<p class="mathjax">Finding ground states of quantum many-body systems is known to be hard for
both classical and quantum computers. As a result, when Nature cools a quantum
system in a low-temperature thermal bath, the ground state cannot always be
found efficiently. Instead, Nature finds a local minimum of the energy. In this
work, we study the problem of finding local minima in quantum systems under
thermal perturbations. While local minima are much easier to find than ground
states, we show that finding a local minimum is computationally hard for
classical computers, even when the task is to output a single-qubit observable
at any local minimum. In contrast, we prove that a quantum computer can always
find a local minimum efficiently using a thermal gradient descent algorithm
that mimics the cooling process in Nature. To establish the classical hardness
of finding local minima, we consider a family of two-dimensional Hamiltonians
such that any problem solvable by polynomial-time quantum algorithms can be
reduced to finding ground states of these Hamiltonians. We prove that for such
Hamiltonians, all local minima are global minima. Therefore, assuming quantum
computation is more powerful than classical computation, finding local minima
is classically hard and quantumly easy.
</p>
</div>
</dd>
<dt><a name="item376">[376]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16598" title="Abstract">arXiv:2309.16598</a> (cross-list from stat.ML) [<a href="/pdf/2309.16598" title="Download PDF">pdf</a>, <a href="/format/2309.16598" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Cross-Prediction-Powered Inference
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Zrnic%2C+T">Tijana Zrnic</a>, 
<a href="/search/stat?searchtype=author&query=Cand%C3%A8s%2C+E+J">Emmanuel J. Cand&#xe8;s</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG); Methodology (stat.ME)

</div>
<p class="mathjax">While reliable data-driven decision-making hinges on high-quality labeled
data, the acquisition of quality labels often involves laborious human
annotations or slow and expensive scientific measurements. Machine learning is
becoming an appealing alternative as sophisticated predictive techniques are
being used to quickly and cheaply produce large amounts of predicted labels;
e.g., predicted protein structures are used to supplement experimentally
derived structures, predictions of socioeconomic indicators from satellite
imagery are used to supplement accurate survey data, and so on. Since
predictions are imperfect and potentially biased, this practice brings into
question the validity of downstream inferences. We introduce cross-prediction:
a method for valid inference powered by machine learning. With a small labeled
dataset and a large unlabeled dataset, cross-prediction imputes the missing
labels via machine learning and applies a form of debiasing to remedy the
prediction inaccuracies. The resulting inferences achieve the desired error
probability and are more powerful than those that only leverage the labeled
data. Closely related is the recent proposal of prediction-powered inference,
which assumes that a good pre-trained model is already available. We show that
cross-prediction is consistently more powerful than an adaptation of
prediction-powered inference in which a fraction of the labeled data is split
off and used to train the model. Finally, we observe that cross-prediction
gives more stable conclusions than its competitors; its confidence intervals
typically have significantly lower variability.
</p>
</div>
</dd>
<dt><a name="item377">[377]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16604" title="Abstract">arXiv:2309.16604</a> (cross-list from stat.ML) [<a href="/pdf/2309.16604" title="Download PDF">pdf</a>, <a href="/format/2309.16604" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exploiting Edge Features in Graphs with Fused Network Gromov-Wasserstein  Distance
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Yang%2C+J">Junjie Yang</a>, 
<a href="/search/stat?searchtype=author&query=Labeau%2C+M">Matthieu Labeau</a>, 
<a href="/search/stat?searchtype=author&query=d%27Alch%C3%A9-Buc%2C+F">Florence d&#x27;Alch&#xe9;-Buc</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Pairwise comparison of graphs is key to many applications in Machine learning
ranging from clustering, kernel-based classification/regression and more
recently supervised graph prediction. Distances between graphs usually rely on
informative representations of these structured objects such as bag of
substructures or other graph embeddings. A recently popular solution consists
in representing graphs as metric measure spaces, allowing to successfully
leverage Optimal Transport, which provides meaningful distances allowing to
compare them: the Gromov-Wasserstein distances. However, this family of
distances overlooks edge attributes, which are essential for many structured
objects. In this work, we introduce an extension of Gromov-Wasserstein distance
for comparing graphs whose both nodes and edges have features. We propose novel
algorithms for distance and barycenter computation. We empirically show the
effectiveness of the novel distance in learning tasks where graphs occur in
either input space or output space, such as classification and graph
prediction.
</p>
</div>
</dd>
<dt><a name="item378">[378]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16620" title="Abstract">arXiv:2309.16620</a> (cross-list from stat.ML) [<a href="/pdf/2309.16620" title="Download PDF">pdf</a>, <a href="/format/2309.16620" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Depthwise Hyperparameter Transfer in Residual Networks: Dynamics and  Scaling Limit
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Bordelon%2C+B">Blake Bordelon</a>, 
<a href="/search/stat?searchtype=author&query=Noci%2C+L">Lorenzo Noci</a>, 
<a href="/search/stat?searchtype=author&query=Li%2C+M+B">Mufan Bill Li</a>, 
<a href="/search/stat?searchtype=author&query=Hanin%2C+B">Boris Hanin</a>, 
<a href="/search/stat?searchtype=author&query=Pehlevan%2C+C">Cengiz Pehlevan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Disordered Systems and Neural Networks (cond-mat.dis-nn); Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">The cost of hyperparameter tuning in deep learning has been rising with model
sizes, prompting practitioners to find new tuning methods using a proxy of
smaller networks. One such proposal uses $\mu$P parameterized networks, where
the optimal hyperparameters for small width networks transfer to networks with
arbitrarily large width. However, in this scheme, hyperparameters do not
transfer across depths. As a remedy, we study residual networks with a residual
branch scale of $1/\sqrt{\text{depth}}$ in combination with the $\mu$P
parameterization. We provide experiments demonstrating that residual
architectures including convolutional ResNets and Vision Transformers trained
with this parameterization exhibit transfer of optimal hyperparameters across
width and depth on CIFAR-10 and ImageNet. Furthermore, our empirical findings
are supported and motivated by theory. Using recent developments in the
dynamical mean field theory (DMFT) description of neural network learning
dynamics, we show that this parameterization of ResNets admits a well-defined
feature learning joint infinite-width and infinite-depth limit and show
convergence of finite-size network dynamics towards this limit.
</p>
</div>
</dd>
<dt><a name="item379">[379]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16627" title="Abstract">arXiv:2309.16627</a> (cross-list from eess.IV) [<a href="/pdf/2309.16627" title="Download PDF">pdf</a>, <a href="/format/2309.16627" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Class Activation Map-based Weakly supervised Hemorrhage Segmentation  using Resnet-LSTM in Non-Contrast Computed Tomography images
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Ramananda%2C+S+H">Shreyas H Ramananda</a>, 
<a href="/search/eess?searchtype=author&query=Sundaresan%2C+V">Vaanathi Sundaresan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">In clinical settings, intracranial hemorrhages (ICH) are routinely diagnosed
using non-contrast CT (NCCT) for severity assessment. Accurate automated
segmentation of ICH lesions is the initial and essential step, immensely useful
for such assessment. However, compared to other structural imaging modalities
such as MRI, in NCCT images ICH appears with very low contrast and poor SNR.
Over recent years, deep learning (DL)-based methods have shown great potential,
however, training them requires a huge amount of manually annotated
lesion-level labels, with sufficient diversity to capture the characteristics
of ICH. In this work, we propose a novel weakly supervised DL method for ICH
segmentation on NCCT scans, using image-level binary classification labels,
which are less time-consuming and labor-efficient when compared to the manual
labeling of individual ICH lesions. Our method initially determines the
approximate location of ICH using class activation maps from a classification
network, which is trained to learn dependencies across contiguous slices. We
further refine the ICH segmentation using pseudo-ICH masks obtained in an
unsupervised manner. The method is flexible and uses a computationally light
architecture during testing. On evaluating our method on the validation data of
the MICCAI 2022 INSTANCE challenge, our method achieves a Dice value of 0.55,
comparable with those of existing weakly supervised method (Dice value of
0.47), despite training on a much smaller training data.
</p>
</div>
</dd>
</dl>
<h3>Replacements for Fri, 29 Sep 23</h3>
<dl>
<dt><a name="item380">[380]</a>&nbsp;  <span class="list-identifier"><a href="/abs/1812.00029" title="Abstract">arXiv:1812.00029</a> (replaced) [<a href="/pdf/1812.00029" title="Download PDF">pdf</a>, <a href="/format/1812.00029" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning Interpretable Characteristic Kernels via Decision Forests
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Panda%2C+S">Sambit Panda</a>, 
<a href="/search/stat?searchtype=author&query=Shen%2C+C">Cencheng Shen</a>, 
<a href="/search/stat?searchtype=author&query=Vogelstein%2C+J+T">Joshua T. Vogelstein</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item381">[381]</a>&nbsp;  <span class="list-identifier"><a href="/abs/1910.03656" title="Abstract">arXiv:1910.03656</a> (replaced) [<a href="/pdf/1910.03656" title="Download PDF">pdf</a>, <a href="/format/1910.03656" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Bayesian open games
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bolt%2C+J">Joe Bolt</a>, 
<a href="/search/cs?searchtype=author&query=Hedges%2C+J">Jules Hedges</a>, 
<a href="/search/cs?searchtype=author&query=Zahn%2C+P">Philipp Zahn</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Compositionality 5, 9 (2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>; Category Theory (math.CT)

</div>
</div>
</dd>
<dt><a name="item382">[382]</a>&nbsp;  <span class="list-identifier"><a href="/abs/1911.09307" title="Abstract">arXiv:1911.09307</a> (replaced) [<a href="/pdf/1911.09307" title="Download PDF">pdf</a>, <a href="/format/1911.09307" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Patch-level Neighborhood Interpolation: A General and Effective  Graph-based Regularization Strategy
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sun%2C+K">Ke Sun</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+B">Bing Yu</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+Z">Zhouchen Lin</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+Z">Zhanxing Zhu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted in ACML 2023 conference track
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item383">[383]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2005.07917" title="Abstract">arXiv:2005.07917</a> (replaced) [<a href="/pdf/2005.07917" title="Download PDF">pdf</a>, <a href="/format/2005.07917" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Gathering on a Circle with Limited Visibility by Anonymous Oblivious  Robots
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Di+Luna%2C+G+A">Giuseppe A. Di Luna</a>, 
<a href="/search/cs?searchtype=author&query=Uehara%2C+R">Ryuhei Uehara</a>, 
<a href="/search/cs?searchtype=author&query=Viglietta%2C+G">Giovanni Viglietta</a>, 
<a href="/search/cs?searchtype=author&query=Yamauchi%2C+Y">Yukiko Yamauchi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 33 pages, 9 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>; Computational Geometry (cs.CG); Robotics (cs.RO)

</div>
</div>
</dd>
<dt><a name="item384">[384]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2103.02324" title="Abstract">arXiv:2103.02324</a> (replaced) [<a href="/pdf/2103.02324" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Estimating the Expected Influence Capacities of Nodes in Complex  Networks under the Susceptible-Infectious-Recovered (SIR) Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=%C5%9Eim%C5%9Fek%2C+A">Aybike &#x15e;im&#x15f;ek</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> There was a minor inaccuracy in coefficient calculation for a competitor centrality measure named as Convex Combinations of Centrality Measures. So, we excluded this centrality measure. Also, there were some minor computational errors in monotonicity calculations, which we think are caused by the computational precision of the programming tools we use or the computer. We fixed it
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>

</div>
</div>
</dd>
<dt><a name="item385">[385]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2103.09882" title="Abstract">arXiv:2103.09882</a> (replaced) [<a href="/pdf/2103.09882" title="Download PDF">pdf</a>, <a href="/format/2103.09882" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Hierarchical Attention-based Age Estimation and Bias Estimation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hiba%2C+S">Shakediel Hiba</a>, 
<a href="/search/cs?searchtype=author&query=Keller%2C+Y">Yosi Keller</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages, 7 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item386">[386]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2106.00749" title="Abstract">arXiv:2106.00749</a> (replaced) [<a href="/pdf/2106.00749" title="Download PDF">pdf</a>, <a href="/format/2106.00749" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Higher-order Derivatives of Weighted Finite-state Machines
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zmigrod%2C+R">Ran Zmigrod</a>, 
<a href="/search/cs?searchtype=author&query=Vieira%2C+T">Tim Vieira</a>, 
<a href="/search/cs?searchtype=author&query=Cotterell%2C+R">Ryan Cotterell</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item387">[387]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2107.09834" title="Abstract">arXiv:2107.09834</a> (replaced) [<a href="/pdf/2107.09834" title="Download PDF">pdf</a>, <a href="/format/2107.09834" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Communication lower bounds for nested bilinear algorithms via rank  expansion of Kronecker products
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ju%2C+C">Caleb Ju</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yifan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Solomonik%2C+E">Edgar Solomonik</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 47 pages, 6 figures, 1 table. Revisions to paper for submission
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>; Numerical Analysis (math.NA)

</div>
</div>
</dd>
<dt><a name="item388">[388]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2108.12547" title="Abstract">arXiv:2108.12547</a> (replaced) [<a href="/pdf/2108.12547" title="Download PDF">pdf</a>, <a href="/format/2108.12547" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Dynamic Selection in Algorithmic Decision-making
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/econ?searchtype=author&query=Li%2C+J">Jin Li</a>, 
<a href="/search/econ?searchtype=author&query=Luo%2C+Y">Ye Luo</a>, 
<a href="/search/econ?searchtype=author&query=Zhang%2C+X">Xiaowei Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Main Body: 27 pages, 4 figures, 1 table; Supplemental Material: 30 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Econometrics (econ.EM)</span>; Machine Learning (cs.LG); Optimization and Control (math.OC); Methodology (stat.ME); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item389">[389]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2109.03890" title="Abstract">arXiv:2109.03890</a> (replaced) [<a href="/e-print/2109.03890" title="Download source">src</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Axiomatic Aggregations of Abductive Explanations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Biradar%2C+G">Gagan Biradar</a>, 
<a href="/search/cs?searchtype=author&query=Izza%2C+Y">Yacine Izza</a>, 
<a href="/search/cs?searchtype=author&query=Lobo%2C+E">Elita Lobo</a>, 
<a href="/search/cs?searchtype=author&query=Viswanathan%2C+V">Vignesh Viswanathan</a>, 
<a href="/search/cs?searchtype=author&query=Zick%2C+Y">Yair Zick</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This version is significantly different from the previous versions due to its focus on abductive explanations. We will therefore re-upload it with the same (or similar) title as a different manuscript
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item390">[390]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2109.06977" title="Abstract">arXiv:2109.06977</a> (replaced) [<a href="/pdf/2109.06977" title="Download PDF">pdf</a>, <a href="/format/2109.06977" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Design Guidelines for Prompt Engineering Text-to-Image Generative Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+V">Vivian Liu</a>, 
<a href="/search/cs?searchtype=author&query=Chilton%2C+L+B">Lydia B. Chilton</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
</div>
</dd>
<dt><a name="item391">[391]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2111.05175" title="Abstract">arXiv:2111.05175</a> (replaced) [<a href="/pdf/2111.05175" title="Download PDF">pdf</a>, <a href="/format/2111.05175" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Area Rate Efficiency in Multi-Link Molecular Communications
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Brand%2C+L">Lukas Brand</a>, 
<a href="/search/cs?searchtype=author&query=Lotter%2C+S">Sebastian Lotter</a>, 
<a href="/search/cs?searchtype=author&query=Jamali%2C+V">Vahid Jamali</a>, 
<a href="/search/cs?searchtype=author&query=Schober%2C+R">Robert Schober</a>, 
<a href="/search/cs?searchtype=author&query=Sch%C3%A4fer%2C+M">Maximilian Sch&#xe4;fer</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 pages double column, 15 figures, 1 table. This paper has been accepted for publication in the IEEE Transactions on Molecular, Biological, and Multi-Scale Communications. arXiv admin note: text overlap with <a href="/abs/2105.01590">arXiv:2105.01590</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Emerging Technologies (cs.ET)

</div>
</div>
</dd>
<dt><a name="item392">[392]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2112.00723" title="Abstract">arXiv:2112.00723</a> (replaced) [<a href="/pdf/2112.00723" title="Download PDF">pdf</a>, <a href="/format/2112.00723" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Infinite Neural Network Quantum States: Entanglement and Training  Dynamics
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Luo%2C+D">Di Luo</a>, 
<a href="/search/quant-ph?searchtype=author&query=Halverson%2C+J">James Halverson</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Mach. Learn.: Sci. Technol. 4 025038 (2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Disordered Systems and Neural Networks (cond-mat.dis-nn); Machine Learning (cs.LG); High Energy Physics - Theory (hep-th)

</div>
</div>
</dd>
<dt><a name="item393">[393]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2202.05135" title="Abstract">arXiv:2202.05135</a> (replaced) [<a href="/pdf/2202.05135" title="Download PDF">pdf</a>, <a href="/format/2202.05135" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Group-Agent Reinforcement Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+K">Kaiyue Wu</a>, 
<a href="/search/cs?searchtype=author&query=Zeng%2C+X">Xiao-Jun Zeng</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item394">[394]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2202.09134" title="Abstract">arXiv:2202.09134</a> (replaced) [<a href="/pdf/2202.09134" title="Download PDF">pdf</a>, <a href="/format/2202.09134" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Data Augmentation in the Underparameterized and Overparameterized  Regimes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+K+H">Kevin Han Huang</a>, 
<a href="/search/cs?searchtype=author&query=Orbanz%2C+P">Peter Orbanz</a>, 
<a href="/search/cs?searchtype=author&query=Austern%2C+M">Morgane Austern</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Changed title and added an analysis on the effect of augmentations on the double-descent risk curve of a high-dimensional ridgeless estimator
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Statistics Theory (math.ST); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item395">[395]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2202.12496" title="Abstract">arXiv:2202.12496</a> (replaced) [<a href="/pdf/2202.12496" title="Download PDF">pdf</a>, <a href="/ps/2202.12496" title="Download PostScript">ps</a>, <a href="/format/2202.12496" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Parametrized constant-depth quantum neuron
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=de+Carvalho%2C+J+H+A">Jonathan H. A. de Carvalho</a>, 
<a href="/search/quant-ph?searchtype=author&query=de+Paula+Neto%2C+F+M">Fernando M. de Paula Neto</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted version. 21 pages, 14 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Emerging Technologies (cs.ET)

</div>
</div>
</dd>
<dt><a name="item396">[396]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2203.03959" title="Abstract">arXiv:2203.03959</a> (replaced) [<a href="/pdf/2203.03959" title="Download PDF">pdf</a>, <a href="/format/2203.03959" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Enhancing Door-Status Detection for Autonomous Mobile Robots during  Environment-Specific Operational Use
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Antonazzi%2C+M">Michele Antonazzi</a>, 
<a href="/search/cs?searchtype=author&query=Luperto%2C+M">Matteo Luperto</a>, 
<a href="/search/cs?searchtype=author&query=Basilico%2C+N">Nicola Basilico</a>, 
<a href="/search/cs?searchtype=author&query=Borghese%2C+N+A">N. Alberto Borghese</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> 2023 European Conference on Mobile Robots (ECMR), Coimbra,
  Portugal, 2023, pp. 1-8
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
</div>
</dd>
<dt><a name="item397">[397]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2203.04975" title="Abstract">arXiv:2203.04975</a> (replaced) [<a href="/pdf/2203.04975" title="Download PDF">pdf</a>, <a href="/format/2203.04975" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Quantifying Grover speed-ups beyond asymptotic analysis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Cade%2C+C">Chris Cade</a>, 
<a href="/search/quant-ph?searchtype=author&query=Folkertsma%2C+M">Marten Folkertsma</a>, 
<a href="/search/quant-ph?searchtype=author&query=Niesen%2C+I">Ido Niesen</a>, 
<a href="/search/quant-ph?searchtype=author&query=Weggemans%2C+J">Jordi Weggemans</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 57 pages, 3 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Data Structures and Algorithms (cs.DS)

</div>
</div>
</dd>
<dt><a name="item398">[398]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2203.10486" title="Abstract">arXiv:2203.10486</a> (replaced) [<a href="/pdf/2203.10486" title="Download PDF">pdf</a>, <a href="/format/2203.10486" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Understanding Bulk-Bitwise Processing In-Memory Through Database  Analytics
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Perach%2C+B">Ben Perach</a>, 
<a href="/search/cs?searchtype=author&query=Ronen%2C+R">Ronny Ronen</a>, 
<a href="/search/cs?searchtype=author&query=Kimelfeld%2C+B">Benny Kimelfeld</a>, 
<a href="/search/cs?searchtype=author&query=Kvatinsky%2C+S">Shahar Kvatinsky</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> published in IEEE Transactions on Emerging Topics in Computing
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Hardware Architecture (cs.AR)</span>; Emerging Technologies (cs.ET)

</div>
</div>
</dd>
<dt><a name="item399">[399]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2204.09596" title="Abstract">arXiv:2204.09596</a> (replaced) [<a href="/pdf/2204.09596" title="Download PDF">pdf</a>, <a href="/format/2204.09596" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Risk-Averse Receding Horizon Motion Planning for Obstacle Avoidance  using Coherent Risk Measures
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Dixit%2C+A">Anushri Dixit</a>, 
<a href="/search/eess?searchtype=author&query=Ahmadi%2C+M">Mohamadreza Ahmadi</a>, 
<a href="/search/eess?searchtype=author&query=Burdick%2C+J+W">Joel W. Burdick</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to Artificial Intelligence Journal, Special Issue on Risk-aware Autonomous Systems: Theory and Practice. arXiv admin note: text overlap with <a href="/abs/2011.11211">arXiv:2011.11211</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Robotics (cs.RO); Optimization and Control (math.OC)

</div>
</div>
</dd>
<dt><a name="item400">[400]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2205.00147" title="Abstract">arXiv:2205.00147</a> (replaced) [<a href="/pdf/2205.00147" title="Download PDF">pdf</a>, <a href="/format/2205.00147" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DIRA: Dynamic Domain Incremental Regularised Adaptation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ghobrial%2C+A">Abanoub Ghobrial</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+X">Xuan Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Hond%2C+D">Darryl Hond</a>, 
<a href="/search/cs?searchtype=author&query=Asgari%2C+H">Hamid Asgari</a>, 
<a href="/search/cs?searchtype=author&query=Eder%2C+K">Kerstin Eder</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item401">[401]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2205.05625" title="Abstract">arXiv:2205.05625</a> (replaced) [<a href="/pdf/2205.05625" title="Download PDF">pdf</a>, <a href="/format/2205.05625" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Quantum Self-Attention Neural Networks for Text Classification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Li%2C+G">Guangxi Li</a>, 
<a href="/search/quant-ph?searchtype=author&query=Zhao%2C+X">Xuanqiang Zhao</a>, 
<a href="/search/quant-ph?searchtype=author&query=Wang%2C+X">Xin Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> v2 is close to the published version
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item402">[402]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2206.07836" title="Abstract">arXiv:2206.07836</a> (replaced) [<a href="/pdf/2206.07836" title="Download PDF">pdf</a>, <a href="/format/2206.07836" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Personal Entity, Concept, and Named Entity Linking in Conversations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Joko%2C+H">Hideaki Joko</a>, 
<a href="/search/cs?searchtype=author&query=Hasibi%2C+F">Faegheh Hasibi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Information Retrieval (cs.IR)

</div>
</div>
</dd>
<dt><a name="item403">[403]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2206.14171" title="Abstract">arXiv:2206.14171</a> (replaced) [<a href="/pdf/2206.14171" title="Download PDF">pdf</a>, <a href="/ps/2206.14171" title="Download PostScript">ps</a>, <a href="/format/2206.14171" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Formally Unimodular Packings for the Gaussian Wiretap Channel
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bollauf%2C+M+F">Maiara F. Bollauf</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+H">Hsuan-Yin Lin</a>, 
<a href="/search/cs?searchtype=author&query=Ytrehus%2C+%C3%98">&#xd8;yvind Ytrehus</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted for publication in IEEE Transactions on Information Theory. arXiv admin note: text overlap with <a href="/abs/2111.01439">arXiv:2111.01439</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>

</div>
</div>
</dd>
<dt><a name="item404">[404]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2207.08031" title="Abstract">arXiv:2207.08031</a> (replaced) [<a href="/pdf/2207.08031" title="Download PDF">pdf</a>, <a href="/ps/2207.08031" title="Download PostScript">ps</a>, <a href="/format/2207.08031" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MWS and FWS Codes for Coordinate-Wise Weight Functions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Alderson%2C+T">Tim Alderson</a>, 
<a href="/search/cs?searchtype=author&query=Morine%2C+B">Benjamin Morine</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 17 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Combinatorics (math.CO)

</div>
</div>
</dd>
<dt><a name="item405">[405]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2208.06308" title="Abstract">arXiv:2208.06308</a> (replaced) [<a href="/pdf/2208.06308" title="Download PDF">pdf</a>, <a href="/ps/2208.06308" title="Download PostScript">ps</a>, <a href="/format/2208.06308" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Developing a Philosophical Framework for Fair Machine Learning: Lessons  From The Case of Algorithmic Collusion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Michelson%2C+J">James Michelson</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computers and Society (cs.CY)

</div>
</div>
</dd>
<dt><a name="item406">[406]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2208.08310" title="Abstract">arXiv:2208.08310</a> (replaced) [<a href="/pdf/2208.08310" title="Download PDF">pdf</a>, <a href="/format/2208.08310" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Decomposition and factorisation of transients in Functional Graphs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Dor%C3%A9%2C+F">Fran&#xe7;ois Dor&#xe9;</a>, 
<a href="/search/math?searchtype=author&query=Formenti%2C+E">Enrico Formenti</a>, 
<a href="/search/math?searchtype=author&query=Porreca%2C+A+E">Antonio E. Porreca</a>, 
<a href="/search/math?searchtype=author&query=Riva%2C+S">Sara Riva</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Dynamical Systems (math.DS)</span>; Discrete Mathematics (cs.DM)

</div>
</div>
</dd>
<dt><a name="item407">[407]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2208.10074" title="Abstract">arXiv:2208.10074</a> (replaced) [<a href="/pdf/2208.10074" title="Download PDF">pdf</a>, <a href="/ps/2208.10074" title="Download PostScript">ps</a>, <a href="/format/2208.10074" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Product structure of graph classes with strongly sublinear separators
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Dvo%C5%99%C3%A1k%2C+Z">Zden&#x11b;k Dvo&#x159;&#xe1;k</a>, 
<a href="/search/math?searchtype=author&query=Wood%2C+D+R">David R. Wood</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> v2: added bad news subsection; v3: removed section "Polynomial Expansion Classes" which had an error, added section "Lower Bounds", and added a new author; v4: minor revisions and corrections;
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Combinatorics (math.CO)</span>; Discrete Mathematics (cs.DM)

</div>
</div>
</dd>
<dt><a name="item408">[408]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2208.14708" title="Abstract">arXiv:2208.14708</a> (replaced) [<a href="/pdf/2208.14708" title="Download PDF">pdf</a>, <a href="/format/2208.14708" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Classical-to-quantum convolutional neural network transfer learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Kim%2C+J">Juhyeon Kim</a>, 
<a href="/search/quant-ph?searchtype=author&query=Huh%2C+J">Joonsuk Huh</a>, 
<a href="/search/quant-ph?searchtype=author&query=Park%2C+D+K">Daniel K. Park</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 pages, 7 figures
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Neurocomputing 555 (2023) 126643
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item409">[409]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2209.04963" title="Abstract">arXiv:2209.04963</a> (replaced) [<a href="/pdf/2209.04963" title="Download PDF">pdf</a>, <a href="/format/2209.04963" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Responsible AI Pattern Catalogue: A Collection of Best Practices for AI  Governance and Engineering
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lu%2C+Q">Qinghua Lu</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+L">Liming Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+X">Xiwei Xu</a>, 
<a href="/search/cs?searchtype=author&query=Whittle%2C+J">Jon Whittle</a>, 
<a href="/search/cs?searchtype=author&query=Zowghi%2C+D">Didar Zowghi</a>, 
<a href="/search/cs?searchtype=author&query=Jacquet%2C+A">Aurelie Jacquet</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computers and Society (cs.CY); Software Engineering (cs.SE)

</div>
</div>
</dd>
<dt><a name="item410">[410]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2209.05856" title="Abstract">arXiv:2209.05856</a> (replaced) [<a href="/e-print/2209.05856" title="Download source">src</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Just Noticeable Difference Modeling for Face Recognition System
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tian%2C+Y">Yu Tian</a>, 
<a href="/search/cs?searchtype=author&query=Ni%2C+Z">Zhangkai Ni</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+B">Baoliang Chen</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Shurun Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Shiqi Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Hanli Wang</a>, 
<a href="/search/cs?searchtype=author&query=Kwong%2C+S">Sam Kwong</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> MegaFace dataset we used in the manuscript are no longer publicly available
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item411">[411]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2209.07403" title="Abstract">arXiv:2209.07403</a> (replaced) [<a href="/pdf/2209.07403" title="Download PDF">pdf</a>, <a href="/format/2209.07403" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Private Stochastic Optimization With Large Worst-Case Lipschitz  Parameter: Optimal Rates for (Non-Smooth) Convex Losses and Extension to  Non-Convex Losses
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lowy%2C+A">Andrew Lowy</a>, 
<a href="/search/cs?searchtype=author&query=Razaviyayn%2C+M">Meisam Razaviyayn</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> The 34th International Conference on Algorithmic Learning Theory (ALT 2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Cryptography and Security (cs.CR); Optimization and Control (math.OC); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item412">[412]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2210.00982" title="Abstract">arXiv:2210.00982</a> (replaced) [<a href="/pdf/2210.00982" title="Download PDF">pdf</a>, <a href="/format/2210.00982" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Assuring Safety of Vision-Based Swarm Formation Control
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hsieh%2C+C">Chiao Hsieh</a> (1), 
<a href="/search/cs?searchtype=author&query=Koh%2C+Y">Yubin Koh</a> (1), 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yangge Li</a> (1), 
<a href="/search/cs?searchtype=author&query=Mitra%2C+S">Sayan Mitra</a> (1) ((1) Coordinated Science Laboratory at the University of Illinois at Urbana-Champaign)
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 7 figures, submitted to the 2024 American Control Conference (ACC 2024)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Multiagent Systems (cs.MA)</span>; Robotics (cs.RO); Software Engineering (cs.SE)

</div>
</div>
</dd>
<dt><a name="item413">[413]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2210.06061" title="Abstract">arXiv:2210.06061</a> (replaced) [<a href="/pdf/2210.06061" title="Download PDF">pdf</a>, <a href="/format/2210.06061" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Non-Smooth, H&#xf6;lder-Smooth, and Robust Submodular Maximization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Lee%2C+D">Duksang Lee</a>, 
<a href="/search/math?searchtype=author&query=Ho-Nguyen%2C+N">Nam Ho-Nguyen</a>, 
<a href="/search/math?searchtype=author&query=Lee%2C+D">Dabeen Lee</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Data Structures and Algorithms (cs.DS)

</div>
</div>
</dd>
<dt><a name="item414">[414]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2210.06984" title="Abstract">arXiv:2210.06984</a> (replaced) [<a href="/pdf/2210.06984" title="Download PDF">pdf</a>, <a href="/format/2210.06984" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> QDTrack: Quasi-Dense Similarity Learning for Appearance-Only Multiple  Object Tracking
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fischer%2C+T">Tobias Fischer</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+T+E">Thomas E. Huang</a>, 
<a href="/search/cs?searchtype=author&query=Pang%2C+J">Jiangmiao Pang</a>, 
<a href="/search/cs?searchtype=author&query=Qiu%2C+L">Linlu Qiu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+H">Haofeng Chen</a>, 
<a href="/search/cs?searchtype=author&query=Darrell%2C+T">Trevor Darrell</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+F">Fisher Yu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item415">[415]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2211.03891" title="Abstract">arXiv:2211.03891</a> (replaced) [<a href="/pdf/2211.03891" title="Download PDF">pdf</a>, <a href="/ps/2211.03891" title="Download PostScript">ps</a>, <a href="/format/2211.03891" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A deterministic near-linear time approximation scheme for geometric  transportation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fox%2C+E">Emily Fox</a> (1), 
<a href="/search/cs?searchtype=author&query=Lu%2C+J">Jiashuai Lu</a> (1) ((1) The University of Texas at Dallas)
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To appear in FOCS 2023. 24 pages. Update 2: Added corrections for minimum cost flow approximation scheme. Addressed reviewer comments. Update 1: Adds a new randomized near-linear time approximation scheme for uncapacitated minimum cost flow in undirected graphs (transshipment) with arbitrary edge costs. References more recent work in geometric bipartite matching
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Geometry (cs.CG)</span>; Data Structures and Algorithms (cs.DS)

</div>
</div>
</dd>
<dt><a name="item416">[416]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2211.08217" title="Abstract">arXiv:2211.08217</a> (replaced) [<a href="/pdf/2211.08217" title="Download PDF">pdf</a>, <a href="/format/2211.08217" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Low-Shot Object Counting Network With Iterative Prototype Adaptation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Djukic%2C+N">Nikola Djukic</a>, 
<a href="/search/cs?searchtype=author&query=Lukezic%2C+A">Alan Lukezic</a>, 
<a href="/search/cs?searchtype=author&query=Zavrtanik%2C+V">Vitjan Zavrtanik</a>, 
<a href="/search/cs?searchtype=author&query=Kristan%2C+M">Matej Kristan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to ICCV2023, code: <a href="https://github.com/djukicn/loca">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item417">[417]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2211.09916" title="Abstract">arXiv:2211.09916</a> (replaced) [<a href="/pdf/2211.09916" title="Download PDF">pdf</a>, <a href="/format/2211.09916" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Online Distribution Shift Detection via Recency Prediction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Luo%2C+R">Rachel Luo</a>, 
<a href="/search/cs?searchtype=author&query=Sinha%2C+R">Rohan Sinha</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+Y">Yixiao Sun</a>, 
<a href="/search/cs?searchtype=author&query=Hindy%2C+A">Ali Hindy</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+S">Shengjia Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Savarese%2C+S">Silvio Savarese</a>, 
<a href="/search/cs?searchtype=author&query=Schmerling%2C+E">Edward Schmerling</a>, 
<a href="/search/cs?searchtype=author&query=Pavone%2C+M">Marco Pavone</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item418">[418]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2211.10754" title="Abstract">arXiv:2211.10754</a> (replaced) [<a href="/pdf/2211.10754" title="Download PDF">pdf</a>, <a href="/format/2211.10754" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> HALSIE: Hybrid Approach to Learning Segmentation by Simultaneously  Exploiting Image and Event Modalities
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Biswas%2C+S+D">Shristi Das Biswas</a>, 
<a href="/search/cs?searchtype=author&query=Kosta%2C+A">Adarsh Kosta</a>, 
<a href="/search/cs?searchtype=author&query=Liyanagedera%2C+C">Chamika Liyanagedera</a>, 
<a href="/search/cs?searchtype=author&query=Apolinario%2C+M">Marco Apolinario</a>, 
<a href="/search/cs?searchtype=author&query=Roy%2C+K">Kaushik Roy</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to IEEE/CVF Winter Conference on Applications of Computer Vision (WACV) 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item419">[419]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2211.12814" title="Abstract">arXiv:2211.12814</a> (replaced) [<a href="/pdf/2211.12814" title="Download PDF">pdf</a>, <a href="/format/2211.12814" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Vertical Federated Learning: Concepts, Advances and Challenges
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Kang%2C+Y">Yan Kang</a>, 
<a href="/search/cs?searchtype=author&query=Zou%2C+T">Tianyuan Zou</a>, 
<a href="/search/cs?searchtype=author&query=Pu%2C+Y">Yanhong Pu</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+Y">Yuanqin He</a>, 
<a href="/search/cs?searchtype=author&query=Ye%2C+X">Xiaozhou Ye</a>, 
<a href="/search/cs?searchtype=author&query=Ouyang%2C+Y">Ye Ouyang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Ya-Qin Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Q">Qiang Yang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> We added new works and revised the manuscript
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Cryptography and Security (cs.CR); Distributed, Parallel, and Cluster Computing (cs.DC)

</div>
</div>
</dd>
<dt><a name="item420">[420]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2211.16808" title="Abstract">arXiv:2211.16808</a> (replaced) [<a href="/pdf/2211.16808" title="Download PDF">pdf</a>, <a href="/format/2211.16808" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Efficient Adversarial Input Generation via Neural Net Patching
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Khan%2C+T">Tooba Khan</a>, 
<a href="/search/cs?searchtype=author&query=Madhukar%2C+K">Kumar Madhukar</a>, 
<a href="/search/cs?searchtype=author&query=Sharma%2C+S+V">Subodh Vishnu Sharma</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Cryptography and Security (cs.CR)

</div>
</div>
</dd>
<dt><a name="item421">[421]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2212.02941" title="Abstract">arXiv:2212.02941</a> (replaced) [<a href="/pdf/2212.02941" title="Download PDF">pdf</a>, <a href="/format/2212.02941" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Safe Imitation Learning of Nonlinear Model Predictive Control for  Flexible Robots
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mamedov%2C+S">Shamil Mamedov</a>, 
<a href="/search/cs?searchtype=author&query=Reiter%2C+R">Rudolf Reiter</a>, 
<a href="/search/cs?searchtype=author&query=Azad%2C+S+M+B">Seyed Mahdi Basiri Azad</a>, 
<a href="/search/cs?searchtype=author&query=Boedecker%2C+J">Joschka Boedecker</a>, 
<a href="/search/cs?searchtype=author&query=Diehl%2C+M">Moritz Diehl</a>, 
<a href="/search/cs?searchtype=author&query=Swevers%2C+J">Jan Swevers</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to ICRA 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Machine Learning (cs.LG); Optimization and Control (math.OC)

</div>
</div>
</dd>
<dt><a name="item422">[422]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2212.03072" title="Abstract">arXiv:2212.03072</a> (replaced) [<a href="/pdf/2212.03072" title="Download PDF">pdf</a>, <a href="/ps/2212.03072" title="Download PostScript">ps</a>, <a href="/format/2212.03072" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Inapproximability of Counting Independent Sets in Linear Hypergraphs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Qiu%2C+G">Guoliang Qiu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jiaheng Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted in Information Processing Letters
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Complexity (cs.CC)</span>; Discrete Mathematics (cs.DM); Data Structures and Algorithms (cs.DS)

</div>
</div>
</dd>
<dt><a name="item423">[423]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2212.03559" title="Abstract">arXiv:2212.03559</a> (replaced) [<a href="/pdf/2212.03559" title="Download PDF">pdf</a>, <a href="/format/2212.03559" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Attribute Graph Clustering via Learnable Augmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+X">Xihong Yang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yue Liu</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+K">Ke Liang</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+S">Sihang Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xinwang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+E">En Zhu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item424">[424]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2212.06129" title="Abstract">arXiv:2212.06129</a> (replaced) [<a href="/pdf/2212.06129" title="Download PDF">pdf</a>, <a href="/format/2212.06129" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Safe Reinforcement Learning with Probabilistic Guarantees Satisfying  Temporal Logic Specifications in Continuous Action Spaces
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Krasowski%2C+H">Hanna Krasowski</a>, 
<a href="/search/cs?searchtype=author&query=Akella%2C+P">Prithvi Akella</a>, 
<a href="/search/cs?searchtype=author&query=Ames%2C+A+D">Aaron D. Ames</a>, 
<a href="/search/cs?searchtype=author&query=Althoff%2C+M">Matthias Althoff</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Systems and Control (eess.SY)

</div>
</div>
</dd>
<dt><a name="item425">[425]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2212.10538" title="Abstract">arXiv:2212.10538</a> (replaced) [<a href="/pdf/2212.10538" title="Download PDF">pdf</a>, <a href="/format/2212.10538" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> HyperBO+: Pre-training a universal prior for Bayesian optimization with  hierarchical Gaussian processes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fan%2C+Z">Zhou Fan</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+X">Xinran Han</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zi Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Full version of the workshop paper at 2022 NeurIPS Workshop on Gaussian Processes, Spatiotemporal Modeling, and Decision-making Systems
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item426">[426]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2212.11654" title="Abstract">arXiv:2212.11654</a> (replaced) [<a href="/pdf/2212.11654" title="Download PDF">pdf</a>, <a href="/format/2212.11654" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Active SLAM: A Review On Last Decade
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ahmed%2C+M+F">Muhammad Farhan Ahmed</a>, 
<a href="/search/cs?searchtype=author&query=Masood%2C+K">Khayyam Masood</a>, 
<a href="/search/cs?searchtype=author&query=Fremont%2C+V">Vincent Fremont</a>, 
<a href="/search/cs?searchtype=author&query=Fantoni%2C+I">Isabelle Fantoni</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 34 pages, 8 figures, 6 tables
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Sensors 2023, 23, 8097
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
</div>
</dd>
<dt><a name="item427">[427]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.01253" title="Abstract">arXiv:2301.01253</a> (replaced) [<a href="/pdf/2301.01253" title="Download PDF">pdf</a>, <a href="/format/2301.01253" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deep learning for bias-correcting CMIP6-class Earth system models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Hess%2C+P">Philipp Hess</a>, 
<a href="/search/physics?searchtype=author&query=Lange%2C+S">Stefan Lange</a>, 
<a href="/search/physics?searchtype=author&query=Sch%C3%B6tz%2C+C">Christof Sch&#xf6;tz</a>, 
<a href="/search/physics?searchtype=author&query=Boers%2C+N">Niklas Boers</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Atmospheric and Oceanic Physics (physics.ao-ph)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item428">[428]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.02077" title="Abstract">arXiv:2301.02077</a> (replaced) [<a href="/pdf/2301.02077" title="Download PDF">pdf</a>, <a href="/format/2301.02077" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the $L^\infty(0,T;L^2(&#x3a9;)^d)$-stability of Discontinuous Galerkin  schemes for incompressible flows
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Gazca-Orozco%2C+P+A">Pablo Alexei Gazca-Orozco</a>, 
<a href="/search/math?searchtype=author&query=Kaltenbach%2C+A">Alex Kaltenbach</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> convergence proof has been added
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
</div>
</dd>
<dt><a name="item429">[429]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.09738" title="Abstract">arXiv:2301.09738</a> (replaced) [<a href="/pdf/2301.09738" title="Download PDF">pdf</a>, <a href="/format/2301.09738" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Security of Electrical, Optical and Wireless On-Chip Interconnects: A  Survey
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Weerasena%2C+H">Hansika Weerasena</a>, 
<a href="/search/cs?searchtype=author&query=Mishra%2C+P">Prabhat Mishra</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 41 pages, 24 figures, 4 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Hardware Architecture (cs.AR); Networking and Internet Architecture (cs.NI)

</div>
</div>
</dd>
<dt><a name="item430">[430]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.11562" title="Abstract">arXiv:2301.11562</a> (replaced) [<a href="/pdf/2301.11562" title="Download PDF">pdf</a>, <a href="/format/2301.11562" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Is My Prediction Arbitrary? Confounding Effects of Variance in Fair  Classification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cooper%2C+A+F">A. Feder Cooper</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+K">Katherine Lee</a>, 
<a href="/search/cs?searchtype=author&query=Choksi%2C+M">Madiha Choksi</a>, 
<a href="/search/cs?searchtype=author&query=Barocas%2C+S">Solon Barocas</a>, 
<a href="/search/cs?searchtype=author&query=De+Sa%2C+C">Christopher De Sa</a>, 
<a href="/search/cs?searchtype=author&query=Grimmelmann%2C+J">James Grimmelmann</a>, 
<a href="/search/cs?searchtype=author&query=Kleinberg%2C+J">Jon Kleinberg</a>, 
<a href="/search/cs?searchtype=author&query=Sen%2C+S">Siddhartha Sen</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+B">Baobao Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computers and Society (cs.CY); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item431">[431]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.00407" title="Abstract">arXiv:2302.00407</a> (replaced) [<a href="/pdf/2302.00407" title="Download PDF">pdf</a>, <a href="/format/2302.00407" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the Role of Morphological Information for Contextual Lemmatization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Toporkov%2C+O">Olia Toporkov</a>, 
<a href="/search/cs?searchtype=author&query=Agerri%2C+R">Rodrigo Agerri</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 30 pages, 5 figures, 11 tables; Accepted for publication in Computational Linguistics journal (to appear)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item432">[432]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.03587" title="Abstract">arXiv:2302.03587</a> (replaced) [<a href="/pdf/2302.03587" title="Download PDF">pdf</a>, <a href="/format/2302.03587" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Design of an Energy-Aware Cartesian Impedance Controller for  Collaborative Disassembly
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hjorth%2C+S">Sebastian Hjorth</a> (1), 
<a href="/search/cs?searchtype=author&query=Lamon%2C+E">Edoardo Lamon</a> (2), 
<a href="/search/cs?searchtype=author&query=Chrysostomou%2C+D">Dimitrios Chrysostomou</a> (1), 
<a href="/search/cs?searchtype=author&query=Ajoudani%2C+A">Arash Ajoudani</a> (2) ((1) Dept. of Materials and Production, Aalborg University, Aalborg, Denmark, (2) Human-Robot Interfaces and Interaction, Istituto Italiano di Tecnologia, Genoa, Italy)
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, 6 figures, presented at the 2023 IEEE International Conference on Robotics and Automation (ICRA). Video available at <a href="https://www.youtube-nocookie.com/embed/SgYFHMlEl0k">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
</div>
</dd>
<dt><a name="item433">[433]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.06807" title="Abstract">arXiv:2302.06807</a> (replaced) [<a href="/pdf/2302.06807" title="Download PDF">pdf</a>, <a href="/format/2302.06807" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Horospherical Decision Boundaries for Large Margin Classification in  Hyperbolic Space
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Fan%2C+X">Xiran Fan</a>, 
<a href="/search/stat?searchtype=author&query=Yang%2C+C">Chun-Hao Yang</a>, 
<a href="/search/stat?searchtype=author&query=Vemuri%2C+B+C">Baba C. Vemuri</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To appear at Neural Information Processing Systems (NeurIPS) 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item434">[434]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.08200" title="Abstract">arXiv:2302.08200</a> (replaced) [<a href="/pdf/2302.08200" title="Download PDF">pdf</a>, <a href="/ps/2302.08200" title="Download PostScript">ps</a>, <a href="/format/2302.08200" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Weak Similarity in Higher-Order Mathematical Operational Semantics
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Urbat%2C+H">Henning Urbat</a>, 
<a href="/search/cs?searchtype=author&query=Tsampas%2C+S">Stelios Tsampas</a>, 
<a href="/search/cs?searchtype=author&query=Goncharov%2C+S">Sergey Goncharov</a>, 
<a href="/search/cs?searchtype=author&query=Milius%2C+S">Stefan Milius</a>, 
<a href="/search/cs?searchtype=author&query=Schr%C3%B6der%2C+L">Lutz Schr&#xf6;der</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Programming Languages (cs.PL)</span>; Logic in Computer Science (cs.LO)

</div>
</div>
</dd>
<dt><a name="item435">[435]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.09648" title="Abstract">arXiv:2302.09648</a> (replaced) [<a href="/pdf/2302.09648" title="Download PDF">pdf</a>, <a href="/format/2302.09648" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Wrapyfi: A Wrapper for Message-Oriented and Robotics Middleware
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Abawi%2C+F">Fares Abawi</a>, 
<a href="/search/cs?searchtype=author&query=Allgeuer%2C+P">Philipp Allgeuer</a>, 
<a href="/search/cs?searchtype=author&query=Fu%2C+D">Di Fu</a>, 
<a href="/search/cs?searchtype=author&query=Wermter%2C+S">Stefan Wermter</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Distributed, Parallel, and Cluster Computing (cs.DC)

</div>
</div>
</dd>
<dt><a name="item436">[436]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.09907" title="Abstract">arXiv:2302.09907</a> (replaced) [<a href="/pdf/2302.09907" title="Download PDF">pdf</a>, <a href="/format/2302.09907" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> General Rotation Invariance Learning for Point Clouds via Weight-Feature  Alignment
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xie%2C+L">Liang Xie</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yibo Yang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+W">Wenxiao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+B">Binbin Lin</a>, 
<a href="/search/cs?searchtype=author&query=Cai%2C+D">Deng Cai</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+X">Xiaofei He</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+R">Ronghua Liang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 4 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item437">[437]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.09940" title="Abstract">arXiv:2302.09940</a> (replaced) [<a href="/pdf/2302.09940" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Computing persistent homology by spanning trees and critical simplices
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Shi%2C+D">Dinghua Shi</a>, 
<a href="/search/math?searchtype=author&query=Chen%2C+Z">Zhifeng Chen</a>, 
<a href="/search/math?searchtype=author&query=Ma%2C+C">Chuang Ma</a>, 
<a href="/search/math?searchtype=author&query=Chen%2C+G">Guanrong Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 6 figures, 5 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Algebraic Topology (math.AT)</span>; Computational Complexity (cs.CC)

</div>
</div>
</dd>
<dt><a name="item438">[438]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.09976" title="Abstract">arXiv:2302.09976</a> (replaced) [<a href="/pdf/2302.09976" title="Download PDF">pdf</a>, <a href="/format/2302.09976" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Discouraging posterior collapse in hierarchical Variational Autoencoders  using context
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kuzina%2C+A">Anna Kuzina</a>, 
<a href="/search/cs?searchtype=author&query=Tomczak%2C+J+M">Jakub M. Tomczak</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Code: <a href="https://github.com/AKuzina/dct_vae">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item439">[439]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.11578" title="Abstract">arXiv:2302.11578</a> (replaced) [<a href="/pdf/2302.11578" title="Download PDF">pdf</a>, <a href="/format/2302.11578" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Guidable Local Hamiltonian Problems with Implications to Heuristic  Ans&#xe4;tze State Preparation and the Quantum PCP Conjecture
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Weggemans%2C+J">Jordi Weggemans</a>, 
<a href="/search/quant-ph?searchtype=author&query=Folkertsma%2C+M">Marten Folkertsma</a>, 
<a href="/search/quant-ph?searchtype=author&query=Cade%2C+C">Chris Cade</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 61 pages, 6 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Computational Complexity (cs.CC)

</div>
</div>
</dd>
<dt><a name="item440">[440]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.00031" title="Abstract">arXiv:2303.00031</a> (replaced) [<a href="/pdf/2303.00031" title="Download PDF">pdf</a>, <a href="/format/2303.00031" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Tiny Classifier Circuits: Evolving Accelerators for Tabular Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Iordanou%2C+K">Konstantinos Iordanou</a>, 
<a href="/search/cs?searchtype=author&query=Atkinson%2C+T">Timothy Atkinson</a>, 
<a href="/search/cs?searchtype=author&query=Ozer%2C+E">Emre Ozer</a>, 
<a href="/search/cs?searchtype=author&query=Kufel%2C+J">Jedrzej Kufel</a>, 
<a href="/search/cs?searchtype=author&query=Biggs%2C+J">John Biggs</a>, 
<a href="/search/cs?searchtype=author&query=Brown%2C+G">Gavin Brown</a>, 
<a href="/search/cs?searchtype=author&query=Lujan%2C+M">Mikel Lujan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages, 16 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Hardware Architecture (cs.AR)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item441">[441]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.01952" title="Abstract">arXiv:2303.01952</a> (replaced) [<a href="/pdf/2303.01952" title="Download PDF">pdf</a>, <a href="/ps/2303.01952" title="Download PostScript">ps</a>, <a href="/format/2303.01952" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Quantum state testing beyond the polarizing regime and quantum  triangular discrimination
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Liu%2C+Y">Yupan Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 31 pages. v3: added a simple QSZK-hardness proof for QEDP, updated a correct version of Theorem 5.1(2), and improved presentation. v2: minor changes
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Computational Complexity (cs.CC); Information Theory (cs.IT)

</div>
</div>
</dd>
<dt><a name="item442">[442]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.02607" title="Abstract">arXiv:2303.02607</a> (replaced) [<a href="/pdf/2303.02607" title="Download PDF">pdf</a>, <a href="/format/2303.02607" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Tight Collision Probability for UAV Motion Planning in Uncertain  Environment
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+T">Tianyu Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+F">Fu Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+F">Fei Gao</a>, 
<a href="/search/cs?searchtype=author&query=Pan%2C+J">Jia Pan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Paper Accepted by IROS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
</div>
</dd>
<dt><a name="item443">[443]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.03031" title="Abstract">arXiv:2303.03031</a> (replaced) [<a href="/pdf/2303.03031" title="Download PDF">pdf</a>, <a href="/format/2303.03031" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Computational Landscape of Autonomous Mobile Robots: The Visibility  Perspective
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Das%2C+A">Archak Das</a>, 
<a href="/search/cs?searchtype=author&query=Ghosh%2C+S">Satakshi Ghosh</a>, 
<a href="/search/cs?searchtype=author&query=Sharma%2C+A">Avisek Sharma</a>, 
<a href="/search/cs?searchtype=author&query=Goswami%2C+P">Pritam Goswami</a>, 
<a href="/search/cs?searchtype=author&query=Sau%2C+B">Buddhadeb Sau</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: text overlap with <a href="/abs/2203.06546">arXiv:2203.06546</a> by other authors
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>

</div>
</div>
</dd>
<dt><a name="item444">[444]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.03037" title="Abstract">arXiv:2303.03037</a> (replaced) [<a href="/pdf/2303.03037" title="Download PDF">pdf</a>, <a href="/format/2303.03037" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> EvCenterNet: Uncertainty Estimation for Object Detection using  Evidential Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nallapareddy%2C+M+R">Monish R. Nallapareddy</a>, 
<a href="/search/cs?searchtype=author&query=Sirohi%2C+K">Kshitij Sirohi</a>, 
<a href="/search/cs?searchtype=author&query=J.%2C+P+L">Paulo L. J. Drews-Jr</a>, 
<a href="/search/cs?searchtype=author&query=Burgard%2C+W">Wolfram Burgard</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+C">Chih-Hong Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Valada%2C+A">Abhinav Valada</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item445">[445]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.03906" title="Abstract">arXiv:2303.03906</a> (replaced) [<a href="/pdf/2303.03906" title="Download PDF">pdf</a>, <a href="/ps/2303.03906" title="Download PostScript">ps</a>, <a href="/format/2303.03906" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Compositional Confluence Criteria
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shintani%2C+K">Kiraku Shintani</a>, 
<a href="/search/cs?searchtype=author&query=Hirokawa%2C+N">Nao Hirokawa</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 28 pages, 3 figures, 1 table, submitted to LMCS
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>

</div>
</div>
</dd>
<dt><a name="item446">[446]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.04032" title="Abstract">arXiv:2303.04032</a> (replaced) [<a href="/pdf/2303.04032" title="Download PDF">pdf</a>, <a href="/format/2303.04032" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GMCR: Graph-based Maximum Consensus Estimation for Point Cloud  Registration
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gentner%2C+M">Michael Gentner</a>, 
<a href="/search/cs?searchtype=author&query=Murali%2C+P+K">Prajval Kumar Murali</a>, 
<a href="/search/cs?searchtype=author&query=Kaboli%2C+M">Mohsen Kaboli</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at icra 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
</div>
</dd>
<dt><a name="item447">[447]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.04116" title="Abstract">arXiv:2303.04116</a> (replaced) [<a href="/pdf/2303.04116" title="Download PDF">pdf</a>, <a href="/format/2303.04116" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> TrafficBots: Towards World Models for Autonomous Driving Simulation and  Motion Prediction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zhejun Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Liniger%2C+A">Alexander Liniger</a>, 
<a href="/search/cs?searchtype=author&query=Dai%2C+D">Dengxin Dai</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+F">Fisher Yu</a>, 
<a href="/search/cs?searchtype=author&query=Van+Gool%2C+L">Luc Van Gool</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Published at ICRA 2023. The repository is available at <a href="https://github.com/zhejz/TrafficBots">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item448">[448]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.11003" title="Abstract">arXiv:2303.11003</a> (replaced) [<a href="/pdf/2303.11003" title="Download PDF">pdf</a>, <a href="/format/2303.11003" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Tubelet-Contrastive Self-Supervision for Video-Efficient Generalization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Thoker%2C+F+M">Fida Mohammad Thoker</a>, 
<a href="/search/cs?searchtype=author&query=Doughty%2C+H">Hazel Doughty</a>, 
<a href="/search/cs?searchtype=author&query=Snoek%2C+C">Cees Snoek</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted in ICCV 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item449">[449]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.12414" title="Abstract">arXiv:2303.12414</a> (replaced) [<a href="/pdf/2303.12414" title="Download PDF">pdf</a>, <a href="/format/2303.12414" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Delay-Aware Hierarchical Federated Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lin%2C+F+P">Frank Po-Chen Lin</a>, 
<a href="/search/cs?searchtype=author&query=Hosseinalipour%2C+S">Seyyedali Hosseinalipour</a>, 
<a href="/search/cs?searchtype=author&query=Michelusi%2C+N">Nicol&#xf2; Michelusi</a>, 
<a href="/search/cs?searchtype=author&query=Brinton%2C+C">Christopher Brinton</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> A condensed version of this paper was presented at IEEE Globecom 2020
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Distributed, Parallel, and Cluster Computing (cs.DC)

</div>
</div>
</dd>
<dt><a name="item450">[450]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.12506" title="Abstract">arXiv:2303.12506</a> (replaced) [<a href="/pdf/2303.12506" title="Download PDF">pdf</a>, <a href="/ps/2303.12506" title="Download PostScript">ps</a>, <a href="/format/2303.12506" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Leximin Approximation: From Single-Objective to Multi-Objective
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hartman%2C+E">Eden Hartman</a>, 
<a href="/search/cs?searchtype=author&query=Hassidim%2C+A">Avinatan Hassidim</a>, 
<a href="/search/cs?searchtype=author&query=Aumann%2C+Y">Yonatan Aumann</a>, 
<a href="/search/cs?searchtype=author&query=Segal-Halevi%2C+E">Erel Segal-Halevi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>; Data Structures and Algorithms (cs.DS); Multiagent Systems (cs.MA)

</div>
</div>
</dd>
<dt><a name="item451">[451]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.14454" title="Abstract">arXiv:2303.14454</a> (replaced) [<a href="/pdf/2303.14454" title="Download PDF">pdf</a>, <a href="/ps/2303.14454" title="Download PostScript">ps</a>, <a href="/format/2303.14454" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Weighted Fair Division with Matroid-Rank Valuations: Monotonicity and  Strategyproofness
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/econ?searchtype=author&query=Suksompong%2C+W">Warut Suksompong</a>, 
<a href="/search/econ?searchtype=author&query=Teh%2C+N">Nicholas Teh</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Appears in the 16th International Symposium on Algorithmic Game Theory (SAGT), 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Theoretical Economics (econ.TH)</span>; Computer Science and Game Theory (cs.GT)

</div>
</div>
</dd>
<dt><a name="item452">[452]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.16296" title="Abstract">arXiv:2303.16296</a> (replaced) [<a href="/pdf/2303.16296" title="Download PDF">pdf</a>, <a href="/format/2303.16296" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Dice Semimetric Losses: Optimizing the Dice Score with Soft Labels
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zifu Wang</a>, 
<a href="/search/cs?searchtype=author&query=Popordanoska%2C+T">Teodora Popordanoska</a>, 
<a href="/search/cs?searchtype=author&query=Bertels%2C+J">Jeroen Bertels</a>, 
<a href="/search/cs?searchtype=author&query=Lemmens%2C+R">Robin Lemmens</a>, 
<a href="/search/cs?searchtype=author&query=Blaschko%2C+M+B">Matthew B. Blaschko</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> MICCAI 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item453">[453]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.03652" title="Abstract">arXiv:2304.03652</a> (replaced) [<a href="/pdf/2304.03652" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An Accessible Toolkit for 360 VR Studies
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Green%2C+C">Corrie Green</a>, 
<a href="/search/cs?searchtype=author&query=Farr%2C+C">Chlo&#xeb; Farr</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+Y">Yang Jiang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> for associated github repo, <a href="https://github.com/corriedotdev/vr-360-player">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Multimedia (cs.MM)

</div>
</div>
</dd>
<dt><a name="item454">[454]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.06366" title="Abstract">arXiv:2304.06366</a> (replaced) [<a href="/pdf/2304.06366" title="Download PDF">pdf</a>, <a href="/format/2304.06366" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> IBIA: An Incremental Build-Infer-Approximate Framework for Approximate  Inference of Partition Function
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bathla%2C+S">Shivani Bathla</a>, 
<a href="/search/cs?searchtype=author&query=Vasudevan%2C+V">Vinita Vasudevan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Pages: 24(main) 3(references) 4(appendix), Figures: 5, Tables: 7
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Transaction on Machine Learning Research (TMLR), 09/2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item455">[455]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.07556" title="Abstract">arXiv:2304.07556</a> (replaced) [<a href="/pdf/2304.07556" title="Download PDF">pdf</a>, <a href="/format/2304.07556" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Unique Nash equilibrium of a nonlinear model of opinion dynamics on  networks with friction-inspired stubbornness
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Reynolds%2C+D+N">David N. Reynolds</a>, 
<a href="/search/math?searchtype=author&query=Tudisco%2C+F">Francesco Tudisco</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Dynamical Systems (math.DS)</span>; Social and Information Networks (cs.SI); Adaptation and Self-Organizing Systems (nlin.AO); Physics and Society (physics.soc-ph)

</div>
</div>
</dd>
<dt><a name="item456">[456]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.08551" title="Abstract">arXiv:2304.08551</a> (replaced) [<a href="/pdf/2304.08551" title="Download PDF">pdf</a>, <a href="/format/2304.08551" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Generative Disco: Text-to-Video Generation for Music Visualization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+V">Vivian Liu</a>, 
<a href="/search/cs?searchtype=author&query=Long%2C+T">Tao Long</a>, 
<a href="/search/cs?searchtype=author&query=Raw%2C+N">Nathan Raw</a>, 
<a href="/search/cs?searchtype=author&query=Chilton%2C+L">Lydia Chilton</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item457">[457]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.10749" title="Abstract">arXiv:2304.10749</a> (replaced) [<a href="/pdf/2304.10749" title="Download PDF">pdf</a>, <a href="/format/2304.10749" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Emergence of Brain-inspired Small-world Spiking Neural Network through  Neuroevolution
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pan%2C+W">Wenxuan Pan</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+F">Feifei Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+B">Bing Han</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+Y">Yiting Dong</a>, 
<a href="/search/cs?searchtype=author&query=Zeng%2C+Y">Yi Zeng</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neural and Evolutionary Computing (cs.NE)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item458">[458]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.12014" title="Abstract">arXiv:2304.12014</a> (replaced) [<a href="/pdf/2304.12014" title="Download PDF">pdf</a>, <a href="/format/2304.12014" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Optimal Layout Synthesis for Quantum Circuits as Classical Planning  (full version)
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Shaik%2C+I">Irfansha Shaik</a>, 
<a href="/search/quant-ph?searchtype=author&query=van+de+Pol%2C+J">Jaco van de Pol</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 5 figures, 15 listings and 2 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item459">[459]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.12405" title="Abstract">arXiv:2304.12405</a> (replaced) [<a href="/pdf/2304.12405" title="Download PDF">pdf</a>, <a href="/format/2304.12405" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Synthesizing Stable Reduced-Order Visuomotor Policies for Nonlinear  Systems via Sums-of-Squares Optimization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chou%2C+G">Glen Chou</a>, 
<a href="/search/cs?searchtype=author&query=Tedrake%2C+R">Russ Tedrake</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> IEEE Conference on Decision and Control (CDC), Singapore, December 2023 (accepted)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG); Systems and Control (eess.SY); Optimization and Control (math.OC)

</div>
</div>
</dd>
<dt><a name="item460">[460]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.12586" title="Abstract">arXiv:2304.12586</a> (replaced) [<a href="/pdf/2304.12586" title="Download PDF">pdf</a>, <a href="/format/2304.12586" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Unsupervised Discovery of Extreme Weather Events Using Universal  Representations of Emergent Organization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Rupe%2C+A">Adam Rupe</a>, 
<a href="/search/physics?searchtype=author&query=Kashinath%2C+K">Karthik Kashinath</a>, 
<a href="/search/physics?searchtype=author&query=Kumar%2C+N">Nalini Kumar</a>, 
<a href="/search/physics?searchtype=author&query=Crutchfield%2C+J+P">James P. Crutchfield</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Physics (physics.comp-ph)</span>; Machine Learning (cs.LG); Dynamical Systems (math.DS); Pattern Formation and Solitons (nlin.PS)

</div>
</div>
</dd>
<dt><a name="item461">[461]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.14821" title="Abstract">arXiv:2304.14821</a> (replaced) [<a href="/pdf/2304.14821" title="Download PDF">pdf</a>, <a href="/ps/2304.14821" title="Download PostScript">ps</a>, <a href="/format/2304.14821" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Conditional logic as a short-circuit logic
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bergstra%2C+J+A">Jan A. Bergstra</a>, 
<a href="/search/cs?searchtype=author&query=Ponse%2C+A">Alban Ponse</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 20 pages, 4 tables. Differences with v1: 1) Definitions 3.7 and 3.8 - the normal forms are more elegantly defined, based on a set of strings A^s which now includes the empty string: nicer proofs of La.3.10 and Thm.3.11; the same goes for the related definitions and proofs in the setting with U. 2) Thm.5.1 - best Prover9 results tightened
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>

</div>
</div>
</dd>
<dt><a name="item462">[462]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.01355" title="Abstract">arXiv:2305.01355</a> (replaced) [<a href="/pdf/2305.01355" title="Download PDF">pdf</a>, <a href="/ps/2305.01355" title="Download PostScript">ps</a>, <a href="/format/2305.01355" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Spectral approach to the communication complexity of multi-party key  agreement
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Caillat-Grenier%2C+G">Geoffroy Caillat-Grenier</a>, 
<a href="/search/cs?searchtype=author&query=Romashchenko%2C+A">Andrei Romashchenko</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 28 pages, 6 figures. Major revision of the previous version
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Discrete Mathematics (cs.DM)

</div>
</div>
</dd>
<dt><a name="item463">[463]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.03354" title="Abstract">arXiv:2305.03354</a> (replaced) [<a href="/pdf/2305.03354" title="Download PDF">pdf</a>, <a href="/format/2305.03354" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Close-range Human Following Control on a Cane-type Robot with  Multi-camera Fusion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Liu%2C+H">Haowen Liu</a>, 
<a href="/search/eess?searchtype=author&query=Wu%2C+F">Fengxian Wu</a>, 
<a href="/search/eess?searchtype=author&query=Zhong%2C+B">Bin Zhong</a>, 
<a href="/search/eess?searchtype=author&query=Zhao%2C+Y">Yijun Zhao</a>, 
<a href="/search/eess?searchtype=author&query=Zhang%2C+J">Jiatong Zhang</a>, 
<a href="/search/eess?searchtype=author&query=Niu%2C+W">Wenxin Niu</a>, 
<a href="/search/eess?searchtype=author&query=Zhang%2C+M">Mingming Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This paper has been accepted for publication in IEEE Robotics and Automation Letters.( Volume: 8, Issue: 10, October 2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
</div>
</dd>
<dt><a name="item464">[464]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.03942" title="Abstract">arXiv:2305.03942</a> (replaced) [<a href="/pdf/2305.03942" title="Download PDF">pdf</a>, <a href="/format/2305.03942" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> HACMan: Learning Hybrid Actor-Critic Maps for 6D Non-Prehensile  Manipulation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhou%2C+W">Wenxuan Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+B">Bowen Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+F">Fan Yang</a>, 
<a href="/search/cs?searchtype=author&query=Paxton%2C+C">Chris Paxton</a>, 
<a href="/search/cs?searchtype=author&query=Held%2C+D">David Held</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7th Conference on Robot Learning (CoRL 2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item465">[465]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.04811" title="Abstract">arXiv:2305.04811</a> (replaced) [<a href="/pdf/2305.04811" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deep learning models for price forecasting of financial time series: A  review of recent advancements: 2020-2022
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-fin?searchtype=author&query=Zhang%2C+C">Cheng Zhang</a>, 
<a href="/search/q-fin?searchtype=author&query=Sjarif%2C+N+N+A">Nilam Nur Amir Sjarif</a>, 
<a href="/search/q-fin?searchtype=author&query=Ibrahim%2C+R">Roslina Ibrahim</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 37 pages, 19 figures, 5 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Statistical Finance (q-fin.ST)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item466">[466]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.04866" title="Abstract">arXiv:2305.04866</a> (replaced) [<a href="/pdf/2305.04866" title="Download PDF">pdf</a>, <a href="/format/2305.04866" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Causal Policy Gradient for Whole-Body Mobile Manipulation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hu%2C+J">Jiaheng Hu</a>, 
<a href="/search/cs?searchtype=author&query=Stone%2C+P">Peter Stone</a>, 
<a href="/search/cs?searchtype=author&query=Mart%C3%ADn-Mart%C3%ADn%2C+R">Roberto Mart&#xed;n-Mart&#xed;n</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Robotics: science and systems. 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item467">[467]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.06141" title="Abstract">arXiv:2305.06141</a> (replaced) [<a href="/pdf/2305.06141" title="Download PDF">pdf</a>, <a href="/ps/2305.06141" title="Download PostScript">ps</a>, <a href="/format/2305.06141" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Active Semantic Localization with Graph Neural Embedding
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yoshida%2C+M">Mitsuki Yoshida</a>, 
<a href="/search/cs?searchtype=author&query=Tanaka%2C+K">Kanji Tanaka</a>, 
<a href="/search/cs?searchtype=author&query=Yamamoto%2C+R">Ryogo Yamamoto</a>, 
<a href="/search/cs?searchtype=author&query=Iwata%2C+D">Daiki Iwata</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, 6 figures, 1 table
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Robotics (cs.RO)

</div>
</div>
</dd>
<dt><a name="item468">[468]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.06979" title="Abstract">arXiv:2305.06979</a> (replaced) [<a href="/pdf/2305.06979" title="Download PDF">pdf</a>, <a href="/format/2305.06979" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Specification and Verification of Side-channel Security for Open-source  Processors via Leakage Contracts
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zilong Wang</a>, 
<a href="/search/cs?searchtype=author&query=Mohr%2C+G">Gideon Mohr</a>, 
<a href="/search/cs?searchtype=author&query=von+Gleissenthall%2C+K">Klaus von Gleissenthall</a>, 
<a href="/search/cs?searchtype=author&query=Reineke%2C+J">Jan Reineke</a>, 
<a href="/search/cs?searchtype=author&query=Guarnieri%2C+M">Marco Guarnieri</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Technical report containing full formalization and proofs of all results. A short version of this report (with the same title) appears in the proceedings of the 30th ACM SIGSAC Conference on Computer and Communication Security (CCS 2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
</div>
</dd>
<dt><a name="item469">[469]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.10775" title="Abstract">arXiv:2305.10775</a> (replaced) [<a href="/pdf/2305.10775" title="Download PDF">pdf</a>, <a href="/format/2305.10775" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Enhancing Speech Articulation Analysis using a Geometric Transformation  of the X-ray Microbeam Dataset
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Attia%2C+A+A">Ahmed Adel Attia</a>, 
<a href="/search/eess?searchtype=author&query=Tiede%2C+M">Mark Tiede</a>, 
<a href="/search/eess?searchtype=author&query=Espy-Wilson%2C+C+Y">Carol Y. Espy-Wilson</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item470">[470]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.11364" title="Abstract">arXiv:2305.11364</a> (replaced) [<a href="/pdf/2305.11364" title="Download PDF">pdf</a>, <a href="/format/2305.11364" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Visualizing Linguistic Diversity of Text Datasets Synthesized by Large  Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Reif%2C+E">Emily Reif</a>, 
<a href="/search/cs?searchtype=author&query=Kahng%2C+M">Minsuk Kahng</a>, 
<a href="/search/cs?searchtype=author&query=Petridis%2C+S">Savvas Petridis</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item471">[471]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.11627" title="Abstract">arXiv:2305.11627</a> (replaced) [<a href="/pdf/2305.11627" title="Download PDF">pdf</a>, <a href="/format/2305.11627" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LLM-Pruner: On the Structural Pruning of Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ma%2C+X">Xinyin Ma</a>, 
<a href="/search/cs?searchtype=author&query=Fang%2C+G">Gongfan Fang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xinchao Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item472">[472]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.13969" title="Abstract">arXiv:2305.13969</a> (replaced) [<a href="/pdf/2305.13969" title="Download PDF">pdf</a>, <a href="/format/2305.13969" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CTopPRM: Clustering Topological PRM for Planning Multiple Distinct Paths  in 3D Environments
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Novosad%2C+M">Matej Novosad</a>, 
<a href="/search/cs?searchtype=author&query=Penicka%2C+R">Robert Penicka</a>, 
<a href="/search/cs?searchtype=author&query=Vonasek%2C+V">Vojtech Vonasek</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> in IEEE Robotics and Automation Letters
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
</div>
</dd>
<dt><a name="item473">[473]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.14091" title="Abstract">arXiv:2305.14091</a> (replaced) [<a href="/pdf/2305.14091" title="Download PDF">pdf</a>, <a href="/format/2305.14091" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Revisiting Acceptability Judgements
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hu%2C+H">Hai Hu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Ziyin Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+W">Weifang Huang</a>, 
<a href="/search/cs?searchtype=author&query=Lai%2C+J+Y">Jackie Yan-Ki Lai</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+A">Aini Li</a>, 
<a href="/search/cs?searchtype=author&query=Patterson%2C+Y">Yina Patterson</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+J">Jiahui Huang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+P">Peng Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+C+C">Chien-Jer Charles Lin</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+R">Rui Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item474">[474]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.14093" title="Abstract">arXiv:2305.14093</a> (replaced) [<a href="/pdf/2305.14093" title="Download PDF">pdf</a>, <a href="/format/2305.14093" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Weakly Supervised 3D Open-vocabulary Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+K">Kunhao Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhan%2C+F">Fangneng Zhan</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jiahui Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+M">Muyu Xu</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+Y">Yingchen Yu</a>, 
<a href="/search/cs?searchtype=author&query=Saddik%2C+A+E">Abdulmotaleb El Saddik</a>, 
<a href="/search/cs?searchtype=author&query=Theobalt%2C+C">Christian Theobalt</a>, 
<a href="/search/cs?searchtype=author&query=Xing%2C+E">Eric Xing</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+S">Shijian Lu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item475">[475]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.15883" title="Abstract">arXiv:2305.15883</a> (replaced) [<a href="/pdf/2305.15883" title="Download PDF">pdf</a>, <a href="/format/2305.15883" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> RC-BEVFusion: A Plug-In Module for Radar-Camera Bird&#x27;s Eye View Feature  Fusion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=St%C3%A4cker%2C+L">Lukas St&#xe4;cker</a>, 
<a href="/search/cs?searchtype=author&query=Mishra%2C+S">Shashank Mishra</a>, 
<a href="/search/cs?searchtype=author&query=Heidenreich%2C+P">Philipp Heidenreich</a>, 
<a href="/search/cs?searchtype=author&query=Rambach%2C+J">Jason Rambach</a>, 
<a href="/search/cs?searchtype=author&query=Stricker%2C+D">Didier Stricker</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> GCPR 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item476">[476]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.16912" title="Abstract">arXiv:2305.16912</a> (replaced) [<a href="/pdf/2305.16912" title="Download PDF">pdf</a>, <a href="/format/2305.16912" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Disambiguated Attention Embedding for Multi-Instance Partial-Label  Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tang%2C+W">Wei Tang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+W">Weijia Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+M">Min-Ling Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item477">[477]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.18135" title="Abstract">arXiv:2305.18135</a> (replaced) [<a href="/pdf/2305.18135" title="Download PDF">pdf</a>, <a href="/format/2305.18135" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Alignment-free HDR Deghosting with Semantics Consistent Transformer
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tel%2C+S">Steven Tel</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Z">Zongwei Wu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yulun Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Heyrman%2C+B">Barth&#xe9;l&#xe9;my Heyrman</a>, 
<a href="/search/cs?searchtype=author&query=Demonceaux%2C+C">C&#xe9;dric Demonceaux</a>, 
<a href="/search/cs?searchtype=author&query=Timofte%2C+R">Radu Timofte</a>, 
<a href="/search/cs?searchtype=author&query=Ginhac%2C+D">Dominique Ginhac</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to ICCV 2023. Version 2: Corrections are made to the conference proceedings to address issues with the production of our benchmark input. We have now updated Table 3 and Figure 6 to reflect these changes
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item478">[478]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.18471" title="Abstract">arXiv:2305.18471</a> (replaced) [<a href="/pdf/2305.18471" title="Download PDF">pdf</a>, <a href="/ps/2305.18471" title="Download PostScript">ps</a>, <a href="/format/2305.18471" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Convergence of AdaGrad for Non-convex Objectives: Simple Proofs and  Relaxed Assumptions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+B">Bohan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Huishuai Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+Z">Zhi-Ming Ma</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+W">Wei Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> COLT 2023, renewed references
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Optimization and Control (math.OC)

</div>
</div>
</dd>
<dt><a name="item479">[479]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.00632" title="Abstract">arXiv:2306.00632</a> (replaced) [<a href="/pdf/2306.00632" title="Download PDF">pdf</a>, <a href="/format/2306.00632" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A low-rank isogeometric solver based on Tucker tensors
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Montardini%2C+M">Monica Montardini</a>, 
<a href="/search/math?searchtype=author&query=Sangalli%2C+G">Giancarlo Sangalli</a>, 
<a href="/search/math?searchtype=author&query=Tani%2C+M">Mattia Tani</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 27 pages, 8 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
</div>
</dd>
<dt><a name="item480">[480]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.00914" title="Abstract">arXiv:2306.00914</a> (replaced) [<a href="/pdf/2306.00914" title="Download PDF">pdf</a>, <a href="/format/2306.00914" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Conditioning Diffusion Models via Attributes and Semantic Masks for Face  Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Giambi%2C+N">Nico Giambi</a>, 
<a href="/search/cs?searchtype=author&query=Lisanti%2C+G">Giuseppe Lisanti</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> The paper is under consideration at Computer Vision and Image Understanding
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item481">[481]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.03573" title="Abstract">arXiv:2306.03573</a> (replaced) [<a href="/pdf/2306.03573" title="Download PDF">pdf</a>, <a href="/format/2306.03573" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> mdTLS: How to make middlebox-aware TLS more efficient?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ahn%2C+T">Taehyun Ahn</a>, 
<a href="/search/cs?searchtype=author&query=Kwak%2C+J">Jiwon Kwak</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+S">Seungjoo Kim</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 20 pages, 6 figures, 5 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
</div>
</dd>
<dt><a name="item482">[482]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.03574" title="Abstract">arXiv:2306.03574</a> (replaced) [<a href="/pdf/2306.03574" title="Download PDF">pdf</a>, <a href="/ps/2306.03574" title="Download PostScript">ps</a>, <a href="/format/2306.03574" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A block $&#x3b1;$-circulant based preconditioned MINRES method for wave  equations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Lin%2C+X">Xue-lei Lin</a>, 
<a href="/search/math?searchtype=author&query=Hon%2C+S">Sean Hon</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
</div>
</dd>
<dt><a name="item483">[483]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.05671" title="Abstract">arXiv:2306.05671</a> (replaced) [<a href="/pdf/2306.05671" title="Download PDF">pdf</a>, <a href="/format/2306.05671" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Topology-Aware Uncertainty for Image Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gupta%2C+S">Saumya Gupta</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yikai Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+X">Xiaoling Hu</a>, 
<a href="/search/cs?searchtype=author&query=Prasanna%2C+P">Prateek Prasanna</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+C">Chao Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to NeurIPS 2023; 19 pages, 13 figures, 5 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item484">[484]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.05805" title="Abstract">arXiv:2306.05805</a> (replaced) [<a href="/pdf/2306.05805" title="Download PDF">pdf</a>, <a href="/format/2306.05805" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DynaBench: A benchmark dataset for learning dynamical systems from  low-resolution data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dulny%2C+A">Andrzej Dulny</a>, 
<a href="/search/cs?searchtype=author&query=Hotho%2C+A">Andreas Hotho</a>, 
<a href="/search/cs?searchtype=author&query=Krause%2C+A">Anna Krause</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This version is the final camera-ready version that has been published in the Proceedings of ECML-PKDD 2023
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Machine Learning and Knowledge Discovery in Databases: Research
  Track. ECML PKDD 2023. Lecture Notes in Computer Science(), vol 14169, p.
  438-455. Springer, Cham
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item485">[485]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.08836" title="Abstract">arXiv:2306.08836</a> (replaced) [<a href="/pdf/2306.08836" title="Download PDF">pdf</a>, <a href="/format/2306.08836" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Probabilistic-based Feature Embedding of 4-D Light Fields for  Compressive Imaging and Denoising
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Lyu%2C+X">Xianqiang Lyu</a>, 
<a href="/search/eess?searchtype=author&query=Hou%2C+J">Junhui Hou</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item486">[486]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.09304" title="Abstract">arXiv:2306.09304</a> (replaced) [<a href="/pdf/2306.09304" title="Download PDF">pdf</a>, <a href="/format/2306.09304" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Radars for Autonomous Driving: A Review of Deep Learning Methods and  Challenges
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Srivastav%2C+A">Arvind Srivastav</a>, 
<a href="/search/cs?searchtype=author&query=Mandal%2C+S">Soumyajit Mandal</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item487">[487]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.10244" title="Abstract">arXiv:2306.10244</a> (replaced) [<a href="/pdf/2306.10244" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Cryogenic Reconfigurable Logic with Superconducting Heater Cryotron:  Enhancing Area Efficiency and Enabling Camouflaged Processors
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Alam%2C+S">Shamiul Alam</a>, 
<a href="/search/cs?searchtype=author&query=Rampini%2C+D+S">Dana S. Rampini</a>, 
<a href="/search/cs?searchtype=author&query=Oripov%2C+B+G">Bakhrom G. Oripov</a>, 
<a href="/search/cs?searchtype=author&query=McCaughan%2C+A+N">Adam N. McCaughan</a>, 
<a href="/search/cs?searchtype=author&query=Aziz%2C+A">Ahmedullah Aziz</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, 6 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Emerging Technologies (cs.ET)</span>; Superconductivity (cond-mat.supr-con); Hardware Architecture (cs.AR); Applied Physics (physics.app-ph)

</div>
</div>
</dd>
<dt><a name="item488">[488]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.15891" title="Abstract">arXiv:2306.15891</a> (replaced) [<a href="/pdf/2306.15891" title="Download PDF">pdf</a>, <a href="/format/2306.15891" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Capturing the Diffusive Behavior of the Multiscale Linear Transport  Equations by Asymptotic-Preserving Convolutional DeepONets
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+K">Keke Wu</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+X">Xiong-bin Yan</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+S">Shi Jin</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+Z">Zheng Ma</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item489">[489]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.01026" title="Abstract">arXiv:2307.01026</a> (replaced) [<a href="/pdf/2307.01026" title="Download PDF">pdf</a>, <a href="/format/2307.01026" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Temporal Graph Benchmark for Machine Learning on Temporal Graphs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+S">Shenyang Huang</a>, 
<a href="/search/cs?searchtype=author&query=Poursafaei%2C+F">Farimah Poursafaei</a>, 
<a href="/search/cs?searchtype=author&query=Danovitch%2C+J">Jacob Danovitch</a>, 
<a href="/search/cs?searchtype=author&query=Fey%2C+M">Matthias Fey</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+W">Weihua Hu</a>, 
<a href="/search/cs?searchtype=author&query=Rossi%2C+E">Emanuele Rossi</a>, 
<a href="/search/cs?searchtype=author&query=Leskovec%2C+J">Jure Leskovec</a>, 
<a href="/search/cs?searchtype=author&query=Bronstein%2C+M">Michael Bronstein</a>, 
<a href="/search/cs?searchtype=author&query=Rabusseau%2C+G">Guillaume Rabusseau</a>, 
<a href="/search/cs?searchtype=author&query=Rabbany%2C+R">Reihaneh Rabbany</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 20 pages, 7 figures, 7 tables, accepted at NeurIPS 2023 Datasets and Benchmarks Track
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item490">[490]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.01435" title="Abstract">arXiv:2307.01435</a> (replaced) [<a href="/pdf/2307.01435" title="Download PDF">pdf</a>, <a href="/format/2307.01435" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A tangential and penalty-free finite element method for the surface  Stokes problem
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Demlow%2C+A">Alan Demlow</a>, 
<a href="/search/math?searchtype=author&query=Neilan%2C+M">Michael Neilan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
</div>
</dd>
<dt><a name="item491">[491]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.02245" title="Abstract">arXiv:2307.02245</a> (replaced) [<a href="/pdf/2307.02245" title="Download PDF">pdf</a>, <a href="/format/2307.02245" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Set Learning for Accurate and Calibrated Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Muttenthaler%2C+L">Lukas Muttenthaler</a>, 
<a href="/search/cs?searchtype=author&query=Vandermeulen%2C+R+A">Robert A. Vandermeulen</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Q">Qiuyi Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Unterthiner%2C+T">Thomas Unterthiner</a>, 
<a href="/search/cs?searchtype=author&query=M%C3%BCller%2C+K">Klaus-Robert M&#xfc;ller</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV); Information Theory (cs.IT)

</div>
</div>
</dd>
<dt><a name="item492">[492]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.02274" title="Abstract">arXiv:2307.02274</a> (replaced) [<a href="/pdf/2307.02274" title="Download PDF">pdf</a>, <a href="/format/2307.02274" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Dadu-RBD: Robot Rigid Body Dynamics Accelerator with Multifunctional  Pipelines
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yuxin Yang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+X">Xiaoming Chen</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+Y">Yinhe Han</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Hardware Architecture (cs.AR)

</div>
</div>
</dd>
<dt><a name="item493">[493]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.04870" title="Abstract">arXiv:2307.04870</a> (replaced) [<a href="/pdf/2307.04870" title="Download PDF">pdf</a>, <a href="/ps/2307.04870" title="Download PostScript">ps</a>, <a href="/format/2307.04870" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> RACH-Space: Reconstructing Adaptive Convex Hull Space with applications  in weak supervision
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Na%2C+W">Woojoo Na</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Optimization and Control (math.OC)

</div>
</div>
</dd>
<dt><a name="item494">[494]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.06135" title="Abstract">arXiv:2307.06135</a> (replaced) [<a href="/pdf/2307.06135" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SayPlan: Grounding Large Language Models using 3D Scene Graphs for  Scalable Robot Task Planning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rana%2C+K">Krishan Rana</a>, 
<a href="/search/cs?searchtype=author&query=Haviland%2C+J">Jesse Haviland</a>, 
<a href="/search/cs?searchtype=author&query=Garg%2C+S">Sourav Garg</a>, 
<a href="/search/cs?searchtype=author&query=Abou-Chakra%2C+J">Jad Abou-Chakra</a>, 
<a href="/search/cs?searchtype=author&query=Reid%2C+I">Ian Reid</a>, 
<a href="/search/cs?searchtype=author&query=Suenderhauf%2C+N">Niko Suenderhauf</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted for oral presentation at the Conference on Robot Learning (CoRL), 2023. Project page can be found here: <a href="https://sayplan.github.io">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item495">[495]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.06738" title="Abstract">arXiv:2307.06738</a> (replaced) [<a href="/pdf/2307.06738" title="Download PDF">pdf</a>, <a href="/ps/2307.06738" title="Download PostScript">ps</a>, <a href="/format/2307.06738" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Closeness Centralities of Lollipop Graphs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dangalchev%2C+C">Chavdar Dangalchev</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Discrete Mathematics (cs.DM)</span>; Combinatorics (math.CO)

</div>
</div>
</dd>
<dt><a name="item496">[496]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.06822" title="Abstract">arXiv:2307.06822</a> (replaced) [<a href="/pdf/2307.06822" title="Download PDF">pdf</a>, <a href="/format/2307.06822" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> TinyMetaFed: Efficient Federated Meta-Learning for TinyML
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ren%2C+H">Haoyu Ren</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xue Li</a>, 
<a href="/search/cs?searchtype=author&query=Anicic%2C+D">Darko Anicic</a>, 
<a href="/search/cs?searchtype=author&query=Runkler%2C+T+A">Thomas A. Runkler</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by the ECML PKDD 2023 workshop track: Simplification, Compression, Efficiency, and Frugality for Artificial Intelligence (SCEFA)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Distributed, Parallel, and Cluster Computing (cs.DC)

</div>
</div>
</dd>
<dt><a name="item497">[497]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.08079" title="Abstract">arXiv:2307.08079</a> (replaced) [<a href="/pdf/2307.08079" title="Download PDF">pdf</a>, <a href="/format/2307.08079" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Flexible and efficient spatial extremes emulation via variational  autoencoders
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Zhang%2C+L">Likun Zhang</a>, 
<a href="/search/stat?searchtype=author&query=Ma%2C+X">Xiaoyu Ma</a>, 
<a href="/search/stat?searchtype=author&query=Wikle%2C+C+K">Christopher K. Wikle</a>, 
<a href="/search/stat?searchtype=author&query=Huser%2C+R">Rapha&#xeb;l Huser</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 30 pages, 8 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG); Methodology (stat.ME)

</div>
</div>
</dd>
<dt><a name="item498">[498]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.12499" title="Abstract">arXiv:2307.12499</a> (replaced) [<a href="/pdf/2307.12499" title="Download PDF">pdf</a>, <a href="/format/2307.12499" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AdvDiff: Generating Unrestricted Adversarial Examples using Diffusion  Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dai%2C+X">Xuelong Dai</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+K">Kaisheng Liang</a>, 
<a href="/search/cs?searchtype=author&query=Xiao%2C+B">Bin Xiao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item499">[499]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.12896" title="Abstract">arXiv:2307.12896</a> (replaced) [<a href="/pdf/2307.12896" title="Download PDF">pdf</a>, <a href="/format/2307.12896" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Corrections of Zipf&#x27;s and Heaps&#x27; Laws Derived from Hapax Rate Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=D%C4%99bowski%2C+%C5%81">&#x141;ukasz D&#x119;bowski</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 42 pages, 7 figures, 3 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Applications (stat.AP)

</div>
</div>
</dd>
<dt><a name="item500">[500]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.15506" title="Abstract">arXiv:2307.15506</a> (replaced) [<a href="/pdf/2307.15506" title="Download PDF">pdf</a>, <a href="/format/2307.15506" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Improving Image Quality of Sparse-view Lung Cancer CT Images with a  Convolutional Neural Network
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ries%2C+A">Annika Ries</a>, 
<a href="/search/cs?searchtype=author&query=Dorosti%2C+T">Tina Dorosti</a>, 
<a href="/search/cs?searchtype=author&query=Thalhammer%2C+J">Johannes Thalhammer</a>, 
<a href="/search/cs?searchtype=author&query=Sasse%2C+D">Daniel Sasse</a>, 
<a href="/search/cs?searchtype=author&query=Sauter%2C+A">Andreas Sauter</a>, 
<a href="/search/cs?searchtype=author&query=Meurer%2C+F">Felix Meurer</a>, 
<a href="/search/cs?searchtype=author&query=Benne%2C+A">Ashley Benne</a>, 
<a href="/search/cs?searchtype=author&query=Lasser%2C+T">Tobias Lasser</a>, 
<a href="/search/cs?searchtype=author&query=Pfeiffer%2C+F">Franz Pfeiffer</a>, 
<a href="/search/cs?searchtype=author&query=Schaff%2C+F">Florian Schaff</a>, 
<a href="/search/cs?searchtype=author&query=Pfeiffer%2C+D">Daniela Pfeiffer</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Medical Physics (physics.med-ph)

</div>
</div>
</dd>
<dt><a name="item501">[501]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.15567" title="Abstract">arXiv:2307.15567</a> (replaced) [<a href="/pdf/2307.15567" title="Download PDF">pdf</a>, <a href="/format/2307.15567" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Panoptic Scene Graph Generation with Semantics-prototype Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+L">Li Li</a>, 
<a href="/search/cs?searchtype=author&query=Ji%2C+W">Wei Ji</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Y">Yiming Wu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+M">Mengze Li</a>, 
<a href="/search/cs?searchtype=author&query=Qin%2C+Y">You Qin</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+L">Lina Wei</a>, 
<a href="/search/cs?searchtype=author&query=Zimmermann%2C+R">Roger Zimmermann</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item502">[502]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.16262" title="Abstract">arXiv:2307.16262</a> (replaced) [<a href="/pdf/2307.16262" title="Download PDF">pdf</a>, <a href="/format/2307.16262" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An objective validation of polyp and instrument segmentation methods in  colonoscopy through Medico 2020 polyp segmentation and MedAI 2021  transparency challenges
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Jha%2C+D">Debesh Jha</a>, 
<a href="/search/eess?searchtype=author&query=Sharma%2C+V">Vanshali Sharma</a>, 
<a href="/search/eess?searchtype=author&query=Banik%2C+D">Debapriya Banik</a>, 
<a href="/search/eess?searchtype=author&query=Bhattacharya%2C+D">Debayan Bhattacharya</a>, 
<a href="/search/eess?searchtype=author&query=Roy%2C+K">Kaushiki Roy</a>, 
<a href="/search/eess?searchtype=author&query=Hicks%2C+S+A">Steven A. Hicks</a>, 
<a href="/search/eess?searchtype=author&query=Tomar%2C+N+K">Nikhil Kumar Tomar</a>, 
<a href="/search/eess?searchtype=author&query=Thambawita%2C+V">Vajira Thambawita</a>, 
<a href="/search/eess?searchtype=author&query=Krenzer%2C+A">Adrian Krenzer</a>, 
<a href="/search/eess?searchtype=author&query=Ji%2C+G">Ge-Peng Ji</a>, 
<a href="/search/eess?searchtype=author&query=Poudel%2C+S">Sahadev Poudel</a>, 
<a href="/search/eess?searchtype=author&query=Batchkala%2C+G">George Batchkala</a>, 
<a href="/search/eess?searchtype=author&query=Alam%2C+S">Saruar Alam</a>, 
<a href="/search/eess?searchtype=author&query=Ahmed%2C+A+M+A">Awadelrahman M. A. Ahmed</a>, 
<a href="/search/eess?searchtype=author&query=Trinh%2C+Q">Quoc-Huy Trinh</a>, 
<a href="/search/eess?searchtype=author&query=Khan%2C+Z">Zeshan Khan</a>, 
<a href="/search/eess?searchtype=author&query=Nguyen%2C+T">Tien-Phat Nguyen</a>, 
<a href="/search/eess?searchtype=author&query=Shrestha%2C+S">Shruti Shrestha</a>, 
<a href="/search/eess?searchtype=author&query=Nathan%2C+S">Sabari Nathan</a>, 
<a href="/search/eess?searchtype=author&query=Gwak%2C+J">Jeonghwan Gwak</a>, 
<a href="/search/eess?searchtype=author&query=Jha%2C+R+K">Ritika K. Jha</a>, 
<a href="/search/eess?searchtype=author&query=Zhang%2C+Z">Zheyuan Zhang</a>, 
<a href="/search/eess?searchtype=author&query=Schlaefer%2C+A">Alexander Schlaefer</a>, 
<a href="/search/eess?searchtype=author&query=Bhattacharjee%2C+D">Debotosh Bhattacharjee</a>, 
<a href="/search/eess?searchtype=author&query=Bhuyan%2C+M+K">M.K. Bhuyan</a>, 
<a href="/search/eess?searchtype=author&query=Das%2C+P+K">Pradip K. Das</a>, 
<a href="/search/eess?searchtype=author&query=Fan%2C+D">Deng-Ping Fan</a>, 
<a href="/search/eess?searchtype=author&query=Parsa%2C+S">Sravanthi Parsa</a>, 
<a href="/search/eess?searchtype=author&query=Ali%2C+S">Sharib Ali</a>, 
<a href="/search/eess?searchtype=author&query=Riegler%2C+M+A">Michael A. Riegler</a>, 
<a href="/search/eess?searchtype=author&query=Halvorsen%2C+P">P&#xe5;l Halvorsen</a>, 
<a href="/search/eess?searchtype=author&query=De+Lange%2C+T">Thomas De Lange</a>, 
<a href="/search/eess?searchtype=author&query=Bagci%2C+U">Ulas Bagci</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item503">[503]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.16735" title="Abstract">arXiv:2307.16735</a> (replaced) [<a href="/pdf/2307.16735" title="Download PDF">pdf</a>, <a href="/ps/2307.16735" title="Download PostScript">ps</a>, <a href="/format/2307.16735" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Lossless Transformations and Excess Risk Bounds in Statistical Inference
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gy%C3%B6rfi%2C+L">L&#xe1;szl&#xf3; Gy&#xf6;rfi</a>, 
<a href="/search/cs?searchtype=author&query=Linder%2C+T">Tam&#xe1;s Linder</a>, 
<a href="/search/cs?searchtype=author&query=Walk%2C+H">Harro Walk</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> to appear in Entropy
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Machine Learning (cs.LG); Statistics Theory (math.ST); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item504">[504]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.00147" title="Abstract">arXiv:2308.00147</a> (replaced) [<a href="/pdf/2308.00147" title="Download PDF">pdf</a>, <a href="/format/2308.00147" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Delving into Commit-Issue Correlation to Enhance Commit Message  Generation Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+L">Liran Wang</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+X">Xunzhu Tang</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+Y">Yichen He</a>, 
<a href="/search/cs?searchtype=author&query=Ren%2C+C">Changyu Ren</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+S">Shuhua Shi</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+C">Chaoran Yan</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zhoujun Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ASE2023 accepted paper
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
</div>
</dd>
<dt><a name="item505">[505]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.01045" title="Abstract">arXiv:2308.01045</a> (replaced) [<a href="/pdf/2308.01045" title="Download PDF">pdf</a>, <a href="/format/2308.01045" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Dynamic Token Pruning in Plain Vision Transformers for Semantic  Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tang%2C+Q">Quan Tang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+B">Bowen Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jiajun Liu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+F">Fagui Liu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yifan Liu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item506">[506]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.01213" title="Abstract">arXiv:2308.01213</a> (replaced) [<a href="/pdf/2308.01213" title="Download PDF">pdf</a>, <a href="/format/2308.01213" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Embedding Capabilities of Neural ODEs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Kuehn%2C+C">Christian Kuehn</a>, 
<a href="/search/math?searchtype=author&query=Kuntz%2C+S">Sara-Viola Kuntz</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Dynamical Systems (math.DS)</span>; Neural and Evolutionary Computing (cs.NE)

</div>
</div>
</dd>
<dt><a name="item507">[507]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.03666" title="Abstract">arXiv:2308.03666</a> (replaced) [<a href="/pdf/2308.03666" title="Download PDF">pdf</a>, <a href="/format/2308.03666" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Bridging Trustworthiness and Open-World Learning: An Exploratory Neural  Approach for Enhancing Interpretability, Generalization, and Robustness
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Du%2C+S">Shide Du</a>, 
<a href="/search/stat?searchtype=author&query=Fang%2C+Z">Zihan Fang</a>, 
<a href="/search/stat?searchtype=author&query=Lan%2C+S">Shiyang Lan</a>, 
<a href="/search/stat?searchtype=author&query=Tan%2C+Y">Yanchao Tan</a>, 
<a href="/search/stat?searchtype=author&query=G%C3%BCnther%2C+M">Manuel G&#xfc;nther</a>, 
<a href="/search/stat?searchtype=author&query=Wang%2C+S">Shiping Wang</a>, 
<a href="/search/stat?searchtype=author&query=Guo%2C+W">Wenzhong Guo</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item508">[508]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.04412" title="Abstract">arXiv:2308.04412</a> (replaced) [<a href="/pdf/2308.04412" title="Download PDF">pdf</a>, <a href="/format/2308.04412" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Probabilistic Invariant Learning with Randomized Linear Classifiers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cotta%2C+L">Leonardo Cotta</a>, 
<a href="/search/cs?searchtype=author&query=Yehuda%2C+G">Gal Yehuda</a>, 
<a href="/search/cs?searchtype=author&query=Schuster%2C+A">Assaf Schuster</a>, 
<a href="/search/cs?searchtype=author&query=Maddison%2C+C+J">Chris J. Maddison</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item509">[509]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.05034" title="Abstract">arXiv:2308.05034</a> (replaced) [<a href="/pdf/2308.05034" title="Download PDF">pdf</a>, <a href="/format/2308.05034" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Kairos: Practical Intrusion Detection and Investigation using  Whole-system Provenance
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cheng%2C+Z">Zijun Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Lv%2C+Q">Qiujian Lv</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+J">Jinyuan Liang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+D">Degang Sun</a>, 
<a href="/search/cs?searchtype=author&query=Pasquier%2C+T">Thomas Pasquier</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+X">Xueyuan Han</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 24 pages, 16 figures, to appear in the 45th IEEE Symposium on Security and Privacy (S&amp;P'24)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item510">[510]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.06005" title="Abstract">arXiv:2308.06005</a> (replaced) [<a href="/pdf/2308.06005" title="Download PDF">pdf</a>, <a href="/format/2308.06005" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> How Early Participation Determines Long-Term Sustained Activity in  GitHub Projects?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xiao%2C+W">Wenxin Xiao</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+H">Hao He</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+W">Weiwei Xu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yuxia Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+M">Minghui Zhou</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> The 31st ACM Joint European Software Engineering Conference and Symposium on the Foundations of Software Engineering (ESEC/FSE 2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
</div>
</dd>
<dt><a name="item511">[511]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.06595" title="Abstract">arXiv:2308.06595</a> (replaced) [<a href="/pdf/2308.06595" title="Download PDF">pdf</a>, <a href="/format/2308.06595" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> VisIT-Bench: A Benchmark for Vision-Language Instruction Following  Inspired by Real-World Use
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bitton%2C+Y">Yonatan Bitton</a>, 
<a href="/search/cs?searchtype=author&query=Bansal%2C+H">Hritik Bansal</a>, 
<a href="/search/cs?searchtype=author&query=Hessel%2C+J">Jack Hessel</a>, 
<a href="/search/cs?searchtype=author&query=Shao%2C+R">Rulin Shao</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+W">Wanrong Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Awadalla%2C+A">Anas Awadalla</a>, 
<a href="/search/cs?searchtype=author&query=Gardner%2C+J">Josh Gardner</a>, 
<a href="/search/cs?searchtype=author&query=Taori%2C+R">Rohan Taori</a>, 
<a href="/search/cs?searchtype=author&query=Schimdt%2C+L">Ludwig Schimdt</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item512">[512]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.06922" title="Abstract">arXiv:2308.06922</a> (replaced) [<a href="/pdf/2308.06922" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Probabilistic contingent planning based on HTN for high-quality plans
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhao%2C+P">Peng Zhao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 1 figure
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
</div>
</dd>
<dt><a name="item513">[513]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.08543" title="Abstract">arXiv:2308.08543</a> (replaced) [<a href="/pdf/2308.08543" title="Download PDF">pdf</a>, <a href="/format/2308.08543" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> InsightMapper: A Closer Look at Inner-instance Information for  Vectorized High-Definition Mapping
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+Z">Zhenhua Xu</a>, 
<a href="/search/cs?searchtype=author&query=Wong%2C+K+K+Y">Kenneth K.Y. Wong</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+H">Hengshuang Zhao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Code and demo will be available at <a href="https://tonyxuqaq.github.io/InsightMapper/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Robotics (cs.RO)

</div>
</div>
</dd>
<dt><a name="item514">[514]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.09267" title="Abstract">arXiv:2308.09267</a> (replaced) [<a href="/pdf/2308.09267" title="Download PDF">pdf</a>, <a href="/format/2308.09267" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Enhancing Reasoning Capabilities of Large Language Models: A Graph-Based  Verification Approach
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cao%2C+L">Lang Cao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
</div>
</dd>
<dt><a name="item515">[515]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.09510" title="Abstract">arXiv:2308.09510</a> (replaced) [<a href="/pdf/2308.09510" title="Download PDF">pdf</a>, <a href="/format/2308.09510" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Efficient Simulation of Quantum Circuits by Model Order Reduction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Jim%C3%A9nez-Pastor%2C+A">Antonio Jim&#xe9;nez-Pastor</a>, 
<a href="/search/quant-ph?searchtype=author&query=Larsen%2C+K+G">Kim G. Larsen</a>, 
<a href="/search/quant-ph?searchtype=author&query=Tribastone%2C+M">Mirco Tribastone</a>, 
<a href="/search/quant-ph?searchtype=author&query=Tschaikowski%2C+M">Max Tschaikowski</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 21 pages, 1 figure, 3 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Emerging Technologies (cs.ET)

</div>
</div>
</dd>
<dt><a name="item516">[516]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.09830" title="Abstract">arXiv:2308.09830</a> (replaced) [<a href="/pdf/2308.09830" title="Download PDF">pdf</a>, <a href="/format/2308.09830" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Synergistic Integration of Large Language Models and Cognitive  Architectures for Robust AI: An Exploratory Analysis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Romero%2C+O+J">Oscar J. Romero</a>, 
<a href="/search/cs?searchtype=author&query=Zimmerman%2C+J">John Zimmerman</a>, 
<a href="/search/cs?searchtype=author&query=Steinfeld%2C+A">Aaron Steinfeld</a>, 
<a href="/search/cs?searchtype=author&query=Tomasic%2C+A">Anthony Tomasic</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> AAAI 2023 Fall Symposium
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
</div>
</dd>
<dt><a name="item517">[517]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10379" title="Abstract">arXiv:2308.10379</a> (replaced) [<a href="/pdf/2308.10379" title="Download PDF">pdf</a>, <a href="/format/2308.10379" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Algorithm of Thoughts: Enhancing Exploration of Ideas in Large Language  Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sel%2C+B">Bilgehan Sel</a>, 
<a href="/search/cs?searchtype=author&query=Al-Tawaha%2C+A">Ahmad Al-Tawaha</a>, 
<a href="/search/cs?searchtype=author&query=Khattar%2C+V">Vanshaj Khattar</a>, 
<a href="/search/cs?searchtype=author&query=Jia%2C+R">Ruoxi Jia</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+M">Ming Jin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item518">[518]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10425" title="Abstract">arXiv:2308.10425</a> (replaced) [<a href="/pdf/2308.10425" title="Download PDF">pdf</a>, <a href="/format/2308.10425" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> STAEformer: Spatio-Temporal Adaptive Embedding Makes Vanilla Transformer  SOTA for Traffic Forecasting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+H">Hangchen Liu</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+Z">Zheng Dong</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+R">Renhe Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Deng%2C+J">Jiewen Deng</a>, 
<a href="/search/cs?searchtype=author&query=Deng%2C+J">Jinliang Deng</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Q">Quanjun Chen</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+X">Xuan Song</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted as CIKM2023 Short Paper
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item519">[519]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.13104" title="Abstract">arXiv:2308.13104</a> (replaced) [<a href="/pdf/2308.13104" title="Download PDF">pdf</a>, <a href="/format/2308.13104" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Contrastive Learning of Temporal Distinctiveness for Survival Analysis  in Electronic Health Records
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kerdabadi%2C+M+N">Mohsen Nayebi Kerdabadi</a>, 
<a href="/search/cs?searchtype=author&query=Moghaddam%2C+A+H">Arya Hadizadeh Moghaddam</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+B">Bin Liu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+M">Mei Liu</a>, 
<a href="/search/cs?searchtype=author&query=Yao%2C+Z">Zijun Yao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This paper has been accepted for publication at the CIKM 2023 conference
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item520">[520]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.13436" title="Abstract">arXiv:2308.13436</a> (replaced) [<a href="/pdf/2308.13436" title="Download PDF">pdf</a>, <a href="/format/2308.13436" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An Intermediate Representation for Composable Typed Streaming Dataflow  Designs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Reukers%2C+M+A">Matthijs A. Reukers</a>, 
<a href="/search/cs?searchtype=author&query=Tian%2C+Y">Yongding Tian</a>, 
<a href="/search/cs?searchtype=author&query=Al-Ars%2C+Z">Zaid Al-Ars</a>, 
<a href="/search/cs?searchtype=author&query=Hofstee%2C+P">Peter Hofstee</a>, 
<a href="/search/cs?searchtype=author&query=Brobbel%2C+M">Matthijs Brobbel</a>, 
<a href="/search/cs?searchtype=author&query=Peltenburg%2C+J">Johan Peltenburg</a>, 
<a href="/search/cs?searchtype=author&query=van+Straten%2C+J">Jeroen van Straten</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: substantial text overlap with <a href="/abs/2212.12003">arXiv:2212.12003</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Programming Languages (cs.PL)</span>

</div>
</div>
</dd>
<dt><a name="item521">[521]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.13978" title="Abstract">arXiv:2308.13978</a> (replaced) [<a href="/pdf/2308.13978" title="Download PDF">pdf</a>, <a href="/format/2308.13978" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Graph Neural Network-Based QUBO-Formulated Hamiltonian-Inspired Loss  Function for Combinatorial Optimization using Reinforcement Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rizvee%2C+R+A">Redwan Ahmed Rizvee</a>, 
<a href="/search/cs?searchtype=author&query=Khan%2C+M+M">Md. Mosaddek Khan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Machine Learning (cs.LG); Optimization and Control (math.OC)

</div>
</div>
</dd>
<dt><a name="item522">[522]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.14134" title="Abstract">arXiv:2308.14134</a> (replaced) [<a href="/pdf/2308.14134" title="Download PDF">pdf</a>, <a href="/ps/2308.14134" title="Download PostScript">ps</a>, <a href="/format/2308.14134" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Locally Uniform Hashing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bercea%2C+I+O">Ioana O. Bercea</a>, 
<a href="/search/cs?searchtype=author&query=Beretta%2C+L">Lorenzo Beretta</a>, 
<a href="/search/cs?searchtype=author&query=Klausen%2C+J">Jonas Klausen</a>, 
<a href="/search/cs?searchtype=author&query=Houen%2C+J+B+T">Jakob B&#xe6;k Tejs Houen</a>, 
<a href="/search/cs?searchtype=author&query=Thorup%2C+M">Mikkel Thorup</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> FOCS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>

</div>
</div>
</dd>
<dt><a name="item523">[523]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.14359" title="Abstract">arXiv:2308.14359</a> (replaced) [<a href="/pdf/2308.14359" title="Download PDF">pdf</a>, <a href="/format/2308.14359" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Effect of Attention and Self-Supervised Speech Embeddings on  Non-Semantic Speech Tasks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mohapatra%2C+P">Payal Mohapatra</a>, 
<a href="/search/cs?searchtype=author&query=Pandey%2C+A">Akash Pandey</a>, 
<a href="/search/cs?searchtype=author&query=Sui%2C+Y">Yueyuan Sui</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+Q">Qi Zhu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to appear at ACM Multimedia 2023 Multimedia Grand Challenges Track
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computation and Language (cs.CL)

</div>
</div>
</dd>
<dt><a name="item524">[524]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.15054" title="Abstract">arXiv:2308.15054</a> (replaced) [<a href="/pdf/2308.15054" title="Download PDF">pdf</a>, <a href="/format/2308.15054" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Quasi-Polynomial Algorithm for Subset-Sum Problems with At Most One  Solution
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Costandin%2C+M">Marius Costandin</a>, 
<a href="/search/math?searchtype=author&query=Costandin%2C+B">Beniamin Costandin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: text overlap with <a href="/abs/2307.13015">arXiv:2307.13015</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Computational Complexity (cs.CC); Data Structures and Algorithms (cs.DS); Numerical Analysis (math.NA)

</div>
</div>
</dd>
<dt><a name="item525">[525]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.15728" title="Abstract">arXiv:2308.15728</a> (replaced) [<a href="/pdf/2308.15728" title="Download PDF">pdf</a>, <a href="/ps/2308.15728" title="Download PostScript">ps</a>, <a href="/format/2308.15728" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Computational Lower Bounds for Graphon Estimation via Low-degree  Polynomials
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Luo%2C+Y">Yuetian Luo</a>, 
<a href="/search/math?searchtype=author&query=Gao%2C+C">Chao Gao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Statistics Theory (math.ST)</span>; Computational Complexity (cs.CC); Data Structures and Algorithms (cs.DS); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item526">[526]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.16900" title="Abstract">arXiv:2308.16900</a> (replaced) [<a href="/pdf/2308.16900" title="Download PDF">pdf</a>, <a href="/format/2308.16900" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning to Taste: A Multimodal Wine Dataset
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bender%2C+T">Thoranna Bender</a>, 
<a href="/search/cs?searchtype=author&query=S%C3%B8rensen%2C+S+M">Simon Moe S&#xf8;rensen</a>, 
<a href="/search/cs?searchtype=author&query=Kashani%2C+A">Alireza Kashani</a>, 
<a href="/search/cs?searchtype=author&query=Hjorleifsson%2C+K+E">K. Eldjarn Hjorleifsson</a>, 
<a href="/search/cs?searchtype=author&query=Hyldig%2C+G">Grethe Hyldig</a>, 
<a href="/search/cs?searchtype=author&query=Hauberg%2C+S">S&#xf8;ren Hauberg</a>, 
<a href="/search/cs?searchtype=author&query=Belongie%2C+S">Serge Belongie</a>, 
<a href="/search/cs?searchtype=author&query=Warburg%2C+F">Frederik Warburg</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to NeurIPS 2023. See project page: <a href="https://thoranna.github.io/learning_to_taste/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item527">[527]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.00098" title="Abstract">arXiv:2309.00098</a> (replaced) [<a href="/pdf/2309.00098" title="Download PDF">pdf</a>, <a href="/format/2309.00098" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Dually conformal hypergraphs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Boros%2C+E">Endre Boros</a>, 
<a href="/search/math?searchtype=author&query=Gurvich%2C+V">Vladimir Gurvich</a>, 
<a href="/search/math?searchtype=author&query=Milani%C4%8D%2C+M">Martin Milani&#x10d;</a>, 
<a href="/search/math?searchtype=author&query=Uno%2C+Y">Yushi Uno</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Combinatorics (math.CO)</span>; Computational Complexity (cs.CC); Discrete Mathematics (cs.DM); Data Structures and Algorithms (cs.DS)

</div>
</div>
</dd>
<dt><a name="item528">[528]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01340" title="Abstract">arXiv:2309.01340</a> (replaced) [<a href="/pdf/2309.01340" title="Download PDF">pdf</a>, <a href="/format/2309.01340" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MDSC: Towards Evaluating the Style Consistency Between Music and Dance
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Z">Zixiang Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+B">Baoyuan Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 17 pages, 17 figure
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Computer Vision and Pattern Recognition (cs.CV); Audio and Speech Processing (eess.AS)

</div>
</div>
</dd>
<dt><a name="item529">[529]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.02672" title="Abstract">arXiv:2309.02672</a> (replaced) [<a href="/pdf/2309.02672" title="Download PDF">pdf</a>, <a href="/format/2309.02672" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Geometry of Sensitivity: Twice Sampling and Hybrid Clipping in  Differential Privacy with Optimal Gaussian Noise and Application to Deep  Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xiao%2C+H">Hanshen Xiao</a>, 
<a href="/search/cs?searchtype=author&query=Wan%2C+J">Jun Wan</a>, 
<a href="/search/cs?searchtype=author&query=Devadas%2C+S">Srinivas Devadas</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> ACM CCS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Information Theory (cs.IT)

</div>
</div>
</dd>
<dt><a name="item530">[530]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.03847" title="Abstract">arXiv:2309.03847</a> (replaced) [<a href="/pdf/2309.03847" title="Download PDF">pdf</a>, <a href="/format/2309.03847" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Mixtures of Gaussians are Privately Learnable with a Polynomial Number  of Samples
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Afzali%2C+M">Mohammad Afzali</a>, 
<a href="/search/stat?searchtype=author&query=Ashtiani%2C+H">Hassan Ashtiani</a>, 
<a href="/search/stat?searchtype=author&query=Liaw%2C+C">Christopher Liaw</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Cryptography and Security (cs.CR); Data Structures and Algorithms (cs.DS); Information Theory (cs.IT); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item531">[531]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.05516" title="Abstract">arXiv:2309.05516</a> (replaced) [<a href="/pdf/2309.05516" title="Download PDF">pdf</a>, <a href="/format/2309.05516" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Optimize Weight Rounding via Signed Gradient Descent for the  Quantization of LLMs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cheng%2C+W">Wenhua Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+W">Weiwei Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+H">Haihao Shen</a>, 
<a href="/search/cs?searchtype=author&query=Cai%2C+Y">Yiyang Cai</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+X">Xin He</a>, 
<a href="/search/cs?searchtype=author&query=Lv%2C+K">Kaokao Lv</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item532">[532]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.05525" title="Abstract">arXiv:2309.05525</a> (replaced) [<a href="/pdf/2309.05525" title="Download PDF">pdf</a>, <a href="/format/2309.05525" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Advancing Federated Learning in 6G: A Trusted Architecture with  Graph-based Analysis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ye%2C+W">Wenxuan Ye</a>, 
<a href="/search/cs?searchtype=author&query=Qian%2C+C">Chendi Qian</a>, 
<a href="/search/cs?searchtype=author&query=An%2C+X">Xueli An</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+X">Xueqiang Yan</a>, 
<a href="/search/cs?searchtype=author&query=Carle%2C+G">Georg Carle</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by IEEE Global Communications Conference (GLOBECOM) 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item533">[533]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.05832" title="Abstract">arXiv:2309.05832</a> (replaced) [<a href="/pdf/2309.05832" title="Download PDF">pdf</a>, <a href="/format/2309.05832" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Instance-Agnostic Geometry and Contact Dynamics Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sun%2C+M">Mengti Sun</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+B">Bowen Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Bianchini%2C+B">Bibit Bianchini</a>, 
<a href="/search/cs?searchtype=author&query=Taylor%2C+C+J">Camillo Jose Taylor</a>, 
<a href="/search/cs?searchtype=author&query=Posa%2C+M">Michael Posa</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> IROS 2023 Workshop on Leveraging Models for Contact-Rich Manipulation
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG); Robotics (cs.RO)

</div>
</div>
</dd>
<dt><a name="item534">[534]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.06129" title="Abstract">arXiv:2309.06129</a> (replaced) [<a href="/pdf/2309.06129" title="Download PDF">pdf</a>, <a href="/format/2309.06129" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LEyes: A Lightweight Framework for Deep Learning-Based Eye Tracking  using Synthetic Eye Images
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Byrne%2C+S+A">Sean Anthony Byrne</a>, 
<a href="/search/cs?searchtype=author&query=Maquiling%2C+V">Virmarie Maquiling</a>, 
<a href="/search/cs?searchtype=author&query=Nystr%C3%B6m%2C+M">Marcus Nystr&#xf6;m</a>, 
<a href="/search/cs?searchtype=author&query=Kasneci%2C+E">Enkelejda Kasneci</a>, 
<a href="/search/cs?searchtype=author&query=Niehorster%2C+D+C">Diederick C. Niehorster</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 32 pages, 8 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Human-Computer Interaction (cs.HC)

</div>
</div>
</dd>
<dt><a name="item535">[535]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.06612" title="Abstract">arXiv:2309.06612</a> (replaced) [<a href="/pdf/2309.06612" title="Download PDF">pdf</a>, <a href="/format/2309.06612" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Harmonic-NAS: Hardware-Aware Multimodal Neural Architecture Search on  Resource-constrained Devices
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ghebriout%2C+M+I+E">Mohamed Imed Eddine Ghebriout</a>, 
<a href="/search/cs?searchtype=author&query=Bouzidi%2C+H">Halima Bouzidi</a>, 
<a href="/search/cs?searchtype=author&query=Niar%2C+S">Smail Niar</a>, 
<a href="/search/cs?searchtype=author&query=Ouarnoughi%2C+H">Hamza Ouarnoughi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to the 15th Asian Conference on Machine Learning (ACML 2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item536">[536]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.07014" title="Abstract">arXiv:2309.07014</a> (replaced) [<a href="/pdf/2309.07014" title="Download PDF">pdf</a>, <a href="/format/2309.07014" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Using Lidar Intensity for Robot Navigation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sathyamoorthy%2C+A+J">Adarsh Jagan Sathyamoorthy</a>, 
<a href="/search/cs?searchtype=author&query=Weerakoon%2C+K">Kasun Weerakoon</a>, 
<a href="/search/cs?searchtype=author&query=Elnoor%2C+M">Mohamed Elnoor</a>, 
<a href="/search/cs?searchtype=author&query=Manocha%2C+D">Dinesh Manocha</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages, 7 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
</div>
</dd>
<dt><a name="item537">[537]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.07461" title="Abstract">arXiv:2309.07461</a> (replaced) [<a href="/pdf/2309.07461" title="Download PDF">pdf</a>, <a href="/format/2309.07461" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Detecting Unknown Attacks in IoT Environments: An Open Set Classifier  for Enhanced Network Intrusion Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Farrukh%2C+Y+A">Yasir Ali Farrukh</a>, 
<a href="/search/cs?searchtype=author&query=Wali%2C+S">Syed Wali</a>, 
<a href="/search/cs?searchtype=author&query=Khan%2C+I">Irfan Khan</a>, 
<a href="/search/cs?searchtype=author&query=Bastian%2C+N+D">Nathaniel D. Bastian</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 Pages, 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item538">[538]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.07496" title="Abstract">arXiv:2309.07496</a> (replaced) [<a href="/pdf/2309.07496" title="Download PDF">pdf</a>, <a href="/format/2309.07496" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Comparison of DDS, MQTT, and Zenoh in Edge-to-Edge and Edge-to-Cloud  Communication for Distributed ROS 2 Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jiaqiang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+X">Xianjia Yu</a>, 
<a href="/search/cs?searchtype=author&query=Ha%2C+S">Sier Ha</a>, 
<a href="/search/cs?searchtype=author&query=Queralta%2C+J+P">Jorge Pena Queralta</a>, 
<a href="/search/cs?searchtype=author&query=Westerlund%2C+T">Tomi Westerlund</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 19 pages, 8 figures. Submitted to the Journal of Intelligent &amp; Robotic Systems. Under review
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
</div>
</dd>
<dt><a name="item539">[539]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.07872" title="Abstract">arXiv:2309.07872</a> (replaced) [<a href="/pdf/2309.07872" title="Download PDF">pdf</a>, <a href="/format/2309.07872" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Unified Perspective on Multiple Shooting In Differential Dynamic  Programming
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+H">He Li</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+W">Wenhao Yu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+T">Tingnan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wensing%2C+P+M">Patrick M. Wensing</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
</div>
</dd>
<dt><a name="item540">[540]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08214" title="Abstract">arXiv:2309.08214</a> (replaced) [<a href="/pdf/2309.08214" title="Download PDF">pdf</a>, <a href="/format/2309.08214" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MTG: Mapless Trajectory Generator with Traversability Coverage for  Outdoor Navigation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liang%2C+J">Jing Liang</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+P">Peng Gao</a>, 
<a href="/search/cs?searchtype=author&query=Xiao%2C+X">Xuesu Xiao</a>, 
<a href="/search/cs?searchtype=author&query=Sathyamoorthy%2C+A+J">Adarsh Jagan Sathyamoorthy</a>, 
<a href="/search/cs?searchtype=author&query=Elnoor%2C+M">Mohamed Elnoor</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+M+C">Ming C. Lin</a>, 
<a href="/search/cs?searchtype=author&query=Manocha%2C+D">Dinesh Manocha</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
</div>
</dd>
<dt><a name="item541">[541]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.09175" title="Abstract">arXiv:2309.09175</a> (replaced) [<a href="/e-print/2309.09175" title="Download source">src</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Imbalanced Data Stream Classification using Dynamic Ensemble Selection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=S%2C+P">Priya.S</a>, 
<a href="/search/cs?searchtype=author&query=Sivakumar%2C+H">Haribharathi Sivakumar</a>, 
<a href="/search/cs?searchtype=author&query=R%2C+V+A">Vijay Arvind.R</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Made an error in the research and need to rectify it
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item542">[542]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.09301" title="Abstract">arXiv:2309.09301</a> (replaced) [<a href="/pdf/2309.09301" title="Download PDF">pdf</a>, <a href="/format/2309.09301" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> RenderIH: A Large-scale Synthetic Dataset for 3D Interacting Hand Pose  Estimation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+L">Lijun Li</a>, 
<a href="/search/cs?searchtype=author&query=Tian%2C+L">Linrui Tian</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xindi Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Q">Qi Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+B">Bang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+M">Mengyuan Liu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+C">Chen Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by ICCV 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item543">[543]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.09437" title="Abstract">arXiv:2309.09437</a> (replaced) [<a href="/pdf/2309.09437" title="Download PDF">pdf</a>, <a href="/format/2309.09437" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Using LLMs to Facilitate Formal Verification of RTL
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Orenes-Vera%2C+M">Marcelo Orenes-Vera</a>, 
<a href="/search/cs?searchtype=author&query=Martonosi%2C+M">Margaret Martonosi</a>, 
<a href="/search/cs?searchtype=author&query=Wentzlaff%2C+D">David Wentzlaff</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Hardware Architecture (cs.AR)</span>; Software Engineering (cs.SE)

</div>
</div>
</dd>
<dt><a name="item544">[544]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.09979" title="Abstract">arXiv:2309.09979</a> (replaced) [<a href="/pdf/2309.09979" title="Download PDF">pdf</a>, <a href="/format/2309.09979" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> General In-Hand Object Rotation with Vision and Touch
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Qi%2C+H">Haozhi Qi</a>, 
<a href="/search/cs?searchtype=author&query=Yi%2C+B">Brent Yi</a>, 
<a href="/search/cs?searchtype=author&query=Suresh%2C+S">Sudharshan Suresh</a>, 
<a href="/search/cs?searchtype=author&query=Lambeta%2C+M">Mike Lambeta</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+Y">Yi Ma</a>, 
<a href="/search/cs?searchtype=author&query=Calandra%2C+R">Roberto Calandra</a>, 
<a href="/search/cs?searchtype=author&query=Malik%2C+J">Jitendra Malik</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> CoRL 2023; Website: <a href="https://haozhi.io/rotateit/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item545">[545]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.10003" title="Abstract">arXiv:2309.10003</a> (replaced) [<a href="/pdf/2309.10003" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A novel approach to measuring patent claim scope based on probabilities  obtained from (large) language models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ragot%2C+S">S&#xe9;bastien Ragot</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 58 pages, 8 tables, 6 figures. Substantial changes made to version 2: New section 4.1 added (including a new table); Minor normalization issue corrected in values listed in Appendix B; Content of former appendix C now moved to Section 3; and new Appendix C added
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Information Theory (cs.IT); Machine Learning (cs.LG); Probability (math.PR)

</div>
</div>
</dd>
<dt><a name="item546">[546]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.10196" title="Abstract">arXiv:2309.10196</a> (replaced) [<a href="/pdf/2309.10196" title="Download PDF">pdf</a>, <a href="/ps/2309.10196" title="Download PostScript">ps</a>, <a href="/format/2309.10196" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the Minimum Distance, Minimum Weight Codewords, and the Dimension of  Projective Reed-Muller Codes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ghorpade%2C+S+R">Sudhir R. Ghorpade</a>, 
<a href="/search/cs?searchtype=author&query=Ludhani%2C+R">Rati Ludhani</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 24 pages; to appear in Adv. Math. Commun.; some typos corrected and a reference added in this version
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Combinatorics (math.CO)

</div>
</div>
</dd>
<dt><a name="item547">[547]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.10292" title="Abstract">arXiv:2309.10292</a> (replaced) [<a href="/pdf/2309.10292" title="Download PDF">pdf</a>, <a href="/format/2309.10292" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Julia as a unifying end-to-end workflow language on the Frontier  exascale system
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Godoy%2C+W+F">William F. Godoy</a>, 
<a href="/search/cs?searchtype=author&query=Valero-Lara%2C+P">Pedro Valero-Lara</a>, 
<a href="/search/cs?searchtype=author&query=Anderson%2C+C">Caira Anderson</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+K+W">Katrina W. Lee</a>, 
<a href="/search/cs?searchtype=author&query=Gainaru%2C+A">Ana Gainaru</a>, 
<a href="/search/cs?searchtype=author&query=da+Silva%2C+R+F">Rafael Ferreira da Silva</a>, 
<a href="/search/cs?searchtype=author&query=Vetter%2C+J+S">Jeffrey S. Vetter</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages, 8 figures, accepted at the 18th Workshop on Workflows in Support of Large-Scale Science (WORKS23), IEEE/ACM The International Conference for High Performance Computing, Networking, Storage, and Analysis, SC23
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>; Programming Languages (cs.PL)

</div>
</div>
</dd>
<dt><a name="item548">[548]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.10311" title="Abstract">arXiv:2309.10311</a> (replaced) [<a href="/pdf/2309.10311" title="Download PDF">pdf</a>, <a href="/format/2309.10311" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Resource-Efficient Cooperative Online Scalar Field Mapping via  Distributed Sparse Gaussian Process Regression
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ding%2C+T">Tianyi Ding</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+R">Ronghao Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+S">Senlin Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+M">Meiqin Liu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Systems and Control (eess.SY)

</div>
</div>
</dd>
<dt><a name="item549">[549]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.10331" title="Abstract">arXiv:2309.10331</a> (replaced) [<a href="/pdf/2309.10331" title="Download PDF">pdf</a>, <a href="/format/2309.10331" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Hardness results for decoding the surface code with Pauli noise
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Fischer%2C+A">Alex Fischer</a>, 
<a href="/search/quant-ph?searchtype=author&query=Miyake%2C+A">Akimasa Miyake</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 37 pages, 18 figures. 26 pages, 12 figures in main text
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Computational Complexity (cs.CC)

</div>
</div>
</dd>
<dt><a name="item550">[550]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.10941" title="Abstract">arXiv:2309.10941</a> (replaced) [<a href="/pdf/2309.10941" title="Download PDF">pdf</a>, <a href="/format/2309.10941" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Data-driven design of complex network structures to promote  synchronization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Coraggio%2C+M">Marco Coraggio</a>, 
<a href="/search/eess?searchtype=author&query=di+Bernardo%2C+M">Mario di Bernardo</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
</div>
</dd>
<dt><a name="item551">[551]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.11475" title="Abstract">arXiv:2309.11475</a> (replaced) [<a href="/pdf/2309.11475" title="Download PDF">pdf</a>, <a href="/format/2309.11475" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Creating walls to avoid unwanted points in root finding and optimization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Truong%2C+T+T">Tuyen Trung Truong</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 24 pages. Title changed. A new method added. Some theoretical results added. More experiments added. Several typos fixed. References to the tunnelling/deflation method added. Comments are welcome!
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Machine Learning (cs.LG); Dynamical Systems (math.DS); Numerical Analysis (math.NA)

</div>
</div>
</dd>
<dt><a name="item552">[552]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.11500" title="Abstract">arXiv:2309.11500</a> (replaced) [<a href="/pdf/2309.11500" title="Download PDF">pdf</a>, <a href="/format/2309.11500" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Large-scale Dataset for Audio-Language Representation Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sun%2C+L">Luoyi Sun</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+X">Xuenan Xu</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+M">Mengyue Wu</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+W">Weidi Xie</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Computer Vision and Pattern Recognition (cs.CV); Multimedia (cs.MM); Audio and Speech Processing (eess.AS)

</div>
</div>
</dd>
<dt><a name="item553">[553]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.11589" title="Abstract">arXiv:2309.11589</a> (replaced) [<a href="/pdf/2309.11589" title="Download PDF">pdf</a>, <a href="/format/2309.11589" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Output-Feedback Nonlinear Model Predictive Control with Iterative State-  and Control-Dependent Coefficients
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Kamaldar%2C+M">Mohammadreza Kamaldar</a>, 
<a href="/search/eess?searchtype=author&query=Bernstein%2C+D+S">Dennis S. Bernstein</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to 2024 American Control Conference
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Dynamical Systems (math.DS); Optimization and Control (math.OC)

</div>
</div>
</dd>
<dt><a name="item554">[554]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.11657" title="Abstract">arXiv:2309.11657</a> (replaced) [<a href="/pdf/2309.11657" title="Download PDF">pdf</a>, <a href="/format/2309.11657" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Distribution-Independent Regression for Generalized Linear Models with  Oblivious Corruptions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Diakonikolas%2C+I">Ilias Diakonikolas</a>, 
<a href="/search/cs?searchtype=author&query=Karmalkar%2C+S">Sushrut Karmalkar</a>, 
<a href="/search/cs?searchtype=author&query=Park%2C+J">Jongho Park</a>, 
<a href="/search/cs?searchtype=author&query=Tzamos%2C+C">Christos Tzamos</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Published in COLT 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>; Machine Learning (cs.LG); Statistics Theory (math.ST); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item555">[555]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.11944" title="Abstract">arXiv:2309.11944</a> (replaced) [<a href="/pdf/2309.11944" title="Download PDF">pdf</a>, <a href="/format/2309.11944" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Reachability Analysis of ARMAX Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=L%C3%BCtzow%2C+L">Laura L&#xfc;tzow</a>, 
<a href="/search/eess?searchtype=author&query=Althoff%2C+M">Matthias Althoff</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> \copyright 2023 IEEE. Personal use of this material is permitted. Permission from IEEE must be obtained for all other uses, in any current or future media, including reprinting/republishing this material for advertising or promotional purposes, creating new collective works, for resale or redistribution to servers or lists, or reuse of any copyrighted component of this work in other works
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Robotics (cs.RO)

</div>
</div>
</dd>
<dt><a name="item556">[556]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.12041" title="Abstract">arXiv:2309.12041</a> (replaced) [<a href="/pdf/2309.12041" title="Download PDF">pdf</a>, <a href="/format/2309.12041" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> S-GBDT: Frugal Differentially Private Gradient Boosting Decision Trees
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kirschte%2C+M">Moritz Kirschte</a>, 
<a href="/search/cs?searchtype=author&query=Peinemann%2C+T">Thorsten Peinemann</a>, 
<a href="/search/cs?searchtype=author&query=Stock%2C+J">Joshua Stock</a>, 
<a href="/search/cs?searchtype=author&query=Cotrini%2C+C">Carlos Cotrini</a>, 
<a href="/search/cs?searchtype=author&query=Mohammadi%2C+E">Esfandiar Mohammadi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> The first two authors equally contributed to this work
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item557">[557]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.12818" title="Abstract">arXiv:2309.12818</a> (replaced) [<a href="/pdf/2309.12818" title="Download PDF">pdf</a>, <a href="/format/2309.12818" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> How Automated Market Makers Approach the Thin Market Problem in  Cryptoeconomic Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-fin?searchtype=author&query=Kirste%2C+D">Daniel Kirste</a>, 
<a href="/search/q-fin?searchtype=author&query=Kannengie%C3%9Fer%2C+N">Niclas Kannengie&#xdf;er</a>, 
<a href="/search/q-fin?searchtype=author&query=Lamberty%2C+R">Ricky Lamberty</a>, 
<a href="/search/q-fin?searchtype=author&query=Sunyaev%2C+A">Ali Sunyaev</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Trading and Market Microstructure (q-fin.TR)</span>; Cryptography and Security (cs.CR)

</div>
</div>
</dd>
<dt><a name="item558">[558]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13302" title="Abstract">arXiv:2309.13302</a> (replaced) [<a href="/pdf/2309.13302" title="Download PDF">pdf</a>, <a href="/format/2309.13302" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Gaining the Sparse Rewards by Exploring Binary Lottery Tickets in  Spiking Neural Network
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cheng%2C+H">Hao Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+J">Jiahang Cao</a>, 
<a href="/search/cs?searchtype=author&query=Xiao%2C+E">Erjia Xiao</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+P">Pu Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+M">Mengshu Sun</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jiaxu Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jize Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+X">Xue Lin</a>, 
<a href="/search/cs?searchtype=author&query=Kailkhura%2C+B">Bhavya Kailkhura</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+K">Kaidi Xu</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+R">Renjing Xu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neural and Evolutionary Computing (cs.NE)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item559">[559]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13393" title="Abstract">arXiv:2309.13393</a> (replaced) [<a href="/pdf/2309.13393" title="Download PDF">pdf</a>, <a href="/format/2309.13393" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AgriSORT: A Simple Online Real-time Tracking-by-Detection framework for  robotics in precision agriculture
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Saraceni%2C+L">Leonardo Saraceni</a>, 
<a href="/search/cs?searchtype=author&query=Motoi%2C+I+M">Ionut M. Motoi</a>, 
<a href="/search/cs?searchtype=author&query=Nardi%2C+D">Daniele Nardi</a>, 
<a href="/search/cs?searchtype=author&query=Ciarfuglia%2C+T+A">Thomas A. Ciarfuglia</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 5 figures, submitted to International Conference on Robotics and Automation (ICRA) 2024. Code and dataset will be soon available on my github. This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Robotics (cs.RO)

</div>
</div>
</dd>
<dt><a name="item560">[560]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13405" title="Abstract">arXiv:2309.13405</a> (replaced) [<a href="/pdf/2309.13405" title="Download PDF">pdf</a>, <a href="/format/2309.13405" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning Large-Scale MTP$_2$ Gaussian Graphical Models via Bridge-Block  Decomposition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xiwen Wang</a>, 
<a href="/search/cs?searchtype=author&query=Ying%2C+J">Jiaxi Ying</a>, 
<a href="/search/cs?searchtype=author&query=Palomar%2C+D+P">Daniel P. Palomar</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Signal Processing (eess.SP)

</div>
</div>
</dd>
<dt><a name="item561">[561]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13556" title="Abstract">arXiv:2309.13556</a> (replaced) [<a href="/pdf/2309.13556" title="Download PDF">pdf</a>, <a href="/format/2309.13556" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LOGICSEG: Parsing Visual Semantics with Neural Logic Learning and  Reasoning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+L">Liulei Li</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+W">Wenguan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yi Yang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ICCV 2023 (Oral). Code: <a href="https://github.com/lingorX/LogicSeg/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item562">[562]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13655" title="Abstract">arXiv:2309.13655</a> (replaced) [<a href="/pdf/2309.13655" title="Download PDF">pdf</a>, <a href="/format/2309.13655" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Adaptation of the super resolution SOTA for Art Restoration in camera  capture images
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nagar%2C+S">Sandeep Nagar</a>, 
<a href="/search/cs?searchtype=author&query=Bala%2C+A">Abhinaba Bala</a>, 
<a href="/search/cs?searchtype=author&query=Patnaik%2C+S+A">Sai Amrit Patnaik</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> COMPETITIONS @ ICETCI 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Image and Video Processing (eess.IV)

</div>
</div>
</dd>
<dt><a name="item563">[563]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13752" title="Abstract">arXiv:2309.13752</a> (replaced) [<a href="/pdf/2309.13752" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Improving Robustness of Deep Convolutional Neural Networks via  Multiresolution Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhou%2C+H">Hongyan Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+Y">Yao Liang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item564">[564]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.14074" title="Abstract">arXiv:2309.14074</a> (replaced) [<a href="/pdf/2309.14074" title="Download PDF">pdf</a>, <a href="/format/2309.14074" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FlexCast: genuine overlay-based atomic multicast
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Batista%2C+E">Eli&#xe3; Batista</a>, 
<a href="/search/cs?searchtype=author&query=Coelho%2C+P">Paulo Coelho</a>, 
<a href="/search/cs?searchtype=author&query=Alchieri%2C+E">Eduardo Alchieri</a>, 
<a href="/search/cs?searchtype=author&query=Dotti%2C+F">Fernando Dotti</a>, 
<a href="/search/cs?searchtype=author&query=Pedone%2C+F">Fernando Pedone</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>

</div>
</div>
</dd>
<dt><a name="item565">[565]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.14129" title="Abstract">arXiv:2309.14129</a> (replaced) [<a href="/pdf/2309.14129" title="Download PDF">pdf</a>, <a href="/format/2309.14129" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Speaker anonymization using neural audio codec language models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Panariello%2C+M">Michele Panariello</a>, 
<a href="/search/eess?searchtype=author&query=Nespoli%2C+F">Francesco Nespoli</a>, 
<a href="/search/eess?searchtype=author&query=Todisco%2C+M">Massimiliano Todisco</a>, 
<a href="/search/eess?searchtype=author&query=Evans%2C+N">Nicholas Evans</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to ICASSP 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Sound (cs.SD)

</div>
</div>
</dd>
<dt><a name="item566">[566]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.14181" title="Abstract">arXiv:2309.14181</a> (replaced) [<a href="/pdf/2309.14181" title="Download PDF">pdf</a>, <a href="/format/2309.14181" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Q-Bench: A Benchmark for General-Purpose Foundation Models on Low-level  Vision
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+H">Haoning Wu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zicheng Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+E">Erli Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+C">Chaofeng Chen</a>, 
<a href="/search/cs?searchtype=author&query=Liao%2C+L">Liang Liao</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+A">Annan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+C">Chunyi Li</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+W">Wenxiu Sun</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+Q">Qiong Yan</a>, 
<a href="/search/cs?searchtype=author&query=Zhai%2C+G">Guangtao Zhai</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+W">Weisi Lin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 25 pages, 14 figures, 9 tables, preprint version
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Multimedia (cs.MM)

</div>
</div>
</dd>
<dt><a name="item567">[567]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.14225" title="Abstract">arXiv:2309.14225</a> (replaced) [<a href="/pdf/2309.14225" title="Download PDF">pdf</a>, <a href="/format/2309.14225" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> HumanMimic: Learning Natural Locomotion and Transitions for Humanoid  Robot via Wasserstein Adversarial Imitation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tang%2C+A">Annan Tang</a>, 
<a href="/search/cs?searchtype=author&query=Hiraoka%2C+T">Takuma Hiraoka</a>, 
<a href="/search/cs?searchtype=author&query=Hiraoka%2C+N">Naoki Hiraoka</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+F">Fan Shi</a>, 
<a href="/search/cs?searchtype=author&query=Kawaharazuka%2C+K">Kento Kawaharazuka</a>, 
<a href="/search/cs?searchtype=author&query=Kojima%2C+K">Kunio Kojima</a>, 
<a href="/search/cs?searchtype=author&query=Okada%2C+K">Kei Okada</a>, 
<a href="/search/cs?searchtype=author&query=Inaba%2C+M">Masayuki Inaba</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
</div>
</dd>
<dt><a name="item568">[568]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.14232" title="Abstract">arXiv:2309.14232</a> (replaced) [<a href="/pdf/2309.14232" title="Download PDF">pdf</a>, <a href="/format/2309.14232" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Governance of Decentralized Autonomous Organizations: A Study of  Contributors&#x27; Influence, Networks, and Shifts in Voting Power
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kitzler%2C+S">Stefan Kitzler</a>, 
<a href="/search/cs?searchtype=author&query=Balietti%2C+S">Stefano Balietti</a>, 
<a href="/search/cs?searchtype=author&query=Saggese%2C+P">Pietro Saggese</a>, 
<a href="/search/cs?searchtype=author&query=Haslhofer%2C+B">Bernhard Haslhofer</a>, 
<a href="/search/cs?searchtype=author&query=Strohmaier%2C+M">Markus Strohmaier</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>

</div>
</div>
</dd>
<dt><a name="item569">[569]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.14329" title="Abstract">arXiv:2309.14329</a> (replaced) [<a href="/pdf/2309.14329" title="Download PDF">pdf</a>, <a href="/format/2309.14329" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Innovative Digital Storytelling with AIGC: Exploration and Discussion of  Recent Advances
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gu%2C+R">Rongzhang Gu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Hui Li</a>, 
<a href="/search/cs?searchtype=author&query=Su%2C+C">Changyue Su</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+W">Wayne Wu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project page: <a href="https://lsgm-demo.github.io/Leveraging-recent-advances-of-foundation-models-for-story-telling/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV); Graphics (cs.GR); Multimedia (cs.MM)

</div>
</div>
</dd>
<dt><a name="item570">[570]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.14564" title="Abstract">arXiv:2309.14564</a> (replaced) [<a href="/pdf/2309.14564" title="Download PDF">pdf</a>, <a href="/format/2309.14564" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Generative Escher Meshes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Aigerman%2C+N">Noam Aigerman</a>, 
<a href="/search/cs?searchtype=author&query=Groueix%2C+T">Thibault Groueix</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Computational Geometry (cs.CG); Graphics (cs.GR)

</div>
</div>
</dd>
<dt><a name="item571">[571]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.14642" title="Abstract">arXiv:2309.14642</a> (replaced) [<a href="/pdf/2309.14642" title="Download PDF">pdf</a>, <a href="/format/2309.14642" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Editing Motion Graphics Video via Motion Vectorization and  Transformation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+S">Sharon Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+J">Jiaju Ma</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+J">Jiajun Wu</a>, 
<a href="/search/cs?searchtype=author&query=Ritchie%2C+D">Daniel Ritchie</a>, 
<a href="/search/cs?searchtype=author&query=Agrawala%2C+M">Maneesh Agrawala</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, 12 figures, SIGGRAPH Asia 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Graphics (cs.GR)</span>

</div>
</div>
</dd>
<dt><a name="item572">[572]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.14704" title="Abstract">arXiv:2309.14704</a> (replaced) [<a href="/pdf/2309.14704" title="Download PDF">pdf</a>, <a href="/format/2309.14704" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Tile Classification Based Viewport Prediction with Multi-modal Fusion  Transformer
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zhihao Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yiwei Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+W">Weizhan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+C">Caixia Yan</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+Q">Qinghua Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Q">Qi Wang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+W">Wangdu Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This paper is accepted by ACM-MM 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Multimedia (cs.MM)

</div>
</div>
</dd>
<dt><a name="item573">[573]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.14793" title="Abstract">arXiv:2309.14793</a> (replaced) [<a href="/pdf/2309.14793" title="Download PDF">pdf</a>, <a href="/format/2309.14793" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Semantic Map Learning of Traffic Light to Lane Assignment based on  Motion Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Monninger%2C+T">Thomas Monninger</a>, 
<a href="/search/cs?searchtype=author&query=Weber%2C+A">Andreas Weber</a>, 
<a href="/search/cs?searchtype=author&query=Staab%2C+S">Steffen Staab</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to the 2023 IEEE International Conference on Intelligent Transportation Systems (ITSC 2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Robotics (cs.RO)

</div>
</div>
</dd>
<dt><a name="item574">[574]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15123" title="Abstract">arXiv:2309.15123</a> (replaced) [<a href="/pdf/2309.15123" title="Download PDF">pdf</a>, <a href="/format/2309.15123" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Uncovering Neural Scaling Laws in Molecular Representation Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Chen%2C+D">Dingshuo Chen</a>, 
<a href="/search/physics?searchtype=author&query=Zhu%2C+Y">Yanqiao Zhu</a>, 
<a href="/search/physics?searchtype=author&query=Zhang%2C+J">Jieyu Zhang</a>, 
<a href="/search/physics?searchtype=author&query=Du%2C+Y">Yuanqi Du</a>, 
<a href="/search/physics?searchtype=author&query=Li%2C+Z">Zhixun Li</a>, 
<a href="/search/physics?searchtype=author&query=Liu%2C+Q">Qiang Liu</a>, 
<a href="/search/physics?searchtype=author&query=Wu%2C+S">Shu Wu</a>, 
<a href="/search/physics?searchtype=author&query=Wang%2C+L">Liang Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 23 pages; accepted to NeurIPS 2023 Datasets and Benchmarks
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Chemical Physics (physics.chem-ph)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item575">[575]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15128" title="Abstract">arXiv:2309.15128</a> (replaced) [<a href="/pdf/2309.15128" title="Download PDF">pdf</a>, <a href="/format/2309.15128" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DPA-WNO: A gray box model for a class of stochastic mechanics problem
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tushar">Tushar</a>, 
<a href="/search/cs?searchtype=author&query=Chakraborty%2C+S">Souvik Chakraborty</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item576">[576]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15253" title="Abstract">arXiv:2309.15253</a> (replaced) [<a href="/pdf/2309.15253" title="Download PDF">pdf</a>, <a href="/format/2309.15253" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Method and Validation for Optimal Lineup Creation for Daily Fantasy  Football Using Machine Learning and Linear Programming
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mahoney%2C+J+M">Joseph M. Mahoney</a>, 
<a href="/search/cs?searchtype=author&query=Paniak%2C+T+B">Tomasz B. Paniak</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 32 pages, 12 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item577">[577]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15317" title="Abstract">arXiv:2309.15317</a> (replaced) [<a href="/pdf/2309.15317" title="Download PDF">pdf</a>, <a href="/format/2309.15317" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Joint Prediction and Denoising for Large-scale Multilingual  Self-supervised Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+W">William Chen</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+J">Jiatong Shi</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+B">Brian Yan</a>, 
<a href="/search/cs?searchtype=author&query=Berrebbi%2C+D">Dan Berrebbi</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+W">Wangyou Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+Y">Yifan Peng</a>, 
<a href="/search/cs?searchtype=author&query=Chang%2C+X">Xuankai Chang</a>, 
<a href="/search/cs?searchtype=author&query=Maiti%2C+S">Soumi Maiti</a>, 
<a href="/search/cs?searchtype=author&query=Watanabe%2C+S">Shinji Watanabe</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to ASRU 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Sound (cs.SD); Audio and Speech Processing (eess.AS)

</div>
</div>
</dd>
<dt><a name="item578">[578]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15411" title="Abstract">arXiv:2309.15411</a> (replaced) [<a href="/pdf/2309.15411" title="Download PDF">pdf</a>, <a href="/format/2309.15411" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> 3D Multiple Object Tracking on Autonomous Driving: A Literature Review
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+P">Peng Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xin Li</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+L">Liang He</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+X">Xin Lin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 28 pages, 5 figures, 2 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item579">[579]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15523" title="Abstract">arXiv:2309.15523</a> (replaced) [<a href="/pdf/2309.15523" title="Download PDF">pdf</a>, <a href="/format/2309.15523" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Improving Facade Parsing with Vision Transformers and Line Integration
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+B">Bowen Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jiaxing Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+R">Ran Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yunqin Li</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+L">Liangzhi Li</a>, 
<a href="/search/cs?searchtype=author&query=Nakashima%2C+Y">Yuta Nakashima</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, 7 figures, 9 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item580">[580]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15564" title="Abstract">arXiv:2309.15564</a> (replaced) [<a href="/pdf/2309.15564" title="Download PDF">pdf</a>, <a href="/format/2309.15564" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Jointly Training Large Autoregressive Multimodal Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Aiello%2C+E">Emanuele Aiello</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+L">Lili Yu</a>, 
<a href="/search/cs?searchtype=author&query=Nie%2C+Y">Yixin Nie</a>, 
<a href="/search/cs?searchtype=author&query=Aghajanyan%2C+A">Armen Aghajanyan</a>, 
<a href="/search/cs?searchtype=author&query=Oguz%2C+B">Barlas Oguz</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computation and Language (cs.CL); Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item581">[581]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15639" title="Abstract">arXiv:2309.15639</a> (replaced) [<a href="/pdf/2309.15639" title="Download PDF">pdf</a>, <a href="/format/2309.15639" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Enhancing Sharpness-Aware Optimization Through Variance Suppression
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+B">Bingcong Li</a>, 
<a href="/search/cs?searchtype=author&query=Giannakis%2C+G+B">Georgios B. Giannakis</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item582">[582]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15757" title="Abstract">arXiv:2309.15757</a> (replaced) [<a href="/pdf/2309.15757" title="Download PDF">pdf</a>, <a href="/format/2309.15757" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Latent Graph Powered Semi-Supervised Learning on Biomedical Tabular Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Koloski%2C+B">Boshko Koloski</a>, 
<a href="/search/cs?searchtype=author&query=%C5%A0krlj%2C+B">Bla&#x17e; &#x160;krlj</a>, 
<a href="/search/cs?searchtype=author&query=Pollak%2C+S">Senja Pollak</a>, 
<a href="/search/cs?searchtype=author&query=Lavra%C4%8D%2C+N">Nada Lavra&#x10d;</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
</dl>
<ul>
<li><a href="/list/cs/new?skip=0&amp;show=2000">New submissions</a></li>
<li><a href="#item328">Cross-lists</a></li>
<li><a href="#item380">Replacements</a></li>
</ul>
<small>[ total of 582 entries:  <b>1-582</b>  ]</small><br />
<small>[ showing up to 2000 entries per page:  <a href="/list/cs/new?skip=0&amp;show=1000">fewer</a> |  <font color="#999999">more</font> ]</small><br />
</div>
<br/><small><a id="mathjax_toggle" href="javascript:setMathjaxCookie()">Disable MathJax</a> (<a href="/help/mathjax">What is MathJax?</a>)</small><script type="text/javascript" language="javascript">mathjaxToggle();</script>

<hr />
<p>Links to:
<a href="/" accesskey="a">arXiv</a>,
<a href="/form/cs">form interface</a>,
<a href="/find/cs">find</a>,
<a href="/archive/cs">cs</a>, <a href="/list/cs/recent">recent</a>, <a href="/list/cs/2309">2309</a>,
<a href="/help/contact">contact</a>,
<a href="/help/" accesskey="h"><span class="accesskey">h</span>elp</a>&nbsp;
<small>(<a href="/help/accesskeys">Access key</a> information)</small>
</p>
<hr />
</div>
</div>
 <footer style="clear: both;">
      <div class="columns is-desktop" role="navigation" aria-label="Secondary" style="margin: -0.75em -0.75em 0.75em -0.75em">
        <!-- Macro-Column 1 -->
        <div class="column" style="padding: 0;">
          <div class="columns">
            <div class="column">
              <ul style="list-style: none; line-height: 2;">
                <li><a href="https://arxiv.org/about">About</a></li>
                <li><a href="https://arxiv.org/help">Help</a></li>
              </ul>
            </div>
            <div class="column">
              <ul style="list-style: none; line-height: 2;">
                <li>
                  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon filter-black" role="presentation"><title>contact arXiv</title><desc>Click here to contact arXiv</desc><path d="M502.3 190.8c3.9-3.1 9.7-.2 9.7 4.7V400c0 26.5-21.5 48-48 48H48c-26.5 0-48-21.5-48-48V195.6c0-5 5.7-7.8 9.7-4.7 22.4 17.4 52.1 39.5 154.1 113.6 21.1 15.4 56.7 47.8 92.2 47.6 35.7.3 72-32.8 92.3-47.6 102-74.1 131.6-96.3 154-113.7zM256 320c23.2.4 56.6-29.2 73.4-41.4 132.7-96.3 142.8-104.7 173.4-128.7 5.8-4.5 9.2-11.5 9.2-18.9v-19c0-26.5-21.5-48-48-48H48C21.5 64 0 85.5 0 112v19c0 7.4 3.4 14.3 9.2 18.9 30.6 23.9 40.7 32.4 173.4 128.7 16.8 12.2 50.2 41.8 73.4 41.4z"/></svg>
                  <a href="https://arxiv.org/help/contact"> Contact</a>
                </li>
                <li>
                  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon filter-black" role="presentation"><title>subscribe to arXiv mailings</title><desc>Click here to subscribe</desc><path d="M476 3.2L12.5 270.6c-18.1 10.4-15.8 35.6 2.2 43.2L121 358.4l287.3-253.2c5.5-4.9 13.3 2.6 8.6 8.3L176 407v80.5c0 23.6 28.5 32.9 42.5 15.8L282 426l124.6 52.2c14.2 6 30.4-2.9 33-18.2l72-432C515 7.8 493.3-6.8 476 3.2z"/></svg>
                  <a href="https://arxiv.org/help/subscribe"> Subscribe</a>
                </li>
              </ul>
            </div>
          </div>
        </div>
        <!-- End Macro-Column 1 -->
        <!-- Macro-Column 2 -->
        <div class="column" style="padding: 0;">
          <div class="columns">
            <div class="column">
              <ul style="list-style: none; line-height: 2;">
                <li><a href="https://arxiv.org/help/license">Copyright</a></li>
                <li><a href="https://arxiv.org/help/policies/privacy_policy">Privacy Policy</a></li>
              </ul>
            </div>
            <div class="column sorry-app-links">
              <ul style="list-style: none; line-height: 2;">
                <li><a href="https://arxiv.org/help/web_accessibility">Web Accessibility Assistance</a></li>
                <li>
                  <p class="help">
                    <a class="a11y-main-link" href="https://status.arxiv.org" target="_blank">arXiv Operational Status <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 256 512" class="icon filter-dark_grey" role="presentation"><path d="M224.3 273l-136 136c-9.4 9.4-24.6 9.4-33.9 0l-22.6-22.6c-9.4-9.4-9.4-24.6 0-33.9l96.4-96.4-96.4-96.4c-9.4-9.4-9.4-24.6 0-33.9L54.3 103c9.4-9.4 24.6-9.4 33.9 0l136 136c9.5 9.4 9.5 24.6.1 34z"/></svg></a><br>
                    Get status notifications via
                    <a class="is-link" href="https://subscribe.sorryapp.com/24846f03/email/new" target="_blank"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon filter-black" role="presentation"><path d="M502.3 190.8c3.9-3.1 9.7-.2 9.7 4.7V400c0 26.5-21.5 48-48 48H48c-26.5 0-48-21.5-48-48V195.6c0-5 5.7-7.8 9.7-4.7 22.4 17.4 52.1 39.5 154.1 113.6 21.1 15.4 56.7 47.8 92.2 47.6 35.7.3 72-32.8 92.3-47.6 102-74.1 131.6-96.3 154-113.7zM256 320c23.2.4 56.6-29.2 73.4-41.4 132.7-96.3 142.8-104.7 173.4-128.7 5.8-4.5 9.2-11.5 9.2-18.9v-19c0-26.5-21.5-48-48-48H48C21.5 64 0 85.5 0 112v19c0 7.4 3.4 14.3 9.2 18.9 30.6 23.9 40.7 32.4 173.4 128.7 16.8 12.2 50.2 41.8 73.4 41.4z"/></svg>email</a>
                    or <a class="is-link" href="https://subscribe.sorryapp.com/24846f03/slack/new" target="_blank"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512" class="icon filter-black" role="presentation"><path d="M94.12 315.1c0 25.9-21.16 47.06-47.06 47.06S0 341 0 315.1c0-25.9 21.16-47.06 47.06-47.06h47.06v47.06zm23.72 0c0-25.9 21.16-47.06 47.06-47.06s47.06 21.16 47.06 47.06v117.84c0 25.9-21.16 47.06-47.06 47.06s-47.06-21.16-47.06-47.06V315.1zm47.06-188.98c-25.9 0-47.06-21.16-47.06-47.06S139 32 164.9 32s47.06 21.16 47.06 47.06v47.06H164.9zm0 23.72c25.9 0 47.06 21.16 47.06 47.06s-21.16 47.06-47.06 47.06H47.06C21.16 243.96 0 222.8 0 196.9s21.16-47.06 47.06-47.06H164.9zm188.98 47.06c0-25.9 21.16-47.06 47.06-47.06 25.9 0 47.06 21.16 47.06 47.06s-21.16 47.06-47.06 47.06h-47.06V196.9zm-23.72 0c0 25.9-21.16 47.06-47.06 47.06-25.9 0-47.06-21.16-47.06-47.06V79.06c0-25.9 21.16-47.06 47.06-47.06 25.9 0 47.06 21.16 47.06 47.06V196.9zM283.1 385.88c25.9 0 47.06 21.16 47.06 47.06 0 25.9-21.16 47.06-47.06 47.06-25.9 0-47.06-21.16-47.06-47.06v-47.06h47.06zm0-23.72c-25.9 0-47.06-21.16-47.06-47.06 0-25.9 21.16-47.06 47.06-47.06h117.84c25.9 0 47.06 21.16 47.06 47.06 0 25.9-21.16 47.06-47.06 47.06H283.1z"/></svg>slack</a>
                  </p>
                </li>
              </ul>
            </div>
          </div>
        </div> <!-- end MetaColumn 2 -->
        <!-- End Macro-Column 2 -->
      </div>
    </footer>
</body>
</html>
