<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en">
<head>
<title>Computer Science  authors/titles &quot;new&quot;</title>
<link rel="shortcut icon" href="/favicon.ico" type="image/x-icon" />
<link rel="stylesheet" type="text/css" media="screen" href="//static.arxiv.org/static/browse/0.3.2.8/css/arXiv.css?v=20220215" />
<link rel="stylesheet" type="text/css" media="screen" href="/bibex/bibex.css?20181009">
<link rel="stylesheet" type="text/css" media="screen" href="https://static.arxiv.org/static/browse/0.3.8/css/browse_search.css" />
<link rel="alternate" type="application/rss+xml" title="Computer Science " href="http://arxiv.org/rss/cs"/>
<script src="/js/mathjaxToggle.min.js" type="text/javascript"></script>


</head>
<body class="with-cu-identity">

<div id="cu-identity">
<div id="cu-logo">
<a href="https://www.cornell.edu/"><img src="//static.arxiv.org/icons/cu/cornell-reduced-white-SMALL.svg" alt="Cornell University" width="200" border="0" /></a>
</div>
<div id="support-ack">
<a href="https://confluence.cornell.edu/x/ALlRF">We gratefully acknowledge support from<br /> the Simons Foundation and member institutions.</a>
</div>
</div>
<div id="header">
<h1 class="header-breadcrumbs"><a href="/"><img src="//static.arxiv.org/images/arxiv-logo-one-color-white.svg" aria-label="logo" alt="arxiv logo" width="85" style="width:85px;margin-right:8px;"></a> <span>&gt;</span> <a href="/list/cs/recent">cs</a></h1>
<div class="search-block level-right">
<form class="level-item mini-search" method="GET" action="https://arxiv.org/search" _lpchecked="1">
<div class="field has-addons">
<div class="control">
<input class="input is-small" type="text" name="query" placeholder="Search..." aria-label="Search term or terms" data-com.agilebits.onepassword.user-edited="yes">
<p class="help"><a href="https://arxiv.org/help">Help</a> | <a href="https://arxiv.org/search/advanced">Advanced Search</a></p>
</div>
<div class="control">
<div class="select is-small">
<select name="searchtype" aria-label="Field to search">
<option value="all" selected="selected">All fields</option>
<option value="title">Title</option>
<option value="author">Author</option>
<option value="abstract">Abstract</option>
<option value="comments">Comments</option>
<option value="journal_ref">Journal reference</option>
<option value="acm_class">ACM classification</option>
<option value="msc_class">MSC classification</option>
<option value="report_num">Report number</option>
<option value="paper_id">arXiv identifier</option>
<option value="doi">DOI</option>
<option value="orcid">ORCID</option>
<option value="author_id">arXiv author ID</option>
<option value="help">Help pages</option>
<option value="full_text">Full text</option>
</select>
</div>
</div>
<button class="button is-small is-cul-darker">Search</button>
</div>
</form>
</div>
</div>
<div id="content">
<div id="dlpage">
<h1>Computer Science </h1>
<h2>New submissions</h2>
<div class="list-dateline">Submissions received from  Fri  8 Sep 23  to  Mon 11 Sep 23, announced Tue, 12 Sep 23</div>
<ul>
<li><a href="/list/cs/new?skip=0&amp;show=2000">New submissions</a></li>
<li><a href="#item487">Cross-lists</a></li>
<li><a href="#item551">Replacements</a></li>
</ul>
<small>[ total of 885 entries:  <b>1-885</b>  ]</small><br />
<small>[ showing up to 2000 entries per page:  <a href="/list/cs/new?skip=0&amp;show=1000">fewer</a> |  <font color="#999999">more</font> ]</small><br />
<h3>New submissions for Tue, 12 Sep 23</h3>
<dl>
<dt><a name="item1">[1]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.04487" title="Abstract">arXiv:2309.04487</a> [<a href="/pdf/2309.04487" title="Download PDF">pdf</a>, <a href="/ps/2309.04487" title="Download PostScript">ps</a>, <a href="/format/2309.04487" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Penalization Framework For Autonomous Agents Using Answer Set  Programming
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tummala%2C+V+S+K">Vineel S. K. Tummala</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> In Proceedings ICLP 2023, <a href="/abs/2308.14898">arXiv:2308.14898</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> EPTCS 385, 2023, pp. 411-415
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Logic in Computer Science (cs.LO)

</div>
<p class="mathjax">This paper presents a framework for enforcing penalties on intelligent agents
that do not comply with authorization or obligation policies in a changing
environment. A framework is proposed to represent and reason about penalties in
plans, and an algorithm is proposed to penalize an agent's actions based on
their level of compliance with respect to authorization and obligation
policies. Being aware of penalties an agent can choose a plan with a minimal
total penalty, unless there is an emergency goal like saving a human's life.
The paper concludes that this framework can reprimand insubordinate agents.
</p>
</div>
</dd>
<dt><a name="item2">[2]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.04491" title="Abstract">arXiv:2309.04491</a> [<a href="/pdf/2309.04491" title="Download PDF">pdf</a>, <a href="/ps/2309.04491" title="Download PostScript">ps</a>, <a href="/format/2309.04491" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Context-Sensitive Approach to XAI in Music Performance
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Privato%2C+N">Nicola Privato</a>, 
<a href="/search/cs?searchtype=author&query=Armitage%2C+J">Jack Armitage</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">The rapidly evolving field of Explainable Artificial Intelligence (XAI) has
generated significant interest in developing methods to make AI systems more
transparent and understandable. However, the problem of explainability cannot
be exhaustively solved in the abstract, as there is no single approach that can
be universally applied to generate adequate explanations for any given AI
system, and this is especially true in the arts. In this position paper, we
propose an Explanatory Pragmatism (EP) framework for XAI in music performance,
emphasising the importance of context and audience in the development of
explainability requirements. By tailoring explanations to specific audiences
and continuously refining them based on feedback, EP offers a promising
direction for enhancing the transparency and interpretability of AI systems in
broad artistic applications and more specifically to music performance.
</p>
</div>
</dd>
<dt><a name="item3">[3]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.04492" title="Abstract">arXiv:2309.04492</a> [<a href="/pdf/2309.04492" title="Download PDF">pdf</a>, <a href="/format/2309.04492" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Safe Neural Control for Non-Affine Control Systems with Differentiable  Control Barrier Functions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xiao%2C+W">Wei Xiao</a>, 
<a href="/search/cs?searchtype=author&query=Allen%2C+R">Ross Allen</a>, 
<a href="/search/cs?searchtype=author&query=Rus%2C+D">Daniela Rus</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, accepted in IEEE CDC 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Machine Learning (cs.LG); Robotics (cs.RO)

</div>
<p class="mathjax">This paper addresses the problem of safety-critical control for non-affine
control systems. It has been shown that optimizing quadratic costs subject to
state and control constraints can be sub-optimally reduced to a sequence of
quadratic programs (QPs) by using Control Barrier Functions (CBFs). Our
recently proposed High Order CBFs (HOCBFs) can accommodate constraints of
arbitrary relative degree. The main challenges in this approach are that it
requires affine control dynamics and the solution of the CBF-based QP is
sub-optimal since it is solved point-wise. To address these challenges, we
incorporate higher-order CBFs into neural ordinary differential equation-based
learning models as differentiable CBFs to guarantee safety for non-affine
control systems. The differentiable CBFs are trainable in terms of their
parameters, and thus, they can address the conservativeness of CBFs such that
the system state will not stay unnecessarily far away from safe set boundaries.
Moreover, the imitation learning model is capable of learning complex and
optimal control policies that are usually intractable online. We illustrate the
effectiveness of the proposed framework on LiDAR-based autonomous driving and
compare it with existing methods.
</p>
</div>
</dd>
<dt><a name="item4">[4]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.04494" title="Abstract">arXiv:2309.04494</a> [<a href="/pdf/2309.04494" title="Download PDF">pdf</a>, <a href="/format/2309.04494" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the Existence of Steady-State Solutions to the Equations Governing  Fluid Flow in Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Srinivasan%2C+S">Shriram Srinivasan</a>, 
<a href="/search/math?searchtype=author&query=Panda%2C+N">Nishant Panda</a>, 
<a href="/search/math?searchtype=author&query=Sundar%2C+K">Kaarthik Sundar</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Systems and Control (eess.SY)

</div>
<p class="mathjax">The steady-state solution of fluid flow in pipeline infrastructure networks
driven by junction/node potentials is a crucial ingredient in various decision
support tools for system design and operation. While the non-linear system is
known to have a unique solution (when one exists), the absence of a definite
result on existence of solutions hobbles the development of computational
algorithms, for it is not possible to distinguish between algorithm failure and
non-existence of a solution. In this letter we show that a unique solution
exists for such non-linear systems if the term \emph{solution} is interpreted
in terms of \emph{potentials} and flows rather than \emph{pressures} and flows.
The existence result for flow of natural gas in networks also applies to other
fluid flow networks such as water distribution networks or networks that
transport carbon dioxide in carbon capture and sequestration. Most importantly,
by giving a complete answer to the question of existence of solutions, our
result enables correct diagnosis of algorithmic failure, problem stiffness and
non-convergence in computational algorithms.
</p>
</div>
</dd>
<dt><a name="item5">[5]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.04499" title="Abstract">arXiv:2309.04499</a> [<a href="/pdf/2309.04499" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Weighted Unsupervised Domain Adaptation Considering Geometry Features  and Engineering Performance of 3D Design Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shin%2C+S">Seungyeon Shin</a>, 
<a href="/search/cs?searchtype=author&query=Kang%2C+N">Namwoo Kang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">The product design process in manufacturing involves iterative design
modeling and analysis to achieve the target engineering performance, but such
an iterative process is time consuming and computationally expensive. Recently,
deep learning-based engineering performance prediction models have been
proposed to accelerate design optimization. However, they only guarantee
predictions on training data and may be inaccurate when applied to new domain
data. In particular, 3D design data have complex features, which means domains
with various distributions exist. Thus, the utilization of deep learning has
limitations due to the heavy data collection and training burdens. We propose a
bi-weighted unsupervised domain adaptation approach that considers the geometry
features and engineering performance of 3D design data. It is specialized for
deep learning-based engineering performance predictions. Domain-invariant
features can be extracted through an adversarial training strategy by using
hypothesis discrepancy, and a multi-output regression task can be performed
with the extracted features to predict the engineering performance. In
particular, we present a source instance weighting method suitable for 3D
design data to avoid negative transfers. The developed bi-weighting strategy
based on the geometry features and engineering performance of engineering
structures is incorporated into the training process. The proposed model is
tested on a wheel impact analysis problem to predict the magnitude of the
maximum von Mises stress and the corresponding location of 3D road wheels. This
mechanism can reduce the target risk for unlabeled target domains on the basis
of weighted multi-source domain knowledge and can efficiently replace
conventional finite element analysis.
</p>
</div>
</dd>
<dt><a name="item6">[6]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.04502" title="Abstract">arXiv:2309.04502</a> [<a href="/pdf/2309.04502" title="Download PDF">pdf</a>, <a href="/format/2309.04502" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the Efficacy of Multi-scale Data Samplers for Vision Applications
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nunez%2C+E">Elvis Nunez</a>, 
<a href="/search/cs?searchtype=author&query=Merth%2C+T">Thomas Merth</a>, 
<a href="/search/cs?searchtype=author&query=Prabhu%2C+A">Anish Prabhu</a>, 
<a href="/search/cs?searchtype=author&query=Farajtabar%2C+M">Mehrdad Farajtabar</a>, 
<a href="/search/cs?searchtype=author&query=Rastegari%2C+M">Mohammad Rastegari</a>, 
<a href="/search/cs?searchtype=author&query=Mehta%2C+S">Sachin Mehta</a>, 
<a href="/search/cs?searchtype=author&query=Horton%2C+M">Maxwell Horton</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Multi-scale resolution training has seen an increased adoption across
multiple vision tasks, including classification and detection. Training with
smaller resolutions enables faster training at the expense of a drop in
accuracy. Conversely, training with larger resolutions has been shown to
improve performance, but memory constraints often make this infeasible. In this
paper, we empirically study the properties of multi-scale training procedures.
We focus on variable batch size multi-scale data samplers that randomly sample
an input resolution at each training iteration and dynamically adjust their
batch size according to the resolution. Such samplers have been shown to
improve model accuracy beyond standard training with a fixed batch size and
resolution, though it is not clear why this is the case. We explore the
properties of these data samplers by performing extensive experiments on
ResNet-101 and validate our conclusions across multiple architectures, tasks,
and datasets. We show that multi-scale samplers behave as implicit data
regularizers and accelerate training speed. Compared to models trained with
single-scale samplers, we show that models trained with multi-scale samplers
retain or improve accuracy, while being better-calibrated and more robust to
scaling and data distribution shifts. We additionally extend a multi-scale
variable batch sampler with a simple curriculum that progressively grows
resolutions throughout training, allowing for a compute reduction of more than
30%. We show that the benefits of multi-scale training extend to detection and
instance segmentation tasks, where we observe a 37% reduction in training FLOPs
along with a 3-4% mAP increase on MS-COCO using a Mask R-CNN model.
</p>
</div>
</dd>
<dt><a name="item7">[7]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.04504" title="Abstract">arXiv:2309.04504</a> [<a href="/pdf/2309.04504" title="Download PDF">pdf</a>, <a href="/format/2309.04504" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Compositional Learning of Visually-Grounded Concepts Using Reinforcement
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lin%2C+Z">Zijun Lin</a>, 
<a href="/search/cs?searchtype=author&query=Azaman%2C+H">Haidi Azaman</a>, 
<a href="/search/cs?searchtype=author&query=Kumar%2C+M+G">M Ganesh Kumar</a>, 
<a href="/search/cs?searchtype=author&query=Tan%2C+C">Cheston Tan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Deep reinforcement learning agents need to be trained over millions of
episodes to decently solve navigation tasks grounded to instructions.
Furthermore, their ability to generalize to novel combinations of instructions
is unclear. Interestingly however, children can decompose language-based
instructions and navigate to the referred object, even if they have not seen
the combination of queries prior. Hence, we created three 3D environments to
investigate how deep RL agents learn and compose color-shape based
combinatorial instructions to solve novel combinations in a spatial navigation
task. First, we explore if agents can perform compositional learning, and
whether they can leverage on frozen text encoders (e.g. CLIP, BERT) to learn
word combinations in fewer episodes. Next, we demonstrate that when agents are
pretrained on the shape or color concepts separately, they show a 20 times
decrease in training episodes needed to solve unseen combinations of
instructions. Lastly, we show that agents pretrained on concept and
compositional learning achieve significantly higher reward when evaluated
zero-shot on novel color-shape1-shape2 visual object combinations. Overall, our
results highlight the foundations needed to increase an agent's proficiency in
composing word groups through reinforcement learning and its ability for
zero-shot generalization to new combinations.
</p>
</div>
</dd>
<dt><a name="item8">[8]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.04505" title="Abstract">arXiv:2309.04505</a> [<a href="/pdf/2309.04505" title="Download PDF">pdf</a>, <a href="/format/2309.04505" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> COVID-19 Detection System: A Comparative Analysis of System Performance  Based on Acoustic Features of Cough Audio Signals
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shati%2C+A">Asmaa Shati</a>, 
<a href="/search/cs?searchtype=author&query=Hassan%2C+G+M">Ghulam Mubashar Hassan</a>, 
<a href="/search/cs?searchtype=author&query=Datta%2C+A">Amitava Datta</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 3 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Machine Learning (cs.LG); Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">A wide range of respiratory diseases, such as cold and flu, asthma, and
COVID-19, affect people's daily lives worldwide. In medical practice,
respiratory sounds are widely used in medical services to diagnose various
respiratory illnesses and lung disorders. The traditional diagnosis of such
sounds requires specialized knowledge, which can be costly and reliant on human
expertise. Recently, cough audio recordings have been used to automate the
process of detecting respiratory conditions. This research aims to examine
various acoustic features that enhance the performance of machine learning (ML)
models in detecting COVID-19 from cough signals. This study investigates the
efficacy of three feature extraction techniques, including Mel Frequency
Cepstral Coefficients (MFCC), Chroma, and Spectral Contrast features, on two ML
algorithms, Support Vector Machine (SVM) and Multilayer Perceptron (MLP), and
thus proposes an efficient COVID-19 detection system. The proposed system
produces a practical solution and demonstrates higher state-of-the-art
classification performance on COUGHVID and Virufy datasets for COVID-19
detection.
</p>
</div>
</dd>
<dt><a name="item9">[9]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.04506" title="Abstract">arXiv:2309.04506</a> [<a href="/pdf/2309.04506" title="Download PDF">pdf</a>, <a href="/format/2309.04506" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Unsupervised Gaze-aware Contrastive Learning with Subject-specific  Condition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Du%2C+L">Lingyu Du</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xucong Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Lan%2C+G">Guohao Lan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Appearance-based gaze estimation has shown great promise in many applications
by using a single general-purpose camera as the input device. However, its
success is highly depending on the availability of large-scale well-annotated
gaze datasets, which are sparse and expensive to collect. To alleviate this
challenge we propose ConGaze, a contrastive learning-based framework that
leverages unlabeled facial images to learn generic gaze-aware representations
across subjects in an unsupervised way. Specifically, we introduce the
gaze-specific data augmentation to preserve the gaze-semantic features and
maintain the gaze consistency, which are proven to be crucial for effective
contrastive gaze representation learning. Moreover, we devise a novel
subject-conditional projection module that encourages a share feature extractor
to learn gaze-aware and generic representations. Our experiments on three
public gaze estimation datasets show that ConGaze outperforms existing
unsupervised learning solutions by 6.7% to 22.5%; and achieves 15.1% to 24.6%
improvement over its supervised learning-based counterpart in cross-dataset
evaluations.
</p>
</div>
</dd>
<dt><a name="item10">[10]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.04508" title="Abstract">arXiv:2309.04508</a> [<a href="/pdf/2309.04508" title="Download PDF">pdf</a>, <a href="/format/2309.04508" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Spatial-Temporal Graph Attention Fuser for Calibration in IoT Air  Pollution Monitoring Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Niresi%2C+K+F">Keivan Faghih Niresi</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+M">Mengjie Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Bissig%2C+H">Hugo Bissig</a>, 
<a href="/search/cs?searchtype=author&query=Baumann%2C+H">Henri Baumann</a>, 
<a href="/search/cs?searchtype=author&query=Fink%2C+O">Olga Fink</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Signal Processing (eess.SP)

</div>
<p class="mathjax">The use of Internet of Things (IoT) sensors for air pollution monitoring has
significantly increased, resulting in the deployment of low-cost sensors.
Despite this advancement, accurately calibrating these sensors in uncontrolled
environmental conditions remains a challenge. To address this, we propose a
novel approach that leverages graph neural networks, specifically the graph
attention network module, to enhance the calibration process by fusing data
from sensor arrays. Through our experiments, we demonstrate the effectiveness
of our approach in significantly improving the calibration accuracy of sensors
in IoT air pollution monitoring platforms.
</p>
</div>
</dd>
<dt><a name="item11">[11]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.04509" title="Abstract">arXiv:2309.04509</a> [<a href="/pdf/2309.04509" title="Download PDF">pdf</a>, <a href="/format/2309.04509" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Power of Sound (TPoS): Audio Reactive Video Generation with Stable  Diffusion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jeong%2C+Y">Yujin Jeong</a>, 
<a href="/search/cs?searchtype=author&query=Ryoo%2C+W">Wonjeong Ryoo</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+S">Seunghyun Lee</a>, 
<a href="/search/cs?searchtype=author&query=Seo%2C+D">Dabin Seo</a>, 
<a href="/search/cs?searchtype=author&query=Byeon%2C+W">Wonmin Byeon</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+S">Sangpil Kim</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+J">Jinkyu Kim</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ICCV2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Computer Vision and Pattern Recognition (cs.CV); Graphics (cs.GR); Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">In recent years, video generation has become a prominent generative tool and
has drawn significant attention. However, there is little consideration in
audio-to-video generation, though audio contains unique qualities like temporal
semantics and magnitude. Hence, we propose The Power of Sound (TPoS) model to
incorporate audio input that includes both changeable temporal semantics and
magnitude. To generate video frames, TPoS utilizes a latent stable diffusion
model with textual semantic information, which is then guided by the sequential
audio embedding from our pretrained Audio Encoder. As a result, this method
produces audio reactive video contents. We demonstrate the effectiveness of
TPoS across various tasks and compare its results with current state-of-the-art
techniques in the field of audio-to-video generation. More examples are
available at https://ku-vai.github.io/TPoS/
</p>
</div>
</dd>
<dt><a name="item12">[12]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.04510" title="Abstract">arXiv:2309.04510</a> [<a href="/pdf/2309.04510" title="Download PDF">pdf</a>, <a href="/format/2309.04510" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Decreasing the Computing Time of Bayesian Optimization using  Generalizable Memory Pruning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Siemenn%2C+A+E">Alexander E. Siemenn</a>, 
<a href="/search/cs?searchtype=author&query=Buonassisi%2C+T">Tonio Buonassisi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted as a paper in IEEE HPEC 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Bayesian optimization (BO) suffers from long computing times when processing
highly-dimensional or large data sets. These long computing times are a result
of the Gaussian process surrogate model having a polynomial time complexity
with the number of experiments. Running BO on high-dimensional or massive data
sets becomes intractable due to this time complexity scaling, in turn,
hindering experimentation. Alternative surrogate models have been developed to
reduce the computing utilization of the BO procedure, however, these methods
require mathematical alteration of the inherit surrogate function, pigeonholing
use into only that function. In this paper, we demonstrate a generalizable BO
wrapper of memory pruning and bounded optimization, capable of being used with
any surrogate model and acquisition function. Using this memory pruning
approach, we show a decrease in wall-clock computing times per experiment of BO
from a polynomially increasing pattern to a sawtooth pattern that has a
non-increasing trend without sacrificing convergence performance. Furthermore,
we illustrate the generalizability of the approach across two unique data sets,
two unique surrogate models, and four unique acquisition functions. All model
implementations are run on the MIT Supercloud state-of-the-art computing
hardware.
</p>
</div>
</dd>
<dt><a name="item13">[13]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.04515" title="Abstract">arXiv:2309.04515</a> [<a href="/pdf/2309.04515" title="Download PDF">pdf</a>, <a href="/format/2309.04515" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Privacy Preserving Federated Learning with Convolutional Variational  Bottlenecks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Scheliga%2C+D">Daniel Scheliga</a>, 
<a href="/search/cs?searchtype=author&query=M%C3%A4der%2C+P">Patrick M&#xe4;der</a>, 
<a href="/search/cs?searchtype=author&query=Seeland%2C+M">Marco Seeland</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages (12 figures 6 tables) + 6 pages supplementary materials (6 tables). Under review. This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible. arXiv admin note: substantial text overlap with <a href="/abs/2208.04767">arXiv:2208.04767</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Cryptography and Security (cs.CR)

</div>
<p class="mathjax">Gradient inversion attacks are an ubiquitous threat in federated learning as
they exploit gradient leakage to reconstruct supposedly private training data.
Recent work has proposed to prevent gradient leakage without loss of model
utility by incorporating a PRivacy EnhanCing mODulE (PRECODE) based on
variational modeling. Without further analysis, it was shown that PRECODE
successfully protects against gradient inversion attacks. In this paper, we
make multiple contributions. First, we investigate the effect of PRECODE on
gradient inversion attacks to reveal its underlying working principle. We show
that variational modeling introduces stochasticity into the gradients of
PRECODE and the subsequent layers in a neural network. The stochastic gradients
of these layers prevent iterative gradient inversion attacks from converging.
Second, we formulate an attack that disables the privacy preserving effect of
PRECODE by purposefully omitting stochastic gradients during attack
optimization. To preserve the privacy preserving effect of PRECODE, our
analysis reveals that variational modeling must be placed early in the network.
However, early placement of PRECODE is typically not feasible due to reduced
model utility and the exploding number of additional model parameters.
Therefore, as a third contribution, we propose a novel privacy module -- the
Convolutional Variational Bottleneck (CVB) -- that can be placed early in a
neural network without suffering from these drawbacks. We conduct an extensive
empirical study on three seminal model architectures and six image
classification datasets. We find that all architectures are susceptible to
gradient leakage attacks, which can be prevented by our proposed CVB. Compared
to PRECODE, we show that our novel privacy module requires fewer trainable
parameters, and thus computational and communication costs, to effectively
preserve privacy.
</p>
</div>
</dd>
<dt><a name="item14">[14]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.04522" title="Abstract">arXiv:2309.04522</a> [<a href="/pdf/2309.04522" title="Download PDF">pdf</a>, <a href="/format/2309.04522" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Connecting NTK and NNGP: A Unified Theoretical Framework for Neural  Network Learning Dynamics in the Kernel Regime
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Avidan%2C+Y">Yehonatan Avidan</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Q">Qianyi Li</a>, 
<a href="/search/cs?searchtype=author&query=Sompolinsky%2C+H">Haim Sompolinsky</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Artificial neural networks have revolutionized machine learning in recent
years, but a complete theoretical framework for their learning process is still
lacking. Substantial progress has been made for infinitely wide networks. In
this regime, two disparate theoretical frameworks have been used, in which the
network's output is described using kernels: one framework is based on the
Neural Tangent Kernel (NTK) which assumes linearized gradient descent dynamics,
while the Neural Network Gaussian Process (NNGP) kernel assumes a Bayesian
framework. However, the relation between these two frameworks has remained
elusive. This work unifies these two distinct theories using a Markov proximal
learning model for learning dynamics in an ensemble of randomly initialized
infinitely wide deep networks. We derive an exact analytical expression for the
network input-output function during and after learning, and introduce a new
time-dependent Neural Dynamical Kernel (NDK) from which both NTK and NNGP
kernels can be derived. We identify two learning phases characterized by
different time scales: gradient-driven and diffusive learning. In the initial
gradient-driven learning phase, the dynamics is dominated by deterministic
gradient descent, and is described by the NTK theory. This phase is followed by
the diffusive learning stage, during which the network parameters sample the
solution space, ultimately approaching the equilibrium distribution
corresponding to NNGP. Combined with numerical evaluations on synthetic and
benchmark datasets, we provide novel insights into the different roles of
initialization, regularization, and network depth, as well as phenomena such as
early stopping and representational drift. This work closes the gap between the
NTK and NNGP theories, providing a comprehensive framework for understanding
the learning process of deep neural networks in the infinite width limit.
</p>
</div>
</dd>
<dt><a name="item15">[15]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.04542" title="Abstract">arXiv:2309.04542</a> [<a href="/pdf/2309.04542" title="Download PDF">pdf</a>, <a href="/format/2309.04542" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Examining Autoexposure for Challenging Scenes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tedla%2C+S">SaiKiran Tedla</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+B">Beixuan Yang</a>, 
<a href="/search/cs?searchtype=author&query=Brown%2C+M+S">Michael S. Brown</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ICCV 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Autoexposure (AE) is a critical step applied by camera systems to ensure
properly exposed images. While current AE algorithms are effective in well-lit
environments with constant illumination, these algorithms still struggle in
environments with bright light sources or scenes with abrupt changes in
lighting. A significant hurdle in developing new AE algorithms for challenging
environments, especially those with time-varying lighting, is the lack of
suitable image datasets. To address this issue, we have captured a new 4D
exposure dataset that provides a large solution space (i.e., shutter speed
range from (1/500 to 15 seconds) over a temporal sequence with moving objects,
bright lights, and varying lighting. In addition, we have designed a software
platform to allow AE algorithms to be used in a plug-and-play manner with the
dataset. Our dataset and associate platform enable repeatable evaluation of
different AE algorithms and provide a much-needed starting point to develop
better AE methods. We examine several existing AE strategies using our dataset
and show that most users prefer a simple saliency method for challenging
lighting conditions.
</p>
</div>
</dd>
<dt><a name="item16">[16]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.04543" title="Abstract">arXiv:2309.04543</a> [<a href="/pdf/2309.04543" title="Download PDF">pdf</a>, <a href="/ps/2309.04543" title="Download PostScript">ps</a>, <a href="/format/2309.04543" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Study on Workload Assessment and Usability of Wind-Aware User  Interface for Small Unmanned Aircraft System Remote Operations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tabassum%2C+A">Asma Tabassum</a>, 
<a href="/search/cs?searchtype=author&query=Bai%2C+H">He Bai</a>, 
<a href="/search/cs?searchtype=author&query=Fala%2C+N">Nicoletta Fala</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">This study evaluates pilots' cognitive workload and situational awareness
during remote small unmanned aircraft system operations in different wind
conditions. To complement the urban air mobility concept that envisions safe,
sustainable, and accessible air transportation, we conduct multiple experiments
in a realistic wind-aware simulator-user interface pipeline. Experiments are
performed with basic and wind-aware displays in several wind conditions to
assess how complex wind fields impact pilots' cognitive resources. Post-hoc
analysis reveals that providing pilots with real-time wind information improves
situational awareness while decreasing cognitive workload.
</p>
</div>
</dd>
<dt><a name="item17">[17]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.04546" title="Abstract">arXiv:2309.04546</a> [<a href="/pdf/2309.04546" title="Download PDF">pdf</a>, <a href="/format/2309.04546" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> From Internet of Things to Internet of Data Apps
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fu%2C+S">Silvery Fu</a>, 
<a href="/search/cs?searchtype=author&query=Ratnasamy%2C+S">Sylvia Ratnasamy</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages, 2 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>

</div>
<p class="mathjax">We introduce the Internet of Data Apps (IoDA), representing the next natural
progression of the Internet, Big Data, AI, and the Internet of Things. Despite
advancements in these fields, the full potential of universal data access - the
capability to seamlessly consume and contribute data via data applications -
remains stifled by organizational and technological silos. To address these
constraints, we propose the designs of an IoDA layer borrowing inspirations
from the standard Internet protocols. This layer facilitates the
interconnection of data applications across different devices and domains. This
short paper serves as an invitation to dialogue over this proposal.
</p>
</div>
</dd>
<dt><a name="item18">[18]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.04548" title="Abstract">arXiv:2309.04548</a> [<a href="/pdf/2309.04548" title="Download PDF">pdf</a>, <a href="/format/2309.04548" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Poster: Enabling Flexible Edge-assisted XR
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Heo%2C+J">Jin Heo</a>, 
<a href="/search/cs?searchtype=author&query=Bhardwaj%2C+K">Ketan Bhardwaj</a>, 
<a href="/search/cs?searchtype=author&query=Gavrilovska%2C+A">Ada Gavrilovska</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> extended abstract of 2 pages, 1 figure, 2 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>; Multimedia (cs.MM)

</div>
<p class="mathjax">Extended reality (XR) is touted as the next frontier of the digital future.
XR includes all immersive technologies of augmented reality (AR), virtual
reality (VR), and mixed reality (MR). XR applications obtain the real-world
context of the user from an underlying system, and provide rich, immersive, and
interactive virtual experiences based on the user's context in real-time. XR
systems process streams of data from device sensors, and provide
functionalities including perceptions and graphics required by the
applications. These processing steps are computationally intensive, and the
challenge is that they must be performed within the strict latency requirements
of XR. This poses limitations on the possible XR experiences that can be
supported on mobile devices with limited computing resources.
<br />In this XR context, edge computing is an effective approach to address this
problem for mobile users. The edge is located closer to the end users and
enables processing and storing data near them. In addition, the development of
high bandwidth and low latency network technologies such as 5G facilitates the
application of edge computing for latency-critical use cases [4, 11]. This work
presents an XR system for enabling flexible edge-assisted XR.
</p>
</div>
</dd>
<dt><a name="item19">[19]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.04549" title="Abstract">arXiv:2309.04549</a> [<a href="/pdf/2309.04549" title="Download PDF">pdf</a>, <a href="/format/2309.04549" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Poster: Making Edge-assisted LiDAR Perceptions Robust to Lossy Point  Cloud Compression
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Heo%2C+J">Jin Heo</a>, 
<a href="/search/cs?searchtype=author&query=Phillips%2C+G">Gregorie Phillips</a>, 
<a href="/search/cs?searchtype=author&query=Brodin%2C+P">Per-Erik Brodin</a>, 
<a href="/search/cs?searchtype=author&query=Gavrilovska%2C+A">Ada Gavrilovska</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> extended abstract of 2 pages, 2 figures, 1 table
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Distributed, Parallel, and Cluster Computing (cs.DC); Multimedia (cs.MM); Image and Video Processing (eess.IV)

</div>
<p class="mathjax">Real-time light detection and ranging (LiDAR) perceptions, e.g., 3D object
detection and simultaneous localization and mapping are computationally
intensive to mobile devices of limited resources and often offloaded on the
edge. Offloading LiDAR perceptions requires compressing the raw sensor data,
and lossy compression is used for efficiently reducing the data volume. Lossy
compression degrades the quality of LiDAR point clouds, and the perception
performance is decreased consequently. In this work, we present an
interpolation algorithm improving the quality of a LiDAR point cloud to
mitigate the perception performance loss due to lossy compression. The
algorithm targets the range image (RI) representation of a point cloud and
interpolates points at the RI based on depth gradients. Compared to existing
image interpolation algorithms, our algorithm shows a better qualitative result
when the point cloud is reconstructed from the interpolated RI. With the
preliminary results, we also describe the next steps of the current work.
</p>
</div>
</dd>
<dt><a name="item20">[20]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.04550" title="Abstract">arXiv:2309.04550</a> [<a href="/pdf/2309.04550" title="Download PDF">pdf</a>, <a href="/format/2309.04550" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Retrieving Evidence from EHRs with LLMs: Possibilities and Challenges
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ahsan%2C+H">Hiba Ahsan</a>, 
<a href="/search/cs?searchtype=author&query=McInerney%2C+D+J">Denis Jered McInerney</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+J">Jisoo Kim</a>, 
<a href="/search/cs?searchtype=author&query=Potter%2C+C">Christopher Potter</a>, 
<a href="/search/cs?searchtype=author&query=Young%2C+G">Geoffrey Young</a>, 
<a href="/search/cs?searchtype=author&query=Amir%2C+S">Silvio Amir</a>, 
<a href="/search/cs?searchtype=author&query=Wallace%2C+B+C">Byron C. Wallace</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Unstructured Electronic Health Record (EHR) data often contains critical
information complementary to imaging data that would inform radiologists'
diagnoses. However, time constraints and the large volume of notes frequently
associated with individual patients renders manual perusal of such data to
identify relevant evidence infeasible in practice. Modern Large Language Models
(LLMs) provide a flexible means of interacting with unstructured EHR data, and
may provide a mechanism to efficiently retrieve and summarize unstructured
evidence relevant to a given query. In this work, we propose and evaluate an
LLM (Flan-T5 XXL) for this purpose. Specifically, in a zero-shot setting we
task the LLM to infer whether a patient has or is at risk of a particular
condition; if so, we prompt the model to summarize the supporting evidence.
Enlisting radiologists for manual evaluation, we find that this LLM-based
approach provides outputs consistently preferred to a standard information
retrieval baseline, but we also highlight the key outstanding challenge: LLMs
are prone to hallucinating evidence. However, we provide results indicating
that model confidence in outputs might indicate when LLMs are hallucinating,
potentially providing a means to address this.
</p>
</div>
</dd>
<dt><a name="item21">[21]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.04551" title="Abstract">arXiv:2309.04551</a> [<a href="/pdf/2309.04551" title="Download PDF">pdf</a>, <a href="/ps/2309.04551" title="Download PostScript">ps</a>, <a href="/format/2309.04551" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Recursive Error Reduction for Regular Branching Programs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chattopadhyay%2C+E">Eshan Chattopadhyay</a>, 
<a href="/search/cs?searchtype=author&query=Liao%2C+J">Jyun-Jie Liao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Complexity (cs.CC)</span>; Data Structures and Algorithms (cs.DS)

</div>
<p class="mathjax">In a recent work, Chen, Hoza, Lyu, Tal and Wu (FOCS 2023) showed an improved
error reduction framework for the derandomization of regular read-once
branching programs (ROBPs). Their result is based on a clever modification to
the inverse Laplacian perspective of space-bounded derandomization, which was
originally introduced by Ahmadinejad, Kelner, Murtagh, Peebles, Sidford and
Vadhan (FOCS 2020).
<br />In this work, we give an alternative error reduction framework for regular
ROBPs. Our new framework is based on a binary recursive formula from the work
of Chattopadhyay and Liao (CCC 2020), that they used to construct weighted
pseudorandom generators (WPRGs) for general ROBPs.
<br />Based on our new error reduction framework, we give alternative proofs to the
following results for regular ROBPs of length $n$ and width $w$, both of which
were proved in the work of Chen et al. using their error reduction:
<br />$\bullet$ There is a WPRG with error $\varepsilon$ that has seed length
$\tilde{O}(\log(n)(\sqrt{\log(1/\varepsilon)}+\log(w))+\log(1/\varepsilon)).$
<br />$\bullet$ There is a (non-black-box) deterministic algorithm which estimates
the expectation of any such program within error $\pm\varepsilon$ with space
complexity $\tilde{O}(\log(nw)\cdot\log\log(1/\varepsilon)).$ (This was first
proved in the work of Ahmadinejad et al., but the proof by Chen et al. is
simpler.)
<br />Because of the binary recursive nature of our new framework, both of our
proofs are based on a straightforward induction that is arguably simpler than
the Laplacian-based proof in the work of Chen et al.
</p>
</div>
</dd>
<dt><a name="item22">[22]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.04556" title="Abstract">arXiv:2309.04556</a> [<a href="/pdf/2309.04556" title="Download PDF">pdf</a>, <a href="/format/2309.04556" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Control-Oriented Modeling and Layer-to-Layer Spatial Control of Powder  Bed Fusion Processes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Wang%2C+X">Xin Wang</a>, 
<a href="/search/eess?searchtype=author&query=Park%2C+B">Bumsoo Park</a>, 
<a href="/search/eess?searchtype=author&query=Landers%2C+R+G">Robert G. Landers</a>, 
<a href="/search/eess?searchtype=author&query=Mishra%2C+S">Sandipan Mishra</a>, 
<a href="/search/eess?searchtype=author&query=Bristow%2C+D+A">Douglas A. Bristow</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">Powder Bed Fusion (PBF) is an important Additive Manufacturing (AM) process
that is seeing widespread utilization. However, due to inherent process
variability, it is still very costly and time consuming to certify the process
and the part. This has led researchers to conduct numerous studies in process
modeling, in-situ monitoring and feedback control to better understand the PBF
process and decrease variations, thereby making the process more repeatable. In
this study, we develop a layer-to-layer, spatial, control-oriented thermal PBF
model. This model enables a framework for capturing spatially-driven thermal
effects and constructing layer-to-layer spatial controllers that do not suffer
from inherent temporal delays. Further, this framework is amenable to
voxel-level monitoring and characterization efforts. System output
controllability is analyzed and output controllability conditions are
determined. A spatial Iterative Learning Controller (ILC), constructed using
the spatial modeling framework, is implemented in two experiments, one where
the path and part geometry are layer-invariant and another where the path and
part geometry change each layer. The results illustrate the ability of the
controller to thermally regulate the entire part, even at corners that tend to
overheat and even as the path and part geometry change each layer.
</p>
</div>
</dd>
<dt><a name="item23">[23]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.04557" title="Abstract">arXiv:2309.04557</a> [<a href="/pdf/2309.04557" title="Download PDF">pdf</a>, <a href="/format/2309.04557" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Regret-Optimal Federated Transfer Learning for Kernel Regression with  Applications in American Option Pricing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+X">Xuwei Yang</a>, 
<a href="/search/cs?searchtype=author&query=Kratsios%2C+A">Anastasis Kratsios</a>, 
<a href="/search/cs?searchtype=author&query=Krach%2C+F">Florian Krach</a>, 
<a href="/search/cs?searchtype=author&query=Grasselli%2C+M">Matheus Grasselli</a>, 
<a href="/search/cs?searchtype=author&query=Lucchi%2C+A">Aurelien Lucchi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 54 pages, 3 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Dynamical Systems (math.DS); Optimization and Control (math.OC); Computational Finance (q-fin.CP)

</div>
<p class="mathjax">We propose an optimal iterative scheme for federated transfer learning, where
a central planner has access to datasets ${\cal D}_1,\dots,{\cal D}_N$ for the
same learning model $f_{\theta}$. Our objective is to minimize the cumulative
deviation of the generated parameters $\{\theta_i(t)\}_{t=0}^T$ across all $T$
iterations from the specialized parameters
$\theta^\star_{1},\ldots,\theta^\star_N$ obtained for each dataset, while
respecting the loss function for the model $f_{\theta(T)}$ produced by the
algorithm upon halting. We only allow for continual communication between each
of the specialized models (nodes/agents) and the central planner (server), at
each iteration (round). For the case where the model $f_{\theta}$ is a
finite-rank kernel regression, we derive explicit updates for the
regret-optimal algorithm. By leveraging symmetries within the regret-optimal
algorithm, we further develop a nearly regret-optimal heuristic that runs with
$\mathcal{O}(Np^2)$ fewer elementary operations, where $p$ is the dimension of
the parameter space. Additionally, we investigate the adversarial robustness of
the regret-optimal algorithm showing that an adversary which perturbs $q$
training pairs by at-most $\varepsilon&gt;0$, across all training sets, cannot
reduce the regret-optimal algorithm's regret by more than
$\mathcal{O}(\varepsilon q \bar{N}^{1/2})$, where $\bar{N}$ is the aggregate
number of training pairs. To validate our theoretical findings, we conduct
numerical experiments in the context of American option pricing, utilizing a
randomly generated finite-rank kernel.
</p>
</div>
</dd>
<dt><a name="item24">[24]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.04558" title="Abstract">arXiv:2309.04558</a> [<a href="/pdf/2309.04558" title="Download PDF">pdf</a>, <a href="/format/2309.04558" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Interpretable Solar Flare Prediction with Attention-based Deep  Neural Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pandey%2C+C">Chetraj Pandey</a>, 
<a href="/search/cs?searchtype=author&query=Ji%2C+A">Anli Ji</a>, 
<a href="/search/cs?searchtype=author&query=Angryk%2C+R+A">Rafal A. Angryk</a>, 
<a href="/search/cs?searchtype=author&query=Aydin%2C+B">Berkay Aydin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This is a preprint accepted at the 6th International Conference on Artificial Intelligence and Knowledge Engineering (AIKE), 2023. 8 pages, 6 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Solar and Stellar Astrophysics (astro-ph.SR)

</div>
<p class="mathjax">Solar flare prediction is a central problem in space weather forecasting and
recent developments in machine learning and deep learning accelerated the
adoption of complex models for data-driven solar flare forecasting. In this
work, we developed an attention-based deep learning model as an improvement
over the standard convolutional neural network (CNN) pipeline to perform
full-disk binary flare predictions for the occurrence of $\geq$M1.0-class
flares within the next 24 hours. For this task, we collected compressed images
created from full-disk line-of-sight (LoS) magnetograms. We used data-augmented
oversampling to address the class imbalance issue and used true skill statistic
(TSS) and Heidke skill score (HSS) as the evaluation metrics. Furthermore, we
interpreted our model by overlaying attention maps on input magnetograms and
visualized the important regions focused on by the model that led to the
eventual decision. The significant findings of this study are: (i) We
successfully implemented an attention-based full-disk flare predictor ready for
operational forecasting where the candidate model achieves an average
TSS=0.54$\pm$0.03 and HSS=0.37$\pm$0.07. (ii) we demonstrated that our
full-disk model can learn conspicuous features corresponding to active regions
from full-disk magnetogram images, and (iii) our experimental evaluation
suggests that our model can predict near-limb flares with adept skill and the
predictions are based on relevant active regions (ARs) or AR characteristics
from full-disk magnetograms.
</p>
</div>
</dd>
<dt><a name="item25">[25]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.04561" title="Abstract">arXiv:2309.04561</a> [<a href="/pdf/2309.04561" title="Download PDF">pdf</a>, <a href="/format/2309.04561" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Three Ways to Improve Verbo-visual Fusion for Dense 3D Visual Grounding
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Unal%2C+O">Ozan Unal</a>, 
<a href="/search/cs?searchtype=author&query=Sakaridis%2C+C">Christos Sakaridis</a>, 
<a href="/search/cs?searchtype=author&query=Saha%2C+S">Suman Saha</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+F">Fisher Yu</a>, 
<a href="/search/cs?searchtype=author&query=Van+Gool%2C+L">Luc Van Gool</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Winner of the ICCV 2023 ScanRefer Challenge. This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Computation and Language (cs.CL)

</div>
<p class="mathjax">3D visual grounding is the task of localizing the object in a 3D scene which
is referred by a description in natural language. With a wide range of
applications ranging from autonomous indoor robotics to AR/VR, the task has
recently risen in popularity. A common formulation to tackle 3D visual
grounding is grounding-by-detection, where localization is done via bounding
boxes. However, for real-life applications that require physical interactions,
a bounding box insufficiently describes the geometry of an object. We therefore
tackle the problem of dense 3D visual grounding, i.e. referral-based 3D
instance segmentation. We propose a dense 3D grounding network ConcreteNet,
featuring three novel stand-alone modules which aim to improve grounding
performance for challenging repetitive instances, i.e. instances with
distractors of the same semantic class. First, we introduce a bottom-up
attentive fusion module that aims to disambiguate inter-instance relational
cues, next we construct a contrastive training scheme to induce separation in
the latent space, and finally we resolve view-dependent utterances via a
learned global camera token. ConcreteNet ranks 1st on the challenging ScanRefer
online benchmark by a considerable +9.43% accuracy at 50% IoU and has won the
ICCV 3rd Workshop on Language for 3D Scenes "3D Object Localization" challenge.
</p>
</div>
</dd>
<dt><a name="item26">[26]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.04564" title="Abstract">arXiv:2309.04564</a> [<a href="/pdf/2309.04564" title="Download PDF">pdf</a>, <a href="/format/2309.04564" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> When Less is More: Investigating Data Pruning for Pretraining LLMs at  Scale
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Marion%2C+M">Max Marion</a>, 
<a href="/search/cs?searchtype=author&query=%C3%9Cst%C3%BCn%2C+A">Ahmet &#xdc;st&#xfc;n</a>, 
<a href="/search/cs?searchtype=author&query=Pozzobon%2C+L">Luiza Pozzobon</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+A">Alex Wang</a>, 
<a href="/search/cs?searchtype=author&query=Fadaee%2C+M">Marzieh Fadaee</a>, 
<a href="/search/cs?searchtype=author&query=Hooker%2C+S">Sara Hooker</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages, 8 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Large volumes of text data have contributed significantly to the development
of large language models (LLMs) in recent years. This data is typically
acquired by scraping the internet, leading to pretraining datasets comprised of
noisy web text. To date, efforts to prune these datasets down to a higher
quality subset have relied on hand-crafted heuristics encoded as rule-based
filters. In this work, we take a wider view and explore scalable estimates of
data quality that can be used to systematically measure the quality of
pretraining data. We perform a rigorous comparison at scale of the simple data
quality estimator of perplexity, as well as more sophisticated and
computationally intensive estimates of the Error L2-Norm and memorization.
These metrics are used to rank and prune pretraining corpora, and we
subsequently compare LLMs trained on these pruned datasets. Surprisingly, we
find that the simple technique of perplexity outperforms our more
computationally expensive scoring methods. We improve over our no-pruning
baseline while training on as little as 30% of the original training dataset.
Our work sets the foundation for unexplored strategies in automatically
curating high quality corpora and suggests the majority of pretraining data can
be removed while retaining performance.
</p>
</div>
</dd>
<dt><a name="item27">[27]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.04565" title="Abstract">arXiv:2309.04565</a> [<a href="/pdf/2309.04565" title="Download PDF">pdf</a>, <a href="/format/2309.04565" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Unleashing the Power of Graph Learning through LLM-based Autonomous  Agents
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wei%2C+L">Lanning Wei</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+Z">Zhiqiang He</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+H">Huan Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Yao%2C+Q">Quanming Yao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Graph structured data are widely existed and applied in the real-world
applications, while it is a challenge to handling these diverse data and
learning tasks on graph in an efficient manner. When facing the complicated
graph learning tasks, experts have designed diverse Graph Neural Networks
(GNNs) in recent years. They have also implemented AutoML in Graph, also known
as AutoGraph, to automatically generate data-specific solutions. Despite their
success, they encounter limitations in (1) managing diverse learning tasks at
various levels, (2) dealing with different procedures in graph learning beyond
architecture design, and (3) the huge requirements on the prior knowledge when
using AutoGraph. In this paper, we propose to use Large Language Models (LLMs)
as autonomous agents to simplify the learning process on diverse real-world
graphs. Specifically, in response to a user request which may contain varying
data and learning targets at the node, edge, or graph levels, the complex graph
learning task is decomposed into three components following the agent planning,
namely, detecting the learning intent, configuring solutions based on
AutoGraph, and generating a response. The AutoGraph agents manage crucial
procedures in automated graph learning, including data-processing, AutoML
configuration, searching architectures, and hyper-parameter fine-tuning. With
these agents, those components are processed by decomposing and completing step
by step, thereby generating a solution for the given data automatically,
regardless of the learning task on node or graph. The proposed method is dubbed
Auto$^2$Graph, and the comparable performance on different datasets and
learning tasks. Its effectiveness is demonstrated by its comparable performance
on different datasets and learning tasks, as well as the human-like decisions
made by the agents.
</p>
</div>
</dd>
<dt><a name="item28">[28]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.04566" title="Abstract">arXiv:2309.04566</a> [<a href="/pdf/2309.04566" title="Download PDF">pdf</a>, <a href="/format/2309.04566" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> STAR-RIS-Assisted-Full-Duplex Jamming Design for Secure Wireless  Communications System
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wen%2C+Y">Yun Wen</a> (1), 
<a href="/search/cs?searchtype=author&query=Chen%2C+G">Gaojie Chen</a> (1), 
<a href="/search/cs?searchtype=author&query=Fang%2C+S">Sisai Fang</a> (2), 
<a href="/search/cs?searchtype=author&query=Chu%2C+Z">Zheng Chu</a> (1), 
<a href="/search/cs?searchtype=author&query=Xiao%2C+P">Pei Xiao</a> (1), 
<a href="/search/cs?searchtype=author&query=Tafazolli%2C+R">Rahim Tafazolli</a> (1) ((1) Institute for Communication Systems (ICS), 5GIC &amp; 6GIC, University of Surrey (2) School of Engineering, University of Leicester)
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 7 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Cryptography and Security (cs.CR)

</div>
<p class="mathjax">Physical layer security (PLS) technologies are expected to play an important
role in the next-generation wireless networks, by providing secure
communication to protect critical and sensitive information from illegitimate
devices. In this paper, we propose a novel secure communication scheme where
the legitimate receiver use full-duplex (FD) technology to transmit jamming
signals with the assistance of simultaneous transmitting and reflecting
reconfigurable intelligent surface (STARRIS) which can operate under the energy
splitting (ES) model and the mode switching (MS) model, to interfere with the
undesired reception by the eavesdropper. We aim to maximize the secrecy
capacity by jointly optimizing the FD beamforming vectors, amplitudes and phase
shift coefficients for the ESRIS, and mode selection and phase shift
coefficients for the MS-RIS. With above optimization, the proposed scheme can
concentrate the jamming signals on the eavesdropper while simultaneously
eliminating the self-interference (SI) in the desired receiver. To tackle the
coupling effect of multiple variables, we propose an alternating optimization
algorithm to solve the problem iteratively. Furthermore, we handle the
non-convexity of the problem by the the successive convex approximation (SCA)
scheme for the beamforming optimizations, amplitudes and phase shifts
optimizations for the ES-RIS, as well as the phase shifts optimizations for the
MS-RIS. In addition, we adopt a semi-definite relaxation (SDR) and Gaussian
randomization process to overcome the difficulty introduced by the binary
nature of mode optimization of the MS-RIS. Simulation results validate the
performance of our proposed schemes as well as the efficacy of adapting both
two types of STAR-RISs in enhancing secure communications when compared to the
traditional selfinterference cancellation technology.
</p>
</div>
</dd>
<dt><a name="item29">[29]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.04568" title="Abstract">arXiv:2309.04568</a> [<a href="/pdf/2309.04568" title="Download PDF">pdf</a>, <a href="/format/2309.04568" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Circular economy meets building automation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Cai%2C+H">Hanmin Cai</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">This paper demonstrates the concept of reusing discarded smartphones to
connect the end-of-life of e-wastes with the start-of-life of smart buildings.
Two control-related and one communication-related case studies have been
conducted experimentally to evaluate applicability. Diverse controlled systems,
control tasks, and algorithms have been considered. In addition, the
sufficiency of communication with external agents has been quantified. The
proof-of-concept experiments indicate technical feasibility and applicability
to typical tasks with satisfactory performance. As smartphones improve over
time, higher computing performance and lower communication latency can be
expected, enhancing the prospect of the proposed reuse concept.
</p>
</div>
</dd>
<dt><a name="item30">[30]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.04573" title="Abstract">arXiv:2309.04573</a> [<a href="/pdf/2309.04573" title="Download PDF">pdf</a>, <a href="/format/2309.04573" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Mask2Anomaly: Mask Transformer for Universal Open-set Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rai%2C+S+N">Shyam Nandan Rai</a>, 
<a href="/search/cs?searchtype=author&query=Cermelli%2C+F">Fabio Cermelli</a>, 
<a href="/search/cs?searchtype=author&query=Caputo%2C+B">Barbara Caputo</a>, 
<a href="/search/cs?searchtype=author&query=Masone%2C+C">Carlo Masone</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 pages. arXiv admin note: substantial text overlap with <a href="/abs/2307.13316">arXiv:2307.13316</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Segmenting unknown or anomalous object instances is a critical task in
autonomous driving applications, and it is approached traditionally as a
per-pixel classification problem. However, reasoning individually about each
pixel without considering their contextual semantics results in high
uncertainty around the objects' boundaries and numerous false positives. We
propose a paradigm change by shifting from a per-pixel classification to a mask
classification. Our mask-based method, Mask2Anomaly, demonstrates the
feasibility of integrating a mask-classification architecture to jointly
address anomaly segmentation, open-set semantic segmentation, and open-set
panoptic segmentation. Mask2Anomaly includes several technical novelties that
are designed to improve the detection of anomalies/unknown objects: i) a global
masked attention module to focus individually on the foreground and background
regions; ii) a mask contrastive learning that maximizes the margin between an
anomaly and known classes; iii) a mask refinement solution to reduce false
positives; and iv) a novel approach to mine unknown instances based on the
mask-architecture properties. By comprehensive qualitative and qualitative
evaluation, we show Mask2Anomaly achieves new state-of-the-art results across
the benchmarks of anomaly segmentation, open-set semantic segmentation, and
open-set panoptic segmentation.
</p>
</div>
</dd>
<dt><a name="item31">[31]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.04579" title="Abstract">arXiv:2309.04579</a> [<a href="/pdf/2309.04579" title="Download PDF">pdf</a>, <a href="/format/2309.04579" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> EGOFALLS: A visual-audio dataset and benchmark for fall detection using  egocentric cameras
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xueyi Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Falls are significant and often fatal for vulnerable populations such as the
elderly. Previous works have addressed the detection of falls by relying on
data capture by a single sensor, images or accelerometers. In this work, we
rely on multimodal descriptors extracted from videos captured by egocentric
cameras. Our proposed method includes a late decision fusion layer that builds
on top of the extracted descriptors. Furthermore, we collect a new dataset on
which we assess our proposed approach. We believe this is the first public
dataset of its kind. The dataset comprises 10,948 video samples by 14 subjects.
We conducted ablation experiments to assess the performance of individual
feature extractors, fusion of visual information, and fusion of both visual and
audio information. Moreover, we experimented with internal and external
cross-validation. Our results demonstrate that the fusion of audio and visual
information through late decision fusion improves detection performance, making
it a promising tool for fall prevention and mitigation.
</p>
</div>
</dd>
<dt><a name="item32">[32]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.04581" title="Abstract">arXiv:2309.04581</a> [<a href="/pdf/2309.04581" title="Download PDF">pdf</a>, <a href="/format/2309.04581" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Dynamic Mesh-Aware Radiance Fields
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Qiao%2C+Y">Yi-Ling Qiao</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+A">Alexander Gao</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+Y">Yiran Xu</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+Y">Yue Feng</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+J">Jia-Bin Huang</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+M+C">Ming C. Lin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ICCV 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Graphics (cs.GR)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
<p class="mathjax">Embedding polygonal mesh assets within photorealistic Neural Radience Fields
(NeRF) volumes, such that they can be rendered and their dynamics simulated in
a physically consistent manner with the NeRF, is under-explored from the system
perspective of integrating NeRF into the traditional graphics pipeline. This
paper designs a two-way coupling between mesh and NeRF during rendering and
simulation. We first review the light transport equations for both mesh and
NeRF, then distill them into an efficient algorithm for updating radiance and
throughput along a cast ray with an arbitrary number of bounces. To resolve the
discrepancy between the linear color space that the path tracer assumes and the
sRGB color space that standard NeRF uses, we train NeRF with High Dynamic Range
(HDR) images. We also present a strategy to estimate light sources and cast
shadows on the NeRF. Finally, we consider how the hybrid surface-volumetric
formulation can be efficiently integrated with a high-performance physics
simulator that supports cloth, rigid and soft bodies. The full rendering and
simulation system can be run on a GPU at interactive rates. We show that a
hybrid system approach outperforms alternatives in visual realism for mesh
insertion, because it allows realistic light transport from volumetric NeRF
media onto surfaces, which affects the appearance of reflective/refractive
surfaces and illumination of diffuse surfaces informed by the dynamic scene.
</p>
</div>
</dd>
<dt><a name="item33">[33]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.04583" title="Abstract">arXiv:2309.04583</a> [<a href="/pdf/2309.04583" title="Download PDF">pdf</a>, <a href="/format/2309.04583" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Adaptive REST API Testing with Reinforcement Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kim%2C+M">Myeongsoo Kim</a>, 
<a href="/search/cs?searchtype=author&query=Sinha%2C+S">Saurabh Sinha</a>, 
<a href="/search/cs?searchtype=author&query=Orso%2C+A">Alessandro Orso</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To be published in the 38th IEEE/ACM International Conference on Automated Software Engineering (ASE 2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
<p class="mathjax">Modern web services increasingly rely on REST APIs. Effectively testing these
APIs is challenging due to the vast search space to be explored, which involves
selecting API operations for sequence creation, choosing parameters for each
operation from a potentially large set of parameters, and sampling values from
the virtually infinite parameter input space. Current testing tools lack
efficient exploration mechanisms, treating all operations and parameters
equally (i.e., not considering their importance or complexity) and lacking
prioritization strategies. Furthermore, these tools struggle when response
schemas are absent in the specification or exhibit variants. To address these
limitations, we present an adaptive REST API testing technique that
incorporates reinforcement learning to prioritize operations and parameters
during exploration. Our approach dynamically analyzes request and response data
to inform dependent parameters and adopts a sampling-based strategy for
efficient processing of dynamic API feedback. We evaluated our technique on ten
RESTful services, comparing it against state-of-the-art REST testing tools with
respect to code coverage achieved, requests generated, operations covered, and
service failures triggered. Additionally, we performed an ablation study on
prioritization, dynamic feedback analysis, and sampling to assess their
individual effects. Our findings demonstrate that our approach outperforms
existing REST API testing tools in terms of effectiveness, efficiency, and
fault-finding ability.
</p>
</div>
</dd>
<dt><a name="item34">[34]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.04586" title="Abstract">arXiv:2309.04586</a> [<a href="/pdf/2309.04586" title="Download PDF">pdf</a>, <a href="/ps/2309.04586" title="Download PostScript">ps</a>, <a href="/format/2309.04586" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On Interactive Coding Schemes with Adaptive Termination
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gupta%2C+M">Meghal Gupta</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+R+Y">Rachel Yun Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>; Information Theory (cs.IT)

</div>
<p class="mathjax">In interactive coding, Alice and Bob wish to compute some function $f$ of
their individual private inputs $x$ and $y$. They do this by engaging in an
interactive protocol to jointly compute $f(x,y)$. The goal is to do this in an
error-resilient way, such that even given some fraction of adversarial
corruptions to the protocol, both parties still learn $f(x,y)$.
<br />Typically, the error resilient protocols constructed by interactive coding
schemes are \emph{non-adaptive}, that is, the length of the protocol as well as
the speaker in each round is fixed beforehand. The maximal error resilience
obtainable by non-adaptive schemes is now well understood. In order to
circumvent known barriers and achieve higher error resilience, the work of
Agrawal, Gelles, and Sahai (ISIT 2016) introduced to interactive coding the
notion of \emph{adaptive} schemes, where the length of the protocol or the
speaker order are no longer necessarily fixed.
<br />In this paper, we study the power of \emph{adaptive termination} in the
context of the error resilience of interactive coding schemes. In other words,
what is the power of schemes where Alice and Bob are allowed to disengage from
the protocol early? We study this question in two contexts, both for the task
of \emph{message exchange}, where the goal is to learn the other party's input.
</p>
</div>
</dd>
<dt><a name="item35">[35]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.04588" title="Abstract">arXiv:2309.04588</a> [<a href="/pdf/2309.04588" title="Download PDF">pdf</a>, <a href="/format/2309.04588" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Distributed Optimization via Gradient Descent with Event-Triggered  Zooming over Quantized Communication
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Rikos%2C+A+I">Apostolos I. Rikos</a>, 
<a href="/search/eess?searchtype=author&query=Jiang%2C+W">Wei Jiang</a>, 
<a href="/search/eess?searchtype=author&query=Charalambous%2C+T">Themistoklis Charalambous</a>, 
<a href="/search/eess?searchtype=author&query=Johansson%2C+K+H">Karl H. Johansson</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Optimization and Control (math.OC)

</div>
<p class="mathjax">In this paper, we study unconstrained distributed optimization strongly
convex problems, in which the exchange of information in the network is
captured by a directed graph topology over digital channels that have limited
capacity (and hence information should be quantized). Distributed methods in
which nodes use quantized communication yield a solution at the proximity of
the optimal solution, hence reaching an error floor that depends on the
quantization level used; the finer the quantization the lower the error floor.
However, it is not possible to determine in advance the optimal quantization
level that ensures specific performance guarantees (such as achieving an error
floor below a predefined threshold). Choosing a very small quantization level
that would guarantee the desired performance, requires {information} packets of
very large size, which is not desirable (could increase the probability of
packet losses, increase delays, etc) and often not feasible due to the limited
capacity of the channels available. In order to obtain a
communication-efficient distributed solution and a sufficiently close proximity
to the optimal solution, we propose a quantized distributed optimization
algorithm that converges in a finite number of steps and is able to adjust the
quantization level accordingly. The proposed solution uses a finite-time
distributed optimization protocol to find a solution to the problem for a given
quantization level in a finite number of steps and keeps refining the
quantization level until the difference in the solution between two successive
solutions with different quantization levels is below a certain pre-specified
threshold.
</p>
</div>
</dd>
<dt><a name="item36">[36]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.04589" title="Abstract">arXiv:2309.04589</a> [<a href="/pdf/2309.04589" title="Download PDF">pdf</a>, <a href="/format/2309.04589" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Motif-aware Attribute Masking for Molecular Graph Pre-training
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Inae%2C+E">Eric Inae</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+G">Gang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+M">Meng Jiang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Quantitative Methods (q-bio.QM)

</div>
<p class="mathjax">Attribute reconstruction is used to predict node or edge features in the
pre-training of graph neural networks. Given a large number of molecules, they
learn to capture structural knowledge, which is transferable for various
downstream property prediction tasks and vital in chemistry, biomedicine, and
material science. Previous strategies that randomly select nodes to do
attribute masking leverage the information of local neighbors However, the
over-reliance of these neighbors inhibits the model's ability to learn from
higher-level substructures. For example, the model would learn little from
predicting three carbon atoms in a benzene ring based on the other three but
could learn more from the inter-connections between the functional groups, or
called chemical motifs. In this work, we propose and investigate motif-aware
attribute masking strategies to capture inter-motif structures by leveraging
the information of atoms in neighboring motifs. Once each graph is decomposed
into disjoint motifs, the features for every node within a sample motif are
masked. The graph decoder then predicts the masked features of each node within
the motif for reconstruction. We evaluate our approach on eight molecular
property prediction datasets and demonstrate its advantages.
</p>
</div>
</dd>
<dt><a name="item37">[37]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.04590" title="Abstract">arXiv:2309.04590</a> [<a href="/pdf/2309.04590" title="Download PDF">pdf</a>, <a href="/format/2309.04590" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Robotic Defect Inspection with Visual and Tactile Perception for  Large-scale Components
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Agarwal%2C+A">Arpit Agarwal</a>, 
<a href="/search/cs?searchtype=author&query=Ajith%2C+A">Abhiroop Ajith</a>, 
<a href="/search/cs?searchtype=author&query=Wen%2C+C">Chengtao Wen</a>, 
<a href="/search/cs?searchtype=author&query=Stryzheus%2C+V">Veniamin Stryzheus</a>, 
<a href="/search/cs?searchtype=author&query=Miller%2C+B">Brian Miller</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+M">Matthew Chen</a>, 
<a href="/search/cs?searchtype=author&query=Johnson%2C+M+K">Micah K. Johnson</a>, 
<a href="/search/cs?searchtype=author&query=Rincon%2C+J+L+S">Jose Luis Susa Rincon</a>, 
<a href="/search/cs?searchtype=author&query=Rosca%2C+J">Justinian Rosca</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+W">Wenzhen Yuan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This is a pre-print for International Conference on Intelligent Robots and Systems 2023 publication
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Systems and Control (eess.SY)

</div>
<p class="mathjax">In manufacturing processes, surface inspection is a key requirement for
quality assessment and damage localization. Due to this, automated surface
anomaly detection has become a promising area of research in various industrial
inspection systems. A particular challenge in industries with large-scale
components, like aircraft and heavy machinery, is inspecting large parts with
very small defect dimensions. Moreover, these parts can be of curved shapes. To
address this challenge, we present a 2-stage multi-modal inspection pipeline
with visual and tactile sensing. Our approach combines the best of both visual
and tactile sensing by identifying and localizing defects using a global view
(vision) and using the localized area for tactile scanning for identifying
remaining defects. To benchmark our approach, we propose a novel real-world
dataset with multiple metallic defect types per image, collected in the
production environments on real aerospace manufacturing parts, as well as
online robot experiments in two environments. Our approach is able to identify
85% defects using Stage I and identify 100% defects after Stage II. The dataset
is publicly available at https://zenodo.org/record/8327713
</p>
</div>
</dd>
<dt><a name="item38">[38]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.04596" title="Abstract">arXiv:2309.04596</a> [<a href="/pdf/2309.04596" title="Download PDF">pdf</a>, <a href="/format/2309.04596" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning Task Skills and Goals Simultaneously from Physical Interaction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+H">Haonan Chen</a>, 
<a href="/search/cs?searchtype=author&query=Mun%2C+Y">Ye-Ji Mun</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+Z">Zhe Huang</a>, 
<a href="/search/cs?searchtype=author&query=Niu%2C+Y">Yilong Niu</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+Y">Yiqing Xie</a>, 
<a href="/search/cs?searchtype=author&query=McPherson%2C+D+L">D. Livingston McPherson</a>, 
<a href="/search/cs?searchtype=author&query=Driggs-Campbell%2C+K">Katherine Driggs-Campbell</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 2 pages, 1 figure. Accepted by CASE 2023 Special Session on The Next-Generation Resilient Cyber-Physical Manufacturing Networks
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">In real-world human-robot systems, it is essential for a robot to comprehend
human objectives and respond accordingly while performing an extended series of
motor actions. Although human objective alignment has recently emerged as a
promising paradigm in the realm of physical human-robot interaction, its
application is typically confined to generating simple motions due to inherent
theoretical limitations. In this work, our goal is to develop a general
formulation to learn manipulation functional modules and long-term task goals
simultaneously from physical human-robot interaction. We show the feasibility
of our framework in enabling robots to align their behaviors with the long-term
task objectives inferred from human interactions.
</p>
</div>
</dd>
<dt><a name="item39">[39]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.04605" title="Abstract">arXiv:2309.04605</a> [<a href="/pdf/2309.04605" title="Download PDF">pdf</a>, <a href="/format/2309.04605" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Evaluating Total Environmental Impact for a Computing Infrastructure
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jackson%2C+A">Adrian Jackson</a> (1), 
<a href="/search/cs?searchtype=author&query=Hays%2C+J">Jon Hays</a> (2), 
<a href="/search/cs?searchtype=author&query=Owen%2C+A">Alex Owen</a> (2), 
<a href="/search/cs?searchtype=author&query=Walton%2C+N">Nicholas Walton</a> (3), 
<a href="/search/cs?searchtype=author&query=Packer%2C+A">Alison Packer</a> (4), 
<a href="/search/cs?searchtype=author&query=Mudaraddi%2C+A">Anish Mudaraddi</a> (4) ((1) EPCC, The University of Edinburgh (2) School of Physical and Chemical Sciences, Queen Mary University of London (3) Institute of Astronomy, University of Cambridge, (4) Scientific Computing, STFC, Rutherford Appleton Laboratory)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>; Computers and Society (cs.CY)

</div>
<p class="mathjax">In this paper we outline the results of a project to evaluate the total
climate/carbon impact of a digital research infrastructure for a defined
snapshot period. We outline the carbon model used to calculate the impact and
the data collected to quantify that impact for a defined set of resources. We
discuss the variation in potential impact across both the active and embodied
carbon for computing hardware and produce a range of estimates on the amount of
carbon equivalent climate impact for the snapshot period.
</p>
</div>
</dd>
<dt><a name="item40">[40]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.04607" title="Abstract">arXiv:2309.04607</a> [<a href="/pdf/2309.04607" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Linking Symptom Inventories using Semantic Textual Similarity
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kennedy%2C+E">Eamonn Kennedy</a>, 
<a href="/search/cs?searchtype=author&query=Vadlamani%2C+S">Shashank Vadlamani</a>, 
<a href="/search/cs?searchtype=author&query=Lindsey%2C+H+M">Hannah M Lindsey</a>, 
<a href="/search/cs?searchtype=author&query=Peterson%2C+K+S">Kelly S Peterson</a>, 
<a href="/search/cs?searchtype=author&query=OConnor%2C+K+D">Kristen Dams OConnor</a>, 
<a href="/search/cs?searchtype=author&query=Murray%2C+K">Kenton Murray</a>, 
<a href="/search/cs?searchtype=author&query=Agarwal%2C+R">Ronak Agarwal</a>, 
<a href="/search/cs?searchtype=author&query=Amiri%2C+H+H">Houshang H Amiri</a>, 
<a href="/search/cs?searchtype=author&query=Andersen%2C+R+K">Raeda K Andersen</a>, 
<a href="/search/cs?searchtype=author&query=Babikian%2C+T">Talin Babikian</a>, 
<a href="/search/cs?searchtype=author&query=Baron%2C+D+A">David A Baron</a>, 
<a href="/search/cs?searchtype=author&query=Bigler%2C+E+D">Erin D Bigler</a>, 
<a href="/search/cs?searchtype=author&query=Caeyenberghs%2C+K">Karen Caeyenberghs</a>, 
<a href="/search/cs?searchtype=author&query=Delano-Wood%2C+L">Lisa Delano-Wood</a>, 
<a href="/search/cs?searchtype=author&query=Disner%2C+S+G">Seth G Disner</a>, 
<a href="/search/cs?searchtype=author&query=Dobryakova%2C+E">Ekaterina Dobryakova</a>, 
<a href="/search/cs?searchtype=author&query=Eapen%2C+B+C">Blessen C Eapen</a>, 
<a href="/search/cs?searchtype=author&query=Edelstein%2C+R+M">Rachel M Edelstein</a>, 
<a href="/search/cs?searchtype=author&query=Esopenko%2C+C">Carrie Esopenko</a>, 
<a href="/search/cs?searchtype=author&query=Genova%2C+H+M">Helen M Genova</a>, 
<a href="/search/cs?searchtype=author&query=Geuze%2C+E">Elbert Geuze</a>, 
<a href="/search/cs?searchtype=author&query=Goodrich-Hunsaker%2C+N+J">Naomi J Goodrich-Hunsaker</a>, 
<a href="/search/cs?searchtype=author&query=Grafman%2C+J">Jordan Grafman</a>, 
<a href="/search/cs?searchtype=author&query=Haberg%2C+A+K">Asta K Haberg</a>, 
<a href="/search/cs?searchtype=author&query=Hodges%2C+C+B">Cooper B Hodges</a>, 
<a href="/search/cs?searchtype=author&query=Hoskinson%2C+K+R">Kristen R Hoskinson</a>, 
<a href="/search/cs?searchtype=author&query=Hovenden%2C+E+S">Elizabeth S Hovenden</a>, 
<a href="/search/cs?searchtype=author&query=Irimia%2C+A">Andrei Irimia</a>, 
<a href="/search/cs?searchtype=author&query=Jahanshad%2C+N">Neda Jahanshad</a>, 
<a href="/search/cs?searchtype=author&query=Jha%2C+R+M">Ruchira M Jha</a>, 
<a href="/search/cs?searchtype=author&query=Keleher%2C+F">Finian Keleher</a>, 
<a href="/search/cs?searchtype=author&query=Kenney%2C+K">Kimbra Kenney</a>, 
<a href="/search/cs?searchtype=author&query=Koerte%2C+I+K">Inga K Koerte</a>, 
<a href="/search/cs?searchtype=author&query=Liebel%2C+S+W">Spencer W Liebel</a>, 
<a href="/search/cs?searchtype=author&query=Livny%2C+A">Abigail Livny</a>, 
<a href="/search/cs?searchtype=author&query=Lovstad%2C+M">Marianne Lovstad</a>, 
<a href="/search/cs?searchtype=author&query=Martindale%2C+S+L">Sarah L Martindale</a>, 
<a href="/search/cs?searchtype=author&query=Max%2C+J+E">Jeffrey E Max</a>, 
<a href="/search/cs?searchtype=author&query=Mayer%2C+A+R">Andrew R Mayer</a>, 
<a href="/search/cs?searchtype=author&query=Meier%2C+T+B">Timothy B Meier</a>, 
<a href="/search/cs?searchtype=author&query=Menefee%2C+D+S">Deleene S Menefee</a>, 
<a href="/search/cs?searchtype=author&query=Mohamed%2C+A+Z">Abdalla Z Mohamed</a>, 
<a href="/search/cs?searchtype=author&query=Mondello%2C+S">Stefania Mondello</a>, 
<a href="/search/cs?searchtype=author&query=Monti%2C+M+M">Martin M Monti</a>, 
<a href="/search/cs?searchtype=author&query=Morey%2C+R+A">Rajendra A Morey</a>, 
<a href="/search/cs?searchtype=author&query=Newcombe%2C+V">Virginia Newcombe</a>,  et al. (36 additional authors not shown)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">An extensive library of symptom inventories has been developed over time to
measure clinical symptoms, but this variety has led to several long standing
issues. Most notably, results drawn from different settings and studies are not
comparable, which limits reproducibility. Here, we present an artificial
intelligence (AI) approach using semantic textual similarity (STS) to link
symptoms and scores across previously incongruous symptom inventories. We
tested the ability of four pre-trained STS models to screen thousands of
symptom description pairs for related content - a challenging task typically
requiring expert panels. Models were tasked to predict symptom severity across
four different inventories for 6,607 participants drawn from 16 international
data sources. The STS approach achieved 74.8% accuracy across five tasks,
outperforming other models tested. This work suggests that incorporating
contextual, semantic information can assist expert decision-making processes,
yielding gains for both general and disease-specific clinical assessment.
</p>
</div>
</dd>
<dt><a name="item41">[41]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.04608" title="Abstract">arXiv:2309.04608</a> [<a href="/pdf/2309.04608" title="Download PDF">pdf</a>, <a href="/format/2309.04608" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Style Generation: Image Synthesis based on Coarsely Matched Texts
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cui%2C+M">Mengyao Cui</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+Z">Zhe Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+S">Shao-Ping Lu</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yulu Yang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Multimedia (cs.MM)

</div>
<p class="mathjax">Previous text-to-image synthesis algorithms typically use explicit textual
instructions to generate/manipulate images accurately, but they have difficulty
adapting to guidance in the form of coarsely matched texts. In this work, we
attempt to stylize an input image using such coarsely matched text as guidance.
To tackle this new problem, we introduce a novel task called text-based style
generation and propose a two-stage generative adversarial network: the first
stage generates the overall image style with a sentence feature, and the second
stage refines the generated style with a synthetic feature, which is produced
by a multi-modality style synthesis module. We re-filter one existing dataset
and collect a new dataset for the task. Extensive experiments and ablation
studies are conducted to validate our framework. The practical potential of our
work is demonstrated by various applications such as text-image alignment and
story visualization. Our datasets are published at
https://www.kaggle.com/datasets/mengyaocui/style-generation.
</p>
</div>
</dd>
<dt><a name="item42">[42]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.04612" title="Abstract">arXiv:2309.04612</a> [<a href="/pdf/2309.04612" title="Download PDF">pdf</a>, <a href="/format/2309.04612" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Self-optimizing Feature Generation via Categorical Hashing  Representation and Hierarchical Reinforcement Crossing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ying%2C+W">Wangyang Ying</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+D">Dongjie Wang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+K">Kunpeng Liu</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+L">Leilei Sun</a>, 
<a href="/search/cs?searchtype=author&query=Fu%2C+Y">Yanjie Fu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Feature generation aims to generate new and meaningful features to create a
discriminative representation space.A generated feature is meaningful when the
generated feature is from a feature pair with inherent feature interaction. In
the real world, experienced data scientists can identify potentially useful
feature-feature interactions, and generate meaningful dimensions from an
exponentially large search space, in an optimal crossing form over an optimal
generation path. But, machines have limited human-like abilities.We generalize
such learning tasks as self-optimizing feature generation. Self-optimizing
feature generation imposes several under-addressed challenges on existing
systems: meaningful, robust, and efficient generation. To tackle these
challenges, we propose a principled and generic representation-crossing
framework to solve self-optimizing feature generation.To achieve hashing
representation, we propose a three-step approach: feature discretization,
feature hashing, and descriptive summarization. To achieve reinforcement
crossing, we develop a hierarchical reinforcement feature crossing approach.We
present extensive experimental results to demonstrate the effectiveness and
efficiency of the proposed method. The code is available at
https://github.com/yingwangyang/HRC_feature_cross.git.
</p>
</div>
</dd>
<dt><a name="item43">[43]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.04615" title="Abstract">arXiv:2309.04615</a> [<a href="/pdf/2309.04615" title="Download PDF">pdf</a>, <a href="/format/2309.04615" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Leveraging World Model Disentanglement in Value-Based Multi-Agent  Reinforcement Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zhizun Wang</a>, 
<a href="/search/cs?searchtype=author&query=Meger%2C+D">David Meger</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Multiagent Systems (cs.MA)

</div>
<p class="mathjax">In this paper, we propose a novel model-based multi-agent reinforcement
learning approach named Value Decomposition Framework with Disentangled World
Model to address the challenge of achieving a common goal of multiple agents
interacting in the same environment with reduced sample complexity. Due to
scalability and non-stationarity problems posed by multi-agent systems,
model-free methods rely on a considerable number of samples for training. In
contrast, we use a modularized world model, composed of action-conditioned,
action-free, and static branches, to unravel the environment dynamics and
produce imagined outcomes based on past experience, without sampling directly
from the real environment. We employ variational auto-encoders and variational
graph auto-encoders to learn the latent representations for the world model,
which is merged with a value-based framework to predict the joint action-value
function and optimize the overall training objective. We present experimental
results in Easy, Hard, and Super-Hard StarCraft II micro-management challenges
to demonstrate that our method achieves high sample efficiency and exhibits
superior performance in defeating the enemy armies compared to other baselines.
</p>
</div>
</dd>
<dt><a name="item44">[44]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.04616" title="Abstract">arXiv:2309.04616</a> [<a href="/pdf/2309.04616" title="Download PDF">pdf</a>, <a href="/format/2309.04616" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Knowledge Distillation-Empowered Digital Twin for Anomaly Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+Q">Qinghua Xu</a>, 
<a href="/search/cs?searchtype=author&query=Ali%2C+S">Shaukat Ali</a>, 
<a href="/search/cs?searchtype=author&query=Yue%2C+T">Tao Yue</a>, 
<a href="/search/cs?searchtype=author&query=Nedim%2C+Z">Zaimovic Nedim</a>, 
<a href="/search/cs?searchtype=author&query=Singh%2C+I">Inderjeet Singh</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Software Engineering (cs.SE)

</div>
<p class="mathjax">Cyber-physical systems (CPSs), like train control and management systems
(TCMS), are becoming ubiquitous in critical infrastructures. As safety-critical
systems, ensuring their dependability during operation is crucial. Digital
twins (DTs) have been increasingly studied for this purpose owing to their
capability of runtime monitoring and warning, prediction and detection of
anomalies, etc. However, constructing a DT for anomaly detection in TCMS
necessitates sufficient training data and extracting both chronological and
context features with high quality. Hence, in this paper, we propose a novel
method named KDDT for TCMS anomaly detection. KDDT harnesses a language model
(LM) and a long short-term memory (LSTM) network to extract contexts and
chronological features, respectively. To enrich data volume, KDDT benefits from
out-of-domain data with knowledge distillation (KD). We evaluated KDDT with two
datasets from our industry partner Alstom and obtained the F1 scores of 0.931
and 0.915, respectively, demonstrating the effectiveness of KDDT. We also
explored individual contributions of the DT model, LM, and KD to the overall
performance of KDDT, via a comprehensive empirical study, and observed average
F1 score improvements of 12.4%, 3%, and 6.05%, respectively.
</p>
</div>
</dd>
<dt><a name="item45">[45]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.04618" title="Abstract">arXiv:2309.04618</a> [<a href="/pdf/2309.04618" title="Download PDF">pdf</a>, <a href="/format/2309.04618" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Simulation-driven engineering for the management of harmful algal and  cyanobacterial blooms
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Risco-Mart%C3%ADn%2C+J+L">Jos&#xe9; L. Risco-Mart&#xed;n</a>, 
<a href="/search/eess?searchtype=author&query=Esteban%2C+S">Segundo Esteban</a>, 
<a href="/search/eess?searchtype=author&query=Chac%C3%B3n%2C+J">Jes&#xfa;s Chac&#xf3;n</a>, 
<a href="/search/eess?searchtype=author&query=Carazo-Barbero%2C+G">Gonzalo Carazo-Barbero</a>, 
<a href="/search/eess?searchtype=author&query=Besada-Portas%2C+E">Eva Besada-Portas</a>, 
<a href="/search/eess?searchtype=author&query=L%C3%B3pez-Orozco%2C+J+A">Jos&#xe9; A. L&#xf3;pez-Orozco</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Simulation, 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">Harmful Algal and Cyanobacterial Blooms (HABs), occurring in inland and
maritime waters, pose threats to natural environments by producing toxins that
affect human and animal health. In the past, HABs have been assessed mainly by
the manual collection and subsequent analysis of water samples and occasionally
by automatic instruments that acquire information from fixed locations. These
procedures do not provide data with the desirable spatial and temporal
resolution to anticipate the formation of HABs. Hence, new tools and
technologies are needed to efficiently detect, characterize and respond to HABs
that threaten water quality. It is essential nowadays when the world's water
supply is under tremendous pressure because of climate change,
overexploitation, and pollution. This paper introduces DEVS-BLOOM, a novel
framework for real-time monitoring and management of HABs. Its purpose is to
support high-performance hazard detection with Model Based Systems Engineering
(MBSE) and Cyber-Physical Systems (CPS) infrastructure for dynamic
environments.
</p>
</div>
</dd>
<dt><a name="item46">[46]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.04624" title="Abstract">arXiv:2309.04624</a> [<a href="/pdf/2309.04624" title="Download PDF">pdf</a>, <a href="/ps/2309.04624" title="Download PostScript">ps</a>, <a href="/format/2309.04624" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Non-determinism in a linear logic type discipline: A concrete  categorical perspective
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=D%C3%ADaz-Caro%2C+A">Alejandro D&#xed;az-Caro</a>, 
<a href="/search/cs?searchtype=author&query=Malherbe%2C+O">Octavio Malherbe</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 18 pages plus appendix
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>

</div>
<p class="mathjax">We consider the linear lambda-calculus extended with the sup type
constructor, which provides an additive conjunction along with a
non-deterministic destructor. The sup type constructor has been introduced in
the context of quantum computing. In this paper, we study this type constructor
within a simple linear logic categorical model, employing the category of
semimodules over a commutative semiring. We demonstrate that the
non-deterministic destructor finds a suitable model in a "weighted" codiagonal
map. This approach offers a valid and insightful alternative to interpreting
non-determinism, especially in instances where the conventional Powerset Monad
interpretation does not align with the category's structure, as is the case
with the category of semimodules. The validity of this alternative relies on
the presence of biproducts within the category.
</p>
</div>
</dd>
<dt><a name="item47">[47]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.04635" title="Abstract">arXiv:2309.04635</a> [<a href="/pdf/2309.04635" title="Download PDF">pdf</a>, <a href="/format/2309.04635" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Can NLP Models &#x27;Identify&#x27;, &#x27;Distinguish&#x27;, and &#x27;Justify&#x27; Questions that  Don&#x27;t have a Definitive Answer?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Agarwal%2C+A">Ayushi Agarwal</a>, 
<a href="/search/cs?searchtype=author&query=Patel%2C+N">Nisarg Patel</a>, 
<a href="/search/cs?searchtype=author&query=Varshney%2C+N">Neeraj Varshney</a>, 
<a href="/search/cs?searchtype=author&query=Parmar%2C+M">Mihir Parmar</a>, 
<a href="/search/cs?searchtype=author&query=Mallina%2C+P">Pavan Mallina</a>, 
<a href="/search/cs?searchtype=author&query=Shah%2C+A+B">Aryan Bhavin Shah</a>, 
<a href="/search/cs?searchtype=author&query=Sangaraju%2C+S+R">Srihari Raju Sangaraju</a>, 
<a href="/search/cs?searchtype=author&query=Patel%2C+T">Tirth Patel</a>, 
<a href="/search/cs?searchtype=author&query=Thakkar%2C+N">Nihar Thakkar</a>, 
<a href="/search/cs?searchtype=author&query=Baral%2C+C">Chitta Baral</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> TrustNLP Workshop at ACL 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Though state-of-the-art (SOTA) NLP systems have achieved remarkable
performance on a variety of language understanding tasks, they primarily focus
on questions that have a correct and a definitive answer. However, in
real-world applications, users often ask questions that don't have a definitive
answer. Incorrectly answering such questions certainly hampers a system's
reliability and trustworthiness. Can SOTA models accurately identify such
questions and provide a reasonable response?
<br />To investigate the above question, we introduce QnotA, a dataset consisting
of five different categories of questions that don't have definitive answers.
Furthermore, for each QnotA instance, we also provide a corresponding QA
instance i.e. an alternate question that ''can be'' answered. With this data,
we formulate three evaluation tasks that test a system's ability to 'identify',
'distinguish', and 'justify' QnotA questions. Through comprehensive
experiments, we show that even SOTA models including GPT-3 and Flan T5 do not
fare well on these tasks and lack considerably behind the human performance
baseline. We conduct a thorough analysis which further leads to several
interesting findings. Overall, we believe our work and findings will encourage
and facilitate further research in this important area and help develop more
robust models.
</p>
</div>
</dd>
<dt><a name="item48">[48]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.04640" title="Abstract">arXiv:2309.04640</a> [<a href="/pdf/2309.04640" title="Download PDF">pdf</a>, <a href="/format/2309.04640" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Few-Shot Learning of Force-Based Motions From Demonstration Through  Pre-training of Haptic Representation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Aoyama%2C+M+Y">Marina Y. Aoyama</a>, 
<a href="/search/cs?searchtype=author&query=Moura%2C+J">Jo&#xe3;o Moura</a>, 
<a href="/search/cs?searchtype=author&query=Saito%2C+N">Namiko Saito</a>, 
<a href="/search/cs?searchtype=author&query=Vijayakumar%2C+S">Sethu Vijayakumar</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">In many contact-rich tasks, force sensing plays an essential role in adapting
the motion to the physical properties of the manipulated object. To enable
robots to capture the underlying distribution of object properties necessary
for generalising learnt manipulation tasks to unseen objects, existing Learning
from Demonstration (LfD) approaches require a large number of costly human
demonstrations. Our proposed semi-supervised LfD approach decouples the learnt
model into an haptic representation encoder and a motion generation decoder.
This enables us to pre-train the first using large amount of unsupervised data,
easily accessible, while using few-shot LfD to train the second, leveraging the
benefits of learning skills from humans. We validate the approach on the wiping
task using sponges with different stiffness and surface friction. Our results
demonstrate that pre-training significantly improves the ability of the LfD
model to recognise physical properties and generate desired wiping motions for
unseen sponges, outperforming the LfD method without pre-training. We validate
the motion generated by our semi-supervised LfD model on the physical robot
hardware using the KUKA iiwa robot arm. We also validate that the haptic
representation encoder, pre-trained in simulation, captures the properties of
real objects, explaining its contribution to improving the generalisation of
the downstream task.
</p>
</div>
</dd>
<dt><a name="item49">[49]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.04641" title="Abstract">arXiv:2309.04641</a> [<a href="/pdf/2309.04641" title="Download PDF">pdf</a>, <a href="/format/2309.04641" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exploring Domain-Specific Enhancements for a Neural Foley Synthesizer
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pillay%2C+A">Ashwin Pillay</a>, 
<a href="/search/cs?searchtype=author&query=Betko%2C+S">Sage Betko</a>, 
<a href="/search/cs?searchtype=author&query=Liloia%2C+A">Ari Liloia</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+H">Hao Chen</a>, 
<a href="/search/cs?searchtype=author&query=Shah%2C+A">Ankit Shah</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">Foley sound synthesis refers to the creation of authentic, diegetic sound
effects for media, such as film or radio. In this study, we construct a neural
Foley synthesizer capable of generating mono-audio clips across seven
predefined categories. Our approach introduces multiple enhancements to
existing models in the text-to-audio domain, with the goal of enriching the
diversity and acoustic characteristics of the generated foleys. Notably, we
utilize a pre-trained encoder that retains acoustical and musical attributes in
intermediate embeddings, implement class-conditioning to enhance
differentiability among foley classes in their intermediate representations,
and devise an innovative transformer-based architecture for optimizing
self-attention computations on very large inputs without compromising valuable
information. Subsequent to implementation, we present intermediate outcomes
that surpass the baseline, discuss practical challenges encountered in
achieving optimal results, and outline potential pathways for further research.
</p>
</div>
</dd>
<dt><a name="item50">[50]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.04642" title="Abstract">arXiv:2309.04642</a> [<a href="/pdf/2309.04642" title="Download PDF">pdf</a>, <a href="/ps/2309.04642" title="Download PostScript">ps</a>, <a href="/format/2309.04642" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Complexity of Verifying Boolean Programs as Differentially Private
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bun%2C+M">Mark Bun</a>, 
<a href="/search/cs?searchtype=author&query=Gaboardi%2C+M">Marco Gaboardi</a>, 
<a href="/search/cs?searchtype=author&query=Glinskih%2C+L">Ludmila Glinskih</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Appeared in CSF 2022
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Computational Complexity (cs.CC)

</div>
<p class="mathjax">We study the complexity of the problem of verifying differential privacy for
while-like programs working over boolean values and making probabilistic
choices. Programs in this class can be interpreted into finite-state
discrete-time Markov Chains (DTMC). We show that the problem of deciding
whether a program is differentially private for specific values of the privacy
parameters is PSPACE-complete. To show that this problem is in PSPACE, we adapt
classical results about computing hitting probabilities for DTMC. To show
PSPACE-hardness we use a reduction from the problem of checking whether a
program almost surely terminates or not. We also show that the problem of
approximating the privacy parameters that a program provides is PSPACE-hard.
Moreover, we investigate the complexity of similar problems also for several
relaxations of differential privacy: R\'enyi differential privacy, concentrated
differential privacy, and truncated concentrated differential privacy. For
these notions, we consider gap-versions of the problem of deciding whether a
program is private or not and we show that all of them are PSPACE-complete.
</p>
</div>
</dd>
<dt><a name="item51">[51]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.04643" title="Abstract">arXiv:2309.04643</a> [<a href="/pdf/2309.04643" title="Download PDF">pdf</a>, <a href="/ps/2309.04643" title="Download PostScript">ps</a>, <a href="/format/2309.04643" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Parallel Submodular Function Minimization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chakrabarty%2C+D">Deeparnab Chakrabarty</a>, 
<a href="/search/cs?searchtype=author&query=Graur%2C+A">Andrei Graur</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+H">Haotian Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Sidford%2C+A">Aaron Sidford</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>; Optimization and Control (math.OC)

</div>
<p class="mathjax">We consider the parallel complexity of submodular function minimization
(SFM). We provide a pair of methods which obtain two new query versus depth
trade-offs a submodular function defined on subsets of $n$ elements that has
integer values between $-M$ and $M$. The first method has depth $2$ and query
complexity $n^{O(M)}$ and the second method has depth $\widetilde{O}(n^{1/3}
M^{2/3})$ and query complexity $O(\mathrm{poly}(n, M))$. Despite a line of work
on improved parallel lower bounds for SFM, prior to our work the only known
algorithms for parallel SFM either followed from more general methods for
sequential SFM or highly-parallel minimization of convex $\ell_2$-Lipschitz
functions. Interestingly, to obtain our second result we provide the first
highly-parallel algorithm for minimizing $\ell_\infty$-Lipschitz function over
the hypercube which obtains near-optimal depth for obtaining constant accuracy.
</p>
</div>
</dd>
<dt><a name="item52">[52]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.04644" title="Abstract">arXiv:2309.04644</a> [<a href="/pdf/2309.04644" title="Download PDF">pdf</a>, <a href="/format/2309.04644" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Understanding Neural Collapse: The Effects of Batch  Normalization and Weight Decay
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pan%2C+L">Leyan Pan</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+X">Xinyuan Cao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Neural Collapse is a recently observed geometric structure that emerges in
the final layer of neural network classifiers. Specifically, Neural Collapse
states that at the terminal phase of neural networks training, 1) the
intra-class variability of last-layer features tends to zero, 2) the class
feature means form an Equiangular Tight Frame (ETF), 3) last-layer class
features and weights becomes equal up the scaling, and 4) classification
behavior collapses to the nearest class center (NCC) decision rule. This paper
investigates the effect of batch normalization and weight decay on the
emergence of Neural Collapse. We propose the geometrically intuitive
intra-class and inter-class cosine similarity measure which captures multiple
core aspects of Neural Collapse. With this measure, we provide theoretical
guarantees of Neural Collapse emergence with last-layer batch normalization and
weight decay when the regularized cross-entropy loss is near optimal. We also
perform further experiments to show that the Neural Collapse is most
significant in models with batch normalization and high weight-decay values.
Collectively, our results imply that batch normalization and weight decay may
be fundamental factors in the emergence of Neural Collapse.
</p>
</div>
</dd>
<dt><a name="item53">[53]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.04646" title="Abstract">arXiv:2309.04646</a> [<a href="/pdf/2309.04646" title="Download PDF">pdf</a>, <a href="/ps/2309.04646" title="Download PostScript">ps</a>, <a href="/format/2309.04646" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Efficient Finetuning Large Language Models For Vietnamese Chatbot
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Doan%2C+V">Vu-Thuan Doan</a>, 
<a href="/search/cs?searchtype=author&query=Truong%2C+Q">Quoc-Truong Truong</a>, 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+D">Duc-Vu Nguyen</a>, 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+V">Vinh-Tiep Nguyen</a>, 
<a href="/search/cs?searchtype=author&query=Luu%2C+T+N">Thuy-Ngan Nguyen Luu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: text overlap with <a href="/abs/2304.08177">arXiv:2304.08177</a>, <a href="/abs/2303.16199">arXiv:2303.16199</a> by other authors
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Large language models (LLMs), such as GPT-4, PaLM, and LLaMa, have been shown
to achieve remarkable performance across a variety of natural language tasks.
Recent advancements in instruction tuning bring LLMs with ability in following
user's instructions and producing human-like responses. However, the high costs
associated with training and implementing LLMs pose challenges to academic
research. Furthermore, the availability of pretrained LLMs and instruction-tune
datasets for Vietnamese language is limited. To tackle these concerns, we
leverage large-scale instruction-following datasets from open-source projects,
namely Alpaca, GPT4All, and Chat-Doctor, which cover general domain and
specific medical domain. To the best of our knowledge, these are the first
instructional dataset for Vietnamese. Subsequently, we utilize
parameter-efficient tuning through Low-Rank Adaptation (LoRA) on two open LLMs:
Bloomz (Multilingual) and GPTJ-6B (Vietnamese), resulting four models:
Bloomz-Chat, Bloomz-Doctor, GPTJ-Chat, GPTJ-Doctor.Finally, we assess the
effectiveness of our methodology on a per-sample basis, taking into
consideration the helpfulness, relevance, accuracy, level of detail in their
responses. This evaluation process entails the utilization of GPT-4 as an
automated scoring mechanism. Despite utilizing a low-cost setup, our method
demonstrates about 20-30\% improvement over the original models in our
evaluation tasks.
</p>
</div>
</dd>
<dt><a name="item54">[54]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.04650" title="Abstract">arXiv:2309.04650</a> [<a href="/pdf/2309.04650" title="Download PDF">pdf</a>, <a href="/format/2309.04650" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exploring Robust Features for Improving Adversarial Robustness
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Hong Wang</a>, 
<a href="/search/cs?searchtype=author&query=Deng%2C+Y">Yuefan Deng</a>, 
<a href="/search/cs?searchtype=author&query=Yoo%2C+S">Shinjae Yoo</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+Y">Yuewei Lin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 8 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">While deep neural networks (DNNs) have revolutionized many fields, their
fragility to carefully designed adversarial attacks impedes the usage of DNNs
in safety-critical applications. In this paper, we strive to explore the robust
features which are not affected by the adversarial perturbations, i.e.,
invariant to the clean image and its adversarial examples, to improve the
model's adversarial robustness. Specifically, we propose a feature
disentanglement model to segregate the robust features from non-robust features
and domain specific features. The extensive experiments on four widely used
datasets with different attacks demonstrate that robust features obtained from
our model improve the model's adversarial robustness compared to the
state-of-the-art approaches. Moreover, the trained domain discriminator is able
to identify the domain specific features from the clean images and adversarial
examples almost perfectly. This enables adversarial example detection without
incurring additional computational costs. With that, we can also specify
different classifiers for clean images and adversarial examples, thereby
avoiding any drop in clean image accuracy.
</p>
</div>
</dd>
<dt><a name="item55">[55]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.04652" title="Abstract">arXiv:2309.04652</a> [<a href="/pdf/2309.04652" title="Download PDF">pdf</a>, <a href="/format/2309.04652" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Further Study of Linux Kernel Hugepages on A64FX with FLASH, an  Astrophysical Simulation Code
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Feldman%2C+C">Catherine Feldman</a>, 
<a href="/search/cs?searchtype=author&query=Chheda%2C+S">Smeet Chheda</a>, 
<a href="/search/cs?searchtype=author&query=Calder%2C+A+C">Alan C. Calder</a>, 
<a href="/search/cs?searchtype=author&query=Siegmann%2C+E">Eva Siegmann</a>, 
<a href="/search/cs?searchtype=author&query=Dey%2C+J">John Dey</a>, 
<a href="/search/cs?searchtype=author&query=Curtis%2C+T">Tony Curtis</a>, 
<a href="/search/cs?searchtype=author&query=Harrison%2C+R+J">Robert J. Harrison</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 2 figures, 7 tables. Proceedings for Practice and Experience in Advanced Research Computing (PEARC '23), July 23--27, 2023, Portland, OR, USA
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>; Performance (cs.PF)

</div>
<p class="mathjax">We present an expanded study of the performance of FLASH when using Linux
Kernel Hugepages on Ookami, an HPE Apollo 80 A64FX platform. FLASH is a
multi-scale, multi-physics simulation code written principally in modern
Fortran and makes use of the PARAMESH library to manage a block-structured
adaptive mesh. Our initial study used only the Fujitsu compiler to utilize
standard hugepages (hp), but further investigation allowed us to utilize hp for
multiple compilers by linking to the Fujitsu library libmpg and transparent
hugepages (thp) by enabling it at the node level. By comparing the results of
hardware counters and in-code timers, we found that hp and thp do not
significantly impact the runtime performance of FLASH. Interestingly, there is
a significant reduction in the TLB misses, differences in cache and memory
access counters, and strange behavior is observed when using thp.
</p>
</div>
</dd>
<dt><a name="item56">[56]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.04654" title="Abstract">arXiv:2309.04654</a> [<a href="/pdf/2309.04654" title="Download PDF">pdf</a>, <a href="/format/2309.04654" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Mask-CTC-based Encoder Pre-training for Streaming End-to-End Speech  Recognition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhao%2C+H">Huaibo Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Higuchi%2C+Y">Yosuke Higuchi</a>, 
<a href="/search/cs?searchtype=author&query=Kida%2C+Y">Yusuke Kida</a>, 
<a href="/search/cs?searchtype=author&query=Ogawa%2C+T">Tetsuji Ogawa</a>, 
<a href="/search/cs?searchtype=author&query=Kobayashi%2C+T">Tetsunori Kobayashi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to EUSIPCO 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">Achieving high accuracy with low latency has always been a challenge in
streaming end-to-end automatic speech recognition (ASR) systems. By attending
to more future contexts, a streaming ASR model achieves higher accuracy but
results in larger latency, which hurts the streaming performance. In the
Mask-CTC framework, an encoder network is trained to learn the feature
representation that anticipates long-term contexts, which is desirable for
streaming ASR. Mask-CTC-based encoder pre-training has been shown beneficial in
achieving low latency and high accuracy for triggered attention-based ASR.
However, the effectiveness of this method has not been demonstrated for various
model architectures, nor has it been verified that the encoder has the expected
look-ahead capability to reduce latency. This study, therefore, examines the
effectiveness of Mask-CTCbased pre-training for models with different
architectures, such as Transformer-Transducer and contextual block streaming
ASR. We also discuss the effect of the proposed pre-training method on
obtaining accurate output spike timing.
</p>
</div>
</dd>
<dt><a name="item57">[57]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.04655" title="Abstract">arXiv:2309.04655</a> [<a href="/pdf/2309.04655" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Intelligent upper-limb exoskeleton using deep learning to predict human  intention for sensory-feedback augmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lee%2C+J">Jinwoo Lee</a>, 
<a href="/search/cs?searchtype=author&query=Kwon%2C+K">Kangkyu Kwon</a>, 
<a href="/search/cs?searchtype=author&query=Soltis%2C+I">Ira Soltis</a>, 
<a href="/search/cs?searchtype=author&query=Matthews%2C+J">Jared Matthews</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+Y">Yoonjae Lee</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+H">Hojoong Kim</a>, 
<a href="/search/cs?searchtype=author&query=Romero%2C+L">Lissette Romero</a>, 
<a href="/search/cs?searchtype=author&query=Zavanelli%2C+N">Nathan Zavanelli</a>, 
<a href="/search/cs?searchtype=author&query=Kwon%2C+Y">Youngjin Kwon</a>, 
<a href="/search/cs?searchtype=author&query=Kwon%2C+S">Shinjae Kwon</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+J">Jimin Lee</a>, 
<a href="/search/cs?searchtype=author&query=Na%2C+Y">Yewon Na</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+S+H">Sung Hoon Lee</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+K+J">Ki Jun Yu</a>, 
<a href="/search/cs?searchtype=author&query=Shinohara%2C+M">Minoru Shinohara</a>, 
<a href="/search/cs?searchtype=author&query=Hammond%2C+F+L">Frank L. Hammond</a>, 
<a href="/search/cs?searchtype=author&query=Yeo%2C+W">Woon-Hong Yeo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 15 pages, 6 figures, 1 table, Submitted for possible publication
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Machine Learning (cs.LG); Signal Processing (eess.SP); Systems and Control (eess.SY)

</div>
<p class="mathjax">The age and stroke-associated decline in musculoskeletal strength degrades
the ability to perform daily human tasks using the upper extremities. Although
there are a few examples of exoskeletons, they need manual operations due to
the absence of sensor feedback and no intention prediction of movements. Here,
we introduce an intelligent upper-limb exoskeleton system that uses cloud-based
deep learning to predict human intention for strength augmentation. The
embedded soft wearable sensors provide sensory feedback by collecting real-time
muscle signals, which are simultaneously computed to determine the user's
intended movement. The cloud-based deep-learning predicts four upper-limb joint
motions with an average accuracy of 96.2% at a 200-250 millisecond response
rate, suggesting that the exoskeleton operates just by human intention. In
addition, an array of soft pneumatics assists the intended movements by
providing 897 newton of force and 78.7 millimeter of displacement at maximum.
Collectively, the intent-driven exoskeleton can augment human strength by 5.15
times on average compared to the unassisted exoskeleton. This report
demonstrates an exoskeleton robot that augments the upper-limb joint movements
by human intention based on a machine-learning cloud computing and sensory
feedback.
</p>
</div>
</dd>
<dt><a name="item58">[58]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.04656" title="Abstract">arXiv:2309.04656</a> [<a href="/pdf/2309.04656" title="Download PDF">pdf</a>, <a href="/ps/2309.04656" title="Download PostScript">ps</a>, <a href="/format/2309.04656" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A constant factor approximation for Nash social welfare with subadditive  valuations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dobzinski%2C+S">Shahar Dobzinski</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+W">Wenzheng Li</a>, 
<a href="/search/cs?searchtype=author&query=Rubinstein%2C+A">Aviad Rubinstein</a>, 
<a href="/search/cs?searchtype=author&query=Vondrak%2C+J">Jan Vondrak</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>; Data Structures and Algorithms (cs.DS)

</div>
<p class="mathjax">We present a constant-factor approximation algorithm for the Nash social
welfare maximization problem with subadditive valuations accessible via demand
queries. More generally, we propose a template for NSW optimization by solving
a configuration-type LP and using a rounding procedure for (utilitarian) social
welfare as a blackbox, which could be applicable to other variants of the
problem.
</p>
</div>
</dd>
<dt><a name="item59">[59]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.04657" title="Abstract">arXiv:2309.04657</a> [<a href="/pdf/2309.04657" title="Download PDF">pdf</a>, <a href="/format/2309.04657" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Generation and Recombination for Multifocus Image Fusion with Free  Number of Inputs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Huafeng Li</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+D">Dan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+Y">Yuxin Huang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yafei Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+Z">Zhengtao Yu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Multifocus image fusion is an effective way to overcome the limitation of
optical lenses. Many existing methods obtain fused results by generating
decision maps. However, such methods often assume that the focused areas of the
two source images are complementary, making it impossible to achieve
simultaneous fusion of multiple images. Additionally, the existing methods
ignore the impact of hard pixels on fusion performance, limiting the visual
quality improvement of fusion image. To address these issues, a combining
generation and recombination model, termed as GRFusion, is proposed. In
GRFusion, focus property detection of each source image can be implemented
independently, enabling simultaneous fusion of multiple source images and
avoiding information loss caused by alternating fusion. This makes GRFusion
free from the number of inputs. To distinguish the hard pixels from the source
images, we achieve the determination of hard pixels by considering the
inconsistency among the detection results of focus areas in source images.
Furthermore, a multi-directional gradient embedding method for generating full
focus images is proposed. Subsequently, a hard-pixel-guided recombination
mechanism for constructing fused result is devised, effectively integrating the
complementary advantages of feature reconstruction-based method and focused
pixel recombination-based method. Extensive experimental results demonstrate
the effectiveness and the superiority of the proposed method.The source code
will be released on https://github.com/xxx/xxx.
</p>
</div>
</dd>
<dt><a name="item60">[60]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.04658" title="Abstract">arXiv:2309.04658</a> [<a href="/pdf/2309.04658" title="Download PDF">pdf</a>, <a href="/format/2309.04658" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exploring Large Language Models for Communication Games: An Empirical  Study on Werewolf
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+Y">Yuzhuang Xu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Shuo Wang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+P">Peng Li</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+F">Fuwen Luo</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xiaolong Wang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+W">Weidong Liu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yang Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 23 pages, 5 figures and 4 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Communication games, which we refer to as incomplete information games that
heavily depend on natural language communication, hold significant research
value in fields such as economics, social science, and artificial intelligence.
In this work, we explore the problem of how to engage large language models
(LLMs) in communication games, and in response, propose a tuning-free
framework. Our approach keeps LLMs frozen, and relies on the retrieval and
reflection on past communications and experiences for improvement. An empirical
study on the representative and widely-studied communication game,
``Werewolf'', demonstrates that our framework can effectively play Werewolf
game without tuning the parameters of the LLMs. More importantly, strategic
behaviors begin to emerge in our experiments, suggesting that it will be a
fruitful journey to engage LLMs in communication games and associated domains.
</p>
</div>
</dd>
<dt><a name="item61">[61]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.04659" title="Abstract">arXiv:2309.04659</a> [<a href="/pdf/2309.04659" title="Download PDF">pdf</a>, <a href="/format/2309.04659" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Progressive Feature Adjustment for Semi-supervised Learning from  Pretrained Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+H">Hai-Ming Xu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+L">Lingqiao Liu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+H">Hao Chen</a>, 
<a href="/search/cs?searchtype=author&query=Abbasnejad%2C+E">Ehsan Abbasnejad</a>, 
<a href="/search/cs?searchtype=author&query=Felix%2C+R">Rafael Felix</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> to appear at ICCVW2023 (Workshop on Visual Continual Learning)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">As an effective way to alleviate the burden of data annotation,
semi-supervised learning (SSL) provides an attractive solution due to its
ability to leverage both labeled and unlabeled data to build a predictive
model. While significant progress has been made recently, SSL algorithms are
often evaluated and developed under the assumption that the network is randomly
initialized. This is in sharp contrast to most vision recognition systems that
are built from fine-tuning a pretrained network for better performance. While
the marriage of SSL and a pretrained model seems to be straightforward, recent
literature suggests that naively applying state-of-the-art SSL with a
pretrained model fails to unleash the full potential of training data. In this
paper, we postulate the underlying reason is that the pretrained feature
representation could bring a bias inherited from the source data, and the bias
tends to be magnified through the self-training process in a typical SSL
algorithm. To overcome this issue, we propose to use pseudo-labels from the
unlabelled data to update the feature extractor that is less sensitive to
incorrect labels and only allow the classifier to be trained from the labeled
data. More specifically, we progressively adjust the feature extractor to
ensure its induced feature distribution maintains a good class separability
even under strong input perturbation. Through extensive experimental studies,
we show that the proposed approach achieves superior performance over existing
solutions.
</p>
</div>
</dd>
<dt><a name="item62">[62]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.04660" title="Abstract">arXiv:2309.04660</a> [<a href="/pdf/2309.04660" title="Download PDF">pdf</a>, <a href="/format/2309.04660" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Compiling Recurrences over Dense and Sparse Arrays
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sundram%2C+S">Shiv Sundram</a>, 
<a href="/search/cs?searchtype=author&query=Tariq%2C+M+U">Muhammad Usman Tariq</a>, 
<a href="/search/cs?searchtype=author&query=Kjolstad%2C+F">Fredrik Kjolstad</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Programming Languages (cs.PL)</span>

</div>
<p class="mathjax">Recurrence equations lie at the heart of many computational paradigms
including dynamic programming, graph analysis, and linear solvers. These
equations are often expensive to compute and much work has gone into optimizing
them for different situations. The set of recurrence implementations is a large
design space across the set of all recurrences (e.g., the Viterbi and
Floyd-Warshall algorithms), the choice of data structures (e.g., dense and
sparse matrices), and the set of different loop orders. Optimized library
implementations do not exist for most points in this design space, and
developers must therefore often manually implement and optimize recurrences. We
present a general framework for compiling recurrence equations into native code
corresponding to any valid point in this general design space. In this
framework, users specify a system of recurrences, the type of data structures
for storing the input and outputs, and a set of scheduling primitives for
optimization. A greedy algorithm then takes this specification and lowers it
into a native program that respects the dependencies inherent to the recurrence
equation. We describe the compiler transformations necessary to lower this
high-level specification into native parallel code for either sparse and dense
data structures and provide an algorithm for determining whether the recurrence
system is solvable with the provided scheduling primitives. We evaluate the
performance and correctness of the generated code on various computational
tasks from domains including dense and sparse matrix solvers, dynamic
programming, graph problems, and sparse tensor algebra. We demonstrate that
generated code has competitive performance to handwritten implementations in
libraries.
</p>
</div>
</dd>
<dt><a name="item63">[63]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.04662" title="Abstract">arXiv:2309.04662</a> [<a href="/pdf/2309.04662" title="Download PDF">pdf</a>, <a href="/format/2309.04662" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MADLAD-400: A Multilingual And Document-Level Large Audited Dataset
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kudugunta%2C+S">Sneha Kudugunta</a>, 
<a href="/search/cs?searchtype=author&query=Caswell%2C+I">Isaac Caswell</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+B">Biao Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Garcia%2C+X">Xavier Garcia</a>, 
<a href="/search/cs?searchtype=author&query=Choquette-Choo%2C+C+A">Christopher A. Choquette-Choo</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+K">Katherine Lee</a>, 
<a href="/search/cs?searchtype=author&query=Xin%2C+D">Derrick Xin</a>, 
<a href="/search/cs?searchtype=author&query=Kusupati%2C+A">Aditya Kusupati</a>, 
<a href="/search/cs?searchtype=author&query=Stella%2C+R">Romi Stella</a>, 
<a href="/search/cs?searchtype=author&query=Bapna%2C+A">Ankur Bapna</a>, 
<a href="/search/cs?searchtype=author&query=Firat%2C+O">Orhan Firat</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Preprint
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">We introduce MADLAD-400, a manually audited, general domain 3T token
monolingual dataset based on CommonCrawl, spanning 419 languages. We discuss
the limitations revealed by self-auditing MADLAD-400, and the role data
auditing had in the dataset creation process. We then train and release a
10.7B-parameter multilingual machine translation model on 250 billion tokens
covering over 450 languages using publicly available data, and find that it is
competitive with models that are significantly larger, and report the results
on different domains. In addition, we train a 8B-parameter language model, and
assess the results on few-shot translation. We make the baseline models
available to the research community.
</p>
</div>
</dd>
<dt><a name="item64">[64]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.04663" title="Abstract">arXiv:2309.04663</a> [<a href="/pdf/2309.04663" title="Download PDF">pdf</a>, <a href="/format/2309.04663" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FIAT: Fusing learning paradigms with Instruction-Accelerated Tuning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xinyi Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wieting%2C+J">John Wieting</a>, 
<a href="/search/cs?searchtype=author&query=Clark%2C+J+H">Jonathan H. Clark</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Learning paradigms for large language models (LLMs) currently tend to fall
within either in-context learning (ICL) or full fine-tuning. Each of these
comes with their own trade-offs based on available data, model size, compute
cost, ease-of-use, and final quality with neither solution performing well
across-the-board. In this article, we first describe ICL and fine-tuning
paradigms in a way that highlights their natural connections. Based on these
connections, we propose a new learning paradigm called FIAT that fuses the best
of these paradigms together, enabling prompt-engineered instructions and
chain-of-thought reasoning with the very largest models while also using
similar methods to perform parameter updates on a modestly-sized LLM with
parameter-efficient tuning. We evaluate FIAT's effectiveness on a variety of
multilingual tasks and observe that FIAT performs better than both ICL and
fine-tuning at scales ranging from 100-10,000 training examples. We hope that
FIAT provides a practical way of harnessing the full potential of LLMs without
needing to make a hard choice between learning paradigms.
</p>
</div>
</dd>
<dt><a name="item65">[65]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.04664" title="Abstract">arXiv:2309.04664</a> [<a href="/pdf/2309.04664" title="Download PDF">pdf</a>, <a href="/format/2309.04664" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Compact: Approximating Complex Activation Functions for Secure  Computation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Islam%2C+M">Mazharul Islam</a>, 
<a href="/search/cs?searchtype=author&query=Arora%2C+S+S">Sunpreet S. Arora</a>, 
<a href="/search/cs?searchtype=author&query=Chatterjee%2C+R">Rahul Chatterjee</a>, 
<a href="/search/cs?searchtype=author&query=Rindal%2C+P">Peter Rindal</a>, 
<a href="/search/cs?searchtype=author&query=Shirvanian%2C+M">Maliheh Shirvanian</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Secure multi-party computation (MPC) techniques can be used to provide data
privacy when users query deep neural network (DNN) models hosted on a public
cloud. State-of-the-art MPC techniques can be directly leveraged for DNN models
that use simple activation functions (AFs) such as ReLU. However, DNN model
architectures designed for cutting-edge applications often use complex and
highly non-linear AFs. Designing efficient MPC techniques for such complex AFs
is an open problem.
<br />Towards this, we propose Compact, which produces piece-wise polynomial
approximations of complex AFs to enable their efficient use with
state-of-the-art MPC techniques. Compact neither requires nor imposes any
restriction on model training and results in near-identical model accuracy. We
extensively evaluate Compact on four different machine-learning tasks with DNN
architectures that use popular complex AFs SiLU, GeLU, and Mish. Our
experimental results show that Compact incurs negligible accuracy loss compared
to DNN-specific approaches for handling complex non-linear AFs. We also
incorporate Compact in two state-of-the-art MPC libraries for
privacy-preserving inference and demonstrate that Compact provides 2x-5x
speedup in computation compared to the state-of-the-art approximation approach
for non-linear functions -- while providing similar or better accuracy for DNN
models with large number of hidden layers
</p>
</div>
</dd>
<dt><a name="item66">[66]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.04668" title="Abstract">arXiv:2309.04668</a> [<a href="/pdf/2309.04668" title="Download PDF">pdf</a>, <a href="/format/2309.04668" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Influence Maximization in Social Networks: A Survey
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Hui Li</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+S">Susu Yang</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+M">Mengting Xu</a>, 
<a href="/search/cs?searchtype=author&query=Bhowmick%2C+S+S">Sourav S Bhowmick</a>, 
<a href="/search/cs?searchtype=author&query=Cui%2C+J">Jiangtao Cui</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>

</div>
<p class="mathjax">Online social networks have become an important platform for people to
communicate, share knowledge and disseminate information. Given the widespread
usage of social media, individuals' ideas, preferences and behavior are often
influenced by their peers or friends in the social networks that they
participate in. Since the last decade, influence maximization (IM) problem has
been extensively adopted to model the diffusion of innovations and ideas. The
purpose of IM is to select a set of k seed nodes who can influence the most
individuals in the network.
<br />In this survey, we present a systematical study over the researches and
future directions with respect to IM problem. We review the information
diffusion models and analyze a variety of algorithms for the classic IM
algorithms. We propose a taxonomy for potential readers to understand the key
techniques and challenges. We also organize the milestone works in time order
such that the readers of this survey can experience the research roadmap in
this field. Moreover, we also categorize other application-oriented IM studies
and correspondingly study each of them. What's more, we list a series of open
questions as the future directions for IM-related researches, where a potential
reader of this survey can easily observe what should be done next in this
field.
</p>
</div>
</dd>
<dt><a name="item67">[67]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.04669" title="Abstract">arXiv:2309.04669</a> [<a href="/pdf/2309.04669" title="Download PDF">pdf</a>, <a href="/format/2309.04669" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Unified Language-Vision Pretraining with Dynamic Discrete Visual  Tokenization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jin%2C+Y">Yang Jin</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+K">Kun Xu</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+K">Kun Xu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+L">Liwei Chen</a>, 
<a href="/search/cs?searchtype=author&query=Liao%2C+C">Chao Liao</a>, 
<a href="/search/cs?searchtype=author&query=Tan%2C+J">Jianchao Tan</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+B">Bin Chen</a>, 
<a href="/search/cs?searchtype=author&query=Lei%2C+C">Chenyi Lei</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+A">An Liu</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+C">Chengru Song</a>, 
<a href="/search/cs?searchtype=author&query=Lei%2C+X">Xiaoqiang Lei</a>, 
<a href="/search/cs?searchtype=author&query=Mu%2C+Y">Yadong Mu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+D">Di Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Ou%2C+W">Wenwu Ou</a>, 
<a href="/search/cs?searchtype=author&query=Gai%2C+K">Kun Gai</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Recently, the remarkable advance of the Large Language Model (LLM) has
inspired researchers to transfer its extraordinary reasoning capability to data
across several modalities. The prevailing approaches primarily regard visual
input as the prompt and focus exclusively on optimizing the text generation
process conditioned upon vision content by a frozen LLM. Such an inequitable
treatment of vision and language heavily constrains the model's potential. In
this paper, we break through this limitation by representing both vision and
language in a unified representation. To this end, we craft a visual tokenizer
that translates the non-linguistic image into a sequence of discrete tokens
like a foreign language that LLM can read. The resulting visual tokens
encompass high-level semantics worthy of a word and also support dynamic
sequence length varying from the image content. Coped with this visual
tokenizer, the presented foundation model called LaVIT (Language-VIsion
Transformer) can handle both image and text indiscriminately under a unified
generative learning paradigm. Pre-trained on the web-scale image-text corpus,
LaVIT is empowered with impressive multi-modal comprehension capability. The
extensive experiments showcase that it outperforms existing models by a large
margin on downstream tasks. Our code and models will be available at
https://github.com/jy0205/LaVIT.
</p>
</div>
</dd>
<dt><a name="item68">[68]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.04671" title="Abstract">arXiv:2309.04671</a> [<a href="/pdf/2309.04671" title="Download PDF">pdf</a>, <a href="/format/2309.04671" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Accelerating High-Order Stencils on Modern GPUs and Emerging  Architectures with a Portable Framework
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sai%2C+R">Ryuichi Sai</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+J">Jinfan Xu</a>, 
<a href="/search/cs?searchtype=author&query=Araya-Polo%2C+M">Mauricio Araya-Polo</a>, 
<a href="/search/cs?searchtype=author&query=Mellor-Crummey%2C+J">John Mellor-Crummey</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>

</div>
<p class="mathjax">PDE discretization schemes yielding stencil-like computing patterns are
commonly used for seismic modeling, weather forecast, and other scientific
applications. Achieving HPC-level stencil computations on one architecture is
challenging, porting to other architectures without sacrificing performance
requires significant effort, especially in this golden age of many distinctive
architectures.
<br />To help developers achieve performance, portability, and productivity with
stencil computations, we developed StencilPy. With StencilPy, developers write
stencil computations in a high-level domain-specific language, which promotes
productivity, while its backends generate efficient code for existing and
emerging architectures, including NVIDIA, AMD, and Intel GPUs, A64FX, and STX.
StencilPy demonstrates promising performance results on par with hand-written
code, maintains cross-architectural performance portability, and enhances
productivity. Its modular design enables easy configuration, customization, and
extension. A 25-point star-shaped stencil written in StencilPy is one-quarter
of the length of a hand-crafted CUDA code and achieves similar performance on
an NVIDIA H100 GPU.
</p>
</div>
</dd>
<dt><a name="item69">[69]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.04675" title="Abstract">arXiv:2309.04675</a> [<a href="/pdf/2309.04675" title="Download PDF">pdf</a>, <a href="/format/2309.04675" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> BiLMa: Bidirectional Local-Matching for Text-based Person  Re-identification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fujii%2C+T">Takuro Fujii</a>, 
<a href="/search/cs?searchtype=author&query=Tarashima%2C+S">Shuhei Tarashima</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at ICCVW 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Text-based person re-identification (TBPReID) aims to retrieve person images
represented by a given textual query. In this task, how to effectively align
images and texts globally and locally is a crucial challenge. Recent works have
obtained high performances by solving Masked Language Modeling (MLM) to align
image/text parts. However, they only performed uni-directional (i.e., from
image to text) local-matching, leaving room for improvement by introducing
opposite-directional (i.e., from text to image) local-matching. In this work,
we introduce Bidirectional Local-Matching (BiLMa) framework that jointly
optimize MLM and Masked Image Modeling (MIM) in TBPReID model training. With
this framework, our model is trained so as the labels of randomly masked both
image and text tokens are predicted by unmasked tokens. In addition, to narrow
the semantic gap between image and text in MIM, we propose Semantic MIM
(SemMIM), in which the labels of masked image tokens are automatically given by
a state-of-the-art human parser. Experimental results demonstrate that our
BiLMa framework with SemMIM achieves state-of-the-art Rank@1 and mAP scores on
three benchmarks.
</p>
</div>
</dd>
<dt><a name="item70">[70]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.04676" title="Abstract">arXiv:2309.04676</a> [<a href="/pdf/2309.04676" title="Download PDF">pdf</a>, <a href="/format/2309.04676" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Flexible and Robust Counterfactual Explanations with Minimal Satisfiable  Perturbations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yongjie Wang</a>, 
<a href="/search/cs?searchtype=author&query=Qian%2C+H">Hangwei Qian</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yongjie Liu</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+W">Wei Guo</a>, 
<a href="/search/cs?searchtype=author&query=Miao%2C+C">Chunyan Miao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by CIKM 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Methodology (stat.ME)

</div>
<p class="mathjax">Counterfactual explanations (CFEs) exemplify how to minimally modify a
feature vector to achieve a different prediction for an instance. CFEs can
enhance informational fairness and trustworthiness, and provide suggestions for
users who receive adverse predictions. However, recent research has shown that
multiple CFEs can be offered for the same instance or instances with slight
differences. Multiple CFEs provide flexible choices and cover diverse
desiderata for user selection. However, individual fairness and model
reliability will be damaged if unstable CFEs with different costs are returned.
Existing methods fail to exploit flexibility and address the concerns of
non-robustness simultaneously. To address these issues, we propose a
conceptually simple yet effective solution named Counterfactual Explanations
with Minimal Satisfiable Perturbations (CEMSP). Specifically, CEMSP constrains
changing values of abnormal features with the help of their semantically
meaningful normal ranges. For efficiency, we model the problem as a Boolean
satisfiability problem to modify as few features as possible. Additionally,
CEMSP is a general framework and can easily accommodate more practical
requirements, e.g., casualty and actionability. Compared to existing methods,
we conduct comprehensive experiments on both synthetic and real-world datasets
to demonstrate that our method provides more robust explanations while
preserving flexibility.
</p>
</div>
</dd>
<dt><a name="item71">[71]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.04678" title="Abstract">arXiv:2309.04678</a> [<a href="/pdf/2309.04678" title="Download PDF">pdf</a>, <a href="/format/2309.04678" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Data-driven Bayesian Control of Port-Hamiltonian Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Beckers%2C+T">Thomas Beckers</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">Port-Hamiltonian theory is an established way to describe nonlinear physical
systems widely used in various fields such as robotics, energy management, and
mechanical engineering. This has led to considerable research interest in the
control of Port-Hamiltonian systems, resulting in numerous model-based control
techniques. However, the performance and stability of the closed-loop typically
depend on the quality of the PH model, which is often difficult to obtain using
first principles. We propose a Gaussian Processes (GP) based control approach
for Port-Hamiltonian systems (GPC-PHS) by leveraging gathered data. The
Bayesian characteristics of GPs enable the creation of a distribution
encompassing all potential Hamiltonians instead of providing a singular point
estimate. Using this uncertainty quantification, the proposed approach takes
advantage of passivity-based robust control with interconnection and damping
assignment to establish probabilistic stability guarantees.
</p>
</div>
</dd>
<dt><a name="item72">[72]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.04679" title="Abstract">arXiv:2309.04679</a> [<a href="/pdf/2309.04679" title="Download PDF">pdf</a>, <a href="/format/2309.04679" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Embedding structure matters: Comparing methods to adapt multilingual  vocabularies to new languages
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Downey%2C+C+M">C.M. Downey</a>, 
<a href="/search/cs?searchtype=author&query=Blevins%2C+T">Terra Blevins</a>, 
<a href="/search/cs?searchtype=author&query=Goldfine%2C+N">Nora Goldfine</a>, 
<a href="/search/cs?searchtype=author&query=Steinert-Threlkeld%2C+S">Shane Steinert-Threlkeld</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Pre-trained multilingual language models underpin a large portion of modern
NLP tools outside of English. A strong baseline for specializing these models
for specific languages is Language-Adaptive Pre-Training (LAPT). However,
retaining a large cross-lingual vocabulary and embedding matrix comes at
considerable excess computational cost during adaptation. In this study, we
propose several simple techniques to replace a cross-lingual vocabulary with a
compact, language-specific one. Namely, we address strategies for
re-initializing the token embedding matrix after vocabulary specialization. We
then provide a systematic experimental comparison of our techniques, in
addition to the recently-proposed Focus method. We demonstrate that: 1)
Embedding-replacement techniques in the monolingual transfer literature are
inadequate for adapting multilingual models. 2) Replacing cross-lingual
vocabularies with smaller specialized ones provides an efficient method to
improve performance in low-resource languages. 3) Simple embedding
re-initialization techniques based on script-wise sub-distributions rival
techniques such as Focus, which rely on similarity scores obtained from an
auxiliary model.
</p>
</div>
</dd>
<dt><a name="item73">[73]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.04681" title="Abstract">arXiv:2309.04681</a> [<a href="/pdf/2309.04681" title="Download PDF">pdf</a>, <a href="/format/2309.04681" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Comparing Morse Complexes Using Optimal Transport: An Experimental Study
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+M">Mingzhe Li</a>, 
<a href="/search/cs?searchtype=author&query=Storm%2C+C">Carson Storm</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+A+Y">Austin Yang Li</a>, 
<a href="/search/cs?searchtype=author&query=Needham%2C+T">Tom Needham</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+B">Bei Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> IEEE Visualization Conference (IEEE VIS) Short Paper, accepted, 2023; supplementary materials: <a href="http://www.sci.utah.edu/~beiwang/publications/GWMC_VIS_Short_BeiWang_2023_Supplement.pdf">this http URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Geometry (cs.CG)</span>

</div>
<p class="mathjax">Morse complexes and Morse-Smale complexes are topological descriptors popular
in topology-based visualization. Comparing these complexes plays an important
role in their applications in feature correspondences, feature tracking,
symmetry detection, and uncertainty visualization. Leveraging recent advances
in optimal transport, we apply a class of optimal transport distances to the
comparative analysis of Morse complexes. Contrasting with existing comparative
measures, such distances are easy and efficient to compute, and naturally
provide structural matching between Morse complexes. We perform an experimental
study involving scientific simulation datasets and discuss the effectiveness of
these distances as comparative measures for Morse complexes. We also provide an
initial guideline for choosing the optimal transport distances under various
data assumptions.
</p>
</div>
</dd>
<dt><a name="item74">[74]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.04682" title="Abstract">arXiv:2309.04682</a> [<a href="/pdf/2309.04682" title="Download PDF">pdf</a>, <a href="/format/2309.04682" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DeNoising-MOT: Towards Multiple Object Tracking with Severe Occlusions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fu%2C+T">Teng Fu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xiaocong Wang</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+H">Haiyang Yu</a>, 
<a href="/search/cs?searchtype=author&query=Niu%2C+K">Ke Niu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+B">Bin Li</a>, 
<a href="/search/cs?searchtype=author&query=Xue%2C+X">Xiangyang Xue</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ACM Multimedia 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Multiple object tracking (MOT) tends to become more challenging when severe
occlusions occur. In this paper, we analyze the limitations of traditional
Convolutional Neural Network-based methods and Transformer-based methods in
handling occlusions and propose DNMOT, an end-to-end trainable DeNoising
Transformer for MOT. To address the challenge of occlusions, we explicitly
simulate the scenarios when occlusions occur. Specifically, we augment the
trajectory with noises during training and make our model learn the denoising
process in an encoder-decoder architecture, so that our model can exhibit
strong robustness and perform well under crowded scenes. Additionally, we
propose a Cascaded Mask strategy to better coordinate the interaction between
different types of queries in the decoder to prevent the mutual suppression
between neighboring trajectories under crowded scenes. Notably, the proposed
method requires no additional modules like matching strategy and motion state
estimation in inference. We conduct extensive experiments on the MOT17, MOT20,
and DanceTrack datasets, and the experimental results show that our method
outperforms previous state-of-the-art methods by a clear margin.
</p>
</div>
</dd>
<dt><a name="item75">[75]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.04683" title="Abstract">arXiv:2309.04683</a> [<a href="/pdf/2309.04683" title="Download PDF">pdf</a>, <a href="/format/2309.04683" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Tensors Ranks and the Fine-Grained Complexity of Dynamic Programming
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Alman%2C+J">Josh Alman</a>, 
<a href="/search/cs?searchtype=author&query=Turok%2C+E">Ethan Turok</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+H">Hantao Yu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Hengzhi Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Complexity (cs.CC)</span>

</div>
<p class="mathjax">Generalizing work of K\"unnemann, Paturi, and Schneider [ICALP 2017], we
study a wide class of high-dimensional dynamic programming (DP) problems in
which one must find the shortest path between two points in a high-dimensional
grid given a tensor of transition costs between nodes in the grid. This
captures many classical problems which are solved using DP such as the knapsack
problem, the airplane refueling problem, and the minimal-weight polygon
triangulation problem. We observe that for many of these problems, the tensor
naturally has low tensor rank or low slice rank.
<br />We then give new algorithms and a web of fine-grained reductions to tightly
determine the complexity of these problems. For instance, we show that a
polynomial speedup over the DP algorithm is possible when the tensor rank is a
constant or the slice rank is 1, but that such a speedup is impossible if the
tensor rank is slightly super-constant (assuming SETH) or the slice rank is at
least 3 (assuming the APSP conjecture). We find that this characterizes the
known complexities for many of these problems, and in some cases leads to new
faster algorithms.
</p>
</div>
</dd>
<dt><a name="item76">[76]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.04687" title="Abstract">arXiv:2309.04687</a> [<a href="/pdf/2309.04687" title="Download PDF">pdf</a>, <a href="/format/2309.04687" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Review on Robot Manipulation Methods in Human-Robot Interactions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Haoxu Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Kebria%2C+P+M">Parham M. Kebria</a>, 
<a href="/search/cs?searchtype=author&query=Mohamed%2C+S">Shady Mohamed</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+S">Samson Yu</a>, 
<a href="/search/cs?searchtype=author&query=Nahavandi%2C+S">Saeid Nahavandi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Human-Computer Interaction (cs.HC)

</div>
<p class="mathjax">Robot manipulation is an important part of human-robot interaction
technology. However, traditional pre-programmed methods can only accomplish
simple and repetitive tasks. To enable effective communication between robots
and humans, and to predict and adapt to uncertain environments, this paper
reviews recent autonomous and adaptive learning in robotic manipulation
algorithms. It includes typical applications and challenges of human-robot
interaction, fundamental tasks of robot manipulation and one of the most widely
used formulations of robot manipulation, Markov Decision Process. Recent
research focusing on robot manipulation is mainly based on Reinforcement
Learning and Imitation Learning. This review paper shows the importance of Deep
Reinforcement Learning, which plays an important role in manipulating robots to
complete complex tasks in disturbed and unfamiliar environments. With the
introduction of Imitation Learning, it is possible for robot manipulation to
get rid of reward function design and achieve a simple, stable and supervised
learning process. This paper reviews and compares the main features and popular
algorithms for both Reinforcement Learning and Imitation Learning.
</p>
</div>
</dd>
<dt><a name="item77">[77]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.04689" title="Abstract">arXiv:2309.04689</a> [<a href="/pdf/2309.04689" title="Download PDF">pdf</a>, <a href="/format/2309.04689" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Data Middleware for Obtaining Trusted Price Data for Blockchain
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xian%2C+Y">Youquan Xian</a>, 
<a href="/search/cs?searchtype=author&query=Zeng%2C+X">Xueying Zeng</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+L">Lianghaojie Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+B">Boyi Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+L">Li-e Wang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+P">Peng Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages,8 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Computational Engineering, Finance, and Science (cs.CE); Distributed, Parallel, and Cluster Computing (cs.DC)

</div>
<p class="mathjax">As a trusted middleware connecting the blockchain and the real world, the
blockchain oracle can obtain trusted real-time price information for financial
applications such as payment and settlement, and asset valuation on the
blockchain. However, the current oracle schemes face the dilemma of security
and service quality in the process of node selection, and the implicit interest
relationship in financial applications leads to a significant conflict of
interest between the task publisher and the executor, which reduces the
participation enthusiasm of both parties and system security. Therefore, this
paper proposes an anonymous node selection scheme that anonymously selects
nodes with high reputations to participate in tasks to ensure the security and
service quality of nodes. Then, this paper also details the interest
requirements and behavioral motives of all parties in the payment settlement
and asset valuation scenarios. Under the assumption of rational participants,
an incentive mechanism based on the Stackelberg game is proposed. It can
achieve equilibrium under the pursuit of the interests of task publishers and
executors, thereby ensuring the interests of all types of users and improving
the enthusiasm of participation. Finally, we verify the security of the
proposed scheme through security analysis. The experimental results show that
the proposed scheme can reduce the variance of obtaining price data by about
55\% while ensuring security, and meeting the interests of all parties.
</p>
</div>
</dd>
<dt><a name="item78">[78]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.04691" title="Abstract">arXiv:2309.04691</a> [<a href="/pdf/2309.04691" title="Download PDF">pdf</a>, <a href="/format/2309.04691" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Asynchronous Majority Dynamics on Binomial Random Graphs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mohan%2C+D">Divyarthi Mohan</a>, 
<a href="/search/cs?searchtype=author&query=Pralat%2C+P">Pawel Pralat</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>; Discrete Mathematics (cs.DM); Combinatorics (math.CO)

</div>
<p class="mathjax">We study information aggregation in networks when agents interact to learn a
binary state of the world. Initially each agent privately observes an
independent signal which is "correct" with probability $\frac{1}{2}+\delta$ for
some $\delta &gt; 0$. At each round, a node is selected uniformly at random to
update their public opinion to match the majority of their neighbours (breaking
ties in favour of their initial private signal). Our main result shows that for
sparse and connected binomial random graphs $\mathcal G(n,p)$ the process
stabilizes in a "correct" consensus in $\mathcal O(n\log^2 n/\log\log n)$ steps
with high probability. In fact, when $\log n/n \ll p = o(1)$ the process
terminates at time $\hat T = (1+o(1))n\log n$, where $\hat T$ is the first time
when all nodes have been selected at least once. However, in dense binomial
random graphs with $p=\Omega(1)$, there is an information cascade where the
process terminates in the "incorrect" consensus with probability bounded away
from zero.
</p>
</div>
</dd>
<dt><a name="item79">[79]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.04693" title="Abstract">arXiv:2309.04693</a> [<a href="/pdf/2309.04693" title="Download PDF">pdf</a>, <a href="/ps/2309.04693" title="Download PostScript">ps</a>, <a href="/format/2309.04693" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Security Analysis of Pairing-based Cryptography
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xiaofeng Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+P">Peng Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Xing%2C+Q">Qianqian Xing</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 figures, 8 tables, 5121 words
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">Recent progress in number field sieve (NFS) has shaken the security of
Pairing-based Cryptography. For the discrete logarithm problem (DLP) in finite
field, we present the first systematic review of the NFS algorithms from three
perspectives: the degree $\alpha$, constant $c$, and hidden constant $o(1)$ in
the asymptotic complexity $L_Q\left(\alpha,c\right)$ and indicate that further
research is required to optimize the hidden constant. Using the special
extended tower NFS algorithm, we conduct a thorough security evaluation for all
the existing standardized PF curves as well as several commonly utilized
curves, which reveals that the BN256 curves recommended by the SM9 and the
previous ISO/IEC standard exhibit only 99.92 bits of security, significantly
lower than the intended 128-bit level. In addition, we comprehensively analyze
the security and efficiency of BN, BLS, and KSS curves for different security
levels. Our analysis suggests that the BN curve exhibits superior efficiency
for security strength below approximately 105 bit. For a 128-bit security
level, BLS12 and BLS24 curves are the optimal choices, while the BLS24 curve
offers the best efficiency for security levels of 160bit, 192bit, and 256bit.
</p>
</div>
</dd>
<dt><a name="item80">[80]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.04694" title="Abstract">arXiv:2309.04694</a> [<a href="/pdf/2309.04694" title="Download PDF">pdf</a>, <a href="/format/2309.04694" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Redundancy-Free Self-Supervised Relational Learning for Graph Clustering
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yi%2C+S">Si-Yu Yi</a>, 
<a href="/search/cs?searchtype=author&query=Ju%2C+W">Wei Ju</a>, 
<a href="/search/cs?searchtype=author&query=Qin%2C+Y">Yifang Qin</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+X">Xiao Luo</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+L">Luchen Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Y">Yong-Dao Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+M">Ming Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by IEEE Transactions on Neural Networks and Learning Systems (TNNLS 2024)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Graph clustering, which learns the node representations for effective cluster
assignments, is a fundamental yet challenging task in data analysis and has
received considerable attention accompanied by graph neural networks in recent
years. However, most existing methods overlook the inherent relational
information among the non-independent and non-identically distributed nodes in
a graph. Due to the lack of exploration of relational attributes, the semantic
information of the graph-structured data fails to be fully exploited which
leads to poor clustering performance. In this paper, we propose a novel
self-supervised deep graph clustering method named Relational Redundancy-Free
Graph Clustering (R$^2$FGC) to tackle the problem. It extracts the attribute-
and structure-level relational information from both global and local views
based on an autoencoder and a graph autoencoder. To obtain effective
representations of the semantic information, we preserve the consistent
relation among augmented nodes, whereas the redundant relation is further
reduced for learning discriminative embeddings. In addition, a simple yet valid
strategy is utilized to alleviate the over-smoothing issue. Extensive
experiments are performed on widely used benchmark datasets to validate the
superiority of our R$^2$FGC over state-of-the-art baselines. Our codes are
available at https://github.com/yisiyu95/R2FGC.
</p>
</div>
</dd>
<dt><a name="item81">[81]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.04695" title="Abstract">arXiv:2309.04695</a> [<a href="/pdf/2309.04695" title="Download PDF">pdf</a>, <a href="/format/2309.04695" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Code-Style In-Context Learning for Knowledge-Based Question Answering
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nie%2C+Z">Zhijie Nie</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+R">Richong Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zhongyuan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xudong Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> work in progress
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Current methods for Knowledge-Based Question Answering (KBQA) usually rely on
complex training techniques and model frameworks, leading to many limitations
in practical applications. Recently, the emergence of In-Context Learning (ICL)
capabilities in Large Language Models (LLMs) provides a simple and
training-free semantic parsing paradigm for KBQA: Given a small number of
questions and their labeled logical forms as demo examples, LLMs can understand
the task intent and generate the logic form for a new question. However,
current powerful LLMs have little exposure to logic forms during pre-training,
resulting in a high format error rate. To solve this problem, we propose a
code-style in-context learning method for KBQA, which converts the generation
process of unfamiliar logical form into the more familiar code generation
process for LLMs. Experimental results on three mainstream datasets show that
our method dramatically mitigated the formatting error problem in generating
logic forms while realizing a new SOTA on WebQSP, GrailQA, and GraphQ under the
few-shot setting.
</p>
</div>
</dd>
<dt><a name="item82">[82]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.04696" title="Abstract">arXiv:2309.04696</a> [<a href="/pdf/2309.04696" title="Download PDF">pdf</a>, <a href="/ps/2309.04696" title="Download PostScript">ps</a>, <a href="/format/2309.04696" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> \textsf{pun}: Fun with Properties; Towards a Programming Language With  Built-in Facilities for Program Validation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gashi%2C+T">Triera Gashi</a>, 
<a href="/search/cs?searchtype=author&query=Bosio%2C+S+A+S">Sophie Adeline Solheim Bosio</a>, 
<a href="/search/cs?searchtype=author&query=Kristensen%2C+J+T">Joachim Tilsted Kristensen</a>, 
<a href="/search/cs?searchtype=author&query=Thomsen%2C+M+K">Michael Kirkedal Thomsen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to 35th Norwegian ICT Conference for Research and Education
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Programming Languages (cs.PL)</span>

</div>
<p class="mathjax">Property-based testing is a powerful method to validate program correctness.
It is, however, not widely use in industry as the barrier of entry can be very
high. One of the hindrances is to write the generators that are needed to
generate randomised input data. Program properties often take complicated data
structures as inputs and, it requires a significant amount of effort to write
generators for such structures in a invariant preserving way.
<br />In this paper, we suggest and formalise a new programming language
\textsf{pun}; a simple functional programming with properties as a built-in
mechanism for program validation. We show how to generate input for
\textsf{pun} properties automatically, thus, providing the programmer with a
low barrier of entry for using property-based testing. We evaluate our work a
on library for binary search trees and compare the test results to a similar
library in Haskell.
</p>
</div>
</dd>
<dt><a name="item83">[83]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.04697" title="Abstract">arXiv:2309.04697</a> [<a href="/pdf/2309.04697" title="Download PDF">pdf</a>, <a href="/format/2309.04697" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Leakage-Abuse Attacks Against Forward and Backward Private Searchable  Symmetric Encryption
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+L">Lei Xu</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+L">Leqian Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+C">Chengzhi Xu</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+X">Xingliang Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+C">Cong Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">Dynamic searchable symmetric encryption (DSSE) enables a server to
efficiently search and update over encrypted files. To minimize the leakage
during updates, a security notion named forward and backward privacy is
expected for newly proposed DSSE schemes. Those schemes are generally
constructed in a way to break the linkability across search and update queries
to a given keyword. However, it remains underexplored whether forward and
backward private DSSE is resilient against practical leakage-abuse attacks
(LAAs), where an attacker attempts to recover query keywords from the leakage
passively collected during queries.
<br />In this paper, we aim to be the first to answer this question firmly through
two non-trivial efforts. First, we revisit the spectrum of forward and backward
private DSSE schemes over the past few years, and unveil some inherent
constructional limitations in most schemes. Those limitations allow attackers
to exploit query equality and establish a guaranteed linkage among different
(refreshed) query tokens surjective to a candidate keyword. Second, we refine
volumetric leakage profiles of updates and queries by associating each with a
specific operation. By further exploiting update volume and query response
volume, we demonstrate that all forward and backward private DSSE schemes can
leak the same volumetric information (e.g., insertion volume, deletion volume)
as those without such security guarantees. To testify our findings, we realize
two generic LAAs, i.e., frequency matching attack and volumetric inference
attack, and we evaluate them over various experimental settings in the dynamic
context. Finally, we call for new efficient schemes to protect query equality
and volumetric information across search and update queries.
</p>
</div>
</dd>
<dt><a name="item84">[84]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.04698" title="Abstract">arXiv:2309.04698</a> [<a href="/pdf/2309.04698" title="Download PDF">pdf</a>, <a href="/format/2309.04698" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Advancements in Upper Body Exoskeleton: Implementing Active Gravity  Compensation with a Feedforward Controller
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hussain%2C+M+A">Muhammad Ayaz Hussain</a>, 
<a href="/search/cs?searchtype=author&query=Iossifidis%2C+I">Ioannis Iossifidis</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI); Hardware Architecture (cs.AR)

</div>
<p class="mathjax">In this study, we present a feedforward control system designed for active
gravity compensation on an upper body exoskeleton. The system utilizes only
positional data from internal motor sensors to calculate torque, employing
analytical control equations based on Newton-Euler Inverse Dynamics. Compared
to feedback control systems, the feedforward approach offers several
advantages. It eliminates the need for external torque sensors, resulting in
reduced hardware complexity and weight. Moreover, the feedforward control
exhibits a more proactive response, leading to enhanced performance. The
exoskeleton used in the experiments is lightweight and comprises 4 Degrees of
Freedom, closely mimicking human upper body kinematics and three-dimensional
range of motion. We conducted tests on both hardware and simulations of the
exoskeleton, demonstrating stable performance. The system maintained its
position over an extended period, exhibiting minimal friction and avoiding
undesired slewing.
</p>
</div>
</dd>
<dt><a name="item85">[85]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.04699" title="Abstract">arXiv:2309.04699</a> [<a href="/pdf/2309.04699" title="Download PDF">pdf</a>, <a href="/format/2309.04699" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Weak-PDE-LEARN: A Weak Form Based Approach to Discovering PDEs From  Noisy, Limited Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Stephany%2C+R">Robert Stephany</a>, 
<a href="/search/cs?searchtype=author&query=Earls%2C+C">Christopher Earls</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 29 pages, 8 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">We introduce Weak-PDE-LEARN, a Partial Differential Equation (PDE) discovery
algorithm that can identify non-linear PDEs from noisy, limited measurements of
their solutions. Weak-PDE-LEARN uses an adaptive loss function based on weak
forms to train a neural network, $U$, to approximate the PDE solution while
simultaneously identifying the governing PDE. This approach yields an algorithm
that is robust to noise and can discover a range of PDEs directly from noisy,
limited measurements of their solutions. We demonstrate the efficacy of
Weak-PDE-LEARN by learning several benchmark PDEs.
</p>
</div>
</dd>
<dt><a name="item86">[86]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.04700" title="Abstract">arXiv:2309.04700</a> [<a href="/pdf/2309.04700" title="Download PDF">pdf</a>, <a href="/format/2309.04700" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> From Programming Bugs to Multimillion-Dollar Scams: An Analysis of  Trapdoor Tokens on Decentralized Exchanges
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huynh%2C+P+D">Phuong Duy Huynh</a>, 
<a href="/search/cs?searchtype=author&query=De+Silva%2C+T">Thisal De Silva</a>, 
<a href="/search/cs?searchtype=author&query=Dau%2C+S+H">Son Hoang Dau</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xiaodong Li</a>, 
<a href="/search/cs?searchtype=author&query=Gondal%2C+I">Iqbal Gondal</a>, 
<a href="/search/cs?searchtype=author&query=Viterbo%2C+E">Emanuele Viterbo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 22 pages, 11 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">The rapid development of Blockchain technology and the prosperity of
cryptocurrency in the past decade have driven the massive demand for digital
assets trading, leading to the emergence of many cryptocurrency exchange
platforms. Unlike centralised exchanges (CEXs) where listed tokens and
cryptocurrencies are assessed by authorities to make the secured trading
environment, decentralized exchanges (DEXs) are introduced to allow users to
trade their digital assets without the involvement of any third party,
therefore exposing security issues and encouraging the rise of many scams and
malicious tokens. In this paper, we investigate an emerging malicious token
named Trapdoor, which allows users to buy but prevent them from selling and
getting their funds back. The first collection of Trapdoor tokens is
constructed in this study by investigating malicious behaviours and maneuvers
of these tokens. After manually analysing the tokens' source code, we classify
those Trapdoor tokens into different categories according to their malicious
code embedding technique. Moreover, we also comprehensively analyse the impact
of Trapdoor tokens, the behaviours of scammers, and the characteristics of
victims from various perspective. Finally, we also implement and publish our
Trapdoor token detection tool and Trapdoor maneuvers analysis reports that help
in increasing awareness of investors for this kind of scam.
</p>
</div>
</dd>
<dt><a name="item87">[87]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.04702" title="Abstract">arXiv:2309.04702</a> [<a href="/pdf/2309.04702" title="Download PDF">pdf</a>, <a href="/format/2309.04702" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Spatial-Temporal Deformable Attention based Framework for Breast  Lesion Detection in Videos
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Qin%2C+C">Chao Qin</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+J">Jiale Cao</a>, 
<a href="/search/cs?searchtype=author&query=Fu%2C+H">Huazhu Fu</a>, 
<a href="/search/cs?searchtype=author&query=Anwer%2C+R+M">Rao Muhammad Anwer</a>, 
<a href="/search/cs?searchtype=author&query=Khan%2C+F+S">Fahad Shahbaz Khan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by MICCAI 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Detecting breast lesion in videos is crucial for computer-aided diagnosis.
Existing video-based breast lesion detection approaches typically perform
temporal feature aggregation of deep backbone features based on the
self-attention operation. We argue that such a strategy struggles to
effectively perform deep feature aggregation and ignores the useful local
information. To tackle these issues, we propose a spatial-temporal deformable
attention based framework, named STNet. Our STNet introduces a spatial-temporal
deformable attention module to perform local spatial-temporal feature fusion.
The spatial-temporal deformable attention module enables deep feature
aggregation in each stage of both encoder and decoder. To further accelerate
the detection speed, we introduce an encoder feature shuffle strategy for
multi-frame prediction during inference. In our encoder feature shuffle
strategy, we share the backbone and encoder features, and shuffle encoder
features for decoder to generate the predictions of multiple frames. The
experiments on the public breast lesion ultrasound video dataset show that our
STNet obtains a state-of-the-art detection performance, while operating twice
as fast inference speed. The code and model are available at
https://github.com/AlfredQin/STNet.
</p>
</div>
</dd>
<dt><a name="item88">[88]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.04703" title="Abstract">arXiv:2309.04703</a> [<a href="/pdf/2309.04703" title="Download PDF">pdf</a>, <a href="/ps/2309.04703" title="Download PostScript">ps</a>, <a href="/format/2309.04703" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Task Freshness-aware Incentive Mechanism for Vehicle Twin Migration in  Vehicular Metaverses
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wen%2C+J">Jinbo Wen</a>, 
<a href="/search/cs?searchtype=author&query=Kang%2C+J">Jiawen Kang</a>, 
<a href="/search/cs?searchtype=author&query=Xiong%2C+Z">Zehui Xiong</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Du%2C+H">Hongyang Du</a>, 
<a href="/search/cs?searchtype=author&query=Jiao%2C+Y">Yutao Jiao</a>, 
<a href="/search/cs?searchtype=author&query=Niyato%2C+D">Dusit Niyato</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>

</div>
<p class="mathjax">Vehicular metaverse, which is treated as the future continuum between
automotive industry and metaverse, is envisioned as a blended immersive domain
as the digital twins of intelligent transportation systems. Vehicles access the
vehicular metaverses by their own Vehicle Twins (VTs) (e.g., avatars) that
resource-limited vehicles offload the tasks of building VTs to their nearby
RoadSide Units (RSUs). However, due to the limited coverage of RSUs and the
mobility of vehicles, VTs have to be migrated from one RSU to other RSUs to
ensure uninterrupted metaverse services for users within vehicles. This process
requires the next RSUs to contribute sufficient bandwidth resources for VT
migrations under asymmetric information. To this end, in this paper, we design
an efficient incentive mechanism framework for VT migrations. We first propose
a novel metric named Age of Migration Task (AoMT) to quantify the task
freshness of the VT migration. AoMT measures the time elapsed from the first
collected sensing data of the freshest avatar migration task to the last
successfully processed data at the next RSU. To incentivize the contribution of
bandwidth resources among the next RSUs, we propose an AoMT-based contract
model, where the optimal contract is derived to maximize the expected utility
of the RSU that provides metaverse services. Numerical results demonstrate the
efficiency of the proposed incentive mechanism for VT migrations.
</p>
</div>
</dd>
<dt><a name="item89">[89]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.04704" title="Abstract">arXiv:2309.04704</a> [<a href="/pdf/2309.04704" title="Download PDF">pdf</a>, <a href="/format/2309.04704" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Analysis of Disinformation and Fake News Detection Using Fine-Tuned  Large Language Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pavlyshenko%2C+B+M">Bohdan M. Pavlyshenko</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Computers and Society (cs.CY); Information Retrieval (cs.IR); Machine Learning (cs.LG)

</div>
<p class="mathjax">The paper considers the possibility of fine-tuning Llama 2 large language
model (LLM) for the disinformation analysis and fake news detection. For
fine-tuning, the PEFT/LoRA based approach was used. In the study, the model was
fine-tuned for the following tasks: analysing a text on revealing
disinformation and propaganda narratives, fact checking, fake news detection,
manipulation analytics, extracting named entities with their sentiments. The
obtained results show that the fine-tuned Llama 2 model can perform a deep
analysis of texts and reveal complex styles and narratives. Extracted
sentiments for named entities can be considered as predictive features in
supervised machine learning models.
</p>
</div>
</dd>
<dt><a name="item90">[90]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.04707" title="Abstract">arXiv:2309.04707</a> [<a href="/pdf/2309.04707" title="Download PDF">pdf</a>, <a href="/format/2309.04707" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Advantage Actor-Critic with Reasoner: Explaining the Agent&#x27;s Behavior  from an Exploratory Perspective
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Guo%2C+M">Muzhe Guo</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+F">Feixu Yu</a>, 
<a href="/search/cs?searchtype=author&query=Lan%2C+T">Tian Lan</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+F">Fang Jin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Reinforcement learning (RL) is a powerful tool for solving complex
decision-making problems, but its lack of transparency and interpretability has
been a major challenge in domains where decisions have significant real-world
consequences. In this paper, we propose a novel Advantage Actor-Critic with
Reasoner (A2CR), which can be easily applied to Actor-Critic-based RL models
and make them interpretable. A2CR consists of three interconnected networks:
the Policy Network, the Value Network, and the Reasoner Network. By predefining
and classifying the underlying purpose of the actor's actions, A2CR
automatically generates a more comprehensive and interpretable paradigm for
understanding the agent's decision-making process. It offers a range of
functionalities such as purpose-based saliency, early failure detection, and
model supervision, thereby promoting responsible and trustworthy RL.
Evaluations conducted in action-rich Super Mario Bros environments yield
intriguing findings: Reasoner-predicted label proportions decrease for
``Breakout" and increase for ``Hovering" as the exploration level of the RL
algorithm intensifies. Additionally, purpose-based saliencies are more focused
and comprehensible.
</p>
</div>
</dd>
<dt><a name="item91">[91]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.04708" title="Abstract">arXiv:2309.04708</a> [<a href="/pdf/2309.04708" title="Download PDF">pdf</a>, <a href="/format/2309.04708" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> UnitModule: A Lightweight Joint Image Enhancement Module for Underwater  Object Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zhuoyan Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+B">Bo Wang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Ye Li</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+J">Jiaxian He</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yunfeng Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Underwater object detection faces the problem of underwater image
degradation, which affects the performance of the detector. Underwater object
detection methods based on noise reduction and image enhancement usually do not
provide images preferred by the detector or require additional datasets. In
this paper, we propose a plug-and-play Underwater joint image enhancement
Module (UnitModule) that provides the input image preferred by the detector. We
design an unsupervised learning loss for the joint training of UnitModule with
the detector without additional datasets to improve the interaction between
UnitModule and the detector. Furthermore, a color cast predictor with the
assisting color cast loss and a data augmentation called Underwater Color
Random Transfer (UCRT) are designed to improve the performance of UnitModule on
underwater images with different color casts. Extensive experiments are
conducted on DUO for different object detection models, where UnitModule
achieves the highest performance improvement of 2.6 AP for YOLOv5-S and gains
the improvement of 3.3 AP on the brand-new test set (URPCtest). And UnitModule
significantly improves the performance of all object detection models we test,
especially for models with a small number of parameters. In addition,
UnitModule with a small number of parameters of 31K has little effect on the
inference speed of the original object detection model. Our quantitative and
visual analysis also demonstrates the effectiveness of UnitModule in enhancing
the input image and improving the perception ability of the detector for object
features.
</p>
</div>
</dd>
<dt><a name="item92">[92]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.04709" title="Abstract">arXiv:2309.04709</a> [<a href="/pdf/2309.04709" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Public Information Precoding for MIMO Visible Light Communication  System Based on Manifold Optimization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ghazijahani%2C+H+A">Hamed Alizadeh Ghazijahani</a>, 
<a href="/search/cs?searchtype=author&query=Atashbar%2C+M">Mahmoud Atashbar</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+G+Y">Guan Yong Liang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Z">Zhaojie Yang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This paper has been submitted to an IEEE Journal
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">Visible light communication (VLC) is an attractive subset of optical
communication that provides a high data rate in the access layer of the
network. The combination of multiple inputmultiple output (MIMO) with a VLC
system leads to a higher speed of data transmission named as MIMO-VLC system.
In multi-user (MU) MIMO-VLC, a LED array transmits signals for users. These
signals are categorized as signals of private information for each user and
signals of public information for all users. The main idea of this paper is to
design an omnidirectional precoding to transmit the signals of public
information in the MUMIMO-VLC network. To this end, we propose to maximize the
achievable rate which leads to maximizing the received mean power at the
possible location of the users. Besides maximizing the achievable rate, we
consider equal mean transmission power constraint in all LEDs to achieve higher
power efficiency of the power amplifiers used in the LED array. Based on this
we formulate an optimization problem in which the constraint is in the form of
a manifold and utilize a gradient method projected on the manifold to solve the
problem. Simulation results indicate that the proposed omnidirectional
precoding can achieve superior received mean power and bit error rate with
respect to the classical form without precoding utilization.
</p>
</div>
</dd>
<dt><a name="item93">[93]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.04710" title="Abstract">arXiv:2309.04710</a> [<a href="/pdf/2309.04710" title="Download PDF">pdf</a>, <a href="/format/2309.04710" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Jade: A Differentiable Physics Engine for Articulated Rigid Bodies with  Intersection-Free Frictional Contact
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+G">Gang Yang</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+S">Siyuan Luo</a>, 
<a href="/search/cs?searchtype=author&query=Shao%2C+L">Lin Shao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV); Graphics (cs.GR); Systems and Control (eess.SY)

</div>
<p class="mathjax">We present Jade, a differentiable physics engine for articulated rigid
bodies. Jade models contacts as the Linear Complementarity Problem (LCP).
Compared to existing differentiable simulations, Jade offers features including
intersection-free collision simulation and stable LCP solutions for multiple
frictional contacts. We use continuous collision detection to detect the time
of impact and adopt the backtracking strategy to prevent intersection between
bodies with complex geometry shapes. We derive the gradient calculation to
ensure the whole simulation process is differentiable under the backtracking
mechanism. We modify the popular Dantzig algorithm to get valid solutions under
multiple frictional contacts. We conduct extensive experiments to demonstrate
the effectiveness of our differentiable physics simulation over a variety of
contact-rich tasks.
</p>
</div>
</dd>
<dt><a name="item94">[94]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.04716" title="Abstract">arXiv:2309.04716</a> [<a href="/pdf/2309.04716" title="Download PDF">pdf</a>, <a href="/format/2309.04716" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Toward Reproducing Network Research Results Using Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xiang%2C+Q">Qiao Xiang</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+Y">Yuling Lin</a>, 
<a href="/search/cs?searchtype=author&query=Fang%2C+M">Mingjun Fang</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+B">Bang Huang</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+S">Siyong Huang</a>, 
<a href="/search/cs?searchtype=author&query=Wen%2C+R">Ridi Wen</a>, 
<a href="/search/cs?searchtype=author&query=Le%2C+F">Franck Le</a>, 
<a href="/search/cs?searchtype=author&query=Kong%2C+L">Linghe Kong</a>, 
<a href="/search/cs?searchtype=author&query=Shu%2C+J">Jiwu Shu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL)

</div>
<p class="mathjax">Reproducing research results in the networking community is important for
both academia and industry. The current best practice typically resorts to
three approaches: (1) looking for publicly available prototypes; (2) contacting
the authors to get a private prototype; and (3) manually implementing a
prototype following the description of the publication. However, most published
network research does not have public prototypes and private prototypes are
hard to get. As such, most reproducing efforts are spent on manual
implementation based on the publications, which is both time and labor
consuming and error-prone. In this paper, we boldly propose reproducing network
research results using the emerging large language models (LLMs). In
particular, we first prove its feasibility with a small-scale experiment, in
which four students with essential networking knowledge each reproduces a
different networking system published in prominent conferences and journals by
prompt engineering ChatGPT. We report the experiment's observations and lessons
and discuss future open research questions of this proposal. This work raises
no ethical issue.
</p>
</div>
</dd>
<dt><a name="item95">[95]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.04720" title="Abstract">arXiv:2309.04720</a> [<a href="/pdf/2309.04720" title="Download PDF">pdf</a>, <a href="/format/2309.04720" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Compact Optical Six-Axis Force/Torque Sensor for Legged Robots Using a  Polymorphic Calibration Method
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kim%2C+H">Hyun-Bin Kim</a>, 
<a href="/search/cs?searchtype=author&query=Choi%2C+K">Keun-Ha Choi</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+H">Hyung-Soo Kim</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 13 figures, 9 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Instrumentation and Detectors (physics.ins-det)

</div>
<p class="mathjax">This paper presents a novel design for a compact, lightweight 6-axis
force/torque sensor intended for use in legged robots. The design promotes easy
manufacturing and cost reduction, while introducing innovative calibration
methods that simplify the calibration process and minimize effort. The sensor's
advantages are achieved by streamlining the structure for durability,
implementing noncontact sensors, and providing a wider sensing range compared
to commercial sensors. To maintain a simple structure, the paper proposes a
force sensing scheme using photocouplers where the sensing elements are aligned
in-plane. This strategy enables all sensing elements to be fabricated on a
single printed circuit board, eliminating manual labor tasks such as bonding
and coating the sensing elements. The prototype sensor contains only four
parts, costs less than $250, and exhibits high response frequency and
performance. Traditional calibration methods present challenges, such as the
need for specialized equipment and extensive labor. To facilitate easy
calibration without the need for specialized equipment, a new method using
optimal control is proposed. To verify the feasibility of these ideas, a
prototype six-axis F/T sensor was manufactured. Its performance was evaluated
and compared to a reference F/T sensor and previous calibration methods.
</p>
</div>
</dd>
<dt><a name="item96">[96]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.04722" title="Abstract">arXiv:2309.04722</a> [<a href="/pdf/2309.04722" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> TECVis: A Visual Analytics Tool to Compare People&#x27;s Emotion Feelings
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nemtsov%2C+I">Ilya Nemtsov</a>, 
<a href="/search/cs?searchtype=author&query=Jahan%2C+M+J">MST Jasmine Jahan</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+C">Chuting Yan</a>, 
<a href="/search/cs?searchtype=author&query=Humayoun%2C+S+R">Shah Rukh Humayoun</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 2 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">Twitter is one of the popular social media platforms where people share news
or reactions towards an event or topic using short text messages called
"tweets". Emotion analysis in these tweets can play a vital role in
understanding peoples' feelings towards the underlying event or topic. In this
work, we present our visual analytics tool, called TECVis, that focuses on
providing comparison views of peoples' emotion feelings in tweets towards an
event or topic. The comparison is done based on geolocations or timestamps.
TECVis provides several interaction and filtering options for navigation and
better exploration of underlying tweet data for emotion feelings comparison.
</p>
</div>
</dd>
<dt><a name="item97">[97]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.04723" title="Abstract">arXiv:2309.04723</a> [<a href="/pdf/2309.04723" title="Download PDF">pdf</a>, <a href="/format/2309.04723" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Frequency-Aware Self-Supervised Long-Tailed Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lin%2C+C">Ci-Siang Lin</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+M">Min-Hung Chen</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y+F">Yu-Chiang Frank Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ICCVW 2023 (Oral)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Data collected from the real world typically exhibit long-tailed
distributions, where frequent classes contain abundant data while rare ones
have only a limited number of samples. While existing supervised learning
approaches have been proposed to tackle such data imbalance, the requirement of
label supervision would limit their applicability to real-world scenarios in
which label annotation might not be available. Without the access to class
labels nor the associated class frequencies, we propose Frequency-Aware
Self-Supervised Learning (FASSL) in this paper. Targeting at learning from
unlabeled data with inherent long-tailed distributions, the goal of FASSL is to
produce discriminative feature representations for downstream classification
tasks. In FASSL, we first learn frequency-aware prototypes, reflecting the
associated long-tailed distribution. Particularly focusing on rare-class
samples, the relationships between image data and the derived prototypes are
further exploited with the introduced self-supervised learning scheme.
Experiments on long-tailed image datasets quantitatively and qualitatively
verify the effectiveness of our learning scheme.
</p>
</div>
</dd>
<dt><a name="item98">[98]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.04724" title="Abstract">arXiv:2309.04724</a> [<a href="/pdf/2309.04724" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Visual Analytic Environment to Co-locate Peoples&#x27; Tweets with City  Factual Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Patil%2C+S">Snehal Patil</a>, 
<a href="/search/cs?searchtype=author&query=Humayoun%2C+S+R">Shah Rukh Humayoun</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 2 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">Social Media platforms (e.g., Twitter, Facebook, etc.) are used heavily by
public to provide news, opinions, and reactions towards events or topics.
Integrating such data with the event or topic factual data could provide a more
comprehensive understanding of the underlying event or topic. Targeting this,
we present our visual analytics tool, called VC-FaT, that integrates peoples'
tweet data regarding crimes in San Francisco city with the city factual crime
data. VC-FaT provides a number of interactive visualizations using both data
sources for better understanding and exploration of crime activities happened
in the city during a period of five years.
</p>
</div>
</dd>
<dt><a name="item99">[99]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.04725" title="Abstract">arXiv:2309.04725</a> [<a href="/pdf/2309.04725" title="Download PDF">pdf</a>, <a href="/format/2309.04725" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> EPA: Easy Prompt Augmentation on Large Language Models via Multiple  Sources and Multiple Targets
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lu%2C+H">Hongyuan Lu</a>, 
<a href="/search/cs?searchtype=author&query=Lam%2C+W">Wai Lam</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Large language models (LLMs) have shown promising performance on various NLP
tasks via task prompting. And their performance can be further improved by
appending task demonstrations to the head of the prompt. And usually, a better
performance can be achieved with more demonstrations. However, asking the users
to write the demonstrations can be cumbersome. As a simple yet cost-effective
workaround, this paper proposes a novel method called EPA (\textbf{E}asy
\textbf{P}rompt \textbf{A}ugmentation)\footnote{While this paper considers
augmenting prompts via demonstrations, we name it EPA as the name EDA is
already taken by a well-known NLP method \citep{wei-zou-2019-eda}.} that
effectively minimizes user efforts in writing demonstrations while improving
the model performance at the same time. EPA achieves these goals by
automatically augmenting the demonstrations with multiple sources/targets,
where each of them paraphrases each other. This is well motivated as augmenting
data via paraphrasing effectively improves neural language models. EPA thus
employs paraphrasing as an augmentation method for in-context learning.
Extensive experiments indicate that EPA effectively improves both NLU and NLG
tasks, covering from natural language inference to machine translation in
translating tens of languages.\footnote{Code and data will be released upon
publication.}
</p>
</div>
</dd>
<dt><a name="item100">[100]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.04730" title="Abstract">arXiv:2309.04730</a> [<a href="/pdf/2309.04730" title="Download PDF">pdf</a>, <a href="/format/2309.04730" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Integrated Robotics Networks with Co-optimization of Drone Placement and  Air-Ground Communications
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Hu%2C+M">Menghao Hu</a>, 
<a href="/search/eess?searchtype=author&query=Zhang%2C+T">Tong Zhang</a>, 
<a href="/search/eess?searchtype=author&query=Wang%2C+S">Shuai Wang</a>, 
<a href="/search/eess?searchtype=author&query=Li%2C+G">Guoliang Li</a>, 
<a href="/search/eess?searchtype=author&query=Chen%2C+Y">Yingyang Chen</a>, 
<a href="/search/eess?searchtype=author&query=Li%2C+Q">Qiang Li</a>, 
<a href="/search/eess?searchtype=author&query=Chen%2C+G">Gaojie Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by VTC2023-Fall, 5 pages, 4 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Distributed, Parallel, and Cluster Computing (cs.DC)

</div>
<p class="mathjax">Terrestrial robots, i.e., unmanned ground vehicles (UGVs), and aerial robots,
i.e., unmanned aerial vehicles (UAVs), operate in separate spaces. To exploit
their complementary features (e.g., fields of views, communication links,
computing capabilities), a promising paradigm termed integrated robotics
network emerges, which provides communications for cooperative UAVs-UGVs
applications. However, how to efficiently deploy UAVs and schedule the
UAVs-UGVs connections according to different UGV tasks become challenging. In
this paper, we propose a sum-rate maximization problem, where UGVs plan their
trajectories autonomously and are dynamically associated with UAVs according to
their planned trajectories. Although the problem is a NP-hard mixed integer
program, a fast polynomial time algorithm using alternating gradient descent
and penalty-based binary relaxation, is devised. Simulation results demonstrate
the effectiveness of the proposed algorithm.
</p>
</div>
</dd>
<dt><a name="item101">[101]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.04732" title="Abstract">arXiv:2309.04732</a> [<a href="/pdf/2309.04732" title="Download PDF">pdf</a>, <a href="/format/2309.04732" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> TCGAN: Convolutional Generative Adversarial Network for Time Series  Classification and Clustering
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+F">Fanling Huang</a>, 
<a href="/search/cs?searchtype=author&query=Deng%2C+Y">Yangdong Deng</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Neural Networks, 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Recent works have demonstrated the superiority of supervised Convolutional
Neural Networks (CNNs) in learning hierarchical representations from time
series data for successful classification. These methods require sufficiently
large labeled data for stable learning, however acquiring high-quality labeled
time series data can be costly and potentially infeasible. Generative
Adversarial Networks (GANs) have achieved great success in enhancing
unsupervised and semi-supervised learning. Nonetheless, to our best knowledge,
it remains unclear how effectively GANs can serve as a general-purpose solution
to learn representations for time series recognition, i.e., classification and
clustering. The above considerations inspire us to introduce a Time-series
Convolutional GAN (TCGAN). TCGAN learns by playing an adversarial game between
two one-dimensional CNNs (i.e., a generator and a discriminator) in the absence
of label information. Parts of the trained TCGAN are then reused to construct a
representation encoder to empower linear recognition methods. We conducted
comprehensive experiments on synthetic and real-world datasets. The results
demonstrate that TCGAN is faster and more accurate than existing time-series
GANs. The learned representations enable simple classification and clustering
methods to achieve superior and stable performance. Furthermore, TCGAN retains
high efficacy in scenarios with few-labeled and imbalanced-labeled data. Our
work provides a promising path to effectively utilize abundant unlabeled time
series data.
</p>
</div>
</dd>
<dt><a name="item102">[102]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.04733" title="Abstract">arXiv:2309.04733</a> [<a href="/pdf/2309.04733" title="Download PDF">pdf</a>, <a href="/format/2309.04733" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Spatiotemporal Deep Neural Network for Fine-Grained Multi-Horizon Wind  Prediction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+F">Fanling Huang</a>, 
<a href="/search/cs?searchtype=author&query=Deng%2C+Y">Yangdong Deng</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Data Mining and Knowledge Discovery, 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">The prediction of wind in terms of both wind speed and direction, which has a
crucial impact on many real-world applications like aviation and wind power
generation, is extremely challenging due to the high stochasticity and
complicated correlation in the weather data. Existing methods typically focus
on a sub-set of influential factors and thus lack a systematic treatment of the
problem. In addition, fine-grained forecasting is essential for efficient
industry operations, but has been less attended in the literature. In this
work, we propose a novel data-driven model, Multi-Horizon SpatioTemporal
Network (MHSTN), generally for accurate and efficient fine-grained wind
prediction. MHSTN integrates multiple deep neural networks targeting different
factors in a sequence-to-sequence (Seq2Seq) backbone to effectively extract
features from various data sources and produce multi-horizon predictions for
all sites within a given region. MHSTN is composed of four major modules.
First, a temporal module fuses coarse-grained forecasts derived by Numerical
Weather Prediction (NWP) and historical on-site observation data at stations so
as to leverage both global and local atmospheric information. Second, a spatial
module exploits spatial correlation by modeling the joint representation of all
stations. Third, an ensemble module weighs the above two modules for final
predictions. Furthermore, a covariate selection module automatically choose
influential meteorological variables as initial input. MHSTN is already
integrated into the scheduling platform of one of the busiest international
airports of China. The evaluation results demonstrate that our model
outperforms competitors by a significant margin.
</p>
</div>
</dd>
<dt><a name="item103">[103]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.04734" title="Abstract">arXiv:2309.04734</a> [<a href="/pdf/2309.04734" title="Download PDF">pdf</a>, <a href="/format/2309.04734" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Better Multi-modal Keyphrase Generation via Visual Entity  Enhancement and Multi-granularity Image Noise Filtering
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dong%2C+Y">Yifan Dong</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+S">Suhang Wu</a>, 
<a href="/search/cs?searchtype=author&query=Meng%2C+F">Fandong Meng</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+J">Jie Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xiaoli Wang</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+J">Jianxin Lin</a>, 
<a href="/search/cs?searchtype=author&query=Su%2C+J">Jinsong Su</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted In Proceedings of the 31st ACM International Conference on Multimedia (MM' 23)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Computation and Language (cs.CL); Multimedia (cs.MM)

</div>
<p class="mathjax">Multi-modal keyphrase generation aims to produce a set of keyphrases that
represent the core points of the input text-image pair. In this regard,
dominant methods mainly focus on multi-modal fusion for keyphrase generation.
Nevertheless, there are still two main drawbacks: 1) only a limited number of
sources, such as image captions, can be utilized to provide auxiliary
information. However, they may not be sufficient for the subsequent keyphrase
generation. 2) the input text and image are often not perfectly matched, and
thus the image may introduce noise into the model. To address these
limitations, in this paper, we propose a novel multi-modal keyphrase generation
model, which not only enriches the model input with external knowledge, but
also effectively filters image noise. First, we introduce external visual
entities of the image as the supplementary input to the model, which benefits
the cross-modal semantic alignment for keyphrase generation. Second, we
simultaneously calculate an image-text matching score and image region-text
correlation scores to perform multi-granularity image noise filtering.
Particularly, we introduce the correlation scores between image regions and
ground-truth keyphrases to refine the calculation of the previously-mentioned
correlation scores. To demonstrate the effectiveness of our model, we conduct
several groups of experiments on the benchmark dataset.
<br />Experimental results and in-depth analyses show that our model achieves the
state-of-the-art performance. Our code is available on
https://github.com/DeepLearnXMU/MM-MKP.
</p>
</div>
</dd>
<dt><a name="item104">[104]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.04735" title="Abstract">arXiv:2309.04735</a> [<a href="/pdf/2309.04735" title="Download PDF">pdf</a>, <a href="/format/2309.04735" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Two-State Spin Systems with Negative Interactions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fei%2C+Y">Yumou Fei</a>, 
<a href="/search/cs?searchtype=author&query=Goldberg%2C+L+A">Leslie Ann Goldberg</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+P">Pinyan Lu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Complexity (cs.CC)</span>

</div>
<p class="mathjax">We study the approximability of computing the partition functions of
two-state spin systems. The problem is parameterized by a $2\times 2$ symmetric
matrix. Previous results on this problem were restricted either to the case
where the matrix has non-negative entries, or to the case where the diagonal
entries are equal, i.e. Ising models. In this paper, we study the
generalization to arbitrary $2\times 2$ interaction matrices with real entries.
We show that in some regions of the parameter space, it's \#P-hard to even
determine the sign of the partition function, while in other regions there are
fully polynomial approximation schemes for the partition function. Our results
reveal several new computational phase transitions.
</p>
</div>
</dd>
<dt><a name="item105">[105]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.04737" title="Abstract">arXiv:2309.04737</a> [<a href="/pdf/2309.04737" title="Download PDF">pdf</a>, <a href="/format/2309.04737" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Training of Spiking Neural Network joint Curriculum Learning Strategy
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tang%2C+L">Lingling Tang</a>, 
<a href="/search/cs?searchtype=author&query=Chu%2C+J">Jielei Chu</a>, 
<a href="/search/cs?searchtype=author&query=Gong%2C+Z">Zhiguo Gong</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+T">Tianrui Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Starting with small and simple concepts, and gradually introducing complex
and difficult concepts is the natural process of human learning. Spiking Neural
Networks (SNNs) aim to mimic the way humans process information, but current
SNNs models treat all samples equally, which does not align with the principles
of human learning and overlooks the biological plausibility of SNNs. To address
this, we propose a CL-SNN model that introduces Curriculum Learning(CL) into
SNNs, making SNNs learn more like humans and providing higher biological
interpretability. CL is a training strategy that advocates presenting easier
data to models before gradually introducing more challenging data, mimicking
the human learning process. We use a confidence-aware loss to measure and
process the samples with different difficulty levels. By learning the
confidence of different samples, the model reduces the contribution of
difficult samples to parameter optimization automatically. We conducted
experiments on static image datasets MNIST, Fashion-MNIST, CIFAR10, and
neuromorphic datasets N-MNIST, CIFAR10-DVS, DVS-Gesture. The results are
promising. To our best knowledge, this is the first proposal to enhance the
biologically plausibility of SNNs by introducing CL.
</p>
</div>
</dd>
<dt><a name="item106">[106]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.04739" title="Abstract">arXiv:2309.04739</a> [<a href="/pdf/2309.04739" title="Download PDF">pdf</a>, <a href="/ps/2309.04739" title="Download PostScript">ps</a>, <a href="/format/2309.04739" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Data Augmentation for Conversational AI
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Soudani%2C+H">Heydar Soudani</a>, 
<a href="/search/cs?searchtype=author&query=Kanoulas%2C+E">Evangelos Kanoulas</a>, 
<a href="/search/cs?searchtype=author&query=Hasibi%2C+F">Faegheh Hasibi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Information Retrieval (cs.IR)

</div>
<p class="mathjax">Advancements in conversational systems have revolutionized information
access, surpassing the limitations of single queries. However, developing
dialogue systems requires a large amount of training data, which is a challenge
in low-resource domains and languages. Traditional data collection methods like
crowd-sourcing are labor-intensive and time-consuming, making them ineffective
in this context. Data augmentation (DA) is an affective approach to alleviate
the data scarcity problem in conversational systems. This tutorial provides a
comprehensive and up-to-date overview of DA approaches in the context of
conversational systems. It highlights recent advances in conversation
augmentation, open domain and task-oriented conversation generation, and
different paradigms of evaluating these models. We also discuss current
challenges and future directions in order to help researchers and practitioners
to further advance the field in this area.
</p>
</div>
</dd>
<dt><a name="item107">[107]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.04744" title="Abstract">arXiv:2309.04744</a> [<a href="/pdf/2309.04744" title="Download PDF">pdf</a>, <a href="/ps/2309.04744" title="Download PostScript">ps</a>, <a href="/format/2309.04744" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A General Approach to Fully Linearize the Power Amplifiers in mMIMO with  Less Complexity
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Prasad%2C+G">Ganesh Prasad</a>, 
<a href="/search/cs?searchtype=author&query=Johansson%2C+H">H&#xe5;kan Johansson</a>, 
<a href="/search/cs?searchtype=author&query=Laskar%2C+R+H">Rabul Hussain Laskar</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Hardware Architecture (cs.AR)

</div>
<p class="mathjax">A radio frequency (RF) power amplifier (PA) plays an important role to
amplify the message signal at higher power to transmit it to a distant
receiver. Due to a typical nonlinear behavior of the PA at high power
transmission, a digital predistortion (DPD), exploiting the preinversion of the
nonlinearity, is used to linearize the PA. However, in a massive MIMO (mMIMO)
transmitter, a single DPD is not sufficient to fully linearize the hundreds of
PAs. Further, for the full linearization, assigning a separate DPD to each PA
is complex and not economical. In this work, we address these challenges via
the proposed low-complexity DPD (LC-DPD) scheme. Initially, we describe the
fully-featured DPD (FF-DPD) scheme to linearize the multiple PAs and examine
its complexity. Thereafter, using it, we derive the LC-DPD scheme that can
adaptively linearize the PAs as per the requirement. The coefficients in the
two schemes are learned using the algorithms that adopt indirect learning
architecture based recursive prediction error method (ILA-RPEM) due to its
adaptive and free from matrix inversion operations. Furthermore, for the LC-DPD
structure, we have proposed three algorithms based on correlation of its common
coefficients with the distinct coefficients. Lastly, the performance of the
algorithms are quantified using the obtained numerical results.
</p>
</div>
</dd>
<dt><a name="item108">[108]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.04747" title="Abstract">arXiv:2309.04747</a> [<a href="/pdf/2309.04747" title="Download PDF">pdf</a>, <a href="/format/2309.04747" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> When to Learn What: Model-Adaptive Data Augmentation Curriculum
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hou%2C+C">Chengkai Hou</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jieyu Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+T">Tianyi Zhou</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Data augmentation (DA) is widely used to improve the generalization of neural
networks by enforcing the invariances and symmetries to pre-defined
transformations applied to input data. However, a fixed augmentation policy may
have different effects on each sample in different training stages but existing
approaches cannot adjust the policy to be adaptive to each sample and the
training model. In this paper, we propose Model Adaptive Data Augmentation
(MADAug) that jointly trains an augmentation policy network to teach the model
when to learn what. Unlike previous work, MADAug selects augmentation operators
for each input image by a model-adaptive policy varying between training
stages, producing a data augmentation curriculum optimized for better
generalization. In MADAug, we train the policy through a bi-level optimization
scheme, which aims to minimize a validation-set loss of a model trained using
the policy-produced data augmentations. We conduct an extensive evaluation of
MADAug on multiple image classification tasks and network architectures with
thorough comparisons to existing DA approaches. MADAug outperforms or is on par
with other baselines and exhibits better fairness: it brings improvement to all
classes and more to the difficult ones. Moreover, MADAug learned policy shows
better performance when transferred to fine-grained datasets. In addition, the
auto-optimized policy in MADAug gradually introduces increasing perturbations
and naturally forms an easy-to-hard curriculum.
</p>
</div>
</dd>
<dt><a name="item109">[109]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.04750" title="Abstract">arXiv:2309.04750</a> [<a href="/pdf/2309.04750" title="Download PDF">pdf</a>, <a href="/format/2309.04750" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Mirror-Aware Neural Humans
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ajisafe%2C+D">Daniel Ajisafe</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+J">James Tang</a>, 
<a href="/search/cs?searchtype=author&query=Su%2C+S">Shih-Yang Su</a>, 
<a href="/search/cs?searchtype=author&query=Wandt%2C+B">Bastian Wandt</a>, 
<a href="/search/cs?searchtype=author&query=Rhodin%2C+H">Helge Rhodin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project website: <a href="https://danielajisafe.github.io/mirror-aware-neural-humans/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Human motion capture either requires multi-camera systems or is unreliable
using single-view input due to depth ambiguities. Meanwhile, mirrors are
readily available in urban environments and form an affordable alternative by
recording two views with only a single camera. However, the mirror setting
poses the additional challenge of handling occlusions of real and mirror image.
Going beyond existing mirror approaches for 3D human pose estimation, we
utilize mirrors for learning a complete body model, including shape and dense
appearance. Our main contributions are extending articulated neural radiance
fields to include a notion of a mirror, making it sample-efficient over
potential occlusion regions. Together, our contributions realize a
consumer-level 3D motion capture system that starts from off-the-shelf 2D poses
by automatically calibrating the camera, estimating mirror orientation, and
subsequently lifting 2D keypoint detections to 3D skeleton pose that is used to
condition the mirror-aware NeRF. We empirically demonstrate the benefit of
learning a body model and accounting for occlusion in challenging mirror
scenes.
</p>
</div>
</dd>
<dt><a name="item110">[110]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.04752" title="Abstract">arXiv:2309.04752</a> [<a href="/pdf/2309.04752" title="Download PDF">pdf</a>, <a href="/format/2309.04752" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deep Video Restoration for Under-Display Camera
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+X">Xuanxi Chen</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+T">Tao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Shao%2C+Z">Ziqian Shao</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+K">Kaihao Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+W">Wenhan Luo</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+T">Tong Lu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zikun Liu</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+T">Tae-Kyun Kim</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Hongdong Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Images or videos captured by the Under-Display Camera (UDC) suffer from
severe degradation, such as saturation degeneration and color shift. While
restoration for UDC has been a critical task, existing works of UDC restoration
focus only on images. UDC video restoration (UDC-VR) has not been explored in
the community. In this work, we first propose a GAN-based generation pipeline
to simulate the realistic UDC degradation process. With the pipeline, we build
the first large-scale UDC video restoration dataset called PexelsUDC, which
includes two subsets named PexelsUDC-T and PexelsUDC-P corresponding to
different displays for UDC. Using the proposed dataset, we conduct extensive
benchmark studies on existing video restoration methods and observe their
limitations on the UDC-VR task. To this end, we propose a novel
transformer-based baseline method that adaptively enhances degraded videos. The
key components of the method are a spatial branch with local-aware
transformers, a temporal branch embedded temporal transformers, and a
spatial-temporal fusion module. These components drive the model to fully
exploit spatial and temporal information for UDC-VR. Extensive experiments show
that our method achieves state-of-the-art performance on PexelsUDC. The
benchmark and the baseline method are expected to promote the progress of
UDC-VR in the community, which will be made public.
</p>
</div>
</dd>
<dt><a name="item111">[111]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.04755" title="Abstract">arXiv:2309.04755</a> [<a href="/pdf/2309.04755" title="Download PDF">pdf</a>, <a href="/format/2309.04755" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Real-time Training of Physics-informed Neural Networks:  Applications in Ultrafast Ultrasound Blood Flow Imaging
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Guan%2C+H">Haotian Guan</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+J">Jinping Dong</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+W">Wei-Ning Lee</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Engineering, Finance, and Science (cs.CE)</span>; Artificial Intelligence (cs.AI); Signal Processing (eess.SP)

</div>
<p class="mathjax">Physics-informed Neural Network (PINN) is one of the most preeminent solvers
of Navier-Stokes equations, which are widely used as the governing equation of
blood flow. However, current approaches, relying on full Navier-Stokes
equations, are impractical for ultrafast Doppler ultrasound, the
state-of-the-art technique for depiction of complex blood flow dynamics
\emph{in vivo} through acquired thousands of frames (or, timestamps) per
second. In this article, we first propose a novel training framework of PINN
for solving Navier-Stokes equations by discretizing Navier-Stokes equations
into steady state and sequentially solving steady-state Navier-Stokes equations
with transfer learning. The novel training framework is coined as SeqPINN. Upon
the success of SeqPINN, we adopt the idea of averaged constant stochastic
gradient descent (SGD) as initialization and propose a parallel training scheme
for all timestamps. To ensure an initialization that generalizes well, we
borrow the concept of Stochastic Weight Averaging Gaussian to perform
uncertainty estimation as an indicator of generalizability of the
initialization. This algorithm, named SP-PINN, further expedites training of
PINN while achieving comparable accuracy with SeqPINN. Finite-element
simulations and \emph{in vitro} phantoms of single-branch and trifurcate blood
vessels are used to evaluate the performance of SeqPINN and SP-PINN. Results
show that both SeqPINN and SP-PINN are manyfold faster than the original design
of PINN, while respectively achieving Root Mean Square Errors (RMSEs) of 1.01
cm/s and 1.26 cm/s on the straight vessel and 1.91 cm/s and 2.56 cm/s on the
trifurcate blood vessel when recovering blood flow velocities.
</p>
</div>
</dd>
<dt><a name="item112">[112]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.04756" title="Abstract">arXiv:2309.04756</a> [<a href="/pdf/2309.04756" title="Download PDF">pdf</a>, <a href="/format/2309.04756" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Probabilistic Triangulation for Uncalibrated Multi-View 3D Human Pose  Estimation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jiang%2C+B">Boyuan Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+L">Lei Hu</a>, 
<a href="/search/cs?searchtype=author&query=Xia%2C+S">Shihong Xia</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9pages, 5figures, conference
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">3D human pose estimation has been a long-standing challenge in computer
vision and graphics, where multi-view methods have significantly progressed but
are limited by the tedious calibration processes. Existing multi-view methods
are restricted to fixed camera pose and therefore lack generalization ability.
This paper presents a novel Probabilistic Triangulation module that can be
embedded in a calibrated 3D human pose estimation method, generalizing it to
uncalibration scenes. The key idea is to use a probability distribution to
model the camera pose and iteratively update the distribution from 2D features
instead of using camera pose. Specifically, We maintain a camera pose
distribution and then iteratively update this distribution by computing the
posterior probability of the camera pose through Monte Carlo sampling. This
way, the gradients can be directly back-propagated from the 3D pose estimation
to the 2D heatmap, enabling end-to-end training. Extensive experiments on
Human3.6M and CMU Panoptic demonstrate that our method outperforms other
uncalibration methods and achieves comparable results with state-of-the-art
calibration methods. Thus, our method achieves a trade-off between estimation
accuracy and generalizability. Our code is in
https://github.com/bymaths/probabilistic_triangulation
</p>
</div>
</dd>
<dt><a name="item113">[113]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.04760" title="Abstract">arXiv:2309.04760</a> [<a href="/pdf/2309.04760" title="Download PDF">pdf</a>, <a href="/format/2309.04760" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> RR-CP: Reliable-Region-Based Conformal Prediction for Trustworthy  Medical Image Classification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yizhe Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Shuo Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yejia Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+D+Z">Danny Z. Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> UNSURE2023 (Uncertainty for Safe Utilization of Machine Learning in Medical Imaging) at MICCAI2023; Spotlight
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Conformal prediction (CP) generates a set of predictions for a given test
sample such that the prediction set almost always contains the true label
(e.g., 99.5\% of the time). CP provides comprehensive predictions on possible
labels of a given test sample, and the size of the set indicates how certain
the predictions are (e.g., a set larger than one is `uncertain'). Such distinct
properties of CP enable effective collaborations between human experts and
medical AI models, allowing efficient intervention and quality check in
clinical decision-making. In this paper, we propose a new method called
Reliable-Region-Based Conformal Prediction (RR-CP), which aims to impose a
stronger statistical guarantee so that the user-specified error rate (e.g.,
0.5\%) can be achieved in the test time, and under this constraint, the size of
the prediction set is optimized (to be small). We consider a small prediction
set size an important measure only when the user-specified error rate is
achieved. Experiments on five public datasets show that our RR-CP performs
well: with a reasonably small-sized prediction set, it achieves the
user-specified error rate (e.g., 0.5\%) significantly more frequently than
exiting CP methods.
</p>
</div>
</dd>
<dt><a name="item114">[114]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.04761" title="Abstract">arXiv:2309.04761</a> [<a href="/pdf/2309.04761" title="Download PDF">pdf</a>, <a href="/format/2309.04761" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Comprehensive Survey on Deep Learning Techniques in Educational Data  Mining
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lin%2C+Y">Yuanguo Lin</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+H">Hong Chen</a>, 
<a href="/search/cs?searchtype=author&query=Xia%2C+W">Wei Xia</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+F">Fan Lin</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+P">Pengcheng Wu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zongyue Wang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yong Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 21 pages, 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computers and Society (cs.CY); Information Retrieval (cs.IR)

</div>
<p class="mathjax">Educational Data Mining (EDM) has emerged as a vital field of research, which
harnesses the power of computational techniques to analyze educational data.
With the increasing complexity and diversity of educational data, Deep Learning
techniques have shown significant advantages in addressing the challenges
associated with analyzing and modeling this data. This survey aims to
systematically review the state-of-the-art in EDM with Deep Learning. We begin
by providing a brief introduction to EDM and Deep Learning, highlighting their
relevance in the context of modern education. Next, we present a detailed
review of Deep Learning techniques applied in four typical educational
scenarios, including knowledge tracing, undesirable student detecting,
performance prediction, and personalized recommendation. Furthermore, a
comprehensive overview of public datasets and processing tools for EDM is
provided. Finally, we point out emerging trends and future directions in this
research area.
</p>
</div>
</dd>
<dt><a name="item115">[115]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.04762" title="Abstract">arXiv:2309.04762</a> [<a href="/pdf/2309.04762" title="Download PDF">pdf</a>, <a href="/format/2309.04762" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AudRandAug: Random Image Augmentations for Audio Classification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kumar%2C+T">Teerath Kumar</a>, 
<a href="/search/cs?searchtype=author&query=Turab%2C+M">Muhammad Turab</a>, 
<a href="/search/cs?searchtype=author&query=Mileo%2C+A">Alessandra Mileo</a>, 
<a href="/search/cs?searchtype=author&query=Bendechache%2C+M">Malika Bendechache</a>, 
<a href="/search/cs?searchtype=author&query=Saber%2C+T">Takfarinas Saber</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Paper has accepted at 25th Irish Machine Vision and Image Processing Conference
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG); Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">Data augmentation has proven to be effective in training neural networks.
Recently, a method called RandAug was proposed, randomly selecting data
augmentation techniques from a predefined search space. RandAug has
demonstrated significant performance improvements for image-related tasks while
imposing minimal computational overhead. However, no prior research has
explored the application of RandAug specifically for audio data augmentation,
which converts audio into an image-like pattern. To address this gap, we
introduce AudRandAug, an adaptation of RandAug for audio data. AudRandAug
selects data augmentation policies from a dedicated audio search space. To
evaluate the effectiveness of AudRandAug, we conducted experiments using
various models and datasets. Our findings indicate that AudRandAug outperforms
other existing data augmentation methods regarding accuracy performance.
</p>
</div>
</dd>
<dt><a name="item116">[116]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.04763" title="Abstract">arXiv:2309.04763</a> [<a href="/pdf/2309.04763" title="Download PDF">pdf</a>, <a href="/format/2309.04763" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Visual Material Characteristics Learning for Circular Healthcare
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zocco%2C+F">Federico Zocco</a>, 
<a href="/search/cs?searchtype=author&query=Rahimifard%2C+S">Shahin Rahimifard</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To be submitted
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">The linear take-make-dispose paradigm at the foundations of our traditional
economy is proving to be unsustainable due to waste pollution and material
supply uncertainties. Hence, increasing the circularity of material flows is
necessary. In this paper, we make a step towards circular healthcare by
developing several vision systems targeting three main circular economy tasks:
resources mapping and quantification, waste sorting, and disassembly. The
performance of our systems demonstrates that representation-learning vision can
improve the recovery chain, where autonomous systems are key enablers due to
the contamination risks. We also published two fully-annotated datasets for
image segmentation and for key-point tracking in disassembly operations of
inhalers and glucose meters. The datasets and source code are publicly
available.
</p>
</div>
</dd>
<dt><a name="item117">[117]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.04765" title="Abstract">arXiv:2309.04765</a> [<a href="/pdf/2309.04765" title="Download PDF">pdf</a>, <a href="/format/2309.04765" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> RICO-MR: An Open-Source Architecture for Robot Intent Communication  through Mixed Reality
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Macci%C3%B2%2C+S">Simone Macci&#xf2;</a>, 
<a href="/search/cs?searchtype=author&query=Shaaban%2C+M">Mohamad Shaaban</a>, 
<a href="/search/cs?searchtype=author&query=Carf%C3%AC%2C+A">Alessandro Carf&#xec;</a>, 
<a href="/search/cs?searchtype=author&query=Zaccaria%2C+R">Renato Zaccaria</a>, 
<a href="/search/cs?searchtype=author&query=Mastrogiovanni%2C+F">Fulvio Mastrogiovanni</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages, 3 figures, accepted for publication in the proceedings of the 32nd IEEE International Conference on Robot and Human Interactive Communication (RO-MAN)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">This article presents an open-source architecture for conveying robots'
intentions to human teammates using Mixed Reality and Head-Mounted Displays.
The architecture has been developed focusing on its modularity and re-usability
aspects. Both binaries and source code are available, enabling researchers and
companies to adopt the proposed architecture as a standalone solution or to
integrate it in more comprehensive implementations. Due to its scalability, the
proposed architecture can be easily employed to develop shared Mixed Reality
experiences involving multiple robots and human teammates in complex
collaborative scenarios.
</p>
</div>
</dd>
<dt><a name="item118">[118]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.04766" title="Abstract">arXiv:2309.04766</a> [<a href="/pdf/2309.04766" title="Download PDF">pdf</a>, <a href="/format/2309.04766" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SeaEval for Multilingual Foundation Models: From Cross-Lingual Alignment  to Cultural Reasoning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+B">Bin Wang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zhengyuan Liu</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+X">Xin Huang</a>, 
<a href="/search/cs?searchtype=author&query=Jiao%2C+F">Fangkai Jiao</a>, 
<a href="/search/cs?searchtype=author&query=Ding%2C+Y">Yang Ding</a>, 
<a href="/search/cs?searchtype=author&query=Aw%2C+A+T">Ai Ti Aw</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+N+F">Nancy F. Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 15 pages, 7 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">We present SeaEval, a benchmark for multilingual foundation models. In
addition to characterizing how these models understand and reason with natural
language, we also investigate how well they comprehend cultural practices,
nuances, and values. Alongside standard accuracy metrics, we investigate the
brittleness of foundation models in the dimensions of semantics and
multilinguality. Our analyses span both open-sourced and closed models, leading
to empirical results across classic NLP tasks, reasoning, and cultural
comprehension. Key findings indicate (1) Most models exhibit varied behavior
when given paraphrased instructions. (2) Many models still suffer from exposure
bias (e.g., positional bias, majority label bias). (3) For questions rooted in
factual, scientific, and commonsense knowledge, consistent responses are
expected across multilingual queries that are semantically equivalent. Yet,
most models surprisingly demonstrate inconsistent performance on these queries.
(4) Multilingually-trained models have not attained "balanced multilingual"
capabilities. Our endeavors underscore the need for more generalizable semantic
representations and enhanced multilingual contextualization. SeaEval can serve
as a launchpad for more thorough investigations and evaluations for
multilingual and multicultural scenarios.
</p>
</div>
</dd>
<dt><a name="item119">[119]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.04777" title="Abstract">arXiv:2309.04777</a> [<a href="/pdf/2309.04777" title="Download PDF">pdf</a>, <a href="/format/2309.04777" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Robust Model Watermark via Reducing Parametric Vulnerability
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gan%2C+G">Guanhao Gan</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yiming Li</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+D">Dongxian Wu</a>, 
<a href="/search/cs?searchtype=author&query=Xia%2C+S">Shu-Tao Xia</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This paper is accepted by ICCV 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
<p class="mathjax">Deep neural networks are valuable assets considering their commercial
benefits and huge demands for costly annotation and computation resources. To
protect the copyright of DNNs, backdoor-based ownership verification becomes
popular recently, in which the model owner can watermark the model by embedding
a specific backdoor behavior before releasing it. The defenders (usually the
model owners) can identify whether a suspicious third-party model is ``stolen''
from them based on the presence of the behavior. Unfortunately, these
watermarks are proven to be vulnerable to removal attacks even like
fine-tuning. To further explore this vulnerability, we investigate the
parameter space and find there exist many watermark-removed models in the
vicinity of the watermarked one, which may be easily used by removal attacks.
Inspired by this finding, we propose a mini-max formulation to find these
watermark-removed models and recover their watermark behavior. Extensive
experiments demonstrate that our method improves the robustness of the model
watermarking against parametric changes and numerous watermark-removal attacks.
The codes for reproducing our main experiments are available at
\url{https://github.com/GuanhaoGan/robust-model-watermarking}.
</p>
</div>
</dd>
<dt><a name="item120">[120]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.04780" title="Abstract">arXiv:2309.04780</a> [<a href="/pdf/2309.04780" title="Download PDF">pdf</a>, <a href="/format/2309.04780" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Latent Degradation Representation Constraint for Single Image Deraining
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=He%2C+Y">Yuhong He</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+L">Long Peng</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+L">Lu Wang</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+J">Jun Cheng</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Image and Video Processing (eess.IV)

</div>
<p class="mathjax">Since rain streaks show a variety of shapes and directions, learning the
degradation representation is extremely challenging for single image deraining.
Existing methods are mainly targeted at designing complicated modules to
implicitly learn latent degradation representation from coupled rainy images.
This way, it is hard to decouple the content-independent degradation
representation due to the lack of explicit constraint, resulting in over- or
under-enhancement problems. To tackle this issue, we propose a novel Latent
Degradation Representation Constraint Network (LDRCNet) that consists of
Direction-Aware Encoder (DAEncoder), UNet Deraining Network, and Multi-Scale
Interaction Block (MSIBlock). Specifically, the DAEncoder is proposed to
adaptively extract latent degradation representation by using the deformable
convolutions to exploit the direction consistency of rain streaks. Next, a
constraint loss is introduced to explicitly constraint the degradation
representation learning during training. Last, we propose an MSIBlock to fuse
with the learned degradation representation and decoder features of the
deraining network for adaptive information interaction, which enables the
deraining network to remove various complicated rainy patterns and reconstruct
image details. Experimental results on synthetic and real datasets demonstrate
that our method achieves new state-of-the-art performance.
</p>
</div>
</dd>
<dt><a name="item121">[121]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.04782" title="Abstract">arXiv:2309.04782</a> [<a href="/pdf/2309.04782" title="Download PDF">pdf</a>, <a href="/format/2309.04782" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> RRCNN$^{+}$: An Enhanced Residual Recursive Convolutional Neural Network  for Non-stationary Signal Decomposition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhou%2C+F">Feng Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Cicone%2C+A">Antonio Cicone</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+H">Haomin Zhou</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 4 figure
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Time-frequency analysis is an important and challenging task in many
applications. Fourier and wavelet analysis are two classic methods that have
achieved remarkable success in many fields. They also exhibit limitations when
applied to nonlinear and non-stationary signals. To address this challenge, a
series of nonlinear and adaptive methods, pioneered by the empirical mode
decomposition method have been proposed. Their aim is to decompose a
non-stationary signal into quasi-stationary components which reveal better
features in the time-frequency analysis. Recently, inspired by deep learning,
we proposed a novel method called residual recursive convolutional neural
network (RRCNN). Not only RRCNN can achieve more stable decomposition than
existing methods while batch processing large-scale signals with low
computational cost, but also deep learning provides a unique perspective for
non-stationary signal decomposition. In this study, we aim to further improve
RRCNN with the help of several nimble techniques from deep learning and
optimization to ameliorate the method and overcome some of the limitations of
this technique.
</p>
</div>
</dd>
<dt><a name="item122">[122]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.04785" title="Abstract">arXiv:2309.04785</a> [<a href="/pdf/2309.04785" title="Download PDF">pdf</a>, <a href="/format/2309.04785" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Implementation of Autonomous Supply Chains for Digital Twinning: a  Multi-Agent Approach
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+L">Liming Xu</a>, 
<a href="/search/cs?searchtype=author&query=Proselkov%2C+Y">Yaniv Proselkov</a>, 
<a href="/search/cs?searchtype=author&query=Schoepf%2C+S">Stefan Schoepf</a>, 
<a href="/search/cs?searchtype=author&query=Minarsch%2C+D">David Minarsch</a>, 
<a href="/search/cs?searchtype=author&query=Minaricova%2C+M">Maria Minaricova</a>, 
<a href="/search/cs?searchtype=author&query=Brintrup%2C+A">Alexandra Brintrup</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This paper includes 7 Pages, 4 Figures, and has been accepted by the IFAC World Congress 2023, 9 July - 14 July, 2023, Yokohama, Japan and will be published in IFAC-PapersOnLine
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Multiagent Systems (cs.MA)</span>; Computers and Society (cs.CY)

</div>
<p class="mathjax">Trade disruptions, the pandemic, and the Ukraine war over the past years have
adversely affected global supply chains, revealing their vulnerability.
Autonomous supply chains are an emerging topic that has gained attention in
industry and academia as a means of increasing their monitoring and robustness.
While many theoretical frameworks exist, there is only sparse work to
facilitate generalisable technical implementation. We address this gap by
investigating multi-agent system approaches for implementing autonomous supply
chains, presenting an autonomous economic agent-based technical framework. We
illustrate this framework with a prototype, studied in a perishable food supply
chain scenario, and discuss possible extensions.
</p>
</div>
</dd>
<dt><a name="item123">[123]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.04788" title="Abstract">arXiv:2309.04788</a> [<a href="/pdf/2309.04788" title="Download PDF">pdf</a>, <a href="/format/2309.04788" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Stochastic Gradient Descent outperforms Gradient Descent in recovering a  high-dimensional signal in a glassy energy landscape
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kamali%2C+P+J">Persia Jana Kamali</a>, 
<a href="/search/cs?searchtype=author&query=Urbani%2C+P">Pierfrancesco Urbani</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages + appendix. 3 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Disordered Systems and Neural Networks (cond-mat.dis-nn)

</div>
<p class="mathjax">Stochastic Gradient Descent (SGD) is an out-of-equilibrium algorithm used
extensively to train artificial neural networks. However very little is known
on to what extent SGD is crucial for to the success of this technology and, in
particular, how much it is effective in optimizing high-dimensional non-convex
cost functions as compared to other optimization algorithms such as Gradient
Descent (GD). In this work we leverage dynamical mean field theory to analyze
exactly its performances in the high-dimensional limit. We consider the problem
of recovering a hidden high-dimensional non-linearly encrypted signal, a
prototype high-dimensional non-convex hard optimization problem. We compare the
performances of SGD to GD and we show that SGD largely outperforms GD. In
particular, a power law fit of the relaxation time of these algorithms shows
that the recovery threshold for SGD with small batch size is smaller than the
corresponding one of GD.
</p>
</div>
</dd>
<dt><a name="item124">[124]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.04789" title="Abstract">arXiv:2309.04789</a> [<a href="/pdf/2309.04789" title="Download PDF">pdf</a>, <a href="/format/2309.04789" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Local Certification of Some Geometric Intersection Graph Classes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jauregui%2C+B">Benjam&#xed;n Jauregui</a>, 
<a href="/search/cs?searchtype=author&query=Montealegre%2C+P">Pedro Montealegre</a>, 
<a href="/search/cs?searchtype=author&query=Ram%C3%ADrez-Romero%2C+D">Diego Ram&#xed;rez-Romero</a>, 
<a href="/search/cs?searchtype=author&query=Rapaport%2C+I">Ivan Rapaport</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>

</div>
<p class="mathjax">In the context of distributed certification, the recognition of graph classes
has started to be intensively studied. For instance, different results related
to the recognition of planar, bounded tree-width and $H$-minor free graphs have
been recently obtained. The goal of the present work is to design compact
certificates for the local recognition of relevant geometric intersection graph
classes, namely interval, chordal, circular arc, trapezoid and permutation.
More precisely, we give proof labeling schemes recognizing each of these
classes with logarithmic-sized certificates. We also provide tight logarithmic
lower bounds on the size of the certificates on the proof labeling schemes for
the recognition of any of the aforementioned geometric intersection graph
classes.
</p>
</div>
</dd>
<dt><a name="item125">[125]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.04790" title="Abstract">arXiv:2309.04790</a> [<a href="/pdf/2309.04790" title="Download PDF">pdf</a>, <a href="/format/2309.04790" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MMHQA-ICL: Multimodal In-context Learning for Hybrid Question Answering  over Text, Tables and Images
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+W">Weihao Liu</a>, 
<a href="/search/cs?searchtype=author&query=Lei%2C+F">Fangyu Lei</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+T">Tongxu Luo</a>, 
<a href="/search/cs?searchtype=author&query=Lei%2C+J">Jiahe Lei</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+S">Shizhu He</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+J">Jun Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+K">Kang Liu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">In the real world, knowledge often exists in a multimodal and heterogeneous
form. Addressing the task of question answering with hybrid data types,
including text, tables, and images, is a challenging task (MMHQA). Recently,
with the rise of large language models (LLM), in-context learning (ICL) has
become the most popular way to solve QA problems. We propose MMHQA-ICL
framework for addressing this problems, which includes stronger heterogeneous
data retriever and an image caption module. Most importantly, we propose a
Type-specific In-context Learning Strategy for MMHQA, enabling LLMs to leverage
their powerful performance in this task. We are the first to use end-to-end LLM
prompting method for this task. Experimental results demonstrate that our
framework outperforms all baselines and methods trained on the full dataset,
achieving state-of-the-art results under the few-shot setting on the
MultimodalQA dataset.
</p>
</div>
</dd>
<dt><a name="item126">[126]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.04791" title="Abstract">arXiv:2309.04791</a> [<a href="/pdf/2309.04791" title="Download PDF">pdf</a>, <a href="/format/2309.04791" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> osmAG: Hierarchical Semantic Topometric Area Graph Maps in the OSM  Format for Mobile Robotics
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Feng%2C+D">Delin Feng</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+C">Chengqian Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yongqi Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+C">Chen Yu</a>, 
<a href="/search/cs?searchtype=author&query=Schwertfeger%2C+S">Soeren Schwertfeger</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Maps are essential to mobile robotics tasks like localization and planning.
We propose the open street map (osm) XML based Area Graph file format to store
hierarchical, topometric semantic multi-floor maps of indoor and outdoor
environments, since currently no such format is popular within the robotics
community. Building on-top of osm we leverage the available open source editing
tools and libraries of osm, while adding the needed mobile robotics aspect with
building-level obstacle representation yet very compact, topometric data that
facilitates planning algorithms. Through the use of common osm keys as well as
custom ones we leverage the power of semantic annotation to enable various
applications. For example, we support planning based on robot capabilities, to
take the locomotion mode and attributes in conjunction with the environment
information into account. The provided C++ library is integrated into ROS. We
evaluate the performance of osmAG using real data in a global path planning
application on a very big osmAG map, demonstrating its convenience and
effectiveness for mobile robots.
</p>
</div>
</dd>
<dt><a name="item127">[127]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.04795" title="Abstract">arXiv:2309.04795</a> [<a href="/pdf/2309.04795" title="Download PDF">pdf</a>, <a href="/format/2309.04795" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Self-Supervised Transformer with Domain Adaptive Reconstruction for  General Face Forgery Video Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+D">Daichi Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Xiao%2C+Z">Zihao Xiao</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jianmin Li</a>, 
<a href="/search/cs?searchtype=author&query=Ge%2C+S">Shiming Ge</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Face forgery videos have caused severe social public concern, and various
detectors have been proposed recently. However, most of them are trained in a
supervised manner with limited generalization when detecting videos from
different forgery methods or real source videos. To tackle this issue, we
explore to take full advantage of the difference between real and forgery
videos by only exploring the common representation of real face videos. In this
paper, a Self-supervised Transformer cooperating with Contrastive and
Reconstruction learning (CoReST) is proposed, which is first pre-trained only
on real face videos in a self-supervised manner, and then fine-tuned a linear
head on specific face forgery video datasets. Two specific auxiliary tasks
incorporated contrastive and reconstruction learning are designed to enhance
the representation learning. Furthermore, a Domain Adaptive Reconstruction
(DAR) module is introduced to bridge the gap between different forgery domains
by reconstructing on unlabeled target videos when fine-tuning. Extensive
experiments on public datasets demonstrate that our proposed method performs
even better than the state-of-the-art supervised competitors with impressive
generalization.
</p>
</div>
</dd>
<dt><a name="item128">[128]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.04797" title="Abstract">arXiv:2309.04797</a> [<a href="/pdf/2309.04797" title="Download PDF">pdf</a>, <a href="/format/2309.04797" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Full-fledged Commit Message Quality Checker Based on Machine Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Farag%C3%B3%2C+D">David Farag&#xf3;</a>, 
<a href="/search/cs?searchtype=author&query=F%C3%A4rber%2C+M">Michael F&#xe4;rber</a>, 
<a href="/search/cs?searchtype=author&query=Petrov%2C+C">Christian Petrov</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> published at COMPSAC'23
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Commit messages (CMs) are an essential part of version control. By providing
important context in regard to what has changed and why, they strongly support
software maintenance and evolution. But writing good CMs is difficult and often
neglected by developers. So far, there is no tool suitable for practice that
automatically assesses how well a CM is written, including its meaning and
context. Since this task is challenging, we ask the research question: how well
can the CM quality, including semantics and context, be measured with machine
learning methods? By considering all rules from the most popular CM quality
guideline, creating datasets for those rules, and training and evaluating
state-of-the-art machine learning models to check those rules, we can answer
the research question with: sufficiently well for practice, with the lowest
F$_1$ score of 82.9\%, for the most challenging task. We develop a full-fledged
open-source framework that checks all these CM quality rules. It is useful for
research, e.g., automatic CM generation, but most importantly for software
practitioners to raise the quality of CMs and thus the maintainability and
evolution speed of their software.
</p>
</div>
</dd>
<dt><a name="item129">[129]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.04798" title="Abstract">arXiv:2309.04798</a> [<a href="/pdf/2309.04798" title="Download PDF">pdf</a>, <a href="/format/2309.04798" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Low-Quality Training Data Only? A Robust Framework for Detecting  Encrypted Malicious Network Traffic
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Qing%2C+Y">Yuqi Qing</a>, 
<a href="/search/cs?searchtype=author&query=Yin%2C+Q">Qilei Yin</a>, 
<a href="/search/cs?searchtype=author&query=Deng%2C+X">Xinhao Deng</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yihao Chen</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zhuotao Liu</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+K">Kun Sun</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+K">Ke Xu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jia Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Q">Qi Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">Machine learning (ML) is promising in accurately detecting malicious flows in
encrypted network traffic; however, it is challenging to collect a training
dataset that contains a sufficient amount of encrypted malicious data with
correct labels. When ML models are trained with low-quality training data, they
suffer degraded performance. In this paper, we aim at addressing a real-world
low-quality training dataset problem, namely, detecting encrypted malicious
traffic generated by continuously evolving malware. We develop RAPIER that
fully utilizes different distributions of normal and malicious traffic data in
the feature space, where normal data is tightly distributed in a certain area
and the malicious data is scattered over the entire feature space to augment
training data for model training. RAPIER includes two pre-processing modules to
convert traffic into feature vectors and correct label noises. We evaluate our
system on two public datasets and one combined dataset. With 1000 samples and
45% noises from each dataset, our system achieves the F1 scores of 0.770,
0.776, and 0.855, respectively, achieving average improvements of 352.6%,
284.3%, and 214.9% over the existing methods, respectively. Furthermore, We
evaluate RAPIER with a real-world dataset obtained from a security enterprise.
RAPIER effectively achieves encrypted malicious traffic detection with the best
F1 score of 0.773 and improves the F1 score of existing methods by an average
of 272.5%.
</p>
</div>
</dd>
<dt><a name="item130">[130]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.04799" title="Abstract">arXiv:2309.04799</a> [<a href="/pdf/2309.04799" title="Download PDF">pdf</a>, <a href="/format/2309.04799" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Benne: A Modular and Self-Optimizing Algorithm for Data Stream  Clustering
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zhengru Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xin Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+S">Shuhao Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Databases (cs.DB)</span>

</div>
<p class="mathjax">In various real-world applications, ranging from the Internet of Things (IoT)
to social media and financial systems, data stream clustering is a critical
operation. This paper introduces Benne, a modular and highly configurable data
stream clustering algorithm designed to offer a nuanced balance between
clustering accuracy and computational efficiency. Benne distinguishes itself by
clearly demarcating four pivotal design dimensions: the summarizing data
structure, the window model for handling data temporality, the outlier
detection mechanism, and the refinement strategy for improving cluster quality.
This clear separation not only facilitates a granular understanding of the
impact of each design choice on the algorithm's performance but also enhances
the algorithm's adaptability to a wide array of application contexts. We
provide a comprehensive analysis of these design dimensions, elucidating the
challenges and opportunities inherent to each. Furthermore, we conduct a
rigorous performance evaluation of Benne, employing diverse configurations and
benchmarking it against existing state-of-the-art data stream clustering
algorithms. Our empirical results substantiate that Benne either matches or
surpasses competing algorithms in terms of clustering accuracy, processing
throughput, and adaptability to varying data stream characteristics. This
establishes Benne as a valuable asset for both practitioners and researchers in
the field of data stream mining.
</p>
</div>
</dd>
<dt><a name="item131">[131]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.04800" title="Abstract">arXiv:2309.04800</a> [<a href="/pdf/2309.04800" title="Download PDF">pdf</a>, <a href="/format/2309.04800" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> VeRi3D: Generative Vertex-based Radiance Fields for 3D Controllable  Human Image Synthesis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+X">Xinya Chen</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+J">Jiaxin Huang</a>, 
<a href="/search/cs?searchtype=author&query=Bin%2C+Y">Yanrui Bin</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+L">Lu Yu</a>, 
<a href="/search/cs?searchtype=author&query=Liao%2C+Y">Yiyi Liao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Unsupervised learning of 3D-aware generative adversarial networks has lately
made much progress. Some recent work demonstrates promising results of learning
human generative models using neural articulated radiance fields, yet their
generalization ability and controllability lag behind parametric human models,
i.e., they do not perform well when generalizing to novel pose/shape and are
not part controllable. To solve these problems, we propose VeRi3D, a generative
human vertex-based radiance field parameterized by vertices of the parametric
human template, SMPL. We map each 3D point to the local coordinate system
defined on its neighboring vertices, and use the corresponding vertex feature
and local coordinates for mapping it to color and density values. We
demonstrate that our simple approach allows for generating photorealistic human
images with free control over camera pose, human pose, shape, as well as
enabling part-level editing.
</p>
</div>
</dd>
<dt><a name="item132">[132]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.04801" title="Abstract">arXiv:2309.04801</a> [<a href="/pdf/2309.04801" title="Download PDF">pdf</a>, <a href="/format/2309.04801" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> TMComposites: Plug-and-Play Collaboration Between Specialized Tsetlin  Machines
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Granmo%2C+O">Ole-Christoffer Granmo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 6 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Tsetlin Machines (TMs) provide a fundamental shift from arithmetic-based to
logic-based machine learning. Supporting convolution, they deal successfully
with image classification datasets like MNIST, Fashion-MNIST, and CIFAR-2.
However, the TM struggles with getting state-of-the-art performance on CIFAR-10
and CIFAR-100, representing more complex tasks. This paper introduces
plug-and-play collaboration between specialized TMs, referred to as TM
Composites. The collaboration relies on a TM's ability to specialize during
learning and to assess its competence during inference. When teaming up, the
most confident TMs make the decisions, relieving the uncertain ones. In this
manner, a TM Composite becomes more competent than its members, benefiting from
their specializations. The collaboration is plug-and-play in that members can
be combined in any way, at any time, without fine-tuning. We implement three TM
specializations in our empirical evaluation: Histogram of Gradients, Adaptive
Gaussian Thresholding, and Color Thermometers. The resulting TM Composite
increases accuracy on Fashion-MNIST by two percentage points, CIFAR-10 by
twelve points, and CIFAR-100 by nine points, yielding new state-of-the-art
results for TMs. Overall, we envision that TM Composites will enable an
ultra-low energy and transparent alternative to state-of-the-art deep learning
on more tasks and datasets.
</p>
</div>
</dd>
<dt><a name="item133">[133]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.04802" title="Abstract">arXiv:2309.04802</a> [<a href="/pdf/2309.04802" title="Download PDF">pdf</a>, <a href="/format/2309.04802" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CPMR: Context-Aware Incremental Sequential Recommendation with  Pseudo-Multi-Task Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bian%2C+Q">Qingtian Bian</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+J">Jiaxing Xu</a>, 
<a href="/search/cs?searchtype=author&query=Fang%2C+H">Hui Fang</a>, 
<a href="/search/cs?searchtype=author&query=Ke%2C+Y">Yiping Ke</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by CIKM 2023
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> ACM International Conference on Information and Knowledge
  Management(CIKM '23), October 21-25,2023,Birmingham,United Kingdom
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">The motivations of users to make interactions can be divided into static
preference and dynamic interest. To accurately model user representations over
time, recent studies in sequential recommendation utilize information
propagation and evolution to mine from batches of arriving interactions.
However, they ignore the fact that people are easily influenced by the recent
actions of other users in the contextual scenario, and applying evolution
across all historical interactions dilutes the importance of recent ones, thus
failing to model the evolution of dynamic interest accurately. To address this
issue, we propose a Context-Aware Pseudo-Multi-Task Recommender System (CPMR)
to model the evolution in both historical and contextual scenarios by creating
three representations for each user and item under different dynamics: static
embedding, historical temporal states, and contextual temporal states. To
dually improve the performance of temporal states evolution and incremental
recommendation, we design a Pseudo-Multi-Task Learning (PMTL) paradigm by
stacking the incremental single-target recommendations into one multi-target
task for joint optimization. Within the PMTL paradigm, CPMR employs a
shared-bottom network to conduct the evolution of temporal states across
historical and contextual scenarios, as well as the fusion of them at the
user-item level. In addition, CPMR incorporates one real tower for incremental
predictions, and two pseudo towers dedicated to updating the respective
temporal states based on new batches of interactions. Experimental results on
four benchmark recommendation datasets show that CPMR consistently outperforms
state-of-the-art baselines and achieves significant gains on three of them. The
code is available at: https://github.com/DiMarzioBian/CPMR.
</p>
</div>
</dd>
<dt><a name="item134">[134]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.04803" title="Abstract">arXiv:2309.04803</a> [<a href="/pdf/2309.04803" title="Download PDF">pdf</a>, <a href="/format/2309.04803" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Real-World Burst Image Super-Resolution: Benchmark and Method
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wei%2C+P">Pengxu Wei</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+Y">Yujing Sun</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+X">Xingbei Guo</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+C">Chang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Jie Chen</a>, 
<a href="/search/cs?searchtype=author&query=Ji%2C+X">Xiangyang Ji</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+L">Liang Lin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by ICCV2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Despite substantial advances, single-image super-resolution (SISR) is always
in a dilemma to reconstruct high-quality images with limited information from
one input image, especially in realistic scenarios. In this paper, we establish
a large-scale real-world burst super-resolution dataset, i.e., RealBSR, to
explore the faithful reconstruction of image details from multiple frames.
Furthermore, we introduce a Federated Burst Affinity network (FBAnet) to
investigate non-trivial pixel-wise displacements among images under real-world
image degradation. Specifically, rather than using pixel-wise alignment, our
FBAnet employs a simple homography alignment from a structural geometry aspect
and a Federated Affinity Fusion (FAF) strategy to aggregate the complementary
information among frames. Those fused informative representations are fed to a
Transformer-based module of burst representation decoding. Besides, we have
conducted extensive experiments on two versions of our datasets, i.e.,
RealBSR-RAW and RealBSR-RGB. Experimental results demonstrate that our FBAnet
outperforms existing state-of-the-art burst SR methods and also achieves
visually-pleasant SR image predictions with model details. Our dataset, codes,
and models are publicly available at https://github.com/yjsunnn/FBANet.
</p>
</div>
</dd>
<dt><a name="item135">[135]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.04806" title="Abstract">arXiv:2309.04806</a> [<a href="/pdf/2309.04806" title="Download PDF">pdf</a>, <a href="/format/2309.04806" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Timely Fusion of Surround Radar/Lidar for Object Detection in Autonomous  Driving Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xie%2C+W">Wenjing Xie</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+T">Tao Hu</a>, 
<a href="/search/cs?searchtype=author&query=Ling%2C+N">Neiwen Ling</a>, 
<a href="/search/cs?searchtype=author&query=Xing%2C+G">Guoliang Xing</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+S">Shaoshan Liu</a>, 
<a href="/search/cs?searchtype=author&query=Guan%2C+N">Nan Guan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at DATE 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Fusing Radar and Lidar sensor data can fully utilize their complementary
advantages and provide more accurate reconstruction of the surrounding for
autonomous driving systems. Surround Radar/Lidar can provide 360-degree view
sampling with the minimal cost, which are promising sensing hardware solutions
for autonomous driving systems. However, due to the intrinsic physical
constraints, the rotating speed of surround Radar, and thus the frequency to
generate Radar data frames, is much lower than surround Lidar. Existing
Radar/Lidar fusion methods have to work at the low frequency of surround Radar,
which cannot meet the high responsiveness requirement of autonomous driving
systems.This paper develops techniques to fuse surround Radar/Lidar with
working frequency only limited by the faster surround Lidar instead of the
slower surround Radar, based on the state-of-the-art object detection model
MVDNet. The basic idea of our approach is simple: we let MVDNet work with
temporally unaligned data from Radar/Lidar, so that fusion can take place at
any time when a new Lidar data frame arrives, instead of waiting for the slow
Radar data frame. However, directly applying MVDNet to temporally unaligned
Radar/Lidar data greatly degrades its object detection accuracy. The key
information revealed in this paper is that we can achieve high output frequency
with little accuracy loss by enhancing the training procedure to explore the
temporal redundancy in MVDNet so that it can tolerate the temporal unalignment
of input data. We explore several different ways of training enhancement and
compare them quantitatively with experiments.
</p>
</div>
</dd>
<dt><a name="item136">[136]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.04807" title="Abstract">arXiv:2309.04807</a> [<a href="/pdf/2309.04807" title="Download PDF">pdf</a>, <a href="/ps/2309.04807" title="Download PostScript">ps</a>, <a href="/format/2309.04807" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Linear convergence of the Collatz method for computing the Perron  eigenpair of primitive dual number matrix
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Chen%2C+Y">Yongjun Chen</a>, 
<a href="/search/math?searchtype=author&query=Zhang%2C+L">Liping Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: text overlap with <a href="/abs/2306.16140">arXiv:2306.16140</a> by other authors
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">Very recently, Qi and Cui extended the Perron-Frobenius theory to dual number
matrices with primitive and irreducible nonnegative standard parts and proved
that they have Perron eigenpair and Perron-Frobenius eigenpair. The Collatz
method was also extended to find Perron eigenpair. Qi and Cui proposed two
conjectures. One is the k-order power of a dual number matrix tends to zero if
and only if the spectral radius of its standard part less than one, and another
is the linear convergence of the Collatz method. In this paper, we confirm
these conjectures and provide theoretical proof. The main contribution is to
show that the Collatz method R-linearly converges with an explicit rate.
</p>
</div>
</dd>
<dt><a name="item137">[137]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.04810" title="Abstract">arXiv:2309.04810</a> [<a href="/pdf/2309.04810" title="Download PDF">pdf</a>, <a href="/format/2309.04810" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Neural Latent Geometry Search: Product Manifold Inference via  Gromov-Hausdorff-Informed Bayesian Optimization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=de+Ocariz+Borde%2C+H+S">Haitz Saez de Ocariz Borde</a>, 
<a href="/search/cs?searchtype=author&query=Arroyo%2C+A">Alvaro Arroyo</a>, 
<a href="/search/cs?searchtype=author&query=Morales%2C+I">Ismael Morales</a>, 
<a href="/search/cs?searchtype=author&query=Posner%2C+I">Ingmar Posner</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+X">Xiaowen Dong</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
<p class="mathjax">Recent research indicates that the performance of machine learning models can
be improved by aligning the geometry of the latent space with the underlying
data structure. Rather than relying solely on Euclidean space, researchers have
proposed using hyperbolic and spherical spaces with constant curvature, or
combinations thereof, to better model the latent space and enhance model
performance. However, little attention has been given to the problem of
automatically identifying the optimal latent geometry for the downstream task.
We mathematically define this novel formulation and coin it as neural latent
geometry search (NLGS). More specifically, we introduce a principled method
that searches for a latent geometry composed of a product of constant curvature
model spaces with minimal query evaluations. To accomplish this, we propose a
novel notion of distance between candidate latent geometries based on the
Gromov-Hausdorff distance from metric geometry. In order to compute the
Gromov-Hausdorff distance, we introduce a mapping function that enables the
comparison of different manifolds by embedding them in a common
high-dimensional ambient space. Finally, we design a graph search space based
on the calculated distances between candidate manifolds and use Bayesian
optimization to search for the optimal latent geometry in a query-efficient
manner. This is a general method which can be applied to search for the optimal
latent geometry for a variety of models and downstream tasks. Extensive
experiments on synthetic and real-world datasets confirm the efficacy of our
method in identifying the optimal latent geometry for multiple machine learning
problems.
</p>
</div>
</dd>
<dt><a name="item138">[138]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.04814" title="Abstract">arXiv:2309.04814</a> [<a href="/pdf/2309.04814" title="Download PDF">pdf</a>, <a href="/format/2309.04814" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Speech2Lip: High-fidelity Speech to Lip Generation by Learning from a  Short Video
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+X">Xiuzhe Wu</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+P">Pengfei Hu</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Y">Yang Wu</a>, 
<a href="/search/cs?searchtype=author&query=Lyu%2C+X">Xiaoyang Lyu</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+Y">Yan-Pei Cao</a>, 
<a href="/search/cs?searchtype=author&query=Shan%2C+Y">Ying Shan</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+W">Wenming Yang</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+Z">Zhongqian Sun</a>, 
<a href="/search/cs?searchtype=author&query=Qi%2C+X">Xiaojuan Qi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Synthesizing realistic videos according to a given speech is still an open
challenge. Previous works have been plagued by issues such as inaccurate lip
shape generation and poor image quality. The key reason is that only motions
and appearances on limited facial areas (e.g., lip area) are mainly driven by
the input speech. Therefore, directly learning a mapping function from speech
to the entire head image is prone to ambiguity, particularly when using a short
video for training. We thus propose a decomposition-synthesis-composition
framework named Speech to Lip (Speech2Lip) that disentangles speech-sensitive
and speech-insensitive motion/appearance to facilitate effective learning from
limited training data, resulting in the generation of natural-looking videos.
First, given a fixed head pose (i.e., canonical space), we present a
speech-driven implicit model for lip image generation which concentrates on
learning speech-sensitive motion and appearance. Next, to model the major
speech-insensitive motion (i.e., head movement), we introduce a geometry-aware
mutual explicit mapping (GAMEM) module that establishes geometric mappings
between different head poses. This allows us to paste generated lip images at
the canonical space onto head images with arbitrary poses and synthesize
talking videos with natural head movements. In addition, a Blend-Net and a
contrastive sync loss are introduced to enhance the overall synthesis
performance. Quantitative and qualitative results on three benchmarks
demonstrate that our model can be trained by a video of just a few minutes in
length and achieve state-of-the-art performance in both visual quality and
speech-visual synchronization. Code: https://github.com/CVMI-Lab/Speech2Lip.
</p>
</div>
</dd>
<dt><a name="item139">[139]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.04820" title="Abstract">arXiv:2309.04820</a> [<a href="/pdf/2309.04820" title="Download PDF">pdf</a>, <a href="/format/2309.04820" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ABC Easy as 123: A Blind Counter for Exemplar-Free Multi-Class  Class-agnostic Counting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hobley%2C+M+A">Michael A. Hobley</a>, 
<a href="/search/cs?searchtype=author&query=Prisacariu%2C+V+A">Victor A. Prisacariu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Class-agnostic counting methods enumerate objects of an arbitrary class,
providing tremendous utility in many fields. Prior works have limited
usefulness as they require either a set of examples of the type to be counted
or that the image contains only a single type of object. A significant factor
in these shortcomings is the lack of a dataset to properly address counting in
settings with more than one kind of object present. To address these issues, we
propose the first Multi-class, Class-Agnostic Counting dataset (MCAC) and A
Blind Counter (ABC123), a method that can count multiple types of objects
simultaneously without using examples of type during training or inference.
ABC123 introduces a new paradigm where instead of requiring exemplars to guide
the enumeration, examples are found after the counting stage to help a user
understand the generated outputs. We show that ABC123 outperforms contemporary
methods on MCAC without the requirement of human in-the-loop annotations. We
also show that this performance transfers to FSC-147, the standard
class-agnostic counting dataset.
</p>
</div>
</dd>
<dt><a name="item140">[140]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.04823" title="Abstract">arXiv:2309.04823</a> [<a href="/pdf/2309.04823" title="Download PDF">pdf</a>, <a href="/format/2309.04823" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FaNS: a Facet-based Narrative Similarity Metric
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Akter%2C+M">Mousumi Akter</a>, 
<a href="/search/cs?searchtype=author&query=Santu%2C+S+K+K">Shubhra Kanti Karmaker Santu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Similar Narrative Retrieval is a crucial task since narratives are essential
for explaining and understanding events, and multiple related narratives often
help to create a holistic view of the event of interest. To accurately identify
semantically similar narratives, this paper proposes a novel narrative
similarity metric called Facet-based Narrative Similarity (FaNS), based on the
classic 5W1H facets (Who, What, When, Where, Why, and How), which are extracted
by leveraging the state-of-the-art Large Language Models (LLMs). Unlike
existing similarity metrics that only focus on overall lexical/semantic match,
FaNS provides a more granular matching along six different facets independently
and then combines them. To evaluate FaNS, we created a comprehensive dataset by
collecting narratives from AllSides, a third-party news portal. Experimental
results demonstrate that the FaNS metric exhibits a higher correlation (37\%
higher) than traditional text similarity metrics that directly measure the
lexical/semantic match between narratives, demonstrating its effectiveness in
comparing the finer details between a pair of narratives.
</p>
</div>
</dd>
<dt><a name="item141">[141]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.04824" title="Abstract">arXiv:2309.04824</a> [<a href="/pdf/2309.04824" title="Download PDF">pdf</a>, <a href="/format/2309.04824" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Correcting sampling biases via importancereweighting for spatial  modeling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Prokhorov%2C+B">Boris Prokhorov</a>, 
<a href="/search/cs?searchtype=author&query=Koldasbayeva%2C+D">Diana Koldasbayeva</a>, 
<a href="/search/cs?searchtype=author&query=Zaytsev%2C+A">Alexey Zaytsev</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">In machine learning models, the estimation of errors is often complex due to
distribution bias, particularly in spatial data such as those found in
environmental studies. We introduce an approach based on the ideas of
importance sampling to obtain an unbiased estimate of the target error. By
taking into account difference between desirable error and available data, our
method reweights errors at each sample point and neutralizes the shift.
Importance sampling technique and kernel density estimation were used for
reweighteing. We validate the effectiveness of our approach using artificial
data that resemble real-world spatial datasets. Our findings demonstrate
advantages of the proposed approach for the estimation of the target error,
offering a solution to a distribution shift problem. Overall error of
predictions dropped from 7% to just 2% and it gets smaller for larger samples.
</p>
</div>
</dd>
<dt><a name="item142">[142]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.04825" title="Abstract">arXiv:2309.04825</a> [<a href="/pdf/2309.04825" title="Download PDF">pdf</a>, <a href="/format/2309.04825" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Few-Shot Medical Image Segmentation via a Region-enhanced Prototypical  Transformer
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhu%2C+Y">Yazhou Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Shidong Wang</a>, 
<a href="/search/cs?searchtype=author&query=Xin%2C+T">Tong Xin</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Haofeng Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by MICCAI
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Automated segmentation of large volumes of medical images is often plagued by
the limited availability of fully annotated data and the diversity of organ
surface properties resulting from the use of different acquisition protocols
for different patients. In this paper, we introduce a more promising few-shot
learning-based method named Region-enhanced Prototypical Transformer (RPT) to
mitigate the effects of large intra-class diversity/bias. First, a subdivision
strategy is introduced to produce a collection of regional prototypes from the
foreground of the support prototype. Second, a self-selection mechanism is
proposed to incorporate into the Bias-alleviated Transformer (BaT) block to
suppress or remove interferences present in the query prototype and regional
support prototypes. By stacking BaT blocks, the proposed RPT can iteratively
optimize the generated regional prototypes and finally produce rectified and
more accurate global prototypes for Few-Shot Medical Image Segmentation (FSMS).
Extensive experiments are conducted on three publicly available medical image
datasets, and the obtained results show consistent improvements compared to
state-of-the-art FSMS methods. The source code is available at:
https://github.com/YazhouZhu19/RPT.
</p>
</div>
</dd>
<dt><a name="item143">[143]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.04827" title="Abstract">arXiv:2309.04827</a> [<a href="/pdf/2309.04827" title="Download PDF">pdf</a>, <a href="/format/2309.04827" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Neurons in Large Language Models: Dead, N-gram, Positional
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Voita%2C+E">Elena Voita</a>, 
<a href="/search/cs?searchtype=author&query=Ferrando%2C+J">Javier Ferrando</a>, 
<a href="/search/cs?searchtype=author&query=Nalmpantis%2C+C">Christoforos Nalmpantis</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">We analyze a family of large language models in such a lightweight manner
that can be done on a single GPU. Specifically, we focus on the OPT family of
models ranging from 125m to 66b parameters and rely only on whether an FFN
neuron is activated or not. First, we find that the early part of the network
is sparse and represents many discrete features. Here, many neurons (more than
70% in some layers of the 66b model) are "dead", i.e. they never activate on a
large collection of diverse data. At the same time, many of the alive neurons
are reserved for discrete features and act as token and n-gram detectors.
Interestingly, their corresponding FFN updates not only promote next token
candidates as could be expected, but also explicitly focus on removing the
information about triggering them tokens, i.e., current input. To the best of
our knowledge, this is the first example of mechanisms specialized at removing
(rather than adding) information from the residual stream. With scale, models
become more sparse in a sense that they have more dead neurons and token
detectors. Finally, some neurons are positional: them being activated or not
depends largely (or solely) on position and less so (or not at all) on textual
data. We find that smaller models have sets of neurons acting as position range
indicators while larger models operate in a less explicit manner.
</p>
</div>
</dd>
<dt><a name="item144">[144]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.04828" title="Abstract">arXiv:2309.04828</a> [<a href="/pdf/2309.04828" title="Download PDF">pdf</a>, <a href="/format/2309.04828" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FAIR: Flow Type-Aware Pre-Training of Compiler Intermediate  Representations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Niu%2C+C">Changan Niu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+C">Chuanyi Li</a>, 
<a href="/search/cs?searchtype=author&query=Ng%2C+V">Vincent Ng</a>, 
<a href="/search/cs?searchtype=author&query=Lo%2C+D">David Lo</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+B">Bin Luo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ICSE 2024 First Cycle
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
<p class="mathjax">While the majority of existing pre-trained models from code learn source code
features such as code tokens and abstract syntax trees, there are some other
works that focus on learning from compiler intermediate representations (IRs).
Existing IR-based models typically utilize IR features such as instructions,
control and data flow graphs (CDFGs), call graphs, etc. However, these methods
confuse variable nodes and instruction nodes in a CDFG and fail to distinguish
different types of flows, and the neural networks they use fail to capture
long-distance dependencies and have over-smoothing and over-squashing problems.
To address these weaknesses, we propose FAIR, a Flow type-Aware pre-trained
model for IR that involves employing (1) a novel input representation of IR
programs; (2) Graph Transformer to address over-smoothing, over-squashing and
long-dependencies problems; and (3) five pre-training tasks that we
specifically propose to enable FAIR to learn the semantics of IR tokens, flow
type information, and the overall representation of IR. Experimental results
show that FAIR can achieve state-of-the-art results on four code-related
downstream tasks.
</p>
</div>
</dd>
<dt><a name="item145">[145]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.04833" title="Abstract">arXiv:2309.04833</a> [<a href="/pdf/2309.04833" title="Download PDF">pdf</a>, <a href="/format/2309.04833" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Effectiveness of Security Interventions on GitHub
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fischer%2C+F">Felix Fischer</a>, 
<a href="/search/cs?searchtype=author&query=H%C3%B6benreich%2C+J">Jonas H&#xf6;benreich</a>, 
<a href="/search/cs?searchtype=author&query=Grossklags%2C+J">Jens Grossklags</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">Since 2017, GitHub has been the first online open source platform to show
security warnings to its users. It has since introduced further security
interventions to help developers improve the security of their open source
software. In this study, we investigate and compare the effects of these
interventions. We perform time series analysis of security-altering commits to
infer the causal effects of the interventions. Our analysis shows that while
all of GitHub's security interventions have a significant positive effect on
security, they differ greatly in their effect size. By comparing the design of
each intervention, we identify the building blocks that worked well and those
that did not. We also provide recommendations on how practitioners can improve
the design of their interventions to enhance their effectiveness.
</p>
</div>
</dd>
<dt><a name="item146">[146]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.04836" title="Abstract">arXiv:2309.04836</a> [<a href="/pdf/2309.04836" title="Download PDF">pdf</a>, <a href="/format/2309.04836" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Neural Semantic Surface Maps
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Morreale%2C+L">Luca Morreale</a>, 
<a href="/search/cs?searchtype=author&query=Aigerman%2C+N">Noam Aigerman</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+V+G">Vladimir G. Kim</a>, 
<a href="/search/cs?searchtype=author&query=Mitra%2C+N+J">Niloy J. Mitra</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Graphics (cs.GR)

</div>
<p class="mathjax">We present an automated technique for computing a map between two genus-zero
shapes, which matches semantically corresponding regions to one another. Lack
of annotated data prohibits direct inference of 3D semantic priors; instead,
current State-of-the-art methods predominantly optimize geometric properties or
require varying amounts of manual annotation. To overcome the lack of annotated
training data, we distill semantic matches from pre-trained vision models: our
method renders the pair of 3D shapes from multiple viewpoints; the resulting
renders are then fed into an off-the-shelf image-matching method which
leverages a pretrained visual model to produce feature points. This yields
semantic correspondences, which can be projected back to the 3D shapes,
producing a raw matching that is inaccurate and inconsistent between different
viewpoints. These correspondences are refined and distilled into an
inter-surface map by a dedicated optimization scheme, which promotes
bijectivity and continuity of the output map. We illustrate that our approach
can generate semantic surface-to-surface maps, eliminating manual annotations
or any 3D training data requirement. Furthermore, it proves effective in
scenarios with high semantic complexity, where objects are non-isometrically
related, as well as in situations where they are nearly isometric.
</p>
</div>
</dd>
<dt><a name="item147">[147]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.04837" title="Abstract">arXiv:2309.04837</a> [<a href="/pdf/2309.04837" title="Download PDF">pdf</a>, <a href="/format/2309.04837" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> HAct: Out-of-Distribution Detection with Neural Net Activation  Histograms
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mondal%2C+S">Sudeepta Mondal</a>, 
<a href="/search/cs?searchtype=author&query=Sundaramoorthi%2C+G">Ganesh Sundaramoorthi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">We propose a simple, efficient, and accurate method for detecting
out-of-distribution (OOD) data for trained neural networks, a potential first
step in methods for OOD generalization. We propose a novel descriptor, HAct -
activation histograms, for OOD detection, that is, probability distributions
(approximated by histograms) of output values of neural network layers under
the influence of incoming data. We demonstrate that HAct is significantly more
accurate than state-of-the-art on multiple OOD image classification benchmarks.
For instance, our approach achieves a true positive rate (TPR) of 95% with only
0.05% false-positives using Resnet-50 on standard OOD benchmarks, outperforming
previous state-of-the-art by 20.66% in the false positive rate (at the same TPR
of 95%). The low computational complexity and the ease of implementation make
HAct suitable for online implementation in monitoring deployed neural networks
in practice at scale.
</p>
</div>
</dd>
<dt><a name="item148">[148]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.04839" title="Abstract">arXiv:2309.04839</a> [<a href="/pdf/2309.04839" title="Download PDF">pdf</a>, <a href="/format/2309.04839" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Safe Control of Euler-Lagrange Systems with Limited Model Information
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yujie Wang</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+X">Xiangru Xu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to IEEE CDC 2023 and this is the extended version
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Optimization and Control (math.OC)

</div>
<p class="mathjax">This paper presents a new safe control framework for Euler-Lagrange (EL)
systems with limited model information, external disturbances, and measurement
uncertainties. The EL system is decomposed into two subsystems called the proxy
subsystem and the virtual tracking subsystem. An adaptive safe controller based
on barrier Lyapunov functions is designed for the virtual tracking subsystem to
ensure the boundedness of the safe velocity tracking error, and a safe
controller based on control barrier functions is designed for the proxy
subsystem to ensure controlled invariance of the safe set defined either in the
joint space or task space. Theorems that guarantee the safety of the proposed
controllers are provided. In contrast to existing safe control strategies for
EL systems, the proposed method requires much less model information and can
ensure safety rather than input-to-state safety. Simulation results are
provided to illustrate the effectiveness of the proposed method.
</p>
</div>
</dd>
<dt><a name="item149">[149]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.04840" title="Abstract">arXiv:2309.04840</a> [<a href="/pdf/2309.04840" title="Download PDF">pdf</a>, <a href="/format/2309.04840" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AnyPose: Anytime 3D Human Pose Forecasting via Neural Ordinary  Differential Equations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zixing Wang</a>, 
<a href="/search/cs?searchtype=author&query=Qureshi%2C+A+H">Ahmed H. Qureshi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Anytime 3D human pose forecasting is crucial to synchronous real-world
human-machine interaction, where the term ``anytime" corresponds to predicting
human pose at any real-valued time step. However, to the best of our knowledge,
all the existing methods in human pose forecasting perform predictions at
preset, discrete time intervals. Therefore, we introduce AnyPose, a lightweight
continuous-time neural architecture that models human behavior dynamics with
neural ordinary differential equations. We validate our framework on the
Human3.6M, AMASS, and 3DPW dataset and conduct a series of comprehensive
analyses towards comparison with existing methods and the intersection of human
pose and neural ordinary differential equations. Our results demonstrate that
AnyPose exhibits high-performance accuracy in predicting future poses and takes
significantly lower computational time than traditional methods in solving
anytime prediction tasks.
</p>
</div>
</dd>
<dt><a name="item150">[150]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.04842" title="Abstract">arXiv:2309.04842</a> [<a href="/pdf/2309.04842" title="Download PDF">pdf</a>, <a href="/format/2309.04842" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Leveraging Large Language Models for Exploiting ASR Uncertainty
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dighe%2C+P">Pranay Dighe</a>, 
<a href="/search/cs?searchtype=author&query=Su%2C+Y">Yi Su</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+S">Shangshang Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yunshu Liu</a>, 
<a href="/search/cs?searchtype=author&query=Garg%2C+V">Vineet Garg</a>, 
<a href="/search/cs?searchtype=author&query=Niu%2C+X">Xiaochuan Niu</a>, 
<a href="/search/cs?searchtype=author&query=Tewfik%2C+A">Ahmed Tewfik</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Human-Computer Interaction (cs.HC); Sound (cs.SD); Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">While large language models excel in a variety of natural language processing
(NLP) tasks, to perform well on spoken language understanding (SLU) tasks, they
must either rely on off-the-shelf automatic speech recognition (ASR) systems
for transcription, or be equipped with an in-built speech modality. This work
focuses on the former scenario, where LLM's accuracy on SLU tasks is
constrained by the accuracy of a fixed ASR system on the spoken input.
Specifically, we tackle speech-intent classification task, where a high
word-error-rate can limit the LLM's ability to understand the spoken intent.
Instead of chasing a high accuracy by designing complex or specialized
architectures regardless of deployment costs, we seek to answer how far we can
go without substantially changing the underlying ASR and LLM, which can
potentially be shared by multiple unrelated tasks. To this end, we propose
prompting the LLM with an n-best list of ASR hypotheses instead of only the
error-prone 1-best hypothesis. We explore prompt-engineering to explain the
concept of n-best lists to the LLM; followed by the finetuning of Low-Rank
Adapters on the downstream tasks. Our approach using n-best lists proves to be
effective on a device-directed speech detection task as well as on a keyword
spotting task, where systems using n-best list prompts outperform those using
1-best ASR hypothesis; thus paving the way for an efficient method to exploit
ASR uncertainty via LLMs for speech-based applications.
</p>
</div>
</dd>
<dt><a name="item151">[151]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.04843" title="Abstract">arXiv:2309.04843</a> [<a href="/pdf/2309.04843" title="Download PDF">pdf</a>, <a href="/format/2309.04843" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DeRi-IGP: Manipulating Rigid Objects Using Deformable Objects via  Iterative Grasp-Pull
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zixing Wang</a>, 
<a href="/search/cs?searchtype=author&query=Qureshi%2C+A+H">Ahmed H. Qureshi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Heterogeneous systems manipulation, i.e., manipulating rigid objects via
deformable (soft) objects, is an emerging field that remains in its early
stages of research. Existing works in this field suffer from limited action and
operational space, poor generalization ability, and expensive development. To
address these challenges, we propose a universally applicable and effective
moving primitive, Iterative Grasp-Pull (IGP), and a sample-based framework,
DeRi-IGP, to solve the heterogeneous system manipulation task. The DeRi-IGP
framework uses local onboard robots' RGBD sensors to observe the environment,
comprising a soft-rigid body system. It then uses this information to
iteratively grasp and pull a soft body (e.g., rope) to move the attached rigid
body to a desired location. We evaluate the effectiveness of our framework in
solving various heterogeneous manipulation tasks and compare its performance
with several state-of-the-art baselines. The result shows that DeRi-IGP
outperforms other methods by a significant margin. In addition, we also
demonstrate the advantage of the large operational space of IGP in the
long-distance object acquisition task within both simulated and real
environments.
</p>
</div>
</dd>
<dt><a name="item152">[152]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.04849" title="Abstract">arXiv:2309.04849</a> [<a href="/pdf/2309.04849" title="Download PDF">pdf</a>, <a href="/format/2309.04849" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Speech Emotion Recognition with Distilled Prosodic and Linguistic Affect  Representations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shome%2C+D">Debaditya Shome</a>, 
<a href="/search/cs?searchtype=author&query=Etemad%2C+A">Ali Etemad</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Under review
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">We propose EmoDistill, a novel speech emotion recognition (SER) framework
that leverages cross-modal knowledge distillation during training to learn
strong linguistic and prosodic representations of emotion from speech. During
inference, our method only uses a stream of speech signals to perform unimodal
SER thus reducing computation overhead and avoiding run-time transcription and
prosodic feature extraction errors. During training, our method distills
information at both embedding and logit levels from a pair of pre-trained
Prosodic and Linguistic teachers that are fine-tuned for SER. Experiments on
the IEMOCAP benchmark demonstrate that our method outperforms other unimodal
and multimodal techniques by a considerable margin, and achieves
state-of-the-art performance of 77.49% unweighted accuracy and 78.91% weighted
accuracy. Detailed ablation studies demonstrate the impact of each component of
our method.
</p>
</div>
</dd>
<dt><a name="item153">[153]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.04851" title="Abstract">arXiv:2309.04851</a> [<a href="/pdf/2309.04851" title="Download PDF">pdf</a>, <a href="/format/2309.04851" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Leaf: Modularity for Temporary Sharing in Separation Logic (Extended  Version)
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hance%2C+T">Travis Hance</a>, 
<a href="/search/cs?searchtype=author&query=Howell%2C+J">Jon Howell</a>, 
<a href="/search/cs?searchtype=author&query=Padon%2C+O">Oded Padon</a>, 
<a href="/search/cs?searchtype=author&query=Parno%2C+B">Bryan Parno</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>

</div>
<p class="mathjax">In concurrent verification, separation logic provides a strong story for
handling both resources that are owned exclusively and resources that are
shared persistently (i.e., forever). However, the situation is more complicated
for temporarily shared state, where state might be shared and then later
reclaimed as exclusive. We believe that a framework for temporarily-shared
state should meet two key goals not adequately met by existing techniques. One,
it should allow and encourage users to verify new sharing strategies. Two, it
should provide an abstraction where users manipulate shared state in a way
agnostic to the means with which it is shared.
<br />We present Leaf, a library in the Iris separation logic which accomplishes
both of these goals by introducing a novel operator, which we call guarding,
that allows one proposition to represent a shared version of another. We
demonstrate that Leaf meets these two goals through a modular case study: we
verify a reader-writer lock that supports shared state, and a hash table built
on top of it that uses shared state.
</p>
</div>
</dd>
<dt><a name="item154">[154]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.04856" title="Abstract">arXiv:2309.04856</a> [<a href="/pdf/2309.04856" title="Download PDF">pdf</a>, <a href="/format/2309.04856" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AmbientFlow: Invertible generative models from incomplete, noisy  measurements
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kelkar%2C+V+A">Varun A. Kelkar</a>, 
<a href="/search/cs?searchtype=author&query=Deshpande%2C+R">Rucha Deshpande</a>, 
<a href="/search/cs?searchtype=author&query=Banerjee%2C+A">Arindam Banerjee</a>, 
<a href="/search/cs?searchtype=author&query=Anastasio%2C+M+A">Mark A. Anastasio</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Image and Video Processing (eess.IV)

</div>
<p class="mathjax">Generative models have gained popularity for their potential applications in
imaging science, such as image reconstruction, posterior sampling and data
sharing. Flow-based generative models are particularly attractive due to their
ability to tractably provide exact density estimates along with fast,
inexpensive and diverse samples. Training such models, however, requires a
large, high quality dataset of objects. In applications such as computed
imaging, it is often difficult to acquire such data due to requirements such as
long acquisition time or high radiation dose, while acquiring noisy or
partially observed measurements of these objects is more feasible. In this
work, we propose AmbientFlow, a framework for learning flow-based generative
models directly from noisy and incomplete data. Using variational Bayesian
methods, a novel framework for establishing flow-based generative models from
noisy, incomplete data is proposed. Extensive numerical studies demonstrate the
effectiveness of AmbientFlow in correctly learning the object distribution. The
utility of AmbientFlow in a downstream inference task of image reconstruction
is demonstrated.
</p>
</div>
</dd>
<dt><a name="item155">[155]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.04858" title="Abstract">arXiv:2309.04858</a> [<a href="/pdf/2309.04858" title="Download PDF">pdf</a>, <a href="/format/2309.04858" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Reverse-Engineering Decoding Strategies Given Blackbox Access to a  Language Generation System
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ippolito%2C+D">Daphne Ippolito</a>, 
<a href="/search/cs?searchtype=author&query=Carlini%2C+N">Nicholas Carlini</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+K">Katherine Lee</a>, 
<a href="/search/cs?searchtype=author&query=Nasr%2C+M">Milad Nasr</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+Y+W">Yun William Yu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages, 4 figures, 3 tables. Also, 5 page appendix. Accepted to INLG 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computation and Language (cs.CL); Cryptography and Security (cs.CR)

</div>
<p class="mathjax">Neural language models are increasingly deployed into APIs and websites that
allow a user to pass in a prompt and receive generated text. Many of these
systems do not reveal generation parameters. In this paper, we present methods
to reverse-engineer the decoding method used to generate text (i.e., top-$k$ or
nucleus sampling). Our ability to discover which decoding strategy was used has
implications for detecting generated text. Additionally, the process of
discovering the decoding strategy can reveal biases caused by selecting
decoding settings which severely truncate a model's predicted distributions. We
perform our attack on several families of open-source language models, as well
as on production systems (e.g., ChatGPT).
</p>
</div>
</dd>
<dt><a name="item156">[156]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.04859" title="Abstract">arXiv:2309.04859</a> [<a href="/pdf/2309.04859" title="Download PDF">pdf</a>, <a href="/format/2309.04859" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PyHGL: A Python-based Hardware Generation Language Framework
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sun%2C+J">Jintao Sun</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zeke Wang</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+T">Tao Lu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+W">Wenzhi Chen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Hardware Architecture (cs.AR)</span>

</div>
<p class="mathjax">Hardware generation languages (HGLs) increase hardware design productivity by
creating parameterized modules and test benches. Unfortunately, existing tools
are not widely adopted due to several demerits, including limited support for
asynchronous circuits and unknown states, lack of concise and efficient
language features, and low integration of simulation and verification
functions. This paper introduces PyHGL, an open-source Python framework that
aims to provide a simple and unified environment for hardware generation,
simulation, and verification. PyHGL language is a syntactical superset of
Python, which greatly reduces the lines of code (LOC) and improves productivity
by providing unique features such as dynamic typing, vectorized operations, and
automatic port deduction. In addition, PyHGL integrates an event-driven
simulator that simulates the asynchronous behaviors of digital circuits using
three-state logic. We also propose an algorithm that eliminates the calculation
and transmission overhead of unknown state propagation for binary stimuli. The
results suggest that PyHGL code is up to 6.1x denser than traditional RTL and
generates high-quality synthesizable RTL code. Moreover, the optimized
simulator achieves 2.9x speed up and matches the performance of a commonly used
open-source logic simulator.
</p>
</div>
</dd>
<dt><a name="item157">[157]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.04860" title="Abstract">arXiv:2309.04860</a> [<a href="/pdf/2309.04860" title="Download PDF">pdf</a>, <a href="/format/2309.04860" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Approximation Results for Gradient Descent trained Neural Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Welper%2C+G">G. Welper</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Numerical Analysis (math.NA); Machine Learning (stat.ML)

</div>
<p class="mathjax">The paper contains approximation guarantees for neural networks that are
trained with gradient flow, with error measured in the continuous
$L_2(\mathbb{S}^{d-1})$-norm on the $d$-dimensional unit sphere and targets
that are Sobolev smooth. The networks are fully connected of constant depth and
increasing width. Although all layers are trained, the gradient flow
convergence is based on a neural tangent kernel (NTK) argument for the
non-convex second but last layer. Unlike standard NTK analysis, the continuous
error norm implies an under-parametrized regime, possible by the natural
smoothness assumption required for approximation. The typical
over-parametrization re-enters the results in form of a loss in approximation
rate relative to established approximation methods for Sobolev smooth
functions.
</p>
</div>
</dd>
<dt><a name="item158">[158]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.04861" title="Abstract">arXiv:2309.04861</a> [<a href="/pdf/2309.04861" title="Download PDF">pdf</a>, <a href="/format/2309.04861" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exploring Music Genre Classification: Algorithm Analysis and Deployment  Architecture
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Biswas%2C+A">Ayan Biswas</a>, 
<a href="/search/cs?searchtype=author&query=Dhabal%2C+S">Supriya Dhabal</a>, 
<a href="/search/cs?searchtype=author&query=Venkateswaran%2C+P">Palaniandavar Venkateswaran</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Information Retrieval (cs.IR); Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">Music genre classification has become increasingly critical with the advent
of various streaming applications. Nowadays, we find it impossible to imagine
using the artist's name and song title to search for music in a sophisticated
music app. It is always difficult to classify music correctly because the
information linked to music, such as region, artist, album, or non-album, is so
variable. This paper presents a study on music genre classification using a
combination of Digital Signal Processing (DSP) and Deep Learning (DL)
techniques. A novel algorithm is proposed that utilizes both DSP and DL methods
to extract relevant features from audio signals and classify them into various
genres. The algorithm was tested on the GTZAN dataset and achieved high
accuracy. An end-to-end deployment architecture is also proposed for
integration into music-related applications. The performance of the algorithm
is analyzed and future directions for improvement are discussed. The proposed
DSP and DL-based music genre classification algorithm and deployment
architecture demonstrate a promising approach for music genre classification.
</p>
</div>
</dd>
<dt><a name="item159">[159]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.04862" title="Abstract">arXiv:2309.04862</a> [<a href="/pdf/2309.04862" title="Download PDF">pdf</a>, <a href="/format/2309.04862" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Distributional Data Augmentation Methods for Low Resource Language
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mahamud%2C+M">Mosleh Mahamud</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+Z">Zed Lee</a>, 
<a href="/search/cs?searchtype=author&query=Samsten%2C+I">Isak Samsten</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> AAAI 2023 Workshop on Knowledge Augmented Methods for NLP
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Text augmentation is a technique for constructing synthetic data from an
under-resourced corpus to improve predictive performance. Synthetic data
generation is common in numerous domains. However, recently text augmentation
has emerged in natural language processing (NLP) to improve downstream tasks.
One of the current state-of-the-art text augmentation techniques is easy data
augmentation (EDA), which augments the training data by injecting and replacing
synonyms and randomly permuting sentences. One major obstacle with EDA is the
need for versatile and complete synonym dictionaries, which cannot be easily
found in low-resource languages. To improve the utility of EDA, we propose two
extensions, easy distributional data augmentation (EDDA) and type specific
similar word replacement (TSSR), which uses semantic word context information
and part-of-speech tags for word replacement and augmentation. In an extensive
empirical evaluation, we show the utility of the proposed methods, measured by
F1 score, on two representative datasets in Swedish as an example of a
low-resource language. With the proposed methods, we show that augmented data
improve classification performances in low-resource settings.
</p>
</div>
</dd>
<dt><a name="item160">[160]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.04863" title="Abstract">arXiv:2309.04863</a> [<a href="/pdf/2309.04863" title="Download PDF">pdf</a>, <a href="/format/2309.04863" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Design of a Low-Power High-Gain Bio-Medical Operational Amplifier in  65nm Technology using gm/ID Methodology
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Biswas%2C+A">Ayan Biswas</a>, 
<a href="/search/cs?searchtype=author&query=Dhabal%2C+S">Supriya Dhabal</a>, 
<a href="/search/cs?searchtype=author&query=Venkateswaran%2C+P">Palaniandavar Venkateswaran</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Hardware Architecture (cs.AR)</span>; Systems and Control (eess.SY)

</div>
<p class="mathjax">Operational Amplifiers (Op-Amps) play a crucial role in the field of
biomedical engineering, as they enable signal amplification and processing in
various medical devices. With the increasing demand for portable and low-power
biomedical devices, designing Op-Amps specifically tailored for such
applications is essential. In response to this need, a low-power high-gain
Op-Amp designed for biomedical applications using TSMC 65nm technology has been
proposed. This Op-Amp incorporates a two-stage miller compensated topology,
which is well-known for its superior performance in gain, gain bandwidth
product and power consumption. The proposed Op-Amp contributes to the field of
biomedical engineering by offering a tailored solution that enhances signal
processing capabilities, enables accurate data acquisition, and improves
overall efficiency in healthcare systems. The design methodology and simulation
results presented in this paper provide insights into the performance and
potential impact of the Op-Amp in advancing biomedical devices and systems.
</p>
</div>
</dd>
<dt><a name="item161">[161]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.04867" title="Abstract">arXiv:2309.04867</a> [<a href="/pdf/2309.04867" title="Download PDF">pdf</a>, <a href="/format/2309.04867" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Finite-sample analysis of rotation operator under $l_2$ norm and  $l_\infty$ norm
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhou%2C+M">Mi Zhou</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Discrete Mathematics (cs.DM)</span>; Probability (math.PR)

</div>
<p class="mathjax">In this article, we consider a special operator called the two-dimensional
rotation operator and analyze its convergence and finite-sample bounds under
the $l_2$ norm and $l_\infty$ norm with constant step size. We then consider
the same problem with stochastic noise with affine variance. Furthermore,
simulations are provided to illustrate our results. Finally, we conclude this
article by proposing some possible future extensions.
</p>
</div>
</dd>
<dt><a name="item162">[162]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.04868" title="Abstract">arXiv:2309.04868</a> [<a href="/pdf/2309.04868" title="Download PDF">pdf</a>, <a href="/format/2309.04868" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MemSPICE: Automated Simulation and Energy Estimation Framework for  MAGIC-Based Logic-in-Memory
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Singh%2C+S">Simranjeet Singh</a>, 
<a href="/search/cs?searchtype=author&query=Jha%2C+C+K">Chandan Kumar Jha</a>, 
<a href="/search/cs?searchtype=author&query=Bende%2C+A">Ankit Bende</a>, 
<a href="/search/cs?searchtype=author&query=Rana%2C+V">Vikas Rana</a>, 
<a href="/search/cs?searchtype=author&query=Patkar%2C+S">Sachin Patkar</a>, 
<a href="/search/cs?searchtype=author&query=Drechsler%2C+R">Rolf Drechsler</a>, 
<a href="/search/cs?searchtype=author&query=Merchant%2C+F">Farhad Merchant</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted in ASP-DAC 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Emerging Technologies (cs.ET)</span>; Logic in Computer Science (cs.LO)

</div>
<p class="mathjax">Existing logic-in-memory (LiM) research is limited to generating mappings and
micro-operations. In this paper, we present~\emph{MemSPICE}, a novel framework
that addresses this gap by automatically generating both the netlist and
testbench needed to evaluate the LiM on a memristive crossbar. MemSPICE goes
beyond conventional approaches by providing energy estimation scripts to
calculate the precise energy consumption of the testbench at the SPICE level.
We propose an automated framework that utilizes the mapping obtained from the
SIMPLER tool to perform accurate energy estimation through SPICE simulations.
To the best of our knowledge, no existing framework is capable of generating a
SPICE netlist from a hardware description language. By offering a comprehensive
solution for SPICE-based netlist generation, testbench creation, and accurate
energy estimation, MemSPICE empowers researchers and engineers working on
memristor-based LiM to enhance their understanding and optimization of energy
usage in these systems. Finally, we tested the circuits from the ISCAS'85
benchmark on MemSPICE and conducted a detailed energy analysis.
</p>
</div>
</dd>
<dt><a name="item163">[163]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.04873" title="Abstract">arXiv:2309.04873</a> [<a href="/pdf/2309.04873" title="Download PDF">pdf</a>, <a href="/ps/2309.04873" title="Download PostScript">ps</a>, <a href="/format/2309.04873" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> From Reversible Computation to Checkpoint-Based Rollback Recovery for  Message-Passing Concurrent Programs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Vidal%2C+G">Germ&#xe1;n Vidal</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Programming Languages (cs.PL)</span>

</div>
<p class="mathjax">The reliability of concurrent and distributed systems often depends on some
well-known techniques for fault tolerance. One such technique is based on
checkpointing and rollback recovery. Checkpointing involves processes to take
snapshots of their current states regularly, so that a rollback recovery
strategy is able to bring the system back to a previous consistent state
whenever a failure occurs. In this paper, we consider a message-passing
concurrent programming language and propose a novel rollback recovery strategy
that is based on some explicit checkpointing primitives and the use of a
(partially) reversible semantics for rolling back the system.
</p>
</div>
</dd>
<dt><a name="item164">[164]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.04875" title="Abstract">arXiv:2309.04875</a> [<a href="/pdf/2309.04875" title="Download PDF">pdf</a>, <a href="/format/2309.04875" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Approximating ReLU on a Reduced Ring for Efficient MPC-based Private  Inference
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Maeng%2C+K">Kiwan Maeng</a>, 
<a href="/search/cs?searchtype=author&query=Suh%2C+G+E">G. Edward Suh</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Cryptography and Security (cs.CR)

</div>
<p class="mathjax">Secure multi-party computation (MPC) allows users to offload machine learning
inference on untrusted servers without having to share their privacy-sensitive
data. Despite their strong security properties, MPC-based private inference has
not been widely adopted in the real world due to their high communication
overhead. When evaluating ReLU layers, MPC protocols incur a significant amount
of communication between the parties, making the end-to-end execution time
multiple orders slower than its non-private counterpart.
<br />This paper presents HummingBird, an MPC framework that reduces the ReLU
communication overhead significantly by using only a subset of the bits to
evaluate ReLU on a smaller ring. Based on theoretical analyses, HummingBird
identifies bits in the secret share that are not crucial for accuracy and
excludes them during ReLU evaluation to reduce communication. With its
efficient search engine, HummingBird discards 87--91% of the bits during ReLU
and still maintains high accuracy. On a real MPC setup involving multiple
servers, HummingBird achieves on average 2.03--2.67x end-to-end speedup without
introducing any errors, and up to 8.64x average speedup when some amount of
accuracy degradation can be tolerated, due to its up to 8.76x communication
reduction.
</p>
</div>
</dd>
<dt><a name="item165">[165]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.04877" title="Abstract">arXiv:2309.04877</a> [<a href="/pdf/2309.04877" title="Download PDF">pdf</a>, <a href="/format/2309.04877" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Gentle Introduction to Gradient-Based Optimization and Variational  Inequalities for Machine Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wadia%2C+N+S">Neha S. Wadia</a>, 
<a href="/search/cs?searchtype=author&query=Dandi%2C+Y">Yatin Dandi</a>, 
<a href="/search/cs?searchtype=author&query=Jordan%2C+M+I">Michael I. Jordan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 36 pages, 7 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
<p class="mathjax">The rapid progress in machine learning in recent years has been based on a
highly productive connection to gradient-based optimization. Further progress
hinges in part on a shift in focus from pattern recognition to decision-making
and multi-agent problems. In these broader settings, new mathematical
challenges emerge that involve equilibria and game theory instead of optima.
Gradient-based methods remain essential -- given the high dimensionality and
large scale of machine-learning problems -- but simple gradient descent is no
longer the point of departure for algorithm design. We provide a gentle
introduction to a broader framework for gradient-based algorithms in machine
learning, beginning with saddle points and monotone games, and proceeding to
general variational inequalities. While we provide convergence proofs for
several of the algorithms that we present, our main focus is that of providing
motivation and intuition.
</p>
</div>
</dd>
<dt><a name="item166">[166]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.04878" title="Abstract">arXiv:2309.04878</a> [<a href="/pdf/2309.04878" title="Download PDF">pdf</a>, <a href="/format/2309.04878" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Characterizing Cyber Attacks against Space Systems with Missing Data:  Framework and Case Study
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ear%2C+E">Ekzhin Ear</a>, 
<a href="/search/cs?searchtype=author&query=Remy%2C+J+L+C">Jose L. C. Remy</a>, 
<a href="/search/cs?searchtype=author&query=Feffer%2C+A">Antonia Feffer</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+S">Shouhuai Xu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted for publication: IEEE International Conference on Communications and Network Security 2023 (IEEE CNS)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">Cybersecurity of space systems is an emerging topic, but there is no single
dataset that documents cyber attacks against space systems that have occurred
in the past. These incidents are often scattered in media reports while missing
many details, which we dub the missing-data problem. Nevertheless, even
"low-quality" datasets containing such reports would be extremely valuable
because of the dearth of space cybersecurity data and the sensitivity of space
systems which are often restricted from disclosure by governments. This prompts
a research question: How can we characterize real-world cyber attacks against
space systems? In this paper, we address the problem by proposing a framework,
including metrics, while also addressing the missing-data problem, by
"extrapolating" the missing data in a principled fashion. To show the
usefulness of the framework, we extract data for 72 cyber attacks against space
systems and show how to extrapolate this "low-quality" dataset to derive 4,076
attack technique kill chains. Our findings include: cyber attacks against space
systems are getting increasingly sophisticated; and, successful protection
against on-path and social engineering attacks could have prevented 80% of the
attacks.
</p>
</div>
</dd>
<dt><a name="item167">[167]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.04884" title="Abstract">arXiv:2309.04884</a> [<a href="/pdf/2309.04884" title="Download PDF">pdf</a>, <a href="/format/2309.04884" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> RecAD: Towards A Unified Library for Recommender Attack and Defense
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+C">Changsheng Wang</a>, 
<a href="/search/cs?searchtype=author&query=Ye%2C+J">Jianbai Ye</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+W">Wenjie Wang</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+C">Chongming Gao</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+F">Fuli Feng</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+X">Xiangnan He</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>

</div>
<p class="mathjax">In recent years, recommender systems have become a ubiquitous part of our
daily lives, while they suffer from a high risk of being attacked due to the
growing commercial and social values. Despite significant research progress in
recommender attack and defense, there is a lack of a widely-recognized
benchmarking standard in the field, leading to unfair performance comparison
and limited credibility of experiments. To address this, we propose RecAD, a
unified library aiming at establishing an open benchmark for recommender attack
and defense. RecAD takes an initial step to set up a unified benchmarking
pipeline for reproducible research by integrating diverse datasets, standard
source codes, hyper-parameter settings, running logs, attack knowledge, attack
budget, and evaluation results. The benchmark is designed to be comprehensive
and sustainable, covering both attack, defense, and evaluation tasks, enabling
more researchers to easily follow and contribute to this promising field. RecAD
will drive more solid and reproducible research on recommender systems attack
and defense, reduce the redundant efforts of researchers, and ultimately
increase the credibility and practical value of recommender attack and defense.
The project is released at https://github.com/gusye1234/recad.
</p>
</div>
</dd>
<dt><a name="item168">[168]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.04885" title="Abstract">arXiv:2309.04885</a> [<a href="/pdf/2309.04885" title="Download PDF">pdf</a>, <a href="/format/2309.04885" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Symplectic Structure-Aware Hamiltonian (Graph) Embeddings
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jiaxu Liu</a>, 
<a href="/search/cs?searchtype=author&query=Yi%2C+X">Xinping Yi</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+T">Tianle Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+X">Xiaowei Huang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages main content with 3 pages appendix
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Symplectic Geometry (math.SG)

</div>
<p class="mathjax">In traditional Graph Neural Networks (GNNs), the assumption of a fixed
embedding manifold often limits their adaptability to diverse graph geometries.
Recently, Hamiltonian system-inspired GNNs are proposed to address the dynamic
nature of such embeddings by incorporating physical laws into node feature
updates. In this work, we present SAH-GNN, a novel approach that generalizes
Hamiltonian dynamics for more flexible node feature updates. Unlike existing
Hamiltonian-inspired GNNs, SAH-GNN employs Riemannian optimization on the
symplectic Stiefel manifold to adaptively learn the underlying symplectic
structure during training, circumventing the limitations of existing
Hamiltonian GNNs that rely on a pre-defined form of standard symplectic
structure. This innovation allows SAH-GNN to automatically adapt to various
graph datasets without extensive hyperparameter tuning. Moreover, it conserves
energy during training such that the implicit Hamiltonian system is physically
meaningful. To this end, we empirically validate SAH-GNN's superior performance
and adaptability in node classification tasks across multiple types of graph
datasets.
</p>
</div>
</dd>
<dt><a name="item169">[169]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.04887" title="Abstract">arXiv:2309.04887</a> [<a href="/pdf/2309.04887" title="Download PDF">pdf</a>, <a href="/format/2309.04887" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SortedAP: Rethinking evaluation metrics for instance segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+L">Long Chen</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Y">Yuli Wu</a>, 
<a href="/search/cs?searchtype=author&query=Stegmaier%2C+J">Johannes Stegmaier</a>, 
<a href="/search/cs?searchtype=author&query=Merhof%2C+D">Dorit Merhof</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Designing metrics for evaluating instance segmentation revolves around
comprehensively considering object detection and segmentation accuracy.
However, other important properties, such as sensitivity, continuity, and
equality, are overlooked in the current study. In this paper, we reveal that
most existing metrics have a limited resolution of segmentation quality. They
are only conditionally sensitive to the change of masks or false predictions.
For certain metrics, the score can change drastically in a narrow range which
could provide a misleading indication of the quality gap between results.
Therefore, we propose a new metric called sortedAP, which strictly decreases
with both object- and pixel-level imperfections and has an uninterrupted
penalization scale over the entire domain. We provide the evaluation toolkit
and experiment code at https://www.github.com/looooongChen/sortedAP.
</p>
</div>
</dd>
<dt><a name="item170">[170]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.04888" title="Abstract">arXiv:2309.04888</a> [<a href="/pdf/2309.04888" title="Download PDF">pdf</a>, <a href="/format/2309.04888" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Semi-supervised Instance Segmentation with a Learned Shape Prior
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+L">Long Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+W">Weiwen Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Y">Yuli Wu</a>, 
<a href="/search/cs?searchtype=author&query=Strauch%2C+M">Martin Strauch</a>, 
<a href="/search/cs?searchtype=author&query=Merhof%2C+D">Dorit Merhof</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">To date, most instance segmentation approaches are based on supervised
learning that requires a considerable amount of annotated object contours as
training ground truth. Here, we propose a framework that searches for the
target object based on a shape prior. The shape prior model is learned with a
variational autoencoder that requires only a very limited amount of training
data: In our experiments, a few dozens of object shape patches from the target
dataset, as well as purely synthetic shapes, were sufficient to achieve results
en par with supervised methods with full access to training data on two out of
three cell segmentation datasets. Our method with a synthetic shape prior was
superior to pre-trained supervised models with access to limited
domain-specific training data on all three datasets. Since the learning of
prior models requires shape patches, whether real or synthetic data, we call
this framework semi-supervised learning.
</p>
</div>
</dd>
<dt><a name="item171">[171]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.04889" title="Abstract">arXiv:2309.04889</a> [<a href="/pdf/2309.04889" title="Download PDF">pdf</a>, <a href="/format/2309.04889" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A subspace constrained randomized Kaczmarz method for structure or  external knowledge exploitation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Lok%2C+J">Jackie Lok</a>, 
<a href="/search/math?searchtype=author&query=Rebrova%2C+E">Elizaveta Rebrova</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 34 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Probability (math.PR)

</div>
<p class="mathjax">We study a subspace constrained version of the randomized Kaczmarz algorithm
for solving large linear systems in which the iterates are confined to the
space of solutions of a selected subsystem. We show that the subspace
constraint leads to an accelerated convergence rate, especially when the system
has structure such as having coherent rows or being approximately low-rank. On
Gaussian-like random data, it results in a form of dimension reduction that
effectively improves the aspect ratio of the system. Furthermore, this method
serves as a building block for a second, quantile-based algorithm for the
problem of solving linear systems with arbitrary sparse corruptions, which is
able to efficiently exploit partial external knowledge about uncorrupted
equations and achieve convergence in difficult settings such as in
almost-square systems. Numerical experiments on synthetic and real-world data
support our theoretical results and demonstrate the validity of the proposed
methods for even more general data models than guaranteed by the theory.
</p>
</div>
</dd>
<dt><a name="item172">[172]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.04891" title="Abstract">arXiv:2309.04891</a> [<a href="/pdf/2309.04891" title="Download PDF">pdf</a>, <a href="/format/2309.04891" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> How to Evaluate Semantic Communications for Images with ViTScore Metric?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhu%2C+T">Tingting Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+B">Bo Peng</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+J">Jifan Liang</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+T">Tingchen Han</a>, 
<a href="/search/cs?searchtype=author&query=Wan%2C+H">Hai Wan</a>, 
<a href="/search/cs?searchtype=author&query=Fu%2C+J">Jingqiao Fu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Junjie Chen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Information Theory (cs.IT)

</div>
<p class="mathjax">Semantic communications (SC) have been expected to be a new paradigm shifting
to catalyze the next generation communication, whose main concerns shift from
accurate bit transmission to effective semantic information exchange in
communications. However, the previous and widely-used metrics for images are
not applicable to evaluate the image semantic similarity in SC. Classical
metrics to measure the similarity between two images usually rely on the pixel
level or the structural level, such as the PSNR and the MS-SSIM.
Straightforwardly using some tailored metrics based on deep-learning methods in
CV community, such as the LPIPS, is infeasible for SC. To tackle this, inspired
by BERTScore in NLP community, we propose a novel metric for evaluating image
semantic similarity, named Vision Transformer Score (ViTScore). We prove
theoretically that ViTScore has 3 important properties, including symmetry,
boundedness, and normalization, which make ViTScore convenient and intuitive
for image measurement. To evaluate the performance of ViTScore, we compare
ViTScore with 3 typical metrics (PSNR, MS-SSIM, and LPIPS) through 5 classes of
experiments. Experimental results demonstrate that ViTScore can better evaluate
the image semantic similarity than the other 3 typical metrics, which indicates
that ViTScore is an effective performance metric when deployed in SC scenarios.
</p>
</div>
</dd>
<dt><a name="item173">[173]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.04898" title="Abstract">arXiv:2309.04898</a> [<a href="/pdf/2309.04898" title="Download PDF">pdf</a>, <a href="/format/2309.04898" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Energy-Constrained Programmable Matter Under Unfair Adversaries
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Weber%2C+J+W">Jamison W. Weber</a>, 
<a href="/search/cs?searchtype=author&query=Chhabra%2C+T">Tishya Chhabra</a>, 
<a href="/search/cs?searchtype=author&query=Richa%2C+A+W">Andr&#xe9;a W. Richa</a>, 
<a href="/search/cs?searchtype=author&query=Daymude%2C+J+J">Joshua J. Daymude</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 31 pages, 4 figures, 1 table. Submitted to OPODIS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>

</div>
<p class="mathjax">Individual modules of programmable matter participate in their system's
collective behavior by expending energy to perform actions. However, not all
modules may have access to the external energy source powering the system,
necessitating a local and distributed strategy for supplying energy to modules.
In this work, we present a general energy distribution framework for the
canonical amoebot model of programmable matter that transforms energy-agnostic
algorithms into energy-constrained ones with equivalent behavior and an
$\mathcal{O}(n^2)$-round runtime overhead -- even under an unfair adversary --
provided the original algorithms satisfy certain conventions. We then prove
that existing amoebot algorithms for leader election (ICDCN 2023) and shape
formation (Distributed Computing, 2023) are compatible with this framework and
show simulations of their energy-constrained counterparts, demonstrating how
other unfair algorithms can be generalized to the energy-constrained setting
with relatively little effort. Finally, we show that our energy distribution
framework can be composed with the concurrency control framework for amoebot
algorithms (Distributed Computing, 2023), allowing algorithm designers to focus
on the simpler energy-agnostic, sequential setting but gain the general
applicability of energy-constrained, asynchronous correctness.
</p>
</div>
</dd>
<dt><a name="item174">[174]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.04899" title="Abstract">arXiv:2309.04899</a> [<a href="/pdf/2309.04899" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Transient Attack against the VMG-KLJN Secure Key Exchanger
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ferdous%2C+S">Shahriar Ferdous</a>, 
<a href="/search/cs?searchtype=author&query=Kish%2C+L+B">Laszlo B. Kish</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">The security vulnerability of the Vadai, Mingesz, and Gingl (VMG)
Kirchhoff-Law-Johnson-Noise (KLJN) key exchanger, as presented in the
publication "Nature, Science Report 5 (2015) 13653," has been exposed to
transient attacks. Recently an effective defense protocol was introduced (Appl.
Phys. Lett. 122 (2023) 143503) to counteract mean-square voltage-based (or
mean-square current-based) transient attacks targeted at the ideal KLJN
framework.
<br />In the present study, this same mitigation methodology has been employed to
fortify the security of the VMG-KLJN key exchanger. It is worth noting that the
protective measures need to be separately implemented for the HL and LH
scenarios. This conceptual framework is corroborated through computer
simulations, demonstrating that the application of this defensive technique
substantially mitigates information leakage to a point of insignificance.
</p>
</div>
</dd>
<dt><a name="item175">[175]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.04902" title="Abstract">arXiv:2309.04902</a> [<a href="/pdf/2309.04902" title="Download PDF">pdf</a>, <a href="/format/2309.04902" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Transformers in Small Object Detection: A Benchmark and Survey of  State-of-the-Art
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rekavandi%2C+A+M">Aref Miri Rekavandi</a>, 
<a href="/search/cs?searchtype=author&query=Rashidi%2C+S">Shima Rashidi</a>, 
<a href="/search/cs?searchtype=author&query=Boussaid%2C+F">Farid Boussaid</a>, 
<a href="/search/cs?searchtype=author&query=Hoefs%2C+S">Stephen Hoefs</a>, 
<a href="/search/cs?searchtype=author&query=Akbas%2C+E">Emre Akbas</a>, 
<a href="/search/cs?searchtype=author&query=bennamoun%2C+M">Mohammed bennamoun</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Transformers have rapidly gained popularity in computer vision, especially in
the field of object recognition and detection. Upon examining the outcomes of
state-of-the-art object detection methods, we noticed that transformers
consistently outperformed well-established CNN-based detectors in almost every
video or image dataset. While transformer-based approaches remain at the
forefront of small object detection (SOD) techniques, this paper aims to
explore the performance benefits offered by such extensive networks and
identify potential reasons for their SOD superiority. Small objects have been
identified as one of the most challenging object types in detection frameworks
due to their low visibility. We aim to investigate potential strategies that
could enhance transformers' performance in SOD. This survey presents a taxonomy
of over 60 research studies on developed transformers for the task of SOD,
spanning the years 2020 to 2023. These studies encompass a variety of detection
applications, including small object detection in generic images, aerial
images, medical images, active millimeter images, underwater images, and
videos. We also compile and present a list of 12 large-scale datasets suitable
for SOD that were overlooked in previous studies and compare the performance of
the reviewed studies using popular metrics such as mean Average Precision
(mAP), Frames Per Second (FPS), number of parameters, and more. Researchers can
keep track of newer studies on our web page, which is available at
\url{https://github.com/arekavandi/Transformer-SOD}.
</p>
</div>
</dd>
<dt><a name="item176">[176]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.04907" title="Abstract">arXiv:2309.04907</a> [<a href="/pdf/2309.04907" title="Download PDF">pdf</a>, <a href="/format/2309.04907" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Effective Real Image Editing with Accelerated Iterative Diffusion  Inversion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pan%2C+Z">Zhihong Pan</a>, 
<a href="/search/cs?searchtype=author&query=Gherardi%2C+R">Riccardo Gherardi</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+X">Xiufeng Xie</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+S">Stephen Huang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to ICCV 2023 (Oral)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Despite all recent progress, it is still challenging to edit and manipulate
natural images with modern generative models. When using Generative Adversarial
Network (GAN), one major hurdle is in the inversion process mapping a real
image to its corresponding noise vector in the latent space, since its
necessary to be able to reconstruct an image to edit its contents. Likewise for
Denoising Diffusion Implicit Models (DDIM), the linearization assumption in
each inversion step makes the whole deterministic inversion process unreliable.
Existing approaches that have tackled the problem of inversion stability often
incur in significant trade-offs in computational efficiency. In this work we
propose an Accelerated Iterative Diffusion Inversion method, dubbed AIDI, that
significantly improves reconstruction accuracy with minimal additional overhead
in space and time complexity. By using a novel blended guidance technique, we
show that effective results can be obtained on a large range of image editing
tasks without large classifier-free guidance in inversion. Furthermore, when
compared with other diffusion inversion based works, our proposed process is
shown to be more robust for fast image editing in the 10 and 20 diffusion
steps' regimes.
</p>
</div>
</dd>
<dt><a name="item177">[177]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.04909" title="Abstract">arXiv:2309.04909</a> [<a href="/pdf/2309.04909" title="Download PDF">pdf</a>, <a href="/ps/2309.04909" title="Download PostScript">ps</a>, <a href="/format/2309.04909" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Bicoptor 2.0: Addressing Challenges in Probabilistic Truncation for  Enhanced Privacy-Preserving Machine Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhou%2C+L">Lijing Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+Q">Qingrui Song</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+S">Su Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Ziyu Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xianggui Wang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yong Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 17 pages, 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">This paper primarily focuses on analyzing the problems and proposing
solutions for the probabilistic truncation protocol in existing PPML works from
the perspectives of accuracy and efficiency. In terms of accuracy, we reveal
that precision selections recommended in some of the existing works are
incorrect. We conduct a thorough analysis of their open-source code and find
that their errors were mainly due to simplified implementation, more
specifically, fixed numbers are used instead of random numbers in probabilistic
truncation protocols. Based on this, we provide a detailed theoretical analysis
to validate our views. We propose a solution and a precision selection
guideline for future works. Regarding efficiency, we identify limitations in
the state-of-the-art comparison protocol, Bicoptor's (S\&amp;P 2023) DReLU
protocol, which relies on the probabilistic truncation protocol and is heavily
constrained by the security parameter to avoid errors, significantly impacting
the protocol's performance. To address these challenges, we introduce the first
non-interactive deterministic truncation protocol, replacing the original
probabilistic truncation protocol. Additionally, we design a non-interactive
modulo switch protocol to enhance the protocol's security. Finally, we provide
a guideline to reduce computational and communication overhead by using only a
portion of the bits of the input, i.e., the key bits, for DReLU operations
based on different model parameters. With the help of key bits, the performance
of our DReLU protocol is further improved. We evaluate the performance of our
protocols on three GPU servers, and achieve a 10x improvement in DReLU
protocol, and a 6x improvement in the ReLU protocol over the state-of-the-art
work Piranha-Falcon (USENIX Sec 22). Overall, the performance of our end-to-end
(E2E) privacy-preserving machine learning (PPML) inference is improved by 3-4
times.
</p>
</div>
</dd>
<dt><a name="item178">[178]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.04911" title="Abstract">arXiv:2309.04911</a> [<a href="/pdf/2309.04911" title="Download PDF">pdf</a>, <a href="/format/2309.04911" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Review of Machine Learning-based Security in Cloud Computing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Babaei%2C+A">Aptin Babaei</a>, 
<a href="/search/cs?searchtype=author&query=Kebria%2C+P+M">Parham M. Kebria</a>, 
<a href="/search/cs?searchtype=author&query=Dalvand%2C+M+M">Mohsen Moradi Dalvand</a>, 
<a href="/search/cs?searchtype=author&query=Nahavandi%2C+S">Saeid Nahavandi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Networking and Internet Architecture (cs.NI)

</div>
<p class="mathjax">Cloud Computing (CC) is revolutionizing the way IT resources are delivered to
users, allowing them to access and manage their systems with increased
cost-effectiveness and simplified infrastructure. However, with the growth of
CC comes a host of security risks, including threats to availability,
integrity, and confidentiality. To address these challenges, Machine Learning
(ML) is increasingly being used by Cloud Service Providers (CSPs) to reduce the
need for human intervention in identifying and resolving security issues. With
the ability to analyze vast amounts of data, and make high-accuracy
predictions, ML can transform the way CSPs approach security. In this paper, we
will explore some of the most recent research in the field of ML-based security
in Cloud Computing. We will examine the features and effectiveness of a range
of ML algorithms, highlighting their unique strengths and potential
limitations. Our goal is to provide a comprehensive overview of the current
state of ML in cloud security and to shed light on the exciting possibilities
that this emerging field has to offer.
</p>
</div>
</dd>
<dt><a name="item179">[179]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.04914" title="Abstract">arXiv:2309.04914</a> [<a href="/pdf/2309.04914" title="Download PDF">pdf</a>, <a href="/format/2309.04914" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MFPNet: Multi-scale Feature Propagation Nwtwork For Lightweight Semantic  Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+G">Guoan Xu</a>, 
<a href="/search/cs?searchtype=author&query=Jia%2C+W">Wenjing Jia</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+T">Tao Wu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+L">Ligeng Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages, 3 figures, 5tables, conference
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">In contrast to the abundant research focusing on large-scale models, the
progress in lightweight semantic segmentation appears to be advancing at a
comparatively slower pace. However, existing compact methods often suffer from
limited feature representation capability due to the shallowness of their
networks. In this paper, we propose a novel lightweight segmentation
architecture, called Multi-scale Feature Propagation Network (MFPNet), to
address the dilemma. Specifically, we design a robust Encoder-Decoder structure
featuring symmetrical residual blocks that consist of flexible bottleneck
residual modules (BRMs) to explore deep and rich muti-scale semantic context.
Furthermore, taking benefit from their capacity to model latent long-range
contextual relationships, we leverage Graph Convolutional Networks (GCNs) to
facilitate multi-scale feature propagation between the BRM blocks. When
evaluated on benchmark datasets, our proposed approach shows superior
segmentation results.
</p>
</div>
</dd>
<dt><a name="item180">[180]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.04917" title="Abstract">arXiv:2309.04917</a> [<a href="/pdf/2309.04917" title="Download PDF">pdf</a>, <a href="/format/2309.04917" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Text-driven Editing of 3D Scenes without Retraining
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fang%2C+S">Shuangkang Fang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yufeng Wang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yi Yang</a>, 
<a href="/search/cs?searchtype=author&query=Tsai%2C+Y">Yi-Hsuan Tsai</a>, 
<a href="/search/cs?searchtype=author&query=Ding%2C+W">Wenrui Ding</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+M">Ming-Hsuan Yang</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+S">Shuchang Zhou</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project Website: <a href="http://sk-fun.fun/DN2N">this http URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Numerous diffusion models have recently been applied to image synthesis and
editing. However, editing 3D scenes is still in its early stages. It poses
various challenges, such as the requirement to design specific methods for
different editing types, retraining new models for various 3D scenes, and the
absence of convenient human interaction during editing. To tackle these issues,
we introduce a text-driven editing method, termed DN2N, which allows for the
direct acquisition of a NeRF model with universal editing capabilities,
eliminating the requirement for retraining. Our method employs off-the-shelf
text-based editing models of 2D images to modify the 3D scene images, followed
by a filtering process to discard poorly edited images that disrupt 3D
consistency. We then consider the remaining inconsistency as a problem of
removing noise perturbation, which can be solved by generating training data
with similar perturbation characteristics for training. We further propose
cross-view regularization terms to help the generalized NeRF model mitigate
these perturbations. Our text-driven method allows users to edit a 3D scene
with their desired description, which is more friendly, intuitive, and
practical than prior works. Empirical results show that our method achieves
multiple editing types, including but not limited to appearance editing,
weather transition, material changing, and style transfer. Most importantly,
our method generalizes well with editing abilities shared among a set of model
parameters without requiring a customized editing model for some specific
scenes, thus inferring novel views with editing effects directly from user
input. The project website is available at <a href="http://sk-fun.fun/DN2N">this http URL</a>
</p>
</div>
</dd>
<dt><a name="item181">[181]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.04918" title="Abstract">arXiv:2309.04918</a> [<a href="/pdf/2309.04918" title="Download PDF">pdf</a>, <a href="/format/2309.04918" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Distributed Kafka Clusters: A Novel Approach to Global Message Ordering
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kumar%2C+S">Shashank Kumar</a>, 
<a href="/search/cs?searchtype=author&query=Sharma%2C+S">Sachin Sharma</a>, 
<a href="/search/cs?searchtype=author&query=Jadon%2C+A">Aryan Jadon</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 Pages, 6 Figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>; Software Engineering (cs.SE)

</div>
<p class="mathjax">In contemporary distributed systems, logs are produced at an astounding rate,
generating terabytes of data within mere seconds. These logs, containing
pivotal details like system metrics, user actions, and diverse events, are
foundational to the system's consistent and accurate operations. Precise log
ordering becomes indispensable to avert potential ambiguities and discordances
in system functionalities. Apache Kafka, a prevalent distributed message queue,
offers significant solutions to various distributed log processing challenges.
However, it presents an inherent limitation while Kafka ensures the in-order
delivery of messages within a single partition to the consumer, it falls short
in guaranteeing a global order for messages spanning multiple partitions. This
research delves into innovative methodologies to achieve global ordering of
messages within a Kafka topic, aiming to bolster the integrity and consistency
of log processing in distributed systems. Our code is available on GitHub.
</p>
</div>
</dd>
<dt><a name="item182">[182]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.04919" title="Abstract">arXiv:2309.04919</a> [<a href="/pdf/2309.04919" title="Download PDF">pdf</a>, <a href="/format/2309.04919" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Unsupervised Chunking with Hierarchical RNN
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+Z">Zijun Wu</a>, 
<a href="/search/cs?searchtype=author&query=Deshmukh%2C+A+A">Anup Anand Deshmukh</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Y">Yongkang Wu</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+J">Jimmy Lin</a>, 
<a href="/search/cs?searchtype=author&query=Mou%2C+L">Lili Mou</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">In Natural Language Processing (NLP), predicting linguistic structures, such
as parsing and chunking, has mostly relied on manual annotations of syntactic
structures. This paper introduces an unsupervised approach to chunking, a
syntactic task that involves grouping words in a non-hierarchical manner. We
present a two-layer Hierarchical Recurrent Neural Network (HRNN) designed to
model word-to-chunk and chunk-to-sentence compositions. Our approach involves a
two-stage training process: pretraining with an unsupervised parser and
finetuning on downstream NLP tasks. Experiments on the CoNLL-2000 dataset
reveal a notable improvement over existing unsupervised methods, enhancing
phrase F1 score by up to 6 percentage points. Further, finetuning with
downstream tasks results in an additional performance improvement.
Interestingly, we observe that the emergence of the chunking structure is
transient during the neural model's downstream-task training. This study
contributes to the advancement of unsupervised syntactic structure discovery
and opens avenues for further research in linguistic theory.
</p>
</div>
</dd>
<dt><a name="item183">[183]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.04922" title="Abstract">arXiv:2309.04922</a> [<a href="/pdf/2309.04922" title="Download PDF">pdf</a>, <a href="/format/2309.04922" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Quantification of Distributionally Robust Risk of Cascade of Failures in  Platoon of Vehicles
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Pandey%2C+V">Vivek Pandey</a>, 
<a href="/search/eess?searchtype=author&query=Liu%2C+G">Guangyi Liu</a>, 
<a href="/search/eess?searchtype=author&query=Amini%2C+A">Arash Amini</a>, 
<a href="/search/eess?searchtype=author&query=Motee%2C+N">Nader Motee</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">Achieving safety is a critical aspect of attaining autonomy in a platoon of
autonomous vehicles. In this paper, we propose a distributionally robust risk
framework to investigate cascading failures in platoons. To examine the impact
of network connectivity and system dynamics on the emergence of cascading
failures, we consider a time-delayed network model of the platoon of vehicles
as a benchmark. To study the cascading effects among pairs of vehicles in the
platoon, we use the measure of conditional distributionally robust functional.
We extend the risk framework to quantify cascading failures by utilizing a
bi-variate normal distribution. Our work establishes closed-form risk formulas
that illustrate the effects of time-delay, noise statistics, underlying
communication graph, and sets of soft failures. The insights gained from our
research can be applied to design safe platoons that are robust to the risk of
cascading failures. We validate our results through extensive simulations.
</p>
</div>
</dd>
<dt><a name="item184">[184]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.04929" title="Abstract">arXiv:2309.04929</a> [<a href="/pdf/2309.04929" title="Download PDF">pdf</a>, <a href="/ps/2309.04929" title="Download PostScript">ps</a>, <a href="/format/2309.04929" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning-based Incentive Mechanism for Task Freshness-aware Vehicular  Twin Migration
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Junhong Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Nie%2C+J">Jiangtian Nie</a>, 
<a href="/search/cs?searchtype=author&query=Wen%2C+J">Jinbo Wen</a>, 
<a href="/search/cs?searchtype=author&query=Kang%2C+J">Jiawen Kang</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+M">Minrui Xu</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+X">Xiaofeng Luo</a>, 
<a href="/search/cs?searchtype=author&query=Niyato%2C+D">Dusit Niyato</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 2023 IEEE 43rd International Conference on Distributed Computing Systems Workshops, ICDCSW 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>

</div>
<p class="mathjax">Vehicular metaverses are an emerging paradigm that integrates extended
reality technologies and real-time sensing data to bridge the physical space
and digital spaces for intelligent transportation, providing immersive
experiences for Vehicular Metaverse Users (VMUs). VMUs access the vehicular
metaverse by continuously updating Vehicular Twins (VTs) deployed on nearby
RoadSide Units (RSUs). Due to the limited RSU coverage, VTs need to be
continuously online migrated between RSUs to ensure seamless immersion and
interactions for VMUs with the nature of mobility. However, the VT migration
process requires sufficient bandwidth resources from RSUs to enable online and
fast migration, leading to a resource trading problem between RSUs and VMUs. To
this end, we propose a learning-based incentive mechanism for migration task
freshness-aware VT migration in vehicular metaverses. To quantify the freshness
of the VT migration task, we first propose a new metric named Age of Twin
Migration (AoTM), which measures the time elapsed of completing the VT
migration task. Then, we propose an AoTM-based Stackelberg model, where RSUs
act as the leader and VMUs act as followers. Due to incomplete information
between RSUs and VMUs caused by privacy and security concerns, we utilize deep
reinforcement learning to learn the equilibrium of the Stackelberg game.
Numerical results demonstrate the effectiveness of our proposed learning-based
incentive mechanism for vehicular metaverses.
</p>
</div>
</dd>
<dt><a name="item185">[185]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.04937" title="Abstract">arXiv:2309.04937</a> [<a href="/pdf/2309.04937" title="Download PDF">pdf</a>, <a href="/format/2309.04937" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LONER: LiDAR Only Neural Representations for Real-Time SLAM
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Isaacson%2C+S">Seth Isaacson</a>, 
<a href="/search/cs?searchtype=author&query=Kung%2C+P">Pou-Chun Kung</a>, 
<a href="/search/cs?searchtype=author&query=Ramanagopal%2C+M">Mani Ramanagopal</a>, 
<a href="/search/cs?searchtype=author&query=Vasudevan%2C+R">Ram Vasudevan</a>, 
<a href="/search/cs?searchtype=author&query=Skinner%2C+K+A">Katherine A. Skinner</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> First two authors equally contributed. Webpage: <a href="https://umautobots.github.io/loner">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">This paper proposes LONER, the first real-time LiDAR SLAM algorithm that uses
a neural implicit scene representation. Existing implicit mapping methods for
LiDAR show promising results in large-scale reconstruction, but either require
groundtruth poses or run slower than real-time. In contrast, LONER uses LiDAR
data to train an MLP to estimate a dense map in real-time, while simultaneously
estimating the trajectory of the sensor. To achieve real-time performance, this
paper proposes a novel information-theoretic loss function that accounts for
the fact that different regions of the map may be learned to varying degrees
throughout online training. % different regions of the map having varying
degrees of uncertainty during online operation. The proposed method is
evaluated qualitatively and quantitatively on two open-source datasets. This
evaluation illustrates that the proposed loss function converges faster and
leads to more accurate geometry reconstruction than other loss functions used
in depth-supervised neural implicit frameworks. Finally, this paper shows that
LONER estimates trajectories competitively with state-of-the-art LiDAR SLAM
methods, while also producing dense maps competitive with existing real-time
implicit mapping methods that use groundtruth poses.
</p>
</div>
</dd>
<dt><a name="item186">[186]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.04940" title="Abstract">arXiv:2309.04940</a> [<a href="/pdf/2309.04940" title="Download PDF">pdf</a>, <a href="/format/2309.04940" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> What&#x27;s Hard in English RST Parsing? Predictive Models for Error Analysis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y+J">Yang Janet Liu</a>, 
<a href="/search/cs?searchtype=author&query=Aoyama%2C+T">Tatsuya Aoyama</a>, 
<a href="/search/cs?searchtype=author&query=Zeldes%2C+A">Amir Zeldes</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> SIGDIAL 2023 camera-ready; 12 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Despite recent advances in Natural Language Processing (NLP), hierarchical
discourse parsing in the framework of Rhetorical Structure Theory remains
challenging, and our understanding of the reasons for this are as yet limited.
In this paper, we examine and model some of the factors associated with parsing
difficulties in previous work: the existence of implicit discourse relations,
challenges in identifying long-distance relations, out-of-vocabulary items, and
more. In order to assess the relative importance of these variables, we also
release two annotated English test-sets with explicit correct and distracting
discourse markers associated with gold standard RST relations. Our results show
that as in shallow discourse parsing, the explicit/implicit distinction plays a
role, but that long-distance dependencies are the main challenge, while lack of
lexical overlap is less of a problem, at least for in-domain parsing. Our final
model is able to predict where errors will occur with an accuracy of 76.3% for
the bottom-up parser and 76.6% for the top-down parser.
</p>
</div>
</dd>
<dt><a name="item187">[187]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.04941" title="Abstract">arXiv:2309.04941</a> [<a href="/pdf/2309.04941" title="Download PDF">pdf</a>, <a href="/ps/2309.04941" title="Download PostScript">ps</a>, <a href="/format/2309.04941" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Distance-Restricted Folklore Weisfeiler-Leman GNNs with Provable Cycle  Counting Power
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhou%2C+J">Junru Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+J">Jiarui Feng</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xiyuan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+M">Muhan Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">The ability of graph neural networks (GNNs) to count certain graph
substructures, especially cycles, is important for the success of GNNs on a
wide range of tasks. It has been recently used as a popular metric for
evaluating the expressive power of GNNs. Many of the proposed GNN models with
provable cycle counting power are based on subgraph GNNs, i.e., extracting a
bag of subgraphs from the input graph, generating representations for each
subgraph, and using them to augment the representation of the input graph.
However, those methods require heavy preprocessing, and suffer from high time
and memory costs. In this paper, we overcome the aforementioned limitations of
subgraph GNNs by proposing a novel class of GNNs -- $d$-Distance-Restricted
FWL(2) GNNs, or $d$-DRFWL(2) GNNs. $d$-DRFWL(2) GNNs use node pairs whose
mutual distances are at most $d$ as the units for message passing to balance
the expressive power and complexity. By performing message passing among
distance-restricted node pairs in the original graph, $d$-DRFWL(2) GNNs avoid
the expensive subgraph extraction operations in subgraph GNNs, making both the
time and space complexity lower. We theoretically show that the discriminative
power of $d$-DRFWL(2) GNNs strictly increases as $d$ increases. More
importantly, $d$-DRFWL(2) GNNs have provably strong cycle counting power even
with $d=2$: they can count all 3, 4, 5, 6-cycles. Since 6-cycles (e.g., benzene
rings) are ubiquitous in organic molecules, being able to detect and count them
is crucial for achieving robust and generalizable performance on molecular
tasks. Experiments on both synthetic datasets and molecular datasets verify our
theory. To the best of our knowledge, our model is the most efficient GNN model
to date (both theoretically and empirically) that can count up to 6-cycles.
</p>
</div>
</dd>
<dt><a name="item188">[188]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.04943" title="Abstract">arXiv:2309.04943</a> [<a href="/pdf/2309.04943" title="Download PDF">pdf</a>, <a href="/format/2309.04943" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A multi-fidelity machine learning based semi-Lagrangian finite volume  scheme for linear transport equations and the nonlinear Vlasov-Poisson system
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Chen%2C+Y">Yongsheng Chen</a>, 
<a href="/search/math?searchtype=author&query=Guo%2C+W">Wei Guo</a>, 
<a href="/search/math?searchtype=author&query=Zhong%2C+X">Xinghui Zhong</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">Machine-learning (ML) based discretization has been developed to simulate
complex partial differential equations (PDEs) with tremendous success across
various fields. These learned PDE solvers can effectively resolve the
underlying solution structures of interest and achieve a level of accuracy
which often requires an order-of-magnitude finer grid for a conventional
numerical method using polynomial-based approximations. In a previous work in
[13], we introduced a learned finite volume discretization that further
incorporates the semi-Lagrangian (SL) mechanism, enabling larger CFL numbers
for stability. However, the efficiency and effectiveness of such methodology
heavily rely on the availability of abundant high-resolution training data,
which can be prohibitively expensive to obtain. To address this challenge, in
this paper, we propose a novel multi-fidelity ML-based SL method for transport
equations. This method leverages a combination of a small amount of
high-fidelity data and sufficient but cheaper low-fidelity data. The approach
is designed based on a composite convolutional neural network architecture that
explore the inherent correlation between high-fidelity and low-fidelity data.
The proposed method demonstrates the capability to achieve a reasonable level
of accuracy, particularly in scenarios where a single-fidelity model fails to
generalize effectively. We further extend the method to the nonlinear
Vlasov-Poisson system by employing high order Runge-Kutta exponential
integrators. A collection of numerical tests are provided to validate the
efficiency and accuracy of the proposed method.
</p>
</div>
</dd>
<dt><a name="item189">[189]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.04945" title="Abstract">arXiv:2309.04945</a> [<a href="/pdf/2309.04945" title="Download PDF">pdf</a>, <a href="/format/2309.04945" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> O2ATH: An OpenMP Offloading Toolkit for the Sunway Heterogeneous  Manycore Platform
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lin%2C+H">Haoran Lin</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+L">Lifeng Yan</a>, 
<a href="/search/cs?searchtype=author&query=Chang%2C+Q">Qixin Chang</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+H">Haitian Lu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+C">Chenlin Li</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+Q">Quanjie He</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+Z">Zeyu Song</a>, 
<a href="/search/cs?searchtype=author&query=Duan%2C+X">Xiaohui Duan</a>, 
<a href="/search/cs?searchtype=author&query=Yin%2C+Z">Zekun Yin</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yuxuan Li</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zhao Liu</a>, 
<a href="/search/cs?searchtype=author&query=Xue%2C+W">Wei Xue</a>, 
<a href="/search/cs?searchtype=author&query=Fu%2C+H">Haohuan Fu</a>, 
<a href="/search/cs?searchtype=author&query=Gan%2C+L">Lin Gan</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+G">Guangwen Yang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+W">Weiguo Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 15 pages, 6 figures, 5 tables,
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Programming Languages (cs.PL)</span>; Software Engineering (cs.SE)

</div>
<p class="mathjax">The next generation Sunway supercomputer employs the SW26010pro processor,
which features a specialized on-chip heterogeneous architecture. Applications
with significant hotspots can benefit from the great computation capacity
improvement of Sunway many-core architectures by carefully making intensive
manual many-core parallelization efforts. However, some legacy projects with
large codebases, such as CESM, ROMS and WRF, contain numerous lines of code and
do not have significant hotspots. The cost of manually porting such
applications to the Sunway architecture is almost unaffordable. To overcome
such a challenge, we have developed a toolkit named O2ATH. O2ATH forwards GNU
OpenMP runtime library calls to Sunway's Athread library, which greatly
simplifies the parallelization work on the Sunway architecture.O2ATH enables
users to write both MPE and CPE code in a single file, and parallelization can
be achieved by utilizing OpenMP directives and attributes. In practice, O2ATH
has helped us to port two large projects, CESM and ROMS, to the CPEs of the
next generation Sunway supercomputers via the OpenMP offload method. In the
experiments, kernel speedups range from 3 to 15 times, resulting in 3 to 6
times whole application speedups.Furthermore, O2ATH requires significantly
fewer code modifications compared to manually crafting CPE functions.This
indicates that O2ATH can greatly enhance development efficiency when porting or
optimizing large software projects on Sunway supercomputers.
</p>
</div>
</dd>
<dt><a name="item190">[190]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.04946" title="Abstract">arXiv:2309.04946</a> [<a href="/pdf/2309.04946" title="Download PDF">pdf</a>, <a href="/format/2309.04946" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Efficient Emotional Adaptation for Audio-Driven Talking-Head Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gan%2C+Y">Yuan Gan</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Z">Zongxin Yang</a>, 
<a href="/search/cs?searchtype=author&query=Yue%2C+X">Xihang Yue</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+L">Lingyun Sun</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yi Yang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to ICCV 2023. Project page: <a href="https://yuangan.github.io/eat/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Computer Vision and Pattern Recognition (cs.CV); Graphics (cs.GR); Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">Audio-driven talking-head synthesis is a popular research topic for virtual
human-related applications. However, the inflexibility and inefficiency of
existing methods, which necessitate expensive end-to-end training to transfer
emotions from guidance videos to talking-head predictions, are significant
limitations. In this work, we propose the Emotional Adaptation for Audio-driven
Talking-head (EAT) method, which transforms emotion-agnostic talking-head
models into emotion-controllable ones in a cost-effective and efficient manner
through parameter-efficient adaptations. Our approach utilizes a pretrained
emotion-agnostic talking-head transformer and introduces three lightweight
adaptations (the Deep Emotional Prompts, Emotional Deformation Network, and
Emotional Adaptation Module) from different perspectives to enable precise and
realistic emotion controls. Our experiments demonstrate that our approach
achieves state-of-the-art performance on widely-used benchmarks, including LRW
and MEAD. Additionally, our parameter-efficient adaptations exhibit remarkable
generalization ability, even in scenarios where emotional training videos are
scarce or nonexistent. Project website: https://yuangan.github.io/eat/
</p>
</div>
</dd>
<dt><a name="item191">[191]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.04949" title="Abstract">arXiv:2309.04949</a> [<a href="/pdf/2309.04949" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A multiple k-means cluster ensemble framework for clustering citation  trajectories
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chakraborty%2C+J">Joyita Chakraborty</a>, 
<a href="/search/cs?searchtype=author&query=Pradhan%2C+D+K">Dinesh K. Pradhan</a>, 
<a href="/search/cs?searchtype=author&query=Nandi%2C+S">Subrata Nandi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 29 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>; Databases (cs.DB); Digital Libraries (cs.DL); Information Retrieval (cs.IR); Machine Learning (cs.LG)

</div>
<p class="mathjax">Citation maturity time varies for different articles. However, the impact of
all articles is measured in a fixed window. Clustering their citation
trajectories helps understand the knowledge diffusion process and reveals that
not all articles gain immediate success after publication. Moreover, clustering
trajectories is necessary for paper impact recommendation algorithms. It is a
challenging problem because citation time series exhibit significant
variability due to non linear and non stationary characteristics. Prior works
propose a set of arbitrary thresholds and a fixed rule based approach. All
methods are primarily parameter dependent. Consequently, it leads to
inconsistencies while defining similar trajectories and ambiguities regarding
their specific number. Most studies only capture extreme trajectories. Thus, a
generalised clustering framework is required. This paper proposes a feature
based multiple k means cluster ensemble framework. 1,95,783 and 41,732 well
cited articles from the Microsoft Academic Graph data are considered for
clustering short term (10 year) and long term (30 year) trajectories,
respectively. It has linear run time. Four distinct trajectories are obtained
Early Rise Rapid Decline (2.2%), Early Rise Slow Decline (45%), Delayed Rise No
Decline (53%), and Delayed Rise Slow Decline (0.8%). Individual trajectory
differences for two different spans are studied. Most papers exhibit Early Rise
Slow Decline and Delayed Rise No Decline patterns. The growth and decay times,
cumulative citation distribution, and peak characteristics of individual
trajectories are redefined empirically. A detailed comparative study reveals
our proposed methodology can detect all distinct trajectory classes.
</p>
</div>
</dd>
<dt><a name="item192">[192]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.04950" title="Abstract">arXiv:2309.04950</a> [<a href="/pdf/2309.04950" title="Download PDF">pdf</a>, <a href="/format/2309.04950" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Dominant Interferer-based Approximation for Uplink SINR Meta  Distribution in Cellular Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Qin%2C+Y">Yujie Qin</a>, 
<a href="/search/cs?searchtype=author&query=Kishk%2C+M+A">Mustafa A. Kishk</a>, 
<a href="/search/cs?searchtype=author&query=Alouini%2C+M">Mohamed-Slim Alouini</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: text overlap with <a href="/abs/2302.03574">arXiv:2302.03574</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Systems and Control (eess.SY)

</div>
<p class="mathjax">This work studies the signal-to-interference-plus-noise-ratio (SINR) meta
distribution for the uplink transmission of a Poisson network with Rayleigh
fading by using the dominant interferer-based approximation. The proposed
approach relies on computing the mix of exact and mean-field analysis of
interference. In particular, it requires the distance distribution of the
nearest interferer and the conditional average of the rest of the interference.
Using the widely studied fractional path-loss inversion power control and
modeling the spatial locations of base stations (BSs) by a Poisson point
process (PPP), we obtain the meta distribution based on the proposed method and
compare it with the traditional beta approximation, as well as the exact
results obtained via Monte-Carlo simulations. Our numerical results validate
that the proposed method shows good matching and is time competitive.
</p>
</div>
</dd>
<dt><a name="item193">[193]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.04951" title="Abstract">arXiv:2309.04951</a> [<a href="/pdf/2309.04951" title="Download PDF">pdf</a>, <a href="/ps/2309.04951" title="Download PostScript">ps</a>, <a href="/format/2309.04951" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multi-document Summarization: A Comparative Evaluation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hewapathirana%2C+K">Kushan Hewapathirana</a> (1 and 2), 
<a href="/search/cs?searchtype=author&query=de+Silva%2C+N">Nisansa de Silva</a> (1), 
<a href="/search/cs?searchtype=author&query=Athuraliya%2C+C+D">C.D. Athuraliya</a> (2) ((1) Department of Computer Science &amp; Engineering, University of Moratuwa, Sri Lanka, (2) ConscientAI, Sri Lanka)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">This paper is aimed at evaluating state-of-the-art models for Multi-document
Summarization (MDS) on different types of datasets in various domains and
investigating the limitations of existing models to determine future research
directions. To address this gap, we conducted an extensive literature review to
identify state-of-the-art models and datasets. We analyzed the performance of
PRIMERA and PEGASUS models on BigSurvey-MDS and MS$^2$ datasets, which posed
unique challenges due to their varied domains. Our findings show that the
General-Purpose Pre-trained Model LED outperforms PRIMERA and PEGASUS on the
MS$^2$ dataset. We used the ROUGE score as a performance metric to evaluate the
identified models on different datasets. Our study provides valuable insights
into the models' strengths and weaknesses, as well as their applicability in
different domains. This work serves as a reference for future MDS research and
contributes to the development of accurate and robust models which can be
utilized on demanding datasets with academically and/or scientifically complex
data as well as generalized, relatively simple datasets.
</p>
</div>
</dd>
<dt><a name="item194">[194]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.04952" title="Abstract">arXiv:2309.04952</a> [<a href="/pdf/2309.04952" title="Download PDF">pdf</a>, <a href="/ps/2309.04952" title="Download PostScript">ps</a>, <a href="/format/2309.04952" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Hutchinson&#x27;s Estimator is Bad at Kronecker-Trace-Estimation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Meyer%2C+R+A">Raphael A. Meyer</a>, 
<a href="/search/cs?searchtype=author&query=Avron%2C+H">Haim Avron</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 35 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>; Numerical Analysis (math.NA)

</div>
<p class="mathjax">We study the problem of estimating the trace of a matrix $\mathbf{A}$ that
can only be accessed through Kronecker-matrix-vector products. That is, for any
Kronecker-structured vector $\boldsymbol{\mathrm{x}} = \otimes_{i=1}^k
\boldsymbol{\mathrm{x}}_i$, we can compute $\mathbf{A}\boldsymbol{\mathrm{x}}$.
We focus on the natural generalization of Hutchinson's Estimator to this
setting, proving tight rates for the number of matrix-vector products this
estimator needs to find a $(1\pm\varepsilon)$ approximation to the trace of
$\mathbf{A}$.
<br />We find an exact equation for the variance of the estimator when using a
Kronecker of Gaussian vectors, revealing an intimate relationship between
Hutchinson's Estimator, the partial trace operator, and the partial transpose
operator. Using this equation, we show that when using real vectors, in the
worst case, this estimator needs $O(\frac{3^k}{\varepsilon^2})$ products to
recover a $(1\pm\varepsilon)$ approximation of the trace of any PSD
$\mathbf{A}$, and a matching lower bound for certain PSD $\mathbf{A}$. However,
when using complex vectors, this can be exponentially improved to
$\Theta(\frac{2^k}{\varepsilon^2})$. We show that Hutchinson's Estimator
converges slowest when $\mathbf{A}$ itself also has Kronecker structure. We
conclude with some theoretical evidence suggesting that, by combining
Hutchinson's Estimator with other techniques, it may be possible to avoid the
exponential dependence on $k$.
</p>
</div>
</dd>
<dt><a name="item195">[195]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.04954" title="Abstract">arXiv:2309.04954</a> [<a href="/pdf/2309.04954" title="Download PDF">pdf</a>, <a href="/format/2309.04954" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Penny a Function: Towards Cost Transparent Cloud Programming
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=B%C3%B6hme%2C+L">Lukas B&#xf6;hme</a>, 
<a href="/search/cs?searchtype=author&query=Beckmann%2C+T">Tom Beckmann</a>, 
<a href="/search/cs?searchtype=author&query=Baltes%2C+S">Sebastian Baltes</a>, 
<a href="/search/cs?searchtype=author&query=Hirschfeld%2C+R">Robert Hirschfeld</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Proceedings of the 2nd ACM SIGPLAN International Workshop on Programming Abstractions and Interactive Notations, Tools, and Environments (PAINT 2023), 10 pages, 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
<p class="mathjax">Understanding and managing monetary cost factors is crucial when developing
cloud applications. However, the diverse range of factors influencing costs for
computation, storage, and networking in cloud applications poses a challenge
for developers who want to manage and minimize costs proactively. Existing
tools for understanding cost factors are often detached from source code,
causing opaqueness regarding the origin of costs. Moreover, existing cost
models for cloud applications focus on specific factors such as compute
resources and necessitate manual effort to create the models. This paper
presents initial work toward a cost model based on a directed graph that allows
deriving monetary cost estimations directly from code using static analysis.
Leveraging the cost model, we explore visualizations embedded in a code editor
that display costs close to the code causing them. This makes cost exploration
an integrated part of the developer experience, thereby removing the overhead
of external tooling for cost estimation of cloud applications at development
time.
</p>
</div>
</dd>
<dt><a name="item196">[196]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.04958" title="Abstract">arXiv:2309.04958</a> [<a href="/pdf/2309.04958" title="Download PDF">pdf</a>, <a href="/format/2309.04958" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Semi-Supervised learning for Face Anti-Spoofing using Apex frame
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Muhammad%2C+U">Usman Muhammad</a>, 
<a href="/search/cs?searchtype=author&query=Oussalah%2C+M">Mourad Oussalah</a>, 
<a href="/search/cs?searchtype=author&query=Laaksonen%2C+J">Jorma Laaksonen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Conventional feature extraction techniques in the face anti-spoofing domain
either analyze the entire video sequence or focus on a specific segment to
improve model performance. However, identifying the optimal frames that provide
the most valuable input for the face anti-spoofing remains a challenging task.
In this paper, we address this challenge by employing Gaussian weighting to
create apex frames for videos. Specifically, an apex frame is derived from a
video by computing a weighted sum of its frames, where the weights are
determined using a Gaussian distribution centered around the video's central
frame. Furthermore, we explore various temporal lengths to produce multiple
unlabeled apex frames using a Gaussian function, without the need for
convolution. By doing so, we leverage the benefits of semi-supervised learning,
which considers both labeled and unlabeled apex frames to effectively
discriminate between live and spoof classes. Our key contribution emphasizes
the apex frame's capacity to represent the most significant moments in the
video, while unlabeled apex frames facilitate efficient semi-supervised
learning, as they enable the model to learn from videos of varying temporal
lengths. Experimental results using four face anti-spoofing databases: CASIA,
REPLAY-ATTACK, OULU-NPU, and MSU-MFSD demonstrate the apex frame's efficacy in
advancing face anti-spoofing techniques.
</p>
</div>
</dd>
<dt><a name="item197">[197]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.04959" title="Abstract">arXiv:2309.04959</a> [<a href="/pdf/2309.04959" title="Download PDF">pdf</a>, <a href="/ps/2309.04959" title="Download PostScript">ps</a>, <a href="/format/2309.04959" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Information Theory of Blockchain Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+Q">Quan-Lin Li</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+Y">Yaqian Ma</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+J">Jing-Yu Ma</a>, 
<a href="/search/cs?searchtype=author&query=Chang%2C+Y">Yan-Xia Chang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages, 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>

</div>
<p class="mathjax">In this paper, we apply the information theory to provide an approximate
expression of the steady-state probability distribution for blockchain systems.
We achieve this goal by maximizing an entropy function subject to specific
constraints. These constraints are based on some prior information, including
the average numbers of transactions in the block and the transaction pool,
respectively. Furthermore, we use some numerical experiments to analyze how the
key factors in this approximate expression depend on the crucial parameters of
the blockchain system. As a result, this approximate expression has important
theoretical significance in promoting practical applications of blockchain
technology. At the same time, not only do the method and results given in this
paper provide a new line in the study of blockchain queueing systems, but they
also provide the theoretical basis and technical support for how to apply the
information theory to the investigation of blockchain queueing networks and
stochastic models more broadly.
</p>
</div>
</dd>
<dt><a name="item198">[198]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.04961" title="Abstract">arXiv:2309.04961</a> [<a href="/pdf/2309.04961" title="Download PDF">pdf</a>, <a href="/format/2309.04961" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multi-modal Extreme Classification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mittal%2C+A">Anshul Mittal</a>, 
<a href="/search/cs?searchtype=author&query=Dahiya%2C+K">Kunal Dahiya</a>, 
<a href="/search/cs?searchtype=author&query=Malani%2C+S">Shreya Malani</a>, 
<a href="/search/cs?searchtype=author&query=Ramaswamy%2C+J">Janani Ramaswamy</a>, 
<a href="/search/cs?searchtype=author&query=Kuruvilla%2C+S">Seba Kuruvilla</a>, 
<a href="/search/cs?searchtype=author&query=Ajmera%2C+J">Jitendra Ajmera</a>, 
<a href="/search/cs?searchtype=author&query=Chang%2C+K">Keng-hao Chang</a>, 
<a href="/search/cs?searchtype=author&query=Agarwal%2C+S">Sumeet Agarwal</a>, 
<a href="/search/cs?searchtype=author&query=Kar%2C+P">Purushottam Kar</a>, 
<a href="/search/cs?searchtype=author&query=Varma%2C+M">Manik Varma</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Proceedings of the IEEE/CVF Conference on Computer Vision and
  Pattern Recognition (CVPR) 2022
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">This paper develops the MUFIN technique for extreme classification (XC) tasks
with millions of labels where datapoints and labels are endowed with visual and
textual descriptors. Applications of MUFIN to product-to-product recommendation
and bid query prediction over several millions of products are presented.
Contemporary multi-modal methods frequently rely on purely embedding-based
methods. On the other hand, XC methods utilize classifier architectures to
offer superior accuracies than embedding only methods but mostly focus on
text-based categorization tasks. MUFIN bridges this gap by reformulating
multi-modal categorization as an XC problem with several millions of labels.
This presents the twin challenges of developing multi-modal architectures that
can offer embeddings sufficiently expressive to allow accurate categorization
over millions of labels; and training and inference routines that scale
logarithmically in the number of labels. MUFIN develops an architecture based
on cross-modal attention and trains it in a modular fashion using pre-training
and positive and negative mining. A novel product-to-product recommendation
dataset MM-AmazonTitles-300K containing over 300K products was curated from
publicly available amazon.com listings with each product endowed with a title
and multiple images. On the all datasets MUFIN offered at least 3% higher
accuracy than leading text-based, image-based and multi-modal techniques. Code
for MUFIN is available at https://github.com/Extreme-classification/MUFIN
</p>
</div>
</dd>
<dt><a name="item199">[199]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.04965" title="Abstract">arXiv:2309.04965</a> [<a href="/pdf/2309.04965" title="Download PDF">pdf</a>, <a href="/format/2309.04965" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Prefix-diffusion: A Lightweight Diffusion Model for Diverse Image  Captioning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+G">Guisheng Liu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yi Li</a>, 
<a href="/search/cs?searchtype=author&query=Fei%2C+Z">Zhengcong Fei</a>, 
<a href="/search/cs?searchtype=author&query=Fu%2C+H">Haiyan Fu</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+X">Xiangyang Luo</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+Y">Yanqing Guo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages,4 figures, 6 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL)

</div>
<p class="mathjax">While impressive performance has been achieved in image captioning, the
limited diversity of the generated captions and the large parameter scale
remain major barriers to the real-word application of these systems. In this
work, we propose a lightweight image captioning network in combination with
continuous diffusion, called Prefix-diffusion. To achieve diversity, we design
an efficient method that injects prefix image embeddings into the denoising
process of the diffusion model. In order to reduce trainable parameters, we
employ a pre-trained model to extract image features and further design an
extra mapping network. Prefix-diffusion is able to generate diverse captions
with relatively less parameters, while maintaining the fluency and relevance of
the captions benefiting from the generative capabilities of the diffusion
model. Our work paves the way for scaling up diffusion models for image
captioning, and achieves promising performance compared with recent approaches.
</p>
</div>
</dd>
<dt><a name="item200">[200]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.04967" title="Abstract">arXiv:2309.04967</a> [<a href="/pdf/2309.04967" title="Download PDF">pdf</a>, <a href="/format/2309.04967" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Fully Decoupled End-to-End Person Search
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+P">Pengcheng Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Bai%2C+X">Xiao Bai</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+J">Jin Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Ning%2C+X">Xin Ning</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> DICTA 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">End-to-end person search aims to jointly detect and re-identify a target
person in raw scene images with a unified model. The detection task unifies all
persons while the re-id task discriminates different identities, resulting in
conflict optimal objectives. Existing works proposed to decouple end-to-end
person search to alleviate such conflict. Yet these methods are still
sub-optimal on one or two of the sub-tasks due to their partially decoupled
models, which limits the overall person search performance. In this paper, we
propose to fully decouple person search towards optimal person search. A
task-incremental person search network is proposed to incrementally construct
an end-to-end model for the detection and re-id sub-task, which decouples the
model architecture for the two sub-tasks. The proposed task-incremental network
allows task-incremental training for the two conflicting tasks. This enables
independent learning for different objectives thus fully decoupled the model
for persons earch. Comprehensive experimental evaluations demonstrate the
effectiveness of the proposed fully decoupled models for end-to-end person
search.
</p>
</div>
</dd>
<dt><a name="item201">[201]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.04970" title="Abstract">arXiv:2309.04970</a> [<a href="/pdf/2309.04970" title="Download PDF">pdf</a>, <a href="/format/2309.04970" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A rapid and automated computational approach to the design of  multistable soft actuators
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Mirramezani%2C+M">Mehran Mirramezani</a>, 
<a href="/search/math?searchtype=author&query=Oktay%2C+D">Deniz Oktay</a>, 
<a href="/search/math?searchtype=author&query=Adams%2C+R+P">Ryan P. Adams</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Computational Engineering, Finance, and Science (cs.CE)

</div>
<p class="mathjax">We develop an automated computational modeling framework for rapid
gradient-based design of multistable soft mechanical structures composed of
non-identical bistable unit cells with appropriate geometric parameterization.
This framework includes a custom isogeometric analysis-based continuum
mechanics solver that is robust and end-to-end differentiable, which enables
geometric and material optimization to achieve a desired multistability
pattern. We apply this numerical modeling approach in two dimensions to design
a variety of multistable structures, accounting for various geometric and
material constraints. Our framework demonstrates consistent agreement with
experimental results, and robust performance in designing for multistability,
which facilities soft actuator design with high precision and reliability.
</p>
</div>
</dd>
<dt><a name="item202">[202]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.04971" title="Abstract">arXiv:2309.04971</a> [<a href="/pdf/2309.04971" title="Download PDF">pdf</a>, <a href="/format/2309.04971" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Prompt Learning With Knowledge Memorizing Prototypes For Generalized  Few-Shot Intent Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Luoyiching%2C+C">Chaiyut Luoyiching</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yangning Li</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yinghui Li</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+R">Rongsheng Li</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+H">Hai-Tao Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+N">Nannan Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Su%2C+H">Hanjing Su</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Under Review
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Generalized Few-Shot Intent Detection (GFSID) is challenging and realistic
because it needs to categorize both seen and novel intents simultaneously.
Previous GFSID methods rely on the episodic learning paradigm, which makes it
hard to extend to a generalized setup as they do not explicitly learn the
classification of seen categories and the knowledge of seen intents. To address
the dilemma, we propose to convert the GFSID task into the class incremental
learning paradigm. Specifically, we propose a two-stage learning framework,
which sequentially learns the knowledge of different intents in various periods
via prompt learning. And then we exploit prototypes for categorizing both seen
and novel intents. Furthermore, to achieve the transfer knowledge of intents in
different stages, for different scenarios we design two knowledge preservation
methods which close to realistic applications. Extensive experiments and
detailed analyses on two widely used datasets show that our framework based on
the class incremental learning paradigm achieves promising performance.
</p>
</div>
</dd>
<dt><a name="item203">[203]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.04974" title="Abstract">arXiv:2309.04974</a> [<a href="/pdf/2309.04974" title="Download PDF">pdf</a>, <a href="/format/2309.04974" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Continual Robot Learning using Self-Supervised Task Inference
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hafez%2C+M+B">Muhammad Burhan Hafez</a>, 
<a href="/search/cs?searchtype=author&query=Wermter%2C+S">Stefan Wermter</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted for publication in IEEE Transactions on Cognitive and Developmental Systems
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Endowing robots with the human ability to learn a growing set of skills over
the course of a lifetime as opposed to mastering single tasks is an open
problem in robot learning. While multi-task learning approaches have been
proposed to address this problem, they pay little attention to task inference.
In order to continually learn new tasks, the robot first needs to infer the
task at hand without requiring predefined task representations. In this paper,
we propose a self-supervised task inference approach. Our approach learns
action and intention embeddings from self-organization of the observed movement
and effect parts of unlabeled demonstrations and a higher-level behavior
embedding from self-organization of the joint action-intention embeddings. We
construct a behavior-matching self-supervised learning objective to train a
novel Task Inference Network (TINet) to map an unlabeled demonstration to its
nearest behavior embedding, which we use as the task representation. A
multi-task policy is built on top of the TINet and trained with reinforcement
learning to optimize performance over tasks. We evaluate our approach in the
fixed-set and continual multi-task learning settings with a humanoid robot and
compare it to different multi-task learning baselines. The results show that
our approach outperforms the other baselines, with the difference being more
pronounced in the challenging continual learning setting, and can infer tasks
from incomplete demonstrations. Our approach is also shown to generalize to
unseen tasks based on a single demonstration in one-shot task generalization
experiments.
</p>
</div>
</dd>
<dt><a name="item204">[204]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.04975" title="Abstract">arXiv:2309.04975</a> [<a href="/pdf/2309.04975" title="Download PDF">pdf</a>, <a href="/ps/2309.04975" title="Download PostScript">ps</a>, <a href="/format/2309.04975" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Trade-Off Between Beamforming and Macro-Diversity Gains in Distributed  mMIMO
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tominaga%2C+E+N">Eduardo Noboro Tominaga</a>, 
<a href="/search/cs?searchtype=author&query=Su%2C+H">Hsuan-Jung Su</a>, 
<a href="/search/cs?searchtype=author&query=Du%2C+J">Jinfeng Du</a>, 
<a href="/search/cs?searchtype=author&query=Venkatesan%2C+S">Sivarama Venkatesan</a>, 
<a href="/search/cs?searchtype=author&query=Souza%2C+R+D">Richard Demo Souza</a>, 
<a href="/search/cs?searchtype=author&query=Alves%2C+H">Hirley Alves</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages, 3 figures. Manuscript submitted to the IEEE Wireless Communications and Networking Conference (WCNC) 2024, Dubai, United Arab Emirates
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">Industry and academia have been working towards the evolution from
Centralized massive Multiple-Input Multiple-Output (CmMIMO) to Distributed
mMIMO (DmMIMO) architectures. Instead of splitting a coverage area into many
cells, each served by a single Base Station equipped with several antennas, the
whole coverage area is jointly covered by several Access Points (AP) equipped
with few or single antennas. Nevertheless, when choosing between deploying more
APs with few or single antennas or fewer APs equipped with many antennas, one
observes an inherent trade-off between the beamforming and macro-diversity
gains that has not been investigated in the literature. Given a total number of
antenna elements and total downlink power, under a channel model that takes
into account a probability of Line-of-Sight (LoS) as a function of the distance
between the User Equipments (UEs) and APs, our numerical results show that
there exists a ``sweet spot" on the optimal number of APs and of antenna
elements per AP which is a function of the physical dimensions of the coverage
area.
</p>
</div>
</dd>
<dt><a name="item205">[205]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.04976" title="Abstract">arXiv:2309.04976</a> [<a href="/pdf/2309.04976" title="Download PDF">pdf</a>, <a href="/format/2309.04976" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AVARS -- Alleviating Unexpected Urban Road Traffic Congestion using UAVs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Guo%2C+J">Jiaying Guo</a>, 
<a href="/search/cs?searchtype=author&query=Jones%2C+M+R">Michael R. Jones</a>, 
<a href="/search/cs?searchtype=author&query=Djahel%2C+S">Soufiene Djahel</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Shen Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Systems and Control (eess.SY)

</div>
<p class="mathjax">Reducing unexpected urban traffic congestion caused by en-route events (e.g.,
road closures, car crashes, etc.) often requires fast and accurate reactions to
choose the best-fit traffic signals. Traditional traffic light control systems,
such as SCATS and SCOOT, are not efficient as their traffic data provided by
induction loops has a low update frequency (i.e., longer than 1 minute).
Moreover, the traffic light signal plans used by these systems are selected
from a limited set of candidate plans pre-programmed prior to unexpected
events' occurrence. Recent research demonstrates that camera-based traffic
light systems controlled by deep reinforcement learning (DRL) algorithms are
more effective in reducing traffic congestion, in which the cameras can provide
high-frequency high-resolution traffic data. However, these systems are costly
to deploy in big cities due to the excessive potential upgrades required to
road infrastructure. In this paper, we argue that Unmanned Aerial Vehicles
(UAVs) can play a crucial role in dealing with unexpected traffic congestion
because UAVs with onboard cameras can be economically deployed when and where
unexpected congestion occurs. Then, we propose a system called "AVARS" that
explores the potential of using UAVs to reduce unexpected urban traffic
congestion using DRL-based traffic light signal control. This approach is
validated on a widely used open-source traffic simulator with practical UAV
settings, including its traffic monitoring ranges and battery lifetime. Our
simulation results show that AVARS can effectively recover the unexpected
traffic congestion in Dublin, Ireland, back to its original un-congested level
within the typical battery life duration of a UAV.
</p>
</div>
</dd>
<dt><a name="item206">[206]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.04977" title="Abstract">arXiv:2309.04977</a> [<a href="/pdf/2309.04977" title="Download PDF">pdf</a>, <a href="/format/2309.04977" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> RGAT: A Deeper Look into Syntactic Dependency Information for  Coreference Resolution
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Meng%2C+Y">Yuan Meng</a>, 
<a href="/search/cs?searchtype=author&query=Pan%2C+X">Xuhao Pan</a>, 
<a href="/search/cs?searchtype=author&query=Chang%2C+J">Jun Chang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yue Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 5 figures
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> 2023 International Joint Conference on Neural Networks (IJCNN)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Although syntactic information is beneficial for many NLP tasks, combining it
with contextual information between words to solve the coreference resolution
problem needs to be further explored. In this paper, we propose an end-to-end
parser that combines pre-trained BERT with a Syntactic Relation Graph Attention
Network (RGAT) to take a deeper look into the role of syntactic dependency
information for the coreference resolution task. In particular, the RGAT model
is first proposed, then used to understand the syntactic dependency graph and
learn better task-specific syntactic embeddings. An integrated architecture
incorporating BERT embeddings and syntactic embeddings is constructed to
generate blending representations for the downstream task. Our experiments on a
public Gendered Ambiguous Pronouns (GAP) dataset show that with the supervision
learning of the syntactic dependency graph and without fine-tuning the entire
BERT, we increased the F1-score of the previous best model (RGCN-with-BERT)
from 80.3% to 82.5%, compared to the F1-score by single BERT embeddings from
78.5% to 82.5%. Experimental results on another public dataset - OntoNotes 5.0
demonstrate that the performance of the model is also improved by incorporating
syntactic dependency information learned from RGAT.
</p>
</div>
</dd>
<dt><a name="item207">[207]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.04979" title="Abstract">arXiv:2309.04979</a> [<a href="/pdf/2309.04979" title="Download PDF">pdf</a>, <a href="/format/2309.04979" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Retrieval-Augmented Meta Learning for Low-Resource Text Classification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+R">Rongsheng Li</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yangning Li</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yinghui Li</a>, 
<a href="/search/cs?searchtype=author&query=Luoyiching%2C+C">Chaiyut Luoyiching</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+H">Hai-Tao Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+N">Nannan Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Su%2C+H">Hanjing Su</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Under Review
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Meta learning have achieved promising performance in low-resource text
classification which aims to identify target classes with knowledge transferred
from source classes with sets of small tasks named episodes. However, due to
the limited training data in the meta-learning scenario and the inherent
properties of parameterized neural networks, poor generalization performance
has become a pressing problem that needs to be addressed. To deal with this
issue, we propose a meta-learning based method called Retrieval-Augmented Meta
Learning(RAML). It not only uses parameterization for inference but also
retrieves non-parametric knowledge from an external corpus to make inferences,
which greatly alleviates the problem of poor generalization performance caused
by the lack of diverse training data in meta-learning. This method differs from
previous models that solely rely on parameters, as it explicitly emphasizes the
importance of non-parametric knowledge, aiming to strike a balance between
parameterized neural networks and non-parametric knowledge. The model is
required to determine which knowledge to access and utilize during inference.
Additionally, our multi-view passages fusion network module can effectively and
efficiently integrate the retrieved information into low-resource
classification task. The extensive experiments demonstrate that RAML
significantly outperforms current SOTA low-resource text classification models.
</p>
</div>
</dd>
<dt><a name="item208">[208]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.04981" title="Abstract">arXiv:2309.04981</a> [<a href="/pdf/2309.04981" title="Download PDF">pdf</a>, <a href="/ps/2309.04981" title="Download PostScript">ps</a>, <a href="/format/2309.04981" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Streamlined Data Fusion: Unleashing the Power of Linear Combination with  Minimal Relevance Judgments
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xua%2C+Q">Qiuyu Xua</a>, 
<a href="/search/cs?searchtype=author&query=Huanga%2C+Y">Yidong Huanga</a>, 
<a href="/search/cs?searchtype=author&query=Wua%2C+S">Shengli Wua</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 8 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>

</div>
<p class="mathjax">Linear combination is a potent data fusion method in information retrieval
tasks, thanks to its ability to adjust weights for diverse scenarios. However,
achieving optimal weight training has traditionally required manual relevance
judgments on a large percentage of documents, a labor-intensive and expensive
process. In this study, we investigate the feasibility of obtaining
near-optimal weights using a mere 20\%-50\% of relevant documents. Through
experiments on four TREC datasets, we find that weights trained with multiple
linear regression using this reduced set closely rival those obtained with
TREC's official "qrels." Our findings unlock the potential for more efficient
and affordable data fusion, empowering researchers and practitioners to reap
its full benefits with significantly less effort.
</p>
</div>
</dd>
<dt><a name="item209">[209]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.04984" title="Abstract">arXiv:2309.04984</a> [<a href="/pdf/2309.04984" title="Download PDF">pdf</a>, <a href="/format/2309.04984" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Asymptotically Efficient Quasi-Newton Type Identification with Quantized  Observations Under Bounded Persistent Excitations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Wang%2C+Y">Ying Wang</a>, 
<a href="/search/eess?searchtype=author&query=Zhao%2C+Y">Yanlong Zhao</a>, 
<a href="/search/eess?searchtype=author&query=Zhang%2C+J">Ji-Feng Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 pages, 3 figures, submitted to Automatica
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">This paper is concerned with the optimal identification problem of dynamical
systems in which only quantized output observations are available under the
assumption of fixed thresholds and bounded persistent excitations. Based on a
time-varying projection, a weighted Quasi-Newton type projection (WQNP)
algorithm is proposed. With some mild conditions on the weight coefficients,
the algorithm is proved to be mean square and almost surely convergent, and the
convergence rate can be the reciprocal of the number of observations, which is
the same order as the optimal estimate under accurate measurements.
Furthermore, inspired by the structure of the Cramer-Rao lower bound, an
information-based identification (IBID) algorithm is constructed with adaptive
design about weight coefficients of the WQNP algorithm, where the weight
coefficients are related to the parameter estimates which leads to the
essential difficulty of algorithm analysis. Beyond the convergence properties,
this paper demonstrates that the IBID algorithm tends asymptotically to the
Cramer-Rao lower bound, and hence is asymptotically efficient. Numerical
examples are simulated to show the effectiveness of the information-based
identification algorithm.
</p>
</div>
</dd>
<dt><a name="item210">[210]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.04986" title="Abstract">arXiv:2309.04986</a> [<a href="/pdf/2309.04986" title="Download PDF">pdf</a>, <a href="/ps/2309.04986" title="Download PostScript">ps</a>, <a href="/format/2309.04986" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the Capacity of Generalized Quadrature Spatial Modulation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yukiyoshi%2C+K">Kein Yukiyoshi</a>, 
<a href="/search/cs?searchtype=author&query=Ishikawa%2C+N">Naoki Ishikawa</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages, 5 figures
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> IEEE Wireless Communications Letters, 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">In this letter, the average mutual information (AMI) of generalized
quadrature spatial modulation (GQSM) is first derived for continuous-input
continuous-output channels. Our mathematical analysis shows that the
calculation error induced by Monte Carlo integration increases exponentially
with the signal-to-noise ratio. This nature of GQSM is resolved by deriving a
closed-form expression. The derived AMI is compared with other related SM
schemes and evaluated for different antenna activation patterns. Our results
show that an equiprobable antenna selection method slightly decreases AMI of
symbols, while the method significantly improves AMI in total.
</p>
</div>
</dd>
<dt><a name="item211">[211]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.04992" title="Abstract">arXiv:2309.04992</a> [<a href="/pdf/2309.04992" title="Download PDF">pdf</a>, <a href="/format/2309.04992" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Mitigating Word Bias in Zero-shot Prompt-based Classifiers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liusie%2C+A">Adian Liusie</a>, 
<a href="/search/cs?searchtype=author&query=Manakul%2C+P">Potsawee Manakul</a>, 
<a href="/search/cs?searchtype=author&query=Gales%2C+M+J+F">Mark J. F. Gales</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Prompt-based classifiers are an attractive approach for zero-shot
classification. However, the precise choice of the prompt template and label
words can largely influence performance, with semantically equivalent settings
often showing notable performance difference. This discrepancy can be partly
attributed to word biases, where the classifier may be biased towards classes.
To address this problem, it is possible to optimise classification thresholds
on a labelled data set, however, this mitigates some of the advantages of
prompt-based classifiers. This paper instead approaches this problem by
examining the expected marginal probabilities of the classes. Here,
probabilities are reweighted to have a uniform prior over classes, in an
unsupervised fashion. Further, we draw a theoretical connection between the
class priors and the language models' word prior, and offer the ability to set
a threshold in a zero-resource fashion. We show that matching class priors
correlates strongly with the oracle upper bound performance and demonstrate
large consistent performance gains for prompt settings over a range of NLP
tasks.
</p>
</div>
</dd>
<dt><a name="item212">[212]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.04994" title="Abstract">arXiv:2309.04994</a> [<a href="/pdf/2309.04994" title="Download PDF">pdf</a>, <a href="/format/2309.04994" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Sparse-grid sampling recovery and numerical integration of functions  having mixed smoothness
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=D%C5%A9ng%2C+D">Dinh D&#x169;ng</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">We give a short survey of recent results on sparse-grid linear algorithms of
approximate recovery and integration of functions possessing a unweighted or
weighted Sobolev mixed smoothness based on their sampled values at a certain
finite set. Some of them are extended to more general cases.
</p>
</div>
</dd>
<dt><a name="item213">[213]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.04995" title="Abstract">arXiv:2309.04995</a> [<a href="/pdf/2309.04995" title="Download PDF">pdf</a>, <a href="/ps/2309.04995" title="Download PostScript">ps</a>, <a href="/format/2309.04995" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> How to assign volunteers to tasks compatibly ? A graph theoretic and  parameterized approach
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gupta%2C+S">Sushmita Gupta</a>, 
<a href="/search/cs?searchtype=author&query=Jain%2C+P">Pallavi Jain</a>, 
<a href="/search/cs?searchtype=author&query=Saurabh%2C+S">Saket Saurabh</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>; Computer Science and Game Theory (cs.GT)

</div>
<p class="mathjax">In this paper we study a resource allocation problem that encodes correlation
between items in terms of \conflict and maximizes the minimum utility of the
agents under a conflict free allocation. Admittedly, the problem is
computationally hard even under stringent restrictions because it encodes a
variant of the {\sc Maximum Weight Independent Set} problem which is one of the
canonical hard problems in both classical and parameterized complexity.
Recently, this subject was explored by Chiarelli et al.~[Algorithmica'22] from
the classical complexity perspective to draw the boundary between {\sf
NP}-hardness and tractability for a constant number of agents. The problem was
shown to be hard even for small constant number of agents and various other
restrictions on the underlying graph. Notwithstanding this computational
barrier, we notice that there are several parameters that are worth studying:
number of agents, number of items, combinatorial structure that defines the
conflict among the items, all of which could well be small under specific
circumstancs. Our search rules out several parameters (even when taken
together) and takes us towards a characterization of families of input
instances that are amenable to polynomial time algorithms when the parameters
are constant. In addition to this we give a superior $2^{m}|I|^{\Co{O}(1)}$
algorithm for our problem where $m$ denotes the number of items that
significantly beats the exhaustive $\Oh(m^{m})$ algorithm by cleverly using
ideas from FFT based fast polynomial multiplication; and we identify simple
graph classes relevant to our problem's motivation that admit efficient
algorithms.
</p>
</div>
</dd>
<dt><a name="item214">[214]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.04997" title="Abstract">arXiv:2309.04997</a> [<a href="/pdf/2309.04997" title="Download PDF">pdf</a>, <a href="/format/2309.04997" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Gender Bias in Multimodal Models: A Transnational Feminist Approach  Considering Geographical Region and Culture
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mandal%2C+A">Abhishek Mandal</a>, 
<a href="/search/cs?searchtype=author&query=Little%2C+S">Suzanne Little</a>, 
<a href="/search/cs?searchtype=author&query=Leavy%2C+S">Susan Leavy</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Selected for publication at the Aequitas 2023: Workshop on Fairness and Bias in AI | co-located with ECAI 2023, Krak\'ow, Poland
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>

</div>
<p class="mathjax">Deep learning based visual-linguistic multimodal models such as Contrastive
Language Image Pre-training (CLIP) have become increasingly popular recently
and are used within text-to-image generative models such as DALL-E and Stable
Diffusion. However, gender and other social biases have been uncovered in these
models, and this has the potential to be amplified and perpetuated through AI
systems. In this paper, we present a methodology for auditing multimodal models
that consider gender, informed by concepts from transnational feminism,
including regional and cultural dimensions. Focusing on CLIP, we found evidence
of significant gender bias with varying patterns across global regions. Harmful
stereotypical associations were also uncovered related to visual cultural cues
and labels such as terrorism. Levels of gender bias uncovered within CLIP for
different regions aligned with global indices of societal gender equality, with
those from the Global South reflecting the highest levels of gender bias.
</p>
</div>
</dd>
<dt><a name="item215">[215]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.05004" title="Abstract">arXiv:2309.05004</a> [<a href="/pdf/2309.05004" title="Download PDF">pdf</a>, <a href="/format/2309.05004" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Numerical reconstruction of the kinetic chemotaxis kernel from  macroscopic measurement, wellposedness and illposedness
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Hellmuth%2C+K">Kathrin Hellmuth</a>, 
<a href="/search/math?searchtype=author&query=Klingenberg%2C+C">Christian Klingenberg</a>, 
<a href="/search/math?searchtype=author&query=Li%2C+Q">Qin Li</a>, 
<a href="/search/math?searchtype=author&query=Tang%2C+M">Min Tang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Analysis of PDEs (math.AP); Optimization and Control (math.OC); Cell Behavior (q-bio.CB)

</div>
<p class="mathjax">Directed bacterial motion due to external stimuli (chemotaxis) can, on the
mesoscopic phase space, be described by a velocity change parameter $K$. The
numerical reconstruction for $K$ from experimental data provides useful
insights and plays a crucial role in model fitting, verification and
prediction. In this article, the PDE-constrained optimization framework is
deployed to perform the reconstruction of $K$ from velocity-averaged, localized
data taken in the interior of a 1D domain. Depending on the data preparation
and experimental setup, this problem can either be well- or ill-posed. We
analyze these situations, and propose a very specific design that guarantees
local convergence. The design is adapted to the discretization of $K$ and
decouples the reconstruction of local values into smaller cell problem, opening
up opportunities for parallelization. We further provide numerical evidence as
a showcase for the theoretical results.
</p>
</div>
</dd>
<dt><a name="item216">[216]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.05007" title="Abstract">arXiv:2309.05007</a> [<a href="/pdf/2309.05007" title="Download PDF">pdf</a>, <a href="/format/2309.05007" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FOLLOWUPQG: Towards Information-Seeking Follow-up Question Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Meng%2C+Y">Yan Meng</a>, 
<a href="/search/cs?searchtype=author&query=Pan%2C+L">Liangming Pan</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+Y">Yixin Cao</a>, 
<a href="/search/cs?searchtype=author&query=Kan%2C+M">Min-Yen Kan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Humans ask follow-up questions driven by curiosity, which reflects a creative
human cognitive process. We introduce the task of real-world
information-seeking follow-up question generation (FQG), which aims to generate
follow-up questions seeking a more in-depth understanding of an initial
question and answer. We construct FOLLOWUPQG, a dataset of over 3K real-world
(initial question, answer, follow-up question) tuples collected from a Reddit
forum providing layman-friendly explanations for open-ended questions. In
contrast to existing datasets, questions in FOLLOWUPQG use more diverse
pragmatic strategies to seek information, and they also show higher-order
cognitive skills (such as applying and relating). We evaluate current question
generation models on their efficacy for generating follow-up questions,
exploring how to generate specific types of follow-up questions based on
step-by-step demonstrations. Our results validate FOLLOWUPQG as a challenging
benchmark, as model-generated questions are adequate but far from human-raised
questions in terms of informativeness and complexity.
</p>
</div>
</dd>
<dt><a name="item217">[217]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.05013" title="Abstract">arXiv:2309.05013</a> [<a href="/pdf/2309.05013" title="Download PDF">pdf</a>, <a href="/format/2309.05013" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Geometrically Consistent Partial Shape Matching
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ehm%2C+V">Viktoria Ehm</a>, 
<a href="/search/cs?searchtype=author&query=Roetzer%2C+P">Paul Roetzer</a>, 
<a href="/search/cs?searchtype=author&query=Eisenberger%2C+M">Marvin Eisenberger</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+M">Maolin Gao</a>, 
<a href="/search/cs?searchtype=author&query=Bernard%2C+F">Florian Bernard</a>, 
<a href="/search/cs?searchtype=author&query=Cremers%2C+D">Daniel Cremers</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Finding correspondences between 3D shapes is a crucial problem in computer
vision and graphics, which is for example relevant for tasks like shape
interpolation, pose transfer, or texture transfer. An often neglected but
essential property of matchings is geometric consistency, which means that
neighboring triangles in one shape are consistently matched to neighboring
triangles in the other shape. Moreover, while in practice one often has only
access to partial observations of a 3D shape (e.g. due to occlusion, or
scanning artifacts), there do not exist any methods that directly address
geometrically consistent partial shape matching. In this work we fill this gap
by proposing to integrate state-of-the-art deep shape features into a novel
integer linear programming partial shape matching formulation. Our optimization
yields a globally optimal solution on low resolution shapes, which we then
refine using a coarse-to-fine scheme. We show that our method can find more
reliable results on partial shapes in comparison to existing geometrically
consistent algorithms (for which one first has to fill missing parts with a
dummy geometry). Moreover, our matchings are substantially smoother than
learning-based state-of-the-art shape matching methods.
</p>
</div>
</dd>
<dt><a name="item218">[218]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.05015" title="Abstract">arXiv:2309.05015</a> [<a href="/pdf/2309.05015" title="Download PDF">pdf</a>, <a href="/format/2309.05015" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DeViT: Decomposing Vision Transformers for Collaborative Inference in  Edge Devices
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+G">Guanyu Xu</a>, 
<a href="/search/cs?searchtype=author&query=Hao%2C+Z">Zhiwei Hao</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+Y">Yong Luo</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+H">Han Hu</a>, 
<a href="/search/cs?searchtype=author&query=An%2C+J">Jianping An</a>, 
<a href="/search/cs?searchtype=author&query=Mao%2C+S">Shiwen Mao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by IEEE Transactions on Mobile Computing
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Distributed, Parallel, and Cluster Computing (cs.DC); Performance (cs.PF)

</div>
<p class="mathjax">Recent years have witnessed the great success of vision transformer (ViT),
which has achieved state-of-the-art performance on multiple computer vision
benchmarks. However, ViT models suffer from vast amounts of parameters and high
computation cost, leading to difficult deployment on resource-constrained edge
devices. Existing solutions mostly compress ViT models to a compact model but
still cannot achieve real-time inference. To tackle this issue, we propose to
explore the divisibility of transformer structure, and decompose the large ViT
into multiple small models for collaborative inference at edge devices. Our
objective is to achieve fast and energy-efficient collaborative inference while
maintaining comparable accuracy compared with large ViTs. To this end, we first
propose a collaborative inference framework termed DeViT to facilitate edge
deployment by decomposing large ViTs. Subsequently, we design a
decomposition-and-ensemble algorithm based on knowledge distillation, termed
DEKD, to fuse multiple small decomposed models while dramatically reducing
communication overheads, and handle heterogeneous models by developing a
feature matching module to promote the imitations of decomposed models from the
large ViT. Extensive experiments for three representative ViT backbones on four
widely-used datasets demonstrate our method achieves efficient collaborative
inference for ViTs and outperforms existing lightweight ViTs, striking a good
trade-off between efficiency and accuracy. For example, our DeViTs improves
end-to-end latency by 2.89$\times$ with only 1.65% accuracy sacrifice using
CIFAR-100 compared to the large ViT, ViT-L/16, on the GPU server. DeDeiTs
surpasses the recent efficient ViT, MobileViT-S, by 3.54% in accuracy on
ImageNet-1K, while running 1.72$\times$ faster and requiring 55.28% lower
energy consumption on the edge device.
</p>
</div>
</dd>
<dt><a name="item219">[219]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.05017" title="Abstract">arXiv:2309.05017</a> [<a href="/pdf/2309.05017" title="Download PDF">pdf</a>, <a href="/format/2309.05017" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FuseFPS: Accelerating Farthest Point Sampling with Fusing KD-tree  Construction for Point Clouds
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Han%2C+M">Meng Han</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+L">Liang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Xiao%2C+L">Limin Xiao</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Hao Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+C">Chenhao Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+X">Xilong Xie</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+S">Shuai Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+J">Jin Dong</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> conference for ASP-DAC 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Hardware Architecture (cs.AR)</span>

</div>
<p class="mathjax">Point cloud analytics has become a critical workload for embedded and mobile
platforms across various applications. Farthest point sampling (FPS) is a
fundamental and widely used kernel in point cloud processing. However, the
heavy external memory access makes FPS a performance bottleneck for real-time
point cloud processing. Although bucket-based farthest point sampling can
significantly reduce unnecessary memory accesses during the point sampling
stage, the KD-tree construction stage becomes the predominant contributor to
execution time. In this paper, we present FuseFPS, an architecture and
algorithm co-design for bucket-based farthest point sampling. We first propose
a hardware-friendly sampling-driven KD-tree construction algorithm. The
algorithm fuses the KD-tree construction stage into the point sampling stage,
further reducing memory accesses. Then, we design an efficient accelerator for
bucket-based point sampling. The accelerator can offload the entire
bucket-based FPS kernel at a low hardware cost. Finally, we evaluate our
approach on various point cloud datasets. The detailed experiments show that
compared to the state-of-the-art accelerator QuickFPS, FuseFPS achieves about
4.3$\times$ and about 6.1$\times$ improvements on speed and power efficiency,
respectively.
</p>
</div>
</dd>
<dt><a name="item220">[220]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.05019" title="Abstract">arXiv:2309.05019</a> [<a href="/pdf/2309.05019" title="Download PDF">pdf</a>, <a href="/format/2309.05019" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SA-Solver: Stochastic Adams Solver for Fast Sampling of Diffusion Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xue%2C+S">Shuchen Xue</a>, 
<a href="/search/cs?searchtype=author&query=Yi%2C+M">Mingyang Yi</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+W">Weijian Luo</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+S">Shifeng Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+J">Jiacheng Sun</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zhenguo Li</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+Z">Zhi-Ming Ma</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
<p class="mathjax">Diffusion Probabilistic Models (DPMs) have achieved considerable success in
generation tasks. As sampling from DPMs is equivalent to solving diffusion SDE
or ODE which is time-consuming, numerous fast sampling methods built upon
improved differential equation solvers are proposed. The majority of such
techniques consider solving the diffusion ODE due to its superior efficiency.
However, stochastic sampling could offer additional advantages in generating
diverse and high-quality data. In this work, we engage in a comprehensive
analysis of stochastic sampling from two aspects: variance-controlled diffusion
SDE and linear multi-step SDE solver. Based on our analysis, we propose
SA-Solver, which is an improved efficient stochastic Adams method for solving
diffusion SDE to generate data with high quality. Our experiments show that
SA-Solver achieves: 1) improved or comparable performance compared with the
existing state-of-the-art sampling methods for few-step sampling; 2) SOTA FID
scores on substantial benchmark datasets under a suitable number of function
evaluations (NFEs).
</p>
</div>
</dd>
<dt><a name="item221">[221]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.05021" title="Abstract">arXiv:2309.05021</a> [<a href="/pdf/2309.05021" title="Download PDF">pdf</a>, <a href="/format/2309.05021" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Chat2Brain: A Method for Mapping Open-Ended Semantic Queries to Brain  Activation Maps
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wei%2C+Y">Yaonai Wei</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+T">Tuo Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Han Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhong%2C+T">Tianyang Zhong</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+L">Lin Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zhengliang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+C">Chong Ma</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+S">Songyao Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Shang%2C+M">Muheng Shang</a>, 
<a href="/search/cs?searchtype=author&query=Du%2C+L">Lei Du</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xiao Li</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+T">Tianming Liu</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+J">Junwei Han</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 4 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Over decades, neuroscience has accumulated a wealth of research results in
the text modality that can be used to explore cognitive processes.
Meta-analysis is a typical method that successfully establishes a link from
text queries to brain activation maps using these research results, but it
still relies on an ideal query environment. In practical applications, text
queries used for meta-analyses may encounter issues such as semantic redundancy
and ambiguity, resulting in an inaccurate mapping to brain images. On the other
hand, large language models (LLMs) like ChatGPT have shown great potential in
tasks such as context understanding and reasoning, displaying a high degree of
consistency with human natural language. Hence, LLMs could improve the
connection between text modality and neuroscience, resolving existing
challenges of meta-analyses. In this study, we propose a method called
Chat2Brain that combines LLMs to basic text-2-image model, known as Text2Brain,
to map open-ended semantic queries to brain activation maps in data-scarce and
complex query environments. By utilizing the understanding and reasoning
capabilities of LLMs, the performance of the mapping model is optimized by
transferring text queries to semantic queries. We demonstrate that Chat2Brain
can synthesize anatomically plausible neural activation patterns for more
complex tasks of text queries.
</p>
</div>
</dd>
<dt><a name="item222">[222]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.05026" title="Abstract">arXiv:2309.05026</a> [<a href="/pdf/2309.05026" title="Download PDF">pdf</a>, <a href="/format/2309.05026" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Spatial Perceptual Quality Aware Adaptive Volumetric Video Streaming
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xi Wang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+W">Wei Liu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+H">Huitong Liu</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+P">Peng Yang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted byIEEE Globecom 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Multimedia (cs.MM)</span>; Image and Video Processing (eess.IV)

</div>
<p class="mathjax">Volumetric video offers a highly immersive viewing experience, but poses
challenges in ensuring quality of experience (QoE) due to its high bandwidth
requirements. In this paper, we explore the effect of viewing distance
introduced by six degrees of freedom (6DoF) spatial navigation on user's
perceived quality. By considering human visual resolution limitations, we
propose a visual acuity model that describes the relationship between the
virtual viewing distance and the tolerable boundary point cloud density. The
proposed model satisfies spatial visual requirements during 6DoF exploration.
Additionally, it dynamically adjusts quality levels to balance perceptual
quality and bandwidth consumption. Furthermore, we present a QoE model to
represent user's perceived quality at different viewing distances precisely.
Extensive experimental results demonstrate that, the proposed scheme can
effectively improve the overall average QoE by up to 26% over real networks and
user traces, compared to existing baselines.
</p>
</div>
</dd>
<dt><a name="item223">[223]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.05028" title="Abstract">arXiv:2309.05028</a> [<a href="/pdf/2309.05028" title="Download PDF">pdf</a>, <a href="/format/2309.05028" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SC-NeRF: Self-Correcting Neural Radiance Field with Sparse Views
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Song%2C+L">Liang Song</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+G">Guangming Wang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jiuming Liu</a>, 
<a href="/search/cs?searchtype=author&query=Fu%2C+Z">Zhenyang Fu</a>, 
<a href="/search/cs?searchtype=author&query=Miao%2C+Y">Yanzi Miao</a>, 
<a href="/search/cs?searchtype=author&query=Hesheng">Hesheng</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">In recent studies, the generalization of neural radiance fields for novel
view synthesis task has been widely explored. However, existing methods are
limited to objects and indoor scenes. In this work, we extend the
generalization task to outdoor scenes, trained only on object-level datasets.
This approach presents two challenges. Firstly, the significant distributional
shift between training and testing scenes leads to black artifacts in rendering
results. Secondly, viewpoint changes in outdoor scenes cause ghosting or
missing regions in rendered images. To address these challenges, we propose a
geometric correction module and an appearance correction module based on
multi-head attention mechanisms. We normalize rendered depth and combine it
with light direction as query in the attention mechanism. Our network
effectively corrects varying scene structures and geometric features in outdoor
scenes, generalizing well from object-level to unseen outdoor scenes.
Additionally, we use appearance correction module to correct appearance
features, preventing rendering artifacts like blank borders and ghosting due to
viewpoint changes. By combining these modules, our approach successfully
tackles the challenges of outdoor scene generalization, producing high-quality
rendering results. When evaluated on four datasets (Blender, DTU, LLFF,
Spaces), our network outperforms previous methods. Notably, compared to
MVSNeRF, our network improves average PSNR from 19.369 to 25.989, SSIM from
0.838 to 0.889, and reduces LPIPS from 0.265 to 0.224 on Spaces outdoor scenes.
</p>
</div>
</dd>
<dt><a name="item224">[224]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.05030" title="Abstract">arXiv:2309.05030</a> [<a href="/pdf/2309.05030" title="Download PDF">pdf</a>, <a href="/ps/2309.05030" title="Download PostScript">ps</a>, <a href="/format/2309.05030" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Decolonial AI Alignment: Vi&#x15b;esadharma, Argument, and Artistic  Expression
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Varshney%2C+K+R">Kush R. Varshney</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>; Artificial Intelligence (cs.AI); Machine Learning (stat.ML)

</div>
<p class="mathjax">Prior work has explicated the coloniality of artificial intelligence (AI)
development and deployment. One process that that work has not engaged with
much is alignment: the tuning of large language model (LLM) behavior to be in
line with desired values based on fine-grained human feedback. In addition to
other practices, colonialism has a history of altering the beliefs and values
of colonized peoples; this history is recapitulated in current LLM alignment
practices. We suggest that AI alignment be decolonialized using three
proposals: (a) changing the base moral philosophy from Western philosophy to
dharma, (b) permitting traditions of argument and pluralism in alignment
technologies, and (c) expanding the epistemology of values beyond instructions
or commandments given in natural language.
</p>
</div>
</dd>
<dt><a name="item225">[225]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.05032" title="Abstract">arXiv:2309.05032</a> [<a href="/pdf/2309.05032" title="Download PDF">pdf</a>, <a href="/format/2309.05032" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Unified Contrastive Fusion Transformer for Multimodal Human Action  Recognition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+K+O">Kyoung Ok Yang</a>, 
<a href="/search/cs?searchtype=author&query=Koh%2C+J">Junho Koh</a>, 
<a href="/search/cs?searchtype=author&query=Choi%2C+J+W">Jun Won Choi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Various types of sensors have been considered to develop human action
recognition (HAR) models. Robust HAR performance can be achieved by fusing
multimodal data acquired by different sensors. In this paper, we introduce a
new multimodal fusion architecture, referred to as Unified Contrastive Fusion
Transformer (UCFFormer) designed to integrate data with diverse distributions
to enhance HAR performance. Based on the embedding features extracted from each
modality, UCFFormer employs the Unified Transformer to capture the
inter-dependency among embeddings in both time and modality domains. We present
the Factorized Time-Modality Attention to perform self-attention efficiently
for the Unified Transformer. UCFFormer also incorporates contrastive learning
to reduce the discrepancy in feature distributions across various modalities,
thus generating semantically aligned features for information fusion.
Performance evaluation conducted on two popular datasets, UTD-MHAD and NTU
RGB+D, demonstrates that UCFFormer achieves state-of-the-art performance,
outperforming competing methods by considerable margins.
</p>
</div>
</dd>
<dt><a name="item226">[226]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.05033" title="Abstract">arXiv:2309.05033</a> [<a href="/pdf/2309.05033" title="Download PDF">pdf</a>, <a href="/format/2309.05033" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Evolving landscape of US-China science collaboration: Convergence and  divergence
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kitajima%2C+K">Kensei Kitajima</a>, 
<a href="/search/cs?searchtype=author&query=Okamura%2C+K">Keisuke Okamura</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Main Text: 15 pages (4 figures); Supplementary Materials: 3 pages (3 figures)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Digital Libraries (cs.DL)</span>; Computers and Society (cs.CY); Social and Information Networks (cs.SI); Physics and Society (physics.soc-ph)

</div>
<p class="mathjax">International research collaboration among global scientific powerhouses has
exhibited a discernible trend towards convergence in recent decades. Notably,
the US and China have significantly fortified their collaboration across
diverse scientific disciplines, solidifying their status as a national-level
duopoly in global scientific knowledge production. However, recent reports hint
at a potential decline in collaboration between these two giants, even amidst
the backdrop of advancing global convergence. Understanding the intricate
interplay between cooperation and disparity within the US-China relationship is
vital for both academia and policy leaders, as it provides invaluable insights
into the potential future trajectory of global science collaboration. Despite
its significance, there remains a noticeable dearth of quantitative evidence
that adequately encapsulates the dynamism across disciplines and over time. To
bridge this knowledge gap, this study delves into the evolving landscape of
interaction between the US and China over recent decades. This investigation
employs two approaches, one based on paper identifiers and the other on
researcher identifiers, both obtained from bibliometric data sourced from
OpenAlex. From both approaches, our findings unveil the unique and dynamic
nature of the US-China relationship, characterised by a collaboration pattern
initially marked by rapid convergence, followed by a recent phase of
divergence.
</p>
</div>
</dd>
<dt><a name="item227">[227]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.05035" title="Abstract">arXiv:2309.05035</a> [<a href="/pdf/2309.05035" title="Download PDF">pdf</a>, <a href="/format/2309.05035" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Duplicate Question Retrieval and Confirmation Time Prediction in  Software Communities
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hazra%2C+R">Rima Hazra</a>, 
<a href="/search/cs?searchtype=author&query=Saha%2C+D">Debanjan Saha</a>, 
<a href="/search/cs?searchtype=author&query=Sahoo%2C+A">Amruit Sahoo</a>, 
<a href="/search/cs?searchtype=author&query=Banerjee%2C+S">Somnath Banerjee</a>, 
<a href="/search/cs?searchtype=author&query=Mukherjee%2C+A">Animesh Mukherjee</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Full paper accepted at ASONAM 2023: The 2023 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Software Engineering (cs.SE); Social and Information Networks (cs.SI)

</div>
<p class="mathjax">Community Question Answering (CQA) in different domains is growing at a large
scale because of the availability of several platforms and huge shareable
information among users. With the rapid growth of such online platforms, a
massive amount of archived data makes it difficult for moderators to retrieve
possible duplicates for a new question and identify and confirm existing
question pairs as duplicates at the right time. This problem is even more
critical in CQAs corresponding to large software systems like askubuntu where
moderators need to be experts to comprehend something as a duplicate. Note that
the prime challenge in such CQA platforms is that the moderators are themselves
experts and are therefore usually extremely busy with their time being
extraordinarily expensive. To facilitate the task of the moderators, in this
work, we have tackled two significant issues for the askubuntu CQA platform:
(1) retrieval of duplicate questions given a new question and (2) duplicate
question confirmation time prediction. In the first task, we focus on
retrieving duplicate questions from a question pool for a particular newly
posted question. In the second task, we solve a regression problem to rank a
pair of questions that could potentially take a long time to get confirmed as
duplicates. For duplicate question retrieval, we propose a Siamese neural
network based approach by exploiting both text and network-based features,
which outperforms several state-of-the-art baseline techniques. Our method
outperforms DupPredictor and DUPE by 5% and 7% respectively. For duplicate
confirmation time prediction, we have used both the standard machine learning
models and neural network along with the text and graph-based features. We
obtain Spearman's rank correlation of 0.20 and 0.213 (statistically
significant) for text and graph based features respectively.
</p>
</div>
</dd>
<dt><a name="item228">[228]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.05036" title="Abstract">arXiv:2309.05036</a> [<a href="/pdf/2309.05036" title="Download PDF">pdf</a>, <a href="/format/2309.05036" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> What Is Near?: Room Locality Learning for Enhanced Robot  Vision-Language-Navigation in Indoor Living Environments
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gopinathan%2C+M">Muraleekrishna Gopinathan</a>, 
<a href="/search/cs?searchtype=author&query=Abu-Khalaf%2C+J">Jumana Abu-Khalaf</a>, 
<a href="/search/cs?searchtype=author&query=Suter%2C+D">David Suter</a>, 
<a href="/search/cs?searchtype=author&query=Paheding%2C+S">Sidike Paheding</a>, 
<a href="/search/cs?searchtype=author&query=Rawashdeh%2C+N+A">Nathir A. Rawashdeh</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Humans use their knowledge of common house layouts obtained from previous
experiences to predict nearby rooms while navigating in new environments. This
greatly helps them navigate previously unseen environments and locate their
target room. To provide layout prior knowledge to navigational agents based on
common human living spaces, we propose WIN (\textit{W}hat \textit{I}s
\textit{N}ear), a commonsense learning model for Vision Language Navigation
(VLN) tasks. VLN requires an agent to traverse indoor environments based on
descriptive navigational instructions. Unlike existing layout learning works,
WIN predicts the local neighborhood map based on prior knowledge of living
spaces and current observation, operating on an imagined global map of the
entire environment. The model infers neighborhood regions based on visual cues
of current observations, navigational history, and layout common sense. We show
that local-global planning based on locality knowledge and predicting the
indoor layout allows the agent to efficiently select the appropriate action.
Specifically, we devised a cross-modal transformer that utilizes this locality
prior for decision-making in addition to visual inputs and instructions.
Experimental results show that locality learning using WIN provides better
generalizability compared to classical VLN agents in unseen environments. Our
model performs favorably on standard VLN metrics, with Success Rate 68\% and
Success weighted by Path Length 63\% in unseen environments.
</p>
</div>
</dd>
<dt><a name="item229">[229]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.05044" title="Abstract">arXiv:2309.05044</a> [<a href="/pdf/2309.05044" title="Download PDF">pdf</a>, <a href="/format/2309.05044" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Effect of Alignment Objectives on Code-Switching Translation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Anwar%2C+M">Mohamed Anwar</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This paper was originally submitted on 30/06/2022
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">One of the things that need to change when it comes to machine translation is
the models' ability to translate code-switching content, especially with the
rise of social media and user-generated content. In this paper, we are
proposing a way of training a single machine translation model that is able to
translate monolingual sentences from one language to another, along with
translating code-switched sentences to either language. This model can be
considered a bilingual model in the human sense. For better use of parallel
data, we generated synthetic code-switched (CSW) data along with an alignment
loss on the encoder to align representations across languages. Using the WMT14
English-French (En-Fr) dataset, the trained model strongly outperforms
bidirectional baselines on code-switched translation while maintaining quality
for non-code-switched (monolingual) data.
</p>
</div>
</dd>
<dt><a name="item230">[230]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.05049" title="Abstract">arXiv:2309.05049</a> [<a href="/pdf/2309.05049" title="Download PDF">pdf</a>, <a href="/format/2309.05049" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multi-view Self-supervised Disentanglement for General Image Denoising
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+H">Hao Chen</a>, 
<a href="/search/cs?searchtype=author&query=Qu%2C+C">Chenyuan Qu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yu Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+C">Chen Chen</a>, 
<a href="/search/cs?searchtype=author&query=Jiao%2C+J">Jianbo Jiao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> International Conference on Computer Vision 2023 (ICCV 2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">With its significant performance improvements, the deep learning paradigm has
become a standard tool for modern image denoisers. While promising performance
has been shown on seen noise distributions, existing approaches often suffer
from generalisation to unseen noise types or general and real noise. It is
understandable as the model is designed to learn paired mapping (e.g. from a
noisy image to its clean version). In this paper, we instead propose to learn
to disentangle the noisy image, under the intuitive assumption that different
corrupted versions of the same clean image share a common latent space. A
self-supervised learning framework is proposed to achieve the goal, without
looking at the latent clean image. By taking two different corrupted versions
of the same image as input, the proposed Multi-view Self-supervised
Disentanglement (MeD) approach learns to disentangle the latent clean features
from the corruptions and recover the clean image consequently. Extensive
experimental analysis on both synthetic and real noise shows the superiority of
the proposed method over prior self-supervised approaches, especially on unseen
novel noise types. On real noise, the proposed method even outperforms its
supervised counterparts by over 3 dB.
</p>
</div>
</dd>
<dt><a name="item231">[231]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.05055" title="Abstract">arXiv:2309.05055</a> [<a href="/pdf/2309.05055" title="Download PDF">pdf</a>, <a href="/format/2309.05055" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An Overview of Formulae for the Higher-Order Kinematics of Lower-Pair  Chains with Applications in Robotics and Mechanism Theory
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mueller%2C+A">Andreas Mueller</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Mechanism and Machine Theory, Vol. 142, 2019, 103594, 35 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Dynamical Systems (math.DS); Group Theory (math.GR); Numerical Analysis (math.NA)

</div>
<p class="mathjax">The motions of mechanisms can be described in terms of screw coordinates by
means of an exponential mapping. The product of exponentials (POE) describes
the configuration of a chain of bodies connected by lower pair joints. The
kinematics is thus given in terms of joint screws. The POE serves to express
loop constraints for mechanisms as well as the forward kinematics of serial
manipulators. Besides the compact formulations, the POE gives rise to purely
algebraic relations for derivatives wrt. joint variables. It is known that the
partial derivatives of the instantaneous joint screws (columns of the geometric
Jacobian) are determined by Lie brackets the joint screws. Lesser-known is that
derivative of arbitrary order can be compactly expressed by Lie brackets. This
has significance for higher-order forward/inverse kinematics and dynamics of
robots and multibody systems. Various relations were reported but are scattered
in the literature and insufficiently recognized. This paper aims to provide a
comprehensive overview of the relevant relations. Its original contributions
are closed form and recursive relations for higher-order derivatives and Taylor
expansions of various kinematic relations. Their application to kinematic
control and dynamics of robotic manipulators and multibody systems is
discussed.
</p>
</div>
</dd>
<dt><a name="item232">[232]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.05058" title="Abstract">arXiv:2309.05058</a> [<a href="/pdf/2309.05058" title="Download PDF">pdf</a>, <a href="/format/2309.05058" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multimodal Fish Feeding Intensity Assessment in Aquaculture
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cui%2C+M">Meng Cui</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xubo Liu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+H">Haohe Liu</a>, 
<a href="/search/cs?searchtype=author&query=Du%2C+Z">Zhuangzhuang Du</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+T">Tao Chen</a>, 
<a href="/search/cs?searchtype=author&query=Lian%2C+G">Guoping Lian</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+D">Daoliang Li</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+W">Wenwu Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Multimedia (cs.MM); Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">Fish feeding intensity assessment (FFIA) aims to evaluate the intensity
change of fish appetite during the feeding process, which is vital in
industrial aquaculture applications. The main challenges surrounding FFIA are
two-fold. 1) robustness: existing work has mainly leveraged single-modality
(e.g., vision, audio) methods, which have a high sensitivity to input noise. 2)
efficiency: FFIA models are generally expected to be employed on devices. This
presents a challenge in terms of computational efficiency. In this work, we
first introduce an audio-visual dataset, called AV-FFIA. AV-FFIA consists of
27,000 labeled audio and video clips that capture different levels of fish
feeding intensity. To our knowledge, AV-FFIA is the first large-scale
multimodal dataset for FFIA research. Then, we introduce a multi-modal approach
for FFIA by leveraging single-modality pre-trained models and modality-fusion
methods, with benchmark studies on AV-FFIA. Our experimental results indicate
that the multi-modal approach substantially outperforms the single-modality
based approach, especially in noisy environments. While multimodal approaches
provide a performance gain for FFIA, it inherently increase the computational
cost. To overcome this issue, we further present a novel unified model, termed
as U-FFIA. U-FFIA is a single model capable of processing audio, visual, or
audio-visual modalities, by leveraging modality dropout during training and
knowledge distillation from single-modality pre-trained models. We demonstrate
that U-FFIA can achieve performance better than or on par with the
state-of-the-art modality-specific FFIA models, with significantly lower
computational overhead. Our proposed U-FFIA approach enables a more robust and
efficient method for FFIA, with the potential to contribute to improved
management practices and sustainability in aquaculture.
</p>
</div>
</dd>
<dt><a name="item233">[233]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.05059" title="Abstract">arXiv:2309.05059</a> [<a href="/pdf/2309.05059" title="Download PDF">pdf</a>, <a href="/format/2309.05059" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Joint Routing and Energy Optimization for Integrated Access and Backhaul  with Open RAN
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gemmi%2C+G">Gabriele Gemmi</a>, 
<a href="/search/cs?searchtype=author&query=Elkael%2C+M">Maxime Elkael</a>, 
<a href="/search/cs?searchtype=author&query=Polese%2C+M">Michele Polese</a>, 
<a href="/search/cs?searchtype=author&query=Maccari%2C+L">Leonardo Maccari</a>, 
<a href="/search/cs?searchtype=author&query=Castel-Taleb%2C+H">Hind Castel-Taleb</a>, 
<a href="/search/cs?searchtype=author&query=Melodia%2C+T">Tommaso Melodia</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages, Accepted at IEEE GLOBECOM 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>

</div>
<p class="mathjax">Energy consumption represents a major part of the operating expenses of
mobile network operators. With the densification foreseen with 5G and beyond,
energy optimization has become a problem of crucial importance. While energy
optimization is widely studied in the literature, there are limited insights
and algorithms for energy-saving techniques for Integrated Access and Backhaul
(IAB), a self-backhauling architecture that ease deployment of dense cellular
networks reducing the number of fiber drops. This paper proposes a novel
optimization model for dynamic joint routing and energy optimization in IAB
networks. We leverage the closed-loop control framework introduced by the Open
Radio Access Network (O-RAN) architecture to minimize the number of active IAB
nodes while maintaining a minimum capacity per User Equipment (UE). The
proposed approach formulates the problem as a binary nonlinear program, which
is transformed into an equivalent binary linear program and solved using the
Gurobi solver. The approach is evaluated on a scenario built upon open data of
two months of traffic collected by network operators in the city of Milan,
Italy. Results show that the proposed optimization model reduces the RAN energy
consumption by 47%, while guaranteeing a minimum capacity for each UE.
</p>
</div>
</dd>
<dt><a name="item234">[234]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.05063" title="Abstract">arXiv:2309.05063</a> [<a href="/pdf/2309.05063" title="Download PDF">pdf</a>, <a href="/format/2309.05063" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Federated Learning Incentive Mechanism under Buyers&#x27; Auction Market
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+J">Jiaxi Yang</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+Z">Zihao Guo</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+S">Sheng Cao</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+C">Cuifang Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Tsai%2C+L">Li-Chuan Tsai</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computer Science and Game Theory (cs.GT)

</div>
<p class="mathjax">Auction-based Federated Learning (AFL) enables open collaboration among
self-interested data consumers and data owners. Existing AFL approaches are
commonly under the assumption of sellers' market in that the service clients as
sellers are treated as scarce resources so that the aggregation servers as
buyers need to compete the bids. Yet, as the technology progresses, an
increasing number of qualified clients are now capable of performing federated
learning tasks, leading to shift from sellers' market to a buyers' market. In
this paper, we shift the angle by adapting the procurement auction framework,
aiming to explain the pricing behavior under buyers' market. Our modeling
starts with basic setting under complete information, then move further to the
scenario where sellers' information are not fully observable. In order to
select clients with high reliability and data quality, and to prevent from
external attacks, we utilize a blockchain-based reputation mechanism. The
experimental results validate the effectiveness of our approach.
</p>
</div>
</dd>
<dt><a name="item235">[235]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.05067" title="Abstract">arXiv:2309.05067</a> [<a href="/pdf/2309.05067" title="Download PDF">pdf</a>, <a href="/format/2309.05067" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Mutation-based Fault Localization of Deep Neural Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ghanbari%2C+A">Ali Ghanbari</a>, 
<a href="/search/cs?searchtype=author&query=Thomas%2C+D">Deepak-George Thomas</a>, 
<a href="/search/cs?searchtype=author&query=Arshad%2C+M+A">Muhammad Arbab Arshad</a>, 
<a href="/search/cs?searchtype=author&query=Rajan%2C+H">Hridesh Rajan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 38th IEEE/ACM International Conference on Automated Software Engineering (ASE 2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Deep neural networks (DNNs) are susceptible to bugs, just like other types of
software systems. A significant uptick in using DNN, and its applications in
wide-ranging areas, including safety-critical systems, warrant extensive
research on software engineering tools for improving the reliability of
DNN-based systems. One such tool that has gained significant attention in the
recent years is DNN fault localization. This paper revisits mutation-based
fault localization in the context of DNN models and proposes a novel technique,
named deepmufl, applicable to a wide range of DNN models. We have implemented
deepmufl and have evaluated its effectiveness using 109 bugs obtained from
StackOverflow. Our results show that deepmufl detects 53/109 of the bugs by
ranking the buggy layer in top-1 position, outperforming state-of-the-art
static and dynamic DNN fault localization systems that are also designed to
target the class of bugs supported by deepmufl. Moreover, we observed that we
can halve the fault localization time for a pre-trained model using mutation
selection, yet losing only 7.55% of the bugs localized in top-1 position.
</p>
</div>
</dd>
<dt><a name="item236">[236]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.05069" title="Abstract">arXiv:2309.05069</a> [<a href="/pdf/2309.05069" title="Download PDF">pdf</a>, <a href="/format/2309.05069" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exploiting CLIP for Zero-shot HOI Detection Requires Knowledge  Distillation at Multiple Levels
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wan%2C+B">Bo Wan</a>, 
<a href="/search/cs?searchtype=author&query=Tuytelaars%2C+T">Tinne Tuytelaars</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">In this paper, we investigate the task of zero-shot human-object interaction
(HOI) detection, a novel paradigm for identifying HOIs without the need for
task-specific annotations. To address this challenging task, we employ CLIP, a
large-scale pre-trained vision-language model (VLM), for knowledge distillation
on multiple levels. Specifically, we design a multi-branch neural network that
leverages CLIP for learning HOI representations at various levels, including
global images, local union regions encompassing human-object pairs, and
individual instances of humans or objects. To train our model, CLIP is utilized
to generate HOI scores for both global images and local union regions that
serve as supervision signals. The extensive experiments demonstrate the
effectiveness of our novel multi-level CLIP knowledge integration strategy.
Notably, the model achieves strong performance, which is even comparable with
some fully-supervised and weakly-supervised methods on the public HICO-DET
benchmark.
</p>
</div>
</dd>
<dt><a name="item237">[237]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.05070" title="Abstract">arXiv:2309.05070</a> [<a href="/pdf/2309.05070" title="Download PDF">pdf</a>, <a href="/format/2309.05070" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Chasing the Intruder: A Reinforcement Learning Approach for Tracking  Intruder Drones
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kainth%2C+S">Shivam Kainth</a>, 
<a href="/search/cs?searchtype=author&query=Sahoo%2C+S">Subham Sahoo</a>, 
<a href="/search/cs?searchtype=author&query=Pal%2C+R">Rajtilak Pal</a>, 
<a href="/search/cs?searchtype=author&query=Jha%2C+S+S">Shashi Shekhar Jha</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI); Systems and Control (eess.SY)

</div>
<p class="mathjax">Drones are becoming versatile in a myriad of applications. This has led to
the use of drones for spying and intruding into the restricted or private air
spaces. Such foul use of drone technology is dangerous for the safety and
security of many critical infrastructures. In addition, due to the varied
low-cost design and agility of the drones, it is a challenging task to identify
and track them using the conventional radar systems. In this paper, we propose
a reinforcement learning based approach for identifying and tracking any
intruder drone using a chaser drone. Our proposed solution uses computer vision
techniques interleaved with the policy learning framework of reinforcement
learning to learn a control policy for chasing the intruder drone. The whole
system has been implemented using ROS and Gazebo along with the Ardupilot based
flight controller. The results show that the reinforcement learning based
policy converges to identify and track the intruder drone. Further, the learnt
policy is robust with respect to the change in speed or orientation of the
intruder drone.
</p>
</div>
</dd>
<dt><a name="item238">[238]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.05072" title="Abstract">arXiv:2309.05072</a> [<a href="/pdf/2309.05072" title="Download PDF">pdf</a>, <a href="/format/2309.05072" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Spatiotemporal Graph Neural Networks with Uncertainty Quantification for  Traffic Incident Risk Prediction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gao%2C+X">Xiaowei Gao</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+X">Xinke Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Zhuang%2C+D">Dingyi Zhuang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+H">Huanfa Chen</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Shenhao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Haworth%2C+J">James Haworth</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computers and Society (cs.CY)

</div>
<p class="mathjax">Predicting traffic incident risks at granular spatiotemporal levels is
challenging. The datasets predominantly feature zero values, indicating no
incidents, with sporadic high-risk values for severe incidents. Notably, a
majority of current models, especially deep learning methods, focus solely on
estimating risk values, overlooking the uncertainties arising from the
inherently unpredictable nature of incidents. To tackle this challenge, we
introduce the Spatiotemporal Zero-Inflated Tweedie Graph Neural Networks
(STZITD-GNNs). Our model merges the reliability of traditional statistical
models with the flexibility of graph neural networks, aiming to precisely
quantify uncertainties associated with road-level traffic incident risks. This
model strategically employs a compound model from the Tweedie family, as a
Poisson distribution to model risk frequency and a Gamma distribution to
account for incident severity. Furthermore, a zero-inflated component helps to
identify the non-incident risk scenarios. As a result, the STZITD-GNNs
effectively capture the dataset's skewed distribution, placing emphasis on
infrequent but impactful severe incidents. Empirical tests using real-world
traffic data from London, UK, demonstrate that our model excels beyond current
benchmarks. The forte of STZITD-GNN resides not only in its accuracy but also
in its adeptness at curtailing uncertainties, delivering robust predictions
over short (7 days) and extended (14 days) timeframes.
</p>
</div>
</dd>
<dt><a name="item239">[239]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.05073" title="Abstract">arXiv:2309.05073</a> [<a href="/pdf/2309.05073" title="Download PDF">pdf</a>, <a href="/format/2309.05073" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FreeMan: Towards Benchmarking 3D Human Pose Estimation in the Wild
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jiong Wang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+F">Fengyu Yang</a>, 
<a href="/search/cs?searchtype=author&query=Gou%2C+W">Wenbo Gou</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+B">Bingliang Li</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+D">Danqi Yan</a>, 
<a href="/search/cs?searchtype=author&query=Zeng%2C+A">Ailing Zeng</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+Y">Yijun Gao</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Junle Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+R">Ruimao Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 18 pages, 9 figures. Project page: <a href="https://wangjiongw.github.io/freeman/">this https URL</a>; <a href="https://github.com/wangjiongw/FreeMan_API">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Estimating the 3D structure of the human body from natural scenes is a
fundamental aspect of visual perception. This task carries great importance for
fields like AIGC and human-robot interaction. In practice, 3D human pose
estimation in real-world settings is a critical initial step in solving this
problem. However, the current datasets, often collected under controlled
laboratory conditions using complex motion capture equipment and unvarying
backgrounds, are insufficient. The absence of real-world datasets is stalling
the progress of this crucial task. To facilitate the development of 3D pose
estimation, we present FreeMan, the first large-scale, real-world multi-view
dataset. FreeMan was captured by synchronizing 8 smartphones across diverse
scenarios. It comprises 11M frames from 8000 sequences, viewed from different
perspectives. These sequences cover 40 subjects across 10 different scenarios,
each with varying lighting conditions. We have also established an automated,
precise labeling pipeline that allows for large-scale processing efficiently.
We provide comprehensive evaluation baselines for a range of tasks, underlining
the significant challenges posed by FreeMan. Further evaluations of standard
indoor/outdoor human sensing datasets reveal that FreeMan offers robust
representation transferability in real and complex scenes. FreeMan is now
publicly available at https://wangjiongw.github.io/freeman.
</p>
</div>
</dd>
<dt><a name="item240">[240]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.05074" title="Abstract">arXiv:2309.05074</a> [<a href="/pdf/2309.05074" title="Download PDF">pdf</a>, <a href="/format/2309.05074" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LiSum: Open Source Software License Summarization with Multi-Task  Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+L">Linyu Li</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+S">Sihan Xu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+Y">Ya Gao</a>, 
<a href="/search/cs?searchtype=author&query=Cai%2C+X">Xiangrui Cai</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+J">Jiarun Wu</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+W">Wenli Song</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zheli Liu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
<p class="mathjax">Open source software (OSS) licenses regulate the conditions under which users
can reuse, modify, and distribute the software legally. However, there exist
various OSS licenses in the community, written in a formal language, which are
typically long and complicated to understand. In this paper, we conducted a
661-participants online survey to investigate the perspectives and practices of
developers towards OSS licenses. The user study revealed an indeed need for an
automated tool to facilitate license understanding. Motivated by the user study
and the fast growth of licenses in the community, we propose the first study
towards automated license summarization. Specifically, we released the first
high quality text summarization dataset and designed two tasks, i.e., license
text summarization (LTS), aiming at generating a relatively short summary for
an arbitrary license, and license term classification (LTC), focusing on the
attitude inference towards a predefined set of key license terms (e.g.,
Distribute). Aiming at the two tasks, we present LiSum, a multi-task learning
method to help developers overcome the obstacles of understanding OSS licenses.
Comprehensive experiments demonstrated that the proposed jointly training
objective boosted the performance on both tasks, surpassing state-of-the-art
baselines with gains of at least 5 points w.r.t. F1 scores of four
summarization metrics and achieving 95.13% micro average F1 score for
classification simultaneously. We released all the datasets, the replication
package, and the questionnaires for the community.
</p>
</div>
</dd>
<dt><a name="item241">[241]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.05075" title="Abstract">arXiv:2309.05075</a> [<a href="/pdf/2309.05075" title="Download PDF">pdf</a>, <a href="/ps/2309.05075" title="Download PostScript">ps</a>, <a href="/format/2309.05075" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Secure Set-Based State Estimation for Linear Systems under Adversarial  Attacks on Sensors
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Niazi%2C+M+U+B">Muhammad Umar B. Niazi</a>, 
<a href="/search/eess?searchtype=author&query=Chong%2C+M+S">Michelle S. Chong</a>, 
<a href="/search/eess?searchtype=author&query=Alanwar%2C+A">Amr Alanwar</a>, 
<a href="/search/eess?searchtype=author&query=Johansson%2C+K+H">Karl H. Johansson</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Optimization and Control (math.OC)

</div>
<p class="mathjax">When a strategic adversary can attack multiple sensors of a system and freely
choose a different set of sensors at different times, how can we ensure that
the state estimate remains uncorrupted by the attacker? The existing literature
addressing this problem mandates that the adversary can only corrupt less than
half of the total number of sensors. This limitation is fundamental to all
point-based secure state estimators because of their dependence on algorithms
that rely on majority voting among sensors. However, in reality, an adversary
with ample resources may not be limited to attacking less than half of the
total number of sensors. This paper avoids the above-mentioned fundamental
limitation by proposing a set-based approach that allows attacks on all but one
sensor at any given time. We guarantee that the true state is always contained
in the estimated set, which is represented by a collection of constrained
zonotopes, provided that the system is bounded-input-bounded-state stable and
redundantly observable via every combination of sensor subsets with size equal
to the number of uncompromised sensors. Additionally, we show that the
estimated set is secure and stable irrespective of the attack signals if the
process and measurement noises are bounded. To detect the set of attacked
sensors at each time, we propose a simple attack detection technique. However,
we acknowledge that intelligently designed stealthy attacks may not be detected
and, in the worst-case scenario, could even result in exponential growth in the
algorithm's complexity. We alleviate this shortcoming by presenting a range of
strategies that offer different levels of trade-offs between estimation
performance and complexity.
</p>
</div>
</dd>
<dt><a name="item242">[242]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.05076" title="Abstract">arXiv:2309.05076</a> [<a href="/pdf/2309.05076" title="Download PDF">pdf</a>, <a href="/format/2309.05076" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An Appraisal-Based Chain-Of-Emotion Architecture for Affective Language  Model Game Agents
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Croissant%2C+M">Maximilian Croissant</a>, 
<a href="/search/cs?searchtype=author&query=Frister%2C+M">Madeleine Frister</a>, 
<a href="/search/cs?searchtype=author&query=Schofield%2C+G">Guy Schofield</a>, 
<a href="/search/cs?searchtype=author&query=McCall%2C+C">Cade McCall</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computation and Language (cs.CL); Human-Computer Interaction (cs.HC)

</div>
<p class="mathjax">The development of believable, natural, and interactive digital artificial
agents is a field of growing interest. Theoretical uncertainties and technical
barriers present considerable challenges to the field, particularly with
regards to developing agents that effectively simulate human emotions. Large
language models (LLMs) might address these issues by tapping common patterns in
situational appraisal. In three empirical experiments, this study tests the
capabilities of LLMs to solve emotional intelligence tasks and to simulate
emotions. It presents and evaluates a new chain-of-emotion architecture for
emotion simulation within video games, based on psychological appraisal
research. Results show that it outperforms standard LLM architectures on a
range of user experience and content analysis metrics. This study therefore
provides early evidence of how to construct and test affective agents based on
cognitive processes represented in language models.
</p>
</div>
</dd>
<dt><a name="item243">[243]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.05077" title="Abstract">arXiv:2309.05077</a> [<a href="/pdf/2309.05077" title="Download PDF">pdf</a>, <a href="/ps/2309.05077" title="Download PostScript">ps</a>, <a href="/format/2309.05077" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Generalization error bounds for iterative learning algorithms with  bounded updates
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fu%2C+J">Jingwen Fu</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+N">Nanning Zheng</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
<p class="mathjax">This paper explores the generalization characteristics of iterative learning
algorithms with bounded updates for non-convex loss functions, employing
information-theoretic techniques. Our key contribution is a novel bound for the
generalization error of these algorithms with bounded updates, extending beyond
the scope of previous works that only focused on Stochastic Gradient Descent
(SGD). Our approach introduces two main novelties: 1) we reformulate the mutual
information as the uncertainty of updates, providing a new perspective, and 2)
instead of using the chaining rule of mutual information, we employ a variance
decomposition technique to decompose information across iterations, allowing
for a simpler surrogate process. We analyze our generalization bound under
various settings and demonstrate improved bounds when the model dimension
increases at the same rate as the number of training data samples. To bridge
the gap between theory and practice, we also examine the previously observed
scaling behavior in large language models. Ultimately, our work takes a further
step for developing practical generalization theories.
</p>
</div>
</dd>
<dt><a name="item244">[244]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.05079" title="Abstract">arXiv:2309.05079</a> [<a href="/pdf/2309.05079" title="Download PDF">pdf</a>, <a href="/format/2309.05079" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A supervised generative optimization approach for tabular data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hamad%2C+F">Fadi Hamad</a>, 
<a href="/search/cs?searchtype=author&query=Nakamura-Sakai%2C+S">Shinpei Nakamura-Sakai</a>, 
<a href="/search/cs?searchtype=author&query=Obitayo%2C+S">Saheed Obitayo</a>, 
<a href="/search/cs?searchtype=author&query=Potluru%2C+V+K">Vamsi K. Potluru</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Synthetic data generation has emerged as a crucial topic for financial
institutions, driven by multiple factors, such as privacy protection and data
augmentation. Many algorithms have been proposed for synthetic data generation
but reaching the consensus on which method we should use for the specific data
sets and use cases remains challenging. Moreover, the majority of existing
approaches are ``unsupervised'' in the sense that they do not take into account
the downstream task. To address these issues, this work presents a novel
synthetic data generation framework. The framework integrates a supervised
component tailored to the specific downstream task and employs a meta-learning
approach to learn the optimal mixture distribution of existing synthetic
distributions.
</p>
</div>
</dd>
<dt><a name="item245">[245]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.05086" title="Abstract">arXiv:2309.05086</a> [<a href="/pdf/2309.05086" title="Download PDF">pdf</a>, <a href="/format/2309.05086" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Neural-Hidden-CRF: A Robust Weakly-Supervised Sequence Labeler
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+Z">Zhijun Chen</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+H">Hailong Sun</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+W">Wanhao Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+C">Chunyi Xu</a>, 
<a href="/search/cs?searchtype=author&query=Mao%2C+Q">Qianren Mao</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+P">Pengpeng Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, 4 figures, accepted by SIGKDD-2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">We propose a neuralized undirected graphical model called Neural-Hidden-CRF
to solve the weakly-supervised sequence labeling problem. Under the umbrella of
probabilistic undirected graph theory, the proposed Neural-Hidden-CRF embedded
with a hidden CRF layer models the variables of word sequence, latent ground
truth sequence, and weak label sequence with the global perspective that
undirected graphical models particularly enjoy. In Neural-Hidden-CRF, we can
capitalize on the powerful language model BERT or other deep models to provide
rich contextual semantic knowledge to the latent ground truth sequence, and use
the hidden CRF layer to capture the internal label dependencies.
Neural-Hidden-CRF is conceptually simple and empirically powerful. It obtains
new state-of-the-art results on one crowdsourcing benchmark and three
weak-supervision benchmarks, including outperforming the recent advanced model
CHMM by 2.80 F1 points and 2.23 F1 points in average generalization and
inference performance, respectively.
</p>
</div>
</dd>
<dt><a name="item246">[246]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.05088" title="Abstract">arXiv:2309.05088</a> [<a href="/pdf/2309.05088" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Trustworthy Artificial Intelligence for Equitable Global Health
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Qin%2C+H">Hong Qin</a>, 
<a href="/search/cs?searchtype=author&query=Kong%2C+J">Jude Kong</a>, 
<a href="/search/cs?searchtype=author&query=Ding%2C+W">Wandi Ding</a>, 
<a href="/search/cs?searchtype=author&query=Ahluwalia%2C+R">Ramneek Ahluwalia</a>, 
<a href="/search/cs?searchtype=author&query=Morr%2C+C+E">Christo El Morr</a>, 
<a href="/search/cs?searchtype=author&query=Engin%2C+Z">Zeynep Engin</a>, 
<a href="/search/cs?searchtype=author&query=Effoduh%2C+J+O">Jake Okechukwu Effoduh</a>, 
<a href="/search/cs?searchtype=author&query=Hwa%2C+R">Rebecca Hwa</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+S+J">Serena Jingchuan Guo</a>, 
<a href="/search/cs?searchtype=author&query=Seyyed-Kalantari%2C+L">Laleh Seyyed-Kalantari</a>, 
<a href="/search/cs?searchtype=author&query=Muyingo%2C+S+K">Sylvia Kiwuwa Muyingo</a>, 
<a href="/search/cs?searchtype=author&query=Moore%2C+C+M">Candace Makeda Moore</a>, 
<a href="/search/cs?searchtype=author&query=Parikh%2C+R">Ravi Parikh</a>, 
<a href="/search/cs?searchtype=author&query=Schwartz%2C+R">Reva Schwartz</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+D">Dongxiao Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xiaoqian Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yiye Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>; Other Quantitative Biology (q-bio.OT)

</div>
<p class="mathjax">Artificial intelligence (AI) can potentially transform global health, but
algorithmic bias can exacerbate social inequities and disparity. Trustworthy AI
entails the intentional design to ensure equity and mitigate potential biases.
To advance trustworthy AI in global health, we convened a workshop on Fairness
in Machine Intelligence for Global Health (FairMI4GH). The event brought
together a global mix of experts from various disciplines, community health
practitioners, policymakers, and more. Topics covered included managing AI bias
in socio-technical systems, AI's potential impacts on global health, and
balancing data privacy with transparency. Panel discussions examined the
cultural, political, and ethical dimensions of AI in global health. FairMI4GH
aimed to stimulate dialogue, facilitate knowledge transfer, and spark
innovative solutions. Drawing from NIST's AI Risk Management Framework, it
provided suggestions for handling AI risks and biases. The need to mitigate
data biases from the research design stage, adopt a human-centered approach,
and advocate for AI transparency was recognized. Challenges such as updating
legal frameworks, managing cross-border data sharing, and motivating developers
to reduce bias were acknowledged. The event emphasized the necessity of diverse
viewpoints and multi-dimensional dialogue for creating a fair and ethical AI
framework for equitable global health.
</p>
</div>
</dd>
<dt><a name="item247">[247]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.05090" title="Abstract">arXiv:2309.05090</a> [<a href="/pdf/2309.05090" title="Download PDF">pdf</a>, <a href="/format/2309.05090" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Sculpting Efficiency: Pruning Medical Imaging Models for On-Device  Inference
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sreeram%2C+S">Sudarshan Sreeram</a>, 
<a href="/search/cs?searchtype=author&query=Kainz%2C+B">Bernhard Kainz</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Applying ML advancements to healthcare can improve patient outcomes. However,
the sheer operational complexity of ML models, combined with legacy hardware
and multi-modal gigapixel images, poses a severe deployment limitation for
real-time, on-device inference. We consider filter pruning as a solution,
exploring segmentation models in cardiology and ophthalmology. Our preliminary
results show a compression rate of up to 1148x with minimal loss in quality,
stressing the need to consider task complexity and architectural details when
using off-the-shelf models. At high compression rates, filter-pruned models
exhibit faster inference on a CPU than the GPU baseline. We also demonstrate
that such models' robustness and generalisability characteristics exceed that
of the baseline and weight-pruned counterparts. We uncover intriguing questions
and take a step towards realising cost-effective disease diagnosis, monitoring,
and preventive solutions.
</p>
</div>
</dd>
<dt><a name="item248">[248]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.05091" title="Abstract">arXiv:2309.05091</a> [<a href="/pdf/2309.05091" title="Download PDF">pdf</a>, <a href="/format/2309.05091" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SpeechMirror: A Multimodal Visual Analytics System for Personalized  Reflection of Online Public Speaking Effectiveness
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+Z">Zeyuan Huang</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+Q">Qiang He</a>, 
<a href="/search/cs?searchtype=author&query=Maher%2C+K">Kevin Maher</a>, 
<a href="/search/cs?searchtype=author&query=Deng%2C+X">Xiaoming Deng</a>, 
<a href="/search/cs?searchtype=author&query=Lai%2C+Y">Yu-Kun Lai</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+C">Cuixia Ma</a>, 
<a href="/search/cs?searchtype=author&query=Qin%2C+S">Sheng-feng Qin</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yong-Jin Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Hongan Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Main paper (11 pages, 6 figures) and Supplemental document (11 pages, 11 figures). Accepted by VIS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Multimedia (cs.MM)

</div>
<p class="mathjax">As communications are increasingly taking place virtually, the ability to
present well online is becoming an indispensable skill. Online speakers are
facing unique challenges in engaging with remote audiences. However, there has
been a lack of evidence-based analytical systems for people to comprehensively
evaluate online speeches and further discover possibilities for improvement.
This paper introduces SpeechMirror, a visual analytics system facilitating
reflection on a speech based on insights from a collection of online speeches.
The system estimates the impact of different speech techniques on effectiveness
and applies them to a speech to give users awareness of the performance of
speech techniques. A similarity recommendation approach based on speech factors
or script content supports guided exploration to expand knowledge of
presentation evidence and accelerate the discovery of speech delivery
possibilities. SpeechMirror provides intuitive visualizations and interactions
for users to understand speech factors. Among them, SpeechTwin, a novel
multimodal visual summary of speech, supports rapid understanding of critical
speech factors and comparison of different speech samples, and SpeechPlayer
augments the speech video by integrating visualization of the speaker's body
language with interaction, for focused analysis. The system utilizes
visualizations suited to the distinct nature of different speech factors for
user comprehension. The proposed system and visualization techniques were
evaluated with domain experts and amateurs, demonstrating usability for users
with low visualization literacy and its efficacy in assisting users to develop
insights for potential improvement.
</p>
</div>
</dd>
<dt><a name="item249">[249]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.05095" title="Abstract">arXiv:2309.05095</a> [<a href="/pdf/2309.05095" title="Download PDF">pdf</a>, <a href="/format/2309.05095" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MaskRenderer: 3D-Infused Multi-Mask Realistic Face Reenactment
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Behrouzi%2C+T">Tina Behrouzi</a>, 
<a href="/search/cs?searchtype=author&query=Shahroudnejad%2C+A">Atefeh Shahroudnejad</a>, 
<a href="/search/cs?searchtype=author&query=Mousavi%2C+P">Payam Mousavi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">We present a novel end-to-end identity-agnostic face reenactment system,
MaskRenderer, that can generate realistic, high fidelity frames in real-time.
Although recent face reenactment works have shown promising results, there are
still significant challenges such as identity leakage and imitating mouth
movements, especially for large pose changes and occluded faces. MaskRenderer
tackles these problems by using (i) a 3DMM to model 3D face structure to better
handle pose changes, occlusion, and mouth movements compared to 2D
representations; (ii) a triplet loss function to embed the cross-reenactment
during training for better identity preservation; and (iii) multi-scale
occlusion, improving inpainting and restoring missing areas. Comprehensive
quantitative and qualitative experiments conducted on the VoxCeleb1 test set,
demonstrate that MaskRenderer outperforms state-of-the-art models on unseen
faces, especially when the Source and Driving identities are very different.
</p>
</div>
</dd>
<dt><a name="item250">[250]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.05098" title="Abstract">arXiv:2309.05098</a> [<a href="/pdf/2309.05098" title="Download PDF">pdf</a>, <a href="/format/2309.05098" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> 3D Implicit Transporter for Temporally Consistent Keypoint Discovery
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhong%2C+C">Chengliang Zhong</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+Y">Yuhang Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+Y">Yupeng Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+H">Hao Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Yi%2C+L">Li Yi</a>, 
<a href="/search/cs?searchtype=author&query=Mu%2C+X">Xiaodong Mu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+L">Ling Wang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+P">Pengfei Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+G">Guyue Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+C">Chao Yang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xinliang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+J">Jian Zhao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ICCV2023 oral paper
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Keypoint-based representation has proven advantageous in various visual and
robotic tasks. However, the existing 2D and 3D methods for detecting keypoints
mainly rely on geometric consistency to achieve spatial alignment, neglecting
temporal consistency. To address this issue, the Transporter method was
introduced for 2D data, which reconstructs the target frame from the source
frame to incorporate both spatial and temporal information. However, the direct
application of the Transporter to 3D point clouds is infeasible due to their
structural differences from 2D images. Thus, we propose the first 3D version of
the Transporter, which leverages hybrid 3D representation, cross attention, and
implicit reconstruction. We apply this new learning system on 3D articulated
objects and nonrigid animals (humans and rodents) and show that learned
keypoints are spatio-temporally consistent. Additionally, we propose a
closed-loop control strategy that utilizes the learned keypoints for 3D object
manipulation and demonstrate its superior performance. Codes are available at
https://github.com/zhongcl-thu/3D-Implicit-Transporter.
</p>
</div>
</dd>
<dt><a name="item251">[251]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.05103" title="Abstract">arXiv:2309.05103</a> [<a href="/pdf/2309.05103" title="Download PDF">pdf</a>, <a href="/format/2309.05103" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AGent: A Novel Pipeline for Automatically Creating Unanswerable  Questions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tran%2C+S+Q">Son Quoc Tran</a>, 
<a href="/search/cs?searchtype=author&query=Do%2C+G">Gia-Huy Do</a>, 
<a href="/search/cs?searchtype=author&query=Do%2C+P+N">Phong Nguyen-Thuan Do</a>, 
<a href="/search/cs?searchtype=author&query=Kretchmar%2C+M">Matt Kretchmar</a>, 
<a href="/search/cs?searchtype=author&query=Du%2C+X">Xinya Du</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 pages, 10 tables, 3 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">The development of large high-quality datasets and high-performing models
have led to significant advancements in the domain of Extractive Question
Answering (EQA). This progress has sparked considerable interest in exploring
unanswerable questions within the EQA domain. Training EQA models with
unanswerable questions helps them avoid extracting misleading or incorrect
answers for queries that lack valid responses. However, manually annotating
unanswerable questions is labor-intensive. To address this, we propose AGent, a
novel pipeline that automatically creates new unanswerable questions by
re-matching a question with a context that lacks the necessary information for
a correct answer. In this paper, we demonstrate the usefulness of this AGent
pipeline by creating two sets of unanswerable questions from answerable
questions in SQuAD and HotpotQA. These created question sets exhibit low error
rates. Additionally, models fine-tuned on these questions show comparable
performance with those fine-tuned on the SQuAD 2.0 dataset on multiple EQA
benchmarks.
</p>
</div>
</dd>
<dt><a name="item252">[252]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.05113" title="Abstract">arXiv:2309.05113</a> [<a href="/pdf/2309.05113" title="Download PDF">pdf</a>, <a href="/format/2309.05113" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Personalized Search Via Neural Contextual Semantic Relevance Ranking
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kong%2C+D">Deguang Kong</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+D">Daniel Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+Z">Zhiheng Huang</a>, 
<a href="/search/cs?searchtype=author&query=Sigalas%2C+S">Steph Sigalas</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Contextual, Personalization, Search, Semantics, LLM, embedding
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>

</div>
<p class="mathjax">Existing neural relevance models do not give enough consideration for query
and item context information which diversifies the search results to adapt for
personal preference. To bridge this gap, this paper presents a neural learning
framework to personalize document ranking results by leveraging the signals to
capture how the document fits into users' context. In particular, it models the
relationships between document content and user query context using both
lexical representations and semantic embeddings such that the user's intent can
be better understood by data enrichment of personalized query context
information. Extensive experiments performed on the search dataset, demonstrate
the effectiveness of the proposed method.
</p>
</div>
</dd>
<dt><a name="item253">[253]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.05115" title="Abstract">arXiv:2309.05115</a> [<a href="/pdf/2309.05115" title="Download PDF">pdf</a>, <a href="/format/2309.05115" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Real-time Learning of Driving Gap Preference for Personalized Adaptive  Cruise Control
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Zhao%2C+Z">Zhouqiao Zhao</a>, 
<a href="/search/eess?searchtype=author&query=Liao%2C+X">Xishun Liao</a>, 
<a href="/search/eess?searchtype=author&query=Abdelraouf%2C+A">Amr Abdelraouf</a>, 
<a href="/search/eess?searchtype=author&query=Han%2C+K">Kyungtae Han</a>, 
<a href="/search/eess?searchtype=author&query=Gupta%2C+R">Rohit Gupta</a>, 
<a href="/search/eess?searchtype=author&query=Barth%2C+M+J">Matthew J. Barth</a>, 
<a href="/search/eess?searchtype=author&query=Wu%2C+G">Guoyuan Wu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Human-Computer Interaction (cs.HC)

</div>
<p class="mathjax">Advanced Driver Assistance Systems (ADAS) are increasingly important in
improving driving safety and comfort, with Adaptive Cruise Control (ACC) being
one of the most widely used. However, pre-defined ACC settings may not always
align with driver's preferences and habits, leading to discomfort and potential
safety issues. Personalized ACC (P-ACC) has been proposed to address this
problem, but most existing research uses historical driving data to imitate
behaviors that conform to driver preferences, neglecting real-time driver
feedback. To bridge this gap, we propose a cloud-vehicle collaborative P-ACC
framework that incorporates driver feedback adaptation in real time. The
framework is divided into offline and online parts. The offline component
records the driver's naturalistic car-following trajectory and uses inverse
reinforcement learning (IRL) to train the model on the cloud. In the online
component, driver feedback is used to update the driving gap preference in real
time. The model is then retrained on the cloud with driver's takeover
trajectories, achieving incremental learning to better match driver's
preference. Human-in-the-loop (HuiL) simulation experiments demonstrate that
our proposed method significantly reduces driver intervention in automatic
control systems by up to 62.8%. By incorporating real-time driver feedback, our
approach enhances the comfort and safety of P-ACC, providing a personalized and
adaptable driving experience.
</p>
</div>
</dd>
<dt><a name="item254">[254]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.05117" title="Abstract">arXiv:2309.05117</a> [<a href="/pdf/2309.05117" title="Download PDF">pdf</a>, <a href="/format/2309.05117" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Physics-Aware Reduced-Order Modeling of Nonautonomous  Advection-Dominated Problems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Zhao%2C+H">Hongli Zhao</a>, 
<a href="/search/math?searchtype=author&query=Tartakovsky%2C+D+M">Daniel M. Tartakovsky</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 27 pages, 21 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">We present a variant of dynamic mode decomposition (DMD) for constructing a
reduced-order model (ROM) of advection-dominated problems with time-dependent
coefficients. Existing DMD strategies, such as the physics-aware DMD and the
time-varying DMD, struggle to tackle such problems due to their inherent
assumptions of time-invariance and locality. To overcome the compounded
difficulty, we propose to learn the evolution of characteristic lines as a
nonautonomous system. A piecewise locally time-invariant approximation to the
infinite-dimensional Koopman operator is then constructed. We test the accuracy
of time-dependent DMD operator on 2d Navier-Stokes equations, and test the
Lagrangian-based method on 1- and 2-dimensional advection-diffusion with
variable coefficients. Finally, we provide predictive accuracy and perturbation
error upper bounds to guide the selection of rank truncation and subinterval
sizes.
</p>
</div>
</dd>
<dt><a name="item255">[255]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.05120" title="Abstract">arXiv:2309.05120</a> [<a href="/pdf/2309.05120" title="Download PDF">pdf</a>, <a href="/format/2309.05120" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Routing and charging game in ride-hailing service with electric vehicles
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Zhang%2C+K">Kenan Zhang</a>, 
<a href="/search/eess?searchtype=author&query=Lygeros%2C+J">John Lygeros</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">This paper studies the routing and charging behaviors of electric vehicles in
a competitive ride-hailing market. When the vehicles are idle, they can choose
whether to continue cruising to search for passengers, or move a charging
station to recharge. The behaviors of individual vehicles are then modeled by a
Markov decision process (MDP). The state transitions in the MDP model, however,
depend on the aggregate vehicle flows both in service zones and at charging
stations. Accordingly, the value function of each vehicle is determined by the
collective behaviors of all vehicles. With the assumption of the large
population, we formulate the collective routing and charging behaviors as a
mean-field Markov game. We characterize the equilibrium of such a game, prove
its existence, and numerically show that the competition among vehicles leads
to ``inefficient congestion" both in service zones and at charging stations.
</p>
</div>
</dd>
<dt><a name="item256">[256]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.05124" title="Abstract">arXiv:2309.05124</a> [<a href="/pdf/2309.05124" title="Download PDF">pdf</a>, <a href="/format/2309.05124" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> WIP: Development of a Student-Centered Personalized Learning Framework  to Advance Undergraduate Robotics Education
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shill%2C+P+C">Ponkoj Chandra Shill</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+R">Rui Wu</a>, 
<a href="/search/cs?searchtype=author&query=Jamali%2C+H">Hossein Jamali</a>, 
<a href="/search/cs?searchtype=author&query=Hutchins%2C+B">Bryan Hutchins</a>, 
<a href="/search/cs?searchtype=author&query=Dascalu%2C+S">Sergiu Dascalu</a>, 
<a href="/search/cs?searchtype=author&query=Harris%2C+F+C">Frederick C. Harris</a>, 
<a href="/search/cs?searchtype=author&query=Feil-Seifer%2C+D">David Feil-Seifer</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages, 2 figures, conference
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> 2023 IEEE Frontiers in Education Conference (FIE)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI); Human-Computer Interaction (cs.HC)

</div>
<p class="mathjax">This paper presents a work-in-progress on a learn-ing system that will
provide robotics students with a personalized learning environment. This
addresses both the scarcity of skilled robotics instructors, particularly in
community colleges and the expensive demand for training equipment. The study
of robotics at the college level represents a wide range of interests,
experiences, and aims. This project works to provide students the flexibility
to adapt their learning to their own goals and prior experience. We are
developing a system to enable robotics instruction through a web-based
interface that is compatible with less expensive hardware. Therefore, the free
distribution of teaching materials will empower educators. This project has the
potential to increase the number of robotics courses offered at both two- and
four-year schools and universities. The course materials are being designed
with small units and a hierarchical dependency tree in mind; students will be
able to customize their course of study based on the robotics skills they have
already mastered. We present an evaluation of a five module mini-course in
robotics. Students indicated that they had a positive experience with the
online content. They also scored the experience highly on relatedness, mastery,
and autonomy perspectives, demonstrating strong motivation potential for this
approach.
</p>
</div>
</dd>
<dt><a name="item257">[257]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.05125" title="Abstract">arXiv:2309.05125</a> [<a href="/pdf/2309.05125" title="Download PDF">pdf</a>, <a href="/format/2309.05125" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Compressing the memory variables in constant-Q viscoelastic wave  propagation via an improved sum-of-exponentials approximation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Guo%2C+X">Xu Guo</a>, 
<a href="/search/math?searchtype=author&query=Jiang%2C+S">Shidong Jiang</a>, 
<a href="/search/math?searchtype=author&query=Xiong%2C+Y">Yunfeng Xiong</a>, 
<a href="/search/math?searchtype=author&query=Zhang%2C+J">Jiwei Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 28 pages, 52 figures, 6 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">Earth introduces strong attenuation and dispersion to propagating waves. The
time-fractional wave equation with very small fractional exponent, based on
Kjartansson's constant-Q theory, is widely recognized in the field of
geophysics as a reliable model for frequency-independent Q anelastic behavior.
Nonetheless, the numerical resolution of this equation poses considerable
challenges due to the requirement of storing a complete time history of
wavefields. To address this computational challenge, we present a novel
approach: a nearly optimal sum-of-exponentials (SOE) approximation to the
Caputo fractional derivative with very small fractional exponent, utilizing the
machinery of generalized Gaussian quadrature. This method minimizes the number
of memory variables needed to approximate the power attenuation law within a
specified error tolerance. We establish a mathematical equivalence between this
SOE approximation and the continuous fractional stress-strain relationship,
relating it to the generalized Maxwell body model. Furthermore, we prove an
improved SOE approximation error bound to thoroughly assess the ability of
rheological models to replicate the power attenuation law. Numerical
simulations on constant-Q viscoacoustic equation in 3D homogeneous media and
variable-order P- and S- viscoelastic wave equations in 3D inhomogeneous media
are performed. These simulations demonstrate that our proposed technique
accurately captures changes in amplitude and phase resulting from material
anelasticity. This advancement provides a significant step towards the
practical usage of the time-fractional wave equation in seismic inversion.
</p>
</div>
</dd>
<dt><a name="item258">[258]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.05127" title="Abstract">arXiv:2309.05127</a> [<a href="/pdf/2309.05127" title="Download PDF">pdf</a>, <a href="/format/2309.05127" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning Personalized User Preference from Cold Start in Multi-turn  Conversations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kong%2C+D">Deguang Kong</a>, 
<a href="/search/cs?searchtype=author&query=Jha%2C+A">Abhay Jha</a>, 
<a href="/search/cs?searchtype=author&query=Yun%2C+L">Lei Yun</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> preference, personalization, cold-start, dialogue, LLM. embedding
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>

</div>
<p class="mathjax">This paper presents a novel teachable conversation interaction system that is
capable of learning users preferences from cold start by gradually adapting to
personal preferences. In particular, the TAI system is able to automatically
identify and label user preference in live interactions, manage dialogue flows
for interactive teaching sessions, and reuse learned preference for preference
elicitation. We develop the TAI system by leveraging BERT encoder models to
encode both dialogue and relevant context information, and build action
prediction (AP), argument filling (AF) and named entity recognition (NER)
models to understand the teaching session. We adopt a seeker-provider
interaction loop mechanism to generate diverse dialogues from cold-start. TAI
is capable of learning user preference, which achieves 0.9122 turn level
accuracy on out-of-sample dataset, and has been successfully adopted in
production.
</p>
</div>
</dd>
<dt><a name="item259">[259]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.05128" title="Abstract">arXiv:2309.05128</a> [<a href="/pdf/2309.05128" title="Download PDF">pdf</a>, <a href="/format/2309.05128" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Robot-assisted Soil Apparent Electrical Conductivity Measurements in  Orchards
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chatziparaschis%2C+D">Dimitrios Chatziparaschis</a>, 
<a href="/search/cs?searchtype=author&query=Scudiero%2C+E">Elia Scudiero</a>, 
<a href="/search/cs?searchtype=author&query=Karydis%2C+K">Konstantinos Karydis</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 15 pages, 16 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Soil apparent electrical conductivity (ECa) is a vital metric in Precision
Agriculture and Smart Farming, as it is used for optimal water content
management, geological mapping, and yield prediction. Several existing methods
seeking to estimate soil electrical conductivity are available, including
physical soil sampling, ground sensor installation and monitoring, and the use
of sensors that can obtain proximal ECa estimates. However, such methods can be
either very laborious and/or too costly for practical use over larger field
canopies. Robot-assisted ECa measurements, in contrast, may offer a scalable
and cost-effective solution. In this work, we present one such solution that
involves a ground mobile robot equipped with a customized and adjustable
platform to hold an Electromagnetic Induction (EMI) sensor to perform
semi-autonomous and on-demand ECa measurements under various field conditions.
The platform is designed to be easily re-configurable in terms of sensor
placement; results from testing for traversability and robot-to-sensor
interference across multiple case studies help establish appropriate tradeoffs
for sensor placement. Further, a developed simulation software package enables
rapid and accessible estimation of terrain traversability in relation to
desired EMI sensor placement. Extensive experimental evaluation across
different fields demonstrates that the obtained robot-assisted ECa measurements
are of high linearity compared with the ground truth (data collected manually
by a handheld EMI sensor) by scoring more than $90\%$ in Pearson correlation
coefficient in both plot measurements and estimated ECa maps generated by
kriging interpolation. The proposed robotic solution supports autonomous
behavior development in the field since it utilizes the ROS navigation stack
along with the RTK GNSS positioning data and features various ranging sensors.
</p>
</div>
</dd>
<dt><a name="item260">[260]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.05130" title="Abstract">arXiv:2309.05130</a> [<a href="/pdf/2309.05130" title="Download PDF">pdf</a>, <a href="/format/2309.05130" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The online learning architecture with edge computing for high-level  control for assisting patients
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shi%2C+Y">Yue Shi</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Y">Yihui Zhao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">The prevalence of mobility impairments due to conditions such as spinal cord
injuries, strokes, and degenerative diseases is on the rise globally.
Lower-limb exoskeletons have been increasingly recognized as a viable solution
for enhancing mobility and rehabilitation for individuals with such
impairments. However, existing exoskeleton control systems often suffer from
limitations such as latency, lack of adaptability, and computational
inefficiency. To address these challenges, this paper introduces a novel online
adversarial learning architecture integrated with edge computing for high-level
lower-limb exoskeleton control. In the proposed architecture, sensor data from
the user is processed in real-time through edge computing nodes, which then
interact with an online adversarial learning model. This model adapts to the
user's specific needs and controls the exoskeleton with minimal latency.
Experimental evaluations demonstrate significant improvements in control
accuracy and adaptability, as well as enhanced quality-of-service (QoS)
metrics. These findings indicate that the integration of online adversarial
learning with edge computing offers a robust and efficient approach for the
next generation of lower-limb exoskeleton control systems.
</p>
</div>
</dd>
<dt><a name="item261">[261]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.05131" title="Abstract">arXiv:2309.05131</a> [<a href="/pdf/2309.05131" title="Download PDF">pdf</a>, <a href="/format/2309.05131" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Signal Temporal Logic Neural Predictive Control
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Meng%2C+Y">Yue Meng</a>, 
<a href="/search/cs?searchtype=author&query=Fan%2C+C">Chuchu Fan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by IEEE Robotics and Automation Letters (RA-L) and ICRA2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Robotics (cs.RO)

</div>
<p class="mathjax">Ensuring safety and meeting temporal specifications are critical challenges
for long-term robotic tasks. Signal temporal logic (STL) has been widely used
to systematically and rigorously specify these requirements. However,
traditional methods of finding the control policy under those STL requirements
are computationally complex and not scalable to high-dimensional or systems
with complex nonlinear dynamics. Reinforcement learning (RL) methods can learn
the policy to satisfy the STL specifications via hand-crafted or STL-inspired
rewards, but might encounter unexpected behaviors due to ambiguity and sparsity
in the reward. In this paper, we propose a method to directly learn a neural
network controller to satisfy the requirements specified in STL. Our controller
learns to roll out trajectories to maximize the STL robustness score in
training. In testing, similar to Model Predictive Control (MPC), the learned
controller predicts a trajectory within a planning horizon to ensure the
satisfaction of the STL requirement in deployment. A backup policy is designed
to ensure safety when our controller fails. Our approach can adapt to various
initial conditions and environmental parameters. We conduct experiments on six
tasks, where our method with the backup policy outperforms the classical
methods (MPC, STL-solver), model-free and model-based RL methods in STL
satisfaction rate, especially on tasks with complex STL specifications while
being 10X-100X faster than the classical methods.
</p>
</div>
</dd>
<dt><a name="item262">[262]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.05132" title="Abstract">arXiv:2309.05132</a> [<a href="/pdf/2309.05132" title="Download PDF">pdf</a>, <a href="/format/2309.05132" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DAD++: Improved Data-free Test Time Adversarial Defense
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nayak%2C+G+K">Gaurav Kumar Nayak</a>, 
<a href="/search/cs?searchtype=author&query=Khatri%2C+I">Inder Khatri</a>, 
<a href="/search/cs?searchtype=author&query=Randive%2C+S">Shubham Randive</a>, 
<a href="/search/cs?searchtype=author&query=Rawal%2C+R">Ruchit Rawal</a>, 
<a href="/search/cs?searchtype=author&query=Chakraborty%2C+A">Anirban Chakraborty</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> IJCV Journal (Under Review)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG); Machine Learning (stat.ML)

</div>
<p class="mathjax">With the increasing deployment of deep neural networks in safety-critical
applications such as self-driving cars, medical imaging, anomaly detection,
etc., adversarial robustness has become a crucial concern in the reliability of
these networks in real-world scenarios. A plethora of works based on
adversarial training and regularization-based techniques have been proposed to
make these deep networks robust against adversarial attacks. However, these
methods require either retraining models or training them from scratch, making
them infeasible to defend pre-trained models when access to training data is
restricted. To address this problem, we propose a test time Data-free
Adversarial Defense (DAD) containing detection and correction frameworks.
Moreover, to further improve the efficacy of the correction framework in cases
when the detector is under-confident, we propose a soft-detection scheme
(dubbed as "DAD++"). We conduct a wide range of experiments and ablations on
several datasets and network architectures to show the efficacy of our proposed
approach. Furthermore, we demonstrate the applicability of our approach in
imparting adversarial defense at test time under data-free (or data-efficient)
applications/setups, such as Data-free Knowledge Distillation and Source-free
Unsupervised Domain Adaptation, as well as Semi-supervised classification
frameworks. We observe that in all the experiments and applications, our DAD++
gives an impressive performance against various adversarial attacks with a
minimal drop in clean accuracy. The source code is available at:
https://github.com/vcl-iisc/Improved-Data-free-Test-Time-Adversarial-Defense
</p>
</div>
</dd>
<dt><a name="item263">[263]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.05133" title="Abstract">arXiv:2309.05133</a> [<a href="/pdf/2309.05133" title="Download PDF">pdf</a>, <a href="/format/2309.05133" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Parallel RAM from Cyclic Circuits
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Heath%2C+D">David Heath</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>; Computational Complexity (cs.CC)

</div>
<p class="mathjax">Known simulations of random access machines (RAMs) or parallel RAMs (PRAMs)
by Boolean circuits incur significant polynomial blowup, due to the need to
repeatedly simulate accesses to a large main memory.
<br />Consider two modifications to Boolean circuits: (1) remove the restriction
that circuit graphs are acyclic and (2) enhance AND gates such that they output
zero eagerly. If an AND gate has a zero input, it 'short circuits' and outputs
zero without waiting for its second input. We call this the cyclic circuit
model. Note, circuits in this model remain combinational, as they do not allow
wire values to change over time.
<br />We simulate a bounded-word-size PRAM via a cyclic circuit, and the blowup
from the simulation is only polylogarithmic. Consider a PRAM program $P$ that
on a length $n$ input uses an arbitrary number of processors to manipulate
words of size $\Theta(\log n)$ bits and then halts within $W(n)$ work. We
construct a size-$O(W(n)\cdot \log^4 n)$ cyclic circuit that simulates $P$.
Suppose that on a particular input, $P$ halts in time $T$; our circuit computes
the same output within $T \cdot O(\log^3 n)$ gate delay.
<br />This implies theoretical feasibility of powerful parallel machines. Cyclic
circuits can be implemented in hardware, and our circuit achieves performance
within polylog factors of PRAM. Our simulated PRAM synchronizes processors by
simply leveraging logical dependencies between wires.
</p>
</div>
</dd>
<dt><a name="item264">[264]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.05134" title="Abstract">arXiv:2309.05134</a> [<a href="/pdf/2309.05134" title="Download PDF">pdf</a>, <a href="/format/2309.05134" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Benchmarking ground truth trajectories with robotic total stations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Daum%2C+E">Effie Daum</a>, 
<a href="/search/cs?searchtype=author&query=Vaidis%2C+M">Maxime Vaidis</a>, 
<a href="/search/cs?searchtype=author&query=Pomerleau%2C+F">Fran&#xe7;ois Pomerleau</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Benchmarks stand as vital cornerstones in elevating SLAM algorithms within
mobile robotics. Consequently, ensuring accurate and reproducible ground truth
generation is vital for fair evaluation. A majority of outdoor ground truths
are generated by GNSS, which can lead to discrepancies over time, especially in
covered areas. However, research showed that RTS setups are more precise and
can alternatively be used to generate these ground truths. In our work, we
compare both RTS and GNSS systems' precision and repeatability through a set of
experiments conducted weeks and months apart in the same area. We demonstrated
that RTS setups give more reproducible results, with disparities having a
median value of 8.6 mm compared to a median value of 10.6 cm coming from a GNSS
setup. These results highlight that RTS can be considered to benchmark process
for SLAM algorithms with higher precision.
</p>
</div>
</dd>
<dt><a name="item265">[265]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.05135" title="Abstract">arXiv:2309.05135</a> [<a href="/pdf/2309.05135" title="Download PDF">pdf</a>, <a href="/ps/2309.05135" title="Download PostScript">ps</a>, <a href="/format/2309.05135" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Streaming Semidefinite Programs: $O(\sqrt{n})$ Passes, Small Space and  Fast Runtime
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Song%2C+Z">Zhao Song</a>, 
<a href="/search/cs?searchtype=author&query=Ye%2C+M">Mingquan Ye</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+L">Lichen Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>

</div>
<p class="mathjax">We study the problem of solving semidefinite programs (SDP) in the streaming
model. Specifically, $m$ constraint matrices and a target matrix $C$, all of
size $n\times n$ together with a vector $b\in \mathbb{R}^m$ are streamed to us
one-by-one. The goal is to find a matrix $X\in \mathbb{R}^{n\times n}$ such
that $\langle C, X\rangle$ is maximized, subject to $\langle A_i, X\rangle=b_i$
for all $i\in [m]$ and $X\succeq 0$. Previous algorithmic studies of SDP
primarily focus on \emph{time-efficiency}, and all of them require a
prohibitively large $\Omega(mn^2)$ space in order to store \emph{all the
constraints}. Such space consumption is necessary for fast algorithms as it is
the size of the input. In this work, we design an interior point method (IPM)
that uses $\widetilde O(m^2+n^2)$ space, which is strictly sublinear in the
regime $n\gg m$. Our algorithm takes $O(\sqrt n\log(1/\epsilon))$ passes, which
is standard for IPM. Moreover, when $m$ is much smaller than $n$, our algorithm
also matches the time complexity of the state-of-the-art SDP solvers. To
achieve such a sublinear space bound, we design a novel sketching method that
enables one to compute a spectral approximation to the Hessian matrix in
$O(m^2)$ space. To the best of our knowledge, this is the first method that
successfully applies sketching technique to improve SDP algorithm in terms of
space (also time).
</p>
</div>
</dd>
<dt><a name="item266">[266]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.05137" title="Abstract">arXiv:2309.05137</a> [<a href="/pdf/2309.05137" title="Download PDF">pdf</a>, <a href="/format/2309.05137" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Debugging Trait Errors as Logic Programs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gray%2C+G">Gavin Gray</a>, 
<a href="/search/cs?searchtype=author&query=Crichton%2C+W">Will Crichton</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages, 2 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Programming Languages (cs.PL)</span>; Human-Computer Interaction (cs.HC)

</div>
<p class="mathjax">Rust uses traits to define units of shared behavior. Trait constraints build
up an implicit set of first-order hereditary Harrop clauses which is executed
by a powerful logic programming engine in the trait system. But that power
comes at a cost: the number of traits in Rust libraries is increasing, which
puts a growing burden on the trait system to help programmers diagnose errors.
Beyond a certain size of trait constraints, compiler diagnostics fall off the
edge of a complexity cliff, leading to useless error messages. Crate
maintainers have created ad-hoc solutions to diagnose common domain-specific
errors, but the problem of diagnosing trait errors in general is still open. We
propose a trait debugger as a means of getting developers the information
necessary to diagnose trait errors in any domain and at any scale. Our proposed
tool will extract proof trees from the trait solver, and it will interactively
visualize these proof trees to facilitate debugging of trait errors.
</p>
</div>
</dd>
<dt><a name="item267">[267]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.05138" title="Abstract">arXiv:2309.05138</a> [<a href="/pdf/2309.05138" title="Download PDF">pdf</a>, <a href="/format/2309.05138" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GenAIPABench: A Benchmark for Generative AI-based Privacy Assistants
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hamid%2C+A">Aamir Hamid</a>, 
<a href="/search/cs?searchtype=author&query=Samidi%2C+H+R">Hemanth Reddy Samidi</a>, 
<a href="/search/cs?searchtype=author&query=Finin%2C+T">Tim Finin</a>, 
<a href="/search/cs?searchtype=author&query=Pappachan%2C+P">Primal Pappachan</a>, 
<a href="/search/cs?searchtype=author&query=Yus%2C+R">Roberto Yus</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Computers and Society (cs.CY)

</div>
<p class="mathjax">Privacy policies inform users about the data management practices of
organizations. Yet, their complexity often renders them largely
incomprehensible to the average user, necessitating the development of privacy
assistants. With the advent of generative AI (genAI) technologies, there is an
untapped potential to enhance privacy assistants in answering user queries
effectively. However, the reliability of genAI remains a concern due to its
propensity for generating incorrect or misleading information. This study
introduces GenAIPABench, a novel benchmarking framework designed to evaluate
the performance of Generative AI-based Privacy Assistants (GenAIPAs).
GenAIPABench comprises: 1) A comprehensive set of questions about an
organization's privacy policy and a data protection regulation, along with
annotated answers for several organizations and regulations; 2) A robust set of
evaluation metrics for assessing the accuracy, relevance, and consistency of
the generated responses; and 3) An evaluation tool that generates appropriate
prompts to introduce the system to the privacy document and different
variations of the privacy questions to evaluate its robustness. We use
GenAIPABench to assess the potential of three leading genAI systems in becoming
GenAIPAs: ChatGPT, Bard, and Bing AI. Our results demonstrate significant
promise in genAI capabilities in the privacy domain while also highlighting
challenges in managing complex queries, ensuring consistency, and verifying
source accuracy.
</p>
</div>
</dd>
<dt><a name="item268">[268]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.05139" title="Abstract">arXiv:2309.05139</a> [<a href="/pdf/2309.05139" title="Download PDF">pdf</a>, <a href="/format/2309.05139" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Skeleton-based Approach For Rock Crack Detection Towards A Climbing  Robot Application
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Roberts%2C+J+S">Josselin Somerville Roberts</a>, 
<a href="/search/cs?searchtype=author&query=Giacomelli%2C+P">Paul-Emile Giacomelli</a>, 
<a href="/search/cs?searchtype=author&query=Gozlan%2C+Y">Yoni Gozlan</a>, 
<a href="/search/cs?searchtype=author&query=Di%2C+J">Julia Di</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Robotics (cs.RO)

</div>
<p class="mathjax">Conventional wheeled robots are unable to traverse scientifically
interesting, but dangerous, cave environments. Multi-limbed climbing robot
designs, such as ReachBot, are able to grasp irregular surface features and
execute climbing motions to overcome obstacles, given suitable grasp locations.
To support grasp site identification, we present a method for detecting rock
cracks and edges, the SKeleton Intersection Loss (SKIL). SKIL is a loss
designed for thin object segmentation that leverages the skeleton of the label.
A dataset of rock face images was collected, manually annotated, and augmented
with generated data. A new group of metrics, LineAcc, has been proposed for
thin object segmentation such that the impact of the object width on the score
is minimized. In addition, the metric is less sensitive to translation which
can often lead to a score of zero when computing classical metrics such as Dice
on thin objects. Our fine-tuned models outperform previous methods on similar
thin object segmentation tasks such as blood vessel segmentation and show
promise for integration onto a robotic system.
</p>
</div>
</dd>
<dt><a name="item269">[269]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.05142" title="Abstract">arXiv:2309.05142</a> [<a href="/pdf/2309.05142" title="Download PDF">pdf</a>, <a href="/format/2309.05142" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Large Language Models for Difficulty Estimation of Foreign Language  Content with Application to Language Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Vlachos%2C+M">Michalis Vlachos</a>, 
<a href="/search/cs?searchtype=author&query=Lungu%2C+M">Mircea Lungu</a>, 
<a href="/search/cs?searchtype=author&query=Shrestha%2C+Y+R">Yash Raj Shrestha</a>, 
<a href="/search/cs?searchtype=author&query=David%2C+J">Johannes-Rudolf David</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">We use large language models to aid learners enhance proficiency in a foreign
language. This is accomplished by identifying content on topics that the user
is interested in, and that closely align with the learner's proficiency level
in that foreign language. Our work centers on French content, but our approach
is readily transferable to other languages. Our solution offers several
distinctive characteristics that differentiate it from existing
language-learning solutions, such as, a) the discovery of content across topics
that the learner cares about, thus increasing motivation, b) a more precise
estimation of the linguistic difficulty of the content than traditional
readability measures, and c) the availability of both textual and video-based
content. The linguistic complexity of video content is derived from the video
captions. It is our aspiration that such technology will enable learners to
remain engaged in the language-learning process by continuously adapting the
topics and the difficulty of the content to align with the learners' evolving
interests and learning objectives.
</p>
</div>
</dd>
<dt><a name="item270">[270]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.05143" title="Abstract">arXiv:2309.05143</a> [<a href="/pdf/2309.05143" title="Download PDF">pdf</a>, <a href="/format/2309.05143" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Riemannian Acceleration with Preconditioning for symmetric eigenvalue  problems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Shao%2C+N">Nian Shao</a>, 
<a href="/search/math?searchtype=author&query=Chen%2C+W">Wenbin Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Due to the limit in abstract of arXiv, the abstract here is shorter than in PDF
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">In this paper, we propose a Riemannian Acceleration with Preconditioning
(RAP) for symmetric eigenvalue problems, which is one of the most important
geodesically convex optimization problem on Riemannian manifold, and obtain the
acceleration. Firstly, the preconditioning for symmetric eigenvalue problems
from the Riemannian manifold viewpoint is discussed. In order to obtain the
local geodesic convexity, we develop the leading angle to measure the quality
of the preconditioner for symmetric eigenvalue problems. A new Riemannian
acceleration, called Locally Optimal Riemannian Accelerated Gradient (LORAG)
method, is proposed to overcome the local geodesic convexity for symmetric
eigenvalue problems. With similar techniques for RAGD and analysis of local
convex optimization in Euclidean space, we analyze the convergence of LORAG.
Incorporating the local geodesic convexity of symmetric eigenvalue problems
under preconditioning with the LORAG, we propose the Riemannian Acceleration
with Preconditioning (RAP) and prove its acceleration. Additionally, when the
Schwarz preconditioner, especially the overlapping or non-overlapping domain
decomposition method, is applied for elliptic eigenvalue problems, we also
obtain the rate of convergence as $1-C\kappa^{-1/2}$, where $C$ is a constant
independent of the mesh sizes and the eigenvalue gap,
$\kappa=\kappa_{\nu}\lambda_{2}/(\lambda_{2}-\lambda_{1})$, $\kappa_{\nu}$ is
the parameter from the stable decomposition, $\lambda_{1}$ and $\lambda_{2}$
are the smallest two eigenvalues of the elliptic operator. Numerical results
show the power of Riemannian acceleration and preconditioning.
</p>
</div>
</dd>
<dt><a name="item271">[271]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.05145" title="Abstract">arXiv:2309.05145</a> [<a href="/pdf/2309.05145" title="Download PDF">pdf</a>, <a href="/format/2309.05145" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Outlier Robust Adversarial Training
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hu%2C+S">Shu Hu</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Z">Zhenhuan Yang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xin Wang</a>, 
<a href="/search/cs?searchtype=author&query=Ying%2C+Y">Yiming Ying</a>, 
<a href="/search/cs?searchtype=author&query=Lyu%2C+S">Siwei Lyu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by The 15th Asian Conference on Machine Learning (ACML 2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Machine Learning (stat.ML)

</div>
<p class="mathjax">Supervised learning models are challenged by the intrinsic complexities of
training data such as outliers and minority subpopulations and intentional
attacks at inference time with adversarial samples. While traditional robust
learning methods and the recent adversarial training approaches are designed to
handle each of the two challenges, to date, no work has been done to develop
models that are robust with regard to the low-quality training data and the
potential adversarial attack at inference time simultaneously. It is for this
reason that we introduce Outlier Robust Adversarial Training (ORAT) in this
work. ORAT is based on a bi-level optimization formulation of adversarial
training with a robust rank-based loss function. Theoretically, we show that
the learning objective of ORAT satisfies the $\mathcal{H}$-consistency in
binary classification, which establishes it as a proper surrogate to
adversarial 0/1 loss. Furthermore, we analyze its generalization ability and
provide uniform convergence rates in high probability. ORAT can be optimized
with a simple algorithm. Experimental evaluations on three benchmark datasets
demonstrate the effectiveness and robustness of ORAT in handling outliers and
adversarial attacks. Our code is available at
https://github.com/discovershu/ORAT.
</p>
</div>
</dd>
<dt><a name="item272">[272]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.05148" title="Abstract">arXiv:2309.05148</a> [<a href="/pdf/2309.05148" title="Download PDF">pdf</a>, <a href="/format/2309.05148" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Beyond Skin Tone: A Multidimensional Measure of Apparent Skin Color
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Thong%2C+W">William Thong</a>, 
<a href="/search/cs?searchtype=author&query=Joniak%2C+P">Przemyslaw Joniak</a>, 
<a href="/search/cs?searchtype=author&query=Xiang%2C+A">Alice Xiang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at the International Conference on Computer Vision (ICCV) 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">This paper strives to measure apparent skin color in computer vision, beyond
a unidimensional scale on skin tone. In their seminal paper Gender Shades,
Buolamwini and Gebru have shown how gender classification systems can be biased
against women with darker skin tones. Subsequently, fairness researchers and
practitioners have adopted the Fitzpatrick skin type classification as a common
measure to assess skin color bias in computer vision systems. While effective,
the Fitzpatrick scale only focuses on the skin tone ranging from light to dark.
Towards a more comprehensive measure of skin color, we introduce the hue angle
ranging from red to yellow. When applied to images, the hue dimension reveals
additional biases related to skin color in both computer vision datasets and
models. We then recommend multidimensional skin color scales, relying on both
skin tone and hue, for fairness assessments.
</p>
</div>
</dd>
<dt><a name="item273">[273]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.05150" title="Abstract">arXiv:2309.05150</a> [<a href="/pdf/2309.05150" title="Download PDF">pdf</a>, <a href="/format/2309.05150" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Faster, Lighter, More Accurate: A Deep Learning Ensemble for Content  Moderation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hosseini%2C+M">Mohammad Hosseini</a>, 
<a href="/search/cs?searchtype=author&query=Hasan%2C+M">Mahmudul Hasan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages, 22nd IEEE International Conference on Machine Learning and Applications (IEEE ICMLA'23), December 15-17, 2023, Jacksonville Riverfront, Florida, USA. arXiv admin note: substantial text overlap with <a href="/abs/2103.10350">arXiv:2103.10350</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">To address the increasing need for efficient and accurate content moderation,
we propose an efficient and lightweight deep classification ensemble structure.
Our approach is based on a combination of simple visual features, designed for
high-accuracy classification of violent content with low false positives. Our
ensemble architecture utilizes a set of lightweight models with narrowed-down
color features, and we apply it to both images and videos.
<br />We evaluated our approach using a large dataset of explosion and blast
contents and compared its performance to popular deep learning models such as
ResNet-50. Our evaluation results demonstrate significant improvements in
prediction accuracy, while benefiting from 7.64x faster inference and lower
computation cost.
<br />While our approach is tailored to explosion detection, it can be applied to
other similar content moderation and violence detection use cases as well.
Based on our experiments, we propose a "think small, think many" philosophy in
classification scenarios. We argue that transforming a single, large,
monolithic deep model into a verification-based step model ensemble of multiple
small, simple, and lightweight models with narrowed-down visual features can
possibly lead to predictions with higher accuracy.
</p>
</div>
</dd>
<dt><a name="item274">[274]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.05158" title="Abstract">arXiv:2309.05158</a> [<a href="/pdf/2309.05158" title="Download PDF">pdf</a>, <a href="/ps/2309.05158" title="Download PostScript">ps</a>, <a href="/format/2309.05158" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Kinematics-Based Sensor Fault Detection for Autonomous Vehicles Using  Real-Time Numerical Differentiation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Verma%2C+S">Shashank Verma</a>, 
<a href="/search/eess?searchtype=author&query=Rahman%2C+Y">Yousaf Rahman</a>, 
<a href="/search/eess?searchtype=author&query=Sumer%2C+E+D">E. Dogan Sumer</a>, 
<a href="/search/eess?searchtype=author&query=Bernstein%2C+D+S">Dennis S. Bernstein</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">Sensor fault detection is of extreme importance for ensuring the safe
operation of vehicles. This paper introduces a novel approach to detecting and
identifying faulty sensors. For ground vehicles confined to the horizontal
plane, this technique is based on six kinematics-based error metrics that are
computed in real time by using onboard sensor data encompassing compass, radar,
rate gyro, and accelerometer measurements as well as their derivatives.
Real-time numerical differentiation is performed by applying the adaptive input
and state estimation (AIE/ASE) algorithm. Numerical examples are provided to
assess the efficacy of the proposed methodology.
</p>
</div>
</dd>
<dt><a name="item275">[275]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.05162" title="Abstract">arXiv:2309.05162</a> [<a href="/pdf/2309.05162" title="Download PDF">pdf</a>, <a href="/format/2309.05162" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Collecting Visually-Grounded Dialogue with A Game Of Sorts
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Willemsen%2C+B">Bram Willemsen</a>, 
<a href="/search/cs?searchtype=author&query=Kalpakchi%2C+D">Dmytro Kalpakchi</a>, 
<a href="/search/cs?searchtype=author&query=Skantze%2C+G">Gabriel Skantze</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Published at LREC 2022
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Proceedings of the Thirteenth Language Resources and Evaluation
  Conference (LREC 2022), pages 2257-2268, Marseille, France. European Language
  Resources Association
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">An idealized, though simplistic, view of the referring expression production
and grounding process in (situated) dialogue assumes that a speaker must merely
appropriately specify their expression so that the target referent may be
successfully identified by the addressee. However, referring in conversation is
a collaborative process that cannot be aptly characterized as an exchange of
minimally-specified referring expressions. Concerns have been raised regarding
assumptions made by prior work on visually-grounded dialogue that reveal an
oversimplified view of conversation and the referential process. We address
these concerns by introducing a collaborative image ranking task, a grounded
agreement game we call "A Game Of Sorts". In our game, players are tasked with
reaching agreement on how to rank a set of images given some sorting criterion
through a largely unrestricted, role-symmetric dialogue. By putting emphasis on
the argumentation in this mixed-initiative interaction, we collect discussions
that involve the collaborative referential process. We describe results of a
small-scale data collection experiment with the proposed task. All discussed
materials, which includes the collected data, the codebase, and a containerized
version of the application, are publicly available.
</p>
</div>
</dd>
<dt><a name="item276">[276]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.05167" title="Abstract">arXiv:2309.05167</a> [<a href="/pdf/2309.05167" title="Download PDF">pdf</a>, <a href="/format/2309.05167" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Certified Vision-based State Estimation for Autonomous Landing Systems  using Reachability Analysis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Leal%2C+U+S+C">Ulices Santa Cruz Leal</a>, 
<a href="/search/cs?searchtype=author&query=Shoukry%2C+Y">Yasser Shoukry</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages and 9 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Systems and Control (eess.SY)

</div>
<p class="mathjax">This paper studies the problem of designing a certified vision-based state
estimator for autonomous landing systems. In such a system, a neural network
(NN) processes images from a camera to estimate the aircraft relative position
with respect to the runway. We propose an algorithm to design such NNs with
certified properties in terms of their ability to detect runways and provide
accurate state estimation. At the heart of our approach is the use of geometric
models of perspective cameras to obtain a mathematical model that captures the
relation between the aircraft states and the inputs. We show that such
geometric models enjoy mixed monotonicity properties that can be used to design
state estimators with certifiable error bounds. We show the effectiveness of
the proposed approach using an experimental testbed on data collected from
event-based cameras.
</p>
</div>
</dd>
<dt><a name="item277">[277]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.05169" title="Abstract">arXiv:2309.05169</a> [<a href="/pdf/2309.05169" title="Download PDF">pdf</a>, <a href="/format/2309.05169" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SYSPART: Automated Temporal System Call Filtering for Binaries
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rajagopalan%2C+V+L">Vidya Lakshmi Rajagopalan</a> (1), 
<a href="/search/cs?searchtype=author&query=Kleftogiorgos%2C+K">Konstantinos Kleftogiorgos</a> (1), 
<a href="/search/cs?searchtype=author&query=G%C3%B6kta%C5%9F%2C+E">Enes G&#xf6;kta&#x15f;</a> (1), 
<a href="/search/cs?searchtype=author&query=Xu%2C+J">Jun Xu</a> (2), 
<a href="/search/cs?searchtype=author&query=Portokalidis%2C+G">Georgios Portokalidis</a> (1 and 3) ((1) Stevens Institute of Technology, (2) University of Utah, (3) IMDEA Software Institute)
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 17 pages, 3 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">Restricting the system calls available to applications reduces the attack
surface of the kernel and limits the functionality available to compromised
applications. Recent approaches automatically identify the system calls
required by programs to block unneeded ones. For servers, they even consider
different phases of execution to tighten restrictions after initialization
completes. However, they require access to the source code for applications and
libraries, depend on users identifying when the server transitions from
initialization to serving clients, or do not account for dynamically-loaded
libraries. This paper introduces SYSPART, a semi-automatic system-call
filtering system designed for binary-only server programs that addresses the
above limitations. Using a novel algorithm that combines static and dynamic
analysis, SYSPART identifies the serving phases of all working threads of a
server. Static analysis is used to compute the system calls required during the
various serving phases in a sound manner, and dynamic observations are only
used to complement static resolution of dynamically-loaded libraries when
necessary. We evaluated SYSPART using six popular servers on x86-64 Linux to
demonstrate its effectiveness in automatically identifying serving phases,
generating accurate system-call filters, and mitigating attacks. Our results
show that SYSPART outperforms prior binary-only approaches and performs
comparably to source-code approaches.
</p>
</div>
</dd>
<dt><a name="item278">[278]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.05172" title="Abstract">arXiv:2309.05172</a> [<a href="/pdf/2309.05172" title="Download PDF">pdf</a>, <a href="/ps/2309.05172" title="Download PostScript">ps</a>, <a href="/format/2309.05172" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> 2-Approximation for Prize-Collecting Steiner Forest
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ahmadi%2C+A">Ali Ahmadi</a>, 
<a href="/search/cs?searchtype=author&query=Gholami%2C+I">Iman Gholami</a>, 
<a href="/search/cs?searchtype=author&query=Hajiaghayi%2C+M">MohammadTaghi Hajiaghayi</a>, 
<a href="/search/cs?searchtype=author&query=Jabbarzade%2C+P">Peyman Jabbarzade</a>, 
<a href="/search/cs?searchtype=author&query=Mahdavi%2C+M">Mohammad Mahdavi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>

</div>
<p class="mathjax">Approximation algorithms for the prize-collecting Steiner forest problem
(PCSF) have been a subject of research for over three decades, starting with
the seminal works of Agrawal, Klein, and Ravi and Goemans and Williamson on
Steiner forest and prize-collecting problems. In this paper, we propose and
analyze a natural deterministic algorithm for PCSF that achieves a
$2$-approximate solution in polynomial time. This represents a significant
improvement compared to the previously best known algorithm with a
$2.54$-approximation factor developed by Hajiaghayi and Jain in 2006.
Furthermore, K{\"{o}}nemann, Olver, Pashkovich, Ravi, Swamy, and Vygen have
established an integrality gap of at least $9/4$ for the natural LP relaxation
for PCSF. However, we surpass this gap through the utilization of a
combinatorial algorithm and a novel analysis technique. Since $2$ is the best
known approximation guarantee for Steiner forest problem, which is a special
case of PCSF, our result matches this factor and closes the gap between the
Steiner forest problem and its generalized version, PCSF.
</p>
</div>
</dd>
<dt><a name="item279">[279]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.05173" title="Abstract">arXiv:2309.05173</a> [<a href="/pdf/2309.05173" title="Download PDF">pdf</a>, <a href="/format/2309.05173" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DePT: Decomposed Prompt Tuning for Parameter-Efficient Fine-tuning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shi%2C+Z">Zhengxiang Shi</a>, 
<a href="/search/cs?searchtype=author&query=Lipani%2C+A">Aldo Lipani</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Code is available at <a href="https://github.com/ZhengxiangShi/DePT">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
<p class="mathjax">Prompt tuning (PT), where a small amount of trainable soft (continuous)
prompt vectors is affixed to the input of language models (LM), has shown
promising results across various tasks and models for parameter-efficient
fine-tuning (PEFT). PT stands out from other PEFT approaches because it
maintains competitive performance with fewer trainable parameters and does not
drastically scale up its parameters as the model size expands. However, PT
introduces additional soft prompt tokens, leading to longer input sequences,
which significantly impacts training and inference time and memory usage due to
the Transformer's quadratic complexity. Particularly concerning for Large
Language Models (LLMs) that face heavy daily querying. To address this issue,
we propose Decomposed Prompt Tuning (DePT), which decomposes the soft prompt
into a shorter soft prompt and a pair of low-rank matrices that are then
optimised with two different learning rates. This allows DePT to achieve better
performance while saving over 20% memory and time costs compared to vanilla PT
and its variants, without changing trainable parameter sizes. Through extensive
experiments on 23 natural language processing (NLP) and vision-language (VL)
tasks, we demonstrate that DePT outperforms state-of-the-art PEFT approaches,
including the full fine-tuning baseline in some scenarios. Additionally, we
empirically show that DEPT grows more efficient as the model size increases.
Our further study reveals that DePT integrates seamlessly with
parameter-efficient transfer learning in the few-shot learning setting and
highlights its adaptability to various model architectures and sizes.
</p>
</div>
</dd>
<dt><a name="item280">[280]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.05174" title="Abstract">arXiv:2309.05174</a> [<a href="/pdf/2309.05174" title="Download PDF">pdf</a>, <a href="/format/2309.05174" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Serberus: Protecting Cryptographic Code from Spectres at Compile-Time
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mosier%2C+N">Nicholas Mosier</a>, 
<a href="/search/cs?searchtype=author&query=Nemati%2C+H">Hamed Nemati</a>, 
<a href="/search/cs?searchtype=author&query=Mitchell%2C+J+C">John C. Mitchell</a>, 
<a href="/search/cs?searchtype=author&query=Trippel%2C+C">Caroline Trippel</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Authors' version; to appear in the Proceedings of the IEEE Symposium on Security and Privacy (S&amp;P) 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Hardware Architecture (cs.AR)

</div>
<p class="mathjax">We present Serberus, the first comprehensive mitigation for hardening
constant-time (CT) code against Spectre attacks (involving the PHT, BTB, RSB,
STL and/or PSF speculation primitives) on existing hardware. Serberus is based
on three insights. First, some hardware control-flow integrity (CFI)
protections restrict transient control-flow to the extent that it may be
comprehensively considered by software analyses. Second, conformance to the
accepted CT code discipline permits two code patterns that are unsafe in the
post-Spectre era. Third, once these code patterns are addressed, all Spectre
leakage of secrets in CT programs can be attributed to one of four classes of
taint primitives--instructions that can transiently assign a secret value to a
publicly-typed register. We evaluate Serberus on cryptographic primitives in
the OpenSSL, Libsodium, and HACL* libraries. Serberus introduces 21.3% runtime
overhead on average, compared to 24.9% for the next closest state-of-the-art
software mitigation, which is less secure.
</p>
</div>
</dd>
<dt><a name="item281">[281]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.05178" title="Abstract">arXiv:2309.05178</a> [<a href="/pdf/2309.05178" title="Download PDF">pdf</a>, <a href="/format/2309.05178" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Quantifying Uncertainty in Aggregate Queries over Integrated Datasets
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Turkcapar%2C+D">Deniz Turkcapar</a>, 
<a href="/search/cs?searchtype=author&query=Krishnan%2C+S">Sanjay Krishnan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Databases (cs.DB)</span>

</div>
<p class="mathjax">Data integration is a notoriously difficult and heuristic-driven process,
especially when ground-truth data are not readily available. This paper
presents a measure of uncertainty by providing maximal and minimal ranges of a
query outcome in two-table, one-to-many data integration workflows. Users can
use these query results to guide a search through different matching
parameters, similarity metrics, and constraints. Even though there are
exponentially many such matchings, we show that in appropriately constrained
circumstances that this result range can be calculated in polynomial time with
bipartite graph matching. We evaluate this on real-world datasets and synthetic
datasets, and find that uncertainty estimates are more robust when a
graph-matching based approach is used for data integration.
</p>
</div>
</dd>
<dt><a name="item282">[282]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.05179" title="Abstract">arXiv:2309.05179</a> [<a href="/pdf/2309.05179" title="Download PDF">pdf</a>, <a href="/format/2309.05179" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Effect of Adapting to Human Preferences on Trust in Human-Robot Teaming
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bhat%2C+S">Shreyas Bhat</a>, 
<a href="/search/cs?searchtype=author&query=Lyons%2C+J+B">Joseph B. Lyons</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+C">Cong Shi</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+X+J">X. Jessie Yang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages, 6 figures, AAAI Fall Symposium on Agent Teaming in Mixed-Motive Situations
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">We present the effect of adapting to human preferences on trust in a
human-robot teaming task. The team performs a task in which the robot acts as
an action recommender to the human. It is assumed that the behavior of the
human and the robot is based on some reward function they try to optimize. We
use a new human trust-behavior model that enables the robot to learn and adapt
to the human's preferences in real-time during their interaction using Bayesian
Inverse Reinforcement Learning. We present three strategies for the robot to
interact with a human: a non-learner strategy, in which the robot assumes that
the human's reward function is the same as the robot's, a non-adaptive learner
strategy that learns the human's reward function for performance estimation,
but still optimizes its own reward function, and an adaptive-learner strategy
that learns the human's reward function for performance estimation and also
optimizes this learned reward function. Results show that adapting to the
human's reward function results in the highest trust in the robot.
</p>
</div>
</dd>
<dt><a name="item283">[283]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.05180" title="Abstract">arXiv:2309.05180</a> [<a href="/pdf/2309.05180" title="Download PDF">pdf</a>, <a href="/format/2309.05180" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Our Deep CNN Face Matchers Have Developed Achromatopsia
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bhatta%2C+A">Aman Bhatta</a>, 
<a href="/search/cs?searchtype=author&query=Mery%2C+D">Domingo Mery</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+H">Haiyu Wu</a>, 
<a href="/search/cs?searchtype=author&query=Annan%2C+J">Joyce Annan</a>, 
<a href="/search/cs?searchtype=author&query=King%2C+M+C">Micheal C. King</a>, 
<a href="/search/cs?searchtype=author&query=Bowyer%2C+K+W">Kevin W. Bowyer</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Computers and Society (cs.CY)

</div>
<p class="mathjax">Modern deep CNN face matchers are trained on datasets containing color
images. We show that such matchers achieve essentially the same accuracy on the
grayscale or the color version of a set of test images. We then consider
possible causes for deep CNN face matchers ``not seeing color''. Popular
web-scraped face datasets actually have 30 to 60\% of their identities with one
or more grayscale images. We analyze whether this grayscale element in the
training set impacts the accuracy achieved, and conclude that it does not.
Further, we show that even with a 100\% grayscale training set, comparable
accuracy is achieved on color or grayscale test images. Then we show that the
skin region of an individual's images in a web-scraped training set exhibit
significant variation in their mapping to color space. This suggests that
color, at least for web-scraped, in-the-wild face datasets, carries limited
identity-related information for training state-of-the-art matchers. Finally,
we verify that comparable accuracy is achieved from training using
single-channel grayscale images, implying that a larger dataset can be used
within the same memory limit, with a less computationally intensive early
layer.
</p>
</div>
</dd>
<dt><a name="item284">[284]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.05182" title="Abstract">arXiv:2309.05182</a> [<a href="/pdf/2309.05182" title="Download PDF">pdf</a>, <a href="/ps/2309.05182" title="Download PostScript">ps</a>, <a href="/format/2309.05182" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Graph Matching in Correlated Stochastic Block Models for Improved Graph  Clustering
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+J">Joonhyuk Yang</a>, 
<a href="/search/cs?searchtype=author&query=Chung%2C+H+W">Hye Won Chung</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Allerton Conference 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Data Structures and Algorithms (cs.DS)

</div>
<p class="mathjax">We consider community detection from multiple correlated graphs sharing the
same community structure. The correlated graphs are generated by independent
subsampling of a parent graph sampled from the stochastic block model. The
vertex correspondence between the correlated graphs is assumed to be unknown.
We consider the two-step procedure where the vertex correspondence between the
correlated graphs is first revealed, and the communities are recovered from the
union of the correlated graphs, which becomes denser than each single graph. We
derive the information-theoretic limits for exact graph matching in general
density regimes and the number of communities, and then analyze the regime of
graph parameters, where one can benefit from the matching of the correlated
graphs in recovering the latent community structure of the graphs.
</p>
</div>
</dd>
<dt><a name="item285">[285]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.05183" title="Abstract">arXiv:2309.05183</a> [<a href="/pdf/2309.05183" title="Download PDF">pdf</a>, <a href="/ps/2309.05183" title="Download PostScript">ps</a>, <a href="/format/2309.05183" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Data Summarization beyond Monotonicity: Non-monotone Two-Stage  Submodular Maximization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tang%2C+S">Shaojie Tang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">The objective of a two-stage submodular maximization problem is to reduce the
ground set using provided training functions that are submodular, with the aim
of ensuring that optimizing new objective functions over the reduced ground set
yields results comparable to those obtained over the original ground set. This
problem has applications in various domains including data summarization.
Existing studies often assume the monotonicity of the objective function,
whereas our work pioneers the extension of this research to accommodate
non-monotone submodular functions. We have introduced the first constant-factor
approximation algorithms for this more general case.
</p>
</div>
</dd>
<dt><a name="item286">[286]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.05184" title="Abstract">arXiv:2309.05184</a> [<a href="/pdf/2309.05184" title="Download PDF">pdf</a>, <a href="/format/2309.05184" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SIM-Sync: From Certifiably Optimal Synchronization over the 3D  Similarity Group to Scene Reconstruction with Learned Depth
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yu%2C+X">Xihang Yu</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+H">Heng Yang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 28 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">This paper presents SIM-Sync, a certifiably optimal algorithm that estimates
camera trajectory and 3D scene structure directly from multiview image
keypoints. SIM-Sync fills the gap between pose graph optimization and bundle
adjustment; the former admits efficient global optimization but requires
relative pose measurements and the latter directly consumes image keypoints but
is difficult to optimize globally (due to camera projective geometry). The
bridge to this gap is a pretrained depth prediction network. Given a graph with
nodes representing monocular images taken at unknown camera poses and edges
containing pairwise image keypoint correspondences, SIM-Sync first uses a
pretrained depth prediction network to lift the 2D keypoints into 3D scaled
point clouds, where the scaling of the per-image point cloud is unknown due to
the scale ambiguity in monocular depth prediction. SIM-Sync then seeks to
synchronize jointly the unknown camera poses and scaling factors (i.e., over
the 3D similarity group). The SIM-Sync formulation, despite nonconvex, allows
designing an efficient certifiably optimal solver that is almost identical to
the SE-Sync algorithm. We demonstrate the tightness, robustness, and practical
usefulness of SIM-Sync in both simulated and real experiments. In simulation,
we show (i) SIM-Sync compares favorably with SE-Sync in scale-free
synchronization, and (ii) SIM-Sync can be used together with robust estimators
to tolerate a high amount of outliers. In real experiments, we show (a)
SIM-Sync achieves similar performance as Ceres on bundle adjustment datasets,
and (b) SIM-Sync performs on par with ORB-SLAM3 on the TUM dataset with
zero-shot depth prediction.
</p>
</div>
</dd>
<dt><a name="item287">[287]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.05186" title="Abstract">arXiv:2309.05186</a> [<a href="/pdf/2309.05186" title="Download PDF">pdf</a>, <a href="/format/2309.05186" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> HiLM-D: Towards High-Resolution Understanding in Multimodal Large  Language Models for Autonomous Driving
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ding%2C+X">Xinpeng Ding</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+J">Jianhua Han</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+H">Hang Xu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+W">Wei Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xiaomeng Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Autonomous driving systems generally employ separate models for different
tasks resulting in intricate designs. For the first time, we leverage singular
multimodal large language models (MLLMs) to consolidate multiple autonomous
driving tasks from videos, i.e., the Risk Object Localization and Intention and
Suggestion Prediction (ROLISP) task. ROLISP uses natural language to
simultaneously identify and interpret risk objects, understand ego-vehicle
intentions, and provide motion suggestions, eliminating the necessity for
task-specific architectures. However, lacking high-resolution (HR) information,
existing MLLMs often miss small objects (e.g., traffic cones) and overly focus
on salient ones (e.g., large trucks) when applied to ROLISP. We propose HiLM-D
(Towards High-Resolution Understanding in MLLMs for Autonomous Driving), an
efficient method to incorporate HR information into MLLMs for the ROLISP task.
Especially, HiLM-D integrates two branches: (i) the low-resolution reasoning
branch, can be any MLLMs, processes low-resolution videos to caption risk
objects and discern ego-vehicle intentions/suggestions; (ii) the
high-resolution perception branch (HR-PB), prominent to HiLM-D,, ingests HR
images to enhance detection by capturing vision-specific HR feature maps and
prioritizing all potential risks over merely salient objects. Our HR-PB serves
as a plug-and-play module, seamlessly fitting into current MLLMs. Experiments
on the ROLISP benchmark reveal HiLM-D's notable advantage over leading MLLMs,
with improvements of 4.8% in BLEU-4 for captioning and 17.2% in mIoU for
detection.
</p>
</div>
</dd>
<dt><a name="item288">[288]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.05187" title="Abstract">arXiv:2309.05187</a> [<a href="/pdf/2309.05187" title="Download PDF">pdf</a>, <a href="/format/2309.05187" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Haptic Guidance and Haptic Error Amplification in a Virtual Surgical  Robotic Training Environment
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Oquendo%2C+Y+A">Yousi A. Oquendo</a>, 
<a href="/search/cs?searchtype=author&query=Coad%2C+M+M">Margaret M. Coad</a>, 
<a href="/search/cs?searchtype=author&query=Wren%2C+S+M">Sherry M. Wren</a>, 
<a href="/search/cs?searchtype=author&query=Lendvay%2C+T+S">Thomas S. Lendvay</a>, 
<a href="/search/cs?searchtype=author&query=Nisky%2C+I">Ilana Nisky</a>, 
<a href="/search/cs?searchtype=author&query=Jarc%2C+A+M">Anthony M. Jarc</a>, 
<a href="/search/cs?searchtype=author&query=Okamura%2C+A+M">Allison M. Okamura</a>, 
<a href="/search/cs?searchtype=author&query=Chua%2C+Z">Zonghe Chua</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages, 7 Figure, Under Review
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Human-Computer Interaction (cs.HC)

</div>
<p class="mathjax">Teleoperated robotic systems have introduced more intuitive control for
minimally invasive surgery, but the optimal method for training remains
unknown. Recent motor learning studies have demonstrated that exaggeration of
errors helps trainees learn to perform tasks with greater speed and accuracy.
We hypothesized that training in a force field that pushes the operator away
from a desired path would improve their performance on a virtual reality
ring-on-wire task.
<br />Forty surgical novices trained under a no-force, guidance, or
error-amplifying force field over five days. Completion time, translational and
rotational path error, and combined error-time were evaluated under no force
field on the final day. The groups significantly differed in combined
error-time, with the guidance group performing the worst. Error-amplifying
field participants showed the most improvement and did not plateau in their
performance during training, suggesting that learning was still ongoing.
Guidance field participants had the worst performance on the final day,
confirming the guidance hypothesis. Participants with high initial path error
benefited more from guidance. Participants with high initial combined
error-time benefited more from guidance and error-amplifying force field
training. Our results suggest that error-amplifying and error-reducing haptic
training for robot-assisted telesurgery benefits trainees of different
abilities differently.
</p>
</div>
</dd>
<dt><a name="item289">[289]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.05192" title="Abstract">arXiv:2309.05192</a> [<a href="/pdf/2309.05192" title="Download PDF">pdf</a>, <a href="/format/2309.05192" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Viewpoint Robustness in Bird&#x27;s Eye View Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Klinghoffer%2C+T">Tzofi Klinghoffer</a>, 
<a href="/search/cs?searchtype=author&query=Philion%2C+J">Jonah Philion</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+W">Wenzheng Chen</a>, 
<a href="/search/cs?searchtype=author&query=Litany%2C+O">Or Litany</a>, 
<a href="/search/cs?searchtype=author&query=Gojcic%2C+Z">Zan Gojcic</a>, 
<a href="/search/cs?searchtype=author&query=Joo%2C+J">Jungseock Joo</a>, 
<a href="/search/cs?searchtype=author&query=Raskar%2C+R">Ramesh Raskar</a>, 
<a href="/search/cs?searchtype=author&query=Fidler%2C+S">Sanja Fidler</a>, 
<a href="/search/cs?searchtype=author&query=Alvarez%2C+J+M">Jose M. Alvarez</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ICCV 2023. Project Page: <a href="https://nvlabs.github.io/viewpoint-robustness">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Autonomous vehicles (AV) require that neural networks used for perception be
robust to different viewpoints if they are to be deployed across many types of
vehicles without the repeated cost of data collection and labeling for each. AV
companies typically focus on collecting data from diverse scenarios and
locations, but not camera rig configurations, due to cost. As a result, only a
small number of rig variations exist across most fleets. In this paper, we
study how AV perception models are affected by changes in camera viewpoint and
propose a way to scale them across vehicle types without repeated data
collection and labeling. Using bird's eye view (BEV) segmentation as a
motivating task, we find through extensive experiments that existing perception
models are surprisingly sensitive to changes in camera viewpoint. When trained
with data from one camera rig, small changes to pitch, yaw, depth, or height of
the camera at inference time lead to large drops in performance. We introduce a
technique for novel view synthesis and use it to transform collected data to
the viewpoint of target rigs, allowing us to train BEV segmentation models for
diverse target rigs without any additional data collection or labeling cost. To
analyze the impact of viewpoint changes, we leverage synthetic data to mitigate
other gaps (content, ISP, etc). Our approach is then trained on real data and
evaluated on synthetic data, enabling evaluation on diverse target rigs. We
release all data for use in future work. Our method is able to recover an
average of 14.7% of the IoU that is otherwise lost when deploying to new rigs.
</p>
</div>
</dd>
<dt><a name="item290">[290]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.05195" title="Abstract">arXiv:2309.05195</a> [<a href="/pdf/2309.05195" title="Download PDF">pdf</a>, <a href="/ps/2309.05195" title="Download PostScript">ps</a>, <a href="/format/2309.05195" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Cloud-mediated self-triggered synchronization of a general linear  multi-agent system over a directed graph
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Namba%2C+T">Takumi Namba</a>, 
<a href="/search/eess?searchtype=author&query=Takaba%2C+K">Kiyotsugu Takaba</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">This paper proposes a self-triggered synchronization control method of a
general high-order linear time-invariant multi-agent system through a cloud
repository. In the cloud-mediated self-triggered control, each agent
asynchronously accesses the cloud repository to get past information on its
neighboring agents. Then, the agent predicts future behaviors of its neighbors
as well as of its own, and locally determines its next access time to the cloud
repository. In the case of a general high-order linear agent dynamics, each
agent has to estimate exponential evolution of its trajectory characterized by
eigenvalues of a system matrix, which is different from single/double
integrator or first-order linear agents. Our proposed method deals with
exponential behaviors of the agents by tightly evaluating the bounds on matrix
exponentials. Based on these bound, we design the self-triggered controller
through a cloud which achieves bounded state synchronization of the closed-loop
system without exhibiting any Zeno behaviors. The effectiveness of the proposed
method is demonstrated through the numerical simulation.
</p>
</div>
</dd>
<dt><a name="item291">[291]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.05196" title="Abstract">arXiv:2309.05196</a> [<a href="/pdf/2309.05196" title="Download PDF">pdf</a>, <a href="/format/2309.05196" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Does Writing with Language Models Reduce Content Diversity?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Padmakumar%2C+V">Vishakh Padmakumar</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+H">He He</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Preprint
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Computers and Society (cs.CY); Human-Computer Interaction (cs.HC); Machine Learning (cs.LG)

</div>
<p class="mathjax">Large language models (LLMs) have led to a surge in collaborative writing
with model assistance. As different users incorporate suggestions from the same
model, there is a risk of decreased diversity in the produced content,
potentially limiting diverse perspectives in public discourse. In this work, we
measure the impact of co-writing on diversity via a controlled experiment,
where users write argumentative essays in three setups -- using a base LLM
(GPT3), a feedback-tuned LLM (InstructGPT), and writing without model help. We
develop a set of diversity metrics and find that writing with InstructGPT (but
not the GPT3) results in a statistically significant reduction in diversity.
Specifically, it increases the similarity between the writings of different
authors and reduces the overall lexical and content diversity. We additionally
find that this effect is mainly attributable to InstructGPT contributing less
diverse text to co-written essays. In contrast, the user-contributed text
remains unaffected by model collaboration. This suggests that the recent
improvement in generation quality from adapting models to human feedback might
come at the cost of more homogeneous and less diverse content.
</p>
</div>
</dd>
<dt><a name="item292">[292]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.05197" title="Abstract">arXiv:2309.05197</a> [<a href="/pdf/2309.05197" title="Download PDF">pdf</a>, <a href="/format/2309.05197" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning Sequential Acquisition Policies for Robot-Assisted Feeding
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sundaresan%2C+P">Priya Sundaresan</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+J">Jiajun Wu</a>, 
<a href="/search/cs?searchtype=author&query=Sadigh%2C+D">Dorsa Sadigh</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">A robot providing mealtime assistance must perform specialized maneuvers with
various utensils in order to pick up and feed a range of food items. Beyond
these dexterous low-level skills, an assistive robot must also plan these
strategies in sequence over a long horizon to clear a plate and complete a
meal. Previous methods in robot-assisted feeding introduce highly specialized
primitives for food handling without a means to compose them together.
Meanwhile, existing approaches to long-horizon manipulation lack the
flexibility to embed highly specialized primitives into their frameworks. We
propose Visual Action Planning OveR Sequences (VAPORS), a framework for
long-horizon food acquisition. VAPORS learns a policy for high-level action
selection by leveraging learned latent plate dynamics in simulation. To carry
out sequential plans in the real world, VAPORS delegates action execution to
visually parameterized primitives. We validate our approach on complex
real-world acquisition trials involving noodle acquisition and bimanual
scooping of jelly beans. Across 38 plates, VAPORS acquires much more
efficiently than baselines, generalizes across realistic plate variations such
as toppings and sauces, and qualitatively appeals to user feeding preferences
in a survey conducted across 49 individuals. Code, datasets, videos, and
supplementary materials can be found on our website:
https://sites.google.com/view/vaporsbot.
</p>
</div>
</dd>
<dt><a name="item293">[293]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.05200" title="Abstract">arXiv:2309.05200</a> [<a href="/pdf/2309.05200" title="Download PDF">pdf</a>, <a href="/format/2309.05200" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CARE: Confidence-rich Autonomous Robot Exploration using Bayesian Kernel  Inference and Optimization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+Y">Yang Xu</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+R">Ronghao Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+S">Senlin Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+M">Meiqin Liu</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+S">Shoudong Huang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Full version for the paper accepted by IEEE Robotics and Automation Letters (RA-L) 2023. arXiv admin note: text overlap with <a href="/abs/2301.00523">arXiv:2301.00523</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> IEEE Robotics and Automation Letters, 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">In this paper, we consider improving the efficiency of information-based
autonomous robot exploration in unknown and complex environments. We first
utilize Gaussian process (GP) regression to learn a surrogate model to infer
the confidence-rich mutual information (CRMI) of querying control actions, then
adopt an objective function consisting of predicted CRMI values and prediction
uncertainties to conduct Bayesian optimization (BO), i.e., GP-based BO (GPBO).
The trade-off between the best action with the highest CRMI value
(exploitation) and the action with high prediction variance (exploration) can
be realized. To further improve the efficiency of GPBO, we propose a novel
lightweight information gain inference method based on Bayesian kernel
inference and optimization (BKIO), achieving an approximate logarithmic
complexity without the need for training. BKIO can also infer the CRMI and
generate the best action using BO with bounded cumulative regret, which ensures
its comparable accuracy to GPBO with much higher efficiency. Extensive
numerical and real-world experiments show the desired efficiency of our
proposed methods without losing exploration performance in different
unstructured, cluttered environments. We also provide our open-source
implementation code at https://github.com/Shepherd-Gregory/BKIO-Exploration.
</p>
</div>
</dd>
<dt><a name="item294">[294]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.05201" title="Abstract">arXiv:2309.05201</a> [<a href="/pdf/2309.05201" title="Download PDF">pdf</a>, <a href="/format/2309.05201" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Two is Better Than One: Answering Complex Questions by Multiple  Knowledge Sources with Generalized Links
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+M">Minhao Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+Y">Yongliang Ma</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yanzeng Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+R">Ruoyu Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zou%2C+L">Lei Zou</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+M">Ming Zhou</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Incorporating multiple knowledge sources is proven to be beneficial for
answering complex factoid questions. To utilize multiple knowledge bases (KB),
previous works merge all KBs into a single graph via entity alignment and
reduce the problem to question-answering (QA) over the fused KB. In reality,
various link relations between KBs might be adopted in QA over multi-KBs. In
addition to the identity between the alignable entities (i.e. full link),
unalignable entities expressing the different aspects or types of an abstract
concept may also be treated identical in a question (i.e. partial link). Hence,
the KB fusion in prior works fails to represent all types of links, restricting
their ability to comprehend multi-KBs for QA. In this work, we formulate the
novel Multi-KB-QA task that leverages the full and partial links among multiple
KBs to derive correct answers, a benchmark with diversified link and query
types is also constructed to efficiently evaluate Multi-KB-QA performance.
Finally, we propose a method for Multi-KB-QA that encodes all link relations in
the KB embedding to score and rank candidate answers. Experiments show that our
method markedly surpasses conventional KB-QA systems in Multi-KB-QA, justifying
the necessity of devising this task.
</p>
</div>
</dd>
<dt><a name="item295">[295]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.05202" title="Abstract">arXiv:2309.05202</a> [<a href="/pdf/2309.05202" title="Download PDF">pdf</a>, <a href="/format/2309.05202" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Graph Contextual Contrasting for Multivariate Time Series Classification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yucheng Wang</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+Y">Yuecong Xu</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+J">Jianfei Yang</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+M">Min Wu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xiaoli Li</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+L">Lihua Xie</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Z">Zhenghua Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages, 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Contrastive learning, as a self-supervised learning paradigm, becomes popular
for Multivariate Time-Series (MTS) classification. It ensures the consistency
across different views of unlabeled samples and then learns effective
representations for these samples. Existing contrastive learning methods mainly
focus on achieving temporal consistency with temporal augmentation and
contrasting techniques, aiming to preserve temporal patterns against
perturbations for MTS data. However, they overlook spatial consistency that
requires the stability of individual sensors and their correlations. As MTS
data typically originate from multiple sensors, ensuring spatial consistency
becomes essential for the overall performance of contrastive learning on MTS
data. Thus, we propose Graph Contextual Contrasting (GCC) for spatial
consistency across MTS data. Specifically, we propose graph augmentations
including node and edge augmentations to preserve the stability of sensors and
their correlations, followed by graph contrasting with both node- and
graph-level contrasting to extract robust sensor- and global-level features. We
further introduce multi-window temporal contrasting to ensure temporal
consistency in the data for each sensor. Extensive experiments demonstrate that
our proposed GCC achieves state-of-the-art performance on various MTS
classification tasks.
</p>
</div>
</dd>
<dt><a name="item296">[296]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.05203" title="Abstract">arXiv:2309.05203</a> [<a href="/pdf/2309.05203" title="Download PDF">pdf</a>, <a href="/format/2309.05203" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> From Artificially Real to Real: Leveraging Pseudo Data from Large  Language Models for Low-Resource Molecule Discovery
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yuhan Chen</a>, 
<a href="/search/cs?searchtype=author&query=Xi%2C+N">Nuwa Xi</a>, 
<a href="/search/cs?searchtype=author&query=Du%2C+Y">Yanrui Du</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Haochun Wang</a>, 
<a href="/search/cs?searchtype=author&query=Jianyu%2C+C">Chen Jianyu</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+S">Sendong Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Qin%2C+B">Bing Qin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Molecule discovery serves as a cornerstone in numerous scientific domains,
fueling the development of new materials and innovative drug designs. Recent
developments of in-silico molecule discovery have highlighted the promising
results of cross-modal techniques, which bridge molecular structures with their
descriptive annotations. However, these cross-modal methods frequently
encounter the issue of data scarcity, hampering their performance and
application. In this paper, we address the low-resource challenge by utilizing
artificially-real data generated by Large Language Models (LLMs). We first
introduce a retrieval-based prompting strategy to construct high-quality pseudo
data, then explore the optimal method to effectively leverage this pseudo data.
Experiments show that using pseudo data for domain adaptation outperforms all
existing methods, while also requiring a smaller model scale, reduced data size
and lower training cost, highlighting its efficiency. Furthermore, our method
shows a sustained improvement as the volume of pseudo data increases, revealing
the great potential of pseudo data in advancing low-resource cross-modal
molecule discovery.
</p>
</div>
</dd>
<dt><a name="item297">[297]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.05206" title="Abstract">arXiv:2309.05206</a> [<a href="/pdf/2309.05206" title="Download PDF">pdf</a>, <a href="/ps/2309.05206" title="Download PostScript">ps</a>, <a href="/format/2309.05206" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Influence Maximization in Ising Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+Z">Zongchen Chen</a>, 
<a href="/search/cs?searchtype=author&query=Mossel%2C+E">Elchanan Mossel</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>; Social and Information Networks (cs.SI); Probability (math.PR)

</div>
<p class="mathjax">Given a complex high-dimensional distribution over $\{\pm 1\}^n$, what is the
best way to increase the expected number of $+1$'s by controlling the values of
only a small number of variables? Such a problem is known as influence
maximization and has been widely studied in social networks, biology, and
computer science. In this paper, we consider influence maximization on the
Ising model which is a prototypical example of undirected graphical models and
has wide applications in many real-world problems. We establish a sharp
computational phase transition for influence maximization on sparse Ising
models under a bounded budget: In the high-temperature regime, we give a
linear-time algorithm for finding a small subset of variables and their values
which achieve nearly optimal influence; In the low-temperature regime, we show
that the influence maximization problem becomes $\mathsf{NP}$-hard under
commonly-believed complexity assumption. The critical temperature coincides
with the tree uniqueness/non-uniqueness threshold for Ising models which is
also a critical point for other computational problems including approximate
sampling and counting.
</p>
</div>
</dd>
<dt><a name="item298">[298]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.05209" title="Abstract">arXiv:2309.05209</a> [<a href="/pdf/2309.05209" title="Download PDF">pdf</a>, <a href="/format/2309.05209" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Phase-Specific Augmented Reality Guidance for Microscopic Cataract  Surgery Using Long-Short Spatiotemporal Aggregation Transformer
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tu%2C+P">Puxun Tu</a>, 
<a href="/search/cs?searchtype=author&query=Ye%2C+H">Hongfei Ye</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+H">Haochen Shi</a>, 
<a href="/search/cs?searchtype=author&query=Young%2C+J">Jeff Young</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+M">Meng Xie</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+P">Peiquan Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+C">Ce Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+X">Xiaoyi Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+X">Xiaojun Chen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Phacoemulsification cataract surgery (PCS) is a routine procedure conducted
using a surgical microscope, heavily reliant on the skill of the
ophthalmologist. While existing PCS guidance systems extract valuable
information from surgical microscopic videos to enhance intraoperative
proficiency, they suffer from non-phasespecific guidance, leading to redundant
visual information. In this study, our major contribution is the development of
a novel phase-specific augmented reality (AR) guidance system, which offers
tailored AR information corresponding to the recognized surgical phase.
Leveraging the inherent quasi-standardized nature of PCS procedures, we propose
a two-stage surgical microscopic video recognition network. In the first stage,
we implement a multi-task learning structure to segment the surgical limbus
region and extract limbus region-focused spatial feature for each frame. In the
second stage, we propose the long-short spatiotemporal aggregation transformer
(LS-SAT) network to model local fine-grained and global temporal relationships,
and combine the extracted spatial features to recognize the current surgical
phase. Additionally, we collaborate closely with ophthalmologists to design AR
visual cues by utilizing techniques such as limbus ellipse fitting and regional
restricted normal cross-correlation rotation computation. We evaluated the
network on publicly available and in-house datasets, with comparison results
demonstrating its superior performance compared to related works. Ablation
results further validated the effectiveness of the limbus region-focused
spatial feature extractor and the combination of temporal features.
Furthermore, the developed system was evaluated in a clinical setup, with
results indicating remarkable accuracy and real-time performance. underscoring
its potential for clinical applications.
</p>
</div>
</dd>
<dt><a name="item299">[299]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.05210" title="Abstract">arXiv:2309.05210</a> [<a href="/pdf/2309.05210" title="Download PDF">pdf</a>, <a href="/ps/2309.05210" title="Download PostScript">ps</a>, <a href="/format/2309.05210" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Understanding the Impact of Post-Training Quantization on Large-scale  Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Roy%2C+S">Somnath Roy</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Large language models (LLMs) are rapidly increasing in size, with the number
of parameters becoming a key factor in the success of many commercial models,
such as ChatGPT, Claude, and Bard. Even the recently released publicly
accessible models for commercial usage, such as Falcon and Llama2, come
equipped with billions of parameters. This significant increase in the number
of parameters makes deployment and operation very costly. The remarkable
progress in the field of quantization for large neural networks in general and
LLMs in particular, has made these models more accessible by enabling them to
be deployed on consumer-grade GPUs. Quantized models generally demonstrate
comparable performance levels to their unquantized base counterparts.
Nonetheless, there exists a notable gap in our comprehensive understanding of
how these quantized models respond to hyperparameters, such as temperature, max
new tokens, and top\_k, particularly during the decoding phase. The present
analysis reveals that nf4 and fp4 are equally proficient 4-bit quantization
techniques, characterized by similar attributes such as inference speed, memory
consumption, and the quality of generated content. Nevertheless, these
quantization methods exhibit distinct behaviors at varying temperature
settings, both in the context of smaller and larger models. It is noteworthy
that, in general, 4-bit quantized models of varying sizes exhibit heightened
sensitivity to lower temperature settings, unlike their unquantized
counterparts. Additionally, int8 quantization is associated with significantly
slower inference speeds, whereas unquantized fp16 models consistently yield the
fastest inference speeds across models of all sizes.
</p>
</div>
</dd>
<dt><a name="item300">[300]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.05211" title="Abstract">arXiv:2309.05211</a> [<a href="/pdf/2309.05211" title="Download PDF">pdf</a>, <a href="/format/2309.05211" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Two-Sided Quaternion Higher-Order Singular Value Decomposition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Ya%2C+H">Hanxin Ya</a>, 
<a href="/search/math?searchtype=author&query=Wang%2C+Y">Ying Wang</a>, 
<a href="/search/math?searchtype=author&query=Yang%2C+Y">Yuning Yang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Optimization and Control (math.OC)

</div>
<p class="mathjax">Higher-order singular value decomposition (HOSVD) is one of the most
celebrated tensor decompositions that generalizes matrix SVD to higher-order
tensors. It was recently extended to the quaternion domain \cite{miao2023quat}
(we refer to it as L-QHOSVD in this work). However, due to the
non-commutativity of quaternion multiplications, L-QHOSVD is not consistent
with matrix SVD when the order of the quaternion tensor reduces to $2$;
moreover, theoretical guaranteed truncated L-QHOSVD was not investigated. To
derive a more natural higher-order generalization of the quaternion matrix SVD,
we first utilize the feature that left and right multiplications of quaternions
are inconsistent to define left and right quaternion tensor unfoldings and left
and right mode-$k$ products. Then, by using these basic tools, we propose a
two-sided quaternion higher-order singular value decomposition (TS-QHOSVD).
TS-QHOSVD has the following two main features: 1) it computes two factor
matrices at a time from SVDs of left and right unfoldings, inheriting certain
parallel properties of the original HOSVD; 2) it is consistent with matrix SVD
when the order of the tensor is $2$. In addition, we study truncated TS-QHOSVD
and establish its error bound measured by the tail energy; correspondingly, we
also present truncated L-QHOSVD and its error bound. Deriving the error bounds
is nontrivial, as the proofs are more complicated than their real counterparts,
again due to the non-commutativity of quaternion multiplications. Preliminary
numerical examples on color video data show the efficacy of the proposed
TS-QHOSVD.
</p>
</div>
</dd>
<dt><a name="item301">[301]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.05213" title="Abstract">arXiv:2309.05213</a> [<a href="/pdf/2309.05213" title="Download PDF">pdf</a>, <a href="/format/2309.05213" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Federated Learning Under Resource Constraints via Layer-wise  Training and Depth Dropout
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Guo%2C+P">Pengfei Guo</a>, 
<a href="/search/cs?searchtype=author&query=Morningstar%2C+W+R">Warren Richard Morningstar</a>, 
<a href="/search/cs?searchtype=author&query=Vemulapalli%2C+R">Raviteja Vemulapalli</a>, 
<a href="/search/cs?searchtype=author&query=Singhal%2C+K">Karan Singhal</a>, 
<a href="/search/cs?searchtype=author&query=Patel%2C+V+M">Vishal M. Patel</a>, 
<a href="/search/cs?searchtype=author&query=Mansfield%2C+P+A">Philip Andrew Mansfield</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Distributed, Parallel, and Cluster Computing (cs.DC)

</div>
<p class="mathjax">Large machine learning models trained on diverse data have recently seen
unprecedented success. Federated learning enables training on private data that
may otherwise be inaccessible, such as domain-specific datasets decentralized
across many clients. However, federated learning can be difficult to scale to
large models when clients have limited resources. This challenge often results
in a trade-off between model size and access to diverse data. To mitigate this
issue and facilitate training of large models on edge devices, we introduce a
simple yet effective strategy, Federated Layer-wise Learning, to simultaneously
reduce per-client memory, computation, and communication costs. Clients train
just a single layer each round, reducing resource costs considerably with
minimal performance degradation. We also introduce Federated Depth Dropout, a
complementary technique that randomly drops frozen layers during training, to
further reduce resource usage. Coupling these two techniques enables us to
effectively train significantly larger models on edge devices. Specifically, we
reduce training memory usage by 5x or more in federated self-supervised
representation learning and demonstrate that performance in downstream tasks is
comparable to conventional federated self-supervised learning.
</p>
</div>
</dd>
<dt><a name="item302">[302]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.05214" title="Abstract">arXiv:2309.05214</a> [<a href="/pdf/2309.05214" title="Download PDF">pdf</a>, <a href="/format/2309.05214" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Angle Range and Identity Similarity Enhanced Gaze and Head Redirection  based on Synthetic data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Qin%2C+J">Jiawei Qin</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xueting Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">In this paper, we propose a method for improving the angular accuracy and
photo-reality of gaze and head redirection in full-face images. The problem
with current models is that they cannot handle redirection at large angles, and
this limitation mainly comes from the lack of training data. To resolve this
problem, we create data augmentation by monocular 3D face reconstruction to
extend the head pose and gaze range of the real data, which allows the model to
handle a wider redirection range. In addition to the main focus on data
augmentation, we also propose a framework with better image quality and
identity preservation of unseen subjects even training with synthetic data.
Experiments show that our method significantly improves redirection performance
in terms of redirection angular accuracy while maintaining high image quality,
especially when redirecting to large angles.
</p>
</div>
</dd>
<dt><a name="item303">[303]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.05217" title="Abstract">arXiv:2309.05217</a> [<a href="/pdf/2309.05217" title="Download PDF">pdf</a>, <a href="/format/2309.05217" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Quantifying and Attributing the Hallucination of Large Language Models  via Association Analysis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Du%2C+L">Li Du</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yequan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Xing%2C+X">Xingrun Xing</a>, 
<a href="/search/cs?searchtype=author&query=Ya%2C+Y">Yiqun Ya</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xiang Li</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+X">Xin Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Fang%2C+X">Xuezhi Fang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computation and Language (cs.CL)

</div>
<p class="mathjax">Although demonstrating superb performance on various NLP tasks, large
language models (LLMs) still suffer from the hallucination problem, which
threatens the reliability of LLMs. To measure the level of hallucination of
LLMs, previous works first categorize the hallucination according to the
phenomenon similarity, then quantify the proportion that model outputs contain
hallucinatory contents. However, such hallucination rates could easily be
distorted by confounders. Moreover, such hallucination rates could not reflect
the reasons for the hallucination, as similar hallucinatory phenomena may
originate from different sources. To address these issues, we propose to
combine the hallucination level quantification and hallucination reason
investigation through an association analysis, which builds the relationship
between the hallucination rate of LLMs with a set of risk factors. In this way,
we are able to observe the hallucination level under each value of each risk
factor, examining the contribution and statistical significance of each risk
factor, meanwhile excluding the confounding effect of other factors.
Additionally, by recognizing the risk factors according to a taxonomy of model
capability, we reveal a set of potential deficiencies in commonsense
memorization, relational reasoning, and instruction following, which may
further provide guidance for the pretraining and supervised fine-tuning process
of LLMs to mitigate the hallucination.
</p>
</div>
</dd>
<dt><a name="item304">[304]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.05218" title="Abstract">arXiv:2309.05218</a> [<a href="/pdf/2309.05218" title="Download PDF">pdf</a>, <a href="/format/2309.05218" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Constrained Correlated Equilibria
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Boufous%2C+O">Omar Boufous</a>, 
<a href="/search/cs?searchtype=author&query=El-Azouzi%2C+R">Rachid El-Azouzi</a>, 
<a href="/search/cs?searchtype=author&query=Touati%2C+M">Mika&#xeb;l Touati</a>, 
<a href="/search/cs?searchtype=author&query=Altman%2C+E">Eitan Altman</a>, 
<a href="/search/cs?searchtype=author&query=Bouhtou%2C+M">Mustapha Bouhtou</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>

</div>
<p class="mathjax">This paper introduces constrained correlated equilibrium, a solution concept
combining correlation and coupled constraints in finite non-cooperative
games.In the general case of an arbitrary correlation device and coupled
constraints in the extended game, we study the conditions for equilibrium. In
the particular case of constraints induced by a feasible set of probability
distributions over action profiles, we first show that canonical correlation
devices are sufficient to characterize the set of constrained correlated
equilibrium distributions and provide conditions of their existence. Second, it
is shown that constrained correlated equilibria of the mixed extension of the
game do not lead to additional equilibrium distributions. Third, we show that
the constrained correlated equilibrium distributions may not belong to the
polytope of correlated equilibrium distributions. Finally, we illustrate these
results through numerical examples.
</p>
</div>
</dd>
<dt><a name="item305">[305]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.05221" title="Abstract">arXiv:2309.05221</a> [<a href="/pdf/2309.05221" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exploring the Law of Numbers: Evidence from China&#x27;s Real Estate
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+F">Fuqian Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zhenhua Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> DSS
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">The renowned proverb, Numbers do not lie, underscores the reliability and
insight that lie beneath numbers, a concept of undisputed importance,
especially in economics and finance etc. Despite the prosperity of Benford's
Law in the first digit analysis, its scope fails to remain comprehensiveness
when it comes to deciphering the laws of number. This paper delves into number
laws by taking the financial statements of China real estate as a
representative, quantitatively study not only the first digit, but also depict
the other two dimensions of numbers: frequency and length. The research
outcomes transcend mere reservations about data manipulation and open the door
to discussions surrounding number diversity and the delineation of the usage
insights. This study wields both economic significance and the capacity to
foster a deeper comprehension of numerical phenomena.
</p>
</div>
</dd>
<dt><a name="item306">[306]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.05224" title="Abstract">arXiv:2309.05224</a> [<a href="/pdf/2309.05224" title="Download PDF">pdf</a>, <a href="/format/2309.05224" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SparseSwin: Swin Transformer with Sparse Transformer Block
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pinasthika%2C+K">Krisna Pinasthika</a>, 
<a href="/search/cs?searchtype=author&query=Laksono%2C+B+S+P">Blessius Sheldo Putra Laksono</a>, 
<a href="/search/cs?searchtype=author&query=Irsal%2C+R+B+P">Riyandi Banovbi Putera Irsal</a>, 
<a href="/search/cs?searchtype=author&query=Shabiyya%2C+S+H">Syifa Hukma Shabiyya</a>, 
<a href="/search/cs?searchtype=author&query=Yudistira%2C+N">Novanto Yudistira</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Advancements in computer vision research have put transformer architecture as
the state of the art in computer vision tasks. One of the known drawbacks of
the transformer architecture is the high number of parameters, this can lead to
a more complex and inefficient algorithm. This paper aims to reduce the number
of parameters and in turn, made the transformer more efficient. We present
Sparse Transformer (SparTa) Block, a modified transformer block with an
addition of a sparse token converter that reduces the number of tokens used. We
use the SparTa Block inside the Swin T architecture (SparseSwin) to leverage
Swin capability to downsample its input and reduce the number of initial tokens
to be calculated. The proposed SparseSwin model outperforms other state of the
art models in image classification with an accuracy of 86.96%, 97.43%, and
85.35% on the ImageNet100, CIFAR10, and CIFAR100 datasets respectively. Despite
its fewer parameters, the result highlights the potential of a transformer
architecture using a sparse token converter with a limited number of tokens to
optimize the use of the transformer and improve its performance.
</p>
</div>
</dd>
<dt><a name="item307">[307]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.05226" title="Abstract">arXiv:2309.05226</a> [<a href="/pdf/2309.05226" title="Download PDF">pdf</a>, <a href="/format/2309.05226" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Joint Beamforming and Compression Design for Per-Antenna Power  Constrained Cooperative Cellular Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fan%2C+X">Xilai Fan</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Ya-Feng Liu</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+B">Bo Jiang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages, 2 figures, submitted for possible publication
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP); Optimization and Control (math.OC)

</div>
<p class="mathjax">In the cooperative cellular network, relay-like base stations are connected
to the central processor (CP) via rate-limited fronthaul links and the joint
processing is performed at the CP, which thus can effectively mitigate the
multiuser interference. In this paper, we consider the joint beamforming and
compression problem with per-antenna power constraints in the cooperative
cellular network. We first establish the equivalence between the considered
problem and its semidefinite relaxation (SDR). Then we further derive the
partial Lagrangian dual of the SDR problem and show that the objective function
of the obtained dual problem is differentiable. Based on the differentiability,
we propose two efficient projected gradient ascent algorithms for solving the
dual problem, which are projected exact gradient ascent (PEGA) and projected
inexact gradient ascent (PIGA). While PEGA is guaranteed to find the global
solution of the dual problem (and hence the global solution of the original
problem), PIGA is more computationally efficient due to the lower complexity in
inexactly computing the gradient. Global optimality and high efficiency of the
proposed algorithms are demonstrated via numerical experiments.
</p>
</div>
</dd>
<dt><a name="item308">[308]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.05227" title="Abstract">arXiv:2309.05227</a> [<a href="/pdf/2309.05227" title="Download PDF">pdf</a>, <a href="/format/2309.05227" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Detecting Natural Language Biases with Prompt-based Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Aowal%2C+M+A">Md Abdul Aowal</a>, 
<a href="/search/cs?searchtype=author&query=Islam%2C+M+T">Maliha T Islam</a>, 
<a href="/search/cs?searchtype=author&query=Mammen%2C+P+M">Priyanka Mary Mammen</a>, 
<a href="/search/cs?searchtype=author&query=Shetty%2C+S">Sandesh Shetty</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">In this project, we want to explore the newly emerging field of prompt
engineering and apply it to the downstream task of detecting LM biases. More
concretely, we explore how to design prompts that can indicate 4 different
types of biases: (1) gender, (2) race, (3) sexual orientation, and (4)
religion-based. Within our project, we experiment with different manually
crafted prompts that can draw out the subtle biases that may be present in the
language model. We apply these prompts to multiple variations of popular and
well-recognized models: BERT, RoBERTa, and T5 to evaluate their biases. We
provide a comparative analysis of these models and assess them using a two-fold
method: use human judgment to decide whether model predictions are biased and
utilize model-level judgment (through further prompts) to understand if a model
can self-diagnose the biases of its own prediction.
</p>
</div>
</dd>
<dt><a name="item309">[309]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.05230" title="Abstract">arXiv:2309.05230</a> [<a href="/pdf/2309.05230" title="Download PDF">pdf</a>, <a href="/format/2309.05230" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Fence Complexity of Persistent Sets
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Coccimiglio%2C+G">Gaetano Coccimiglio</a>, 
<a href="/search/cs?searchtype=author&query=Brown%2C+T">Trevor Brown</a>, 
<a href="/search/cs?searchtype=author&query=Ravi%2C+S">Srivatsan Ravi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>

</div>
<p class="mathjax">We study the psync complexity of concurrent sets in the non-volatile shared
memory model. Flush instructions are used in non-volatile memory to force
shared state to be written back to non-volatile memory and must typically be
accompanied by the use of expensive fence instructions to enforce ordering
among such flushes. Collectively we refer to a flush and a fence as a psync.
The safety property of strict linearizability forces crashed operations to take
effect before the crash or not take effect at all; the weaker property of
durable linearizability enforces this requirement only for operations that have
completed prior to the crash event. We consider lock-free implementations of
list-based sets and prove two lower bounds. We prove that for any durable
linearizable lock-free set there must exist an execution where some process
must perform at least one redundant psync as part of an update operation. We
introduce an extension to strict linearizability specialized for persistent
sets that we call strict limited effect (SLE) linearizability. SLE
linearizability explicitly ensures that operations do not take effect after a
crash which better reflects the original intentions of strict linearizability.
We show that it is impossible to implement SLE linearizable lock-free sets in
which read-only (or search) operations do not flush or fence. We undertake an
empirical study of persistent sets that examines various algorithmic design
techniques and the impact of flush instructions in practice. We present
concurrent set algorithms that provide matching upper bounds and rigorously
evaluate them against existing persistent sets to expose the impact of
algorithmic design and safety properties on psync complexity in practice as
well as the cost of recovering the data structure following a system crash.
</p>
</div>
</dd>
<dt><a name="item310">[310]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.05235" title="Abstract">arXiv:2309.05235</a> [<a href="/pdf/2309.05235" title="Download PDF">pdf</a>, <a href="/format/2309.05235" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> P2LSG: Powers-of-2 Low-Discrepancy Sequence Generator for Stochastic  Computing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Moghadam%2C+M+S">Mehran Shoushtari Moghadam</a>, 
<a href="/search/cs?searchtype=author&query=Aygun%2C+S">Sercan Aygun</a>, 
<a href="/search/cs?searchtype=author&query=Alam%2C+M+R">Mohsen Riahi Alam</a>, 
<a href="/search/cs?searchtype=author&query=Najafi%2C+M+H">M. Hassan Najafi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, 7 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Emerging Technologies (cs.ET)</span>; Hardware Architecture (cs.AR)

</div>
<p class="mathjax">Stochastic Computing (SC) is an unconventional computing paradigm processing
data in the form of random bit-streams. The accuracy and energy efficiency of
SC systems highly depend on the stochastic number generator (SNG) unit that
converts the data from conventional binary to stochastic bit-streams. Recent
work has shown significant improvement in the efficiency of SC systems by
employing low-discrepancy (LD) sequences such as Sobol and Halton sequences in
the SNG unit. Still, the usage of many well-known random sequences for SC
remains unexplored. This work studies some new random sequences for potential
application in SC. Our design space exploration proposes a promising random
number generator for accurate and energy-efficient SC. We propose P2LSG, a
low-cost and energy-efficient Low-discrepancy Sequence Generator derived from
Powers-of-2 VDC (Van der Corput) sequences. We evaluate the performance of our
novel bit-stream generator for two SC image and video processing case studies:
image scaling and scene merging. For the scene merging task, we propose a novel
SC design for the first time. Our experimental results show higher accuracy and
lower hardware cost and energy consumption compared to the state-of-the-art.
</p>
</div>
</dd>
<dt><a name="item311">[311]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.05238" title="Abstract">arXiv:2309.05238</a> [<a href="/pdf/2309.05238" title="Download PDF">pdf</a>, <a href="/format/2309.05238" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Generating Natural Language Queries for More Effective Systematic Review  Screening Prioritisation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Shuai Wang</a>, 
<a href="/search/cs?searchtype=author&query=Scells%2C+H">Harrisen Scells</a>, 
<a href="/search/cs?searchtype=author&query=Potthast%2C+M">Martin Potthast</a>, 
<a href="/search/cs?searchtype=author&query=Koopman%2C+B">Bevan Koopman</a>, 
<a href="/search/cs?searchtype=author&query=Zuccon%2C+G">Guido Zuccon</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Preprints for Accepted paper in SIGIR-AP-2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Screening prioritisation in medical systematic reviews aims to rank the set
of documents retrieved by complex Boolean queries. The goal is to prioritise
the most important documents so that subsequent review steps can be carried out
more efficiently and effectively. The current state of the art uses the final
title of the review to rank documents using BERT-based neural neural rankers.
However, the final title is only formulated at the end of the review process,
which makes this approach impractical as it relies on ex post facto
information. At the time of screening, only a rough working title is available,
with which the BERT-based ranker achieves is significantly worse than the final
title. In this paper, we explore alternative sources of queries for screening
prioritisation, such as the Boolean query used to retrieve the set of documents
to be screened, and queries generated by instruction-based generative large
language models such as ChatGPT and Alpaca. Our best approach is not only
practical based on the information available at screening time, but is similar
in effectiveness with the final title.
</p>
</div>
</dd>
<dt><a name="item312">[312]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.05239" title="Abstract">arXiv:2309.05239</a> [<a href="/pdf/2309.05239" title="Download PDF">pdf</a>, <a href="/format/2309.05239" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> HAT: Hybrid Attention Transformer for Image Restoration
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+X">Xiangyu Chen</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xintao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+W">Wenlong Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Kong%2C+X">Xiangtao Kong</a>, 
<a href="/search/cs?searchtype=author&query=Qiao%2C+Y">Yu Qiao</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+J">Jiantao Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+C">Chao Dong</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Extended version of HAT
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Transformer-based methods have shown impressive performance in image
restoration tasks, such as image super-resolution and denoising. However, we
find that these networks can only utilize a limited spatial range of input
information through attribution analysis. This implies that the potential of
Transformer is still not fully exploited in existing networks. In order to
activate more input pixels for better restoration, we propose a new Hybrid
Attention Transformer (HAT). It combines both channel attention and
window-based self-attention schemes, thus making use of their complementary
advantages. Moreover, to better aggregate the cross-window information, we
introduce an overlapping cross-attention module to enhance the interaction
between neighboring window features. In the training stage, we additionally
adopt a same-task pre-training strategy to further exploit the potential of the
model for further improvement. Extensive experiments have demonstrated the
effectiveness of the proposed modules. We further scale up the model to show
that the performance of the SR task can be greatly improved. Besides, we extend
HAT to more image restoration applications, including real-world image
super-resolution, Gaussian image denoising and image compression artifacts
reduction. Experiments on benchmark and real-world datasets demonstrate that
our HAT achieves state-of-the-art performance both quantitatively and
qualitatively. Codes and models are publicly available at
https://github.com/XPixelGroup/HAT.
</p>
</div>
</dd>
<dt><a name="item313">[313]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.05242" title="Abstract">arXiv:2309.05242</a> [<a href="/pdf/2309.05242" title="Download PDF">pdf</a>, <a href="/format/2309.05242" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Flexible Architecture for Broadcast Broadband Convergence in Beyond 5G
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yadav%2C+R">Rashmi Yadav</a>, 
<a href="/search/cs?searchtype=author&query=Kamran%2C+R">Rashmi Kamran</a>, 
<a href="/search/cs?searchtype=author&query=Jha%2C+P">Pranav Jha</a>, 
<a href="/search/cs?searchtype=author&query=Karandikar%2C+A">Abhay Karandikar</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages, conference paper
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>

</div>
<p class="mathjax">There has been an exponential increase in the usage of multimedia services in
mobile networks in recent years. To address this accelerating data demand,
mobile networks are experiencing a subtle transformation in their architecture.
One of the changes in this direction is the support of Multicast/Broadcast
Service (MBS) in the Third Generation Partnership Project (3GPP) Fifth
Generation (5G) network. The MBS has been introduced to enhance resource
utilization and user experience in 3GPP 5G networks. However, there are certain
limitations in the 3GPP 5G MBS architecture, such as the selection of the
delivery method (unicast or broadcast) by the core network (may result in
sub-optimal radio resource utilization) and no provision for converging
non-3GPP broadcast technologies (like digital terrestrial television) with
cellular (3GPP 5G) broadband. In this context, we propose a new architecture
for broadcast broadband convergence in mobile networks. A novelty of the
architecture is that it treats signalling exchange with User Equipment (UE) as
data (service) which results in improved scalability of mobile networks. The
proposed architecture can also be extended for the convergence of cellular
broadband and non-3GPP broadcast networks with ease. The architecture supports
enhanced flexibility in choosing a delivery method (3GPP 5G unicast, 3GPP 5G
broadcast, or non-3GPP broadcast) for user data. We evaluate the performance of
the proposed architecture using process algebra-based simulations,
demonstrating a significant reduction in the number of signalling messages
exchanged between the UE and the network for MBS session establishment as
compared to the 3GPP 5G network.
</p>
</div>
</dd>
<dt><a name="item314">[314]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.05249" title="Abstract">arXiv:2309.05249</a> [<a href="/pdf/2309.05249" title="Download PDF">pdf</a>, <a href="/format/2309.05249" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Evaluating Visual Odometry Methods for Autonomous Driving in Rain
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tan%2C+Y+X">Yu Xiang Tan</a>, 
<a href="/search/cs?searchtype=author&query=Prasetyo%2C+M+B">Marcel Bartholomeus Prasetyo</a>, 
<a href="/search/cs?searchtype=author&query=Daffa%2C+M+A">Mohammad Alif Daffa</a>, 
<a href="/search/cs?searchtype=author&query=Nitin%2C+D+S">Deshpande Sunny Nitin</a>, 
<a href="/search/cs?searchtype=author&query=Meghjani%2C+M">Malika Meghjani</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 4 figures, Accepted at IEEE International Conference on Automation Science and Engineering (CASE) 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">The increasing demand for autonomous vehicles has created a need for robust
navigation systems that can also operate effectively in adverse weather
conditions. Visual odometry is a technique used in these navigation systems,
enabling the estimation of vehicle position and motion using input from onboard
cameras. However, visual odometry accuracy can be significantly impacted in
challenging weather conditions, such as heavy rain, snow, or fog. In this
paper, we evaluate a range of visual odometry methods, including our DROIDSLAM
based heuristic approach. Specifically, these algorithms are tested on both
clear and rainy weather urban driving data to evaluate their robustness. We
compiled a dataset comprising of a range of rainy weather conditions from
different cities. This includes, the Oxford Robotcar dataset from Oxford, the
4Seasons dataset from Munich and an internal dataset collected in Singapore. We
evaluated different visual odometry algorithms for both monocular and stereo
camera setups using the Absolute Trajectory Error (ATE). Our evaluation
suggests that the Depth and Flow for Visual Odometry (DF-VO) algorithm with
monocular setup worked well for short range distances (&lt; 500m) and our proposed
DROID-SLAM based heuristic approach for the stereo setup performed relatively
well for long-term localization. Both algorithms performed consistently well
across all rain conditions.
</p>
</div>
</dd>
<dt><a name="item315">[315]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.05251" title="Abstract">arXiv:2309.05251</a> [<a href="/pdf/2309.05251" title="Download PDF">pdf</a>, <a href="/format/2309.05251" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multi3DRefer: Grounding Text Description to Multiple 3D Objects
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yiming Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Gong%2C+Z">ZeMing Gong</a>, 
<a href="/search/cs?searchtype=author&query=Chang%2C+A+X">Angel X. Chang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ICCV 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">We introduce the task of localizing a flexible number of objects in
real-world 3D scenes using natural language descriptions. Existing 3D visual
grounding tasks focus on localizing a unique object given a text description.
However, such a strict setting is unnatural as localizing potentially multiple
objects is a common need in real-world scenarios and robotic tasks (e.g.,
visual navigation and object rearrangement). To address this setting we propose
Multi3DRefer, generalizing the ScanRefer dataset and task. Our dataset contains
61926 descriptions of 11609 objects, where zero, single or multiple target
objects are referenced by each description. We also introduce a new evaluation
metric and benchmark methods from prior work to enable further investigation of
multi-modal 3D scene understanding. Furthermore, we develop a better baseline
leveraging 2D features from CLIP by rendering object proposals online with
contrastive learning, which outperforms the state of the art on the ScanRefer
benchmark.
</p>
</div>
</dd>
<dt><a name="item316">[316]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.05254" title="Abstract">arXiv:2309.05254</a> [<a href="/pdf/2309.05254" title="Download PDF">pdf</a>, <a href="/format/2309.05254" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Better Data Exploitation In Self-Supervised Monocular Depth  Estimation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jinfeng Liu</a>, 
<a href="/search/cs?searchtype=author&query=Kong%2C+L">Lingtong Kong</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+J">Jie Yang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+W">Wei Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 6 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Depth estimation plays an important role in the robotic perception system.
Self-supervised monocular paradigm has gained significant attention since it
can free training from the reliance on depth annotations. Despite recent
advancements, existing self-supervised methods still underutilize the available
training data, limiting their generalization ability. In this paper, we take
two data augmentation techniques, namely Resizing-Cropping and
Splitting-Permuting, to fully exploit the potential of training datasets.
Specifically, the original image and the generated two augmented images are fed
into the training pipeline simultaneously and we leverage them to conduct
self-distillation. Additionally, we introduce the detail-enhanced DepthNet with
an extra full-scale branch in the encoder and a grid decoder to enhance the
restoration of fine details in depth maps. Experimental results demonstrate our
method can achieve state-of-the-art performance on the KITTI benchmark, with
both raw ground truth and improved ground truth. Moreover, our models also show
superior generalization performance when transferring to Make3D and NYUv2
datasets. Our codes are available at https://github.com/Sauf4896/BDEdepth.
</p>
</div>
</dd>
<dt><a name="item317">[317]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.05255" title="Abstract">arXiv:2309.05255</a> [<a href="/pdf/2309.05255" title="Download PDF">pdf</a>, <a href="/ps/2309.05255" title="Download PostScript">ps</a>, <a href="/format/2309.05255" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Locking-Free Weak Galerkin Finite Element Method for Linear Elasticity  Problems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Huo%2C+F">Fuchang Huo</a>, 
<a href="/search/math?searchtype=author&query=Wang%2C+R">Ruishu Wang</a>, 
<a href="/search/math?searchtype=author&query=Wang%2C+Y">Yanqiu Wang</a>, 
<a href="/search/math?searchtype=author&query=Zhang%2C+R">Ran Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">In this paper, we introduce and analyze a lowest-order locking-free weak
Galerkin (WG) finite element scheme for the grad-div formulation of linear
elasticity problems. The scheme uses linear functions in the interior of mesh
elements and constants on edges (2D) or faces (3D), respectively, to
approximate the displacement. An $H(div)$-conforming displacement
reconstruction operator is employed to modify test functions in the right-hand
side of the discrete form, in order to eliminate the dependence of the
$Lam\acute{e}$ parameter $\lambda$ in error estimates, i.e., making the scheme
locking-free. The method works without requiring $\lambda \|\nabla\cdot
\mathbf{u}\|_1$ to be bounded. We prove optimal error estimates, independent of
$\lambda$, in both the $H^1$-norm and the $L^2$-norm. Numerical experiments
validate that the method is effective and locking-free.
</p>
</div>
</dd>
<dt><a name="item318">[318]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.05256" title="Abstract">arXiv:2309.05256</a> [<a href="/pdf/2309.05256" title="Download PDF">pdf</a>, <a href="/format/2309.05256" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Examining the Effect of Pre-training on Time Series Classification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pu%2C+J">Jiashu Pu</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+S">Shiwei Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+L">Ling Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Chang%2C+Y">Yongzhu Chang</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+R">Runze Wu</a>, 
<a href="/search/cs?searchtype=author&query=Lv%2C+T">Tangjie Lv</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+R">Rongsheng Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Although the pre-training followed by fine-tuning paradigm is used
extensively in many fields, there is still some controversy surrounding the
impact of pre-training on the fine-tuning process. Currently, experimental
findings based on text and image data lack consensus. To delve deeper into the
unsupervised pre-training followed by fine-tuning paradigm, we have extended
previous research to a new modality: time series. In this study, we conducted a
thorough examination of 150 classification datasets derived from the Univariate
Time Series (UTS) and Multivariate Time Series (MTS) benchmarks. Our analysis
reveals several key conclusions. (i) Pre-training can only help improve the
optimization process for models that fit the data poorly, rather than those
that fit the data well. (ii) Pre-training does not exhibit the effect of
regularization when given sufficient training time. (iii) Pre-training can only
speed up convergence if the model has sufficient ability to fit the data. (iv)
Adding more pre-training data does not improve generalization, but it can
strengthen the advantage of pre-training on the original data volume, such as
faster convergence. (v) While both the pre-training task and the model
structure determine the effectiveness of the paradigm on a given dataset, the
model structure plays a more significant role.
</p>
</div>
</dd>
<dt><a name="item319">[319]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.05257" title="Abstract">arXiv:2309.05257</a> [<a href="/pdf/2309.05257" title="Download PDF">pdf</a>, <a href="/format/2309.05257" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FusionFormer: A Multi-sensory Fusion in Bird&#x27;s-Eye-View and Temporal  Consistent Transformer for 3D Objection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hu%2C+C">Chunyong Hu</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+H">Hang Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+K">Kun Li</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+J">Jianyun Xu</a>, 
<a href="/search/cs?searchtype=author&query=Mao%2C+W">Weibo Mao</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+M">Maochun Luo</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+L">Lingxuan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+M">Mingxia Chen</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+K">Kaixuan Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Y">Yiru Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Hao%2C+P">Peihan Hao</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+M">Minzhe Liu</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+K">Kaicheng Yu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Multi-sensor modal fusion has demonstrated strong advantages in 3D object
detection tasks. However, existing methods that fuse multi-modal features
through a simple channel concatenation require transformation features into
bird's eye view space and may lose the information on Z-axis thus leads to
inferior performance. To this end, we propose FusionFormer, an end-to-end
multi-modal fusion framework that leverages transformers to fuse multi-modal
features and obtain fused BEV features. And based on the flexible adaptability
of FusionFormer to the input modality representation, we propose a depth
prediction branch that can be added to the framework to improve detection
performance in camera-based detection tasks. In addition, we propose a
plug-and-play temporal fusion module based on transformers that can fuse
historical frame BEV features for more stable and reliable detection results.
We evaluate our method on the nuScenes dataset and achieve 72.6% mAP and 75.1%
NDS for 3D object detection tasks, outperforming state-of-the-art methods.
</p>
</div>
</dd>
<dt><a name="item320">[320]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.05259" title="Abstract">arXiv:2309.05259</a> [<a href="/pdf/2309.05259" title="Download PDF">pdf</a>, <a href="/format/2309.05259" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A physics-informed and attention-based graph learning approach for  regional electric vehicle charging demand prediction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Qu%2C+H">Haohao Qu</a>, 
<a href="/search/cs?searchtype=author&query=Kuang%2C+H">Haoxuan Kuang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jun Li</a>, 
<a href="/search/cs?searchtype=author&query=You%2C+L">Linlin You</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Preprint. This work has been submitted to the IEEE Transactions on ITS for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Along with the proliferation of electric vehicles (EVs), optimizing the use
of EV charging space can significantly alleviate the growing load on
intelligent transportation systems. As the foundation to achieve such an
optimization, a spatiotemporal method for EV charging demand prediction in
urban areas is required. Although several solutions have been proposed by using
data-driven deep learning methods, it can be found that these
performance-oriented methods may suffer from misinterpretations to correctly
handle the reverse relationship between charging demands and prices. To tackle
the emerging challenges of training an accurate and interpretable prediction
model, this paper proposes a novel approach that enables the integration of
graph and temporal attention mechanisms for feature extraction and the usage of
physic-informed meta-learning in the model pre-training step for knowledge
transfer. Evaluation results on a dataset of 18,013 EV charging piles in
Shenzhen, China, show that the proposed approach, named PAG, can achieve
state-of-the-art forecasting performance and the ability in understanding the
adaptive changes in charging demands caused by price fluctuations.
</p>
</div>
</dd>
<dt><a name="item321">[321]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.05261" title="Abstract">arXiv:2309.05261</a> [<a href="/pdf/2309.05261" title="Download PDF">pdf</a>, <a href="/format/2309.05261" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Gall Bladder Cancer Detection from US Images with Only Image Level  Labels
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Basu%2C+S">Soumen Basu</a>, 
<a href="/search/cs?searchtype=author&query=Papanai%2C+A">Ashish Papanai</a>, 
<a href="/search/cs?searchtype=author&query=Gupta%2C+M">Mayank Gupta</a>, 
<a href="/search/cs?searchtype=author&query=Gupta%2C+P">Pankaj Gupta</a>, 
<a href="/search/cs?searchtype=author&query=Arora%2C+C">Chetan Arora</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at MICCAI 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Automated detection of Gallbladder Cancer (GBC) from Ultrasound (US) images
is an important problem, which has drawn increased interest from researchers.
However, most of these works use difficult-to-acquire information such as
bounding box annotations or additional US videos. In this paper, we focus on
GBC detection using only image-level labels. Such annotation is usually
available based on the diagnostic report of a patient, and do not require
additional annotation effort from the physicians. However, our analysis reveals
that it is difficult to train a standard image classification model for GBC
detection. This is due to the low inter-class variance (a malignant region
usually occupies only a small portion of a US image), high intra-class variance
(due to the US sensor capturing a 2D slice of a 3D object leading to large
viewpoint variations), and low training data availability. We posit that even
when we have only the image level label, still formulating the problem as
object detection (with bounding box output) helps a deep neural network (DNN)
model focus on the relevant region of interest. Since no bounding box
annotations is available for training, we pose the problem as weakly supervised
object detection (WSOD). Motivated by the recent success of transformer models
in object detection, we train one such model, DETR, using
multi-instance-learning (MIL) with self-supervised instance selection to suit
the WSOD task. Our proposed method demonstrates an improvement of AP and
detection sensitivity over the SOTA transformer-based and CNN-based WSOD
methods. Project page is at https://gbc-iitd.github.io/wsod-gbc
</p>
</div>
</dd>
<dt><a name="item322">[322]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.05262" title="Abstract">arXiv:2309.05262</a> [<a href="/pdf/2309.05262" title="Download PDF">pdf</a>, <a href="/format/2309.05262" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A horizon line annotation tool for streamlining autonomous sea  navigation experiments
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zardoua%2C+Y">Yassir Zardoua</a>, 
<a href="/search/cs?searchtype=author&query=Wahabi%2C+A+E">Abdelhamid El Wahabi</a>, 
<a href="/search/cs?searchtype=author&query=Boulaala%2C+M">Mohammed Boulaala</a>, 
<a href="/search/cs?searchtype=author&query=Astito%2C+A">Abdelali Astito</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Horizon line (or sea line) detection (HLD) is a critical component in
multiple marine autonomous navigation tasks, such as identifying the navigation
area (i.e., the sea), obstacle detection and geo-localization, and digital
video stabilization. A recent survey highlighted several weaknesses of such
detectors, particularly on sea conditions lacking from the most extensive
dataset currently used by HLD researchers. Experimental validation of more
robust HLDs involves collecting an extensive set of these lacking sea
conditions and annotating each collected image with the correct position and
orientation of the horizon line. The annotation task is daunting without a
proper tool. Therefore, we present the first public annotation software with
tailored features to make the sea line annotation process fast and easy. The
software is available at:
https://drive.google.com/drive/folders/1c0ZmvYDckuQCPIWfh_70P7E1A_DWlIvF?usp=sharing
</p>
</div>
</dd>
<dt><a name="item323">[323]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.05263" title="Abstract">arXiv:2309.05263</a> [<a href="/pdf/2309.05263" title="Download PDF">pdf</a>, <a href="/format/2309.05263" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Brain-inspired Evolutionary Architectures for Spiking Neural Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pan%2C+W">Wenxuan Pan</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+F">Feifei Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Z">Zhuoya Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Zeng%2C+Y">Yi Zeng</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neural and Evolutionary Computing (cs.NE)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">The complex and unique neural network topology of the human brain formed
through natural evolution enables it to perform multiple cognitive functions
simultaneously. Automated evolutionary mechanisms of biological network
structure inspire us to explore efficient architectural optimization for
Spiking Neural Networks (SNNs). Instead of manually designed fixed
architectures or hierarchical Network Architecture Search (NAS), this paper
evolves SNNs architecture by incorporating brain-inspired local modular
structure and global cross-module connectivity. Locally, the brain
region-inspired module consists of multiple neural motifs with excitatory and
inhibitory connections; Globally, we evolve free connections among modules,
including long-term cross-module feedforward and feedback connections. We
further introduce an efficient multi-objective evolutionary algorithm based on
a few-shot performance predictor, endowing SNNs with high performance,
efficiency and low energy consumption. Extensive experiments on static datasets
(CIFAR10, CIFAR100) and neuromorphic datasets (CIFAR10-DVS, DVS128-Gesture)
demonstrate that our proposed model boosts energy efficiency, archiving
consistent and remarkable performance. This work explores brain-inspired neural
architectures suitable for SNNs and also provides preliminary insights into the
evolutionary mechanisms of biological neural networks in the human brain.
</p>
</div>
</dd>
<dt><a name="item324">[324]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.05264" title="Abstract">arXiv:2309.05264</a> [<a href="/pdf/2309.05264" title="Download PDF">pdf</a>, <a href="/format/2309.05264" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Enabling Runtime Verification of Causal Discovery Algorithms with  Automated Conditional Independence Reasoning (Extended Version)
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ma%2C+P">Pingchuan Ma</a>, 
<a href="/search/cs?searchtype=author&query=Ji%2C+Z">Zhenlan Ji</a>, 
<a href="/search/cs?searchtype=author&query=Yao%2C+P">Peisen Yao</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Shuai Wang</a>, 
<a href="/search/cs?searchtype=author&query=Ren%2C+K">Kui Ren</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Causal discovery is a powerful technique for identifying causal relationships
among variables in data. It has been widely used in various applications in
software engineering. Causal discovery extensively involves conditional
independence (CI) tests. Hence, its output quality highly depends on the
performance of CI tests, which can often be unreliable in practice. Moreover,
privacy concerns arise when excessive CI tests are performed.
<br />Despite the distinct nature between unreliable and excessive CI tests, this
paper identifies a unified and principled approach to addressing both of them.
Generally, CI statements, the outputs of CI tests, adhere to Pearl's axioms,
which are a set of well-established integrity constraints on conditional
independence. Hence, we can either detect erroneous CI statements if they
violate Pearl's axioms or prune excessive CI statements if they are logically
entailed by Pearl's axioms. Holistically, both problems boil down to reasoning
about the consistency of CI statements under Pearl's axioms (referred to as CIR
problem).
<br />We propose a runtime verification tool called CICheck, designed to harden
causal discovery algorithms from reliability and privacy perspectives. CICheck
employs a sound and decidable encoding scheme that translates CIR into SMT
problems. To solve the CIR problem efficiently, CICheck introduces a four-stage
decision procedure with three lightweight optimizations that actively prove or
refute consistency, and only resort to costly SMT-based reasoning when
necessary. Based on the decision procedure to CIR, CICheck includes two
variants: ED-CICheck and ED-CICheck, which detect erroneous CI tests (to
enhance reliability) and prune excessive CI tests (to enhance privacy),
respectively. [abridged due to length limit]
</p>
</div>
</dd>
<dt><a name="item325">[325]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.05267" title="Abstract">arXiv:2309.05267</a> [<a href="/pdf/2309.05267" title="Download PDF">pdf</a>, <a href="/format/2309.05267" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Diving into Darkness: A Dual-Modulated Framework for High-Fidelity  Super-Resolution in Ultra-Dark Environments
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gao%2C+J">Jiaxin Gao</a>, 
<a href="/search/cs?searchtype=author&query=Yue%2C+Z">Ziyu Yue</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yaohua Liu</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+S">Sihan Xie</a>, 
<a href="/search/cs?searchtype=author&query=Fan%2C+X">Xin Fan</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+R">Risheng Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Super-resolution tasks oriented to images captured in ultra-dark environments
is a practical yet challenging problem that has received little attention. Due
to uneven illumination and low signal-to-noise ratio in dark environments, a
multitude of problems such as lack of detail and color distortion may be
magnified in the super-resolution process compared to normal-lighting
environments. Consequently, conventional low-light enhancement or
super-resolution methods, whether applied individually or in a cascaded manner
for such problem, often encounter limitations in recovering luminance, color
fidelity, and intricate details. To conquer these issues, this paper proposes a
specialized dual-modulated learning framework that, for the first time,
attempts to deeply dissect the nature of the low-light super-resolution task.
Leveraging natural image color characteristics, we introduce a self-regularized
luminance constraint as a prior for addressing uneven lighting. Expanding on
this, we develop Illuminance-Semantic Dual Modulation (ISDM) components to
enhance feature-level preservation of illumination and color details. Besides,
instead of deploying naive up-sampling strategies, we design the
Resolution-Sensitive Merging Up-sampler (RSMU) module that brings together
different sampling modalities as substrates, effectively mitigating the
presence of artifacts and halos. Comprehensive experiments showcases the
applicability and generalizability of our approach to diverse and challenging
ultra-low-light conditions, outperforming state-of-the-art methods with a
notable improvement (i.e., $\uparrow$5\% in PSNR, and $\uparrow$43\% in LPIPS).
Especially noteworthy is the 19-fold increase in the RMSE score, underscoring
our method's exceptional generalization across different darkness levels. The
code will be available online upon publication of the paper.
</p>
</div>
</dd>
<dt><a name="item326">[326]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.05269" title="Abstract">arXiv:2309.05269</a> [<a href="/pdf/2309.05269" title="Download PDF">pdf</a>, <a href="/format/2309.05269" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> UniKG: A Benchmark and Universal Embedding for Large-Scale Knowledge  Graphs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Qiu%2C+Y">Yide Qiu</a>, 
<a href="/search/cs?searchtype=author&query=Ling%2C+S">Shaoxiang Ling</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+T">Tong Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+B">Bo Huang</a>, 
<a href="/search/cs?searchtype=author&query=Cui%2C+Z">Zhen Cui</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages, 4 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Irregular data in real-world are usually organized as heterogeneous graphs
(HGs) consisting of multiple types of nodes and edges. To explore useful
knowledge from real-world data, both the large-scale encyclopedic HG datasets
and corresponding effective learning methods are crucial, but haven't been well
investigated. In this paper, we construct a large-scale HG benchmark dataset
named UniKG from Wikidata to facilitate knowledge mining and heterogeneous
graph representation learning. Overall, UniKG contains more than 77 million
multi-attribute entities and 2000 diverse association types, which
significantly surpasses the scale of existing HG datasets. To perform effective
learning on the large-scale UniKG, two key measures are taken, including (i)
the semantic alignment strategy for multi-attribute entities, which projects
the feature description of multi-attribute nodes into a common embedding space
to facilitate node aggregation in a large receptive field; (ii) proposing a
novel plug-and-play anisotropy propagation module (APM) to learn effective
multi-hop anisotropy propagation kernels, which extends methods of large-scale
homogeneous graphs to heterogeneous graphs. These two strategies enable
efficient information propagation among a tremendous number of multi-attribute
entities and meantimes adaptively mine multi-attribute association through the
multi-hop aggregation in large-scale HGs. We set up a node classification task
on our UniKG dataset, and evaluate multiple baseline methods which are
constructed by embedding our APM into large-scale homogenous graph learning
methods. Our UniKG dataset and the baseline codes have been released at
https://github.com/Yide-Qiu/UniKG.
</p>
</div>
</dd>
<dt><a name="item327">[327]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.05270" title="Abstract">arXiv:2309.05270</a> [<a href="/pdf/2309.05270" title="Download PDF">pdf</a>, <a href="/format/2309.05270" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CONFLATOR: Incorporating Switching Point based Rotatory Positional  Encodings for Code-Mixed Language Modeling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ali%2C+M">Mohsin Ali</a>, 
<a href="/search/cs?searchtype=author&query=Teja%2C+K+S">Kandukuri Sai Teja</a>, 
<a href="/search/cs?searchtype=author&query=Gupta%2C+N">Neeharika Gupta</a>, 
<a href="/search/cs?searchtype=author&query=Patwa%2C+P">Parth Patwa</a>, 
<a href="/search/cs?searchtype=author&query=Chatterjee%2C+A">Anubhab Chatterjee</a>, 
<a href="/search/cs?searchtype=author&query=Jain%2C+V">Vinija Jain</a>, 
<a href="/search/cs?searchtype=author&query=Chadha%2C+A">Aman Chadha</a>, 
<a href="/search/cs?searchtype=author&query=Das%2C+A">Amitava Das</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">The mixing of two or more languages is called Code-Mixing (CM). CM is a
social norm in multilingual societies. Neural Language Models (NLMs) like
transformers have been very effective on many NLP tasks. However, NLM for CM is
an under-explored area. Though transformers are capable and powerful, they
cannot always encode positional/sequential information since they are
non-recurrent. Therefore, to enrich word information and incorporate positional
information, positional encoding is defined. We hypothesize that Switching
Points (SPs), i.e., junctions in the text where the language switches (L1 -&gt; L2
or L2-&gt; L1), pose a challenge for CM Language Models (LMs), and hence give
special emphasis to switching points in the modeling process. We experiment
with several positional encoding mechanisms and show that rotatory positional
encodings along with switching point information yield the best results.
<br />We introduce CONFLATOR: a neural language modeling approach for code-mixed
languages. CONFLATOR tries to learn to emphasize switching points using smarter
positional encoding, both at unigram and bigram levels. CONFLATOR outperforms
the state-of-the-art on two tasks based on code-mixed Hindi and English
(Hinglish): (i) sentiment analysis and (ii) machine translation.
</p>
</div>
</dd>
<dt><a name="item328">[328]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.05272" title="Abstract">arXiv:2309.05272</a> [<a href="/pdf/2309.05272" title="Download PDF">pdf</a>, <a href="/format/2309.05272" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Minuteman: Machine and Human Joining Forces in Meeting Summarization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kmje%C4%8D%2C+F">Franti&#x161;ek Kmje&#x10d;</a>, 
<a href="/search/cs?searchtype=author&query=Bojar%2C+O">Ond&#x159;ej Bojar</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages, 3 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Many meetings require creating a meeting summary to keep everyone up to date.
Creating minutes of sufficient quality is however very cognitively demanding.
Although we currently possess capable models for both audio speech recognition
(ASR) and summarization, their fully automatic use is still problematic. ASR
models frequently commit errors when transcribing named entities while the
summarization models tend to hallucinate and misinterpret the transcript. We
propose a novel tool -- Minuteman -- to enable efficient semi-automatic meeting
minuting. The tool provides a live transcript and a live meeting summary to the
users, who can edit them in a collaborative manner, enabling correction of ASR
errors and imperfect summary points in real time. The resulting application
eases the cognitive load of the notetakers and allows them to easily catch up
if they missed a part of the meeting due to absence or a lack of focus. We
conduct several tests of the application in varied settings, exploring the
worthiness of the concept and the possible user strategies.
</p>
</div>
</dd>
<dt><a name="item329">[329]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.05273" title="Abstract">arXiv:2309.05273</a> [<a href="/pdf/2309.05273" title="Download PDF">pdf</a>, <a href="/format/2309.05273" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Formalizing Multimedia Recommendation through Multimodal Deep Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Malitesta%2C+D">Daniele Malitesta</a>, 
<a href="/search/cs?searchtype=author&query=Cornacchia%2C+G">Giandomenico Cornacchia</a>, 
<a href="/search/cs?searchtype=author&query=Pomo%2C+C">Claudio Pomo</a>, 
<a href="/search/cs?searchtype=author&query=Merra%2C+F+A">Felice Antonio Merra</a>, 
<a href="/search/cs?searchtype=author&query=Di+Noia%2C+T">Tommaso Di Noia</a>, 
<a href="/search/cs?searchtype=author&query=Di+Sciascio%2C+E">Eugenio Di Sciascio</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>

</div>
<p class="mathjax">Recommender systems (RSs) offer personalized navigation experiences on online
platforms, but recommendation remains a challenging task, particularly in
specific scenarios and domains. Multimodality can help tap into richer
information sources and construct more refined user/item profiles for
recommendations. However, existing literature lacks a shared and universal
schema for modeling and solving the recommendation problem through the lens of
multimodality. This work aims to formalize a general multimodal schema for
multimedia recommendation. It provides a comprehensive literature review of
multimodal approaches for multimedia recommendation from the last eight years,
outlines the theoretical foundations of a multimodal pipeline, and demonstrates
its rationale by applying it to selected state-of-the-art approaches. The work
also conducts a benchmarking analysis of recent algorithms for multimedia
recommendation within Elliot, a rigorous framework for evaluating recommender
systems. The main aim is to provide guidelines for designing and implementing
the next generation of multimodal approaches in multimedia recommendation.
</p>
</div>
</dd>
<dt><a name="item330">[330]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.05274" title="Abstract">arXiv:2309.05274</a> [<a href="/pdf/2309.05274" title="Download PDF">pdf</a>, <a href="/format/2309.05274" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FuzzLLM: A Novel and Universal Fuzzing Framework for Proactively  Discovering Jailbreak Vulnerabilities in Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yao%2C+D">Dongyu Yao</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jianshu Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Harris%2C+I+G">Ian G. Harris</a>, 
<a href="/search/cs?searchtype=author&query=Carlsson%2C+M">Marcel Carlsson</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> In submission, a preprint version
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">Jailbreak vulnerabilities in Large Language Models (LLMs), which exploit
meticulously crafted prompts to elicit content that violates service
guidelines, have captured the attention of research communities. While model
owners can defend against individual jailbreak prompts through safety training
strategies, this relatively passive approach struggles to handle the broader
category of similar jailbreaks. To tackle this issue, we introduce FuzzLLM, an
automated fuzzing framework designed to proactively test and discover jailbreak
vulnerabilities in LLMs. We utilize templates to capture the structural
integrity of a prompt and isolate key features of a jailbreak class as
constraints. By integrating different base classes into powerful combo attacks
and varying the elements of constraints and prohibited questions, FuzzLLM
enables efficient testing with reduced manual effort. Extensive experiments
demonstrate FuzzLLM's effectiveness and comprehensiveness in vulnerability
discovery across various LLMs.
</p>
</div>
</dd>
<dt><a name="item331">[331]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.05276" title="Abstract">arXiv:2309.05276</a> [<a href="/pdf/2309.05276" title="Download PDF">pdf</a>, <a href="/format/2309.05276" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Beamforming in Wireless Coded-Caching Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Madhusudan%2C+S">Sneha Madhusudan</a>, 
<a href="/search/cs?searchtype=author&query=Madapatha%2C+C">Charitha Madapatha</a>, 
<a href="/search/cs?searchtype=author&query=Makki%2C+B">Behrooz Makki</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+H">Hao Guo</a>, 
<a href="/search/cs?searchtype=author&query=Svensson%2C+T">Tommy Svensson</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to IEEE Future Networks World Forum, 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Machine Learning (cs.LG); Networking and Internet Architecture (cs.NI); Signal Processing (eess.SP)

</div>
<p class="mathjax">Increased capacity in the access network poses capacity challenges on the
transport network due to the aggregated traffic. However, there are spatial and
time correlation in the user data demands that could potentially be utilized.
To that end, we investigate a wireless transport network architecture that
integrates beamforming and coded-caching strategies. Especially, our proposed
design entails a server with multiple antennas that broadcasts content to cache
nodes responsible for serving users. Traditional caching methods face the
limitation of relying on the individual memory with additional overhead. Hence,
we develop an efficient genetic algorithm-based scheme for beam optimization in
the coded-caching system. By exploiting the advantages of beamforming and
coded-caching, the architecture achieves gains in terms of multicast
opportunities, interference mitigation, and reduced peak backhaul traffic. A
comparative analysis of this joint design with traditional, un-coded caching
schemes is also conducted to assess the benefits of the proposed approach.
Additionally, we examine the impact of various buffering and decoding methods
on the performance of the coded-caching scheme. Our findings suggest that
proper beamforming is useful in enhancing the effectiveness of the
coded-caching technique, resulting in significant reduction in peak backhaul
traffic.
</p>
</div>
</dd>
<dt><a name="item332">[332]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.05277" title="Abstract">arXiv:2309.05277</a> [<a href="/pdf/2309.05277" title="Download PDF">pdf</a>, <a href="/format/2309.05277" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Interactive Class-Agnostic Object Counting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+Y">Yifeng Huang</a>, 
<a href="/search/cs?searchtype=author&query=Ranjan%2C+V">Viresh Ranjan</a>, 
<a href="/search/cs?searchtype=author&query=Hoai%2C+M">Minh Hoai</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">We propose a novel framework for interactive class-agnostic object counting,
where a human user can interactively provide feedback to improve the accuracy
of a counter. Our framework consists of two main components: a user-friendly
visualizer to gather feedback and an efficient mechanism to incorporate it. In
each iteration, we produce a density map to show the current prediction result,
and we segment it into non-overlapping regions with an easily verifiable number
of objects. The user can provide feedback by selecting a region with obvious
counting errors and specifying the range for the estimated number of objects
within it. To improve the counting result, we develop a novel adaptation loss
to force the visual counter to output the predicted count within the
user-specified range. For effective and efficient adaptation, we propose a
refinement module that can be used with any density-based visual counter, and
only the parameters in the refinement module will be updated during adaptation.
Our experiments on two challenging class-agnostic object counting benchmarks,
FSCD-LVIS and FSC-147, show that our method can reduce the mean absolute error
of multiple state-of-the-art visual counters by roughly 30% to 40% with minimal
user input. Our project can be found at
https://yifehuang97.github.io/ICACountProjectPage/.
</p>
</div>
</dd>
<dt><a name="item333">[333]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.05278" title="Abstract">arXiv:2309.05278</a> [<a href="/pdf/2309.05278" title="Download PDF">pdf</a>, <a href="/format/2309.05278" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Low Peak-to-Average Power Ratio FBMC-OQAM System based on Data Mapping  and DFT Precoding
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+L">Liming Li</a>, 
<a href="/search/cs?searchtype=author&query=Ding%2C+L">Liqin Ding</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jiliang Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">Filter bank multicarrier with offset quadrature amplitude modulation
(FBMC-OQAM) is an alternative to OFDM for enhanced spectrum flexible usage. To
reduce the peak-to-average power ratio (PAPR), DFT spreading is usually adopted
in OFDM systems. However, in FBMC-OQAM systems, because the OQAM pre-processing
splits the spread data into the real and imaginary parts, the DFT spreading can
result in only marginal PAPR reduction. This letter proposes a novel
map-DFT-spread FBMC-OQAM scheme. In this scheme, the transmitting data symbols
are first mapped with a conjugate symmetry rule and then coded by the DFT.
According to this method, the OQAM pre-processing can be avoided. Compared with
the simple DFT-spread scheme, the proposed scheme achieves a better PAPR
reduction. In addition, the effect of the prototype filter on the PAPR is
studied via numerical simulation and a trade-off exists between the PAPR and
out-of-band performances.
</p>
</div>
</dd>
<dt><a name="item334">[334]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.05281" title="Abstract">arXiv:2309.05281</a> [<a href="/pdf/2309.05281" title="Download PDF">pdf</a>, <a href="/format/2309.05281" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Class-Incremental Grouping Network for Continual Audio-Visual Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mo%2C+S">Shentong Mo</a>, 
<a href="/search/cs?searchtype=author&query=Pian%2C+W">Weiguo Pian</a>, 
<a href="/search/cs?searchtype=author&query=Tian%2C+Y">Yapeng Tian</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ICCV 2023. arXiv admin note: text overlap with <a href="/abs/2303.17056">arXiv:2303.17056</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG); Multimedia (cs.MM)

</div>
<p class="mathjax">Continual learning is a challenging problem in which models need to be
trained on non-stationary data across sequential tasks for class-incremental
learning. While previous methods have focused on using either regularization or
rehearsal-based frameworks to alleviate catastrophic forgetting in image
classification, they are limited to a single modality and cannot learn compact
class-aware cross-modal representations for continual audio-visual learning. To
address this gap, we propose a novel class-incremental grouping network (CIGN)
that can learn category-wise semantic features to achieve continual
audio-visual learning. Our CIGN leverages learnable audio-visual class tokens
and audio-visual grouping to continually aggregate class-aware features.
Additionally, it utilizes class tokens distillation and continual grouping to
prevent forgetting parameters learned from previous tasks, thereby improving
the model's ability to capture discriminative audio-visual categories. We
conduct extensive experiments on VGGSound-Instruments, VGGSound-100, and
VGG-Sound Sources benchmarks. Our experimental results demonstrate that the
CIGN achieves state-of-the-art audio-visual class-incremental learning
performance. Code is available at https://github.com/stoneMo/CIGN.
</p>
</div>
</dd>
<dt><a name="item335">[335]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.05282" title="Abstract">arXiv:2309.05282</a> [<a href="/pdf/2309.05282" title="Download PDF">pdf</a>, <a href="/format/2309.05282" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Can you text what is happening? Integrating pre-trained language  encoders into trajectory prediction models for autonomous driving
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Keysan%2C+A">Ali Keysan</a>, 
<a href="/search/cs?searchtype=author&query=Look%2C+A">Andreas Look</a>, 
<a href="/search/cs?searchtype=author&query=Kosman%2C+E">Eitan Kosman</a>, 
<a href="/search/cs?searchtype=author&query=G%C3%BCrsun%2C+G">Gonca G&#xfc;rsun</a>, 
<a href="/search/cs?searchtype=author&query=Wagner%2C+J">J&#xf6;rg Wagner</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+Y">Yao Yu</a>, 
<a href="/search/cs?searchtype=author&query=Rakitsch%2C+B">Barbara Rakitsch</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">In autonomous driving tasks, scene understanding is the first step towards
predicting the future behavior of the surrounding traffic participants. Yet,
how to represent a given scene and extract its features are still open research
questions. In this study, we propose a novel text-based representation of
traffic scenes and process it with a pre-trained language encoder.
<br />First, we show that text-based representations, combined with classical
rasterized image representations, lead to descriptive scene embeddings. Second,
we benchmark our predictions on the nuScenes dataset and show significant
improvements compared to baselines. Third, we show in an ablation study that a
joint encoder of text and rasterized images outperforms the individual encoders
confirming that both representations have their complementary strengths.
</p>
</div>
</dd>
<dt><a name="item336">[336]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.05287" title="Abstract">arXiv:2309.05287</a> [<a href="/pdf/2309.05287" title="Download PDF">pdf</a>, <a href="/format/2309.05287" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Addressing Feature Imbalance in Sound Source Separation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kim%2C+J">Jaechang Kim</a>, 
<a href="/search/cs?searchtype=author&query=Hwang%2C+J">Jeongyeon Hwang</a>, 
<a href="/search/cs?searchtype=author&query=Yi%2C+S">Soheun Yi</a>, 
<a href="/search/cs?searchtype=author&query=Cho%2C+J">Jaewoong Cho</a>, 
<a href="/search/cs?searchtype=author&query=Ok%2C+J">Jungseul Ok</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Artificial Intelligence (cs.AI); Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">Neural networks often suffer from a feature preference problem, where they
tend to overly rely on specific features to solve a task while disregarding
other features, even if those neglected features are essential for the task.
Feature preference problems have primarily been investigated in classification
task. However, we observe that feature preference occurs in high-dimensional
regression task, specifically, source separation. To mitigate feature
preference in source separation, we propose FEAture BAlancing by Suppressing
Easy feature (FEABASE). This approach enables efficient data utilization by
learning hidden information about the neglected feature. We evaluate our method
in a multi-channel source separation task, where feature preference between
spatial feature and timbre feature appears.
</p>
</div>
</dd>
<dt><a name="item337">[337]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.05288" title="Abstract">arXiv:2309.05288</a> [<a href="/pdf/2309.05288" title="Download PDF">pdf</a>, <a href="/ps/2309.05288" title="Download PostScript">ps</a>, <a href="/format/2309.05288" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the Structure of the Linear Codes with a Given Automorphism
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bouyuklieva%2C+S">Stefka Bouyuklieva</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Discrete Mathematics (cs.DM); Combinatorics (math.CO)

</div>
<p class="mathjax">The purpose of this paper is to present the structure of the linear codes
over a finite field with q elements that have a permutation automorphism of
order m. These codes can be considered as generalized quasi-cyclic codes.
Quasi-cyclic codes and almost quasi-cyclic codes are discussed in detail,
presenting necessary and sufficient conditions for which linear codes with such
an automorphism are self-orthogonal, self-dual, or linear complementary dual.
</p>
</div>
</dd>
<dt><a name="item338">[338]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.05289" title="Abstract">arXiv:2309.05289</a> [<a href="/pdf/2309.05289" title="Download PDF">pdf</a>, <a href="/format/2309.05289" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Task-driven Compression for Collision Encoding based on Depth Images
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kulkarni%2C+M">Mihir Kulkarni</a>, 
<a href="/search/cs?searchtype=author&query=Alexis%2C+K">Kostas Alexis</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages, 5, figures. Accepted to the International Symposium on Visual Computing 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Robotics (cs.RO)

</div>
<p class="mathjax">This paper contributes a novel learning-based method for aggressive
task-driven compression of depth images and their encoding as images tailored
to collision prediction for robotic systems. A novel 3D image processing
methodology is proposed that accounts for the robot's size in order to
appropriately "inflate" the obstacles represented in the depth image and thus
obtain the distance that can be traversed by the robot in a collision-free
manner along any given ray within the camera frustum. Such depth-and-collision
image pairs are used to train a neural network that follows the architecture of
Variational Autoencoders to compress-and-transform the information in the
original depth image to derive a latent representation that encodes the
collision information for the given depth image. We compare our proposed
task-driven encoding method with classical task-agnostic methods and
demonstrate superior performance for the task of collision image prediction
from extremely low-dimensional latent spaces. A set of comparative studies show
that the proposed approach is capable of encoding depth image-and-collision
image tuples from complex scenes with thin obstacles at long distances better
than the classical methods at compression ratios as high as 4050:1.
</p>
</div>
</dd>
<dt><a name="item339">[339]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.05292" title="Abstract">arXiv:2309.05292</a> [<a href="/pdf/2309.05292" title="Download PDF">pdf</a>, <a href="/format/2309.05292" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The fine print on tempered posteriors
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pitas%2C+K">Konstantinos Pitas</a>, 
<a href="/search/cs?searchtype=author&query=Arbel%2C+J">Julyan Arbel</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
<p class="mathjax">We conduct a detailed investigation of tempered posteriors and uncover a
number of crucial and previously undiscussed points. Contrary to previous
results, we first show that for realistic models and datasets and the tightly
controlled case of the Laplace approximation to the posterior, stochasticity
does not in general improve test accuracy. The coldest temperature is often
optimal. One might think that Bayesian models with some stochasticity can at
least obtain improvements in terms of calibration. However, we show empirically
that when gains are obtained this comes at the cost of degradation in test
accuracy. We then discuss how targeting Frequentist metrics using Bayesian
models provides a simple explanation of the need for a temperature parameter
$\lambda$ in the optimization objective. Contrary to prior works, we finally
show through a PAC-Bayesian analysis that the temperature $\lambda$ cannot be
seen as simply fixing a misspecified prior or likelihood.
</p>
</div>
</dd>
<dt><a name="item340">[340]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.05295" title="Abstract">arXiv:2309.05295</a> [<a href="/pdf/2309.05295" title="Download PDF">pdf</a>, <a href="/format/2309.05295" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Discrete Denoising Diffusion Approach to Integer Factorization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Freivalds%2C+K">Karlis Freivalds</a>, 
<a href="/search/cs?searchtype=author&query=Ozolins%2C+E">Emils Ozolins</a>, 
<a href="/search/cs?searchtype=author&query=Barzdins%2C+G">Guntis Barzdins</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> International Conference on Artificial Neural Networks ICANN 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Integer factorization is a famous computational problem unknown whether being
solvable in the polynomial time. With the rise of deep neural networks, it is
interesting whether they can facilitate faster factorization. We present an
approach to factorization utilizing deep neural networks and discrete denoising
diffusion that works by iteratively correcting errors in a partially-correct
solution. To this end, we develop a new seq2seq neural network architecture,
employ relaxed categorical distribution and adapt the reverse diffusion process
to cope better with inaccuracies in the denoising step. The approach is able to
find factors for integers of up to 56 bits long. Our analysis indicates that
investment in training leads to an exponential decrease of sampling steps
required at inference to achieve a given success rate, thus counteracting an
exponential run-time increase depending on the bit-length.
</p>
</div>
</dd>
<dt><a name="item341">[341]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.05298" title="Abstract">arXiv:2309.05298</a> [<a href="/pdf/2309.05298" title="Download PDF">pdf</a>, <a href="/format/2309.05298" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Real-Time Parallel Trajectory Optimization with Spatiotemporal Safety  Constraints for Autonomous Driving in Congested Traffic
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zheng%2C+L">Lei Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+R">Rui Yang</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+Z">Zengqi Peng</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+H">Haichao Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+M+Y">Michael Yu Wang</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+J">Jun Ma</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 7 figures, accepted for publication in the 26th IEEE International Conference on Intelligent Transportation Systems (ITSC 2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Systems and Control (eess.SY)

</div>
<p class="mathjax">Multi-modal behaviors exhibited by surrounding vehicles (SVs) can typically
lead to traffic congestion and reduce the travel efficiency of autonomous
vehicles (AVs) in dense traffic. This paper proposes a real-time parallel
trajectory optimization method for the AV to achieve high travel efficiency in
dynamic and congested environments. A spatiotemporal safety module is developed
to facilitate the safe interaction between the AV and SVs in the presence of
trajectory prediction errors resulting from the multi-modal behaviors of the
SVs. By leveraging multiple shooting and constraint transcription, we transform
the trajectory optimization problem into a nonlinear programming problem, which
allows for the use of optimization solvers and parallel computing techniques to
generate multiple feasible trajectories in parallel. Subsequently, these
spatiotemporal trajectories are fed into a multi-objective evaluation module
considering both safety and efficiency objectives, such that the optimal
feasible trajectory corresponding to the optimal target lane can be selected.
The proposed framework is validated through simulations in a dense and
congested driving scenario with multiple uncertain SVs. The results demonstrate
that our method enables the AV to safely navigate through a dense and congested
traffic scenario while achieving high travel efficiency and task accuracy in
real time.
</p>
</div>
</dd>
<dt><a name="item342">[342]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.05300" title="Abstract">arXiv:2309.05300</a> [<a href="/pdf/2309.05300" title="Download PDF">pdf</a>, <a href="/format/2309.05300" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DeCUR: decoupling common &amp; unique representations for multimodal  self-supervision
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yi Wang</a>, 
<a href="/search/cs?searchtype=author&query=Albrecht%2C+C+M">Conrad M Albrecht</a>, 
<a href="/search/cs?searchtype=author&query=Braham%2C+N+A+A">Nassim Ait Ali Braham</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+C">Chenying Liu</a>, 
<a href="/search/cs?searchtype=author&query=Xiong%2C+Z">Zhitong Xiong</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+X+X">Xiao Xiang Zhu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 19 pages, 10 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">The increasing availability of multi-sensor data sparks interest in
multimodal self-supervised learning. However, most existing approaches learn
only common representations across modalities while ignoring intra-modal
training and modality-unique representations. We propose Decoupling Common and
Unique Representations (DeCUR), a simple yet effective method for multimodal
self-supervised learning. By distinguishing inter- and intra-modal embeddings,
DeCUR is trained to integrate complementary information across different
modalities. We evaluate DeCUR in three common multimodal scenarios
(radar-optical, RGB-elevation, and RGB-depth), and demonstrate its consistent
benefits on scene classification and semantic segmentation downstream tasks.
Notably, we get straightforward improvements by transferring our pretrained
backbones to state-of-the-art supervised multimodal methods without any
hyperparameter tuning. Furthermore, we conduct a comprehensive explainability
analysis to shed light on the interpretation of common and unique features in
our multimodal approach. Codes are available at
\url{https://github.com/zhu-xlab/DeCUR}.
</p>
</div>
</dd>
<dt><a name="item343">[343]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.05303" title="Abstract">arXiv:2309.05303</a> [<a href="/pdf/2309.05303" title="Download PDF">pdf</a>, <a href="/ps/2309.05303" title="Download PostScript">ps</a>, <a href="/format/2309.05303" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Morley Type Virtual Element Method for Von K&#xe1;rm&#xe1;n Equations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Shylaja%2C+D">Devika Shylaja</a>, 
<a href="/search/math?searchtype=author&query=Kumar%2C+S">Sarvesh Kumar</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 23 pages, 6 figures, 6 tables Submitted to a journal. arXiv admin note: text overlap with <a href="/abs/1708.07815">arXiv:1708.07815</a> by other authors
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">This paper analyses the nonconforming Morley type virtual element method to
approximate a regular solution to the von K\'{a}rm\'{a}n equations that
describes bending of very thin elastic plates. Local existence and uniqueness
of a discrete solution to the non-linear problem is discussed. A priori error
estimate in the energy norm is established under minimal regularity assumptions
on the exact solution. Error estimates in piecewise $H^1$ and $L^2$ norm are
also derived. A working procedure to find an approximation for the discrete
solution using Newtons method is discussed. Numerical results that justify
theoretical estimates are presented.
</p>
</div>
</dd>
<dt><a name="item344">[344]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.05305" title="Abstract">arXiv:2309.05305</a> [<a href="/pdf/2309.05305" title="Download PDF">pdf</a>, <a href="/format/2309.05305" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fully-Connected Spatial-Temporal Graph for Multivariate Time Series Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yucheng Wang</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+Y">Yuecong Xu</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+J">Jianfei Yang</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+M">Min Wu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xiaoli Li</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+L">Lihua Xie</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Z">Zhenghua Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages, 8 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Multivariate Time-Series (MTS) data is crucial in various application fields.
With its sequential and multi-source (multiple sensors) properties, MTS data
inherently exhibits Spatial-Temporal (ST) dependencies, involving temporal
correlations between timestamps and spatial correlations between sensors in
each timestamp. To effectively leverage this information, Graph Neural
Network-based methods (GNNs) have been widely adopted. However, existing
approaches separately capture spatial dependency and temporal dependency and
fail to capture the correlations between Different sEnsors at Different
Timestamps (DEDT). Overlooking such correlations hinders the comprehensive
modelling of ST dependencies within MTS data, thus restricting existing GNNs
from learning effective representations. To address this limitation, we propose
a novel method called Fully-Connected Spatial-Temporal Graph Neural Network
(FC-STGNN), including two key components namely FC graph construction and FC
graph convolution. For graph construction, we design a decay graph to connect
sensors across all timestamps based on their temporal distances, enabling us to
fully model the ST dependencies by considering the correlations between DEDT.
Further, we devise FC graph convolution with a moving-pooling GNN layer to
effectively capture the ST dependencies for learning effective representations.
Extensive experiments show the effectiveness of FC-STGNN on multiple MTS
datasets compared to SOTA methods.
</p>
</div>
</dd>
<dt><a name="item345">[345]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.05308" title="Abstract">arXiv:2309.05308</a> [<a href="/pdf/2309.05308" title="Download PDF">pdf</a>, <a href="/ps/2309.05308" title="Download PostScript">ps</a>, <a href="/format/2309.05308" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Two-way Linear Probing Revisited
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dalal%2C+K">Ketan Dalal</a>, 
<a href="/search/cs?searchtype=author&query=Devroye%2C+L">Luc Devroye</a>, 
<a href="/search/cs?searchtype=author&query=Malalla%2C+E">Ebrahim Malalla</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 31 pages, 8 figures, 5 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>

</div>
<p class="mathjax">We introduce linear probing hashing schemes that construct a hash table of
size $n$, with constant load factor $\alpha$, on which the worst-case
unsuccessful search time is asymptotically almost surely $O(\log \log n)$. The
schemes employ two linear probe sequences to find empty cells for the keys.
Matching lower bounds on the maximum cluster size produced by any algorithm
that uses two linear probe sequences are obtained as well.
</p>
</div>
</dd>
<dt><a name="item346">[346]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.05310" title="Abstract">arXiv:2309.05310</a> [<a href="/pdf/2309.05310" title="Download PDF">pdf</a>, <a href="/format/2309.05310" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Unsupervised human-to-robot motion retargeting via expressive latent  space
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yan%2C+Y">Yashuai Yan</a>, 
<a href="/search/cs?searchtype=author&query=Mascaro%2C+E+V">Esteve Valls Mascaro</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+D">Dongheui Lee</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">This paper introduces a novel approach for human-to-robot motion retargeting,
enabling robots to mimic human motion with precision while preserving the
semantics of the motion. For that, we propose a deep learning method for direct
translation from human to robot motion. Our method does not require annotated
paired human-to-robot motion data, which reduces the effort when adopting new
robots. To this end, we first propose a cross-domain similarity metric to
compare the poses from different domains (i.e., human and robot). Then, our
method achieves the construction of a shared latent space via contrastive
learning and decodes latent representations to robot motion control commands.
The learned latent space exhibits expressiveness as it captures the motions
precisely and allows direct motion control in the latent space. We showcase how
to generate in-between motion through simple linear interpolation in the latent
space between two projected human poses. Additionally, we conducted a
comprehensive evaluation of robot control using diverse modality inputs, such
as texts, RGB videos, and key-poses, which enhances the ease of robot control
to users of all backgrounds. Finally, we compare our model with existing works
and quantitatively and qualitatively demonstrate the effectiveness of our
approach, enhancing natural human-robot communication and fostering trust in
integrating robots into daily life.
</p>
</div>
</dd>
<dt><a name="item347">[347]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.05311" title="Abstract">arXiv:2309.05311</a> [<a href="/pdf/2309.05311" title="Download PDF">pdf</a>, <a href="/format/2309.05311" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Analysing Cross-Lingual Transfer in Low-Resourced African Named Entity  Recognition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Beukman%2C+M">Michael Beukman</a>, 
<a href="/search/cs?searchtype=author&query=Fokam%2C+M">Manuel Fokam</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to IJCNLP-AACL 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Transfer learning has led to large gains in performance for nearly all NLP
tasks while making downstream models easier and faster to train. This has also
been extended to low-resourced languages, with some success. We investigate the
properties of cross-lingual transfer learning between ten low-resourced
languages, from the perspective of a named entity recognition task. We
specifically investigate how much adaptive fine-tuning and the choice of
transfer language affect zero-shot transfer performance. We find that models
that perform well on a single language often do so at the expense of
generalising to others, while models with the best generalisation to other
languages suffer in individual language performance. Furthermore, the amount of
data overlap between the source and target datasets is a better predictor of
transfer performance than either the geographical or genetic distance between
the languages.
</p>
</div>
</dd>
<dt><a name="item348">[348]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.05312" title="Abstract">arXiv:2309.05312</a> [<a href="/pdf/2309.05312" title="Download PDF">pdf</a>, <a href="/format/2309.05312" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Experimenting with UD Adaptation of an Unsupervised Rule-based Approach  for Sentiment Analysis of Mexican Tourist Texts
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kellert%2C+O">Olga Kellert</a>, 
<a href="/search/cs?searchtype=author&query=Zaman%2C+M+U">Mahmud Uz Zaman</a>, 
<a href="/search/cs?searchtype=author&query=Matlis%2C+N+H">Nicholas Hill Matlis</a>, 
<a href="/search/cs?searchtype=author&query=G%C3%B3mez-Rodr%C3%ADguez%2C+C">Carlos G&#xf3;mez-Rodr&#xed;guez</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Proceedings of IberLEF 2023, Ja\'en, Spain, 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">This paper summarizes the results of experimenting with Universal
Dependencies (UD) adaptation of an Unsupervised, Compositional and Recursive
(UCR) rule-based approach for Sentiment Analysis (SA) submitted to the Shared
Task at Rest-Mex 2023 (Team Olga/LyS-SALSA) (within the IberLEF 2023
conference). By using basic syntactic rules such as rules of modification and
negation applied on words from sentiment dictionaries, our approach exploits
some advantages of an unsupervised method for SA: (1) interpretability and
explainability of SA, (2) robustness across datasets, languages and domains and
(3) usability by non-experts in NLP. We compare our approach with other
unsupervised approaches of SA that in contrast to our UCR rule-based approach
use simple heuristic rules to deal with negation and modification. Our results
show a considerable improvement over these approaches. We discuss future
improvements of our results by using modality features as another shifting rule
of polarity and word disambiguation techniques to identify the right sentiment
words.
</p>
</div>
</dd>
<dt><a name="item349">[349]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.05314" title="Abstract">arXiv:2309.05314</a> [<a href="/pdf/2309.05314" title="Download PDF">pdf</a>, <a href="/format/2309.05314" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Semantic Latent Decomposition with Normalizing Flows for Face Editing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+B">Binglei Li</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+Z">Zhizhong Huang</a>, 
<a href="/search/cs?searchtype=author&query=Shan%2C+H">Hongming Shan</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Junping Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Navigating in the latent space of StyleGAN has shown effectiveness for face
editing. However, the resulting methods usually encounter challenges in
complicated navigation due to the entanglement among different attributes in
the latent space. To address this issue, this paper proposes a novel framework,
termed SDFlow, with a semantic decomposition in original latent space using
continuous conditional normalizing flows. Specifically, SDFlow decomposes the
original latent code into different irrelevant variables by jointly optimizing
two components: (i) a semantic encoder to estimate semantic variables from
input faces and (ii) a flow-based transformation module to map the latent code
into a semantic-irrelevant variable in Gaussian distribution, conditioned on
the learned semantic variables. To eliminate the entanglement between
variables, we employ a disentangled learning strategy under a mutual
information framework, thereby providing precise manipulation controls.
Experimental results demonstrate that SDFlow outperforms existing
state-of-the-art face editing methods both qualitatively and quantitatively.
The source code is made available at https://github.com/phil329/SDFlow.
</p>
</div>
</dd>
<dt><a name="item350">[350]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.05317" title="Abstract">arXiv:2309.05317</a> [<a href="/pdf/2309.05317" title="Download PDF">pdf</a>, <a href="/format/2309.05317" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Neural Koopman prior for data assimilation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Frion%2C+A">Anthony Frion</a>, 
<a href="/search/cs?searchtype=author&query=Drumetz%2C+L">Lucas Drumetz</a>, 
<a href="/search/cs?searchtype=author&query=Mura%2C+M+D">Mauro Dalla Mura</a>, 
<a href="/search/cs?searchtype=author&query=Tochon%2C+G">Guillaume Tochon</a>, 
<a href="/search/cs?searchtype=author&query=Bey%2C+A+A+E">Abdeldjalil A&#xef;ssa El Bey</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">With the increasing availability of large scale datasets, computational power
and tools like automatic differentiation and expressive neural network
architectures, sequential data are now often treated in a data-driven way, with
a dynamical model trained from the observation data. While neural networks are
often seen as uninterpretable black-box architectures, they can still benefit
from physical priors on the data and from mathematical knowledge. In this
paper, we use a neural network architecture which leverages the long-known
Koopman operator theory to embed dynamical systems in latent spaces where their
dynamics can be described linearly, enabling a number of appealing features. We
introduce methods that enable to train such a model for long-term continuous
reconstruction, even in difficult contexts where the data comes in
irregularly-sampled time series. The potential for self-supervised learning is
also demonstrated, as we show the promising use of trained dynamical models as
priors for variational data assimilation techniques, with applications to e.g.
time series interpolation and forecasting.
</p>
</div>
</dd>
<dt><a name="item351">[351]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.05320" title="Abstract">arXiv:2309.05320</a> [<a href="/pdf/2309.05320" title="Download PDF">pdf</a>, <a href="/ps/2309.05320" title="Download PostScript">ps</a>, <a href="/format/2309.05320" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DynamicScore: a Novel Metric for Quantifying Graph Dynamics
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bridonneau%2C+V">Vincent Bridonneau</a> (RI2C - LITIS), 
<a href="/search/cs?searchtype=author&query=Guinand%2C+F">Fr&#xe9;d&#xe9;ric Guinand</a> (RI2C - LITIS), 
<a href="/search/cs?searchtype=author&query=Pign%C3%A9%2C+Y">Yoann Pign&#xe9;</a> (RI2C - LITIS)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Discrete Mathematics (cs.DM)</span>

</div>
<p class="mathjax">This study introduces a new metric called ''DynamicScore'' to evaluate the
dynamics of graphs. It can be applied to both vertices and edges. Unlike
traditional metrics, DynamicScore not only measures changes in the number of
vertices or edges between consecutive time steps, but also takes into account
the composition of these sets. To illustrate the possible contributions of this
metric, we calculate it for increasing networks of preferential attachment
(Barab{\'a}si-Albert model) and Edge-Markovian graphs. The results improve our
understanding of the dynamics inherent in these generated evolving graphs.
</p>
</div>
</dd>
<dt><a name="item352">[352]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.05327" title="Abstract">arXiv:2309.05327</a> [<a href="/pdf/2309.05327" title="Download PDF">pdf</a>, <a href="/format/2309.05327" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Iterative Interference Cancellation for Time Reversal Division Multiple  Access
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mokh%2C+A">Ali Mokh</a>, 
<a href="/search/cs?searchtype=author&query=Alexandropoulos%2C+G+C">George C. Alexandropoulos</a>, 
<a href="/search/cs?searchtype=author&query=Kamoun%2C+M">Mohamed Kamoun</a>, 
<a href="/search/cs?searchtype=author&query=Ourir%2C+A">Abdelwaheb Ourir</a>, 
<a href="/search/cs?searchtype=author&query=Tourin%2C+A">Arnaud Tourin</a>, 
<a href="/search/cs?searchtype=author&query=Fink%2C+M">Mathias Fink</a>, 
<a href="/search/cs?searchtype=author&query=de+Rosny%2C+J">Julien de Rosny</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, 8 figures, published in an IEEE Journal
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Emerging Technologies (cs.ET)

</div>
<p class="mathjax">Time Reversal (TR) has been proposed as a competitive precoding strategy for
low-complexity devices, relying on ultra-wideband waveforms. This transmit
processing paradigm can address the need for low power and low complexity
receivers, which is particularly important for the Internet of Things, since it
shifts most of the communications signal processing complexity to the
transmitter side. Due to its spatio-temporal focusing property, TR has also
been used to design multiple access schemes for multi-user communications
scenarios. However, in wideband time-division multiple access schemes, the
signals received by users suffer from significant levels of inter-symbol
interference as well as interference from uncoordinated users, which often
require additional processing at the receiver side. This paper proposes an
iterative TR scheme that aims to reduce the level of interference in wideband
multi-user settings, while keeping the processing complexity only at the
transmitter side. The performance of the proposed TR-based protocol is
evaluated using analytical derivations. In addition, its superiority over the
conventional Time Reversal Division Multiple Access (TRDMA) scheme is
demonstrated through simulations as well as experimental measurements at $2.5$
GHz carrier frequency with variable bandwidth values.
</p>
</div>
</dd>
<dt><a name="item353">[353]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.05330" title="Abstract">arXiv:2309.05330</a> [<a href="/pdf/2309.05330" title="Download PDF">pdf</a>, <a href="/format/2309.05330" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Diff-Privacy: Diffusion-based Face Privacy Protection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=He%2C+X">Xiao He</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+M">Mingrui Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+D">Dongxin Chen</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+N">Nannan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+X">Xinbo Gao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 17pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Privacy protection has become a top priority as the proliferation of AI
techniques has led to widespread collection and misuse of personal data.
Anonymization and visual identity information hiding are two important facial
privacy protection tasks that aim to remove identification characteristics from
facial images at the human perception level. However, they have a significant
difference in that the former aims to prevent the machine from recognizing
correctly, while the latter needs to ensure the accuracy of machine
recognition. Therefore, it is difficult to train a model to complete these two
tasks simultaneously. In this paper, we unify the task of anonymization and
visual identity information hiding and propose a novel face privacy protection
method based on diffusion models, dubbed Diff-Privacy. Specifically, we train
our proposed multi-scale image inversion module (MSI) to obtain a set of SDM
format conditional embeddings of the original image. Based on the conditional
embeddings, we design corresponding embedding scheduling strategies and
construct different energy functions during the denoising process to achieve
anonymization and visual identity information hiding. Extensive experiments
have been conducted to validate the effectiveness of our proposed framework in
protecting facial privacy.
</p>
</div>
</dd>
<dt><a name="item354">[354]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.05331" title="Abstract">arXiv:2309.05331</a> [<a href="/pdf/2309.05331" title="Download PDF">pdf</a>, <a href="/format/2309.05331" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Distributed Algebra System for Time Integration on Parallel Computers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Singh%2C+A">Abhinav Singh</a>, 
<a href="/search/cs?searchtype=author&query=Kraatz%2C+L">Landfried Kraatz</a>, 
<a href="/search/cs?searchtype=author&query=Incardona%2C+P">Pietro Incardona</a>, 
<a href="/search/cs?searchtype=author&query=Sbalzarini%2C+I+F">Ivo F. Sbalzarini</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Mathematical Software (cs.MS)</span>; Distributed, Parallel, and Cluster Computing (cs.DC)

</div>
<p class="mathjax">We present a distributed algebra system for efficient and compact
implementation of numerical time integration schemes on parallel computers and
graphics processing units (GPU). The software implementation combines the time
integration library Odeint from Boost with the OpenFPM framework for scalable
scientific computing. Implementing multi-stage, multi-step, or adaptive time
integration methods in distributed-memory parallel codes or on GPUs is
challenging. The present algebra system addresses this by making the time
integration methods from Odeint available in a concise template-expression
language for numerical simulations distributed and parallelized using OpenFPM.
This allows using state-of-the-art time integration schemes, or switching
between schemes, by changing one line of code, while maintaining parallel
scalability. This enables scalable time integration with compact code and
facilitates rapid rewriting and deployment of simulation algorithms. We
benchmark the present software for exponential and sigmoidal dynamics and
present an application example to the 3D Gray-Scott reaction-diffusion problem
on both CPUs and GPUs in only 60 lines of code.
</p>
</div>
</dd>
<dt><a name="item355">[355]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.05334" title="Abstract">arXiv:2309.05334</a> [<a href="/pdf/2309.05334" title="Download PDF">pdf</a>, <a href="/format/2309.05334" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MultIOD: Rehearsal-free Multihead Incremental Object Detector
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Belouadah%2C+E">Eden Belouadah</a>, 
<a href="/search/cs?searchtype=author&query=Dapogny%2C+A">Arnaud Dapogny</a>, 
<a href="/search/cs?searchtype=author&query=Bailly%2C+K">Kevin Bailly</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Under review at the WACV 2024 conference
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Class-Incremental learning (CIL) is the ability of artificial agents to
accommodate new classes as they appear in a stream. It is particularly
interesting in evolving environments where agents have limited access to memory
and computational resources. The main challenge of class-incremental learning
is catastrophic forgetting, the inability of neural networks to retain past
knowledge when learning a new one. Unfortunately, most existing
class-incremental object detectors are applied to two-stage algorithms such as
Faster-RCNN and rely on rehearsal memory to retain past knowledge. We believe
that the current benchmarks are not realistic, and more effort should be
dedicated to anchor-free and rehearsal-free object detection. In this context,
we propose MultIOD, a class-incremental object detector based on CenterNet. Our
main contributions are: (1) we propose a multihead feature pyramid and
multihead detection architecture to efficiently separate class representations,
(2) we employ transfer learning between classes learned initially and those
learned incrementally to tackle catastrophic forgetting, and (3) we use a
class-wise non-max-suppression as a post-processing technique to remove
redundant boxes. Without bells and whistles, our method outperforms a range of
state-of-the-art methods on two Pascal VOC datasets.
</p>
</div>
</dd>
<dt><a name="item356">[356]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.05338" title="Abstract">arXiv:2309.05338</a> [<a href="/pdf/2309.05338" title="Download PDF">pdf</a>, <a href="/format/2309.05338" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Incentive-Based Software Security: Fair Micro-Payments for Writing  Secure Code
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rass%2C+S">Stefan Rass</a>, 
<a href="/search/cs?searchtype=author&query=Pinzger%2C+M">Martin Pinzger</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> presented as a poster at GameSec 2023 (www.gamesec-conf.org)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>; Computer Science and Game Theory (cs.GT)

</div>
<p class="mathjax">We describe a mechanism to create fair and explainable incentives for
software developers to reward contributions to security of a product. We use
cooperative game theory to model the actions of the developer team inside a
risk management workflow, considering the team to actively work against known
threats, and thereby receive micro-payments based on their performance. The use
of the Shapley-value provides natural explanations here directly through (new)
interpretations of the axiomatic grounding of the imputation. The resulting
mechanism is straightforward to implement, and relies on standard tools from
collaborative software development, such as are available for git repositories
and mining thereof. The micropayment model itself is deterministic and does not
rely on uncertain information outside the scope of the developer team or the
enterprise, hence is void of assumptions about adversarial incentives, or user
behavior, up to their role in the risk management process that the mechanism is
part of. We corroborate our model with a worked example based on real-life
data.
</p>
</div>
</dd>
<dt><a name="item357">[357]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.05339" title="Abstract">arXiv:2309.05339</a> [<a href="/pdf/2309.05339" title="Download PDF">pdf</a>, <a href="/format/2309.05339" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PAg-NeRF: Towards fast and efficient end-to-end panoptic 3D  representations for agricultural robotics
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Smitt%2C+C">Claus Smitt</a>, 
<a href="/search/cs?searchtype=author&query=Halstead%2C+M">Michael Halstead</a>, 
<a href="/search/cs?searchtype=author&query=Zimmer%2C+P">Patrick Zimmer</a>, 
<a href="/search/cs?searchtype=author&query=L%C3%A4be%2C+T">Thomas L&#xe4;be</a>, 
<a href="/search/cs?searchtype=author&query=Guclu%2C+E">Esra Guclu</a>, 
<a href="/search/cs?searchtype=author&query=Stachniss%2C+C">Cyrill Stachniss</a>, 
<a href="/search/cs?searchtype=author&query=McCool%2C+C">Chris McCool</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
<p class="mathjax">Precise scene understanding is key for most robot monitoring and intervention
tasks in agriculture. In this work we present PAg-NeRF which is a novel
NeRF-based system that enables 3D panoptic scene understanding. Our
representation is trained using an image sequence with noisy robot odometry
poses and automatic panoptic predictions with inconsistent IDs between frames.
Despite this noisy input, our system is able to output scene geometry,
photo-realistic renders and 3D consistent panoptic representations with
consistent instance IDs. We evaluate this novel system in a very challenging
horticultural scenario and in doing so demonstrate an end-to-end trainable
system that can make use of noisy robot poses rather than precise poses that
have to be pre-calculated. Compared to a baseline approach the peak signal to
noise ratio is improved from 21.34dB to 23.37dB while the panoptic quality
improves from 56.65% to 70.08%. Furthermore, our approach is faster and can be
tuned to improve inference time by more than a factor of 2 while being memory
efficient with approximately 12 times fewer parameters.
</p>
</div>
</dd>
<dt><a name="item358">[358]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.05345" title="Abstract">arXiv:2309.05345</a> [<a href="/pdf/2309.05345" title="Download PDF">pdf</a>, <a href="/format/2309.05345" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Empirical study on the efficiency of Spiking Neural Networks with axonal  delays, and algorithm-hardware benchmarking
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pati%C3%B1o-Saucedo%2C+A">Alberto Pati&#xf1;o-Saucedo</a>, 
<a href="/search/cs?searchtype=author&query=Yousefzadeh%2C+A">Amirreza Yousefzadeh</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+G">Guangzhi Tang</a>, 
<a href="/search/cs?searchtype=author&query=Corradi%2C+F">Federico Corradi</a>, 
<a href="/search/cs?searchtype=author&query=Linares-Barranco%2C+B">Bernab&#xe9; Linares-Barranco</a>, 
<a href="/search/cs?searchtype=author&query=Sifalakis%2C+M">Manolis Sifalakis</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Emerging Technologies (cs.ET)</span>

</div>
<p class="mathjax">The role of axonal synaptic delays in the efficacy and performance of
artificial neural networks has been largely unexplored. In step-based
analog-valued neural network models (ANNs), the concept is almost absent. In
their spiking neuroscience-inspired counterparts, there is hardly a systematic
account of their effects on model performance in terms of accuracy and number
of synaptic operations.This paper proposes a methodology for accounting for
axonal delays in the training loop of deep Spiking Neural Networks (SNNs),
intending to efficiently solve machine learning tasks on data with rich
temporal dependencies. We then conduct an empirical study of the effects of
axonal delays on model performance during inference for the Adding task, a
benchmark for sequential regression, and for the Spiking Heidelberg Digits
dataset (SHD), commonly used for evaluating event-driven models. Quantitative
results on the SHD show that SNNs incorporating axonal delays instead of
explicit recurrent synapses achieve state-of-the-art, over 90% test accuracy
while needing less than half trainable synapses. Additionally, we estimate the
required memory in terms of total parameters and energy consumption of
accomodating such delay-trained models on a modern neuromorphic accelerator.
These estimations are based on the number of synaptic operations and the
reference GF-22nm FDX CMOS technology. As a result, we demonstrate that a
reduced parameterization, which incorporates axonal delays, leads to
approximately 90% energy and memory reduction in digital hardware
implementations for a similar performance in the aforementioned task.
</p>
</div>
</dd>
<dt><a name="item359">[359]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.05346" title="Abstract">arXiv:2309.05346</a> [<a href="/pdf/2309.05346" title="Download PDF">pdf</a>, <a href="/format/2309.05346" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning Geometric Representations of Objects via Interaction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Reichlin%2C+A">Alfredo Reichlin</a>, 
<a href="/search/cs?searchtype=author&query=Marchetti%2C+G+L">Giovanni Luca Marchetti</a>, 
<a href="/search/cs?searchtype=author&query=Yin%2C+H">Hang Yin</a>, 
<a href="/search/cs?searchtype=author&query=Varava%2C+A">Anastasiia Varava</a>, 
<a href="/search/cs?searchtype=author&query=Kragic%2C+D">Danica Kragic</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">We address the problem of learning representations from observations of a
scene involving an agent and an external object the agent interacts with. To
this end, we propose a representation learning framework extracting the
location in physical space of both the agent and the object from unstructured
observations of arbitrary nature. Our framework relies on the actions performed
by the agent as the only source of supervision, while assuming that the object
is displaced by the agent via unknown dynamics. We provide a theoretical
foundation and formally prove that an ideal learner is guaranteed to infer an
isometric representation, disentangling the agent from the object and correctly
extracting their locations. We evaluate empirically our framework on a variety
of scenarios, showing that it outperforms vision-based approaches such as a
state-of-the-art keypoint extractor. We moreover demonstrate how the extracted
representations enable the agent to solve downstream tasks via reinforcement
learning in an efficient manner.
</p>
</div>
</dd>
<dt><a name="item360">[360]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.05347" title="Abstract">arXiv:2309.05347</a> [<a href="/pdf/2309.05347" title="Download PDF">pdf</a>, <a href="/format/2309.05347" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Improving Asynchrony Resilience in Dynamically Available Total-Order  Broadcast Protocols
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=D%27Amato%2C+F">Francesco D&#x27;Amato</a>, 
<a href="/search/cs?searchtype=author&query=Losa%2C+G">Giuliano Losa</a>, 
<a href="/search/cs?searchtype=author&query=Zanolini%2C+L">Luca Zanolini</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>

</div>
<p class="mathjax">Dynamically available total-order broadcast (TOB) protocols are essential in
permissionless systems in which participants may unpredictably go offline and
later come back online. Existing dynamically-available protocols are
synchronous protocols, and they lose their safety guarantees during periods of
asynchrony. This is a major issue in practice.
<br />In this paper, we explore the challenge of tolerating bounded periods of
asynchrony in dynamically-available TOB protocols that ensure safety
deterministically. We propose to trade off assumptions limiting the
online/offline churn rate in exchange for tolerating bounded asynchronous
periods through the use of a configurable message-expiration period. We show
how to apply this idea to a state-of-the-art protocol to make it tolerate
bounded periods of asynchrony.
</p>
</div>
</dd>
<dt><a name="item361">[361]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.05349" title="Abstract">arXiv:2309.05349</a> [<a href="/pdf/2309.05349" title="Download PDF">pdf</a>, <a href="/format/2309.05349" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A survey on real-time 3D scene reconstruction with SLAM methods in  embedded systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Picard%2C+Q">Quentin Picard</a>, 
<a href="/search/cs?searchtype=author&query=Chevobbe%2C+S">Stephane Chevobbe</a>, 
<a href="/search/cs?searchtype=author&query=Darouich%2C+M">Mehdi Darouich</a>, 
<a href="/search/cs?searchtype=author&query=Didier%2C+J">Jean-Yves Didier</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Image and Video Processing (eess.IV)

</div>
<p class="mathjax">The 3D reconstruction of simultaneous localization and mapping (SLAM) is an
important topic in the field for transport systems such as drones, service
robots and mobile AR/VR devices. Compared to a point cloud representation, the
3D reconstruction based on meshes and voxels is particularly useful for
high-level functions, like obstacle avoidance or interaction with the physical
environment. This article reviews the implementation of a visual-based 3D scene
reconstruction pipeline on resource-constrained hardware platforms. Real-time
performances, memory management and low power consumption are critical for
embedded systems. A conventional SLAM pipeline from sensors to 3D
reconstruction is described, including the potential use of deep learning. The
implementation of advanced functions with limited resources is detailed. Recent
systems propose the embedded implementation of 3D reconstruction methods with
different granularities. The trade-off between required accuracy and resource
consumption for real-time localization and reconstruction is one of the open
research questions identified and discussed in this paper.
</p>
</div>
</dd>
<dt><a name="item362">[362]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.05352" title="Abstract">arXiv:2309.05352</a> [<a href="/pdf/2309.05352" title="Download PDF">pdf</a>, <a href="/format/2309.05352" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Neural Discovery of Permutation Subgroups
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Karjol%2C+P">Pavan Karjol</a>, 
<a href="/search/cs?searchtype=author&query=Kashyap%2C+R">Rohan Kashyap</a>, 
<a href="/search/cs?searchtype=author&query=P%2C+P+A">Prathosh A P</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> In International Conference on Artificial Intelligence and
  Statistics, pp. 4668-4678. Volume 206. PMLR, 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">We consider the problem of discovering subgroup $H$ of permutation group
$S_{n}$. Unlike the traditional $H$-invariant networks wherein $H$ is assumed
to be known, we present a method to discover the underlying subgroup, given
that it satisfies certain conditions. Our results show that one could discover
any subgroup of type $S_{k} (k \leq n)$ by learning an $S_{n}$-invariant
function and a linear transformation. We also prove similar results for cyclic
and dihedral subgroups. Finally, we provide a general theorem that can be
extended to discover other subgroups of $S_{n}$. We also demonstrate the
applicability of our results through numerical experiments on image-digit sum
and symmetric polynomial regression tasks.
</p>
</div>
</dd>
<dt><a name="item363">[363]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.05353" title="Abstract">arXiv:2309.05353</a> [<a href="/pdf/2309.05353" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Applied design thinking in urban air mobility: creating the airtaxi  cabin design of the future from a user perspective
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Reimer%2C+F">F.Reimer</a>, 
<a href="/search/cs?searchtype=author&query=Herzig%2C+J">J.Herzig</a>, 
<a href="/search/cs?searchtype=author&query=Winkler%2C+L">L.Winkler</a>, 
<a href="/search/cs?searchtype=author&query=Biedermann%2C+J">J.Biedermann</a>, 
<a href="/search/cs?searchtype=author&query=Meller%2C+F">F.Meller</a>, 
<a href="/search/cs?searchtype=author&query=Nagel%2C+B">B.Nagel</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">In the course of developing digital and future aviation cabin concepts at the
German Aerospace Center, the exploration of user-centered and
acceptance-enhancing methods plays a central role. The challenge here is to
identify the flexible range of requirements of different user groups for a
previously non-existent transport concept, to translate these into a concept
and to generate a rapid evaluation process by the user groups. Therefore, this
paper aims to demonstrate the application of the user-centered Design Thinking
method in the design of cabin for future air taxis. Based on the Design
Thinking approach and its iterative process steps, the direct implementation is
described on the combined airport shuttle and intracity UAM concept. The main
focus is on the identification of key user requirements by means of a focus
group study and the evaluation of initial cabin designs and key ideas by means
of an online survey. Consequently, the creative design process of a digital
prototype will be presented. In addition to an increased awareness and
acceptance among the population towards a novel mode of transportation, the
application of the Design Thinking methodology offers a flexible and
user-centered approach for further testing and simulation scenarios.
</p>
</div>
</dd>
<dt><a name="item364">[364]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.05357" title="Abstract">arXiv:2309.05357</a> [<a href="/pdf/2309.05357" title="Download PDF">pdf</a>, <a href="/format/2309.05357" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> EDAC: Efficient Deployment of Audio Classification Models For COVID-19  Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jovanovi%C4%87%2C+A">Andrej Jovanovi&#x107;</a>, 
<a href="/search/cs?searchtype=author&query=Mihaly%2C+M">Mario Mihaly</a>, 
<a href="/search/cs?searchtype=author&query=Donaldson%2C+L">Lennon Donaldson</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Machine Learning (cs.LG); Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">The global spread of COVID-19 had severe consequences for public health and
the world economy. The quick onset of the pandemic highlighted the potential
benefits of cheap and deployable pre-screening methods to monitor the
prevalence of the disease in a population. Various researchers made use of
machine learning methods in an attempt to detect COVID-19. The solutions
leverage various input features, such as CT scans or cough audio signals, with
state-of-the-art results arising from deep neural network architectures.
However, larger models require more compute; a pertinent consideration when
deploying to the edge. To address this, we first recreated two models that use
cough audio recordings to detect COVID-19. Through applying network pruning and
quantisation, we were able to compress these two architectures without reducing
the model's predictive performance. Specifically, we were able to achieve an
105.76x and an 19.34x reduction in the compressed model file size with
corresponding 1.37x and 1.71x reductions in the inference times of the two
models.
</p>
</div>
</dd>
<dt><a name="item365">[365]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.05358" title="Abstract">arXiv:2309.05358</a> [<a href="/pdf/2309.05358" title="Download PDF">pdf</a>, <a href="/format/2309.05358" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Rescaling method for blow-up solutions of nonlinear wave equations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Benjemaa%2C+M">Mondher Benjemaa</a>, 
<a href="/search/math?searchtype=author&query=Jrajria%2C+A">Aida Jrajria</a>, 
<a href="/search/math?searchtype=author&query=Zaag%2C+H">Hatem Zaag</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 20 pages, 5 figures, 2 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Analysis of PDEs (math.AP)

</div>
<p class="mathjax">We develop a hybrid scheme based on a finite difference scheme and a
rescaling technique to approximate the solution of nonlinear wave equation. In
order to numerically reproduce the blow-up phenomena, we propose a rule of
scaling transformation, which is a variant of what was successfully used in the
case of nonlinear parabolic equations. A careful study of the convergence of
the proposed scheme is carried out and several numerical examples are performed
in illustration.
</p>
</div>
</dd>
<dt><a name="item366">[366]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.05362" title="Abstract">arXiv:2309.05362</a> [<a href="/pdf/2309.05362" title="Download PDF">pdf</a>, <a href="/format/2309.05362" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Mechanized Theory of the Box Calculus
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fourment%2C+J">Joseph Fourment</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+Y">Yichen Xu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Proceedings of the 9th International Workshop on Aliasing, Confinement and Ownership (IWACO '23). ACM, New York, NY, USA, 8 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>; Programming Languages (cs.PL)

</div>
<p class="mathjax">The capture calculus is an extension of System F&lt;: that tracks free variables
of terms in their type, allowing one to represent capabilities while limiting
their scope. While previous calculi had mechanized soundness proofs -- notably
System CF&lt;: -- the latest version, namely the box calculus (System CC&lt;:box),
only had a paper proof. We present here our work on mechanizing the theory of
the box calculus in Coq, and the challenges encountered along the way. While
doing so, we motivate the current design of capture calculus, in particular the
concept of boxes, from both user and metatheoretical standpoints. Our
mechanization is complete and available on GitHub.
</p>
</div>
</dd>
<dt><a name="item367">[367]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.05366" title="Abstract">arXiv:2309.05366</a> [<a href="/pdf/2309.05366" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Incipient Slip-Based Rotation Measurement via Visuotactile Sensing  During In-Hand Object Pivoting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+M">Mingxuan Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Y+H">Yen Hang Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+T">Tiemin Li</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+Y">Yao Jiang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, 9 figures, submitted to ICRA 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">In typical in-hand manipulation tasks represented by object pivoting, the
real-time perception of rotational slippage has been proven beneficial for
improving the dexterity and stability of robotic hands. An effective strategy
is to obtain the contact properties for measuring rotation angle through
visuotactile sensing. However, existing methods for rotation estimation did not
consider the impact of the incipient slip during the pivoting process, which
introduces measurement errors and makes it hard to determine the boundary
between stable contact and macro slip. This paper describes a generalized 2-d
contact model under pivoting, and proposes a rotation measurement method based
on the line-features in the stick region. The proposed method was applied to
the Tac3D vision-based tactile sensors using continuous marker patterns.
Experiments show that the rotation measurement system could achieve an average
static measurement error of 0.17 degree and an average dynamic measurement
error of 1.34 degree. Besides, the proposed method requires no training data
and can achieve real-time sensing during the in-hand object pivoting.
</p>
</div>
</dd>
<dt><a name="item368">[368]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.05369" title="Abstract">arXiv:2309.05369</a> [<a href="/pdf/2309.05369" title="Download PDF">pdf</a>, <a href="/format/2309.05369" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Adaptive Address Family Selection for Latency-Sensitive Applications on  Dual-stack Hosts
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Piraux%2C+M">Maxime Piraux</a>, 
<a href="/search/cs?searchtype=author&query=Bonaventure%2C+O">Olivier Bonaventure</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>

</div>
<p class="mathjax">Latency is becoming a key factor of performance for Internet applications and
has triggered a number of changes in its protocols. Our work revisits the
impact on latency of address family selection in dual-stack hosts. Through RIPE
Atlas measurements, we analyse the address families latency difference and
establish two requirements based on our findings for a latency-focused
selection mechanism. First, the address family should be chosen per
destination. Second, the choice should be able to evolve over time dynamically.
We propose and implement a solution formulated as an online learning problem
balancing exploration and exploitation. We validate our solution in simulations
based on RIPE Atlas measurements, implement and evaluate our prototype in four
access networks using Chrome and popular web services. We demonstrate the
ability of our solution to converge towards the lowest-latency address family
and improve the latency of transport connections used by applications.
</p>
</div>
</dd>
<dt><a name="item369">[369]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.05370" title="Abstract">arXiv:2309.05370</a> [<a href="/pdf/2309.05370" title="Download PDF">pdf</a>, <a href="/format/2309.05370" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Opinion Dynamics in Two-Step Process: Message Sources, Opinion Leaders  and Normal Agents
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Huisheng Wang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yuejiang Li</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+Y">Yiqing Lin</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+H+V">H. Vicky Zhao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">According to mass media theory, the dissemination of messages and the
evolution of opinions in social networks follow a two-step process. First,
opinion leaders receive the message from the message sources, and then they
transmit their opinions to normal agents. However, most opinion models only
consider the evolution of opinions within a single network, which fails to
capture the two-step process accurately. To address this limitation, we propose
a unified framework called the Two-Step Model, which analyzes the communication
process among message sources, opinion leaders, and normal agents. In this
study, we examine the steady-state opinions and stability of the Two-Step
Model. Our findings reveal that several factors, such as message distribution,
initial opinion, level of stubbornness, and preference coefficient, influence
the sample mean and variance of steady-state opinions. Notably, normal agents'
opinions tend to be influenced by opinion leaders in the two-step process. We
also conduct numerical and social experiments to validate the accuracy of the
Two-Step Model, which outperforms other models on average. Our results provide
valuable insights into the factors that shape social opinions and can guide the
development of effective strategies for opinion guidance in social networks.
</p>
</div>
</dd>
<dt><a name="item370">[370]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.05371" title="Abstract">arXiv:2309.05371</a> [<a href="/pdf/2309.05371" title="Download PDF">pdf</a>, <a href="/format/2309.05371" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exploring Minecraft Settlement Generators with Generative Shift Analysis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Herv%C3%A9%2C+J">Jean-Baptiste Herv&#xe9;</a>, 
<a href="/search/cs?searchtype=author&query=Withington%2C+O">Oliver Withington</a>, 
<a href="/search/cs?searchtype=author&query=Herv%C3%A9%2C+M">Marion Herv&#xe9;</a>, 
<a href="/search/cs?searchtype=author&query=Tokarchuk%2C+L">Laurissa Tokarchuk</a>, 
<a href="/search/cs?searchtype=author&query=Salge%2C+C">Christoph Salge</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
<p class="mathjax">With growing interest in Procedural Content Generation (PCG) it becomes
increasingly important to develop methods and tools for evaluating and
comparing alternative systems. There is a particular lack regarding the
evaluation of generative pipelines, where a set of generative systems work in
series to make iterative changes to an artifact. We introduce a novel method
called Generative Shift for evaluating the impact of individual stages in a PCG
pipeline by quantifying the impact that a generative process has when it is
applied to a pre-existing artifact. We explore this technique by applying it to
a very rich dataset of Minecraft game maps produced by a set of alternative
settlement generators developed as part of the Generative Design in Minecraft
Competition (GDMC), all of which are designed to produce appropriate
settlements for a pre-existing map. While this is an early exploration of this
technique we find it to be a promising lens to apply to PCG evaluation, and we
are optimistic about the potential of Generative Shift to be a domain-agnostic
method for evaluating generative pipelines.
</p>
</div>
</dd>
<dt><a name="item371">[371]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.05372" title="Abstract">arXiv:2309.05372</a> [<a href="/pdf/2309.05372" title="Download PDF">pdf</a>, <a href="/format/2309.05372" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Peaceman Well Block Problem For Time-Dependent Flows of Compressible  Fluid
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Ibraguimov%2C+A">A. Ibraguimov</a>, 
<a href="/search/math?searchtype=author&query=Zakirov%2C+E">E. Zakirov</a>, 
<a href="/search/math?searchtype=author&query=Indrupskiy%2C+I">I. Indrupskiy</a>, 
<a href="/search/math?searchtype=author&query=Anikeev%2C+D">D. Anikeev</a>, 
<a href="/search/math?searchtype=author&query=Zhaglova%2C+A">A. Zhaglova</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">We consider sewing machinery between finite difference and analytical
solutions defined at different scales: far away and near the source of the
perturbation of the flow. One of the essences of the approach is that coarse
problem and boundary value problem in the proxy of the source model two
different flows. In his remarkable paper Peaceman propose a framework how to
deal with solutions defined on different scale for linear \textbf{time
independent} problem by introducing famous, Peaceman well block radius. In this
article we consider novel problem how to solve this issue for transient flow
generated by compressiblity of the fluid. We are proposing method to glue
solution via total fluxes, which is predefined on coarse grid and changes in
the pressure, due to compressibility, in the block containing
production(injection) well. It is important to mention that the coarse solution
"does not see" boundary. From industrial point of view our report provide
mathematical tool for analytical interpretation of simulated data for
compressible fluid flow around a well in a porous medium. It can be considered
as a mathematical "shirt" on famous Peaceman well-block radius formula for
linear (Darcy) transient flow but can be applied in much more general scenario.
In the article we use Einstein approach to derive Material Balance equation, a
key instrument to define $R_0$. We will enlarge Einstein approach for three
regimes of the Darcy and non-Darcy flows for compressible fluid(time
dependent): $\textbf{I}. Stationary ; \textbf{II}. Pseudo \ Stationary(PSS) ;
\textbf{III}. Boundary \ Dominated(BD).$
</p>
</div>
</dd>
<dt><a name="item372">[372]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.05373" title="Abstract">arXiv:2309.05373</a> [<a href="/pdf/2309.05373" title="Download PDF">pdf</a>, <a href="/format/2309.05373" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SPEChpc 2021 Benchmarks on Ice Lake and Sapphire Rapids Infiniband  Clusters: A Performance and Energy Case Study
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Afzal%2C+A">Ayesha Afzal</a>, 
<a href="/search/cs?searchtype=author&query=Hager%2C+G">Georg Hager</a>, 
<a href="/search/cs?searchtype=author&query=Wellein%2C+G">Gerhard Wellein</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages, 6 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Performance (cs.PF)</span>; Distributed, Parallel, and Cluster Computing (cs.DC)

</div>
<p class="mathjax">In this work, fundamental performance, power, and energy characteristics of
the full SPEChpc 2021 benchmark suite are assessed on two different clusters
based on Intel Ice Lake and Sapphire Rapids CPUs using the MPI-only codes'
variants. We use memory bandwidth, data volume, and scalability metrics in
order to categorize the benchmarks and pinpoint relevant performance and
scalability bottlenecks on the node and cluster levels. Common patterns such as
memory bandwidth limitation, dominating communication and synchronization
overhead, MPI serialization, superlinear scaling, and alignment issues could be
identified, in isolation or in combination, showing that SPEChpc 2021 is
representative of many HPC workloads. Power dissipation and energy measurements
indicate that the modern Intel server CPUs have such a high idle power level
that race-to-idle is the paramount strategy for energy to solution and
energy-delay product minimization. On the chip level, only memory-bound code
shows a clear advantage of Sapphire Rapids compared to Ice Lake in terms of
energy to solution.
</p>
</div>
</dd>
<dt><a name="item373">[373]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.05375" title="Abstract">arXiv:2309.05375</a> [<a href="/pdf/2309.05375" title="Download PDF">pdf</a>, <a href="/format/2309.05375" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CNN or ViT? Revisiting Vision Transformers Through the Lens of  Convolution
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+C">Chenghao Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+C">Chaoning Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">The success of Vision Transformer (ViT) has been widely reported on a wide
range of image recognition tasks. The merit of ViT over CNN has been largely
attributed to large training datasets or auxiliary pre-training. Without
pre-training, the performance of ViT on small datasets is limited because the
global self-attention has limited capacity in local modeling. Towards boosting
ViT on small datasets without pre-training, this work improves its local
modeling by applying a weight mask on the original self-attention matrix. A
straightforward way to locally adapt the self-attention matrix can be realized
by an element-wise learnable weight mask (ELM), for which our preliminary
results show promising results. However, the element-wise simple learnable
weight mask not only induces a non-trivial additional parameter overhead but
also increases the optimization complexity. To this end, this work proposes a
novel Gaussian mixture mask (GMM) in which one mask only has two learnable
parameters and it can be conveniently used in any ViT variants whose attention
mechanism allows the use of masks. Experimental results on multiple small
datasets demonstrate that the effectiveness of our proposed Gaussian mask for
boosting ViTs for free (almost zero additional parameter or computation cost).
Our code will be publicly available at
\href{https://github.com/CatworldLee/Gaussian-Mixture-Mask-Attention}{https://github.com/CatworldLee/Gaussian-Mixture-Mask-Attention}.
</p>
</div>
</dd>
<dt><a name="item374">[374]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.05377" title="Abstract">arXiv:2309.05377</a> [<a href="/pdf/2309.05377" title="Download PDF">pdf</a>, <a href="/format/2309.05377" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Truthful Interval Covering
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Deligkas%2C+A">Argyrios Deligkas</a>, 
<a href="/search/cs?searchtype=author&query=Filos-Ratsikas%2C+A">Aris Filos-Ratsikas</a>, 
<a href="/search/cs?searchtype=author&query=Voudouris%2C+A+A">Alexandros A. Voudouris</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>

</div>
<p class="mathjax">We initiate the study of a novel problem in mechanism design without money,
which we term Truthful Interval Covering (TIC). An instance of TIC consists of
a set of agents each associated with an individual interval on a line, and the
objective is to decide where to place a covering interval to minimize the total
social cost of the agents, which is determined by the intersection of this
interval with their individual ones. This fundamental problem can model
situations of provisioning a public good, such as the use of power generators
to prevent or mitigate load shedding in developing countries. In the strategic
version of the problem, the agents wish to minimize their individual costs, and
might misreport the position and/or length of their intervals to achieve that.
Our goal is to design truthful mechanisms to prevent such strategic misreports
and achieve good approximations to the best possible social cost. We consider
the fundamental setting of known intervals with equal lengths and provide tight
bounds on the approximation ratios achieved by truthful deterministic
mechanisms. We also design a randomized truthful mechanism that outperforms all
possible deterministic ones. Finally, we highlight a plethora of natural
extensions of our model for future work, as well as some natural limitations of
those settings.
</p>
</div>
</dd>
<dt><a name="item375">[375]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.05378" title="Abstract">arXiv:2309.05378</a> [<a href="/pdf/2309.05378" title="Download PDF">pdf</a>, <a href="/format/2309.05378" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Steps Towards Satisficing Distributed Dynamic Team Trust
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hunt%2C+E+R">Edmund R. Hunt</a>, 
<a href="/search/cs?searchtype=author&query=Baber%2C+C">Chris Baber</a>, 
<a href="/search/cs?searchtype=author&query=Sobhani%2C+M">Mehdi Sobhani</a>, 
<a href="/search/cs?searchtype=author&query=Milivojevic%2C+S">Sanja Milivojevic</a>, 
<a href="/search/cs?searchtype=author&query=Yusuf%2C+S">Sagir Yusuf</a>, 
<a href="/search/cs?searchtype=author&query=Musolesi%2C+M">Mirco Musolesi</a>, 
<a href="/search/cs?searchtype=author&query=Waterson%2C+P">Patrick Waterson</a>, 
<a href="/search/cs?searchtype=author&query=Maynard%2C+S">Sally Maynard</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Human-Computer Interaction (cs.HC); Robotics (cs.RO)

</div>
<p class="mathjax">Defining and measuring trust in dynamic, multiagent teams is important in a
range of contexts, particularly in defense and security domains. Team members
should be trusted to work towards agreed goals and in accordance with shared
values. In this paper, our concern is with the definition of goals and values
such that it is possible to define 'trust' in a way that is interpretable, and
hence usable, by both humans and robots. We argue that the outcome of team
activity can be considered in terms of 'goal', 'individual/team values', and
'legal principles'. We question whether alignment is possible at the level of
'individual/team values', or only at the 'goal' and 'legal principles' levels.
We argue for a set of metrics to define trust in human-robot teams that are
interpretable by human or robot team members, and consider an experiment that
could demonstrate the notion of 'satisficing trust' over the course of a
simulated mission.
</p>
</div>
</dd>
<dt><a name="item376">[376]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.05379" title="Abstract">arXiv:2309.05379</a> [<a href="/pdf/2309.05379" title="Download PDF">pdf</a>, <a href="/ps/2309.05379" title="Download PostScript">ps</a>, <a href="/format/2309.05379" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On Truthful Constrained Facility Location with Max-Variant Cost
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lotfi%2C+M">Mohammad Lotfi</a>, 
<a href="/search/cs?searchtype=author&query=Voudouris%2C+A+A">Alexandros A. Voudouris</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>

</div>
<p class="mathjax">We consider a problem where agents are positioned on a line, have approval
preferences over two facilities, and their cost is the maximum distance from
their approved facilities. The goal is to decide the facility locations to
minimize the total and the max cost, while incentivizing the agents to be
truthful. We show that a simple strategyproof mechanism is $7$-approximate for
the total cost and $5$-approximate for the max cost, thus improving upon the
previous bounds of $2n+1$ and $9$.
</p>
</div>
</dd>
<dt><a name="item377">[377]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.05380" title="Abstract">arXiv:2309.05380</a> [<a href="/pdf/2309.05380" title="Download PDF">pdf</a>, <a href="/format/2309.05380" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Collective PV-RCNN: A Novel Fusion Technique using Collective Detections  for Enhanced Local LiDAR-Based Perception
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Teufel%2C+S">Sven Teufel</a>, 
<a href="/search/cs?searchtype=author&query=Gamerdinger%2C+J">J&#xf6;rg Gamerdinger</a>, 
<a href="/search/cs?searchtype=author&query=Volk%2C+G">Georg Volk</a>, 
<a href="/search/cs?searchtype=author&query=Bringmann%2C+O">Oliver Bringmann</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> accepted at IEEE ITSC 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Comprehensive perception of the environment is crucial for the safe operation
of autonomous vehicles. However, the perception capabilities of autonomous
vehicles are limited due to occlusions, limited sensor ranges, or environmental
influences. Collective Perception (CP) aims to mitigate these problems by
enabling the exchange of information between vehicles. A major challenge in CP
is the fusion of the exchanged information. Due to the enormous bandwidth
requirement of early fusion approaches and the interchangeability issues of
intermediate fusion approaches, only the late fusion of shared detections is
practical. Current late fusion approaches neglect valuable information for
local detection, this is why we propose a novel fusion method to fuse the
detections of cooperative vehicles within the local LiDAR-based detection
pipeline. Therefore, we present Collective PV-RCNN (CPV-RCNN), which extends
the PV-RCNN++ framework to fuse collective detections. Code is available at
https://github.com/ekut-es
</p>
</div>
</dd>
<dt><a name="item378">[378]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.05381" title="Abstract">arXiv:2309.05381</a> [<a href="/pdf/2309.05381" title="Download PDF">pdf</a>, <a href="/format/2309.05381" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Hazards in Deep Learning Testing: Prevalence, Impact and Recommendations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ghamizi%2C+S">Salah Ghamizi</a>, 
<a href="/search/cs?searchtype=author&query=Cordy%2C+M">Maxime Cordy</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+Y">Yuejun Guo</a>, 
<a href="/search/cs?searchtype=author&query=Papadakis%2C+M">Mike Papadakis</a>, 
<a href="/search/cs?searchtype=author&query=Traon%2C+A+Y+L">And Yves Le Traon</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Much research on Machine Learning testing relies on empirical studies that
evaluate and show their potential. However, in this context empirical results
are sensitive to a number of parameters that can adversely impact the results
of the experiments and potentially lead to wrong conclusions (Type I errors,
i.e., incorrectly rejecting the Null Hypothesis). To this end, we survey the
related literature and identify 10 commonly adopted empirical evaluation
hazards that may significantly impact experimental results. We then perform a
sensitivity analysis on 30 influential studies that were published in top-tier
SE venues, against our hazard set and demonstrate their criticality. Our
findings indicate that all 10 hazards we identify have the potential to
invalidate experimental findings, such as those made by the related literature,
and should be handled properly. Going a step further, we propose a point set of
10 good empirical practices that has the potential to mitigate the impact of
the hazards. We believe our work forms the first step towards raising awareness
of the common pitfalls and good practices within the software engineering
community and hopefully contribute towards setting particular expectations for
empirical research in the field of deep learning testing.
</p>
</div>
</dd>
<dt><a name="item379">[379]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.05382" title="Abstract">arXiv:2309.05382</a> [<a href="/pdf/2309.05382" title="Download PDF">pdf</a>, <a href="/format/2309.05382" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CANF-VC++: Enhancing Conditional Augmented Normalizing Flows for Video  Compression with Advanced Techniques
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+P">Peng-Yu Chen</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+W">Wen-Hsiao Peng</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Multimedia (cs.MM)</span>

</div>
<p class="mathjax">Video has become the predominant medium for information dissemination,
driving the need for efficient video codecs. Recent advancements in learned
video compression have shown promising results, surpassing traditional codecs
in terms of coding efficiency. However, challenges remain in integrating
fragmented techniques and incorporating new tools into existing codecs. In this
paper, we comprehensively review the state-of-the-art CANF-VC codec and propose
CANF-VC++, an enhanced version that addresses these challenges. We
systematically explore architecture design, reference frame type, training
procedure, and entropy coding efficiency, leading to substantial coding
improvements. CANF-VC++ achieves significant Bj{\o}ntegaard-Delta rate savings
on conventional datasets UVG, HEVC Class B and MCL-JCV, outperforming the
baseline CANF-VC and even the H.266 reference software VTM. Our work
demonstrates the potential of integrating advancements in video compression and
serves as inspiration for future research in the field.
</p>
</div>
</dd>
<dt><a name="item380">[380]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.05386" title="Abstract">arXiv:2309.05386</a> [<a href="/pdf/2309.05386" title="Download PDF">pdf</a>, <a href="/format/2309.05386" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Data-Driven Model Reduction and Nonlinear Model Predictive Control of an  Air Separation Unit by Applied Koopman Theory
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Schulze%2C+J+C">Jan C. Schulze</a>, 
<a href="/search/eess?searchtype=author&query=Doncevic%2C+D+T">Danimir T. Doncevic</a>, 
<a href="/search/eess?searchtype=author&query=Erwes%2C+N">Nils Erwes</a>, 
<a href="/search/eess?searchtype=author&query=Mitsos%2C+A">Alexander Mitsos</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Foundations of Computer Aided Process Operations / Chemical
  Process Control (FOCAPO), 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Achieving real-time capability is an essential prerequisite for the
industrial implementation of nonlinear model predictive control (NMPC).
Data-driven model reduction offers a way to obtain low-order control models
from complex digital twins. In particular, data-driven approaches require
little expert knowledge of the particular process and its model, and provide
reduced models of a well-defined generic structure. Herein, we apply our
recently proposed data-driven reduction strategy based on Koopman theory
[Schulze et al. (2022), Comput. Chem. Eng.] to generate a low-order control
model of an air separation unit (ASU). The reduced Koopman model combines
autoencoders and linear latent dynamics and is constructed using machine
learning. Further, we present an NMPC implementation that uses derivative
computation tailored to the fixed block structure of reduced Koopman models.
Our reduction approach with tailored NMPC implementation enables real-time NMPC
of an ASU at an average CPU time decrease by 98 %.
</p>
</div>
</dd>
<dt><a name="item381">[381]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.05388" title="Abstract">arXiv:2309.05388</a> [<a href="/pdf/2309.05388" title="Download PDF">pdf</a>, <a href="/format/2309.05388" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Robust Single Rotation Averaging Revisited
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lee%2C+S+H">Seong Hun Lee</a>, 
<a href="/search/cs?searchtype=author&query=Civera%2C+J">Javier Civera</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Robotics (cs.RO)

</div>
<p class="mathjax">In this work, we propose a novel method for robust single rotation averaging
that can efficiently handle an extremely large fraction of outliers. Our
approach is to minimize the total truncated least unsquared deviations (TLUD)
cost of geodesic distances. The proposed algorithm consists of three steps:
First, we consider each input rotation as a potential initial solution and
choose the one that yields the least sum of truncated chordal deviations. Next,
we obtain the inlier set using the initial solution and compute its chordal
$L_2$-mean. Finally, starting from this estimate, we iteratively compute the
geodesic $L_1$-mean of the inliers using the Weiszfeld algorithm on $SO(3)$. An
extensive evaluation shows that our method is robust against up to 99% outliers
given a sufficient number of accurate inliers, outperforming the current state
of the art.
</p>
</div>
</dd>
<dt><a name="item382">[382]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.05389" title="Abstract">arXiv:2309.05389</a> [<a href="/pdf/2309.05389" title="Download PDF">pdf</a>, <a href="/ps/2309.05389" title="Download PostScript">ps</a>, <a href="/format/2309.05389" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Soundness and Completeness of a Model-Checking Proof System for CTL
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Schuppe%2C+G+F">Georg Friedrich Schuppe</a>, 
<a href="/search/cs?searchtype=author&query=Gurov%2C+D">Dilian Gurov</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>

</div>
<p class="mathjax">We propose a local model-checking proof system for a fragment of CTL. The
rules of the proof system are motivated by the well-known fixed-point
characterisation of CTL based on unfolding of the temporal operators. To
guarantee termination of proofs, we tag the sequents of our proof system with
the set of states that have already been explored for the respective temporal
formula. We define the semantics of tagged sequents, and then state and prove
soundness and completeness of the proof system, as well as termination of proof
search for finite-state models.
</p>
</div>
</dd>
<dt><a name="item383">[383]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.05391" title="Abstract">arXiv:2309.05391</a> [<a href="/pdf/2309.05391" title="Download PDF">pdf</a>, <a href="/format/2309.05391" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Career Path Recommendations for Long-term Income Maximization: A  Reinforcement Learning Approach
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Avlonitis%2C+S">Spyros Avlonitis</a>, 
<a href="/search/cs?searchtype=author&query=Lavi%2C+D">Dor Lavi</a>, 
<a href="/search/cs?searchtype=author&query=Mansoury%2C+M">Masoud Mansoury</a>, 
<a href="/search/cs?searchtype=author&query=Graus%2C+D">David Graus</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> accepted for publication at RecSys in HR '23 (at the 17th ACM Conference on Recommender Systems)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">This study explores the potential of reinforcement learning algorithms to
enhance career planning processes. Leveraging data from Randstad The
Netherlands, the study simulates the Dutch job market and develops strategies
to optimize employees' long-term income. By formulating career planning as a
Markov Decision Process (MDP) and utilizing machine learning algorithms such as
Sarsa, Q-Learning, and A2C, we learn optimal policies that recommend career
paths with high-income occupations and industries. The results demonstrate
significant improvements in employees' income trajectories, with RL models,
particularly Q-Learning and Sarsa, achieving an average increase of 5% compared
to observed career paths. The study acknowledges limitations, including narrow
job filtering, simplifications in the environment formulation, and assumptions
regarding employment continuity and zero application costs. Future research can
explore additional objectives beyond income optimization and address these
limitations to further enhance career planning processes.
</p>
</div>
</dd>
<dt><a name="item384">[384]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.05395" title="Abstract">arXiv:2309.05395</a> [<a href="/pdf/2309.05395" title="Download PDF">pdf</a>, <a href="/format/2309.05395" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Practical Homomorphic Aggregation for Byzantine ML
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Choffrut%2C+A">Antoine Choffrut</a>, 
<a href="/search/cs?searchtype=author&query=Guerraoui%2C+R">Rachid Guerraoui</a>, 
<a href="/search/cs?searchtype=author&query=Pinot%2C+R">Rafael Pinot</a>, 
<a href="/search/cs?searchtype=author&query=Sirdey%2C+R">Renaud Sirdey</a>, 
<a href="/search/cs?searchtype=author&query=Stephan%2C+J">John Stephan</a>, 
<a href="/search/cs?searchtype=author&query=Zuber%2C+M">Martin Zuber</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Cryptography and Security (cs.CR); Distributed, Parallel, and Cluster Computing (cs.DC)

</div>
<p class="mathjax">Due to the large-scale availability of data, machine learning (ML) algorithms
are being deployed in distributed topologies, where different nodes collaborate
to train ML models over their individual data by exchanging model-related
information (e.g., gradients) with a central server. However, distributed
learning schemes are notably vulnerable to two threats. First, Byzantine nodes
can single-handedly corrupt the learning by sending incorrect information to
the server, e.g., erroneous gradients. The standard approach to mitigate such
behavior is to use a non-linear robust aggregation method at the server.
Second, the server can violate the privacy of the nodes. Recent attacks have
shown that exchanging (unencrypted) gradients enables a curious server to
recover the totality of the nodes' data. The use of homomorphic encryption
(HE), a gold standard security primitive, has extensively been studied as a
privacy-preserving solution to distributed learning in non-Byzantine scenarios.
However, due to HE's large computational demand especially for high-dimensional
ML models, there has not yet been any attempt to design purely homomorphic
operators for non-linear robust aggregators. In this work, we present SABLE,
the first completely homomorphic and Byzantine robust distributed learning
algorithm. SABLE essentially relies on a novel plaintext encoding method that
enables us to implement the robust aggregator over batching-friendly BGV.
Moreover, this encoding scheme also accelerates state-of-the-art homomorphic
sorting with larger security margins and smaller ciphertext size. We perform
extensive experiments on image classification tasks and show that our algorithm
achieves practical execution times while matching the ML performance of its
non-private counterpart.
</p>
</div>
</dd>
<dt><a name="item385">[385]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.05396" title="Abstract">arXiv:2309.05396</a> [<a href="/pdf/2309.05396" title="Download PDF">pdf</a>, <a href="/format/2309.05396" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SlideSpeech: A Large-Scale Slide-Enriched Audio-Visual Corpus
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Haoxu Wang</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+F">Fan Yu</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+X">Xian Shi</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yuezhang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+S">Shiliang Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">Multi-Modal automatic speech recognition (ASR) techniques aim to leverage
additional modalities to improve the performance of speech recognition systems.
While existing approaches primarily focus on video or contextual information,
the utilization of extra supplementary textual information has been overlooked.
Recognizing the abundance of online conference videos with slides, which
provide rich domain-specific information in the form of text and images, we
release SlideSpeech, a large-scale audio-visual corpus enriched with slides.
The corpus contains 1,705 videos, 1,000+ hours, with 473 hours of high-quality
transcribed speech. Moreover, the corpus contains a significant amount of
real-time synchronized slides. In this work, we present the pipeline for
constructing the corpus and propose baseline methods for utilizing text
information in the visual slide context. Through the application of keyword
extraction and contextual ASR methods in the benchmark system, we demonstrate
the potential of improving speech recognition performance by incorporating
textual information from supplementary video slides.
</p>
</div>
</dd>
<dt><a name="item386">[386]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.05404" title="Abstract">arXiv:2309.05404</a> [<a href="/pdf/2309.05404" title="Download PDF">pdf</a>, <a href="/format/2309.05404" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Physics-informed reinforcement learning via probabilistic co-adjustment  functions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wannawas%2C+N">Nat Wannawas</a>, 
<a href="/search/cs?searchtype=author&query=Faisal%2C+A+A">A. Aldo Faisal</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Systems and Control (eess.SY)

</div>
<p class="mathjax">Reinforcement learning of real-world tasks is very data inefficient, and
extensive simulation-based modelling has become the dominant approach for
training systems. However, in human-robot interaction and many other real-world
settings, there is no appropriate one-model-for-all due to differences in
individual instances of the system (e.g. different people) or necessary
oversimplifications in the simulation models. This requires two approaches: 1.
either learning the individual system's dynamics approximately from data which
requires data-intensive training or 2. using a complete digital twin of the
instances, which may not be realisable in many cases. We introduce two
approaches: co-kriging adjustments (CKA) and ridge regression adjustment (RRA)
as novel ways to combine the advantages of both approaches. Our adjustment
methods are based on an auto-regressive AR1 co-kriging model that we integrate
with GP priors. This yield a data- and simulation-efficient way of using
simplistic simulation models (e.g., simple two-link model) and rapidly adapting
them to individual instances (e.g., biomechanics of individual people). Using
CKA and RRA, we obtain more accurate uncertainty quantification of the entire
system's dynamics than pure GP-based and AR1 methods. We demonstrate the
efficiency of co-kriging adjustment with an interpretable reinforcement
learning control example, learning to control a biomechanical human arm using
only a two-link arm simulation model (offline part) and CKA derived from a
small amount of interaction data (on-the-fly online). Our method unlocks an
efficient and uncertainty-aware way to implement reinforcement learning methods
in real world complex systems for which only imperfect simulation models exist.
</p>
</div>
</dd>
<dt><a name="item387">[387]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.05416" title="Abstract">arXiv:2309.05416</a> [<a href="/pdf/2309.05416" title="Download PDF">pdf</a>, <a href="/format/2309.05416" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards characterization of edge-cloud continuum
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Khalyeyev%2C+D">Danylo Khalyeyev</a>, 
<a href="/search/cs?searchtype=author&query=Bure%C5%A1%2C+T">Tom&#xe1;&#x161; Bure&#x161;</a>, 
<a href="/search/cs?searchtype=author&query=Hn%C4%9Btynka%2C+P">Petr Hn&#x11b;tynka</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>

</div>
<p class="mathjax">Internet of Things and cloud computing are two technological paradigms that
reached widespread adoption in recent years. These paradigms are complementary:
IoT applications often rely on the computational resources of the cloud to
process the data generated by IoT devices. The highly distributed nature of IoT
applications and the giant amounts of data involved led to significant parts of
computation being moved from the centralized cloud to the edge of the network.
This gave rise to new hybrid paradigms, such as edge-cloud computing and fog
computing. Recent advances in IoT hardware, combined with the continued
increase in complexity and variability of the edge-cloud environment, led to an
emergence of a new vision of edge-cloud continuum: the next step of integration
between the IoT and the cloud, where software components can seamlessly move
between the levels of computational hierarchy. However, as this concept is very
new, there is still no established view of what exactly it entails. Several
views on the future edge-cloud continuum have been proposed, each with its own
set of requirements and expected characteristics. In order to move the
discussion of this concept forward, these views need to be put into a coherent
picture. In this paper, we provide a review and generalization of the existing
literature on edge-cloud continuum, point out its expected features, and
discuss the challenges that need to be addressed in order to bring about this
envisioned environment for the next generation of smart distributed
applications.
</p>
</div>
</dd>
<dt><a name="item388">[388]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.05417" title="Abstract">arXiv:2309.05417</a> [<a href="/pdf/2309.05417" title="Download PDF">pdf</a>, <a href="/format/2309.05417" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Grabbing power line conductors based on the measurements of the magnetic  field strength
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Vasiljevic%2C+G">Goran Vasiljevic</a>, 
<a href="/search/cs?searchtype=author&query=Martinovic%2C+D">Dean Martinovic</a>, 
<a href="/search/cs?searchtype=author&query=Orsag%2C+M">Matko Orsag</a>, 
<a href="/search/cs?searchtype=author&query=Bogdan%2C+S">Stjepan Bogdan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 2021 Aerial Robotic Systems Physically Interacting with the Environment (AIRPHARO). arXiv admin note: text overlap with <a href="/abs/2206.09169">arXiv:2206.09169</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">This paper presents the method for the localization and grabbing of the long
straight conductor based only on the magnetic field generated by the
alternating current flowing through the conductor. The method uses two
magnetometers mounted on the robot arm end-effector for localization. This
location is then used to determine needed robot movement in order to grab the
conductor. The method was tested in the laboratory conditions using the Schunk
LWA 4P 6-axis robot arm.
</p>
</div>
</dd>
<dt><a name="item389">[389]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.05418" title="Abstract">arXiv:2309.05418</a> [<a href="/pdf/2309.05418" title="Download PDF">pdf</a>, <a href="/format/2309.05418" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FlowIBR: Leveraging Pre-Training for Efficient Neural Image-Based  Rendering of Dynamic Scenes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=B%C3%BCsching%2C+M">Marcel B&#xfc;sching</a>, 
<a href="/search/cs?searchtype=author&query=Bengtson%2C+J">Josef Bengtson</a>, 
<a href="/search/cs?searchtype=author&query=Nilsson%2C+D">David Nilsson</a>, 
<a href="/search/cs?searchtype=author&query=Bj%C3%B6rkman%2C+M">M&#xe5;rten Bj&#xf6;rkman</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">We introduce a novel approach for monocular novel view synthesis of dynamic
scenes. Existing techniques already show impressive rendering quality but tend
to focus on optimization within a single scene without leveraging prior
knowledge. This limitation has been primarily attributed to the lack of
datasets of dynamic scenes available for training and the diversity of scene
dynamics. Our method FlowIBR circumvents these issues by integrating a neural
image-based rendering method, pre-trained on a large corpus of widely available
static scenes, with a per-scene optimized scene flow field. Utilizing this flow
field, we bend the camera rays to counteract the scene dynamics, thereby
presenting the dynamic scene as if it were static to the rendering network. The
proposed method reduces per-scene optimization time by an order of magnitude,
achieving comparable results to existing methods - all on a single
consumer-grade GPU.
</p>
</div>
</dd>
<dt><a name="item390">[390]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.05425" title="Abstract">arXiv:2309.05425</a> [<a href="/pdf/2309.05425" title="Download PDF">pdf</a>, <a href="/ps/2309.05425" title="Download PostScript">ps</a>, <a href="/format/2309.05425" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On optimal recovering high order partial derivatives of bivariate  functions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Semenova%2C+Y+V">Y.V. Semenova</a>, 
<a href="/search/math?searchtype=author&query=Solodky%2C+S+G">S.G. Solodky</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">The problem of recovering partial derivatives of high orders of bivariate
functions with finite smoothness is studied. Based on the truncation method, a
numerical differentiation algorithm was constructed, which is optimal by the
order, both in the sense of accuracy and in the sense of the amount of Galerkin
information involved. Numerical demonstrations are provided to illustrate that
the proposed method can be implemented successfully.
</p>
</div>
</dd>
<dt><a name="item391">[391]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.05429" title="Abstract">arXiv:2309.05429</a> [<a href="/pdf/2309.05429" title="Download PDF">pdf</a>, <a href="/format/2309.05429" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Improving Information Extraction on Business Documents with Specific  Pre-Training Tasks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Douzon%2C+T">Thibault Douzon</a>, 
<a href="/search/cs?searchtype=author&query=Duffner%2C+S">Stefan Duffner</a>, 
<a href="/search/cs?searchtype=author&query=Garcia%2C+C">Christophe Garcia</a>, 
<a href="/search/cs?searchtype=author&query=Espinas%2C+J">J&#xe9;r&#xe9;my Espinas</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Conference: Document Analysis Systems. DAS 2022
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Document Analysis Systems (DAS) 2022 pages 111 to 125
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Transformer-based Language Models are widely used in Natural Language
Processing related tasks. Thanks to their pre-training, they have been
successfully adapted to Information Extraction in business documents. However,
most pre-training tasks proposed in the literature for business documents are
too generic and not sufficient to learn more complex structures. In this paper,
we use LayoutLM, a language model pre-trained on a collection of business
documents, and introduce two new pre-training tasks that further improve its
capacity to extract relevant information. The first is aimed at better
understanding the complex layout of documents, and the second focuses on
numeric values and their order of magnitude. These tasks force the model to
learn better-contextualized representations of the scanned documents. We
further introduce a new post-processing algorithm to decode BIESO tags in
Information Extraction that performs better with complex entities. Our method
significantly improves extraction performance on both public (from 93.88 to
95.50 F1 score) and private (from 84.35 to 84.84 F1 score) datasets composed of
expense receipts, invoices, and purchase orders.
</p>
</div>
</dd>
<dt><a name="item392">[392]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.05430" title="Abstract">arXiv:2309.05430</a> [<a href="/pdf/2309.05430" title="Download PDF">pdf</a>, <a href="/format/2309.05430" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Neuromorphic Auditory Perception by Neural Spiketrum
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tang%2C+H">Huajin Tang</a>, 
<a href="/search/cs?searchtype=author&query=Gu%2C+P">Pengjie Gu</a>, 
<a href="/search/cs?searchtype=author&query=Wijekoon%2C+J">Jayawan Wijekoon</a>, 
<a href="/search/cs?searchtype=author&query=Alsakkal%2C+M+A">MHD Anas Alsakkal</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Ziming Wang</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+J">Jiangrong Shen</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+R">Rui Yan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This work has been submitted to the IEEE for possible publication
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neural and Evolutionary Computing (cs.NE)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Neuromorphic computing holds the promise to achieve the energy efficiency and
robust learning performance of biological neural systems. To realize the
promised brain-like intelligence, it needs to solve the challenges of the
neuromorphic hardware architecture design of biological neural substrate and
the hardware amicable algorithms with spike-based encoding and learning. Here
we introduce a neural spike coding model termed spiketrum, to characterize and
transform the time-varying analog signals, typically auditory signals, into
computationally efficient spatiotemporal spike patterns. It minimizes the
information loss occurring at the analog-to-spike transformation and possesses
informational robustness to neural fluctuations and spike losses. The model
provides a sparse and efficient coding scheme with precisely controllable spike
rate that facilitates training of spiking neural networks in various auditory
perception tasks. We further investigate the algorithm-hardware co-designs
through a neuromorphic cochlear prototype which demonstrates that our approach
can provide a systematic solution for spike-based artificial intelligence by
fully exploiting its advantages with spike-based computation.
</p>
</div>
</dd>
<dt><a name="item393">[393]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.05433" title="Abstract">arXiv:2309.05433</a> [<a href="/pdf/2309.05433" title="Download PDF">pdf</a>, <a href="/format/2309.05433" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Design and Validation of a Wireless Drone Docking Station
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Stuhne%2C+D">Dario Stuhne</a>, 
<a href="/search/cs?searchtype=author&query=Vasiljevic%2C+G">Goran Vasiljevic</a>, 
<a href="/search/cs?searchtype=author&query=Bogdan%2C+S">Stjepan Bogdan</a>, 
<a href="/search/cs?searchtype=author&query=Kovacic%2C+Z">Zdenko Kovacic</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 2023 International Conference on Unmanned Aircraft Systems (ICUAS)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Drones are increasingly operating autonomously, and the need for extending
drone power autonomy is rapidly increasing. One of the most promising solutions
to extend drone power autonomy is the use of docking stations to support both
landing and recharging of the drone. To this end, we introduce a novel wireless
drone docking station with three commercial wireless charging modules. We have
developed two independent units, both in mechanical and electrical aspects: the
energy transmitting unit and the energy receiving unit. We have also studied
the efficiency of wireless power transfer and demonstrated the advantages of
connecting three receiver modules connected in series and parallel. We have
achieved maximum output power of 96.5 W with a power transfer efficiency of
56.6% for the series connection of coils. Finally, we implemented the system in
practice on a drone and tested both energy transfer and landing.
</p>
</div>
</dd>
<dt><a name="item394">[394]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.05434" title="Abstract">arXiv:2309.05434</a> [<a href="/pdf/2309.05434" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A parameterised model for link prediction using node centrality and  similarity measure based on graph embedding
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lu%2C+H">Haohui Lu</a>, 
<a href="/search/cs?searchtype=author&query=Uddin%2C+S">Shahadat Uddin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Social and Information Networks (cs.SI)

</div>
<p class="mathjax">Link prediction is a key aspect of graph machine learning, with applications
as diverse as disease prediction, social network recommendations, and drug
discovery. It involves predicting new links that may form between network
nodes. Despite the clear importance of link prediction, existing models have
significant shortcomings. Graph Convolutional Networks, for instance, have been
proven to be highly efficient for link prediction on a variety of datasets.
However, they encounter severe limitations when applied to short-path networks
and ego networks, resulting in poor performance. This presents a critical
problem space that this work aims to address. In this paper, we present the
Node Centrality and Similarity Based Parameterised Model (NCSM), a novel method
for link prediction tasks. NCSM uniquely integrates node centrality and
similarity measures as edge features in a customised Graph Neural Network (GNN)
layer, effectively leveraging the topological information of large networks.
This model represents the first parameterised GNN-based link prediction model
that considers topological information. The proposed model was evaluated on
five benchmark graph datasets, each comprising thousands of nodes and edges.
Experimental results highlight NCSM's superiority over existing
state-of-the-art models like Graph Convolutional Networks and Variational Graph
Autoencoder, as it outperforms them across various metrics and datasets. This
exceptional performance can be attributed to NCSM's innovative integration of
node centrality, similarity measures, and its efficient use of topological
information.
</p>
</div>
</dd>
<dt><a name="item395">[395]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.05436" title="Abstract">arXiv:2309.05436</a> [<a href="/pdf/2309.05436" title="Download PDF">pdf</a>, <a href="/format/2309.05436" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Quantized Fourier and Polynomial Features for more Expressive Tensor  Network Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wesel%2C+F">Frederiek Wesel</a>, 
<a href="/search/cs?searchtype=author&query=Batselier%2C+K">Kim Batselier</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">In the context of kernel machines, polynomial and Fourier features are
commonly used to provide a nonlinear extension to linear models by mapping the
data to a higher-dimensional space. Unless one considers the dual formulation
of the learning problem, which renders exact large-scale learning unfeasible,
the exponential increase of model parameters in the dimensionality of the data
caused by their tensor-product structure prohibits to tackle high-dimensional
problems. One of the possible approaches to circumvent this exponential scaling
is to exploit the tensor structure present in the features by constraining the
model weights to be an underparametrized tensor network. In this paper we
quantize, i.e. further tensorize, polynomial and Fourier features. Based on
this feature quantization we propose to quantize the associated model weights,
yielding quantized models. We show that, for the same number of model
parameters, the resulting quantized models have a higher bound on the
VC-dimension as opposed to their non-quantized counterparts, at no additional
computational cost while learning from identical features. We verify
experimentally how this additional tensorization regularizes the learning
problem by prioritizing the most salient features in the data and how it
provides models with increased generalization capabilities. We finally
benchmark our approach on large regression task, achieving state-of-the-art
results on a laptop computer.
</p>
</div>
</dd>
<dt><a name="item396">[396]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.05438" title="Abstract">arXiv:2309.05438</a> [<a href="/pdf/2309.05438" title="Download PDF">pdf</a>, <a href="/format/2309.05438" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Content-based Pixel Retrieval in Revisited Oxford and Paris
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=An%2C+G">Guoyuan An</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+W+J">Woo Jae Kim</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+S">Saelyne Yang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+R">Rong Li</a>, 
<a href="/search/cs?searchtype=author&query=Huo%2C+Y">Yuchi Huo</a>, 
<a href="/search/cs?searchtype=author&query=Yoon%2C+S">Sung-Eui Yoon</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Information Retrieval (cs.IR)

</div>
<p class="mathjax">This paper introduces the first two pixel retrieval benchmarks. Pixel
retrieval is segmented instance retrieval. Like semantic segmentation extends
classification to the pixel level, pixel retrieval is an extension of image
retrieval and offers information about which pixels are related to the query
object. In addition to retrieving images for the given query, it helps users
quickly identify the query object in true positive images and exclude false
positive images by denoting the correlated pixels. Our user study results show
pixel-level annotation can significantly improve the user experience.
<br />Compared with semantic and instance segmentation, pixel retrieval requires a
fine-grained recognition capability for variable-granularity targets. To this
end, we propose pixel retrieval benchmarks named PROxford and PRParis, which
are based on the widely used image retrieval datasets, ROxford and RParis.
Three professional annotators label 5,942 images with two rounds of
double-checking and refinement. Furthermore, we conduct extensive experiments
and analysis on the SOTA methods in image search, image matching, detection,
segmentation, and dense matching using our pixel retrieval benchmarks. Results
show that the pixel retrieval task is challenging to these approaches and
distinctive from existing problems, suggesting that further research can
advance the content-based pixel-retrieval and thus user search experience. The
datasets can be downloaded from
\href{https://github.com/anguoyuan/Pixel_retrieval-Segmented_instance_retrieval}{this
link}.
</p>
</div>
</dd>
<dt><a name="item397">[397]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.05440" title="Abstract">arXiv:2309.05440</a> [<a href="/pdf/2309.05440" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Emissions and energy efficiency on large-scale high performance  computing facilities: ARCHER2 UK national supercomputing service case study
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jackson%2C+A">Adrian Jackson</a>, 
<a href="/search/cs?searchtype=author&query=Simpson%2C+A">Alan Simpson</a>, 
<a href="/search/cs?searchtype=author&query=Turner%2C+A">Andrew Turner</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>

</div>
<p class="mathjax">Large supercomputing facilities are critical to research in many areas that
impact on decisions such as how to address the current climate emergency. For
example, climate modelling, renewable energy facility design and new battery
technologies. However, these systems themselves are a source of large amounts
of emissions due to the embodied emissions associated with their construction,
transport, and decommissioning; and the power consumption associated with
running the facility. Recently, the UK National Supercomputing Service,
ARCHER2, has been analysing the impact of the facility in terms of energy and
emissions. Based on this work, we have made changes to the operation of the
service that give a cumulative saving of more than 20% in power draw of the
computational resources with all application benchmarks showing reduced power
to solution. In this paper, we describe our analysis and the changes made to
the operation of the service to improve its energy efficiency, and thereby
reduce its climate impacts.
</p>
</div>
</dd>
<dt><a name="item398">[398]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.05442" title="Abstract">arXiv:2309.05442</a> [<a href="/pdf/2309.05442" title="Download PDF">pdf</a>, <a href="/format/2309.05442" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Testing Spreading Behavior in Networks with Arbitrary Topologies
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Modanese%2C+A">Augusto Modanese</a>, 
<a href="/search/cs?searchtype=author&query=Yoshida%2C+Y">Yuichi Yoshida</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 33 pages, 3 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>; Computational Complexity (cs.CC); Data Structures and Algorithms (cs.DS)

</div>
<p class="mathjax">Inspired by the works of Goldreich and Ron (J. ACM, 2017) and Nakar and Ron
(ICALP, 2021), we initiate the study of property testing in dynamic
environments with arbitrary topologies. Our focus is on the simplest
non-trivial rule that can be tested, which corresponds to the 1-BP rule of
bootstrap percolation and models a simple spreading behavior: Every "infected"
node stays infected forever, and each "healthy" node becomes infected if and
only if it has at least one infected neighbor. We show various results for both
the case where we test a single time step of evolution and where the evolution
spans several time steps. In the first, we show that the worst-case query
complexity is $O(\Delta/\varepsilon)$ or $\tilde{O}(\sqrt{n}/\varepsilon)$
(whichever is smaller), where $\Delta$ and $n$ are the maximum degree of a node
and number of vertices, respectively, in the underlying graph, and we also show
lower bounds for both one- and two-sided error testers that match our upper
bounds up to $\Delta = o(\sqrt{n})$ and $\Delta = O(n^{1/3})$, respectively. In
the second setting of testing the environment over $T$ time steps, we show
upper bounds of $O(\Delta^{T-1}/\varepsilon T)$ and $\tilde{O}(|E|/\varepsilon
T)$, where $E$ is the set of edges of the underlying graph. All of our
algorithms are one-sided error, and all of them are also time-conforming and
non-adaptive, with the single exception of the more complex
$\tilde{O}(\sqrt{n}/\varepsilon)$-query tester for the case $T = 2$.
</p>
</div>
</dd>
<dt><a name="item399">[399]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.05443" title="Abstract">arXiv:2309.05443</a> [<a href="/pdf/2309.05443" title="Download PDF">pdf</a>, <a href="/format/2309.05443" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Know What Not To Know: Users&#x27; Perception of Abstaining Classifiers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Papenmeier%2C+A">Andrea Papenmeier</a>, 
<a href="/search/cs?searchtype=author&query=Hienert%2C+D">Daniel Hienert</a>, 
<a href="/search/cs?searchtype=author&query=Kammerer%2C+Y">Yvonne Kammerer</a>, 
<a href="/search/cs?searchtype=author&query=Seifert%2C+C">Christin Seifert</a>, 
<a href="/search/cs?searchtype=author&query=Kern%2C+D">Dagmar Kern</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> In Companion Publication of the 2023 ACM Designing Interactive
  Systems Conference (DIS 2023 Companion)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">Machine learning systems can help humans to make decisions by providing
decision suggestions (i.e., a label for a datapoint). However, individual
datapoints do not always provide enough clear evidence to make confident
suggestions. Although methods exist that enable systems to identify those
datapoints and subsequently abstain from suggesting a label, it remains unclear
how users would react to such system behavior. This paper presents first
findings from a user study on systems that do or do not abstain from labeling
ambiguous datapoints. Our results show that label suggestions on ambiguous
datapoints bear a high risk of unconsciously influencing the users' decisions,
even toward incorrect ones. Furthermore, participants perceived a system that
abstains from labeling uncertain datapoints as equally competent and
trustworthy as a system that delivers label suggestions for all datapoints.
Consequently, if abstaining does not impair a system's credibility, it can be a
useful mechanism to increase decision quality.
</p>
</div>
</dd>
<dt><a name="item400">[400]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.05444" title="Abstract">arXiv:2309.05444</a> [<a href="/pdf/2309.05444" title="Download PDF">pdf</a>, <a href="/format/2309.05444" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Pushing Mixture of Experts to the Limit: Extremely Parameter Efficient  MoE for Instruction Tuning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zadouri%2C+T">Ted Zadouri</a>, 
<a href="/search/cs?searchtype=author&query=%C3%9Cst%C3%BCn%2C+A">Ahmet &#xdc;st&#xfc;n</a>, 
<a href="/search/cs?searchtype=author&query=Ahmadian%2C+A">Arash Ahmadian</a>, 
<a href="/search/cs?searchtype=author&query=Ermi%C5%9F%2C+B">Beyza Ermi&#x15f;</a>, 
<a href="/search/cs?searchtype=author&query=Locatelli%2C+A">Acyr Locatelli</a>, 
<a href="/search/cs?searchtype=author&query=Hooker%2C+S">Sara Hooker</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">The Mixture of Experts (MoE) is a widely known neural architecture where an
ensemble of specialized sub-models optimizes overall performance with a
constant computational cost. However, conventional MoEs pose challenges at
scale due to the need to store all experts in memory. In this paper, we push
MoE to the limit. We propose extremely parameter-efficient MoE by uniquely
combining MoE architecture with lightweight experts.Our MoE architecture
outperforms standard parameter-efficient fine-tuning (PEFT) methods and is on
par with full fine-tuning by only updating the lightweight experts -- less than
1% of an 11B parameters model. Furthermore, our method generalizes to unseen
tasks as it does not depend on any prior task knowledge. Our research
underscores the versatility of the mixture of experts architecture, showcasing
its ability to deliver robust performance even when subjected to rigorous
parameter constraints. Our code used in all the experiments is publicly
available here: https://github.com/for-ai/parameter-efficient-moe.
</p>
</div>
</dd>
<dt><a name="item401">[401]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.05445" title="Abstract">arXiv:2309.05445</a> [<a href="/pdf/2309.05445" title="Download PDF">pdf</a>, <a href="/ps/2309.05445" title="Download PostScript">ps</a>, <a href="/format/2309.05445" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Many Cores, Many Models: GPU Programming Model vs. Vendor Compatibility  Overview
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Herten%2C+A">Andreas Herten</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>; Programming Languages (cs.PL)

</div>
<p class="mathjax">In recent history, GPUs became a key driver of compute performance in HPC.
With the installation of the Frontier supercomputer, they became the enablers
of the Exascale era; further largest-scale installations are in progress
(Aurora, El Capitan, JUPITER). But the early-day dominance by NVIDIA and their
CUDA programming model has changed: The current HPC GPU landscape features
three vendors (AMD, Intel, NVIDIA), each with native and derived programming
models. The choices are ample, but not all models are supported on all
platforms, especially if support for Fortran is needed; in addition, some
restrictions might apply. It is hard for scientific programmers to navigate
this abundance of choices and limits.
<br />This paper gives a guide by matching the GPU platforms with supported
programming models, presented in a concise table and further elaborated in
detailed comments. An assessment is made regarding the level of support of a
model on a platform.
</p>
</div>
</dd>
<dt><a name="item402">[402]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.05447" title="Abstract">arXiv:2309.05447</a> [<a href="/pdf/2309.05447" title="Download PDF">pdf</a>, <a href="/format/2309.05447" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> TeGit: Generating High-Quality Instruction-Tuning Data with  Text-Grounded Task Design
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yongrui Chen</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+H">Haiyun Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+X">Xinting Huang</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+S">Shuming Shi</a>, 
<a href="/search/cs?searchtype=author&query=Qi%2C+G">Guilin Qi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Work in progress
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">High-quality instruction-tuning data is critical to improving LLM
capabilities. Existing data collection methods are limited by unrealistic
manual labeling costs or by the hallucination of relying solely on LLM
generation. To address the problems, this paper presents a scalable method to
automatically collect high-quality instructional adaptation data by training
language models to automatically design tasks based on human-written texts.
Intuitively, human-written text helps to help the model attenuate illusions
during the generation of tasks. Unlike instruction back-translation-based
methods that directly take the given text as a response, we require the model
to generate the \textit{instruction}, \textit{input}, and \textit{output}
simultaneously to filter the noise. The results of the automated and manual
evaluation experiments demonstrate the quality of our dataset.
</p>
</div>
</dd>
<dt><a name="item403">[403]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.05448" title="Abstract">arXiv:2309.05448</a> [<a href="/pdf/2309.05448" title="Download PDF">pdf</a>, <a href="/format/2309.05448" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Panoptic Vision-Language Feature Fields
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+H">Haoran Chen</a>, 
<a href="/search/cs?searchtype=author&query=Blomqvist%2C+K">Kenneth Blomqvist</a>, 
<a href="/search/cs?searchtype=author&query=Milano%2C+F">Francesco Milano</a>, 
<a href="/search/cs?searchtype=author&query=Siegwart%2C+R">Roland Siegwart</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL)

</div>
<p class="mathjax">Recently, methods have been proposed for 3D open-vocabulary semantic
segmentation. Such methods are able to segment scenes into arbitrary classes
given at run-time using their text description. In this paper, we propose to
our knowledge the first algorithm for open-vocabulary panoptic segmentation,
simultaneously performing both semantic and instance segmentation. Our
algorithm, Panoptic Vision-Language Feature Fields (PVLFF) learns a feature
field of the scene, jointly learning vision-language features and hierarchical
instance features through a contrastive loss function from 2D instance segment
proposals on input frames. Our method achieves comparable performance against
the state-of-the-art close-set 3D panoptic systems on the HyperSim, ScanNet and
Replica dataset and outperforms current 3D open-vocabulary systems in terms of
semantic segmentation. We additionally ablate our method to demonstrate the
effectiveness of our model architecture. Our code will be available at
https://github.com/ethz-asl/autolabel.
</p>
</div>
</dd>
<dt><a name="item404">[404]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.05450" title="Abstract">arXiv:2309.05450</a> [<a href="/pdf/2309.05450" title="Download PDF">pdf</a>, <a href="/format/2309.05450" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Comparison between Frame-based and Event-based Cameras for  Flapping-Wing Robot Perception
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tapia%2C+R">Raul Tapia</a>, 
<a href="/search/cs?searchtype=author&query=Rodr%C3%ADguez-G%C3%B3mez%2C+J+P">Juan Pablo Rodr&#xed;guez-G&#xf3;mez</a>, 
<a href="/search/cs?searchtype=author&query=Sanchez-Diaz%2C+J+A">Juan Antonio Sanchez-Diaz</a>, 
<a href="/search/cs?searchtype=author&query=Ga%C3%B1%C3%A1n%2C+F+J">Francisco Javier Ga&#xf1;&#xe1;n</a>, 
<a href="/search/cs?searchtype=author&query=Rodr%C3%ADguez%2C+I+G">Iv&#xe1;n Gutierrez Rodr&#xed;guez</a>, 
<a href="/search/cs?searchtype=author&query=Luna-Santamaria%2C+J">Javier Luna-Santamaria</a>, 
<a href="/search/cs?searchtype=author&query=Dios%2C+J+R+M">Jos&#xe9; Ramiro Mart&#xed;nez-de Dios</a>, 
<a href="/search/cs?searchtype=author&query=Ollero%2C+A">Anibal Ollero</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Perception systems for ornithopters face severe challenges. The harsh
vibrations and abrupt movements caused during flapping are prone to produce
motion blur and strong lighting condition changes. Their strict restrictions in
weight, size, and energy consumption also limit the type and number of sensors
to mount onboard. Lightweight traditional cameras have become a standard
off-the-shelf solution in many flapping-wing designs. However, bioinspired
event cameras are a promising solution for ornithopter perception due to their
microsecond temporal resolution, high dynamic range, and low power consumption.
This paper presents an experimental comparison between frame-based and an
event-based camera. Both technologies are analyzed considering the particular
flapping-wing robot specifications and also experimentally analyzing the
performance of well-known vision algorithms with data recorded onboard a
flapping-wing robot. Our results suggest event cameras as the most suitable
sensors for ornithopters. Nevertheless, they also evidence the open challenges
for event-based vision on board flapping-wing robots.
</p>
</div>
</dd>
<dt><a name="item405">[405]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.05451" title="Abstract">arXiv:2309.05451</a> [<a href="/pdf/2309.05451" title="Download PDF">pdf</a>, <a href="/format/2309.05451" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Dual-view Curricular Optimal Transport for Cross-lingual Cross-modal  Retrieval
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yabing Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Shuhui Wang</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+H">Hao Luo</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+J">Jianfeng Dong</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+F">Fan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+M">Meng Han</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xun Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+M">Meng Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Multimedia (cs.MM)

</div>
<p class="mathjax">Current research on cross-modal retrieval is mostly English-oriented, as the
availability of a large number of English-oriented human-labeled
vision-language corpora. In order to break the limit of non-English labeled
data, cross-lingual cross-modal retrieval (CCR) has attracted increasing
attention. Most CCR methods construct pseudo-parallel vision-language corpora
via Machine Translation (MT) to achieve cross-lingual transfer. However, the
translated sentences from MT are generally imperfect in describing the
corresponding visual contents. Improperly assuming the pseudo-parallel data are
correctly correlated will make the networks overfit to the noisy
correspondence. Therefore, we propose Dual-view Curricular Optimal Transport
(DCOT) to learn with noisy correspondence in CCR. In particular, we quantify
the confidence of the sample pair correlation with optimal transport theory
from both the cross-lingual and cross-modal views, and design dual-view
curriculum learning to dynamically model the transportation costs according to
the learning stage of the two views. Extensive experiments are conducted on two
multilingual image-text datasets and one video-text dataset, and the results
demonstrate the effectiveness and robustness of the proposed method. Besides,
our proposed method also shows a good expansibility to cross-lingual image-text
baselines and a decent generalization on out-of-domain data.
</p>
</div>
</dd>
<dt><a name="item406">[406]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.05452" title="Abstract">arXiv:2309.05452</a> [<a href="/pdf/2309.05452" title="Download PDF">pdf</a>, <a href="/format/2309.05452" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Evaluating the Deductive Competence of Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Seals%2C+S+M">S.M. Seals</a>, 
<a href="/search/cs?searchtype=author&query=Shalin%2C+V+L">Valerie L. Shalin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, 7 figures, under review
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">The development of highly fluent large language models (LLMs) has prompted
increased interest in assessing their reasoning and problem-solving
capabilities. We investigate whether several LLMs can solve a classic type of
deductive reasoning problem from the cognitive science literature. The tested
LLMs have limited abilities to solve these problems in their conventional form.
We performed follow up experiments to investigate if changes to the
presentation format and content improve model performance. We do find
performance differences between conditions; however, they do not improve
overall performance. Moreover, we find that performance interacts with
presentation format and content in unexpected ways that differ from human
performance. Overall, our results suggest that LLMs have unique reasoning
biases that are only partially predicted from human reasoning performance.
</p>
</div>
</dd>
<dt><a name="item407">[407]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.05453" title="Abstract">arXiv:2309.05453</a> [<a href="/pdf/2309.05453" title="Download PDF">pdf</a>, <a href="/ps/2309.05453" title="Download PostScript">ps</a>, <a href="/format/2309.05453" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Minimum-propellant Pontryagin-based Nonlinear MPC for Spacecraft  Rendezvous in Lunar Orbit: the Extended Version
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Pagone%2C+M">Michele Pagone</a>, 
<a href="/search/eess?searchtype=author&query=Bucchioni%2C+G">Giordana Bucchioni</a>, 
<a href="/search/eess?searchtype=author&query=Alfino%2C+F">Francesco Alfino</a>, 
<a href="/search/eess?searchtype=author&query=Novara%2C+C">Carlo Novara</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Optimization and Control (math.OC)

</div>
<p class="mathjax">We propose a Nonlinear Model Predictive Control approach to spacecraft
rendezvous in non-Keplerian Lunar orbits. The approach is based on the
Pontryagin Minimum Principle and allows the accomplishment of
minimum-propellant maneuvers. The relative motion between the chaser and the
target is described by the nonlinear and unstable dynamics of the circular
restricted three body-problem. In the proposed formulation, we design a
minimum-propellant controller, which leads to a bang-bang behavior of the
control signal. Under suitable assumptions, simplified dynamics is employed as
prediction model, in order to reduce the complexity of the controller algorithm
but, at the same time, without penalizing the controller tracking performance.
The proposed approach's effectiveness is validated by a simulation example.
</p>
</div>
</dd>
<dt><a name="item408">[408]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.05454" title="Abstract">arXiv:2309.05454</a> [<a href="/pdf/2309.05454" title="Download PDF">pdf</a>, <a href="/format/2309.05454" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Flesch or Fumble? Evaluating Readability Standard Alignment of  Instruction-Tuned Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Imperial%2C+J+M">Joseph Marvin Imperial</a>, 
<a href="/search/cs?searchtype=author&query=Madabushi%2C+H+T">Harish Tayyar Madabushi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Readability metrics and standards such as Flesch Kincaid Grade Level (FKGL)
and the Common European Framework of Reference for Languages (CEFR) exist to
guide teachers and educators to properly assess the complexity of educational
materials before administering them for classroom use. In this study, we select
a diverse set of open and closed-source instruction-tuned language models and
investigate their performances in writing story completions and simplifying
narratives$-$tasks that teachers perform$-$using standard-guided prompts
controlling text readability. Our extensive findings provide empirical proof of
how globally recognized models like ChatGPT may be considered less effective
and may require more refined prompts for these generative tasks compared to
other open-sourced models such as BLOOMZ and FlanT5$-$which have shown
promising results.
</p>
</div>
</dd>
<dt><a name="item409">[409]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.05457" title="Abstract">arXiv:2309.05457</a> [<a href="/pdf/2309.05457" title="Download PDF">pdf</a>, <a href="/format/2309.05457" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Unveiling the Sentinels: Assessing AI Performance in Cybersecurity Peer  Review
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Niu%2C+L">Liang Niu</a>, 
<a href="/search/cs?searchtype=author&query=Xue%2C+N">Nian Xue</a>, 
<a href="/search/cs?searchtype=author&query=P%C3%B6pper%2C+C">Christina P&#xf6;pper</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Peer review is the method employed by the scientific community for evaluating
research advancements. In the field of cybersecurity, the practice of
double-blind peer review is the de-facto standard. This paper touches on the
holy grail of peer reviewing and aims to shed light on the performance of AI in
reviewing for academic security conferences. Specifically, we investigate the
predictability of reviewing outcomes by comparing the results obtained from
human reviewers and machine-learning models. To facilitate our study, we
construct a comprehensive dataset by collecting thousands of papers from
renowned computer science conferences and the arXiv preprint website. Based on
the collected data, we evaluate the prediction capabilities of ChatGPT and a
two-stage classification approach based on the Doc2Vec model with various
classifiers. Our experimental evaluation of review outcome prediction using the
Doc2Vec-based approach performs significantly better than the ChatGPT and
achieves an accuracy of over 90%. While analyzing the experimental results, we
identify the potential advantages and limitations of the tested ML models. We
explore areas within the paper-reviewing process that can benefit from
automated support approaches, while also recognizing the irreplaceable role of
human intellect in certain aspects that cannot be matched by state-of-the-art
AI techniques.
</p>
</div>
</dd>
<dt><a name="item410">[410]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.05460" title="Abstract">arXiv:2309.05460</a> [<a href="/pdf/2309.05460" title="Download PDF">pdf</a>, <a href="/format/2309.05460" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Intuitive HMI for UAV Control
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zoric%2C+F">Filip Zoric</a>, 
<a href="/search/cs?searchtype=author&query=Vasiljevic%2C+G">Goran Vasiljevic</a>, 
<a href="/search/cs?searchtype=author&query=Orsag%2C+M">Matko Orsag</a>, 
<a href="/search/cs?searchtype=author&query=Kovacic%2C+Z">Zdenko Kovacic</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 2022 International Conference on Smart Systems and Technologies (SST)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Robotics (cs.RO)

</div>
<p class="mathjax">In the last decade, UAVs have become a widely used technology. As they are
used by both professionals and amateurs, there is a need to explore different
control modalities to make control intuitive and easier, especially for new
users. In this work, we compared the most widely used joystick control with a
custom human pose control. We used human pose estimation and arm movements to
send UAV commands in the same way that operators use their fingers to send
joystick commands. Experiments were conducted in a simulation environment with
first-person visual feedback. Participants had to traverse the same maze with
joystick and human pose control. Participants' subjective experience was
assessed using the raw NASA Task Load Index.
</p>
</div>
</dd>
<dt><a name="item411">[411]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.05463" title="Abstract">arXiv:2309.05463</a> [<a href="/pdf/2309.05463" title="Download PDF">pdf</a>, <a href="/format/2309.05463" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Textbooks Are All You Need II: phi-1.5 technical report
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yuanzhi Li</a>, 
<a href="/search/cs?searchtype=author&query=Bubeck%2C+S">S&#xe9;bastien Bubeck</a>, 
<a href="/search/cs?searchtype=author&query=Eldan%2C+R">Ronen Eldan</a>, 
<a href="/search/cs?searchtype=author&query=Del+Giorno%2C+A">Allie Del Giorno</a>, 
<a href="/search/cs?searchtype=author&query=Gunasekar%2C+S">Suriya Gunasekar</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+Y+T">Yin Tat Lee</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">We continue the investigation into the power of smaller Transformer-based
language models as initiated by \textbf{TinyStories} -- a 10 million parameter
model that can produce coherent English -- and the follow-up work on
\textbf{phi-1}, a 1.3 billion parameter model with Python coding performance
close to the state-of-the-art. The latter work proposed to use existing Large
Language Models (LLMs) to generate ``textbook quality" data as a way to enhance
the learning process compared to traditional web data. We follow the
``Textbooks Are All You Need" approach, focusing this time on common sense
reasoning in natural language, and create a new 1.3 billion parameter model
named \textbf{phi-1.5}, with performance on natural language tasks comparable
to models 5x larger, and surpassing most non-frontier LLMs on more complex
reasoning tasks such as grade-school mathematics and basic coding. More
generally, \textbf{phi-1.5} exhibits many of the traits of much larger LLMs,
both good -- such as the ability to ``think step by step" or perform some
rudimentary in-context learning -- and bad, including hallucinations and the
potential for toxic and biased generations -- encouragingly though, we are
seeing improvement on that front thanks to the absence of web data. We
open-source \textbf{phi-1.5} to promote further research on these urgent
topics.
</p>
</div>
</dd>
<dt><a name="item412">[412]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.05467" title="Abstract">arXiv:2309.05467</a> [<a href="/pdf/2309.05467" title="Download PDF">pdf</a>, <a href="/format/2309.05467" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Assessing Wind Impact on Semi-Autonomous Drone Landings for In-Contact  Power Line Inspection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Gendron%2C+E">Etienne Gendron</a>, 
<a href="/search/eess?searchtype=author&query=Leclerc%2C+M">Marc-Antoine Leclerc</a>, 
<a href="/search/eess?searchtype=author&query=Hovington%2C+S">Samuel Hovington</a>, 
<a href="/search/eess?searchtype=author&query=Perron%2C+E">Etienne Perron</a>, 
<a href="/search/eess?searchtype=author&query=Rancourt%2C+D">David Rancourt</a>, 
<a href="/search/eess?searchtype=author&query=Lussier-Desbiens%2C+A">Alexis Lussier-Desbiens</a>, 
<a href="/search/eess?searchtype=author&query=Hamelin%2C+P">Philippe Hamelin</a>, 
<a href="/search/eess?searchtype=author&query=Girard%2C+A">Alexandre Girard</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Robotics (cs.RO)

</div>
<p class="mathjax">In recent years, the use of inspection drones has become increasingly popular
for high-voltage electric cable inspections due to their efficiency,
cost-effectiveness, and ability to access hard-to-reach areas. However, safely
landing drones on power lines, especially under windy conditions, remains a
significant challenge. This study introduces a semi-autonomous control scheme
for landing on an electrical line with the NADILE drone (an experimental drone
based on original LineDrone key features for inspection of power lines) and
assesses the operating envelope under various wind conditions. A Monte Carlo
method is employed to analyze the success probability of landing given initial
drone states. The performance of the system is evaluated for two landing
strategies, variously controllers parameters and four level of wind
intensities. The results show that a two-stage landing strategies offers higher
probabilities of landing success and give insight regarding the best controller
parameters and the maximum wind level for which the system is robust. Lastly,
an experimental demonstration of the system landing autonomously on a power
line is presented.
</p>
</div>
</dd>
<dt><a name="item413">[413]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.05472" title="Abstract">arXiv:2309.05472</a> [<a href="/pdf/2309.05472" title="Download PDF">pdf</a>, <a href="/format/2309.05472" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LeBenchmark 2.0: a Standardized, Replicable and Enhanced Framework for  Self-supervised Representations of French Speech
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Parcollet%2C+T">Titouan Parcollet</a>, 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+H">Ha Nguyen</a>, 
<a href="/search/cs?searchtype=author&query=Evain%2C+S">Solene Evain</a>, 
<a href="/search/cs?searchtype=author&query=Boito%2C+M+Z">Marcely Zanon Boito</a>, 
<a href="/search/cs?searchtype=author&query=Pupier%2C+A">Adrien Pupier</a>, 
<a href="/search/cs?searchtype=author&query=Mdhaffar%2C+S">Salima Mdhaffar</a>, 
<a href="/search/cs?searchtype=author&query=Le%2C+H">Hang Le</a>, 
<a href="/search/cs?searchtype=author&query=Alisamir%2C+S">Sina Alisamir</a>, 
<a href="/search/cs?searchtype=author&query=Tomashenko%2C+N">Natalia Tomashenko</a>, 
<a href="/search/cs?searchtype=author&query=Dinarelli%2C+M">Marco Dinarelli</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+S">Shucong Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Allauzen%2C+A">Alexandre Allauzen</a>, 
<a href="/search/cs?searchtype=author&query=Coavoux%2C+M">Maximin Coavoux</a>, 
<a href="/search/cs?searchtype=author&query=Esteve%2C+Y">Yannick Esteve</a>, 
<a href="/search/cs?searchtype=author&query=Rouvier%2C+M">Mickael Rouvier</a>, 
<a href="/search/cs?searchtype=author&query=Goulian%2C+J">Jerome Goulian</a>, 
<a href="/search/cs?searchtype=author&query=Lecouteux%2C+B">Benjamin Lecouteux</a>, 
<a href="/search/cs?searchtype=author&query=Portet%2C+F">Francois Portet</a>, 
<a href="/search/cs?searchtype=author&query=Rossato%2C+S">Solange Rossato</a>, 
<a href="/search/cs?searchtype=author&query=Ringeval%2C+F">Fabien Ringeval</a>, 
<a href="/search/cs?searchtype=author&query=Schwab%2C+D">Didier Schwab</a>, 
<a href="/search/cs?searchtype=author&query=Besacier%2C+L">Laurent Besacier</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Under submission at Computer Science and Language. Preprint allowed
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Sound (cs.SD); Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">Self-supervised learning (SSL) is at the origin of unprecedented improvements
in many different domains including computer vision and natural language
processing. Speech processing drastically benefitted from SSL as most of the
current domain-related tasks are now being approached with pre-trained models.
This work introduces LeBenchmark 2.0 an open-source framework for assessing and
building SSL-equipped French speech technologies. It includes documented,
large-scale and heterogeneous corpora with up to 14,000 hours of heterogeneous
speech, ten pre-trained SSL wav2vec 2.0 models containing from 26 million to
one billion learnable parameters shared with the community, and an evaluation
protocol made of six downstream tasks to complement existing benchmarks.
LeBenchmark 2.0 also presents unique perspectives on pre-trained SSL models for
speech with the investigation of frozen versus fine-tuned downstream models,
task-agnostic versus task-specific pre-trained models as well as a discussion
on the carbon footprint of large-scale model training.
</p>
</div>
</dd>
<dt><a name="item414">[414]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.05475" title="Abstract">arXiv:2309.05475</a> [<a href="/pdf/2309.05475" title="Download PDF">pdf</a>, <a href="/format/2309.05475" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Zero-shot Learning with Minimum Instruction to Extract Social  Determinants and Family History from Clinical Notes using GPT Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bhate%2C+N+J">Neel Jitesh Bhate</a>, 
<a href="/search/cs?searchtype=author&query=Mittal%2C+A">Ansh Mittal</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+Z">Zhe He</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+X">Xiao Luo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages, 4 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Demographics, Social determinants of health, and family history documented in
the unstructured text within the electronic health records are increasingly
being studied to understand how this information can be utilized with the
structured data to improve healthcare outcomes. After the GPT models were
released, many studies have applied GPT models to extract this information from
the narrative clinical notes. Different from the existing work, our research
focuses on investigating the zero-shot learning on extracting this information
together by providing minimum information to the GPT model. We utilize
de-identified real-world clinical notes annotated for demographics, various
social determinants, and family history information. Given that the GPT model
might provide text different from the text in the original data, we explore two
sets of evaluation metrics, including the traditional NER evaluation metrics
and semantic similarity evaluation metrics, to completely understand the
performance. Our results show that the GPT-3.5 method achieved an average of
0.975 F1 on demographics extraction, 0.615 F1 on social determinants
extraction, and 0.722 F1 on family history extraction. We believe these results
can be further improved through model fine-tuning or few-shots learning.
Through the case studies, we also identified the limitations of the GPT models,
which need to be addressed in future research.
</p>
</div>
</dd>
<dt><a name="item415">[415]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.05477" title="Abstract">arXiv:2309.05477</a> [<a href="/pdf/2309.05477" title="Download PDF">pdf</a>, <a href="/format/2309.05477" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning Objective-Specific Active Learning Strategies with Attentive  Neural Processes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bakker%2C+T">Tim Bakker</a>, 
<a href="/search/cs?searchtype=author&query=van+Hoof%2C+H">Herke van Hoof</a>, 
<a href="/search/cs?searchtype=author&query=Welling%2C+M">Max Welling</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at ECML 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Pool-based active learning (AL) is a promising technology for increasing
data-efficiency of machine learning models. However, surveys show that
performance of recent AL methods is very sensitive to the choice of dataset and
training setting, making them unsuitable for general application. In order to
tackle this problem, the field Learning Active Learning (LAL) suggests to learn
the active learning strategy itself, allowing it to adapt to the given setting.
In this work, we propose a novel LAL method for classification that exploits
symmetry and independence properties of the active learning problem with an
Attentive Conditional Neural Process model. Our approach is based on learning
from a myopic oracle, which gives our model the ability to adapt to
non-standard objectives, such as those that do not equally weight the error on
all data points. We experimentally verify that our Neural Process model
outperforms a variety of baselines in these settings. Finally, our experiments
show that our model exhibits a tendency towards improved stability to changing
datasets. However, performance is sensitive to choice of classifier and more
work is necessary to reduce the performance the gap with the myopic oracle and
to improve scalability. We present our work as a proof-of-concept for LAL on
nonstandard objectives and hope our analysis and modelling considerations
inspire future LAL work.
</p>
</div>
</dd>
<dt><a name="item416">[416]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.05478" title="Abstract">arXiv:2309.05478</a> [<a href="/pdf/2309.05478" title="Download PDF">pdf</a>, <a href="/format/2309.05478" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Classification of Quantum Computer Fault Injection Attacks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+C">Chuanqi Xu</a>, 
<a href="/search/cs?searchtype=author&query=Erata%2C+F">Ferhat Erata</a>, 
<a href="/search/cs?searchtype=author&query=Szefer%2C+J">Jakub Szefer</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, 4 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Quantum Physics (quant-ph)

</div>
<p class="mathjax">The rapid growth of interest in quantum computing has brought about the need
to secure these powerful machines against a range of physical attacks. As qubit
counts increase and quantum computers achieve higher levels of fidelity, their
potential to execute novel algorithms and generate sensitive intellectual
property becomes more promising. However, there is a significant gap in our
understanding of the vulnerabilities these computers face in terms of security
and privacy attacks. Among the potential threats are physical attacks,
including those orchestrated by malicious insiders within data centers where
the quantum computers are located, which could compromise the integrity of
computations and resulting data. This paper presents an exploration of
fault-injection attacks as one class of physical attacks on quantum computers.
This work first introduces a classification of fault-injection attacks and
strategies, including the domain of fault-injection attacks, the fault targets,
and fault manifestations in quantum computers. The resulting classification
highlights the potential threats that exist. By shedding light on the
vulnerabilities of quantum computers to fault-injection attacks, this work
contributes to the development of robust security measures for this emerging
technology.
</p>
</div>
</dd>
<dt><a name="item417">[417]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.05483" title="Abstract">arXiv:2309.05483</a> [<a href="/pdf/2309.05483" title="Download PDF">pdf</a>, <a href="/format/2309.05483" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Sound Atomicity Inference for Data-Centric Synchronization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Paulino%2C+H">Herv&#xe9; Paulino</a>, 
<a href="/search/cs?searchtype=author&query=Matos%2C+A+A">Ana Almeida Matos</a>, 
<a href="/search/cs?searchtype=author&query=Cederquist%2C+J">Jan Cederquist</a>, 
<a href="/search/cs?searchtype=author&query=Giunti%2C+M">Marco Giunti</a>, 
<a href="/search/cs?searchtype=author&query=Matos%2C+J">Jo&#xe3;o Matos</a>, 
<a href="/search/cs?searchtype=author&query=Ravara%2C+A">Ant&#xf3;nio Ravara</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Programming Languages (cs.PL)</span>

</div>
<p class="mathjax">Data-Centric Concurrency Control (DCCC) shifts the reasoning about
concurrency restrictions from control structures to data declaration. It is a
high-level declarative approach that abstracts away from the actual concurrency
control mechanism(s) in use. Despite its advantages, the practical use of DCCC
is hindered by the fact that it may require many annotations and/or multiple
implementations of the same method to cope with differently qualified
parameters. Moreover, the existing DCCC solutions do not address the use of
interfaces, precluding their use in most object-oriented programs. To overcome
these limitations, in this paper we present AtomiS, a new DCCC model based on a
rigorously defined type-sound programming language. Programming with AtomiS
requires only (atomic)-qualifying types of parameters and return values in
interface definitions, and of fields in class definitions. From this atomicity
specification, a static analysis infers the atomicity constraints that are
local to each method, considering valid only the method variants that are
consistent with the specification, and performs code generation for all valid
variants of each method. The generated code is then the target for automatic
injection of concurrency control primitives, by means of the desired automatic
technique and associated atomicity and deadlock-freedom guarantees, which can
be plugged-into the model's pipeline. We present the foundations for the AtomiS
analysis and synthesis, with formal guarantees that the generated program is
well-typed and that it corresponds behaviourally to the original one. The
proofs are mechanised in Coq. We also provide a Java implementation that
showcases the applicability of AtomiS in real-life programs.
</p>
</div>
</dd>
<dt><a name="item418">[418]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.05490" title="Abstract">arXiv:2309.05490</a> [<a href="/pdf/2309.05490" title="Download PDF">pdf</a>, <a href="/format/2309.05490" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning Semantic Segmentation with Query Points Supervision on Aerial  Images
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rivier%2C+S">Santiago Rivier</a>, 
<a href="/search/cs?searchtype=author&query=Hinojosa%2C+C">Carlos Hinojosa</a>, 
<a href="/search/cs?searchtype=author&query=Giancola%2C+S">Silvio Giancola</a>, 
<a href="/search/cs?searchtype=author&query=Ghanem%2C+B">Bernard Ghanem</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Paper presented at the LXCV workshop at ICCV 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Semantic segmentation is crucial in remote sensing, where high-resolution
satellite images are segmented into meaningful regions. Recent advancements in
deep learning have significantly improved satellite image segmentation.
However, most of these methods are typically trained in fully supervised
settings that require high-quality pixel-level annotations, which are expensive
and time-consuming to obtain. In this work, we present a weakly supervised
learning algorithm to train semantic segmentation algorithms that only rely on
query point annotations instead of full mask labels. Our proposed approach
performs accurate semantic segmentation and improves efficiency by
significantly reducing the cost and time required for manual annotation.
Specifically, we generate superpixels and extend the query point labels into
those superpixels that group similar meaningful semantics. Then, we train
semantic segmentation models, supervised with images partially labeled with the
superpixels pseudo-labels. We benchmark our weakly supervised training approach
on an aerial image dataset and different semantic segmentation architectures,
showing that we can reach competitive performance compared to fully supervised
training while reducing the annotation effort.
</p>
</div>
</dd>
<dt><a name="item419">[419]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.05491" title="Abstract">arXiv:2309.05491</a> [<a href="/pdf/2309.05491" title="Download PDF">pdf</a>, <a href="/format/2309.05491" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CLAM-Accelerated K-Nearest Neighbors Entropy-Scaling Search of Large  High-Dimensional Datasets via an Actualization of the Manifold Hypothesis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Prior%2C+M+E">Morgan E. Prior</a>, 
<a href="/search/cs?searchtype=author&query=Howard%2C+T+J">Thomas J. Howard III</a>, 
<a href="/search/cs?searchtype=author&query=McLaughlin%2C+O">Oliver McLaughlin</a>, 
<a href="/search/cs?searchtype=author&query=Ishaq%2C+N">Najib Ishaq</a>, 
<a href="/search/cs?searchtype=author&query=Daniels%2C+N+M">Noah M. Daniels</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> As submitted to IEEE Big Data 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>

</div>
<p class="mathjax">Many fields are experiencing a Big Data explosion, with data collection rates
outpacing the rate of computing performance improvements predicted by Moore's
Law.
<br />Researchers are often interested in similarity search on such data.
<br />We present CAKES (CLAM-Accelerated $K$-NN Entropy Scaling Search), a novel
algorithm for $k$-nearest-neighbor ($k$-NN) search which leverages geometric
and topological properties inherent in large datasets.
<br />CAKES assumes the manifold hypothesis and performs best when data occupy a
low dimensional manifold, even if the data occupy a very high dimensional
embedding space.
<br />We demonstrate performance improvements ranging from hundreds to tens of
thousands of times faster when compared to state-of-the-art approaches such as
FAISS and HNSW, when benchmarked on 5 standard datasets.
<br />Unlike locality-sensitive hashing approaches, CAKES can work with any
user-defined distance function.
<br />When data occupy a metric space, CAKES exhibits perfect recall.
</p>
</div>
</dd>
<dt><a name="item420">[420]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.05494" title="Abstract">arXiv:2309.05494</a> [<a href="/pdf/2309.05494" title="Download PDF">pdf</a>, <a href="/format/2309.05494" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CrisisTransformers: Pre-trained language models and sentence encoders  for crisis-related social media texts
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lamsal%2C+R">Rabindra Lamsal</a>, 
<a href="/search/cs?searchtype=author&query=Read%2C+M+R">Maria Rodriguez Read</a>, 
<a href="/search/cs?searchtype=author&query=Karunasekera%2C+S">Shanika Karunasekera</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Social media platforms play an essential role in crisis communication, but
analyzing crisis-related social media texts is challenging due to their
informal nature. Transformer-based pre-trained models like BERT and RoBERTa
have shown success in various NLP tasks, but they are not tailored for
crisis-related texts. Furthermore, general-purpose sentence encoders are used
to generate sentence embeddings, regardless of the textual complexities in
crisis-related texts. Advances in applications like text classification,
semantic search, and clustering contribute to effective processing of
crisis-related texts, which is essential for emergency responders to gain a
comprehensive view of a crisis event, whether historical or real-time. To
address these gaps in crisis informatics literature, this study introduces
CrisisTransformers, an ensemble of pre-trained language models and sentence
encoders trained on an extensive corpus of over 15 billion word tokens from
tweets associated with more than 30 crisis events, including disease outbreaks,
natural disasters, conflicts, and other critical incidents. We evaluate
existing models and CrisisTransformers on 18 crisis-specific public datasets.
Our pre-trained models outperform strong baselines across all datasets in
classification tasks, and our best-performing sentence encoder improves the
state-of-the-art by 17.43% in sentence encoding tasks. Additionally, we
investigate the impact of model initialization on convergence and evaluate the
significance of domain-specific models in generating semantically meaningful
sentence embeddings. All models are publicly released
(https://huggingface.co/crisistransformers), with the anticipation that they
will serve as a robust baseline for tasks involving the analysis of
crisis-related social media texts.
</p>
</div>
</dd>
<dt><a name="item421">[421]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.05497" title="Abstract">arXiv:2309.05497</a> [<a href="/pdf/2309.05497" title="Download PDF">pdf</a>, <a href="/format/2309.05497" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Personality Detection and Analysis using Twitter Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Datta%2C+A">Abhilash Datta</a>, 
<a href="/search/cs?searchtype=author&query=Chakraborty%2C+S">Souvic Chakraborty</a>, 
<a href="/search/cs?searchtype=author&query=Mukherjee%2C+A">Animesh Mukherjee</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to ASONAM 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Computers and Society (cs.CY)

</div>
<p class="mathjax">Personality types are important in various fields as they hold relevant
information about the characteristics of a human being in an explainable
format. They are often good predictors of a person's behaviors in a particular
environment and have applications ranging from candidate selection to marketing
and mental health. Recently automatic detection of personality traits from
texts has gained significant attention in computational linguistics. Most
personality detection and analysis methods have focused on small datasets
making their experimental observations often limited. To bridge this gap, we
focus on collecting and releasing the largest automatically curated dataset for
the research community which has 152 million tweets and 56 thousand data points
for the Myers-Briggs personality type (MBTI) prediction task. We perform a
series of extensive qualitative and quantitative studies on our dataset to
analyze the data patterns in a better way and infer conclusions. We show how
our intriguing analysis results often follow natural intuition. We also perform
a series of ablation studies to show how the baselines perform for our dataset.
</p>
</div>
</dd>
<dt><a name="item422">[422]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.05499" title="Abstract">arXiv:2309.05499</a> [<a href="/pdf/2309.05499" title="Download PDF">pdf</a>, <a href="/format/2309.05499" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Zero-Shot Co-salient Object Detection Framework
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xiao%2C+H">Haoke Xiao</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+L">Lv Tang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+B">Bo Li</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+Z">Zhiming Luo</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+S">Shaozi Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Co-salient Object Detection (CoSOD) endeavors to replicate the human visual
system's capacity to recognize common and salient objects within a collection
of images. Despite recent advancements in deep learning models, these models
still rely on training with well-annotated CoSOD datasets. The exploration of
training-free zero-shot CoSOD frameworks has been limited. In this paper,
taking inspiration from the zero-shot transfer capabilities of foundational
computer vision models, we introduce the first zero-shot CoSOD framework that
harnesses these models without any training process. To achieve this, we
introduce two novel components in our proposed framework: the group prompt
generation (GPG) module and the co-saliency map generation (CMP) module. We
evaluate the framework's performance on widely-used datasets and observe
impressive results. Our approach surpasses existing unsupervised methods and
even outperforms fully supervised methods developed before 2020, while
remaining competitive with some fully supervised methods developed before 2022.
</p>
</div>
</dd>
<dt><a name="item423">[423]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.05500" title="Abstract">arXiv:2309.05500</a> [<a href="/pdf/2309.05500" title="Download PDF">pdf</a>, <a href="/format/2309.05500" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> NeCo@ALQAC 2023: Legal Domain Knowledge Acquisition for Low-Resource  Languages through Data Enrichment
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+H">Hai-Long Nguyen</a>, 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+D">Dieu-Quynh Nguyen</a>, 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+H">Hoang-Trung Nguyen</a>, 
<a href="/search/cs?searchtype=author&query=Pham%2C+T">Thu-Trang Pham</a>, 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+H">Huu-Dong Nguyen</a>, 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+T">Thach-Anh Nguyen</a>, 
<a href="/search/cs?searchtype=author&query=Vuong%2C+T">Thi-Hai-Yen Vuong</a>, 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+H">Ha-Thanh Nguyen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ISAILD@KSE 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">In recent years, natural language processing has gained significant
popularity in various sectors, including the legal domain. This paper presents
NeCo Team's solutions to the Vietnamese text processing tasks provided in the
Automated Legal Question Answering Competition 2023 (ALQAC 2023), focusing on
legal domain knowledge acquisition for low-resource languages through data
enrichment. Our methods for the legal document retrieval task employ a
combination of similarity ranking and deep learning models, while for the
second task, which requires extracting an answer from a relevant legal article
in response to a question, we propose a range of adaptive techniques to handle
different question types. Our approaches achieve outstanding results on both
tasks of the competition, demonstrating the potential benefits and
effectiveness of question answering systems in the legal field, particularly
for low-resource languages.
</p>
</div>
</dd>
<dt><a name="item424">[424]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.05501" title="Abstract">arXiv:2309.05501</a> [<a href="/pdf/2309.05501" title="Download PDF">pdf</a>, <a href="/format/2309.05501" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Black-Box Analysis: GPTs Across Time in Legal Textual Entailment Task
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+H">Ha-Thanh Nguyen</a>, 
<a href="/search/cs?searchtype=author&query=Goebel%2C+R">Randy Goebel</a>, 
<a href="/search/cs?searchtype=author&query=Toni%2C+F">Francesca Toni</a>, 
<a href="/search/cs?searchtype=author&query=Stathis%2C+K">Kostas Stathis</a>, 
<a href="/search/cs?searchtype=author&query=Satoh%2C+K">Ken Satoh</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ISAILD@KSE 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">The evolution of Generative Pre-trained Transformer (GPT) models has led to
significant advancements in various natural language processing applications,
particularly in legal textual entailment. We present an analysis of GPT-3.5
(ChatGPT) and GPT-4 performances on COLIEE Task 4 dataset, a prominent
benchmark in this domain. The study encompasses data from Heisei 18 (2006) to
Reiwa 3 (2021), exploring the models' abilities to discern entailment
relationships within Japanese statute law across different periods. Our
preliminary experimental results unveil intriguing insights into the models'
strengths and weaknesses in handling legal textual entailment tasks, as well as
the patterns observed in model performance. In the context of proprietary
models with undisclosed architectures and weights, black-box analysis becomes
crucial for evaluating their capabilities. We discuss the influence of training
data distribution and the implications on the models' generalizability. This
analysis serves as a foundation for future research, aiming to optimize
GPT-based models and enable their successful adoption in legal information
extraction and entailment applications.
</p>
</div>
</dd>
<dt><a name="item425">[425]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.05503" title="Abstract">arXiv:2309.05503</a> [<a href="/pdf/2309.05503" title="Download PDF">pdf</a>, <a href="/format/2309.05503" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Long-Range Transformer Architectures for Document Understanding
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Douzon%2C+T">Thibault Douzon</a>, 
<a href="/search/cs?searchtype=author&query=Duffner%2C+S">Stefan Duffner</a>, 
<a href="/search/cs?searchtype=author&query=Garcia%2C+C">Christophe Garcia</a>, 
<a href="/search/cs?searchtype=author&query=Espinas%2C+J">J&#xe9;r&#xe9;my Espinas</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Conference: ICDAR 2023 Workshops on Document Analysis and Recognition
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Document Analysis and Recognition ICDAR 2023 Workshops pages 47 to
  64
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Since their release, Transformers have revolutionized many fields from
Natural Language Understanding to Computer Vision. Document Understanding (DU)
was not left behind with first Transformer based models for DU dating from late
2019. However, the computational complexity of the self-attention operation
limits their capabilities to small sequences. In this paper we explore multiple
strategies to apply Transformer based models to long multi-page documents. We
introduce 2 new multi-modal (text + layout) long-range models for DU. They are
based on efficient implementations of Transformers for long sequences.
Long-range models can process whole documents at once effectively and are less
impaired by the document's length. We compare them to LayoutLM, a classical
Transformer adapted for DU and pre-trained on millions of documents. We further
propose 2D relative attention bias to guide self-attention towards relevant
tokens without harming model efficiency. We observe improvements on multi-page
business documents on Information Retrieval for a small performance cost on
smaller sequences. Relative 2D attention revealed to be effective on dense text
for both normal and long-range models.
</p>
</div>
</dd>
<dt><a name="item426">[426]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.05505" title="Abstract">arXiv:2309.05505</a> [<a href="/pdf/2309.05505" title="Download PDF">pdf</a>, <a href="/format/2309.05505" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Share Your Representation Only: Guaranteed Improvement of the  Privacy-Utility Tradeoff in Federated Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shen%2C+Z">Zebang Shen</a>, 
<a href="/search/cs?searchtype=author&query=Ye%2C+J">Jiayuan Ye</a>, 
<a href="/search/cs?searchtype=author&query=Kang%2C+A">Anmin Kang</a>, 
<a href="/search/cs?searchtype=author&query=Hassani%2C+H">Hamed Hassani</a>, 
<a href="/search/cs?searchtype=author&query=Shokri%2C+R">Reza Shokri</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ICLR 2023 revised
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
<p class="mathjax">Repeated parameter sharing in federated learning causes significant
information leakage about private data, thus defeating its main purpose: data
privacy. Mitigating the risk of this information leakage, using state of the
art differentially private algorithms, also does not come for free. Randomized
mechanisms can prevent convergence of models on learning even the useful
representation functions, especially if there is more disagreement between
local models on the classification functions (due to data heterogeneity). In
this paper, we consider a representation federated learning objective that
encourages various parties to collaboratively refine the consensus part of the
model, with differential privacy guarantees, while separately allowing
sufficient freedom for local personalization (without releasing it). We prove
that in the linear representation setting, while the objective is non-convex,
our proposed new algorithm \DPFEDREP\ converges to a ball centered around the
\emph{global optimal} solution at a linear rate, and the radius of the ball is
proportional to the reciprocal of the privacy budget. With this novel utility
analysis, we improve the SOTA utility-privacy trade-off for this problem by a
factor of $\sqrt{d}$, where $d$ is the input dimension. We empirically evaluate
our method with the image classification task on CIFAR10, CIFAR100, and EMNIST,
and observe a significant performance improvement over the prior work under the
same small privacy budget. The code can be found in this link:
https://github.com/shenzebang/CENTAUR-Privacy-Federated-Representation-Learning.
</p>
</div>
</dd>
<dt><a name="item427">[427]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.05507" title="Abstract">arXiv:2309.05507</a> [<a href="/pdf/2309.05507" title="Download PDF">pdf</a>, <a href="/format/2309.05507" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Co-design Study for Multi-Stakeholder Job Recommender System  Explanations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Schellingerhout%2C+R">Roan Schellingerhout</a>, 
<a href="/search/cs?searchtype=author&query=Barile%2C+F">Francesco Barile</a>, 
<a href="/search/cs?searchtype=author&query=Tintarev%2C+N">Nava Tintarev</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Recent legislation proposals have significantly increased the demand for
eXplainable Artificial Intelligence (XAI) in many businesses, especially in
so-called `high-risk' domains, such as recruitment. Within recruitment, AI has
become commonplace, mainly in the form of job recommender systems (JRSs), which
try to match candidates to vacancies, and vice versa. However, common XAI
techniques often fall short in this domain due to the different levels and
types of expertise of the individuals involved, making explanations difficult
to generalize. To determine the explanation preferences of the different
stakeholder types - candidates, recruiters, and companies - we created and
validated a semi-structured interview guide. Using grounded theory, we
structurally analyzed the results of these interviews and found that different
stakeholder types indeed have strongly differing explanation preferences.
Candidates indicated a preference for brief, textual explanations that allow
them to quickly judge potential matches. On the other hand, hiring managers
preferred visual graph-based explanations that provide a more technical and
comprehensive overview at a glance. Recruiters found more exhaustive textual
explanations preferable, as those provided them with more talking points to
convince both parties of the match. Based on these findings, we describe
guidelines on how to design an explanation interface that fulfills the
requirements of all three stakeholder types. Furthermore, we provide the
validated interview guide, which can assist future research in determining the
explanation preferences of different stakeholder types.
</p>
</div>
</dd>
<dt><a name="item428">[428]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.05516" title="Abstract">arXiv:2309.05516</a> [<a href="/pdf/2309.05516" title="Download PDF">pdf</a>, <a href="/format/2309.05516" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Optimize Weight Rounding via Signed Gradient Descent for the  Quantization of LLMs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cheng%2C+W">Wenhua Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+W">Weiwei Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+H">Haihao Shen</a>, 
<a href="/search/cs?searchtype=author&query=Cai%2C+Y">Yiyang Cai</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+X">Xin He</a>, 
<a href="/search/cs?searchtype=author&query=Lv%2C+K">Kaokao Lv</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Large Language Models (LLMs) have proven their exceptional capabilities in
performing language-related tasks. However, their deployment poses significant
challenges due to their considerable memory and storage requirements. In
response to this issue, weight-only quantization, particularly 3 and 4-bit
weight-only quantization, has emerged as one of the most viable solutions. As
the number of bits decreases, the quantization grid broadens, thus emphasizing
the importance of up and down rounding. While previous studies have
demonstrated that fine-tuning up and down rounding with the addition of
perturbations can enhance accuracy in some scenarios, our study is driven by
the precise and limited boundary of these perturbations, where only the
threshold for altering the rounding value is of significance. Consequently, we
propose a concise and highly effective approach for optimizing the weight
rounding task. Our method, named SignRound, involves lightweight block-wise
tuning using signed gradient descent, enabling us to achieve outstanding
results within 400 steps. SignRound outperforms the established baseline of
rounding-to-nearest (RTN) and competes impressively against recent methods,
without introducing additional inference overhead. The source code will be
publicly available at https://github.com/intel/neural-compressor soon.
</p>
</div>
</dd>
<dt><a name="item429">[429]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.05517" title="Abstract">arXiv:2309.05517</a> [<a href="/pdf/2309.05517" title="Download PDF">pdf</a>, <a href="/format/2309.05517" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Stream-based Active Learning by Exploiting Temporal Properties in  Perception with Temporal Predicted Loss
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Schmidt%2C+S">Sebastian Schmidt</a> (BMW and TUM), 
<a href="/search/cs?searchtype=author&query=G%C3%BCnnemann%2C+S">Stephan G&#xfc;nnemann</a> (TUM)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Active learning (AL) reduces the amount of labeled data needed to train a
machine learning model by intelligently choosing which instances to label.
Classic pool-based AL requires all data to be present in a datacenter, which
can be challenging with the increasing amounts of data needed in deep learning.
However, AL on mobile devices and robots, like autonomous cars, can filter the
data from perception sensor streams before reaching the datacenter. We
exploited the temporal properties for such image streams in our work and
proposed the novel temporal predicted loss (TPL) method. To evaluate the
stream-based setting properly, we introduced the GTA V streets and the A2D2
streets dataset and made both publicly available. Our experiments showed that
our approach significantly improves the diversity of the selection while being
an uncertainty-based method. As pool-based approaches are more common in
perception applications, we derived a concept for comparing pool-based and
stream-based AL, where TPL out-performed state-of-the-art pool- or stream-based
approaches for different models. TPL demonstrated a gain of 2.5 precept points
(pp) less required data while being significantly faster than pool-based
methods.
</p>
</div>
</dd>
<dt><a name="item430">[430]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.05518" title="Abstract">arXiv:2309.05518</a> [<a href="/pdf/2309.05518" title="Download PDF">pdf</a>, <a href="/format/2309.05518" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> STAR-loc: Dataset for STereo And Range-based localization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=D%C3%BCmbgen%2C+F">Frederike D&#xfc;mbgen</a>, 
<a href="/search/cs?searchtype=author&query=Shalaby%2C+M+A">Mohammed A. Shalaby</a>, 
<a href="/search/cs?searchtype=author&query=Holmes%2C+C">Connor Holmes</a>, 
<a href="/search/cs?searchtype=author&query=Cossette%2C+C+C">Charles C. Cossette</a>, 
<a href="/search/cs?searchtype=author&query=Forbes%2C+J+R">James R. Forbes</a>, 
<a href="/search/cs?searchtype=author&query=Ny%2C+J+L">Jerome Le Ny</a>, 
<a href="/search/cs?searchtype=author&query=Barfoot%2C+T+D">Timothy D. Barfoot</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 15 pages, 15 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">This document contains a detailed description of the STAR-loc dataset. For a
quick starting guide please refer to the associated Github repository
(https://github.com/utiasASRL/starloc). The dataset consists of stereo camera
data (rectified/raw images and inertial measurement unit measurements) and
ultra-wideband (UWB) data (range measurements) collected on a sensor rig in a
Vicon motion capture arena. The UWB anchors and visual landmarks (Apriltags)
are of known position, so the dataset can be used for both localization and
Simultaneous Localization and Mapping (SLAM).
</p>
</div>
</dd>
<dt><a name="item431">[431]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.05519" title="Abstract">arXiv:2309.05519</a> [<a href="/pdf/2309.05519" title="Download PDF">pdf</a>, <a href="/format/2309.05519" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> NExT-GPT: Any-to-Any Multimodal LLM
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+S">Shengqiong Wu</a>, 
<a href="/search/cs?searchtype=author&query=Fei%2C+H">Hao Fei</a>, 
<a href="/search/cs?searchtype=author&query=Qu%2C+L">Leigang Qu</a>, 
<a href="/search/cs?searchtype=author&query=Ji%2C+W">Wei Ji</a>, 
<a href="/search/cs?searchtype=author&query=Chua%2C+T">Tat-Seng Chua</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> work in progress
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computation and Language (cs.CL); Machine Learning (cs.LG)

</div>
<p class="mathjax">While recently Multimodal Large Language Models (MM-LLMs) have made exciting
strides, they mostly fall prey to the limitation of only input-side multimodal
understanding, without the ability to produce content in multiple modalities.
As we humans always perceive the world and communicate with people through
various modalities, developing any-to-any MM-LLMs capable of accepting and
delivering content in any modality becomes essential to human-level AI. To fill
the gap, we present an end-to-end general-purpose any-to-any MM-LLM system,
NExT-GPT. We connect an LLM with multimodal adaptors and different diffusion
decoders, enabling NExT-GPT to perceive inputs and generate outputs in
arbitrary combinations of text, images, videos, and audio. By leveraging the
existing well-trained highly-performing encoders and decoders, NExT-GPT is
tuned with only a small amount of parameter (1%) of certain projection layers,
which not only benefits low-cost training and also facilitates convenient
expansion to more potential modalities. Moreover, we introduce a
modality-switching instruction tuning (MosIT) and manually curate a
high-quality dataset for MosIT, based on which NExT-GPT is empowered with
complex cross-modal semantic understanding and content generation. Overall, our
research showcases the promising possibility of building an AI agent capable of
modeling universal modalities, paving the way for more human-like AI research
in the community.
</p>
</div>
</dd>
<dt><a name="item432">[432]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.05520" title="Abstract">arXiv:2309.05520</a> [<a href="/pdf/2309.05520" title="Download PDF">pdf</a>, <a href="/format/2309.05520" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> When ChatGPT Meets Smart Contract Vulnerability Detection: How Far Are  We?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+C">Chong Chen</a>, 
<a href="/search/cs?searchtype=author&query=Su%2C+J">Jianzhong Su</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Jiachi Chen</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yanlin Wang</a>, 
<a href="/search/cs?searchtype=author&query=Bi%2C+T">Tingting Bi</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yanli Wang</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+X">Xingwei Lin</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+T">Ting Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+Z">Zibin Zheng</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
<p class="mathjax">With the development of blockchain technology, smart contracts have become an
important component of blockchain applications. Despite their crucial role, the
development of smart contracts may introduce vulnerabilities and potentially
lead to severe consequences, such as financial losses. Meanwhile, large
language models, represented by ChatGPT, have gained great attentions,
showcasing great capabilities in code analysis tasks. In this paper, we
presented an empirical study to investigate the performance of ChatGPT in
identifying smart contract vulnerabilities. Initially, we evaluated ChatGPT's
effectiveness using a publicly available smart contract dataset. Our findings
discover that while ChatGPT achieves a high recall rate, its precision in
pinpointing smart contract vulnerabilities is limited. Furthermore, ChatGPT's
performance varies when detecting different vulnerability types. We delved into
the root causes for the false positives generated by ChatGPT, and categorized
them into four groups. Second, by comparing ChatGPT with other state-of-the-art
smart contract vulnerability detection tools, we found that ChatGPT's F-score
is lower than others for 3 out of the 7 vulnerabilities. In the case of the
remaining 4 vulnerabilities, ChatGPT exhibits a slight advantage over these
tools. Finally, we analyzed the limitation of ChatGPT in smart contract
vulnerability detection, revealing that the robustness of ChatGPT in this field
needs to be improved from two aspects: its uncertainty in answering questions;
and the limited length of the detected code. In general, our research provides
insights into the strengths and weaknesses of employing large language models,
specifically ChatGPT, for the detection of smart contract vulnerabilities.
</p>
</div>
</dd>
<dt><a name="item433">[433]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.05521" title="Abstract">arXiv:2309.05521</a> [<a href="/pdf/2309.05521" title="Download PDF">pdf</a>, <a href="/ps/2309.05521" title="Download PostScript">ps</a>, <a href="/format/2309.05521" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Re-formalization of Individual Fairness
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kamishima%2C+T">Toshihiro Kamishima</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Published at the 6th FAccTRec Workshop: Responsible Recommendation
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computers and Society (cs.CY); Information Retrieval (cs.IR)

</div>
<p class="mathjax">The notion of individual fairness is a formalization of an ethical principle,
"Treating like cases alike," which has been argued such as by Aristotle. In a
fairness-aware machine learning context, Dwork et al. firstly formalized the
notion. In their formalization, a similar pair of data in an unfair space
should be mapped to similar positions in a fair space. We propose to
re-formalize individual fairness by the statistical independence conditioned by
individuals. This re-formalization has the following merits. First, our
formalization is compatible with that of Dwork et al. Second, our formalization
enables to combine individual fairness with the fairness notion, equalized odds
or sufficiency, as well as statistical parity. Third, though their
formalization implicitly assumes a pre-process approach for making fair
prediction, our formalization is applicable to an in-process or post-process
approach.
</p>
</div>
</dd>
<dt><a name="item434">[434]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.05525" title="Abstract">arXiv:2309.05525</a> [<a href="/pdf/2309.05525" title="Download PDF">pdf</a>, <a href="/format/2309.05525" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Advancing Federated Learning in 6G: A Trusted Architecture with  Graph-based Analysis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ye%2C+W">Wenxuan Ye</a>, 
<a href="/search/cs?searchtype=author&query=Qian%2C+C">Chendi Qian</a>, 
<a href="/search/cs?searchtype=author&query=An%2C+X">Xueli An</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+X">Xueqiang Yan</a>, 
<a href="/search/cs?searchtype=author&query=Carle%2C+G">Georg Carle</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Integrating native AI support into the network architecture is an essential
objective of 6G. Federated Learning (FL) emerges as a potential paradigm,
facilitating decentralized AI model training across a diverse range of devices
under the coordination of a central server. However, several challenges hinder
its wide application in the 6G context, such as malicious attacks and privacy
snooping on local model updates, and centralization pitfalls. This work
proposes a trusted architecture for supporting FL, which utilizes Distributed
Ledger Technology (DLT) and Graph Neural Network (GNN), including three key
features. First, a pre-processing layer employing homomorphic encryption is
incorporated to securely aggregate local models, preserving the privacy of
individual models. Second, given the distributed nature and graph structure
between clients and nodes in the pre-processing layer, GNN is leveraged to
identify abnormal local models, enhancing system security. Third, DLT is
utilized to decentralize the system by selecting one of the candidates to
perform the central server's functions. Additionally, DLT ensures reliable data
management by recording data exchanges in an immutable and transparent ledger.
The feasibility of the novel architecture is validated through simulations,
demonstrating improved performance in anomalous model detection and global
model accuracy compared to relevant baselines.
</p>
</div>
</dd>
<dt><a name="item435">[435]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.05527" title="Abstract">arXiv:2309.05527</a> [<a href="/pdf/2309.05527" title="Download PDF">pdf</a>, <a href="/format/2309.05527" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ReSimAD: Zero-Shot 3D Domain Transfer for Autonomous Driving with Source  Reconstruction and Target Simulation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+B">Bo Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Cai%2C+X">Xinyu Cai</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+J">Jiakang Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+D">Donglin Yang</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+J">Jianfei Guo</a>, 
<a href="/search/cs?searchtype=author&query=Xia%2C+R">Renqiu Xia</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+B">Botian Shi</a>, 
<a href="/search/cs?searchtype=author&query=Dou%2C+M">Min Dou</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+T">Tao Chen</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+S">Si Liu</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+J">Junchi Yan</a>, 
<a href="/search/cs?searchtype=author&query=Qiao%2C+Y">Yu Qiao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Code and simulated points are available at <a href="https://github.com/PJLab-ADG/3DTrans\#resimad">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Domain shifts such as sensor type changes and geographical situation
variations are prevalent in Autonomous Driving (AD), which poses a challenge
since AD model relying on the previous-domain knowledge can be hardly directly
deployed to a new domain without additional costs. In this paper, we provide a
new perspective and approach of alleviating the domain shifts, by proposing a
Reconstruction-Simulation-Perception (ReSimAD) scheme. Specifically, the
implicit reconstruction process is based on the knowledge from the previous old
domain, aiming to convert the domain-related knowledge into domain-invariant
representations, \textit{e.g.}, 3D scene-level meshes. Besides, the point
clouds simulation process of multiple new domains is conditioned on the above
reconstructed 3D meshes, where the target-domain-like simulation samples can be
obtained, thus reducing the cost of collecting and annotating new-domain data
for the subsequent perception process. For experiments, we consider different
cross-domain situations such as Waymo-to-KITTI, Waymo-to-nuScenes,
Waymo-to-ONCE, \textit{etc}, to verify the \textbf{zero-shot} target-domain
perception using ReSimAD. Results demonstrate that our method is beneficial to
boost the domain generalization ability, even promising for 3D pre-training.
</p>
</div>
</dd>
<dt><a name="item436">[436]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.05528" title="Abstract">arXiv:2309.05528</a> [<a href="/pdf/2309.05528" title="Download PDF">pdf</a>, <a href="/format/2309.05528" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the detection of Out-Of-Distribution samples in Multiple Instance  Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bescond%2C+L+L">Lo&#xef;c Le Bescond</a>, 
<a href="/search/cs?searchtype=author&query=Vakalopoulou%2C+M">Maria Vakalopoulou</a>, 
<a href="/search/cs?searchtype=author&query=Christodoulidis%2C+S">Stergios Christodoulidis</a>, 
<a href="/search/cs?searchtype=author&query=Andr%C3%A9%2C+F">Fabrice Andr&#xe9;</a>, 
<a href="/search/cs?searchtype=author&query=Talbot%2C+H">Hugues Talbot</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">The deployment of machine learning solutions in real-world scenarios often
involves addressing the challenge of out-of-distribution (OOD) detection. While
significant efforts have been devoted to OOD detection in classical supervised
settings, the context of weakly supervised learning, particularly the Multiple
Instance Learning (MIL) framework, remains under-explored. In this study, we
tackle this challenge by adapting post-hoc OOD detection methods to the MIL
setting while introducing a novel benchmark specifically designed to assess OOD
detection performance in weakly supervised scenarios. Extensive experiments
based on diverse public datasets do not reveal a single method with a clear
advantage over the others. Although DICE emerges as the best-performing method
overall, it exhibits significant shortcomings on some datasets, emphasizing the
complexity of this under-explored and challenging topic. Our findings shed
light on the complex nature of OOD detection under the MIL framework,
emphasizing the importance of developing novel, robust, and reliable methods
that can generalize effectively in a weakly supervised context. The code for
the paper is available here: https://github.com/loic-lb/OOD_MIL.
</p>
</div>
</dd>
<dt><a name="item437">[437]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.05529" title="Abstract">arXiv:2309.05529</a> [<a href="/pdf/2309.05529" title="Download PDF">pdf</a>, <a href="/format/2309.05529" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the meaning of uncertainty for ethical AI: philosophy and practice
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bird%2C+C">Cassandra Bird</a>, 
<a href="/search/cs?searchtype=author&query=Williamson%2C+D">Daniel Williamson</a>, 
<a href="/search/cs?searchtype=author&query=Leonelli%2C+S">Sabina Leonelli</a> (University of Exeter)
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 26 pages, 2 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Statistics Theory (math.ST)

</div>
<p class="mathjax">Whether and how data scientists, statisticians and modellers should be
accountable for the AI systems they develop remains a controversial and highly
debated topic, especially given the complexity of AI systems and the
difficulties in comparing and synthesising competing claims arising from their
deployment for data analysis. This paper proposes to address this issue by
decreasing the opacity and heightening the accountability of decision making
using AI systems, through the explicit acknowledgement of the statistical
foundations that underpin their development and the ways in which these dictate
how their results should be interpreted and acted upon by users. In turn, this
enhances (1) the responsiveness of the models to feedback, (2) the quality and
meaning of uncertainty on their outputs and (3) their transparency to
evaluation. To exemplify this approach, we extend Posterior Belief Assessment
to offer a route to belief ownership from complex and competing AI structures.
We argue that this is a significant way to bring ethical considerations into
mathematical reasoning, and to implement ethical AI in statistical practice. We
demonstrate these ideas within the context of competing models used to advise
the UK government on the spread of the Omicron variant of COVID-19 during
December 2021.
</p>
</div>
</dd>
<dt><a name="item438">[438]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.05530" title="Abstract">arXiv:2309.05530</a> [<a href="/pdf/2309.05530" title="Download PDF">pdf</a>, <a href="/format/2309.05530" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Stable $C^1$-conforming finite element methods for the  Landau--Lifshitz--Baryakhtar equation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Soenjaya%2C+A+L">Agus L. Soenjaya</a>, 
<a href="/search/math?searchtype=author&query=Tran%2C+T">Thanh Tran</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">The Landau--Lifshitz--Baryakhtar equation describes the evolution of magnetic
spin field in magnetic materials at elevated temperature below the Curie
temperature, when long-range interactions and longitudinal dynamics are taken
into account. We propose two linear fully-discrete $C^1$-conforming methods to
solve the problem, namely a semi-implicit Euler method and a semi-implicit BDF
method, and show that these schemes are unconditionally stable. Error analysis
is performed which shows optimal convergence rates in each case. Numerical
results corroborate our theoretical results.
</p>
</div>
</dd>
<dt><a name="item439">[439]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.05533" title="Abstract">arXiv:2309.05533</a> [<a href="/pdf/2309.05533" title="Download PDF">pdf</a>, <a href="/format/2309.05533" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Safe and Stable Adaptive Control for a Class of Dynamic Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Autenrieb%2C+J">Johannes Autenrieb</a>, 
<a href="/search/eess?searchtype=author&query=Annaswamy%2C+A+M">Anuradha M. Annaswamy</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 5 figures, IEEE CDC 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Optimization and Control (math.OC)

</div>
<p class="mathjax">Adaptive control has focused on online control of dynamic systems in the
presence of parametric uncertainties, with solutions guaranteeing stability and
control performance. Safety, a related property to stability, is becoming
increasingly important as the footprint of autonomous systems grows in society.
One of the popular ways for ensuring safety is through the notion of a control
barrier function (CBF). In this paper, we combine adaptation and CBFs to
develop a real-time controller that guarantees stability and remains safe in
the presence of parametric uncertainties. The class of dynamic systems that we
focus on is linear time-invariant systems whose states are accessible and where
the inputs are subject to a magnitude limit. Conditions of stability, state
convergence to a desired value, and parameter learning are all elucidated. One
of the elements of the proposed adaptive controller that ensures stability and
safety is the use of a CBF-based safety filter that suitably generates safe
reference commands, employs error-based relaxation (EBR) of Nagumo's theorem,
and leads to guarantees of set invariance. To demonstrate the effectiveness of
our approach, we present two numerical examples, an obstacle avoidance case and
a missile flight control case.
</p>
</div>
</dd>
<dt><a name="item440">[440]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.05534" title="Abstract">arXiv:2309.05534</a> [<a href="/pdf/2309.05534" title="Download PDF">pdf</a>, <a href="/format/2309.05534" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PAI-Diffusion: Constructing and Serving a Family of Open Chinese  Diffusion Models for Text-to-image Synthesis on the Cloud
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+C">Chengyu Wang</a>, 
<a href="/search/cs?searchtype=author&query=Duan%2C+Z">Zhongjie Duan</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+B">Bingyan Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zou%2C+X">Xinyi Zou</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+C">Cen Chen</a>, 
<a href="/search/cs?searchtype=author&query=Jia%2C+K">Kui Jia</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+J">Jun Huang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Text-to-image synthesis for the Chinese language poses unique challenges due
to its large vocabulary size, and intricate character relationships. While
existing diffusion models have shown promise in generating images from textual
descriptions, they often neglect domain-specific contexts and lack robustness
in handling the Chinese language. This paper introduces PAI-Diffusion, a
comprehensive framework that addresses these limitations. PAI-Diffusion
incorporates both general and domain-specific Chinese diffusion models,
enabling the generation of contextually relevant images. It explores the
potential of using LoRA and ControlNet for fine-grained image style transfer
and image editing, empowering users with enhanced control over image
generation. Moreover, PAI-Diffusion seamlessly integrates with Alibaba Cloud's
Machine Learning Platform for AI, providing accessible and scalable solutions.
All the Chinese diffusion model checkpoints, LoRAs, and ControlNets, including
domain-specific ones, are publicly available. A user-friendly Chinese WebUI and
the diffusers-api elastic inference toolkit, also open-sourced, further
facilitate the easy deployment of PAI-Diffusion models in various environments,
making it a valuable resource for Chinese text-to-image synthesis.
</p>
</div>
</dd>
<dt><a name="item441">[441]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.05537" title="Abstract">arXiv:2309.05537</a> [<a href="/pdf/2309.05537" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> D2WFP: A Novel Protocol for Forensically Identifying, Extracting, and  Analysing Deep and Dark Web Browsing Activities
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ghanem%2C+M+C">Mohamed Chahine Ghanem</a>, 
<a href="/search/cs?searchtype=author&query=Mulvihill%2C+P">Patrick Mulvihill</a>, 
<a href="/search/cs?searchtype=author&query=Ouazzane%2C+K">Karim Ouazzane</a>, 
<a href="/search/cs?searchtype=author&query=Djemai%2C+R">Ramzi Djemai</a>, 
<a href="/search/cs?searchtype=author&query=Dunsin%2C+D">Dipo Dunsin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Information Retrieval (cs.IR); Networking and Internet Architecture (cs.NI); Operating Systems (cs.OS)

</div>
<p class="mathjax">The use of the un-indexed web, commonly known as the deep web and dark web,
to commit or facilitate criminal activity has drastically increased over the
past decade. The dark web is an in-famously dangerous place where all kinds of
criminal activities take place [1-2], despite advances in web forensics
techniques, tools, and methodologies, few studies have formally tackled the
dark and deep web forensics and the technical differences in terms of
investigative techniques and artefacts identification and extraction. This
research proposes a novel and comprehensive protocol to guide and assist
digital forensics professionals in investigating crimes committed on or via the
deep and dark web, The protocol named D2WFP establishes a new sequential
approach for performing investigative activities by observing the order of
volatility and implementing a systemic approach covering all browsing related
hives and artefacts which ultimately resulted into improv-ing the accuracy and
effectiveness. Rigorous quantitative and qualitative research has been
conducted by assessing D2WFP following a scientifically-sound and comprehensive
process in different scenarios and the obtained results show an apparent
increase in the number of artefacts re-covered when adopting D2WFP which
outperform any current industry or opensource browsing forensics tools. The
second contribution of D2WFP is the robust formulation of artefact correlation
and cross-validation within D2WFP which enables digital forensics professionals
to better document and structure their analysis of host-based deep and dark web
browsing artefacts.
</p>
</div>
</dd>
<dt><a name="item442">[442]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.05542" title="Abstract">arXiv:2309.05542</a> [<a href="/pdf/2309.05542" title="Download PDF">pdf</a>, <a href="/format/2309.05542" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Kani: A Lightweight and Highly Hackable Framework for Building Language  Model Applications
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhu%2C+A">Andrew Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Dugan%2C+L">Liam Dugan</a>, 
<a href="/search/cs?searchtype=author&query=Hwang%2C+A">Alyssa Hwang</a>, 
<a href="/search/cs?searchtype=author&query=Callison-Burch%2C+C">Chris Callison-Burch</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> In submission to NLP-OSS
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL)

</div>
<p class="mathjax">Language model applications are becoming increasingly popular and complex,
often including features like tool usage and retrieval augmentation. However,
existing frameworks for such applications are often opinionated, deciding for
developers how their prompts ought to be formatted and imposing limitations on
customizability and reproducibility. To solve this we present Kani: a
lightweight, flexible, and model-agnostic open-source framework for building
language model applications. Kani helps developers implement a variety of
complex features by supporting the core building blocks of chat interaction:
model interfacing, chat management, and robust function calling. All Kani core
functions are easily overridable and well documented to empower developers to
customize functionality for their own needs. Kani thus serves as a useful tool
for researchers, hobbyists, and industry professionals alike to accelerate
their development while retaining interoperability and fine-grained control.
</p>
</div>
</dd>
<dt><a name="item443">[443]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.05545" title="Abstract">arXiv:2309.05545</a> [<a href="/pdf/2309.05545" title="Download PDF">pdf</a>, <a href="/format/2309.05545" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Nonlinear Model Predictive Control for Uranium Extraction-Scrubbing  Operation in Spent Nuclear Fuel Treatment Process
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Vo%2C+D">Duc-Tri Vo</a>, 
<a href="/search/eess?searchtype=author&query=Prodan%2C+I">Ionela Prodan</a>, 
<a href="/search/eess?searchtype=author&query=Lef%C3%A8vre%2C+L">Laurent Lef&#xe8;vre</a>, 
<a href="/search/eess?searchtype=author&query=Vanel%2C+V">Vincent Vanel</a>, 
<a href="/search/eess?searchtype=author&query=Costenoble%2C+S">Sylvain Costenoble</a>, 
<a href="/search/eess?searchtype=author&query=Dinh%2C+B">Binh Dinh</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">This paper addresses the particularities of the uranium extraction-scrubbing
operation in a spent nuclear fuel treatment process (PUREX-Plutonium Uranium
Refining by Extraction) through the use of set-point tracking MPC (Model
Predictive Control). The presented controller uses the feed solution flow rate
as the manipulated variable to control the saturation of the solvent at the
extraction step. In addition, it guarantees not to loose uranium in the
raffinates, and ensures equipment limitations during operation time. Simulation
results show that the tracking NMPC effectively ensures accurate set point
tracking and constraints guarantee. As a result, the system can be driven to
its optimal working condition, avoid and recover from constraint violations.
The control performance was compared with PID and openloop controllers.
</p>
</div>
</dd>
<dt><a name="item444">[444]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.05548" title="Abstract">arXiv:2309.05548</a> [<a href="/pdf/2309.05548" title="Download PDF">pdf</a>, <a href="/format/2309.05548" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Distance-Aware eXplanation Based Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hagos%2C+M+T">Misgina Tsighe Hagos</a>, 
<a href="/search/cs?searchtype=author&query=Belton%2C+N">Niamh Belton</a>, 
<a href="/search/cs?searchtype=author&query=Curran%2C+K+M">Kathleen M. Curran</a>, 
<a href="/search/cs?searchtype=author&query=Mac+Namee%2C+B">Brian Mac Namee</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at the 35th IEEE International Conference on Tools with Artificial Intelligence, ICTAI 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">eXplanation Based Learning (XBL) is an interactive learning approach that
provides a transparent method of training deep learning models by interacting
with their explanations. XBL augments loss functions to penalize a model based
on deviation of its explanations from user annotation of image features. The
literature on XBL mostly depends on the intersection of visual model
explanations and image feature annotations. We present a method to add a
distance-aware explanation loss to categorical losses that trains a learner to
focus on important regions of a training dataset. Distance is an appropriate
approach for calculating explanation loss since visual model explanations such
as Gradient-weighted Class Activation Mapping (Grad-CAMs) are not strictly
bounded as annotations and their intersections may not provide complete
information on the deviation of a model's focus from relevant image regions. In
addition to assessing our model using existing metrics, we propose an
interpretability metric for evaluating visual feature-attribution based model
explanations that is more informative of the model's performance than existing
metrics. We demonstrate performance of our proposed method on three image
classification tasks.
</p>
</div>
</dd>
<dt><a name="item445">[445]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.05550" title="Abstract">arXiv:2309.05550</a> [<a href="/pdf/2309.05550" title="Download PDF">pdf</a>, <a href="/format/2309.05550" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multiplierless Design of High-Speed Very Large Constant Multiplications
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Aksoy%2C+L">Levent Aksoy</a>, 
<a href="/search/cs?searchtype=author&query=Roy%2C+D+B">Debapriya Basu Roy</a>, 
<a href="/search/cs?searchtype=author&query=Imran%2C+M">Malik Imran</a>, 
<a href="/search/cs?searchtype=author&query=Pagliarini%2C+S">Samuel Pagliarini</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">In cryptographic algorithms, the constants to be multiplied by a variable can
be very large due to security requirements. Thus, the hardware complexity of
such algorithms heavily depends on the design architecture handling large
constants. In this paper, we introduce an electronic design automation tool,
called LEIGER, which can automatically generate the realizations of very large
constant multiplications for low-complexity and high-speed applications,
targeting the ASIC design platform. LEIGER can utilize the shift-adds
architecture and use 3-input operations, i.e., carry-save adders (CSAs), where
the number of CSAs is reduced using a prominent optimization algorithm. It can
also generate constant multiplications under a hybrid design architecture,
where 2-and 3-input operations are used at different stages. Moreover, it can
describe constant multiplications under a design architecture using compressor
trees. As a case study, high-speed Montgomery multiplication, which is a
fundamental operation in cryptographic algorithms, is designed with its
constant multiplication block realized under the proposed architectures.
Experimental results indicate that LEIGER enables a designer to explore the
trade-off between area and delay of the very large constant and Montgomery
multiplications and leads to designs with area-delay product, latency, and
energy consumption values significantly better than those obtained by a
recently proposed algorithm.
</p>
</div>
</dd>
<dt><a name="item446">[446]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.05551" title="Abstract">arXiv:2309.05551</a> [<a href="/pdf/2309.05551" title="Download PDF">pdf</a>, <a href="/format/2309.05551" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> OpenFashionCLIP: Vision-and-Language Contrastive Learning with  Open-Source Fashion Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cartella%2C+G">Giuseppe Cartella</a>, 
<a href="/search/cs?searchtype=author&query=Baldrati%2C+A">Alberto Baldrati</a>, 
<a href="/search/cs?searchtype=author&query=Morelli%2C+D">Davide Morelli</a>, 
<a href="/search/cs?searchtype=author&query=Cornia%2C+M">Marcella Cornia</a>, 
<a href="/search/cs?searchtype=author&query=Bertini%2C+M">Marco Bertini</a>, 
<a href="/search/cs?searchtype=author&query=Cucchiara%2C+R">Rita Cucchiara</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> International Conference on Image Analysis and Processing (ICIAP) 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">The inexorable growth of online shopping and e-commerce demands scalable and
robust machine learning-based solutions to accommodate customer requirements.
In the context of automatic tagging classification and multimodal retrieval,
prior works either defined a low generalizable supervised learning approach or
more reusable CLIP-based techniques while, however, training on closed source
data. In this work, we propose OpenFashionCLIP, a vision-and-language
contrastive learning method that only adopts open-source fashion data stemming
from diverse domains, and characterized by varying degrees of specificity. Our
approach is extensively validated across several tasks and benchmarks, and
experimental results highlight a significant out-of-domain generalization
capability and consistent improvements over state-of-the-art methods both in
terms of accuracy and recall. Source code and trained models are publicly
available at: https://github.com/aimagelab/open-fashion-clip.
</p>
</div>
</dd>
<dt><a name="item447">[447]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.05554" title="Abstract">arXiv:2309.05554</a> [<a href="/pdf/2309.05554" title="Download PDF">pdf</a>, <a href="/ps/2309.05554" title="Download PostScript">ps</a>, <a href="/format/2309.05554" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Concentration of Submodular Functions Under Negative Dependence
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Duppala%2C+S">Sharmila Duppala</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+G+Z">George Z. Li</a>, 
<a href="/search/cs?searchtype=author&query=Luque%2C+J">Juan Luque</a>, 
<a href="/search/cs?searchtype=author&query=Srinivasan%2C+A">Aravind Srinivasan</a>, 
<a href="/search/cs?searchtype=author&query=Valieva%2C+R">Renata Valieva</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>

</div>
<p class="mathjax">We study the question of whether submodular functions of random variables
satisfying various notions of negative dependence satisfy Chernoff-like
concentration inequalities. We prove such a concentration inequality for the
lower tail when the random variables satisfy negative association or negative
regression, resolving an open problem raised in (\citet{approx/QiuS22}).
Previous work showed such concentration results for random variables that come
from specific dependent-rounding algorithms
(\citet{focs/ChekuriVZ10,soda/HarveyO14}). We discuss some applications of our
results to combinatorial optimization and beyond.
</p>
</div>
</dd>
<dt><a name="item448">[448]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.05555" title="Abstract">arXiv:2309.05555</a> [<a href="/pdf/2309.05555" title="Download PDF">pdf</a>, <a href="/format/2309.05555" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Unraveling Managerial Tangents in Firm Disclosure: Concealing Issues or  Being Exposed?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhou%2C+X">Xuan Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+Y">Yushen Huang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Engineering, Finance, and Science (cs.CE)</span>

</div>
<p class="mathjax">Earnings calls influence stock prices and are traditionally analyzed using
sentiment and linguistic traces. Our research introduces a "Topic-Switching
Index," a novel metric quantified through the transformer model FinBERT, to
measure managerial evasion during Q$\&amp;$A sessions in earnings calls. We find a
negative correlation between this index and subsequent stock prices, indicating
that investors penalize managerial evasiveness. This study is the first to
quantify such evasive tactics, adding a new dimension to how earnings calls are
understood and suggesting that topic shifting is an overlooked but significant
factor. We also show the predictability of the index under three different
classifier models and it stands out in all circumstances.
</p>
</div>
</dd>
<dt><a name="item449">[449]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.05557" title="Abstract">arXiv:2309.05557</a> [<a href="/pdf/2309.05557" title="Download PDF">pdf</a>, <a href="/format/2309.05557" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An Empirical Study of NetOps Capability of Pre-Trained Large Language  Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Miao%2C+Y">Yukai Miao</a>, 
<a href="/search/cs?searchtype=author&query=Bai%2C+Y">Yu Bai</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+L">Li Chen</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+D">Dan Li</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+H">Haifeng Sun</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xizheng Wang</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+Z">Ziqiu Luo</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+D">Dapeng Sun</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+X">Xiuting Xu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Networking and Internet Architecture (cs.NI)

</div>
<p class="mathjax">Large language models (LLMs) can respond to human language queries and have
shown powerful potential applications in network operations (NetOps). Thanks to
the large amount of commonsense knowledge inherent, LLMs achieve much better
inference accuracy than traditional models and emerge with strong abilities in
generalization, reasoning, and code generation. These abilities may have a
crucial boost to automated and intelligent NetOps. However, it remains
under-explored how well LLMs perform in various NetOps tasks. In this work, we
make a systematic assessment of the capabilities, strengths, and limitations of
selected LLMs in the field of NetOps. The evaluation is conducted on a
collection of 5,732 questions about NetOps, encompassing 26 publicly available
general-domain LLMs, including ChatGPT, LLaMA, Falcon, etc. We also finetune
some of these LLMs with our collected NetOps corpus and evaluate the resulting
models. The evaluation method follows the widely adopted benchmarks for
general-domain LLMs, combined with Chain-of-Thought Prompts and
Retrieval-Augmented Generation. The results show that only GPT-4 achieves high
accuracy equivalent to passing the NetOps certification exam for humans, while
all the other LLMs have much lower accuracy. However, some open models like
LLaMA 2 still demonstrate significant potential. Furthermore, we evaluate the
impact of factors such as model parameters, prompt engineering, instruction
fine-tuning etc. This work shall be treated as the initial effort to systematic
evaluation of LLMs in NetOps, and a more rigorous study is required for
production use. The evaluation code and dataset will be released to benefit
future research.
</p>
</div>
</dd>
<dt><a name="item450">[450]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.05569" title="Abstract">arXiv:2309.05569</a> [<a href="/pdf/2309.05569" title="Download PDF">pdf</a>, <a href="/format/2309.05569" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ITI-GEN: Inclusive Text-to-Image Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+C">Cheng Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+X">Xuanbai Chen</a>, 
<a href="/search/cs?searchtype=author&query=Chai%2C+S">Siqi Chai</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+C+H">Chen Henry Wu</a>, 
<a href="/search/cs?searchtype=author&query=Lagun%2C+D">Dmitry Lagun</a>, 
<a href="/search/cs?searchtype=author&query=Beeler%2C+T">Thabo Beeler</a>, 
<a href="/search/cs?searchtype=author&query=De+la+Torre%2C+F">Fernando De la Torre</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to ICCV 2023 (Oral Presentation)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Machine Learning (cs.LG)

</div>
<p class="mathjax">Text-to-image generative models often reflect the biases of the training
data, leading to unequal representations of underrepresented groups. This study
investigates inclusive text-to-image generative models that generate images
based on human-written prompts and ensure the resulting images are uniformly
distributed across attributes of interest. Unfortunately, directly expressing
the desired attributes in the prompt often leads to sub-optimal results due to
linguistic ambiguity or model misrepresentation. Hence, this paper proposes a
drastically different approach that adheres to the maxim that "a picture is
worth a thousand words". We show that, for some attributes, images can
represent concepts more expressively than text. For instance, categories of
skin tones are typically hard to specify by text but can be easily represented
by example images. Building upon these insights, we propose a novel approach,
ITI-GEN, that leverages readily available reference images for Inclusive
Text-to-Image GENeration. The key idea is learning a set of prompt embeddings
to generate images that can effectively represent all desired attribute
categories. More importantly, ITI-GEN requires no model fine-tuning, making it
computationally efficient to augment existing text-to-image models. Extensive
experiments demonstrate that ITI-GEN largely improves over state-of-the-art
models to generate inclusive images from a prompt. Project page:
https://czhang0528.github.io/iti-gen.
</p>
</div>
</dd>
<dt><a name="item451">[451]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.05570" title="Abstract">arXiv:2309.05570</a> [<a href="/pdf/2309.05570" title="Download PDF">pdf</a>, <a href="/format/2309.05570" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Safety Barrier Certificates for Stochastic Control Systems with Wireless  Communication Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Akbarzadeh%2C+O">Omid Akbarzadeh</a>, 
<a href="/search/eess?searchtype=author&query=Soudjani%2C+S">Sadegh Soudjani</a>, 
<a href="/search/eess?searchtype=author&query=Lavaei%2C+A">Abolfazl Lavaei</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">This work is concerned with a formal approach for safety controller synthesis
of stochastic control systems with both process and measurement noises while
considering wireless communication networks between sensors, controllers, and
actuators. The proposed scheme is based on control barrier certificates (CBC),
which allows us to provide safety certifications for wirelessly-connected
stochastic control systems. Despite the available literature on designing
control barrier certificates, there has been unfortunately no consideration of
wireless communication networks to capture potential packet losses and
end-to-end delays, which is absolutely crucial in safety-critical real-world
applications. In our proposed setting, the key objective is to construct a
control barrier certificate together with a safety controller while providing a
lower bound on the satisfaction probability of the safety property over a
finite time horizon. We propose a systematic approach in the form of
sum-of-squares optimization and matrix inequalities for the synthesis of CBC
and its associated controller. We demonstrate the efficacy of our approach on a
permanent magnet synchronous motor. For the application of automotive electric
steering under a wireless communication network, we design a CBC together with
a safety controller to maintain the electrical current of the motor in a safe
set within a finite time horizon while providing a formal probabilistic
guarantee.
</p>
</div>
</dd>
<dt><a name="item452">[452]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.05573" title="Abstract">arXiv:2309.05573</a> [<a href="/pdf/2309.05573" title="Download PDF">pdf</a>, <a href="/format/2309.05573" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> UniSeg: A Unified Multi-Modal LiDAR Segmentation Network and the  OpenPCSeg Codebase
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Youquan Liu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+R">Runnan Chen</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xin Li</a>, 
<a href="/search/cs?searchtype=author&query=Kong%2C+L">Lingdong Kong</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yuchen Yang</a>, 
<a href="/search/cs?searchtype=author&query=Xia%2C+Z">Zhaoyang Xia</a>, 
<a href="/search/cs?searchtype=author&query=Bai%2C+Y">Yeqi Bai</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+X">Xinge Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+Y">Yuexin Ma</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yikang Li</a>, 
<a href="/search/cs?searchtype=author&query=Qiao%2C+Y">Yu Qiao</a>, 
<a href="/search/cs?searchtype=author&query=Hou%2C+Y">Yuenan Hou</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ICCV 2023; 21 pages; 9 figures; 18 tables; Code at <a href="https://github.com/PJLab-ADG/PCSeg">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Point-, voxel-, and range-views are three representative forms of point
clouds. All of them have accurate 3D measurements but lack color and texture
information. RGB images are a natural complement to these point cloud views and
fully utilizing the comprehensive information of them benefits more robust
perceptions. In this paper, we present a unified multi-modal LiDAR segmentation
network, termed UniSeg, which leverages the information of RGB images and three
views of the point cloud, and accomplishes semantic segmentation and panoptic
segmentation simultaneously. Specifically, we first design the Learnable
cross-Modal Association (LMA) module to automatically fuse voxel-view and
range-view features with image features, which fully utilize the rich semantic
information of images and are robust to calibration errors. Then, the enhanced
voxel-view and range-view features are transformed to the point space,where
three views of point cloud features are further fused adaptively by the
Learnable cross-View Association module (LVA). Notably, UniSeg achieves
promising results in three public benchmarks, i.e., SemanticKITTI, nuScenes,
and Waymo Open Dataset (WOD); it ranks 1st on two challenges of two benchmarks,
including the LiDAR semantic segmentation challenge of nuScenes and panoptic
segmentation challenges of SemanticKITTI. Besides, we construct the OpenPCSeg
codebase, which is the largest and most comprehensive outdoor LiDAR
segmentation codebase. It contains most of the popular outdoor LiDAR
segmentation algorithms and provides reproducible implementations. The
OpenPCSeg codebase will be made publicly available at
https://github.com/PJLab-ADG/PCSeg.
</p>
</div>
</dd>
<dt><a name="item453">[453]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.05575" title="Abstract">arXiv:2309.05575</a> [<a href="/pdf/2309.05575" title="Download PDF">pdf</a>, <a href="/format/2309.05575" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Anisotropic Diffusion Stencils: From Simple Derivations over Stability  Estimates to ResNet Implementations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Schrader%2C+K">Karl Schrader</a>, 
<a href="/search/math?searchtype=author&query=Weickert%2C+J">Joachim Weickert</a>, 
<a href="/search/math?searchtype=author&query=Krause%2C+M">Michael Krause</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Machine Learning (cs.LG); Image and Video Processing (eess.IV)

</div>
<p class="mathjax">Anisotropic diffusion processes with a diffusion tensor are important in
image analysis, physics, and engineering. However, their numerical
approximation has a strong impact on dissipative artefacts and deviations from
rotation invariance. In this work, we study a large family of finite difference
discretisations on a 3 x 3 stencil. We derive it by splitting 2-D anisotropic
diffusion into four 1-D diffusions. The resulting stencil class involves one
free parameter and covers a wide range of existing discretisations. It
comprises the full stencil family of Weickert et al. (2013) and shows that
their two parameters contain redundancy. Furthermore, we establish a bound on
the spectral norm of the matrix corresponding to the stencil. This gives time
step size limits that guarantee stability of an explicit scheme in the
Euclidean norm. Our directional splitting also allows a very natural
translation of the explicit scheme into ResNet blocks. Employing neural network
libraries enables simple and highly efficient parallel implementations on GPUs.
</p>
</div>
</dd>
<dt><a name="item454">[454]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.05582" title="Abstract">arXiv:2309.05582</a> [<a href="/pdf/2309.05582" title="Download PDF">pdf</a>, <a href="/format/2309.05582" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Mind the Uncertainty: Risk-Aware and Actively Exploring Model-Based  Reinforcement Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Vlastelica%2C+M">Marin Vlastelica</a>, 
<a href="/search/cs?searchtype=author&query=Blaes%2C+S">Sebastian Blaes</a>, 
<a href="/search/cs?searchtype=author&query=Pineri%2C+C">Cristina Pineri</a>, 
<a href="/search/cs?searchtype=author&query=Martius%2C+G">Georg Martius</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Robotics (cs.RO)

</div>
<p class="mathjax">We introduce a simple but effective method for managing risk in model-based
reinforcement learning with trajectory sampling that involves probabilistic
safety constraints and balancing of optimism in the face of epistemic
uncertainty and pessimism in the face of aleatoric uncertainty of an ensemble
of stochastic neural networks.Various experiments indicate that the separation
of uncertainties is essential to performing well with data-driven MPC
approaches in uncertain and safety-critical control environments.
</p>
</div>
</dd>
<dt><a name="item455">[455]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.05583" title="Abstract">arXiv:2309.05583</a> [<a href="/pdf/2309.05583" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Undergraduate Research of Decentralized Localization of Roombas Through  Usage of Wall-Finding Software
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Corvin%2C+M">Madeline Corvin</a>, 
<a href="/search/cs?searchtype=author&query=McDowell%2C+J">Johnathan McDowell</a>, 
<a href="/search/cs?searchtype=author&query=Anglea%2C+T">Timothy Anglea</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yongqiang Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">This paper introduces the research effort of an undergraduate research team
in realizing robot localization. More specifically, the undergraduate research
team developed and tested wall-following software that allowed a ground robot
Roombas to independently find their positions within a defined space. The
software also allows a robot to send its localized position to other Roombas,
so that each Roomba knows its relative location to realize robot cooperation.
</p>
</div>
</dd>
<dt><a name="item456">[456]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.05584" title="Abstract">arXiv:2309.05584</a> [<a href="/pdf/2309.05584" title="Download PDF">pdf</a>, <a href="/format/2309.05584" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Distributional Probabilistic Model Checking
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Elsayed-Aly%2C+I">Ingy Elsayed-Aly</a>, 
<a href="/search/cs?searchtype=author&query=Parker%2C+D">David Parker</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+L">Lu Feng</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 20 pages, 2 pages appendix, 5 figures. Submitted for review. For associated Github repository, see <a href="https://github.com/davexparker/prism/tree/ingy">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>

</div>
<p class="mathjax">Probabilistic model checking can provide formal guarantees on the behavior of
stochastic models relating to a wide range of quantitative properties, such as
runtime, energy consumption or cost. But decision making is typically with
respect to the expected value of these quantities, which can mask important
aspects of the full probability distribution such as the possibility of
high-risk, low-probability events or multimodalities. We propose a
distributional extension of probabilistic model checking, applicable to
discrete-time Markov chains (DTMCs) and Markov decision processes (MDPs). We
formulate distributional queries, which can reason about a variety of
distributional measures, such as variance, value-at-risk or conditional
value-at-risk, for the accumulation of reward until a co-safe linear temporal
logic formula is satisfied. For DTMCs, we propose a method to compute the full
distribution to an arbitrary level of precision, based on a graph analysis and
forward analysis of the model. For MDPs, we approximate the optimal policy with
respect to expected value or conditional value-at-risk using distributional
value iteration. We implement our techniques and investigate their performance
and scalability across a range of benchmark models. Experimental results
demonstrate that our techniques can be successfully applied to check various
distributional properties of large probabilistic models.
</p>
</div>
</dd>
<dt><a name="item457">[457]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.05585" title="Abstract">arXiv:2309.05585</a> [<a href="/pdf/2309.05585" title="Download PDF">pdf</a>, <a href="/format/2309.05585" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Local conservation laws of continuous Galerkin method for the  incompressible Navier--Stokes equations in EMAC form
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Olshanskii%2C+M+A">Maxim A. Olshanskii</a>, 
<a href="/search/math?searchtype=author&query=Rebholz%2C+L+G">Leo G. Rebholz</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">We consider {\it local} balances of momentum and angular momentum for the
incompressible Navier-Stokes equations. First, we formulate new weak forms of
the physical balances (conservation laws) of these quantities, and prove they
are equivalent to the usual conservation law formulations. We then show that
continuous Galerkin discretizations of the Navier-Stokes equations using the
EMAC form of the nonlinearity preserve discrete analogues of the weak form
conservation laws, both in the Eulerian formulation and the Lagrangian
formulation (which are not equivalent after discretizations). Numerical tests
illustrate the new theory.
</p>
</div>
</dd>
<dt><a name="item458">[458]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.05589" title="Abstract">arXiv:2309.05589</a> [<a href="/pdf/2309.05589" title="Download PDF">pdf</a>, <a href="/format/2309.05589" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Quantitative Analysis of Forecasting Models:In the Aspect of Online  Political Bias
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tripuraneni%2C+S+S">Srinath Sai Tripuraneni</a>, 
<a href="/search/cs?searchtype=author&query=Kamal%2C+S">Sadia Kamal</a>, 
<a href="/search/cs?searchtype=author&query=Bagavathi%2C+A">Arunkumar Bagavathi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This is a preprint version of a paper that is accepted to be presented as a poster at the ICMLA conference on December 15-17 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>; Computers and Society (cs.CY); Machine Learning (cs.LG)

</div>
<p class="mathjax">Understanding and mitigating political bias in online social media platforms
are crucial tasks to combat misinformation and echo chamber effects. However,
characterizing political bias temporally using computational methods presents
challenges due to the high frequency of noise in social media datasets. While
existing research has explored various approaches to political bias
characterization, the ability to forecast political bias and anticipate how
political conversations might evolve in the near future has not been
extensively studied. In this paper, we propose a heuristic approach to classify
social media posts into five distinct political leaning categories. Since there
is a lack of prior work on forecasting political bias, we conduct an in-depth
analysis of existing baseline models to identify which model best fits to
forecast political leaning time series. Our approach involves utilizing
existing time series forecasting models on two social media datasets with
different political ideologies, specifically Twitter and Gab. Through our
experiments and analyses, we seek to shed light on the challenges and
opportunities in forecasting political bias in social media platforms.
Ultimately, our work aims to pave the way for developing more effective
strategies to mitigate the negative impact of political bias in the digital
realm.
</p>
</div>
</dd>
<dt><a name="item459">[459]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.05590" title="Abstract">arXiv:2309.05590</a> [<a href="/pdf/2309.05590" title="Download PDF">pdf</a>, <a href="/format/2309.05590" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Temporal Action Localization with Enhanced Instant Discriminability
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shi%2C+D">Dingfeng Shi</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+Q">Qiong Cao</a>, 
<a href="/search/cs?searchtype=author&query=Zhong%2C+Y">Yujie Zhong</a>, 
<a href="/search/cs?searchtype=author&query=An%2C+S">Shan An</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+J">Jian Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+H">Haogang Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Tao%2C+D">Dacheng Tao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> An extended version of the CVPR paper <a href="/abs/2303.07347">arXiv:2303.07347</a>, submitted to IJCV
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Multimedia (cs.MM)

</div>
<p class="mathjax">Temporal action detection (TAD) aims to detect all action boundaries and
their corresponding categories in an untrimmed video. The unclear boundaries of
actions in videos often result in imprecise predictions of action boundaries by
existing methods. To resolve this issue, we propose a one-stage framework named
TriDet. First, we propose a Trident-head to model the action boundary via an
estimated relative probability distribution around the boundary. Then, we
analyze the rank-loss problem (i.e. instant discriminability deterioration) in
transformer-based methods and propose an efficient scalable-granularity
perception (SGP) layer to mitigate this issue. To further push the limit of
instant discriminability in the video backbone, we leverage the strong
representation capability of pretrained large models and investigate their
performance on TAD. Last, considering the adequate spatial-temporal context for
classification, we design a decoupled feature pyramid network with separate
feature pyramids to incorporate rich spatial context from the large model for
localization. Experimental results demonstrate the robustness of TriDet and its
state-of-the-art performance on multiple TAD datasets, including hierarchical
(multilabel) TAD datasets.
</p>
</div>
</dd>
<dt><a name="item460">[460]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.05595" title="Abstract">arXiv:2309.05595</a> [<a href="/pdf/2309.05595" title="Download PDF">pdf</a>, <a href="/ps/2309.05595" title="Download PostScript">ps</a>, <a href="/format/2309.05595" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Undecidability Results and Their Relevance in Modern Music Making
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Young%2C+H">Halley Young</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">This paper delves into the intersection of computational theory and music,
examining the concept of undecidability and its significant, yet overlooked,
implications within the realm of modern music composition and production. It
posits that undecidability, a principle traditionally associated with
theoretical computer science, extends its relevance to the music industry. The
study adopts a multidimensional approach, focusing on five key areas: (1) the
Turing completeness of Ableton, a widely used digital audio workstation, (2)
the undecidability of satisfiability in sound creation utilizing an array of
effects, (3) the undecidability of constraints on polymeters in musical
compositions, (4) the undecidability of satisfiability in just intonation
harmony constraints, and (5) the undecidability of "new ordering systems". In
addition to providing theoretical proof for these assertions, the paper
elucidates the practical relevance of these concepts for practitioners outside
the field of theoretical computer science. The ultimate aim is to foster a new
understanding of undecidability in music, highlighting its broader
applicability and potential to influence contemporary computer-assisted (and
traditional) music making.
</p>
</div>
</dd>
<dt><a name="item461">[461]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.05598" title="Abstract">arXiv:2309.05598</a> [<a href="/pdf/2309.05598" title="Download PDF">pdf</a>, <a href="/format/2309.05598" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Solving Partial Differential Equations with Monte Carlo / Random Walk on  an Analog-Digital Hybrid Computer
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Killat%2C+D">Dirk Killat</a>, 
<a href="/search/cs?searchtype=author&query=K%C3%B6ppel%2C+S">Sven K&#xf6;ppel</a>, 
<a href="/search/cs?searchtype=author&query=Ulmann%2C+B">Bernd Ulmann</a>, 
<a href="/search/cs?searchtype=author&query=Wetzel%2C+L">Lucas Wetzel</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages, 7 figures. Proceeding for the MikroSystemTechnik Kongress 2023 (VDE Verlag MST Kongress 2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Emerging Technologies (cs.ET)</span>

</div>
<p class="mathjax">Current digital computers are about to hit basic physical boundaries with
respect to integration density, clock frequencies, and particularly energy
consumption. This requires the application of new computing paradigms, such as
quantum and analog computing in the near future. Although neither quantum nor
analog computer are general purpose computers they will play an important role
as co-processors to offload certain classes of compute intensive tasks from
classic digital computers, thereby not only reducing run time but also and
foremost power consumption.
<br />In this work, we describe a random walk approach to the solution of certain
types of partial differential equations which is well suited for combinations
of digital and analog computers (hybrid computers). The experiments were
performed on an Analog Paradigm Model-1 analog computer attached to a digital
computer by means of a hybrid interface. At the end we give some estimates of
speedups and power consumption obtainable by using future analog computers on
chip.
</p>
</div>
</dd>
<dt><a name="item462">[462]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.05605" title="Abstract">arXiv:2309.05605</a> [<a href="/pdf/2309.05605" title="Download PDF">pdf</a>, <a href="/format/2309.05605" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Memory Injections: Correcting Multi-Hop Reasoning Failures during  Inference in Transformer-Based Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sakarvadia%2C+M">Mansi Sakarvadia</a>, 
<a href="/search/cs?searchtype=author&query=Ajith%2C+A">Aswathy Ajith</a>, 
<a href="/search/cs?searchtype=author&query=Khan%2C+A">Arham Khan</a>, 
<a href="/search/cs?searchtype=author&query=Grzenda%2C+D">Daniel Grzenda</a>, 
<a href="/search/cs?searchtype=author&query=Hudson%2C+N">Nathaniel Hudson</a>, 
<a href="/search/cs?searchtype=author&query=Bauer%2C+A">Andr&#xe9; Bauer</a>, 
<a href="/search/cs?searchtype=author&query=Chard%2C+K">Kyle Chard</a>, 
<a href="/search/cs?searchtype=author&query=Foster%2C+I">Ian Foster</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Answering multi-hop reasoning questions requires retrieving and synthesizing
information from diverse sources. Large Language Models (LLMs) struggle to
perform such reasoning consistently. Here we propose an approach to pinpoint
and rectify multi-hop reasoning failures through targeted memory injections on
LLM attention heads. First, we analyze the per-layer activations of GPT-2
models in response to single and multi-hop prompts. We then propose a mechanism
that allows users to inject pertinent prompt-specific information, which we
refer to as "memories," at critical LLM locations during inference. By thus
enabling the LLM to incorporate additional relevant information during
inference, we enhance the quality of multi-hop prompt completions. We show
empirically that a simple, efficient, and targeted memory injection into a key
attention layer can often increase the probability of the desired next token in
multi-hop tasks, by up to 424%.
</p>
</div>
</dd>
<dt><a name="item463">[463]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.05607" title="Abstract">arXiv:2309.05607</a> [<a href="/pdf/2309.05607" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Creating a Systematic ESG (Environmental Social Governance) Scoring  System Using Social Network Analysis and Machine Learning for More  Sustainable Company Practices
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Patel%2C+A">Aarav Patel</a>, 
<a href="/search/cs?searchtype=author&query=Gloor%2C+P">Peter Gloor</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Presented at the 10th International COINs Conference. Pending publication in the Edward Elgar Handbook for Social Computing
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Environmental Social Governance (ESG) is a widely used metric that measures
the sustainability of a company practices. Currently, ESG is determined using
self-reported corporate filings, which allows companies to portray themselves
in an artificially positive light. As a result, ESG evaluation is subjective
and inconsistent across raters, giving executives mixed signals on what to
improve. This project aims to create a data-driven ESG evaluation system that
can provide better guidance and more systemized scores by incorporating social
sentiment. Social sentiment allows for more balanced perspectives which
directly highlight public opinion, helping companies create more focused and
impactful initiatives. To build this, Python web scrapers were developed to
collect data from Wikipedia, Twitter, LinkedIn, and Google News for the S&amp;P 500
companies. Data was then cleaned and passed through NLP algorithms to obtain
sentiment scores for ESG subcategories. Using these features, machine-learning
algorithms were trained and calibrated to S&amp;P Global ESG Ratings to test their
predictive capabilities. The Random-Forest model was the strongest model with a
mean absolute error of 13.4% and a correlation of 26.1% (p-value 0.0372),
showing encouraging results. Overall, measuring ESG social sentiment across
sub-categories can help executives focus efforts on areas people care about
most. Furthermore, this data-driven methodology can provide ratings for
companies without coverage, allowing more socially responsible firms to thrive.
</p>
</div>
</dd>
<dt><a name="item464">[464]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.05608" title="Abstract">arXiv:2309.05608</a> [<a href="/pdf/2309.05608" title="Download PDF">pdf</a>, <a href="/format/2309.05608" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Incorporating Pre-trained Model Prompting in Multimodal Stock Volume  Movement Prediction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+R">Ruibo Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zhiyuan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yi Liu</a>, 
<a href="/search/cs?searchtype=author&query=Bao%2C+R">Ruihan Bao</a>, 
<a href="/search/cs?searchtype=author&query=Harimoto%2C+K">Keiko Harimoto</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+X">Xu Sun</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages, 3 figures, 7 tables. Accepted by 2023 KDD Workshop on Machine Learning in Finance
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Computational Engineering, Finance, and Science (cs.CE)

</div>
<p class="mathjax">Multimodal stock trading volume movement prediction with stock-related news
is one of the fundamental problems in the financial area. Existing multimodal
works that train models from scratch face the problem of lacking universal
knowledge when modeling financial news. In addition, the models ability may be
limited by the lack of domain-related knowledge due to insufficient data in the
datasets. To handle this issue, we propose the Prompt-based MUltimodal Stock
volumE prediction model (ProMUSE) to process text and time series modalities.
We use pre-trained language models for better comprehension of financial news
and adopt prompt learning methods to leverage their capability in universal
knowledge to model textual information. Besides, simply fusing two modalities
can cause harm to the unimodal representations. Thus, we propose a novel
cross-modality contrastive alignment while reserving the unimodal heads beside
the fusion head to mitigate this problem. Extensive experiments demonstrate
that our proposed ProMUSE outperforms existing baselines. Comprehensive
analyses further validate the effectiveness of our architecture compared to
potential variants and learning mechanisms.
</p>
</div>
</dd>
<dt><a name="item465">[465]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.05610" title="Abstract">arXiv:2309.05610</a> [<a href="/pdf/2309.05610" title="Download PDF">pdf</a>, <a href="/format/2309.05610" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Privacy Side Channels in Machine Learning Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Debenedetti%2C+E">Edoardo Debenedetti</a>, 
<a href="/search/cs?searchtype=author&query=Severi%2C+G">Giorgio Severi</a>, 
<a href="/search/cs?searchtype=author&query=Carlini%2C+N">Nicholas Carlini</a>, 
<a href="/search/cs?searchtype=author&query=Choquette-Choo%2C+C+A">Christopher A. Choquette-Choo</a>, 
<a href="/search/cs?searchtype=author&query=Jagielski%2C+M">Matthew Jagielski</a>, 
<a href="/search/cs?searchtype=author&query=Nasr%2C+M">Milad Nasr</a>, 
<a href="/search/cs?searchtype=author&query=Wallace%2C+E">Eric Wallace</a>, 
<a href="/search/cs?searchtype=author&query=Tram%C3%A8r%2C+F">Florian Tram&#xe8;r</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Most current approaches for protecting privacy in machine learning (ML)
assume that models exist in a vacuum, when in reality, ML models are part of
larger systems that include components for training data filtering, output
monitoring, and more. In this work, we introduce privacy side channels: attacks
that exploit these system-level components to extract private information at
far higher rates than is otherwise possible for standalone models. We propose
four categories of side channels that span the entire ML lifecycle (training
data filtering, input preprocessing, output post-processing, and query
filtering) and allow for either enhanced membership inference attacks or even
novel threats such as extracting users' test queries. For example, we show that
deduplicating training data before applying differentially-private training
creates a side-channel that completely invalidates any provable privacy
guarantees. Moreover, we show that systems which block language models from
regenerating training data can be exploited to allow exact reconstruction of
private keys contained in the training set -- even if the model did not
memorize these keys. Taken together, our results demonstrate the need for a
holistic, end-to-end privacy analysis of machine learning.
</p>
</div>
</dd>
<dt><a name="item466">[466]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.05613" title="Abstract">arXiv:2309.05613</a> [<a href="/pdf/2309.05613" title="Download PDF">pdf</a>, <a href="/format/2309.05613" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning the Geodesic Embedding with Graph Neural Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pang%2C+B">Bo Pang</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+Z">Zhongtian Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+G">Guoping Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+P">Peng-Shuai Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> SIGGRAPH Asia 2023, Journal Track
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Graphics (cs.GR)

</div>
<p class="mathjax">We present GeGnn, a learning-based method for computing the approximate
geodesic distance between two arbitrary points on discrete polyhedra surfaces
with constant time complexity after fast precomputation. Previous relevant
methods either focus on computing the geodesic distance between a single source
and all destinations, which has linear complexity at least or require a long
precomputation time. Our key idea is to train a graph neural network to embed
an input mesh into a high-dimensional embedding space and compute the geodesic
distance between a pair of points using the corresponding embedding vectors and
a lightweight decoding function. To facilitate the learning of the embedding,
we propose novel graph convolution and graph pooling modules that incorporate
local geodesic information and are verified to be much more effective than
previous designs. After training, our method requires only one forward pass of
the network per mesh as precomputation. Then, we can compute the geodesic
distance between a pair of points using our decoding function, which requires
only several matrix multiplications and can be massively parallelized on GPUs.
We verify the efficiency and effectiveness of our method on ShapeNet and
demonstrate that our method is faster than existing methods by orders of
magnitude while achieving comparable or better accuracy. Additionally, our
method exhibits robustness on noisy and incomplete meshes and strong
generalization ability on out-of-distribution meshes. The code and pretrained
model can be found on https://github.com/IntelligentGeometry/GeGnn.
</p>
</div>
</dd>
<dt><a name="item467">[467]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.05619" title="Abstract">arXiv:2309.05619</a> [<a href="/pdf/2309.05619" title="Download PDF">pdf</a>, <a href="/format/2309.05619" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Effective Proxy for Human Labeling: Ensemble Disagreement Scores in  Large Language Models for Industrial NLP
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Du%2C+W">Wei Du</a>, 
<a href="/search/cs?searchtype=author&query=Advani%2C+L">Laksh Advani</a>, 
<a href="/search/cs?searchtype=author&query=Gambhir%2C+Y">Yashmeet Gambhir</a>, 
<a href="/search/cs?searchtype=author&query=Perry%2C+D+J">Daniel J Perry</a>, 
<a href="/search/cs?searchtype=author&query=Shiralkar%2C+P">Prashant Shiralkar</a>, 
<a href="/search/cs?searchtype=author&query=Xing%2C+Z">Zhengzheng Xing</a>, 
<a href="/search/cs?searchtype=author&query=Colak%2C+A">Aaron Colak</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Large language models (LLMs) have demonstrated significant capability to
generalize across a large number of NLP tasks. For industry applications, it is
imperative to assess the performance of the LLM on unlabeled production data
from time to time to validate for a real-world setting. Human labeling to
assess model error requires considerable expense and time delay. Here we
demonstrate that ensemble disagreement scores work well as a proxy for human
labeling for language models in zero-shot, few-shot, and fine-tuned settings,
per our evaluation on keyphrase extraction (KPE) task. We measure fidelity of
the results by comparing to true error measured from human labeled ground
truth. We contrast with the alternative of using another LLM as a source of
machine labels, or silver labels. Results across various languages and domains
show disagreement scores provide a better estimation of model performance with
mean average error (MAE) as low as 0.4% and on average 13.8% better than using
silver labels.
</p>
</div>
</dd>
<dt><a name="item468">[468]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.05621" title="Abstract">arXiv:2309.05621</a> [<a href="/pdf/2309.05621" title="Download PDF">pdf</a>, <a href="/format/2309.05621" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Comparative Analysis of Deep Reinforcement Learning-based xApps in  O-RAN
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tsampazi%2C+M">Maria Tsampazi</a>, 
<a href="/search/cs?searchtype=author&query=D%27Oro%2C+S">Salvatore D&#x27;Oro</a>, 
<a href="/search/cs?searchtype=author&query=Polese%2C+M">Michele Polese</a>, 
<a href="/search/cs?searchtype=author&query=Bonati%2C+L">Leonardo Bonati</a>, 
<a href="/search/cs?searchtype=author&query=Poitau%2C+G">Gwenael Poitau</a>, 
<a href="/search/cs?searchtype=author&query=Healy%2C+M">Michael Healy</a>, 
<a href="/search/cs?searchtype=author&query=Melodia%2C+T">Tommaso Melodia</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages, 16 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">The highly heterogeneous ecosystem of Next Generation (NextG) wireless
communication systems calls for novel networking paradigms where
functionalities and operations can be dynamically and optimally reconfigured in
real time to adapt to changing traffic conditions and satisfy stringent and
diverse Quality of Service (QoS) demands. Open Radio Access Network (RAN)
technologies, and specifically those being standardized by the O-RAN Alliance,
make it possible to integrate network intelligence into the once monolithic RAN
via intelligent applications, namely, xApps and rApps. These applications
enable flexible control of the network resources and functionalities, network
management, and orchestration through data-driven control loops. Despite recent
work demonstrating the effectiveness of Deep Reinforcement Learning (DRL) in
controlling O-RAN systems, how to design these solutions in a way that does not
create conflicts and unfair resource allocation policies is still an open
challenge. In this paper, we perform a comparative analysis where we dissect
the impact of different DRL-based xApp designs on network performance.
Specifically, we benchmark 12 different xApps that embed DRL agents trained
using different reward functions, with different action spaces and with the
ability to hierarchically control different network parameters. We prototype
and evaluate these xApps on Colosseum, the world's largest O-RAN-compliant
wireless network emulator with hardware-in-the-loop. We share the lessons
learned and discuss our experimental results, which demonstrate how certain
design choices deliver the highest performance while others might result in a
competitive behavior between different classes of traffic with similar
objectives.
</p>
</div>
</dd>
<dt><a name="item469">[469]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.05622" title="Abstract">arXiv:2309.05622</a> [<a href="/pdf/2309.05622" title="Download PDF">pdf</a>, <a href="/format/2309.05622" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Task-Oriented Cross-System Design for Timely and Accurate Modeling in  the Metaverse
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Meng%2C+Z">Zhen Meng</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+K">Kan Chen</a>, 
<a href="/search/cs?searchtype=author&query=Diao%2C+Y">Yufeng Diao</a>, 
<a href="/search/cs?searchtype=author&query=She%2C+C">Changyang She</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+G">Guodong Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Imran%2C+M+A">Muhammad Ali Imran</a>, 
<a href="/search/cs?searchtype=author&query=Vucetic%2C+B">Branka Vucetic</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This paper is accepted by IEEE Journal on Selected Areas in Communications, JSAC-SI-HCM 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Systems and Control (eess.SY)

</div>
<p class="mathjax">In this paper, we establish a task-oriented cross-system design framework to
minimize the required packet rate for timely and accurate modeling of a
real-world robotic arm in the Metaverse, where sensing, communication,
prediction, control, and rendering are considered. To optimize a scheduling
policy and prediction horizons, we design a Constraint Proximal Policy
Optimization(C-PPO) algorithm by integrating domain knowledge from relevant
systems into the advanced reinforcement learning algorithm, Proximal Policy
Optimization(PPO). Specifically, the Jacobian matrix for analyzing the motion
of the robotic arm is included in the state of the C-PPO algorithm, and the
Conditional Value-at-Risk(CVaR) of the state-value function characterizing the
long-term modeling error is adopted in the constraint. Besides, the policy is
represented by a two-branch neural network determining the scheduling policy
and the prediction horizons, respectively. To evaluate our algorithm, we build
a prototype including a real-world robotic arm and its digital model in the
Metaverse. The experimental results indicate that domain knowledge helps to
reduce the convergence time and the required packet rate by up to 50%, and the
cross-system design framework outperforms a baseline framework in terms of the
required packet rate and the tail distribution of the modeling error.
</p>
</div>
</dd>
<dt><a name="item470">[470]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.05632" title="Abstract">arXiv:2309.05632</a> [<a href="/pdf/2309.05632" title="Download PDF">pdf</a>, <a href="/format/2309.05632" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MAPS$^2$: Multi-Robot Anytime Motion Planning under Signal Temporal  Logic Specifications
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sewlia%2C+M">Mayank Sewlia</a>, 
<a href="/search/cs?searchtype=author&query=Verginis%2C+C+K">Christos K. Verginis</a>, 
<a href="/search/cs?searchtype=author&query=Dimarogonas%2C+D+V">Dimos V. Dimarogonas</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">This article presents MAPS$^2$ : a distributed algorithm that allows
multi-robot systems to deliver coupled tasks expressed as Signal Temporal Logic
(STL) constraints. Classical control theoretical tools addressing STL
constraints either adopt a limited fragment of the STL formula or require
approximations of min/max operators, whereas works maximising robustness
through optimisation-based methods often suffer from local minima, relaxing any
completeness arguments due to the NP-hard nature of the problem. Endowed with
probabilistic guarantees, MAPS$^2$ provides an anytime algorithm that
iteratively improves the robots' trajectories. The algorithm selectively
imposes spatial constraints by taking advantage of the temporal properties of
the STL. The algorithm is distributed, in the sense that each robot calculates
its trajectory by communicating only with its immediate neighbours as defined
via a communication graph. We illustrate the efficiency of MAPS$^2$ by
conducting extensive simulation and experimental studies, verifying the
generation of STL satisfying trajectories.
</p>
</div>
</dd>
<dt><a name="item471">[471]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.05633" title="Abstract">arXiv:2309.05633</a> [<a href="/pdf/2309.05633" title="Download PDF">pdf</a>, <a href="/format/2309.05633" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Low-Complexity Vector Source Coding for Discrete Long Sequences with  Unknown Distributions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Woldemariam%2C+L">Leah Woldemariam</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+H">Hang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Scaglione%2C+A">Anna Scaglione</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>

</div>
<p class="mathjax">In this paper, we propose a source coding scheme that represents data from
unknown distributions through frequency and support information. Existing
encoding schemes often compress data by sacrificing computational efficiency or
by assuming the data follows a known distribution. We take advantage of the
structure that arises within the spatial representation and utilize it to
encode run-lengths within this representation using Golomb coding. Through
theoretical analysis, we show that our scheme yields an overall bit rate that
nears entropy without a computationally complex encoding algorithm and verify
these results through numerical experiments.
</p>
</div>
</dd>
<dt><a name="item472">[472]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.05634" title="Abstract">arXiv:2309.05634</a> [<a href="/pdf/2309.05634" title="Download PDF">pdf</a>, <a href="/format/2309.05634" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Kernel Interpolation of Incident Sound Field in Region Including  Scattering Objects
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Koyama%2C+S">Shoichi Koyama</a>, 
<a href="/search/cs?searchtype=author&query=Nakada%2C+M">Masaki Nakada</a>, 
<a href="/search/cs?searchtype=author&query=Ribeiro%2C+J+G+C">Juliano G. C. Ribeiro</a>, 
<a href="/search/cs?searchtype=author&query=Saruwatari%2C+H">Hiroshi Saruwatari</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to IEEE Workshop on Applications of Signal Processing to Audio and Acoustics (WASPAA) 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">A method for estimating the incident sound field inside a region containing
scattering objects is proposed. The sound field estimation method has various
applications, such as spatial audio capturing and spatial active noise control;
however, most existing methods do not take into account the presence of
scatterers within the target estimation region. Although several techniques
exist that employ knowledge or measurements of the properties of the scattering
objects, it is usually difficult to obtain them precisely in advance, and their
properties may change during the estimation process. Our proposed method is
based on the kernel ridge regression of the incident field, with a separation
from the scattering field represented by a spherical wave function expansion,
thus eliminating the need for prior modeling or measurements of the scatterers.
Moreover, we introduce a weighting matrix to induce smoothness of the
scattering field in the angular direction, which alleviates the effect of the
truncation order of the expansion coefficients on the estimation accuracy.
Experimental results indicate that the proposed method achieves a higher level
of estimation accuracy than the kernel ridge regression without separation.
</p>
</div>
</dd>
<dt><a name="item473">[473]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.05637" title="Abstract">arXiv:2309.05637</a> [<a href="/pdf/2309.05637" title="Download PDF">pdf</a>, <a href="/ps/2309.05637" title="Download PostScript">ps</a>, <a href="/format/2309.05637" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Latte: Lightweight Aliasing Tracking for Java
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zimmerman%2C+C">Conrad Zimmerman</a>, 
<a href="/search/cs?searchtype=author&query=Gamboa%2C+C">Catarina Gamboa</a>, 
<a href="/search/cs?searchtype=author&query=Fonseca%2C+A">Alcides Fonseca</a>, 
<a href="/search/cs?searchtype=author&query=Aldrich%2C+J">Jonathan Aldrich</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Programming Languages (cs.PL)</span>; Software Engineering (cs.SE)

</div>
<p class="mathjax">Many existing systems track aliasing and uniqueness, each with their own
trade-off between expressiveness and developer effort. We propose Latte, a new
approach that aims to minimize both the amount of annotations and the
complexity of invariants necessary for reasoning about aliasing in an
object-oriented language with mutation. Our approach only requires annotations
for parameters and fields, while annotations for local variables are inferred.
Furthermore, it relaxes uniqueness to allow aliasing among local variables, as
long as this aliasing can be precisely determined. This enables support for
destructive reads without changes to the language or its run-time semantics.
Despite this simplicity, we show how this design can still be used for tracking
uniqueness and aliasing in a local sequential setting, with practical
applications, such as modeling a stack.
</p>
</div>
</dd>
<dt><a name="item474">[474]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.05638" title="Abstract">arXiv:2309.05638</a> [<a href="/pdf/2309.05638" title="Download PDF">pdf</a>, <a href="/format/2309.05638" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Combinative Cumulative Knowledge Processes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Brandenberger%2C+A">Anna Brandenberger</a>, 
<a href="/search/cs?searchtype=author&query=Marcussen%2C+C">Cassandra Marcussen</a>, 
<a href="/search/cs?searchtype=author&query=Mossel%2C+E">Elchanan Mossel</a>, 
<a href="/search/cs?searchtype=author&query=Sudan%2C+M">Madhu Sudan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 28 pages, 8 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Data Structures and Algorithms (cs.DS); Social and Information Networks (cs.SI); Probability (math.PR)

</div>
<p class="mathjax">We analyze Cumulative Knowledge Processes, introduced by Ben-Eliezer,
Mikulincer, Mossel, and Sudan (ITCS 2023), in the setting of "directed acyclic
graphs", i.e., when new units of knowledge may be derived by combining multiple
previous units of knowledge. The main considerations in this model are the role
of errors (when new units may be erroneous) and local checking (where a few
antecedent units of knowledge are checked when a new unit of knowledge is
discovered). The aforementioned work defined this model but only analyzed an
idealized and simplified "tree-like" setting, i.e., a setting where new units
of knowledge only depended directly on one previously generated unit of
knowledge.
<br />The main goal of our work is to understand when the general process is safe,
i.e., when the effect of errors remains under control. We provide some
necessary and some sufficient conditions for safety. As in the earlier work, we
demonstrate that the frequency of checking as well as the depth of the checks
play a crucial role in determining safety. A key new parameter in the current
work is the $\textit{combination factor}$ which is the distribution of the
number of units $M$ of old knowledge that a new unit of knowledge depends on.
Our results indicate that a large combination factor can compensate for a small
depth of checking. The dependency of the safety on the combination factor is
far from trivial. Indeed some of our main results are stated in terms of
$\mathbb{E}\{1/M\}$ while others depend on $\mathbb{E}\{M\}$.
</p>
</div>
</dd>
<dt><a name="item475">[475]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.05642" title="Abstract">arXiv:2309.05642</a> [<a href="/pdf/2309.05642" title="Download PDF">pdf</a>, <a href="/format/2309.05642" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the Potential and Limitations of Proxy Voting: Delegation with  Incomplete Votes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Amanatidis%2C+G">Georgios Amanatidis</a>, 
<a href="/search/cs?searchtype=author&query=Filos-Ratsikas%2C+A">Aris Filos-Ratsikas</a>, 
<a href="/search/cs?searchtype=author&query=Lazos%2C+P">Philip Lazos</a>, 
<a href="/search/cs?searchtype=author&query=Markakis%2C+E">Evangelos Markakis</a>, 
<a href="/search/cs?searchtype=author&query=Papasotiropoulos%2C+G">Georgios Papasotiropoulos</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>

</div>
<p class="mathjax">We study elections where voters are faced with the challenge of expressing
preferences over an extreme number of issues under consideration. This is
largely motivated by emerging blockchain governance systems, which include
voters with different weights and a massive number of community generated
proposals. In such scenarios, it is natural to expect that voters will have
incomplete preferences, as they may only be able to evaluate or be confident
about a very small proportion of the alternatives. As a result, the election
outcome may be significantly affected, leading to suboptimal decisions. Our
central inquiry revolves around whether delegation of ballots to proxies
possessing greater expertise or a more comprehensive understanding of the
voters' preferences can lead to outcomes with higher legitimacy and enhanced
voters' satisfaction in elections where voters submit incomplete preferences.
To explore its aspects, we introduce the following model: potential proxies
advertise their ballots over multiple issues, and each voter either delegates
to a seemingly attractive proxy or casts a ballot directly. We identify
necessary and sufficient conditions that could lead to a socially better
outcome by leveraging the participation of proxies. We accompany our
theoretical findings with experiments on instances derived from real datasets.
Overall, our results enhance the understanding of the power of delegation
towards improving election outcomes.
</p>
</div>
</dd>
<dt><a name="item476">[476]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.05645" title="Abstract">arXiv:2309.05645</a> [<a href="/pdf/2309.05645" title="Download PDF">pdf</a>, <a href="/format/2309.05645" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CitDet: A Benchmark Dataset for Citrus Fruit Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=James%2C+J+A">Jordan A. James</a>, 
<a href="/search/cs?searchtype=author&query=Manching%2C+H+K">Heather K. Manching</a>, 
<a href="/search/cs?searchtype=author&query=Mattia%2C+M+R">Matthew R. Mattia</a>, 
<a href="/search/cs?searchtype=author&query=Bowman%2C+K+D">Kim D. Bowman</a>, 
<a href="/search/cs?searchtype=author&query=Hulse-Kemp%2C+A+M">Amanda M. Hulse-Kemp</a>, 
<a href="/search/cs?searchtype=author&query=Beksi%2C+W+J">William J. Beksi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to IEEE Robotics and Automation Letters (RA-L)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Robotics (cs.RO)

</div>
<p class="mathjax">In this letter, we present a new dataset to advance the state of the art in
detecting citrus fruit and accurately estimate yield on trees affected by the
Huanglongbing (HLB) disease in orchard environments via imaging. Despite the
fact that significant progress has been made in solving the fruit detection
problem, the lack of publicly available datasets has complicated direct
comparison of results. For instance, citrus detection has long been of interest
in the agricultural research community, yet there is an absence of work,
particularly involving public datasets of citrus affected by HLB. To address
this issue, we enhance state-of-the-art object detection methods for use in
typical orchard settings. Concretely, we provide high-resolution images of
citrus trees located in an area known to be highly affected by HLB, along with
high-quality bounding box annotations of citrus fruit. Fruit on both the trees
and the ground are labeled to allow for identification of fruit location, which
contributes to advancements in yield estimation and potential measure of HLB
impact via fruit drop. The dataset consists of over 32,000 bounding box
annotations for fruit instances contained in 579 high-resolution images. In
summary, our contributions are the following: (i) we introduce a novel dataset
along with baseline performance benchmarks on multiple contemporary object
detection algorithms, (ii) we show the ability to accurately capture fruit
location on tree or on ground, and finally (ii) we present a correlation of our
results with yield estimations.
</p>
</div>
</dd>
<dt><a name="item477">[477]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.05646" title="Abstract">arXiv:2309.05646</a> [<a href="/pdf/2309.05646" title="Download PDF">pdf</a>, <a href="/format/2309.05646" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Novel Supervised Deep Learning Solution to Detect Distributed Denial  of Service (DDoS) attacks on Edge Systems using Convolutional Neural Networks  (CNN)
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ramanathan%2C+V">Vedanth Ramanathan</a>, 
<a href="/search/cs?searchtype=author&query=Mahadevan%2C+K">Krish Mahadevan</a>, 
<a href="/search/cs?searchtype=author&query=Dua%2C+S">Sejal Dua</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Machine Learning (cs.LG); Networking and Internet Architecture (cs.NI)

</div>
<p class="mathjax">Cybersecurity attacks are becoming increasingly sophisticated and pose a
growing threat to individuals, and private and public sectors. Distributed
Denial of Service attacks are one of the most harmful of these threats in
today's internet, disrupting the availability of essential services. This
project presents a novel deep learning-based approach for detecting DDoS
attacks in network traffic using the industry-recognized DDoS evaluation
dataset from the University of New Brunswick, which contains packet captures
from real-time DDoS attacks, creating a broader and more applicable model for
the real world. The algorithm employed in this study exploits the properties of
Convolutional Neural Networks (CNN) and common deep learning algorithms to
build a novel mitigation technique that classifies benign and malicious
traffic. The proposed model preprocesses the data by extracting packet flows
and normalizing them to a fixed length which is fed into a custom architecture
containing layers regulating node dropout, normalization, and a sigmoid
activation function to out a binary classification. This allows for the model
to process the flows effectively and look for the nodes that contribute to DDoS
attacks while dropping the "noise" or the distractors. The results of this
study demonstrate the effectiveness of the proposed algorithm in detecting DDOS
attacks, achieving an accuracy of .9883 on 2000 unseen flows in network
traffic, while being scalable for any network environment.
</p>
</div>
</dd>
<dt><a name="item478">[478]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.05649" title="Abstract">arXiv:2309.05649</a> [<a href="/pdf/2309.05649" title="Download PDF">pdf</a>, <a href="/ps/2309.05649" title="Download PostScript">ps</a>, <a href="/format/2309.05649" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Data efficiency, dimensionality reduction, and the generalized symmetric  information bottleneck
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Martini%2C+K+M">K. Michael Martini</a>, 
<a href="/search/cs?searchtype=author&query=Nemenman%2C+I">Ilya Nemenman</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Statistical Mechanics (cond-mat.stat-mech); Data Analysis, Statistics and Probability (physics.data-an)

</div>
<p class="mathjax">The Symmetric Information Bottleneck (SIB), an extension of the more familiar
Information Bottleneck, is a dimensionality reduction technique that
simultaneously compresses two random variables to preserve information between
their compressed versions. We introduce the Generalized Symmetric Information
Bottleneck (GSIB), which explores different functional forms of the cost of
such simultaneous reduction. We then explore the dataset size requirements of
such simultaneous compression. We do this by deriving bounds and
root-mean-squared estimates of statistical fluctuations of the involved loss
functions. We show that, in typical situations, the simultaneous GSIB
compression requires qualitatively less data to achieve the same errors
compared to compressing variables one at a time. We suggest that this is an
example of a more general principle that simultaneous compression is more data
efficient than independent compression of each of the input variables.
</p>
</div>
</dd>
<dt><a name="item479">[479]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.05652" title="Abstract">arXiv:2309.05652</a> [<a href="/pdf/2309.05652" title="Download PDF">pdf</a>, <a href="/format/2309.05652" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An Effective Two-stage Training Paradigm Detector for Small Dataset
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zheng Wang</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+D">Dong Xie</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Hanzhi Wang</a>, 
<a href="/search/cs?searchtype=author&query=Tian%2C+J">Jiang Tian</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 4 pages, 2 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Learning from the limited amount of labeled data to the pre-train model has
always been viewed as a challenging task. In this report, an effective and
robust solution, the two-stage training paradigm YOLOv8 detector (TP-YOLOv8),
is designed for the object detection track in VIPriors Challenge 2023. First,
the backbone of YOLOv8 is pre-trained as the encoder using the masked image
modeling technique. Then the detector is fine-tuned with elaborate
augmentations. During the test stage, test-time augmentation (TTA) is used to
enhance each model, and weighted box fusion (WBF) is implemented to further
boost the performance. With the well-designed structure, our approach has
achieved 30.4% average precision from 0.50 to 0.95 on the DelftBikes test set,
ranking 4th on the leaderboard.
</p>
</div>
</dd>
<dt><a name="item480">[480]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.05653" title="Abstract">arXiv:2309.05653</a> [<a href="/pdf/2309.05653" title="Download PDF">pdf</a>, <a href="/format/2309.05653" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MAmmoTH: Building Math Generalist Models through Hybrid Instruction  Tuning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yue%2C+X">Xiang Yue</a>, 
<a href="/search/cs?searchtype=author&query=Qu%2C+X">Xingwei Qu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+G">Ge Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Fu%2C+Y">Yao Fu</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+W">Wenhao Huang</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+H">Huan Sun</a>, 
<a href="/search/cs?searchtype=author&query=Su%2C+Y">Yu Su</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+W">Wenhu Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Work in progress; Xiang Yue and Wenhu Chen contributed equally to this paper
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">We introduce MAmmoTH, a series of open-source large language models (LLMs)
specifically tailored for general math problem-solving. The MAmmoTH models are
trained on MathInstruct, our meticulously curated instruction tuning dataset.
MathInstruct is compiled from 13 math datasets with intermediate rationales,
six of which have rationales newly curated by us. It presents a unique hybrid
of chain-of-thought (CoT) and program-of-thought (PoT) rationales, and also
ensures extensive coverage of diverse fields in math. The hybrid of CoT and PoT
not only unleashes the potential of tool use but also allows different thought
processes for different math problems. As a result, the MAmmoTH series
substantially outperform existing open-source models on nine mathematical
reasoning datasets across all scales with an average accuracy gain between 13%
and 29%. Remarkably, our MAmmoTH-7B model reaches 35% on MATH (a
competition-level dataset), which exceeds the best open-source 7B model
(WizardMath) by 25%, and the MAmmoTH-34B model achieves 46% accuracy on MATH,
even surpassing GPT-4's CoT result. Our work underscores the importance of
diverse problem coverage and the use of hybrid rationales in developing
superior math generalist models.
</p>
</div>
</dd>
<dt><a name="item481">[481]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.05655" title="Abstract">arXiv:2309.05655</a> [<a href="/pdf/2309.05655" title="Download PDF">pdf</a>, <a href="/format/2309.05655" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Dynamic Handover: Throw and Catch with Bimanual Hands
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+B">Binghao Huang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yuanpei Chen</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+T">Tianyu Wang</a>, 
<a href="/search/cs?searchtype=author&query=Qin%2C+Y">Yuzhe Qin</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yaodong Yang</a>, 
<a href="/search/cs?searchtype=author&query=Atanasov%2C+N">Nikolay Atanasov</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xiaolong Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at CoRL 2023. <a href="https://binghao-huang.github.io/dynamic_handover/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Humans throw and catch objects all the time. However, such a seemingly common
skill introduces a lot of challenges for robots to achieve: The robots need to
operate such dynamic actions at high-speed, collaborate precisely, and interact
with diverse objects. In this paper, we design a system with two multi-finger
hands attached to robot arms to solve this problem. We train our system using
Multi-Agent Reinforcement Learning in simulation and perform Sim2Real transfer
to deploy on the real robots. To overcome the Sim2Real gap, we provide multiple
novel algorithm designs including learning a trajectory prediction model for
the object. Such a model can help the robot catcher has a real-time estimation
of where the object will be heading, and then react accordingly. We conduct our
experiments with multiple objects in the real-world system, and show
significant improvements over multiple baselines. Our project page is available
at \url{https://binghao-huang.github.io/dynamic_handover/}.
</p>
</div>
</dd>
<dt><a name="item482">[482]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.05658" title="Abstract">arXiv:2309.05658</a> [<a href="/pdf/2309.05658" title="Download PDF">pdf</a>, <a href="/format/2309.05658" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> From Capture to Display: A Survey on Volumetric Video
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jin%2C+Y">Yili Jin</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+K">Kaiyuan Hu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Junhua Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+F">Fangxin Wang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xue Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Multimedia (cs.MM)</span>; Networking and Internet Architecture (cs.NI); Image and Video Processing (eess.IV)

</div>
<p class="mathjax">Volumetric video, which offers immersive viewing experiences, is gaining
increasing prominence. With its six degrees of freedom, it provides viewers
with greater immersion and interactivity compared to traditional videos.
Despite their potential, volumetric video services poses significant
challenges. This survey conducts a comprehensive review of the existing
literature on volumetric video. We firstly provide a general framework of
volumetric video services, followed by a discussion on prerequisites for
volumetric video, encompassing representations, open datasets, and quality
assessment metrics. Then we delve into the current methodologies for each stage
of the volumetric video service pipeline, detailing capturing, compression,
transmission, rendering, and display techniques. Lastly, we explore various
applications enabled by this pioneering technology and we present an array of
research challenges and opportunities in the domain of volumetric video
services. This survey aspires to provide a holistic understanding of this
burgeoning field and shed light on potential future research trajectories,
aiming to bring the vision of volumetric video to fruition.
</p>
</div>
</dd>
<dt><a name="item483">[483]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.05660" title="Abstract">arXiv:2309.05660</a> [<a href="/pdf/2309.05660" title="Download PDF">pdf</a>, <a href="/format/2309.05660" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Hypothesis Search: Inductive Reasoning with Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+R">Ruocheng Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zelikman%2C+E">Eric Zelikman</a>, 
<a href="/search/cs?searchtype=author&query=Poesia%2C+G">Gabriel Poesia</a>, 
<a href="/search/cs?searchtype=author&query=Pu%2C+Y">Yewen Pu</a>, 
<a href="/search/cs?searchtype=author&query=Haber%2C+N">Nick Haber</a>, 
<a href="/search/cs?searchtype=author&query=Goodman%2C+N+D">Noah D. Goodman</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL)

</div>
<p class="mathjax">Inductive reasoning is a core problem-solving capacity: humans can identify
underlying principles from a few examples, which can then be robustly
generalized to novel scenarios. Recent work has evaluated large language models
(LLMs) on inductive reasoning tasks by directly prompting them yielding "in
context learning." This can work well for straightforward inductive tasks, but
performs very poorly on more complex tasks such as the Abstraction and
Reasoning Corpus (ARC). In this work, we propose to improve the inductive
reasoning ability of LLMs by generating explicit hypotheses at multiple levels
of abstraction: we prompt the LLM to propose multiple abstract hypotheses about
the problem, in natural language, then implement the natural language
hypotheses as concrete Python programs. These programs can be directly verified
by running on the observed examples and generalized to novel inputs. Because of
the prohibitive cost of generation with state-of-the-art LLMs, we consider a
middle step to filter the set of hypotheses that will be implemented into
programs: we either ask the LLM to summarize into a smaller set of hypotheses,
or ask human annotators to select a subset of the hypotheses. We verify our
pipeline's effectiveness on the ARC visual inductive reasoning benchmark, its
variant 1D-ARC, and string transformation dataset SyGuS. On a random 40-problem
subset of ARC, our automated pipeline using LLM summaries achieves 27.5%
accuracy, significantly outperforming the direct prompting baseline (accuracy
of 12.5%). With the minimal human input of selecting from LLM-generated
candidates, the performance is boosted to 37.5%. (And we argue this is a lower
bound on the performance of our approach without filtering.) Our ablation
studies show that abstract hypothesis generation and concrete program
representations are both beneficial for LLMs to perform inductive reasoning
tasks.
</p>
</div>
</dd>
<dt><a name="item484">[484]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.05662" title="Abstract">arXiv:2309.05662</a> [<a href="/pdf/2309.05662" title="Download PDF">pdf</a>, <a href="/format/2309.05662" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ViHOPE: Visuotactile In-Hand Object 6D Pose Estimation with Shape  Completion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Hongyu Li</a>, 
<a href="/search/cs?searchtype=author&query=Dikhale%2C+S">Snehal Dikhale</a>, 
<a href="/search/cs?searchtype=author&query=Iba%2C+S">Soshi Iba</a>, 
<a href="/search/cs?searchtype=author&query=Jamali%2C+N">Nawid Jamali</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by RA-L
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">In this letter, we introduce ViHOPE, a novel framework for estimating the 6D
pose of an in-hand object using visuotactile perception. Our key insight is
that the accuracy of the 6D object pose estimate can be improved by explicitly
completing the shape of the object. To this end, we introduce a novel
visuotactile shape completion module that uses a conditional Generative
Adversarial Network to complete the shape of an in-hand object based on
volumetric representation. This approach improves over prior works that
directly regress visuotactile observations to a 6D pose. By explicitly
completing the shape of the in-hand object and jointly optimizing the shape
completion and pose estimation tasks, we improve the accuracy of the 6D object
pose estimate. We train and test our model on a synthetic dataset and compare
it with the state-of-the-art. In the visuotactile shape completion task, we
outperform the state-of-the-art by 265% using the Intersection of Union metric
and achieve 88% lower Chamfer Distance. In the visuotactile pose estimation
task, we present results that suggest our framework reduces position and
angular errors by 35% and 64%, respectively. Furthermore, we ablate our
framework to confirm the gain on the 6D object pose estimate from explicitly
completing the shape. Ultimately, we show that our framework produces models
that are robust to sim-to-real transfer on a real-world robot platform.
</p>
</div>
</dd>
<dt><a name="item485">[485]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.05663" title="Abstract">arXiv:2309.05663</a> [<a href="/pdf/2309.05663" title="Download PDF">pdf</a>, <a href="/format/2309.05663" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Diffusion-Guided Reconstruction of Everyday Hand-Object Interaction  Clips
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ye%2C+Y">Yufei Ye</a>, 
<a href="/search/cs?searchtype=author&query=Hebbar%2C+P">Poorvi Hebbar</a>, 
<a href="/search/cs?searchtype=author&query=Gupta%2C+A">Abhinav Gupta</a>, 
<a href="/search/cs?searchtype=author&query=Tulsiani%2C+S">Shubham Tulsiani</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to ICCV23 (Oral). Project Page: <a href="https://judyye.github.io/diffhoi-www/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">We tackle the task of reconstructing hand-object interactions from short
video clips. Given an input video, our approach casts 3D inference as a
per-video optimization and recovers a neural 3D representation of the object
shape, as well as the time-varying motion and hand articulation. While the
input video naturally provides some multi-view cues to guide 3D inference,
these are insufficient on their own due to occlusions and limited viewpoint
variations. To obtain accurate 3D, we augment the multi-view signals with
generic data-driven priors to guide reconstruction. Specifically, we learn a
diffusion network to model the conditional distribution of (geometric)
renderings of objects conditioned on hand configuration and category label, and
leverage it as a prior to guide the novel-view renderings of the reconstructed
scene. We empirically evaluate our approach on egocentric videos across 6
object categories, and observe significant improvements over prior single-view
and multi-view methods. Finally, we demonstrate our system's ability to
reconstruct arbitrary clips from YouTube, showing both 1st and 3rd person
interactions.
</p>
</div>
</dd>
<dt><a name="item486">[486]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.05665" title="Abstract">arXiv:2309.05665</a> [<a href="/pdf/2309.05665" title="Download PDF">pdf</a>, <a href="/format/2309.05665" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Robot Parkour Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhuang%2C+Z">Ziwen Zhuang</a>, 
<a href="/search/cs?searchtype=author&query=Fu%2C+Z">Zipeng Fu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jianren Wang</a>, 
<a href="/search/cs?searchtype=author&query=Atkeson%2C+C">Christopher Atkeson</a>, 
<a href="/search/cs?searchtype=author&query=Schwertfeger%2C+S">Soeren Schwertfeger</a>, 
<a href="/search/cs?searchtype=author&query=Finn%2C+C">Chelsea Finn</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+H">Hang Zhao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> CoRL 2023 (Oral). Project website at <a href="https://robot-parkour.github.io">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
<p class="mathjax">Parkour is a grand challenge for legged locomotion that requires robots to
overcome various obstacles rapidly in complex environments. Existing methods
can generate either diverse but blind locomotion skills or vision-based but
specialized skills by using reference animal data or complex rewards. However,
autonomous parkour requires robots to learn generalizable skills that are both
vision-based and diverse to perceive and react to various scenarios. In this
work, we propose a system for learning a single end-to-end vision-based parkour
policy of diverse parkour skills using a simple reward without any reference
motion data. We develop a reinforcement learning method inspired by direct
collocation to generate parkour skills, including climbing over high obstacles,
leaping over large gaps, crawling beneath low barriers, squeezing through thin
slits, and running. We distill these skills into a single vision-based parkour
policy and transfer it to a quadrupedal robot using its egocentric depth
camera. We demonstrate that our system can empower two different low-cost
robots to autonomously select and execute appropriate parkour skills to
traverse challenging real-world environments.
</p>
</div>
</dd>
</dl>
<h3>Cross-lists for Tue, 12 Sep 23</h3>
<dl>
<dt><a name="item487">[487]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2005.04513" title="Abstract">arXiv:2005.04513</a> (cross-list from eess.SY) [<a href="/pdf/2005.04513" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Intelligent GPS Spoofing Attack Detection in Power Grids
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Sabouri%2C+M">Mohammad Sabouri</a>, 
<a href="/search/eess?searchtype=author&query=Siamak%2C+S">Sara Siamak</a>, 
<a href="/search/eess?searchtype=author&query=Dehghani%2C+M">Maryam Dehghani</a>, 
<a href="/search/eess?searchtype=author&query=Mohammadi%2C+M">Mohsen Mohammadi</a>, 
<a href="/search/eess?searchtype=author&query=Asemani%2C+M+H">Mohammad Hassan Asemani</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Artificial Intelligence (cs.AI); Cryptography and Security (cs.CR); Machine Learning (cs.LG)

</div>
<p class="mathjax">The GPS is vulnerable to GPS spoofing attack (GSA), which leads to disorder
in time and position results of the GPS receiver. In power grids, phasor
measurement units (PMUs) use GPS to build time-tagged measurements, so they are
susceptible to this attack. As a result of this attack, sampling time and phase
angle of the PMU measurements change. In this paper, a neural network GPS
spoofing detection (NNGSD) with employing PMU data from the dynamic power
system is presented to detect GSAs. Numerical results in different conditions
show the real-time performance of the proposed detection method.
</p>
</div>
</dd>
<dt><a name="item488">[488]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.03878" title="Abstract">arXiv:2309.03878</a> (cross-list from math.CO) [<a href="/pdf/2309.03878" title="Download PDF">pdf</a>, <a href="/format/2309.03878" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On generalized corners and matrix multiplication
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Pratt%2C+K">Kevin Pratt</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Feedback welcome!
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Combinatorics (math.CO)</span>; Discrete Mathematics (cs.DM); Data Structures and Algorithms (cs.DS)

</div>
<p class="mathjax">Suppose that $S \subseteq [n]^2$ contains no three points of the form $(x,y),
(x,y+\delta), (x+\delta,y')$, where $\delta \neq 0$. How big can $S$ be?
Trivially, $n \le |S| \le n^2$. Slight improvements on these bounds are
obtained from Shkredov's upper bound for the corners problem [Shk06], which
shows that $|S| \le O(n^2/(\log \log n)^c)$ for some small $c &gt; 0$, and a
construction due to Petrov [Pet23], which shows that $|S| \ge \Omega(n \log
n/\sqrt{\log \log n})$.
<br />Could it be that for all $\varepsilon &gt; 0$, $|S| \le O(n^{1+\varepsilon})$?
We show that if so, this would rule out obtaining $\omega = 2$ using a large
family of abelian groups in the group-theoretic framework of Cohn, Kleinberg,
Szegedy and Umans [CU03,CKSU05] (which is known to capture the best bounds on
$\omega$ to date), for which no barriers are currently known. Furthermore, an
upper bound of $O(n^{4/3 - \varepsilon})$ for any fixed $\varepsilon &gt; 0$ would
rule out a conjectured approach to obtain $\omega = 2$ of [CKSU05]. Along the
way, we encounter several problems that have much stronger constraints and that
would already have these implications.
</p>
</div>
</dd>
<dt><a name="item489">[489]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.04474" title="Abstract">arXiv:2309.04474</a> (cross-list from cond-mat.mtrl-sci) [<a href="/pdf/2309.04474" title="Download PDF">pdf</a>, <a href="/format/2309.04474" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Weakly supervised learning for pattern classification in serial  femtosecond crystallography
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cond-mat?searchtype=author&query=Xie%2C+J">Jianan Xie</a>, 
<a href="/search/cond-mat?searchtype=author&query=Liu%2C+J">Ji Liu</a>, 
<a href="/search/cond-mat?searchtype=author&query=Zhang%2C+C">Chi Zhang</a>, 
<a href="/search/cond-mat?searchtype=author&query=Chen%2C+X">Xihui Chen</a>, 
<a href="/search/cond-mat?searchtype=author&query=Huai%2C+P">Ping Huai</a>, 
<a href="/search/cond-mat?searchtype=author&query=Zheng%2C+J">Jie Zheng</a>, 
<a href="/search/cond-mat?searchtype=author&query=Zhang%2C+X">Xiaofeng Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 pages, 10 figures, 7 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Materials Science (cond-mat.mtrl-sci)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Serial femtosecond crystallography at X-ray free electron laser facilities
opens a new era for the determination of crystal structure. However, the data
processing of those experiments is facing unprecedented challenge, because the
total number of diffraction patterns needed to determinate a high-resolution
structure is huge. Machine learning methods are very likely to play important
roles in dealing with such a large volume of data. Convolutional neural
networks have made a great success in the field of pattern classification,
however, training of the networks need very large datasets with labels. Th is
heavy dependence on labeled datasets will seriously restrict the application of
networks, because it is very costly to annotate a large number of diffraction
patterns. In this article we present our job on the classification of
diffraction pattern by weakly supervised algorithms, with the aim of reducing
as much as possible the size of the labeled dataset required for training. Our
result shows that weakly supervised methods can significantly reduce the need
for the number of labeled patterns while achieving comparable accuracy to fully
supervised methods.
</p>
</div>
</dd>
<dt><a name="item490">[490]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.04475" title="Abstract">arXiv:2309.04475</a> (cross-list from cond-mat.mtrl-sci) [<a href="/pdf/2309.04475" title="Download PDF">pdf</a>, <a href="/format/2309.04475" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Crystal Structure Prediction by Joint Equivariant Diffusion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cond-mat?searchtype=author&query=Jiao%2C+R">Rui Jiao</a>, 
<a href="/search/cond-mat?searchtype=author&query=Huang%2C+W">Wenbing Huang</a>, 
<a href="/search/cond-mat?searchtype=author&query=Lin%2C+P">Peijia Lin</a>, 
<a href="/search/cond-mat?searchtype=author&query=Han%2C+J">Jiaqi Han</a>, 
<a href="/search/cond-mat?searchtype=author&query=Chen%2C+P">Pin Chen</a>, 
<a href="/search/cond-mat?searchtype=author&query=Lu%2C+Y">Yutong Lu</a>, 
<a href="/search/cond-mat?searchtype=author&query=Liu%2C+Y">Yang Liu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Materials Science (cond-mat.mtrl-sci)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Crystal Structure Prediction (CSP) is crucial in various scientific
disciplines. While CSP can be addressed by employing currently-prevailing
generative models (e.g. diffusion models), this task encounters unique
challenges owing to the symmetric geometry of crystal structures -- the
invariance of translation, rotation, and periodicity. To incorporate the above
symmetries, this paper proposes DiffCSP, a novel diffusion model to learn the
structure distribution from stable crystals. To be specific, DiffCSP jointly
generates the lattice and atom coordinates for each crystal by employing a
periodic-E(3)-equivariant denoising model, to better model the crystal
geometry. Notably, different from related equivariant generative approaches,
DiffCSP leverages fractional coordinates other than Cartesian coordinates to
represent crystals, remarkably promoting the diffusion and the generation
process of atom positions. Extensive experiments verify that our DiffCSP
significantly outperforms existing CSP methods, with a much lower computation
cost in contrast to DFT-based methods. Moreover, the superiority of DiffCSP is
also observed when it is extended for ab initio crystal generation.
</p>
</div>
</dd>
<dt><a name="item491">[491]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.04478" title="Abstract">arXiv:2309.04478</a> (cross-list from cond-mat.mtrl-sci) [<a href="/pdf/2309.04478" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multimodal machine learning for materials science: composition-structure  bimodal learning for experimentally measured properties
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cond-mat?searchtype=author&query=Gong%2C+S">Sheng Gong</a>, 
<a href="/search/cond-mat?searchtype=author&query=Wang%2C+S">Shuo Wang</a>, 
<a href="/search/cond-mat?searchtype=author&query=Zhu%2C+T">Taishan Zhu</a>, 
<a href="/search/cond-mat?searchtype=author&query=Shao-Horn%2C+Y">Yang Shao-Horn</a>, 
<a href="/search/cond-mat?searchtype=author&query=Grossman%2C+J+C">Jeffrey C. Grossman</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Materials Science (cond-mat.mtrl-sci)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">The widespread application of multimodal machine learning models like GPT-4
has revolutionized various research fields including computer vision and
natural language processing. However, its implementation in materials
informatics remains underexplored, despite the presence of materials data
across diverse modalities, such as composition and structure. The effectiveness
of machine learning models trained on large calculated datasets depends on the
accuracy of calculations, while experimental datasets often have limited data
availability and incomplete information. This paper introduces a novel approach
to multimodal machine learning in materials science via composition-structure
bimodal learning. The proposed COmposition-Structure Bimodal Network (COSNet)
is designed to enhance learning and predictions of experimentally measured
materials properties that have incomplete structure information. Bimodal
learning significantly reduces prediction errors across distinct materials
properties including Li conductivity in solid electrolyte, band gap, refractive
index, dielectric constant, energy, and magnetic moment, surpassing
composition-only learning methods. Furthermore, we identified that data
augmentation based on modal availability plays a pivotal role in the success of
bimodal learning.
</p>
</div>
</dd>
<dt><a name="item492">[492]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.04482" title="Abstract">arXiv:2309.04482</a> (cross-list from cond-mat.mtrl-sci) [<a href="/pdf/2309.04482" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Addressing the Accuracy-Cost Tradeoff in Material Property Prediction: A  Teacher-Student Strategy
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cond-mat?searchtype=author&query=Zhu%2C+D">Dong Zhu</a>, 
<a href="/search/cond-mat?searchtype=author&query=xin%2C+Z">Zhikuang xin</a>, 
<a href="/search/cond-mat?searchtype=author&query=Zheng%2C+S">Siming Zheng</a>, 
<a href="/search/cond-mat?searchtype=author&query=Wang%2C+Y">Yangang Wang</a>, 
<a href="/search/cond-mat?searchtype=author&query=Yang%2C+X">Xiaoyu Yang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Materials Science (cond-mat.mtrl-sci)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Deep learning has revolutionized the process of new material discovery, with
state-of-the-art models now able to predict material properties based solely on
chemical compositions, thus eliminating the necessity for material structures.
However, this cost-effective method has led to a trade-off in model accuracy.
Specifically, the accuracy of Chemical Composition-based Property Prediction
Models (CPMs) significantly lags behind that of Structure-based Property
Prediction Models (SPMs). To tackle this challenge, we propose an innovative
Teacher-Student (T-S) strategy, where a pre-trained SPM serves as the 'teacher'
to enhance the accuracy of the CPM. Leveraging the T-S strategy, T-S CrabNet
has risen to become the most accurate model among current CPMs. Initially, we
demonstrated the universality of this strategy. On the Materials Project (MP)
and Jarvis datasets, we validated the effectiveness of the T-S strategy in
boosting the accuracy of CPMs with two distinct network structures, namely
CrabNet and Roost. This led to CrabNet, under the guidance of the T-S strategy,
emerging as the most accurate model among the current CPMs. Moreover, this
strategy shows remarkable efficacy in small datasets. When predicting the
formation energy on a small MP dataset comprising merely 5% of the samples, the
T-S strategy boosted CrabNet's accuracy by 37.1%, exceeding the enhancement
effect of the T-S strategy on the whole dataset.
</p>
</div>
</dd>
<dt><a name="item493">[493]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.04503" title="Abstract">arXiv:2309.04503</a> (cross-list from quant-ph) [<a href="/pdf/2309.04503" title="Download PDF">pdf</a>, <a href="/format/2309.04503" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Quantum Algorithm for Maximum Biclique Problem
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Li%2C+X">Xiaofan Li</a>, 
<a href="/search/quant-ph?searchtype=author&query=Mitra%2C+P">Prasenjit Mitra</a>, 
<a href="/search/quant-ph?searchtype=author&query=Zhou%2C+R">Rui Zhou</a>, 
<a href="/search/quant-ph?searchtype=author&query=Nejdl%2C+W">Wolfgang Nejdl</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Databases (cs.DB); Data Structures and Algorithms (cs.DS)

</div>
<p class="mathjax">Identifying a biclique with the maximum number of edges bears considerable
implications for numerous fields of application, such as detecting anomalies in
E-commerce transactions, discerning protein-protein interactions in biology,
and refining the efficacy of social network recommendation algorithms. However,
the inherent NP-hardness of this problem significantly complicates the matter.
The prohibitive time complexity of existing algorithms is the primary
bottleneck constraining the application scenarios. Aiming to address this
challenge, we present an unprecedented exploration of a quantum computing
approach. Efficient quantum algorithms, as a crucial future direction for
handling NP-hard problems, are presently under intensive investigation, of
which the potential has already been proven in practical arenas such as
cybersecurity. However, in the field of quantum algorithms for graph databases,
little work has been done due to the challenges presented by the quantum
representation of complex graph topologies. In this study, we delve into the
intricacies of encoding a bipartite graph on a quantum computer. Given a
bipartite graph with n vertices, we propose a ground-breaking algorithm qMBS
with time complexity O^*(2^(n/2)), illustrating a quadratic speed-up in terms
of complexity compared to the state-of-the-art. Furthermore, we detail two
variants tailored for the maximum vertex biclique problem and the maximum
balanced biclique problem. To corroborate the practical performance and
efficacy of our proposed algorithms, we have conducted proof-of-principle
experiments utilizing IBM quantum simulators, of which the results provide a
substantial validation of our approach to the extent possible to date.
</p>
</div>
</dd>
<dt><a name="item494">[494]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.04507" title="Abstract">arXiv:2309.04507</a> (cross-list from q-fin.CP) [<a href="/pdf/2309.04507" title="Download PDF">pdf</a>, <a href="/format/2309.04507" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Generating drawdown-realistic financial price paths using path  signatures
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-fin?searchtype=author&query=Lemahieu%2C+E">Emiel Lemahieu</a>, 
<a href="/search/q-fin?searchtype=author&query=Boudt%2C+K">Kris Boudt</a>, 
<a href="/search/q-fin?searchtype=author&query=Wyns%2C+M">Maarten Wyns</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Finance (q-fin.CP)</span>; Machine Learning (cs.LG); Machine Learning (stat.ML)

</div>
<p class="mathjax">A novel generative machine learning approach for the simulation of sequences
of financial price data with drawdowns quantifiably close to empirical data is
introduced. Applications such as pricing drawdown insurance options or
developing portfolio drawdown control strategies call for a host of
drawdown-realistic paths. Historical scenarios may be insufficient to
effectively train and backtest the strategy, while standard parametric Monte
Carlo does not adequately preserve drawdowns. We advocate a non-parametric
Monte Carlo approach combining a variational autoencoder generative model with
a drawdown reconstruction loss function. To overcome issues of numerical
complexity and non-differentiability, we approximate drawdown as a linear
function of the moments of the path, known in the literature as path
signatures. We prove the required regularity of drawdown function and
consistency of the approximation. Furthermore, we obtain close numerical
approximations using linear regression for fractional Brownian and empirical
data. We argue that linear combinations of the moments of a path yield a
mathematically non-trivial smoothing of the drawdown function, which gives one
leeway to simulate drawdown-realistic price paths by including drawdown
evaluation metrics in the learning objective. We conclude with numerical
experiments on mixed equity, bond, real estate and commodity portfolios and
obtain a host of drawdown-realistic paths.
</p>
</div>
</dd>
<dt><a name="item495">[495]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.04511" title="Abstract">arXiv:2309.04511</a> (cross-list from eess.IV) [<a href="/pdf/2309.04511" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Systematic Review of Techniques in Brain Image Synthesis using Deep  Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Singh%2C+S">Shubham Singh</a>, 
<a href="/search/eess?searchtype=author&query=Ranapurwala%2C+A">Ammar Ranapurwala</a>, 
<a href="/search/eess?searchtype=author&query=Bewoor%2C+M">Mrunal Bewoor</a>, 
<a href="/search/eess?searchtype=author&query=Patil%2C+S">Sheetal Patil</a>, 
<a href="/search/eess?searchtype=author&query=Rai%2C+S">Satyam Rai</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">This review paper delves into the present state of medical imaging, with a
specific focus on the use of deep learning techniques for brain image
synthesis. The need for medical image synthesis to improve diagnostic accuracy
and decrease invasiveness in medical procedures is emphasized, along with the
role of deep learning in enabling these advancements. The paper examines
various methods and techniques for brain image synthesis, including 2D to 3D
constructions, MRI synthesis, and the use of transformers. It also addresses
limitations and challenges faced in these methods, such as obtaining
well-curated training data and addressing brain ultrasound issues. The review
concludes by exploring the future potential of this field and the opportunities
for further advancements in medical imaging using deep learning techniques. The
significance of transformers and their potential to revolutionize the medical
imaging field is highlighted. Additionally, the paper discusses the potential
solutions to the shortcomings and limitations faced in this field. The review
provides researchers with an updated reference on the present state of the
field and aims to inspire further research and bridge the gap between the
present state of medical imaging and the future possibilities offered by deep
learning techniques.
</p>
</div>
</dd>
<dt><a name="item496">[496]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.04516" title="Abstract">arXiv:2309.04516</a> (cross-list from eess.AS) [<a href="/pdf/2309.04516" title="Download PDF">pdf</a>, <a href="/ps/2309.04516" title="Download PostScript">ps</a>, <a href="/format/2309.04516" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> End-to-End Speech Recognition and Disfluency Removal with Acoustic  Language Model Pretraining
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Bassi%2C+S">Saksham Bassi</a>, 
<a href="/search/eess?searchtype=author&query=Duregon%2C+G">Giulio Duregon</a>, 
<a href="/search/eess?searchtype=author&query=Jalagam%2C+S">Siddhartha Jalagam</a>, 
<a href="/search/eess?searchtype=author&query=Roth%2C+D">David Roth</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Machine Learning (cs.LG); Sound (cs.SD)

</div>
<p class="mathjax">The SOTA in transcription of disfluent and conversational speech has in
recent years favored two-stage models, with separate transcription and cleaning
stages. We believe that previous attempts at end-to-end disfluency removal have
fallen short because of the representational advantage that large-scale
language model pretraining has given to lexical models. Until recently, the
high dimensionality and limited availability of large audio datasets inhibited
the development of large-scale self-supervised pretraining objectives for
learning effective audio representations, giving a relative advantage to the
two-stage approach, which utilises pretrained representations for lexical
tokens. In light of recent successes in large scale audio pretraining, we
revisit the performance comparison between two-stage and end-to-end model and
find that audio based language models pretrained using weak self-supervised
objectives match or exceed the performance of similarly trained two-stage
models, and further, that the choice of pretraining objective substantially
effects a model's ability to be adapted to the disfluency removal task.
</p>
</div>
</dd>
<dt><a name="item497">[497]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.04585" title="Abstract">arXiv:2309.04585</a> (cross-list from math.OC) [<a href="/pdf/2309.04585" title="Download PDF">pdf</a>, <a href="/format/2309.04585" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Asynchronous Distributed Optimization via ADMM with Efficient  Communication
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Rikos%2C+A+I">Apostolos I. Rikos</a>, 
<a href="/search/math?searchtype=author&query=Jiang%2C+W">Wei Jiang</a>, 
<a href="/search/math?searchtype=author&query=Charalambous%2C+T">Themistoklis Charalambous</a>, 
<a href="/search/math?searchtype=author&query=Johansson%2C+K+H">Karl H. Johansson</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Systems and Control (eess.SY)

</div>
<p class="mathjax">In this paper, we focus on an asynchronous distributed optimization problem.
In our problem, each node is endowed with a convex local cost function, and is
able to communicate with its neighbors over a directed communication network.
Furthermore, we assume that the communication channels between nodes have
limited bandwidth, and each node suffers from processing delays. We present a
distributed algorithm which combines the Alternating Direction Method of
Multipliers (ADMM) strategy with a finite time quantized averaging algorithm.
In our proposed algorithm, nodes exchange quantized valued messages and operate
in an asynchronous fashion. More specifically, during every iteration of our
algorithm each node (i) solves a local convex optimization problem (for the one
of its primal variables), and (ii) utilizes a finite-time quantized averaging
algorithm to obtain the value of the second primal variable (since the cost
function for the second primal variable is not decomposable). We show that our
algorithm converges to the optimal solution at a rate of $O(1/k)$ (where $k$ is
the number of time steps) for the case where the local cost function of every
node is convex and not-necessarily differentiable. Finally, we demonstrate the
operational advantages of our algorithm against other algorithms from the
literature.
</p>
</div>
</dd>
<dt><a name="item498">[498]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.04603" title="Abstract">arXiv:2309.04603</a> (cross-list from math.CO) [<a href="/pdf/2309.04603" title="Download PDF">pdf</a>, <a href="/ps/2309.04603" title="Download PostScript">ps</a>, <a href="/format/2309.04603" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Note on polychromatic coloring of hereditary hypergraph families
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=P%C3%A1lv%C3%B6lgyi%2C+D">D&#xf6;m&#xf6;t&#xf6;r P&#xe1;lv&#xf6;lgyi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Combinatorics (math.CO)</span>; Discrete Mathematics (cs.DM)

</div>
<p class="mathjax">We exhibit a 5-uniform hypergraph that has no polychromatic 3-coloring, but
all its restricted subhypergraphs with edges of size at least 3 are
2-colorable. This disproves a bold conjecture of Keszegh and the author, and
can be considered as the first step to understand polychromatic colorings of
hereditary hypergraph families better since the seminal work of Berge. We also
show that our method cannot give hypergraphs of arbitrary high uniformity, and
mention some connections to panchromatic colorings.
</p>
</div>
</dd>
<dt><a name="item499">[499]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.04626" title="Abstract">arXiv:2309.04626</a> (cross-list from stat.ML) [<a href="/pdf/2309.04626" title="Download PDF">pdf</a>, <a href="/format/2309.04626" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Perceptual adjustment queries and an inverted measurement paradigm for  low-rank metric learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Xu%2C+A">Austin Xu</a>, 
<a href="/search/stat?searchtype=author&query=McRae%2C+A+D">Andrew D. McRae</a>, 
<a href="/search/stat?searchtype=author&query=Wang%2C+J">Jingyan Wang</a>, 
<a href="/search/stat?searchtype=author&query=Davenport%2C+M+A">Mark A. Davenport</a>, 
<a href="/search/stat?searchtype=author&query=Pananjady%2C+A">Ashwin Pananjady</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 42 pages, 6 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Artificial Intelligence (cs.AI); Information Theory (cs.IT); Machine Learning (cs.LG)

</div>
<p class="mathjax">We introduce a new type of query mechanism for collecting human feedback,
called the perceptual adjustment query ( PAQ). Being both informative and
cognitively lightweight, the PAQ adopts an inverted measurement scheme, and
combines advantages from both cardinal and ordinal queries. We showcase the PAQ
in the metric learning problem, where we collect PAQ measurements to learn an
unknown Mahalanobis distance. This gives rise to a high-dimensional, low-rank
matrix estimation problem to which standard matrix estimators cannot be
applied. Consequently, we develop a two-stage estimator for metric learning
from PAQs, and provide sample complexity guarantees for this estimator. We
present numerical simulations demonstrating the performance of the estimator
and its notable properties.
</p>
</div>
</dd>
<dt><a name="item500">[500]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.04627" title="Abstract">arXiv:2309.04627</a> (cross-list from stat.ML) [<a href="/pdf/2309.04627" title="Download PDF">pdf</a>, <a href="/format/2309.04627" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Probabilistic Safety Regions Via Finite Families of Scalable Classifiers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Carlevaro%2C+A">Alberto Carlevaro</a>, 
<a href="/search/stat?searchtype=author&query=Alamo%2C+T">Teodoro Alamo</a>, 
<a href="/search/stat?searchtype=author&query=Dabbene%2C+F">Fabrizio Dabbene</a>, 
<a href="/search/stat?searchtype=author&query=Mongelli%2C+M">Maurizio Mongelli</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, 4 figures, 1 table, submitted to IEEE TNNLS
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Supervised classification recognizes patterns in the data to separate classes
of behaviours. Canonical solutions contain misclassification errors that are
intrinsic to the numerical approximating nature of machine learning. The data
analyst may minimize the classification error on a class at the expense of
increasing the error of the other classes. The error control of such a design
phase is often done in a heuristic manner. In this context, it is key to
develop theoretical foundations capable of providing probabilistic
certifications to the obtained classifiers. In this perspective, we introduce
the concept of probabilistic safety region to describe a subset of the input
space in which the number of misclassified instances is probabilistically
controlled. The notion of scalable classifiers is then exploited to link the
tuning of machine learning with error control. Several tests corroborate the
approach. They are provided through synthetic data in order to highlight all
the steps involved, as well as through a smart mobility application.
</p>
</div>
</dd>
<dt><a name="item501">[501]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.04628" title="Abstract">arXiv:2309.04628</a> (cross-list from eess.AS) [<a href="/pdf/2309.04628" title="Download PDF">pdf</a>, <a href="/format/2309.04628" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Leveraging Pretrained Image-text Models for Improving Audio-Visual  Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Bhati%2C+S">Saurabhchand Bhati</a>, 
<a href="/search/eess?searchtype=author&query=Villalba%2C+J">Jes&#xfa;s Villalba</a>, 
<a href="/search/eess?searchtype=author&query=Moro-Velazquez%2C+L">Laureano Moro-Velazquez</a>, 
<a href="/search/eess?searchtype=author&query=Thebaud%2C+T">Thomas Thebaud</a>, 
<a href="/search/eess?searchtype=author&query=Dehak%2C+N">Najim Dehak</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Sound (cs.SD)

</div>
<p class="mathjax">Visually grounded speech systems learn from paired images and their spoken
captions. Recently, there have been attempts to utilize the visually grounded
models trained from images and their corresponding text captions, such as CLIP,
to improve speech-based visually grounded models' performance. However, the
majority of these models only utilize the pretrained image encoder. Cascaded
SpeechCLIP attempted to generate localized word-level information and utilize
both the pretrained image and text encoders. Despite using both, they noticed a
substantial drop in retrieval performance. We proposed Segmental SpeechCLIP
which used a hierarchical segmental speech encoder to generate sequences of
word-like units. We used the pretrained CLIP text encoder on top of these
word-like unit representations and showed significant improvements over the
cascaded variant of SpeechCLIP. Segmental SpeechCLIP directly learns the word
embeddings as input to the CLIP text encoder bypassing the vocabulary
embeddings. Here, we explore mapping audio to CLIP vocabulary embeddings via
regularization and quantization. As our objective is to distill semantic
information into the speech encoders, we explore the usage of large unimodal
pretrained language models as the text encoders. Our method enables us to
bridge image and text encoders e.g. DINO and RoBERTa trained with uni-modal
data. Finally, we extend our framework in audio-only settings where only pairs
of semantically related audio are available. Experiments show that audio-only
systems perform close to the audio-visual system.
</p>
</div>
</dd>
<dt><a name="item502">[502]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.04630" title="Abstract">arXiv:2309.04630</a> (cross-list from eess.SP) [<a href="/pdf/2309.04630" title="Download PDF">pdf</a>, <a href="/format/2309.04630" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Enhancing Missing Data Imputation of Non-stationary Signals with  Harmonic Decomposition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Ruiz%2C+J">Joaquin Ruiz</a>, 
<a href="/search/eess?searchtype=author&query=Wu%2C+H">Hau-tieng Wu</a>, 
<a href="/search/eess?searchtype=author&query=Colominas%2C+M+A">Marcelo A. Colominas</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Mathematical Software (cs.MS)

</div>
<p class="mathjax">Dealing with time series with missing values, including those afflicted by
low quality or over-saturation, presents a significant signal processing
challenge. The task of recovering these missing values, known as imputation,
has led to the development of several algorithms. However, we have observed
that the efficacy of these algorithms tends to diminish when the time series
exhibit non-stationary oscillatory behavior. In this paper, we introduce a
novel algorithm, coined Harmonic Level Interpolation (HaLI), which enhances the
performance of existing imputation algorithms for oscillatory time series.
After running any chosen imputation algorithm, HaLI leverages the harmonic
decomposition based on the adaptive nonharmonic model of the initial imputation
to improve the imputation accuracy for oscillatory time series. Experimental
assessments conducted on synthetic and real signals consistently highlight that
HaLI enhances the performance of existing imputation algorithms. The algorithm
is made publicly available as a readily employable Matlab code for other
researchers to use.
</p>
</div>
</dd>
<dt><a name="item503">[503]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.04631" title="Abstract">arXiv:2309.04631</a> (cross-list from q-bio.TO) [<a href="/pdf/2309.04631" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Open and reusable deep learning for pathology with WSInfer and QuPath
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-bio?searchtype=author&query=Kaczmarzyk%2C+J+R">Jakub R. Kaczmarzyk</a>, 
<a href="/search/q-bio?searchtype=author&query=O%27Callaghan%2C+A">Alan O&#x27;Callaghan</a>, 
<a href="/search/q-bio?searchtype=author&query=Inglis%2C+F">Fiona Inglis</a>, 
<a href="/search/q-bio?searchtype=author&query=Kurc%2C+T">Tahsin Kurc</a>, 
<a href="/search/q-bio?searchtype=author&query=Gupta%2C+R">Rajarsi Gupta</a>, 
<a href="/search/q-bio?searchtype=author&query=Bremer%2C+E">Erich Bremer</a>, 
<a href="/search/q-bio?searchtype=author&query=Bankhead%2C+P">Peter Bankhead</a>, 
<a href="/search/q-bio?searchtype=author&query=Saltz%2C+J+H">Joel H. Saltz</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Tissues and Organs (q-bio.TO)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">The field of digital pathology has seen a proliferation of deep learning
models in recent years. Despite substantial progress, it remains rare for other
researchers and pathologists to be able to access models published in the
literature and apply them to their own images. This is due to difficulties in
both sharing and running models. To address these concerns, we introduce
WSInfer: a new, open-source software ecosystem designed to make deep learning
for pathology more streamlined and accessible. WSInfer comprises three main
elements: 1) a Python package and command line tool to efficiently apply
patch-based deep learning inference to whole slide images; 2) a QuPath
extension that provides an alternative inference engine through user-friendly
and interactive software, and 3) a model zoo, which enables pathology models
and metadata to be easily shared in a standardized form. Together, these
contributions aim to encourage wider reuse, exploration, and interrogation of
deep learning models for research purposes, by putting them into the hands of
pathologists and eliminating a need for coding experience when accessed through
QuPath. The WSInfer source code is hosted on GitHub and documentation is
available at https://wsinfer.readthedocs.io.
</p>
</div>
</dd>
<dt><a name="item504">[504]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.04651" title="Abstract">arXiv:2309.04651</a> (cross-list from eess.IV) [<a href="/pdf/2309.04651" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Video and Synthetic MRI Pre-training of 3D Vision Architectures for  Neuroimage Analysis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Dhinagar%2C+N+J">Nikhil J. Dhinagar</a>, 
<a href="/search/eess?searchtype=author&query=Singh%2C+A">Amit Singh</a>, 
<a href="/search/eess?searchtype=author&query=Ozarkar%2C+S">Saket Ozarkar</a>, 
<a href="/search/eess?searchtype=author&query=Buwa%2C+K">Ketaki Buwa</a>, 
<a href="/search/eess?searchtype=author&query=Thomopoulos%2C+S+I">Sophia I. Thomopoulos</a>, 
<a href="/search/eess?searchtype=author&query=Owens-Walton%2C+C">Conor Owens-Walton</a>, 
<a href="/search/eess?searchtype=author&query=Laltoo%2C+E">Emily Laltoo</a>, 
<a href="/search/eess?searchtype=author&query=Chen%2C+Y">Yao-Liang Chen</a>, 
<a href="/search/eess?searchtype=author&query=Cook%2C+P">Philip Cook</a>, 
<a href="/search/eess?searchtype=author&query=McMillan%2C+C">Corey McMillan</a>, 
<a href="/search/eess?searchtype=author&query=Tsai%2C+C">Chih-Chien Tsai</a>, 
<a href="/search/eess?searchtype=author&query=Wang%2C+J">J-J Wang</a>, 
<a href="/search/eess?searchtype=author&query=Wu%2C+Y">Yih-Ru Wu</a>, 
<a href="/search/eess?searchtype=author&query=Thompson%2C+P+M">Paul M. Thompson</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Transfer learning represents a recent paradigm shift in the way we build
artificial intelligence (AI) systems. In contrast to training task-specific
models, transfer learning involves pre-training deep learning models on a large
corpus of data and minimally fine-tuning them for adaptation to specific tasks.
Even so, for 3D medical imaging tasks, we do not know if it is best to
pre-train models on natural images, medical images, or even synthetically
generated MRI scans or video data. To evaluate these alternatives, here we
benchmarked vision transformers (ViTs) and convolutional neural networks
(CNNs), initialized with varied upstream pre-training approaches. These methods
were then adapted to three unique downstream neuroimaging tasks with a range of
difficulty: Alzheimer's disease (AD) and Parkinson's disease (PD)
classification, "brain age" prediction. Experimental tests led to the following
key observations: 1. Pre-training improved performance across all tasks
including a boost of 7.4% for AD classification and 4.6% for PD classification
for the ViT and 19.1% for PD classification and reduction in brain age
prediction error by 1.26 years for CNNs, 2. Pre-training on large-scale video
or synthetic MRI data boosted performance of ViTs, 3. CNNs were robust in
limited-data settings, and in-domain pretraining enhanced their performances,
4. Pre-training improved generalization to out-of-distribution datasets and
sites. Overall, we benchmarked different vision architectures, revealing the
value of pre-training them with emerging datasets for model initialization. The
resulting pre-trained models can be adapted to a range of downstream
neuroimaging tasks, even when training data for the target task is limited.
</p>
</div>
</dd>
<dt><a name="item505">[505]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.04670" title="Abstract">arXiv:2309.04670</a> (cross-list from eess.SP) [<a href="/pdf/2309.04670" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Generalized Minimum Error with Fiducial Points Criterion for Robust  Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Zhao%2C+H">Haiquan Zhao</a>, 
<a href="/search/eess?searchtype=author&query=Gao%2C+Y">Yuan Gao</a>, 
<a href="/search/eess?searchtype=author&query=Zhu%2C+Y">Yingying Zhu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 9 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Sound (cs.SD); Audio and Speech Processing (eess.AS); Image and Video Processing (eess.IV); Systems and Control (eess.SY)

</div>
<p class="mathjax">The conventional Minimum Error Entropy criterion (MEE) has its limitations,
showing reduced sensitivity to error mean values and uncertainty regarding
error probability density function locations. To overcome this, a MEE with
fiducial points criterion (MEEF), was presented. However, the efficacy of the
MEEF is not consistent due to its reliance on a fixed Gaussian kernel. In this
paper, a generalized minimum error with fiducial points criterion (GMEEF) is
presented by adopting the Generalized Gaussian Density (GGD) function as
kernel. The GGD extends the Gaussian distribution by introducing a shape
parameter that provides more control over the tail behavior and peakedness. In
addition, due to the high computational complexity of GMEEF criterion, the
quantized idea is introduced to notably lower the computational load of the
GMEEF-type algorithm. Finally, the proposed criterions are introduced to the
domains of adaptive filter, kernel recursive algorithm, and multilayer
perceptron. Several numerical simulations, which contain system identification,
acoustic echo cancellation, times series prediction, and supervised
classification, indicate that the novel algorithms' performance performs
excellently.
</p>
</div>
</dd>
<dt><a name="item506">[506]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.04672" title="Abstract">arXiv:2309.04672</a> (cross-list from eess.IV) [<a href="/pdf/2309.04672" title="Download PDF">pdf</a>, <a href="/format/2309.04672" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SSHNN: Semi-Supervised Hybrid NAS Network for Echocardiographic Image  Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Chen%2C+R">Renqi Chen</a>, 
<a href="/search/eess?searchtype=author&query=Luo%2C+J">Jingjing Luo</a>, 
<a href="/search/eess?searchtype=author&query=Nian%2C+F">Fan Nian</a>, 
<a href="/search/eess?searchtype=author&query=Cen%2C+Y">Yuhui Cen</a>, 
<a href="/search/eess?searchtype=author&query=Peng%2C+Y">Yiheng Peng</a>, 
<a href="/search/eess?searchtype=author&query=Yu%2C+Z">Zekuan Yu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to ICASSP2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Accurate medical image segmentation especially for echocardiographic images
with unmissable noise requires elaborate network design. Compared with manual
design, Neural Architecture Search (NAS) realizes better segmentation results
due to larger search space and automatic optimization, but most of the existing
methods are weak in layer-wise feature aggregation and adopt a ``strong
encoder, weak decoder" structure, insufficient to handle global relationships
and local details. To resolve these issues, we propose a novel semi-supervised
hybrid NAS network for accurate medical image segmentation termed SSHNN. In
SSHNN, we creatively use convolution operation in layer-wise feature fusion
instead of normalized scalars to avoid losing details, making NAS a stronger
encoder. Moreover, Transformers are introduced for the compensation of global
context and U-shaped decoder is designed to efficiently connect global context
with local features. Specifically, we implement a semi-supervised algorithm
Mean-Teacher to overcome the limited volume problem of labeled medical image
dataset. Extensive experiments on CAMUS echocardiography dataset demonstrate
that SSHNN outperforms state-of-the-art approaches and realizes accurate
segmentation. Code will be made publicly available.
</p>
</div>
</dd>
<dt><a name="item507">[507]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.04726" title="Abstract">arXiv:2309.04726</a> (cross-list from math.CO) [<a href="/pdf/2309.04726" title="Download PDF">pdf</a>, <a href="/ps/2309.04726" title="Download PostScript">ps</a>, <a href="/format/2309.04726" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Eigenvalues of some classes of signed complete graphs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=S%2C+P">Prajnanaswaroopa S</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Combinatorics (math.CO)</span>; Discrete Mathematics (cs.DM)

</div>
<p class="mathjax">In this work, we discuss some properties of the eigenvalues of some classes
of signed complete graphs. We also obtain the form of characteristic polynomial
for these graphs.
</p>
</div>
</dd>
<dt><a name="item508">[508]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.04728" title="Abstract">arXiv:2309.04728</a> (cross-list from math.DS) [<a href="/pdf/2309.04728" title="Download PDF">pdf</a>, <a href="/format/2309.04728" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Transitions in echo index and dependence on input repetitions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Ashwin%2C+P">Peter Ashwin</a>, 
<a href="/search/math?searchtype=author&query=Ceni%2C+A">Andrea Ceni</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Dynamical Systems (math.DS)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">The echo index counts the number of simultaneously stable asymptotic
responses of a nonautonomous (i.e. input-driven) dynamical system. It
generalizes the well-known echo state property for recurrent neural networks -
this corresponds to the echo index being equal to one. In this paper, we
investigate how the echo index depends on parameters that govern typical
responses to a finite-state ergodic external input that forces the dynamics. We
consider the echo index for a nonautonomous system that switches between a
finite set of maps, where we assume that each map possesses a finite set of
hyperbolic equilibrium attractors. We find the minimum and maximum repetitions
of each map are crucial for the resulting echo index. Casting our theoretical
findings in the RNN computing framework, we obtain that for small amplitude
forcing the echo index corresponds to the number of attractors for the
input-free system, while for large amplitude forcing, the echo index reduces to
one. The intermediate regime is the most interesting; in this region the echo
index depends not just on the amplitude of forcing but also on more subtle
properties of the input.
</p>
</div>
</dd>
<dt><a name="item509">[509]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.04742" title="Abstract">arXiv:2309.04742</a> (cross-list from stat.ML) [<a href="/pdf/2309.04742" title="Download PDF">pdf</a>, <a href="/format/2309.04742" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Affine Invariant Ensemble Transform Methods to Improve Predictive  Uncertainty in ReLU Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Bhandari%2C+D">Diksha Bhandari</a>, 
<a href="/search/stat?searchtype=author&query=Pidstrigach%2C+J">Jakiw Pidstrigach</a>, 
<a href="/search/stat?searchtype=author&query=Reich%2C+S">Sebastian Reich</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG); Numerical Analysis (math.NA)

</div>
<p class="mathjax">We consider the problem of performing Bayesian inference for logistic
regression using appropriate extensions of the ensemble Kalman filter. Two
interacting particle systems are proposed that sample from an approximate
posterior and prove quantitative convergence rates of these interacting
particle systems to their mean-field limit as the number of particles tends to
infinity. Furthermore, we apply these techniques and examine their
effectiveness as methods of Bayesian approximation for quantifying predictive
uncertainty in ReLU networks.
</p>
</div>
</dd>
<dt><a name="item510">[510]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.04819" title="Abstract">arXiv:2309.04819</a> (cross-list from quant-ph) [<a href="/pdf/2309.04819" title="Download PDF">pdf</a>, <a href="/format/2309.04819" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Detecting Violations of Differential Privacy for Quantum Algorithms
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Guan%2C+J">Ji Guan</a>, 
<a href="/search/quant-ph?searchtype=author&query=Fang%2C+W">Wang Fang</a>, 
<a href="/search/quant-ph?searchtype=author&query=Huang%2C+M">Mingyu Huang</a>, 
<a href="/search/quant-ph?searchtype=author&query=Ying%2C+M">Mingsheng Ying</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> In Proceedings of the 2023 ACM SIGSAC Conference on Computer and
  Communications Security (CCS 2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Cryptography and Security (cs.CR); Machine Learning (cs.LG)

</div>
<p class="mathjax">Quantum algorithms for solving a wide range of practical problems have been
proposed in the last ten years, such as data search and analysis, product
recommendation, and credit scoring. The concern about privacy and other ethical
issues in quantum computing naturally rises up. In this paper, we define a
formal framework for detecting violations of differential privacy for quantum
algorithms. A detection algorithm is developed to verify whether a (noisy)
quantum algorithm is differentially private and automatically generate bugging
information when the violation of differential privacy is reported. The
information consists of a pair of quantum states that violate the privacy, to
illustrate the cause of the violation. Our algorithm is equipped with Tensor
Networks, a highly efficient data structure, and executed both on TensorFlow
Quantum and TorchQuantum which are the quantum extensions of famous machine
learning platforms -- TensorFlow and PyTorch, respectively. The effectiveness
and efficiency of our algorithm are confirmed by the experimental results of
almost all types of quantum algorithms already implemented on realistic quantum
computers, including quantum supremacy algorithms (beyond the capability of
classical algorithms), quantum machine learning models, quantum approximate
optimization algorithms, and variational quantum eigensolvers with up to 21
quantum bits.
</p>
</div>
</dd>
<dt><a name="item511">[511]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.04831" title="Abstract">arXiv:2309.04831</a> (cross-list from math.OC) [<a href="/pdf/2309.04831" title="Download PDF">pdf</a>, <a href="/format/2309.04831" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Global Convergence of Receding-Horizon Policy Search in Learning  Estimator Designs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Zhang%2C+X">Xiangyuan Zhang</a>, 
<a href="/search/math?searchtype=author&query=Mowlavi%2C+S">Saviz Mowlavi</a>, 
<a href="/search/math?searchtype=author&query=Benosman%2C+M">Mouhacine Benosman</a>, 
<a href="/search/math?searchtype=author&query=Ba%C5%9Far%2C+T">Tamer Ba&#x15f;ar</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: text overlap with <a href="/abs/2301.12624">arXiv:2301.12624</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Systems and Control (eess.SY); Dynamical Systems (math.DS)

</div>
<p class="mathjax">We introduce the receding-horizon policy gradient (RHPG) algorithm, the first
PG algorithm with provable global convergence in learning the optimal linear
estimator designs, i.e., the Kalman filter (KF). Notably, the RHPG algorithm
does not require any prior knowledge of the system for initialization and does
not require the target system to be open-loop stable. The key of RHPG is that
we integrate vanilla PG (or any other policy search directions) into a dynamic
programming outer loop, which iteratively decomposes the infinite-horizon KF
problem that is constrained and non-convex in the policy parameter into a
sequence of static estimation problems that are unconstrained and
strongly-convex, thus enabling global convergence. We further provide
fine-grained analyses of the optimization landscape under RHPG and detail the
convergence and sample complexity guarantees of the algorithm. This work serves
as an initial attempt to develop reinforcement learning algorithms specifically
for control applications with performance guarantees by utilizing classic
control theory in both algorithmic design and theoretical analyses. Lastly, we
validate our theories by deploying the RHPG algorithm to learn the Kalman
filter design of a large-scale convection-diffusion model. We open-source the
code repository at \url{https://github.com/xiangyuan-zhang/LearningKF}.
</p>
</div>
</dd>
<dt><a name="item512">[512]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.04841" title="Abstract">arXiv:2309.04841</a> (cross-list from quant-ph) [<a href="/pdf/2309.04841" title="Download PDF">pdf</a>, <a href="/format/2309.04841" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fast Simulation of High-Depth QAOA Circuits
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Lykov%2C+D">Danylo Lykov</a>, 
<a href="/search/quant-ph?searchtype=author&query=Shaydulin%2C+R">Ruslan Shaydulin</a>, 
<a href="/search/quant-ph?searchtype=author&query=Sun%2C+Y">Yue Sun</a>, 
<a href="/search/quant-ph?searchtype=author&query=Alexeev%2C+Y">Yuri Alexeev</a>, 
<a href="/search/quant-ph?searchtype=author&query=Pistoia%2C+M">Marco Pistoia</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> 2023 IEEE/ACM Third International Workshop on Quantum Computing
  Software (QCS)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Distributed, Parallel, and Cluster Computing (cs.DC); Performance (cs.PF)

</div>
<p class="mathjax">Until high-fidelity quantum computers with a large number of qubits become
widely available, classical simulation remains a vital tool for algorithm
design, tuning, and validation. We present a simulator for the Quantum
Approximate Optimization Algorithm (QAOA). Our simulator is designed with the
goal of reducing the computational cost of QAOA parameter optimization and
supports both CPU and GPU execution. Our central observation is that the
computational cost of both simulating the QAOA state and computing the QAOA
objective to be optimized can be reduced by precomputing the diagonal
Hamiltonian encoding the problem. We reduce the time for a typical QAOA
parameter optimization by eleven times for $n = 26$ qubits compared to a
state-of-the-art GPU quantum circuit simulator based on cuQuantum. Our
simulator is available on GitHub: https://github.com/jpmorganchase/QOKit
</p>
</div>
</dd>
<dt><a name="item513">[513]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.04892" title="Abstract">arXiv:2309.04892</a> (cross-list from math.CO) [<a href="/pdf/2309.04892" title="Download PDF">pdf</a>, <a href="/ps/2309.04892" title="Download PostScript">ps</a>, <a href="/format/2309.04892" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Descriptive complexity of controllable graphs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Abiad%2C+A">Aida Abiad</a>, 
<a href="/search/math?searchtype=author&query=Dawar%2C+A">Anuj Dawar</a>, 
<a href="/search/math?searchtype=author&query=Zapata%2C+O">Octavio Zapata</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Combinatorics (math.CO)</span>; Logic in Computer Science (cs.LO)

</div>
<p class="mathjax">Let $G$ be a graph on $n$ vertices with adjacency matrix $A$, and let
$\mathbf{1}$ be the all-ones vector. We call $G$ controllable if the set of
vectors $\mathbf{1}, A\mathbf{1}, \dots, A^{n-1}\mathbf{1}$ spans the whole
space $\mathbb{R}^n$. We characterize the isomorphism problem of controllable
graphs in terms of other combinatorial, geometric and logical problems. We also
describe a polynomial time algorithm for graph isomorphism that works for
almost all graphs.
</p>
</div>
</dd>
<dt><a name="item514">[514]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.04901" title="Abstract">arXiv:2309.04901</a> (cross-list from eess.SP) [<a href="/pdf/2309.04901" title="Download PDF">pdf</a>, <a href="/format/2309.04901" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> One-Bit-Aided Modulo Sampling for DOA Estimation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Zhang%2C+Q">Qi Zhang</a>, 
<a href="/search/eess?searchtype=author&query=Zhu%2C+J">Jiang Zhu</a>, 
<a href="/search/eess?searchtype=author&query=Xu%2C+Z">Zhiwei Xu</a>, 
<a href="/search/eess?searchtype=author&query=Soh%2C+D+W">De Wen Soh</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Information Theory (cs.IT)

</div>
<p class="mathjax">Modulo sampling or unlimited sampling has recently drawn a great deal of
attention for cutting-edge applications, due to overcoming the barrier of
information loss through sensor saturation and clipping. This is a significant
problem, especially when the range of signal amplitudes is unknown or in the
near-far case. To overcome this fundamental bottleneck, we propose a
one-bit-aided (1bit-aided) modulo sampling scheme for direction-of-arrival
(DOA) estimation. On the one hand, one-bit quantization involving a simple
comparator offers the advantages of low-cost and low-complexity implementation.
On the other hand, one-bit quantization provides an estimate of the normalized
covariance matrix of the unquantized measurements via the arcsin law. The
estimate of the normalized covariance matrix is used to implement blind
integer-forcing (BIF) decoder to unwrap the modulo samples to construct the
covariance matrix, and subspace methods can be used to perform the DOA
estimation. Our approach named as 1bit-aided-BIF addresses the near-far problem
well and overcomes the intrinsic low dynamic range of one-bit quantization.
Numerical experiments validate the excellent performance of the proposed
algorithm compared to using a high-precision ADC directly in the given set up.
</p>
</div>
</dd>
<dt><a name="item515">[515]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.04956" title="Abstract">arXiv:2309.04956</a> (cross-list from eess.IV) [<a href="/pdf/2309.04956" title="Download PDF">pdf</a>, <a href="/format/2309.04956" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Anatomy Completor: A Multi-class Completion Framework for 3D Anatomy  Reconstruction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Li%2C+J">Jianning Li</a>, 
<a href="/search/eess?searchtype=author&query=Pepe%2C+A">Antonio Pepe</a>, 
<a href="/search/eess?searchtype=author&query=Luijten%2C+G">Gijs Luijten</a>, 
<a href="/search/eess?searchtype=author&query=Schwarz-Gsaxner%2C+C">Christina Schwarz-Gsaxner</a>, 
<a href="/search/eess?searchtype=author&query=Kleesiek%2C+J">Jens Kleesiek</a>, 
<a href="/search/eess?searchtype=author&query=Egger%2C+J">Jan Egger</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 15 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">In this paper, we introduce a completion framework to reconstruct the
geometric shapes of various anatomies, including organs, vessels and muscles.
Our work targets a scenario where one or multiple anatomies are missing in the
imaging data due to surgical, pathological or traumatic factors, or simply
because these anatomies are not covered by image acquisition. Automatic
reconstruction of the missing anatomies benefits many applications, such as
organ 3D bio-printing, whole-body segmentation, animation realism,
paleoradiology and forensic imaging. We propose two paradigms based on a 3D
denoising auto-encoder (DAE) to solve the anatomy reconstruction problem: (i)
the DAE learns a many-to-one mapping between incomplete and complete instances;
(ii) the DAE learns directly a one-to-one residual mapping between the
incomplete instances and the target anatomies. We apply a loss aggregation
scheme that enables the DAE to learn the many-to-one mapping more effectively
and further enhances the learning of the residual mapping. On top of this, we
extend the DAE to a multiclass completor by assigning a unique label to each
anatomy involved. We evaluate our method using a CT dataset with whole-body
segmentations. Results show that our method produces reasonable anatomy
reconstructions given instances with different levels of incompleteness (i.e.,
one or multiple random anatomies are missing). Codes and pretrained models are
publicly available at https://github.com/Jianningli/medshapenet-feedback/
tree/main/anatomy-completor
</p>
</div>
</dd>
<dt><a name="item516">[516]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.04960" title="Abstract">arXiv:2309.04960</a> (cross-list from eess.IV) [<a href="/pdf/2309.04960" title="Download PDF">pdf</a>, <a href="/format/2309.04960" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SdCT-GAN: Reconstructing CT from Biplanar X-Rays with Self-driven  Generative Adversarial Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Cheng%2C+S">Shuangqin Cheng</a>, 
<a href="/search/eess?searchtype=author&query=Chen%2C+Q">Qingliang Chen</a>, 
<a href="/search/eess?searchtype=author&query=Zhang%2C+Q">Qiyi Zhang</a>, 
<a href="/search/eess?searchtype=author&query=Li%2C+M">Ming Li</a>, 
<a href="/search/eess?searchtype=author&query=Alike%2C+Y">Yamuhanmode Alike</a>, 
<a href="/search/eess?searchtype=author&query=Su%2C+K">Kaile Su</a>, 
<a href="/search/eess?searchtype=author&query=Wen%2C+P">Pengcheng Wen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Computed Tomography (CT) is a medical imaging modality that can generate more
informative 3D images than 2D X-rays. However, this advantage comes at the
expense of more radiation exposure, higher costs, and longer acquisition time.
Hence, the reconstruction of 3D CT images using a limited number of 2D X-rays
has gained significant importance as an economical alternative. Nevertheless,
existing methods primarily prioritize minimizing pixel/voxel-level intensity
discrepancies, often neglecting the preservation of textural details in the
synthesized images. This oversight directly impacts the quality of the
reconstructed images and thus affects the clinical diagnosis. To address the
deficits, this paper presents a new self-driven generative adversarial network
model (SdCT-GAN), which is motivated to pay more attention to image details by
introducing a novel auto-encoder structure in the discriminator. In addition, a
Sobel Gradient Guider (SGG) idea is applied throughout the model, where the
edge information from the 2D X-ray image at the input can be integrated.
Moreover, LPIPS (Learned Perceptual Image Patch Similarity) evaluation metric
is adopted that can quantitatively evaluate the fine contours and textures of
reconstructed images better than the existing ones. Finally, the qualitative
and quantitative results of the empirical studies justify the power of the
proposed model compared to mainstream state-of-the-art baselines.
</p>
</div>
</dd>
<dt><a name="item517">[517]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.04968" title="Abstract">arXiv:2309.04968</a> (cross-list from eess.IV) [<a href="/pdf/2309.04968" title="Download PDF">pdf</a>, <a href="/format/2309.04968" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LMBiS-Net: A Lightweight Multipath Bidirectional Skip Connection based  CNN for Retinal Blood Vessel Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Abbasi%2C+M+M">Mufassir M. Abbasi</a>, 
<a href="/search/eess?searchtype=author&query=Iqbal%2C+S">Shahzaib Iqbal</a>, 
<a href="/search/eess?searchtype=author&query=Naveed%2C+A">Asim Naveed</a>, 
<a href="/search/eess?searchtype=author&query=Khan%2C+T+M">Tariq M. Khan</a>, 
<a href="/search/eess?searchtype=author&query=Naqvi%2C+S+S">Syed S. Naqvi</a>, 
<a href="/search/eess?searchtype=author&query=Khalid%2C+W">Wajeeha Khalid</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Blinding eye diseases are often correlated with altered retinal morphology,
which can be clinically identified by segmenting retinal structures in fundus
images. However, current methodologies often fall short in accurately
segmenting delicate vessels. Although deep learning has shown promise in
medical image segmentation, its reliance on repeated convolution and pooling
operations can hinder the representation of edge information, ultimately
limiting overall segmentation accuracy. In this paper, we propose a lightweight
pixel-level CNN named LMBiS-Net for the segmentation of retinal vessels with an
exceptionally low number of learnable parameters \textbf{(only 0.172 M)}. The
network used multipath feature extraction blocks and incorporates bidirectional
skip connections for the information flow between the encoder and decoder.
Additionally, we have optimized the efficiency of the model by carefully
selecting the number of filters to avoid filter overlap. This optimization
significantly reduces training time and enhances computational efficiency. To
assess the robustness and generalizability of LMBiS-Net, we performed
comprehensive evaluations on various aspects of retinal images. Specifically,
the model was subjected to rigorous tests to accurately segment retinal
vessels, which play a vital role in ophthalmological diagnosis and treatment.
By focusing on the retinal blood vessels, we were able to thoroughly analyze
the performance and effectiveness of the LMBiS-Net model. The results of our
tests demonstrate that LMBiS-Net is not only robust and generalizable but also
capable of maintaining high levels of segmentation accuracy. These
characteristics highlight the potential of LMBiS-Net as an efficient tool for
high-speed and accurate segmentation of retinal images in various clinical
applications.
</p>
</div>
</dd>
<dt><a name="item518">[518]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.04980" title="Abstract">arXiv:2309.04980</a> (cross-list from math.OC) [<a href="/pdf/2309.04980" title="Download PDF">pdf</a>, <a href="/format/2309.04980" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Linear Speedup of Incremental Aggregated Gradient Methods on Streaming  Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Wang%2C+X">Xiaolu Wang</a>, 
<a href="/search/math?searchtype=author&query=Jin%2C+C">Cheng Jin</a>, 
<a href="/search/math?searchtype=author&query=Wai%2C+H">Hoi-To Wai</a>, 
<a href="/search/math?searchtype=author&query=Gu%2C+Y">Yuantao Gu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 3 figures
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> The 62nd IEEE Conference on Decision and Control (CDC 2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">This paper considers a type of incremental aggregated gradient (IAG) method
for large-scale distributed optimization. The IAG method is well suited for the
parameter server architecture as the latter can easily aggregate potentially
staled gradients contributed by workers. Although the convergence of IAG in the
case of deterministic gradient is well known, there are only a few results for
the case of its stochastic variant based on streaming data. Considering
strongly convex optimization, this paper shows that the streaming IAG method
achieves linear speedup when the workers are updating frequently enough, even
if the data sample distribution across workers are heterogeneous. We show that
the expected squared distance to optimal solution decays at O((1+T)/(nt)),
where $n$ is the number of workers, t is the iteration number, and T/n is the
update frequency of workers. Our analysis involves careful treatments of the
conditional expectations with staled gradients and a recursive system with both
delayed and noise terms, which are new to the analysis of IAG-type algorithms.
Numerical results are presented to verify our findings.
</p>
</div>
</dd>
<dt><a name="item519">[519]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.05027" title="Abstract">arXiv:2309.05027</a> (cross-list from eess.AS) [<a href="/pdf/2309.05027" title="Download PDF">pdf</a>, <a href="/format/2309.05027" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> VoiceFlow: Efficient Text-to-Speech with Rectified Flow Matching
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Guo%2C+Y">Yiwei Guo</a>, 
<a href="/search/eess?searchtype=author&query=Du%2C+C">Chenpeng Du</a>, 
<a href="/search/eess?searchtype=author&query=Ma%2C+Z">Ziyang Ma</a>, 
<a href="/search/eess?searchtype=author&query=Chen%2C+X">Xie Chen</a>, 
<a href="/search/eess?searchtype=author&query=Yu%2C+K">Kai Yu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 4 figure, 5 pages, submitted to ICASSP 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Artificial Intelligence (cs.AI); Human-Computer Interaction (cs.HC); Sound (cs.SD)

</div>
<p class="mathjax">Although diffusion models in text-to-speech have become a popular choice due
to their strong generative ability, the intrinsic complexity of sampling from
diffusion models harms their efficiency. Alternatively, we propose VoiceFlow,
an acoustic model that utilizes a rectified flow matching algorithm to achieve
high synthesis quality with a limited number of sampling steps. VoiceFlow
formulates the process of generating mel-spectrograms into an ordinary
differential equation conditional on text inputs, whose vector field is then
estimated. The rectified flow technique then effectively straightens its
sampling trajectory for efficient synthesis. Subjective and objective
evaluations on both single and multi-speaker corpora showed the superior
synthesis quality of VoiceFlow compared to the diffusion counterpart. Ablation
studies further verified the validity of the rectified flow technique in
VoiceFlow.
</p>
</div>
</dd>
<dt><a name="item520">[520]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.05057" title="Abstract">arXiv:2309.05057</a> (cross-list from eess.AS) [<a href="/pdf/2309.05057" title="Download PDF">pdf</a>, <a href="/format/2309.05057" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Gray Jedi MVDR Post-filtering
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Grondin%2C+F">Fran&#xe7;ois Grondin</a>, 
<a href="/search/eess?searchtype=author&query=Rasc%C3%B3n%2C+C">Caleb Rasc&#xf3;n</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> \c{opyright} 2023 IEEE. Personal use of this material is permitted. Permission from IEEE must be obtained for all other uses, in any current or future media, including reprinting/republishing this material for advertising or promotional purposes, creating new collective works, for resale or redistribution to servers or lists, or reuse of any copyrighted component of this work in other works
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Sound (cs.SD)

</div>
<p class="mathjax">Spatial filters can exploit deep-learning-based speech enhancement models to
increase their reliability in scenarios with multiple speech sources scenarios.
To further improve speech quality, it is common to perform postfiltering on the
estimated target speech obtained with spatial filtering. In this work, Minimum
Variance Distortionless Response (MVDR) is employed to provide the interference
estimation, along with the estimation of the target speech, to be later used
for postfiltering. This improves the enhancement performance over a
single-input baseline in a far more significant way than by increasing the
model's complexity. Results suggest that less computing resources are required
for postfiltering when provided with both target and interference signals,
which is a step forward in developing an online speech enhancement system for
multi-speech scenarios.
</p>
</div>
</dd>
<dt><a name="item521">[521]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.05062" title="Abstract">arXiv:2309.05062</a> (cross-list from quant-ph) [<a href="/pdf/2309.05062" title="Download PDF">pdf</a>, <a href="/format/2309.05062" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Machine Learning for maximizing the memristivity of single and coupled  quantum memristors
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Hernani-Morales%2C+C">Carlos Hernani-Morales</a>, 
<a href="/search/quant-ph?searchtype=author&query=Alvarado%2C+G">Gabriel Alvarado</a>, 
<a href="/search/quant-ph?searchtype=author&query=Albarr%C3%A1n-Arriagada%2C+F">Francisco Albarr&#xe1;n-Arriagada</a>, 
<a href="/search/quant-ph?searchtype=author&query=Vives-Gilabert%2C+Y">Yolanda Vives-Gilabert</a>, 
<a href="/search/quant-ph?searchtype=author&query=Solano%2C+E">Enrique Solano</a>, 
<a href="/search/quant-ph?searchtype=author&query=Mart%C3%ADn-Guerrero%2C+J+D">Jos&#xe9; D. Mart&#xed;n-Guerrero</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">We propose machine learning (ML) methods to characterize the memristive
properties of single and coupled quantum memristors. We show that maximizing
the memristivity leads to large values in the degree of entanglement of two
quantum memristors, unveiling the close relationship between quantum
correlations and memory. Our results strengthen the possibility of using
quantum memristors as key components of neuromorphic quantum computing.
</p>
</div>
</dd>
<dt><a name="item522">[522]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.05071" title="Abstract">arXiv:2309.05071</a> (cross-list from math.AP) [<a href="/pdf/2309.05071" title="Download PDF">pdf</a>, <a href="/format/2309.05071" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Super-Resolution Surface Reconstruction from Few Low-Resolution Slices
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Zhang%2C+Y">Yiyao Zhang</a>, 
<a href="/search/math?searchtype=author&query=Chen%2C+K">Ke Chen</a>, 
<a href="/search/math?searchtype=author&query=Yang%2C+S">Shang-Hua Yang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 33 pages, 25 figures
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> AIMS Journal Inverse Problems and Imaging (IPI) 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Analysis of PDEs (math.AP)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">In many imaging applications where segmented features (e.g. blood vessels)
are further used for other numerical simulations (e.g. finite element
analysis), the obtained surfaces do not have fine resolutions suitable for the
task. Increasing the resolution of such surfaces becomes crucial. This paper
proposes a new variational model for solving this problem, based on an
Euler-Elastica-based regulariser. Further, we propose and implement two
numerical algorithms for solving the model, a projected gradient descent method
and the alternating direction method of multipliers. Numerical experiments
using real-life examples (including two from outputs of another variational
model) have been illustrated for effectiveness. The advantages of the new model
are shown through quantitative comparisons by the standard deviation of
Gaussian curvatures and mean curvatures from the viewpoint of discrete
geometry.
</p>
</div>
</dd>
<dt><a name="item523">[523]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.05092" title="Abstract">arXiv:2309.05092</a> (cross-list from stat.ME) [<a href="/pdf/2309.05092" title="Download PDF">pdf</a>, <a href="/format/2309.05092" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Adaptive conformal classification with noisy labels
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Sesia%2C+M">Matteo Sesia</a>, 
<a href="/search/stat?searchtype=author&query=Wang%2C+Y+X+R">Y. X. Rachel Wang</a>, 
<a href="/search/stat?searchtype=author&query=Tong%2C+X">Xin Tong</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 35 pages (98 pages including references and appendices)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Methodology (stat.ME)</span>; Machine Learning (cs.LG); Statistics Theory (math.ST)

</div>
<p class="mathjax">This paper develops novel conformal prediction methods for classification
tasks that can automatically adapt to random label contamination in the
calibration sample, enabling more informative prediction sets with stronger
coverage guarantees compared to state-of-the-art approaches. This is made
possible by a precise theoretical characterization of the effective coverage
inflation (or deflation) suffered by standard conformal inferences in the
presence of label contamination, which is then made actionable through new
calibration algorithms. Our solution is flexible and can leverage different
modeling assumptions about the label contamination process, while requiring no
knowledge about the data distribution or the inner workings of the
machine-learning classifier. The advantages of the proposed methods are
demonstrated through extensive simulations and an application to object
classification with the CIFAR-10H image data set.
</p>
</div>
</dd>
<dt><a name="item524">[524]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.05102" title="Abstract">arXiv:2309.05102</a> (cross-list from q-bio.NC) [<a href="/pdf/2309.05102" title="Download PDF">pdf</a>, <a href="/ps/2309.05102" title="Download PostScript">ps</a>, <a href="/format/2309.05102" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Is Learning in Biological Neural Networks based on Stochastic Gradient  Descent? An analysis using stochastic processes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-bio?searchtype=author&query=Christensen%2C+S">S&#xf6;ren Christensen</a>, 
<a href="/search/q-bio?searchtype=author&query=Kallsen%2C+J">Jan Kallsen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neurons and Cognition (q-bio.NC)</span>; Machine Learning (cs.LG); Neural and Evolutionary Computing (cs.NE); Probability (math.PR)

</div>
<p class="mathjax">In recent years, there has been an intense debate about how learning in
biological neural networks (BNNs) differs from learning in artificial neural
networks. It is often argued that the updating of connections in the brain
relies only on local information, and therefore a stochastic gradient-descent
type optimization method cannot be used. In this paper, we study a stochastic
model for supervised learning in BNNs. We show that a (continuous) gradient
step occurs approximately when each learning opportunity is processed by many
local updates. This result suggests that stochastic gradient descent may indeed
play a role in optimizing BNNs.
</p>
</div>
</dd>
<dt><a name="item525">[525]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.05105" title="Abstract">arXiv:2309.05105</a> (cross-list from math.OC) [<a href="/pdf/2309.05105" title="Download PDF">pdf</a>, <a href="/format/2309.05105" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Convex Q Learning in a Stochastic Environment: Extended Version
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Lu%2C+F">Fan Lu</a>, 
<a href="/search/math?searchtype=author&query=Meyn%2C+S">Sean Meyn</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Extended version of "Convex Q-learning in a stochastic environment", IEEE Conference on Decision and Control, 2023 (to appear)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">The paper introduces the first formulation of convex Q-learning for Markov
decision processes with function approximation. The algorithms and theory rest
on a relaxation of a dual of Manne's celebrated linear programming
characterization of optimal control. The main contributions firstly concern
properties of the relaxation, described as a deterministic convex program: we
identify conditions for a bounded solution, and a significant relationship
between the solution to the new convex program, and the solution to standard
Q-learning. The second set of contributions concern algorithm design and
analysis: (i) A direct model-free method for approximating the convex program
for Q-learning shares properties with its ideal. In particular, a bounded
solution is ensured subject to a simple property of the basis functions; (ii)
The proposed algorithms are convergent and new techniques are introduced to
obtain the rate of convergence in a mean-square sense; (iii) The approach can
be generalized to a range of performance criteria, and it is found that
variance can be reduced by considering ``relative'' dynamic programming
equations; (iv) The theory is illustrated with an application to a classical
inventory control problem.
</p>
</div>
</dd>
<dt><a name="item526">[526]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.05107" title="Abstract">arXiv:2309.05107</a> (cross-list from stat.ML) [<a href="/pdf/2309.05107" title="Download PDF">pdf</a>, <a href="/format/2309.05107" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Nonlinear Granger Causality using Kernel Ridge Regression
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Fulmyk%2C+W+%22">Wojciech &quot;Victor&quot; Fulmyk</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG); Methodology (stat.ME)

</div>
<p class="mathjax">I introduce a novel algorithm and accompanying Python library, named
mlcausality, designed for the identification of nonlinear Granger causal
relationships. This novel algorithm uses a flexible plug-in architecture that
enables researchers to employ any nonlinear regressor as the base prediction
model. Subsequently, I conduct a comprehensive performance analysis of
mlcausality when the prediction regressor is the kernel ridge regressor with
the radial basis function kernel. The results demonstrate that mlcausality
employing kernel ridge regression achieves competitive AUC scores across a
diverse set of simulated data. Furthermore, mlcausality with kernel ridge
regression yields more finely calibrated $p$-values in comparison to rival
algorithms. This enhancement enables mlcausality to attain superior accuracy
scores when using intuitive $p$-value-based thresholding criteria. Finally,
mlcausality with the kernel ridge regression exhibits significantly reduced
computation times compared to existing nonlinear Granger causality algorithms.
In fact, in numerous instances, this innovative approach achieves superior
solutions within computational timeframes that are an order of magnitude
shorter than those required by competing algorithms.
</p>
</div>
</dd>
<dt><a name="item527">[527]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.05109" title="Abstract">arXiv:2309.05109</a> (cross-list from eess.SP) [<a href="/pdf/2309.05109" title="Download PDF">pdf</a>, <a href="/format/2309.05109" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deep Learning-Aided Subspace-Based DOA Recovery for Sparse Arrays
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Amiel%2C+Y">Yoav Amiel</a>, 
<a href="/search/eess?searchtype=author&query=Shmuel%2C+D+H">Dor H. Shmuel</a>, 
<a href="/search/eess?searchtype=author&query=Shlezinger%2C+N">Nir Shlezinger</a>, 
<a href="/search/eess?searchtype=author&query=Huleihel%2C+W">Wasim Huleihel</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 4 pages, 4 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Sparse arrays enable resolving more direction of arrivals (DoAs) than antenna
elements using non-uniform arrays. This is typically achieved by reconstructing
the covariance of a virtual large uniform linear array (ULA), which is then
processed by subspace DoA estimators. However, these method assume that the
signals are non-coherent and the array is calibrated; the latter often
challenging to achieve in sparse arrays, where one cannot access the virtual
array elements. In this work, we propose Sparse-SubspaceNet, which leverages
deep learning to enable subspace-based DoA recovery from sparse miscallibrated
arrays with coherent sources. Sparse- SubspaceNet utilizes a dedicated deep
network to learn from data how to compute a surrogate virtual array covariance
that is divisible into distinguishable subspaces. By doing so, we learn to cope
with coherent sources and miscalibrated sparse arrays, while preserving the
interpretability and the suitability of model-based subspace DoA estimators.
</p>
</div>
</dd>
<dt><a name="item528">[528]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.05119" title="Abstract">arXiv:2309.05119</a> (cross-list from math.AP) [<a href="/pdf/2309.05119" title="Download PDF">pdf</a>, <a href="/ps/2309.05119" title="Download PostScript">ps</a>, <a href="/format/2309.05119" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Reaction-diffusion systems derived from kinetic models for Multiple  Sclerosis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Travaglini%2C+R">Romina Travaglini</a>, 
<a href="/search/math?searchtype=author&query=Oliveira%2C+J+M">Jo&#xe3;o Miguel Oliveira</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Analysis of PDEs (math.AP)</span>; Systems and Control (eess.SY)

</div>
<p class="mathjax">We present a mathematical study for the development of Multiple Sclerosis in
which a spatio-temporal kinetic model describes, at mesoscopic level, the
dynamics of a high number of interacting agents. We consider both interactions
among different populations of human cells and motion of immune cells,
stimulated by cytokines. Moreover, we reproduce the consumption of myelin
sheath due to anomalously activated lymphocytes and its restoration by
oligodendrocytes. Successively, we fix a small time parameter and assume that
the considered processes occur at different scales. This allows to perform a
formal limit, obtaining macroscopic reaction-diffusion equations for the number
densities with a chemotaxis term. A natural step is then to study the system,
inquiring about the formation of spatial patterns through a Turing instability
analysis of the problem and basing the discussion on microscopic parameters of
the model. In particular, we get spatial patterns oscillating in time that may
reproduce brain lesions characteristic of different phases of the pathology.
</p>
</div>
</dd>
<dt><a name="item529">[529]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.05153" title="Abstract">arXiv:2309.05153</a> (cross-list from stat.ML) [<a href="/pdf/2309.05153" title="Download PDF">pdf</a>, <a href="/format/2309.05153" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning Energy-Based Models by Cooperative Diffusion Recovery  Likelihood
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Zhu%2C+Y">Yaxuan Zhu</a>, 
<a href="/search/stat?searchtype=author&query=Xie%2C+J">Jianwen Xie</a>, 
<a href="/search/stat?searchtype=author&query=Wu%2C+Y">Yingnian Wu</a>, 
<a href="/search/stat?searchtype=author&query=Gao%2C+R">Ruiqi Gao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Training energy-based models (EBMs) with maximum likelihood estimation on
high-dimensional data can be both challenging and time-consuming. As a result,
there a noticeable gap in sample quality between EBMs and other generative
frameworks like GANs and diffusion models. To close this gap, inspired by the
recent efforts of learning EBMs by maximimizing diffusion recovery likelihood
(DRL), we propose cooperative diffusion recovery likelihood (CDRL), an
effective approach to tractably learn and sample from a series of EBMs defined
on increasingly noisy versons of a dataset, paired with an initializer model
for each EBM. At each noise level, the initializer model learns to amortize the
sampling process of the EBM, and the two models are jointly estimated within a
cooperative training framework. Samples from the initializer serve as starting
points that are refined by a few sampling steps from the EBM. With the refined
samples, the EBM is optimized by maximizing recovery likelihood, while the
initializer is optimized by learning from the difference between the refined
samples and the initial samples. We develop a new noise schedule and a variance
reduction technique to further improve the sample quality. Combining these
advances, we significantly boost the FID scores compared to existing EBM
methods on CIFAR-10 and ImageNet 32x32, with a 2x speedup over DRL. In
addition, we extend our method to compositional generation and image inpainting
tasks, and showcase the compatibility of CDRL with classifier-free guidance for
conditional generation, achieving similar trade-offs between sample quality and
sample diversity as in diffusion models.
</p>
</div>
</dd>
<dt><a name="item530">[530]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.05155" title="Abstract">arXiv:2309.05155</a> (cross-list from quant-ph) [<a href="/pdf/2309.05155" title="Download PDF">pdf</a>, <a href="/ps/2309.05155" title="Download PostScript">ps</a>, <a href="/format/2309.05155" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Uncloneable Quantum Advice
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Broadbent%2C+A">Anne Broadbent</a>, 
<a href="/search/quant-ph?searchtype=author&query=Karvonen%2C+M">Martti Karvonen</a>, 
<a href="/search/quant-ph?searchtype=author&query=Lord%2C+S">S&#xe9;bastien Lord</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 58 pages, 6 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Computational Complexity (cs.CC)

</div>
<p class="mathjax">The famous no-cloning principle has been shown recently to enable a number of
uncloneable functionalities. Here we address for the first time unkeyed quantum
uncloneablity, via the study of a complexity-theoretic tool that enables a
computation, but that is natively unkeyed: quantum advice. Remarkably, this is
an application of the no-cloning principle in a context where the quantum
states of interest are not chosen by a random process. We show the
unconditional existence of promise problems admitting uncloneable quantum
advice, and the existence of languages with uncloneable advice, assuming the
feasibility of quantum copy-protecting certain functions. Along the way, we
note that state complexity classes, introduced by Rosenthal and Yuen (ITCS
2022) - which concern the computational difficulty of synthesizing sequences of
quantum states - can be naturally generalized to obtain state cloning
complexity classes. We make initial observations on these classes, notably
obtaining a result analogous to the existence of undecidable problems.
<br />Our proof technique establishes the existence of ingenerable sequences of
finite bit strings - essentially meaning that they cannot be generated by any
uniform circuit family. We then prove a generic result showing that the
difficulty of accomplishing a computational task on uniformly random inputs
implies its difficulty on any fixed, ingenerable sequence. We use this result
to derandomize quantum cryptographic games that relate to cloning, and then
incorporate a result of Kundu and Tan (arXiv 2022) to obtain uncloneable
advice. Applying this two-step process to a monogamy-of-entanglement game
yields a promise problem with uncloneable advice, and applying it to the
quantum copy-protection of pseudorandom functions with super-logarithmic output
lengths yields a language with uncloneable advice.
</p>
</div>
</dd>
<dt><a name="item531">[531]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.05188" title="Abstract">arXiv:2309.05188</a> (cross-list from quant-ph) [<a href="/pdf/2309.05188" title="Download PDF">pdf</a>, <a href="/ps/2309.05188" title="Download PostScript">ps</a>, <a href="/format/2309.05188" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Quantitative Convergence Analysis of Path Integral Representations for  Quantum Thermal Average
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Ye%2C+X">Xuda Ye</a>, 
<a href="/search/quant-ph?searchtype=author&query=Zhou%2C+Z">Zhennan Zhou</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Mathematical Physics (math-ph); Numerical Analysis (math.NA); Probability (math.PR)

</div>
<p class="mathjax">The quantum thermal average is a central topic in quantum physics and can be
represented by the path integrals. For the computational perspective, the path
integral representation (PIR) needs to be approximated in a finite-dimensional
space, and the convergence of such approximation is termed as the convergence
of the PIR. In this paper, we establish the Trotter product formula in the
trace form, which connects the quantum thermal average and the Boltzmann
distribution of a continuous loop in a rigorous way. We prove the qualitative
convergence of the standard PIR, and obtain the explicit convergence rates of
the continuous loop PIR. These results showcase various approaches to
approximate the quantum thermal average, which provide theoretical guarantee
for the path integral approaches of quantum thermal equilibrium systems, such
as the path integral molecular dynamics.
</p>
</div>
</dd>
<dt><a name="item532">[532]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.05248" title="Abstract">arXiv:2309.05248</a> (cross-list from eess.AS) [<a href="/pdf/2309.05248" title="Download PDF">pdf</a>, <a href="/format/2309.05248" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Enhancing Speaker Diarization with Large Language Models: A Contextual  Beam Search Approach
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Park%2C+T+J">Tae Jin Park</a>, 
<a href="/search/eess?searchtype=author&query=Dhawan%2C+K">Kunal Dhawan</a>, 
<a href="/search/eess?searchtype=author&query=Koluguri%2C+N">Nithin Koluguri</a>, 
<a href="/search/eess?searchtype=author&query=Balam%2C+J">Jagadeesh Balam</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 4 pages 1 reference page, ICASSP format
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Sound (cs.SD)

</div>
<p class="mathjax">Large language models (LLMs) have shown great promise for capturing
contextual information in natural language processing tasks. We propose a novel
approach to speaker diarization that incorporates the prowess of LLMs to
exploit contextual cues in human dialogues. Our method builds upon an
acoustic-based speaker diarization system by adding lexical information from an
LLM in the inference stage. We model the multi-modal decoding process
probabilistically and perform joint acoustic and lexical beam search to
incorporate cues from both modalities: audio and text. Our experiments
demonstrate that infusing lexical knowledge from the LLM into an acoustics-only
diarization system improves overall speaker-attributed word error rate
(SA-WER). The experimental results show that LLMs can provide complementary
information to acoustic models for the speaker diarization task via proposed
beam search decoding approach showing up to 39.8% relative delta-SA-WER
improvement from the baseline system. Thus, we substantiate that the proposed
technique is able to exploit contextual information that is inaccessible to
acoustics-only systems which is represented by speaker embeddings. In addition,
these findings point to the potential of using LLMs to improve speaker
diarization and other speech processing tasks by capturing semantic and
contextual cues.
</p>
</div>
</dd>
<dt><a name="item533">[533]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.05253" title="Abstract">arXiv:2309.05253</a> (cross-list from quant-ph) [<a href="/pdf/2309.05253" title="Download PDF">pdf</a>, <a href="/format/2309.05253" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A quantum tug of war between randomness and symmetries on homogeneous  spaces
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Arvind%2C+R">Rahul Arvind</a>, 
<a href="/search/quant-ph?searchtype=author&query=Bharti%2C+K">Kishor Bharti</a>, 
<a href="/search/quant-ph?searchtype=author&query=Khoo%2C+J+Y">Jun Yong Khoo</a>, 
<a href="/search/quant-ph?searchtype=author&query=Koh%2C+D+E">Dax Enshan Koh</a>, 
<a href="/search/quant-ph?searchtype=author&query=Kong%2C+J+F">Jian Feng Kong</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 + 1 pages, 3 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Cryptography and Security (cs.CR); Machine Learning (cs.LG); Mathematical Physics (math-ph)

</div>
<p class="mathjax">We explore the interplay between symmetry and randomness in quantum
information. Adopting a geometric approach, we consider states as
$H$-equivalent if related by a symmetry transformation characterized by the
group $H$. We then introduce the Haar measure on the homogeneous space
$\mathbb{U}/H$, characterizing true randomness for $H$-equivalent systems.
While this mathematical machinery is well-studied by mathematicians, it has
seen limited application in quantum information: we believe our work to be the
first instance of utilizing homogeneous spaces to characterize symmetry in
quantum information. This is followed by a discussion of approximations of true
randomness, commencing with $t$-wise independent approximations and defining
$t$-designs on $\mathbb{U}/H$ and $H$-equivalent states. Transitioning further,
we explore pseudorandomness, defining pseudorandom unitaries and states within
homogeneous spaces. Finally, as a practical demonstration of our findings, we
study the expressibility of quantum machine learning ansatze in homogeneous
spaces. Our work provides a fresh perspective on the relationship between
randomness and symmetry in the quantum world.
</p>
</div>
</dd>
<dt><a name="item534">[534]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.05260" title="Abstract">arXiv:2309.05260</a> (cross-list from eess.SP) [<a href="/pdf/2309.05260" title="Download PDF">pdf</a>, <a href="/format/2309.05260" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Generalized Graphon Process: Convergence of Graph Frequencies in  Stretched Cut Distance
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Jian%2C+X">Xingchao Jian</a>, 
<a href="/search/eess?searchtype=author&query=Ji%2C+F">Feng Ji</a>, 
<a href="/search/eess?searchtype=author&query=Tay%2C+W+P">Wee Peng Tay</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Graphons have traditionally served as limit objects for dense graph
sequences, with the cut distance serving as the metric for convergence.
However, sparse graph sequences converge to the trivial graphon under the
conventional definition of cut distance, which make this framework inadequate
for many practical applications. In this paper, we utilize the concepts of
generalized graphons and stretched cut distance to describe the convergence of
sparse graph sequences. Specifically, we consider a random graph process
generated from a generalized graphon. This random graph process converges to
the generalized graphon in stretched cut distance. We use this random graph
process to model the growing sparse graph, and prove the convergence of the
adjacency matrices' eigenvalues. We supplement our findings with experimental
validation. Our results indicate the possibility of transfer learning between
sparse graphs.
</p>
</div>
</dd>
<dt><a name="item535">[535]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.05271" title="Abstract">arXiv:2309.05271</a> (cross-list from eess.IV) [<a href="/pdf/2309.05271" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AutoFuse: Automatic Fusion Networks for Deformable Medical Image  Registration
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Meng%2C+M">Mingyuan Meng</a>, 
<a href="/search/eess?searchtype=author&query=Fulham%2C+M">Michael Fulham</a>, 
<a href="/search/eess?searchtype=author&query=Feng%2C+D">Dagan Feng</a>, 
<a href="/search/eess?searchtype=author&query=Bi%2C+L">Lei Bi</a>, 
<a href="/search/eess?searchtype=author&query=Kim%2C+J">Jinman Kim</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Under Review
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Deformable image registration aims to find a dense non-linear spatial
correspondence between a pair of images, which is a crucial step for many
medical tasks such as tumor growth monitoring and population analysis.
Recently, Deep Neural Networks (DNNs) have been widely recognized for their
ability to perform fast end-to-end registration. However, DNN-based
registration needs to explore the spatial information of each image and fuse
this information to characterize spatial correspondence. This raises an
essential question: what is the optimal fusion strategy to characterize spatial
correspondence? Existing fusion strategies (e.g., early fusion, late fusion)
were empirically designed to fuse information by manually defined prior
knowledge, which inevitably constrains the registration performance within the
limits of empirical designs. In this study, we depart from existing
empirically-designed fusion strategies and develop a data-driven fusion
strategy for deformable image registration. To achieve this, we propose an
Automatic Fusion network (AutoFuse) that provides flexibility to fuse
information at many potential locations within the network. A Fusion Gate (FG)
module is also proposed to control how to fuse information at each potential
network location based on training data. Our AutoFuse can automatically
optimize its fusion strategy during training and can be generalizable to both
unsupervised registration (without any labels) and semi-supervised registration
(with weak labels provided for partial training data). Extensive experiments on
two well-benchmarked medical registration tasks (inter- and intra-patient
registration) with eight public datasets show that our AutoFuse outperforms
state-of-the-art unsupervised and semi-supervised registration methods.
</p>
</div>
</dd>
<dt><a name="item536">[536]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.05337" title="Abstract">arXiv:2309.05337</a> (cross-list from cond-mat.dis-nn) [<a href="/pdf/2309.05337" title="Download PDF">pdf</a>, <a href="/format/2309.05337" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Stochastic Gradient Descent-like relaxation is equivalent to Glauber  dynamics in discrete optimization and inference problems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cond-mat?searchtype=author&query=Angelini%2C+M+C">Maria Chiara Angelini</a>, 
<a href="/search/cond-mat?searchtype=author&query=Cavaliere%2C+A+G">Angelo Giorgio Cavaliere</a>, 
<a href="/search/cond-mat?searchtype=author&query=Marino%2C+R">Raffaele Marino</a>, 
<a href="/search/cond-mat?searchtype=author&query=Ricci-Tersenghi%2C+F">Federico Ricci-Tersenghi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages, 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Disordered Systems and Neural Networks (cond-mat.dis-nn)</span>; Statistical Mechanics (cond-mat.stat-mech); Machine Learning (cs.LG)

</div>
<p class="mathjax">Is Stochastic Gradient Descent (SGD) substantially different from Glauber
dynamics? This is a fundamental question at the time of understanding the most
used training algorithm in the field of Machine Learning, but it received no
answer until now. Here we show that in discrete optimization and inference
problems, the dynamics of an SGD-like algorithm resemble very closely that of
Metropolis Monte Carlo with a properly chosen temperature, which depends on the
mini-batch size. This quantitative matching holds both at equilibrium and in
the out-of-equilibrium regime, despite the two algorithms having fundamental
differences (e.g.\ SGD does not satisfy detailed balance). Such equivalence
allows us to use results about performances and limits of Monte Carlo
algorithms to optimize the mini-batch size in the SGD-like algorithm and make
it efficient at recovering the signal in hard inference problems.
</p>
</div>
</dd>
<dt><a name="item537">[537]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.05343" title="Abstract">arXiv:2309.05343</a> (cross-list from eess.SP) [<a href="/pdf/2309.05343" title="Download PDF">pdf</a>, <a href="/format/2309.05343" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A DRL-based Reflection Enhancement Method for RIS-assisted  Multi-receiver Communications
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Wang%2C+W">Wei Wang</a>, 
<a href="/search/eess?searchtype=author&query=Li%2C+P">Peizheng Li</a>, 
<a href="/search/eess?searchtype=author&query=Doufexi%2C+A">Angela Doufexi</a>, 
<a href="/search/eess?searchtype=author&query=Beach%2C+M+A">Mark A Beach</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages, 6 figures. This paper has been accepted for presentation at the VTC2023-Fall
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">In reconfigurable intelligent surface (RIS)-assisted wireless communication
systems, the pointing accuracy and intensity of reflections depend crucially on
the 'profile,' representing the amplitude/phase state information of all
elements in a RIS array. The superposition of multiple single-reflection
profiles enables multi-reflection for distributed users. However, the
optimization challenges from periodic element arrangements in single-reflection
and multi-reflection profiles are understudied. The combination of periodical
single-reflection profiles leads to amplitude/phase counteractions, affecting
the performance of each reflection beam. This paper focuses on a
dual-reflection optimization scenario and investigates the far-field
performance deterioration caused by the misalignment of overlapped profiles. To
address this issue, we introduce a novel deep reinforcement learning
(DRL)-based optimization method. Comparative experiments against random and
exhaustive searches demonstrate that our proposed DRL method outperforms both
alternatives, achieving the shortest optimization time. Remarkably, our
approach achieves a 1.2 dB gain in the reflection peak gain and a broader beam
without any hardware modifications.
</p>
</div>
</dd>
<dt><a name="item538">[538]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.05361" title="Abstract">arXiv:2309.05361</a> (cross-list from physics.plasm-ph) [<a href="/pdf/2309.05361" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Feature-based Transferable Disruption Prediction for future tokamaks  using domain adaptation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Shen%2C+C">Chengshuo Shen</a>, 
<a href="/search/physics?searchtype=author&query=Zheng%2C+W">Wei Zheng</a>, 
<a href="/search/physics?searchtype=author&query=Guo%2C+B">Bihao Guo</a>, 
<a href="/search/physics?searchtype=author&query=Chen%2C+D">Dalong Chen</a>, 
<a href="/search/physics?searchtype=author&query=Ai%2C+X">Xinkun Ai</a>, 
<a href="/search/physics?searchtype=author&query=Xue%2C+F">Fengming Xue</a>, 
<a href="/search/physics?searchtype=author&query=Zhong%2C+Y">Yu Zhong</a>, 
<a href="/search/physics?searchtype=author&query=Wang%2C+N">Nengchao Wang</a>, 
<a href="/search/physics?searchtype=author&query=Shen%2C+B">Biao Shen</a>, 
<a href="/search/physics?searchtype=author&query=Xiao%2C+B">Binjia Xiao</a>, 
<a href="/search/physics?searchtype=author&query=Ding%2C+Y">Yonghua Ding</a>, 
<a href="/search/physics?searchtype=author&query=Chen%2C+Z">Zhongyong Chen</a>, 
<a href="/search/physics?searchtype=author&query=Pan%2C+Y">Yuan Pan</a>, 
<a href="/search/physics?searchtype=author&query=J-TEXT+team">J-TEXT team</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 15 pages, 9 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Plasma Physics (physics.plasm-ph)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">The high acquisition cost and the significant demand for disruptive
discharges for data-driven disruption prediction models in future tokamaks pose
an inherent contradiction in disruption prediction research. In this paper, we
demonstrated a novel approach to predict disruption in a future tokamak only
using a few discharges based on a domain adaptation algorithm called CORAL. It
is the first attempt at applying domain adaptation in the disruption prediction
task. In this paper, this disruption prediction approach aligns a few data from
the future tokamak (target domain) and a large amount of data from the existing
tokamak (source domain) to train a machine learning model in the existing
tokamak. To simulate the existing and future tokamak case, we selected J-TEXT
as the existing tokamak and EAST as the future tokamak. To simulate the lack of
disruptive data in future tokamak, we only selected 100 non-disruptive
discharges and 10 disruptive discharges from EAST as the target domain training
data. We have improved CORAL to make it more suitable for the disruption
prediction task, called supervised CORAL. Compared to the model trained by
mixing data from the two tokamaks, the supervised CORAL model can enhance the
disruption prediction performance for future tokamaks (AUC value from 0.764 to
0.890). Through interpretable analysis, we discovered that using the supervised
CORAL enables the transformation of data distribution to be more similar to
future tokamak. An assessment method for evaluating whether a model has learned
a trend of similar features is designed based on SHAP analysis. It demonstrates
that the supervised CORAL model exhibits more similarities to the model trained
on large data sizes of EAST. FTDP provides a light, interpretable, and
few-data-required way by aligning features to predict disruption using small
data sizes from the future tokamak.
</p>
</div>
</dd>
<dt><a name="item539">[539]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.05384" title="Abstract">arXiv:2309.05384</a> (cross-list from eess.AS) [<a href="/pdf/2309.05384" title="Download PDF">pdf</a>, <a href="/format/2309.05384" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards generalisable and calibrated synthetic speech detection with  self-supervised representations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Oneata%2C+D">Dan Oneata</a>, 
<a href="/search/eess?searchtype=author&query=Stan%2C+A">Adriana Stan</a>, 
<a href="/search/eess?searchtype=author&query=Pascu%2C+O">Octavian Pascu</a>, 
<a href="/search/eess?searchtype=author&query=Oneata%2C+E">Elisabeta Oneata</a>, 
<a href="/search/eess?searchtype=author&query=Cucu%2C+H">Horia Cucu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to ICASSP 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Sound (cs.SD)

</div>
<p class="mathjax">Generalisation -- the ability of a model to perform well on unseen data -- is
crucial for building reliable deep fake detectors. However, recent studies have
shown that the current audio deep fake models fall short of this desideratum.
In this paper we show that pretrained self-supervised representations followed
by a simple logistic regression classifier achieve strong generalisation
capabilities, reducing the equal error rate from 30% to 8% on the newly
introduced In-the-Wild dataset. Importantly, this approach also produces
considerably better calibrated models when compared to previous approaches.
This means that we can trust our model's predictions more and use these for
downstream tasks, such as uncertainty estimation. In particular, we show that
the entropy of the estimated probabilities provides a reliable way of rejecting
uncertain samples and further improving the accuracy.
</p>
</div>
</dd>
<dt><a name="item540">[540]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.05405" title="Abstract">arXiv:2309.05405</a> (cross-list from eess.IV) [<a href="/pdf/2309.05405" title="Download PDF">pdf</a>, <a href="/format/2309.05405" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Two-Stage Hybrid Supervision Framework for Fast, Low-resource, and  Accurate Organ and Pan-cancer Segmentation in Abdomen CT
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Liu%2C+W">Wentao Liu</a>, 
<a href="/search/eess?searchtype=author&query=Tian%2C+T">Tong Tian</a>, 
<a href="/search/eess?searchtype=author&query=Xu%2C+W">Weijin Xu</a>, 
<a href="/search/eess?searchtype=author&query=Wang%2C+L">Lemeng Wang</a>, 
<a href="/search/eess?searchtype=author&query=Li%2C+H">Haoyuan Li</a>, 
<a href="/search/eess?searchtype=author&query=Yang%2C+H">Huihua Yang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Abdominal organ and tumour segmentation has many important clinical
applications, such as organ quantification, surgical planning, and disease
diagnosis. However, manual assessment is inherently subjective with
considerable inter- and intra-expert variability. In the paper, we propose a
hybrid supervised framework, StMt, that integrates self-training and mean
teacher for the segmentation of abdominal organs and tumors using partially
labeled and unlabeled data. We introduce a two-stage segmentation pipeline and
whole-volume-based input strategy to maximize segmentation accuracy while
meeting the requirements of inference time and GPU memory usage. Experiments on
the validation set of FLARE2023 demonstrate that our method achieves excellent
segmentation performance as well as fast and low-resource model inference. Our
method achieved an average DSC score of 89.79\% and 45.55 \% for the organs and
lesions on the validation set and the average running time and area under GPU
memory-time cure are 11.25s and 9627.82MB, respectively.
</p>
</div>
</dd>
<dt><a name="item541">[541]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.05406" title="Abstract">arXiv:2309.05406</a> (cross-list from eess.IV) [<a href="/pdf/2309.05406" title="Download PDF">pdf</a>, <a href="/format/2309.05406" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Treatment-aware Diffusion Probabilistic Model for Longitudinal MRI  Generation and Diffuse Glioma Growth Prediction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Liu%2C+Q">Qinghui Liu</a>, 
<a href="/search/eess?searchtype=author&query=Fuster-Garcia%2C+E">Elies Fuster-Garcia</a>, 
<a href="/search/eess?searchtype=author&query=Hovden%2C+I+T">Ivar Thokle Hovden</a>, 
<a href="/search/eess?searchtype=author&query=Sederevicius%2C+D">Donatas Sederevicius</a>, 
<a href="/search/eess?searchtype=author&query=Skogen%2C+K">Karoline Skogen</a>, 
<a href="/search/eess?searchtype=author&query=MacIntosh%2C+B+J">Bradley J MacIntosh</a>, 
<a href="/search/eess?searchtype=author&query=Gr%C3%B8dem%2C+E">Edvard Gr&#xf8;dem</a>, 
<a href="/search/eess?searchtype=author&query=Schellhorn%2C+T">Till Schellhorn</a>, 
<a href="/search/eess?searchtype=author&query=Brandal%2C+P">Petter Brandal</a>, 
<a href="/search/eess?searchtype=author&query=Bj%C3%B8rnerud%2C+A">Atle Bj&#xf8;rnerud</a>, 
<a href="/search/eess?searchtype=author&query=Emblem%2C+K+E">Kyrre Eeg Emblem</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, 10 figures, 2 tables, 2 agls, pre-print-v1
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Diffuse gliomas are malignant brain tumors that grow widespread through the
brain. The complex interactions between neoplastic cells and normal tissue, as
well as the treatment-induced changes often encountered, make glioma tumor
growth modeling challenging. In this paper, we present a novel end-to-end
network capable of generating future tumor masks and realistic MRIs of how the
tumor will look at any future time points for different treatment plans. Our
model is built upon cutting-edge diffusion probabilistic models and
deep-segmentation neural networks. We extended a diffusion model to include
sequential multi-parametric MRI and treatment information as conditioning input
to guide the generative diffusion process. This allows us to estimate tumor
growth at any given time point. We trained the model using real-world
postoperative longitudinal MRI data with glioma tumor growth trajectories
represented as tumor segmentation maps over time. The model has demonstrated
promising performance across a range of tasks, including the generation of
high-quality synthetic MRIs with tumor masks, time-series tumor segmentations,
and uncertainty estimation. Combined with the treatment-aware generated MRIs,
the tumor growth predictions with uncertainty estimates can provide useful
information for clinical decision-making.
</p>
</div>
</dd>
<dt><a name="item542">[542]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.05413" title="Abstract">arXiv:2309.05413</a> (cross-list from nlin.AO) [<a href="/pdf/2309.05413" title="Download PDF">pdf</a>, <a href="/format/2309.05413" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning noise-induced transitions by multi-scaling reservoir computing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/nlin?searchtype=author&query=Lin%2C+Z">Zequn Lin</a>, 
<a href="/search/nlin?searchtype=author&query=Lu%2C+Z">Zhaofan Lu</a>, 
<a href="/search/nlin?searchtype=author&query=Di%2C+Z">Zengru Di</a>, 
<a href="/search/nlin?searchtype=author&query=Tang%2C+Y">Ying Tang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Adaptation and Self-Organizing Systems (nlin.AO)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Noise is usually regarded as adversarial to extract the effective dynamics
from time series, such that the conventional data-driven approaches usually aim
at learning the dynamics by mitigating the noisy effect. However, noise can
have a functional role of driving transitions between stable states underlying
many natural and engineered stochastic dynamics. To capture such stochastic
transitions from data, we find that leveraging a machine learning model,
reservoir computing as a type of recurrent neural network, can learn
noise-induced transitions. We develop a concise training protocol for tuning
hyperparameters, with a focus on a pivotal hyperparameter controlling the time
scale of the reservoir dynamics. The trained model generates accurate
statistics of transition time and the number of transitions. The approach is
applicable to a wide class of systems, including a bistable system under a
double-well potential, with either white noise or colored noise. It is also
aware of the asymmetry of the double-well potential, the rotational dynamics
caused by non-detailed balance, and transitions in multi-stable systems. For
the experimental data of protein folding, it learns the transition time between
folded states, providing a possibility of predicting transition statistics from
a small dataset. The results demonstrate the capability of machine-learning
methods in capturing noise-induced phenomena.
</p>
</div>
</dd>
<dt><a name="item543">[543]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.05423" title="Abstract">arXiv:2309.05423</a> (cross-list from eess.AS) [<a href="/pdf/2309.05423" title="Download PDF">pdf</a>, <a href="/format/2309.05423" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multi-Modal Automatic Prosody Annotation with Contrastive Pretraining of  SSWP
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Zhong%2C+J">Jinzuomu Zhong</a>, 
<a href="/search/eess?searchtype=author&query=Li%2C+Y">Yang Li</a>, 
<a href="/search/eess?searchtype=author&query=Huang%2C+H">Hui Huang</a>, 
<a href="/search/eess?searchtype=author&query=Liu%2C+J">Jie Liu</a>, 
<a href="/search/eess?searchtype=author&query=Su%2C+Z">Zhiba Su</a>, 
<a href="/search/eess?searchtype=author&query=Guo%2C+J">Jing Guo</a>, 
<a href="/search/eess?searchtype=author&query=Tang%2C+B">Benlai Tang</a>, 
<a href="/search/eess?searchtype=author&query=Zhu%2C+F">Fengjie Zhu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to ICASSP 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Sound (cs.SD)

</div>
<p class="mathjax">In the realm of expressive Text-to-Speech (TTS), explicit prosodic boundaries
significantly advance the naturalness and controllability of synthesized
speech. While human prosody annotation contributes a lot to the performance, it
is a labor-intensive and time-consuming process, often resulting in
inconsistent outcomes. Despite the availability of extensive supervised data,
the current benchmark model still faces performance setbacks. To address this
issue, a two-stage automatic annotation pipeline is novelly proposed in this
paper. Specifically, in the first stage, we propose contrastive text-speech
pretraining of Speech-Silence and Word-Punctuation (SSWP) pairs. The
pretraining procedure hammers at enhancing the prosodic space extracted from
joint text-speech space. In the second stage, we build a multi-modal prosody
annotator, which consists of pretrained encoders, a straightforward yet
effective text-speech feature fusion scheme, and a sequence classifier.
Extensive experiments conclusively demonstrate that our proposed method excels
at automatically generating prosody annotation and achieves state-of-the-art
(SOTA) performance. Furthermore, our novel model has exhibited remarkable
resilience when tested with varying amounts of data.
</p>
</div>
</dd>
<dt><a name="item544">[544]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.05446" title="Abstract">arXiv:2309.05446</a> (cross-list from eess.IV) [<a href="/pdf/2309.05446" title="Download PDF">pdf</a>, <a href="/format/2309.05446" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Localization-to-Segmentation Framework for Automatic Tumor  Segmentation in Whole-Body PET/CT Images
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Cai%2C+L">Linghan Cai</a>, 
<a href="/search/eess?searchtype=author&query=Huang%2C+J">Jianhao Huang</a>, 
<a href="/search/eess?searchtype=author&query=Zhu%2C+Z">Zihang Zhu</a>, 
<a href="/search/eess?searchtype=author&query=Lu%2C+J">Jinpeng Lu</a>, 
<a href="/search/eess?searchtype=author&query=Zhang%2C+Y">Yongbing Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages,3 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Fluorodeoxyglucose (FDG) positron emission tomography(PET) combined with
computed tomography (CT) is considered the primary solution for detecting some
cancers, such as lung cancer and melanoma. Automatic segmentation of tumors in
PET/CT images can help reduce doctors' workload, thereby improving diagnostic
quality. However, precise tumor segmentation is challenging due to the small
size of many tumors and the similarity of high-uptake normal areas to the tumor
regions. To address these issues, this paper proposes a
localization-to-segmentation framework (L2SNet) for precise tumor segmentation.
L2SNet first localizes the possible lesions in the lesion localization phase
and then uses the location cues to shape the segmentation results in the lesion
segmentation phase. To further improve the segmentation performance of L2SNet,
we design an adaptive threshold scheme that takes the segmentation results of
the two phases into consideration. The experiments with the MICCAI 2023
Automated Lesion Segmentation in Whole-Body FDG-PET/CT challenge dataset show
that our method achieved a competitive result and was ranked in the top 7
methods on the preliminary test set. Our work is available at:
https://github.com/MedCAI/L2SNet.
</p>
</div>
</dd>
<dt><a name="item545">[545]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.05455" title="Abstract">arXiv:2309.05455</a> (cross-list from eess.AS) [<a href="/pdf/2309.05455" title="Download PDF">pdf</a>, <a href="/format/2309.05455" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Diffusion-Based Co-Speech Gesture Generation Using Joint Text and Audio  Representation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Deichler%2C+A">Anna Deichler</a>, 
<a href="/search/eess?searchtype=author&query=Mehta%2C+S">Shivam Mehta</a>, 
<a href="/search/eess?searchtype=author&query=Alexanderson%2C+S">Simon Alexanderson</a>, 
<a href="/search/eess?searchtype=author&query=Beskow%2C+J">Jonas Beskow</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Human-Computer Interaction (cs.HC); Machine Learning (cs.LG); Sound (cs.SD)

</div>
<p class="mathjax">This paper describes a system developed for the GENEA (Generation and
Evaluation of Non-verbal Behaviour for Embodied Agents) Challenge 2023. Our
solution builds on an existing diffusion-based motion synthesis model. We
propose a contrastive speech and motion pretraining (CSMP) module, which learns
a joint embedding for speech and gesture with the aim to learn a semantic
coupling between these modalities. The output of the CSMP module is used as a
conditioning signal in the diffusion-based gesture synthesis model in order to
achieve semantically-aware co-speech gesture generation. Our entry achieved
highest human-likeness and highest speech appropriateness rating among the
submitted entries. This indicates that our system is a promising approach to
achieve human-like co-speech gestures in agents that carry semantic meaning.
</p>
</div>
</dd>
<dt><a name="item546">[546]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.05465" title="Abstract">arXiv:2309.05465</a> (cross-list from quant-ph) [<a href="/pdf/2309.05465" title="Download PDF">pdf</a>, <a href="/format/2309.05465" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> &quot;Toward&quot; Metal-Organic Framework Design by Quantum Computing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Dogahe%2C+K+S">Kourosh Sayar Dogahe</a>, 
<a href="/search/quant-ph?searchtype=author&query=Sarac%2C+T">Tamara Sarac</a>, 
<a href="/search/quant-ph?searchtype=author&query=De+Smedt%2C+D">Delphine De Smedt</a>, 
<a href="/search/quant-ph?searchtype=author&query=Bertels%2C+K">Koen Bertels</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> The article summarizes the study performed in the context of the Deloitte Quantum Climate Challenge in 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Materials Science (cond-mat.mtrl-sci); Computational Engineering, Finance, and Science (cs.CE); Emerging Technologies (cs.ET)

</div>
<p class="mathjax">The article summarizes the study performed in the context of the Deloitte
Quantum Climate Challenge in 2023. We present a hybrid quantum-classical method
for calculating Potential Energy Surface scans, which are essential for
designing Metal-Organic Frameworks for Direct Air Capture applications. The
primary objective of this challenge was to highlight the potential advantages
of employing quantum computing. To evaluate the performance of the model, we
conducted total energy calculations using various computing frameworks and
methods. The results demonstrate, at a small scale, the potential advantage of
quantum computing-based models. We aimed to define relevant classical computing
model references for method benchmarking. The most important benefits of using
the PISQ approach for hybrid quantum-classical computational model development
and assessment are demonstrated.
</p>
</div>
</dd>
<dt><a name="item547">[547]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.05473" title="Abstract">arXiv:2309.05473</a> (cross-list from math.AG) [<a href="/pdf/2309.05473" title="Download PDF">pdf</a>, <a href="/format/2309.05473" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Machine learning the dimension of a Fano variety
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Coates%2C+T">Tom Coates</a>, 
<a href="/search/math?searchtype=author&query=Kasprzyk%2C+A+M">Alexander M. Kasprzyk</a>, 
<a href="/search/math?searchtype=author&query=Veneziale%2C+S">Sara Veneziale</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 28 pages, 5 tables, 23 figures. This version of the article has been accepted for publication, after peer review but is not the Version of Record and does not reflect post-acceptance improvements, or any corrections
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Nat Commun 14, 5526 (2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Algebraic Geometry (math.AG)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Fano varieties are basic building blocks in geometry - they are `atomic
pieces' of mathematical shapes. Recent progress in the classification of Fano
varieties involves analysing an invariant called the quantum period. This is a
sequence of integers which gives a numerical fingerprint for a Fano variety. It
is conjectured that a Fano variety is uniquely determined by its quantum
period. If this is true, one should be able to recover geometric properties of
a Fano variety directly from its quantum period. We apply machine learning to
the question: does the quantum period of X know the dimension of X? Note that
there is as yet no theoretical understanding of this. We show that a simple
feed-forward neural network can determine the dimension of X with 98% accuracy.
Building on this, we establish rigorous asymptotics for the quantum periods of
a class of Fano varieties. These asymptotics determine the dimension of X from
its quantum period. Our results demonstrate that machine learning can pick out
structure from complex mathematical data in situations where we lack
theoretical understanding. They also give positive evidence for the conjecture
that the quantum period of a Fano variety determines that variety.
</p>
</div>
</dd>
<dt><a name="item548">[548]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.05614" title="Abstract">arXiv:2309.05614</a> (cross-list from physics.soc-ph) [<a href="/pdf/2309.05614" title="Download PDF">pdf</a>, <a href="/format/2309.05614" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Detecting communities via edge Random Walk Centrality
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Jain%2C+A">Ashwat Jain</a>, 
<a href="/search/physics?searchtype=author&query=Manimaran%2C+P">P. Manimaran</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 8 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Physics and Society (physics.soc-ph)</span>; Social and Information Networks (cs.SI)

</div>
<p class="mathjax">Herein we present a novel approach of identifying community structures in
complex networks. We propose the usage of the Random Walk Centrality (RWC),
first introduced by Noh and Rieger [Phys. Rev. Lett. 92.11 (2004): 118701]. We
adapt this node centrality metric to an edge centrality metric by applying it
to the line graph of a given network. A crucial feature of our algorithm is the
needlessness of recalculating the centrality metric after each step, in
contrast to most community detection algorithms. We test our algorithm on a
wide variety of standard networks, and compare them with pre-existing
algorithms. As a predictive application, we analyze the Indian Railway network
for robustness and connectedness, and propose edges which would make the system
even sturdier.
</p>
</div>
</dd>
<dt><a name="item549">[549]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.05630" title="Abstract">arXiv:2309.05630</a> (cross-list from stat.ML) [<a href="/pdf/2309.05630" title="Download PDF">pdf</a>, <a href="/format/2309.05630" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Boundary Peeling: Outlier Detection Method Using One-Class Peeling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Arafat%2C+S">Sheikh Arafat</a>, 
<a href="/search/stat?searchtype=author&query=Sun%2C+N">Na Sun</a>, 
<a href="/search/stat?searchtype=author&query=Weese%2C+M+L">Maria L. Weese</a>, 
<a href="/search/stat?searchtype=author&query=Martinez%2C+W+G">Waldyn G. Martinez</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG); Methodology (stat.ME)

</div>
<p class="mathjax">Unsupervised outlier detection constitutes a crucial phase within data
analysis and remains a dynamic realm of research. A good outlier detection
algorithm should be computationally efficient, robust to tuning parameter
selection, and perform consistently well across diverse underlying data
distributions. We introduce One-Class Boundary Peeling, an unsupervised outlier
detection algorithm. One-class Boundary Peeling uses the average signed
distance from iteratively-peeled, flexible boundaries generated by one-class
support vector machines. One-class Boundary Peeling has robust hyperparameter
settings and, for increased flexibility, can be cast as an ensemble method. In
synthetic data simulations One-Class Boundary Peeling outperforms all state of
the art methods when no outliers are present while maintaining comparable or
superior performance in the presence of outliers, as compared to benchmark
methods. One-Class Boundary Peeling performs competitively in terms of correct
classification, AUC, and processing time using common benchmark data sets.
</p>
</div>
</dd>
<dt><a name="item550">[550]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.05657" title="Abstract">arXiv:2309.05657</a> (cross-list from stat.ML) [<a href="/pdf/2309.05657" title="Download PDF">pdf</a>, <a href="/format/2309.05657" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the quality of randomized approximations of Tukey&#x27;s depth
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Briend%2C+S">Simon Briend</a>, 
<a href="/search/stat?searchtype=author&query=Lugosi%2C+G">G&#xe1;bor Lugosi</a>, 
<a href="/search/stat?searchtype=author&query=Oliveira%2C+R+I">Roberto Imbuzeiro Oliveira</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG); Probability (math.PR)

</div>
<p class="mathjax">Tukey's depth (or halfspace depth) is a widely used measure of centrality for
multivariate data. However, exact computation of Tukey's depth is known to be a
hard problem in high dimensions. As a remedy, randomized approximations of
Tukey's depth have been proposed. In this paper we explore when such randomized
algorithms return a good approximation of Tukey's depth. We study the case when
the data are sampled from a log-concave isotropic distribution. We prove that,
if one requires that the algorithm runs in polynomial time in the dimension,
the randomized algorithm correctly approximates the maximal depth $1/2$ and
depths close to zero. On the other hand, for any point of intermediate depth,
any good approximation requires exponential complexity.
</p>
</div>
</dd>
</dl>
<h3>Replacements for Tue, 12 Sep 23</h3>
<dl>
<dt><a name="item551">[551]</a>&nbsp;  <span class="list-identifier"><a href="/abs/1510.07888" title="Abstract">arXiv:1510.07888</a> (replaced) [<a href="/pdf/1510.07888" title="Download PDF">pdf</a>, <a href="/format/1510.07888" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exchanging Goods Using Valuable Money
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-fin?searchtype=author&query=Howard%2C+J+V">J. V. Howard</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 26 pages, 10 figures, revised twice
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">General Economics (econ.GN)</span>; Computer Science and Game Theory (cs.GT)

</div>
</div>
</dd>
<dt><a name="item552">[552]</a>&nbsp;  <span class="list-identifier"><a href="/abs/1805.10766" title="Abstract">arXiv:1805.10766</a> (replaced) [<a href="/pdf/1805.10766" title="Download PDF">pdf</a>, <a href="/format/1805.10766" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Improving the Resolution of CNN Feature Maps Efficiently with  Multisampling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sadigh%2C+S">Shayan Sadigh</a>, 
<a href="/search/cs?searchtype=author&query=Sen%2C+P">Pradeep Sen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Preprint
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item553">[553]</a>&nbsp;  <span class="list-identifier"><a href="/abs/1902.02400" title="Abstract">arXiv:1902.02400</a> (replaced) [<a href="/pdf/1902.02400" title="Download PDF">pdf</a>, <a href="/format/1902.02400" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Weak Galerkin finite element method for second order problems on  curvilinear polytopal meshes with Lipschitz continuous edges or faces
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Guan%2C+Q">Qingguang Guan</a>, 
<a href="/search/math?searchtype=author&query=Queisser%2C+G">Gillian Queisser</a>, 
<a href="/search/math?searchtype=author&query=Zhao%2C+W">Wenju Zhao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
</div>
</dd>
<dt><a name="item554">[554]</a>&nbsp;  <span class="list-identifier"><a href="/abs/1907.04776" title="Abstract">arXiv:1907.04776</a> (replaced) [<a href="/pdf/1907.04776" title="Download PDF">pdf</a>, <a href="/ps/1907.04776" title="Download PostScript">ps</a>, <a href="/format/1907.04776" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The EL Theorem
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Epstein%2C+S">Samuel Epstein</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Complexity (cs.CC)</span>; Logic (math.LO)

</div>
</div>
</dd>
<dt><a name="item555">[555]</a>&nbsp;  <span class="list-identifier"><a href="/abs/1910.10294" title="Abstract">arXiv:1910.10294</a> (replaced) [<a href="/e-print/1910.10294" title="Download source">src</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Unifying Framework of Bilinear LSTMs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rajpal%2C+M">Mohit Rajpal</a>, 
<a href="/search/cs?searchtype=author&query=Low%2C+B+K+H">Bryan Kian Hsiang Low</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> paper abandoned and will never be submitted for peer review
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computation and Language (cs.CL); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item556">[556]</a>&nbsp;  <span class="list-identifier"><a href="/abs/1912.10298" title="Abstract">arXiv:1912.10298</a> (replaced) [<a href="/e-print/1912.10298" title="Download source">src</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Content Addressed P2P File System for the Web with Blockchain-Based  Meta-Data Integrity
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rahalkar%2C+C">Chaitanya Rahalkar</a>, 
<a href="/search/cs?searchtype=author&query=Gujar%2C+D">Dhaval Gujar</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Inaccuracies and inconsistencies in paper
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>; Cryptography and Security (cs.CR)

</div>
</div>
</dd>
<dt><a name="item557">[557]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2003.00835" title="Abstract">arXiv:2003.00835</a> (replaced) [<a href="/e-print/2003.00835" title="Download source">src</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deep Variational Luenberger-type Observer for Stochastic Video  Prediction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+D">Dong Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+F">Feng Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+Z">Zheng Yan</a>, 
<a href="/search/cs?searchtype=author&query=Yao%2C+G">Guang Yao</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zongxuan Liu</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+W">Wennan Ma</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+C">Cewu Lu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> rewrite paper
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item558">[558]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2005.12522" title="Abstract">arXiv:2005.12522</a> (replaced) [<a href="/pdf/2005.12522" title="Download PDF">pdf</a>, <a href="/format/2005.12522" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> What Are People Asking About COVID-19? A Question Classification Dataset
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wei%2C+J">Jerry Wei</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+C">Chengyu Huang</a>, 
<a href="/search/cs?searchtype=author&query=Vosoughi%2C+S">Soroush Vosoughi</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+J">Jason Wei</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Published in Proceedings of the 1st Workshop on NLP for COVID-19 at ACL 2020
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item559">[559]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2006.03051" title="Abstract">arXiv:2006.03051</a> (replaced) [<a href="/pdf/2006.03051" title="Download PDF">pdf</a>, <a href="/format/2006.03051" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> NewB: 200,000+ Sentences for Political Bias Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wei%2C+J">Jerry Wei</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item560">[560]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2007.15386" title="Abstract">arXiv:2007.15386</a> (replaced) [<a href="/pdf/2007.15386" title="Download PDF">pdf</a>, <a href="/format/2007.15386" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ResNet After All? Neural ODEs and Their Numerical Solution
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ott%2C+K">Katharina Ott</a>, 
<a href="/search/cs?searchtype=author&query=Katiyar%2C+P">Prateek Katiyar</a>, 
<a href="/search/cs?searchtype=author&query=Hennig%2C+P">Philipp Hennig</a>, 
<a href="/search/cs?searchtype=author&query=Tiemann%2C+M">Michael Tiemann</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item561">[561]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2008.06896" title="Abstract">arXiv:2008.06896</a> (replaced) [<a href="/pdf/2008.06896" title="Download PDF">pdf</a>, <a href="/format/2008.06896" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Adaptive Shape Servoing of Elastic Rods using Parameterized Regression  Features and Auto-Tuning Motion Controls
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Qi%2C+J">Jiaming Qi</a>, 
<a href="/search/cs?searchtype=author&query=Ran%2C+G">Guangtao Ran</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+B">Bohui Wang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jian Liu</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+W">Wanyu Ma</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+P">Peng Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Navarro-Alarcon%2C+D">David Navarro-Alarcon</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 12 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Systems and Control (eess.SY)

</div>
</div>
</dd>
<dt><a name="item562">[562]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2010.15525" title="Abstract">arXiv:2010.15525</a> (replaced) [<a href="/pdf/2010.15525" title="Download PDF">pdf</a>, <a href="/format/2010.15525" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Self-Learning Threshold-Based Load Balancing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Goldsztajn%2C+D">Diego Goldsztajn</a>, 
<a href="/search/cs?searchtype=author&query=Borst%2C+S+C">Sem C. Borst</a>, 
<a href="/search/cs?searchtype=author&query=van+Leeuwaarden%2C+J+S+H">Johan S. H. van Leeuwaarden</a>, 
<a href="/search/cs?searchtype=author&query=Mukherjee%2C+D">Debankur Mukherjee</a>, 
<a href="/search/cs?searchtype=author&query=Whiting%2C+P+A">Philip A. Whiting</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 52 pages, 6 figures
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> INFORMS Journal on Computing, 34(1):39-54, 2022
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Performance (cs.PF)</span>; Probability (math.PR)

</div>
</div>
</dd>
<dt><a name="item563">[563]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2101.04248" title="Abstract">arXiv:2101.04248</a> (replaced) [<a href="/pdf/2101.04248" title="Download PDF">pdf</a>, <a href="/format/2101.04248" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Photo2CAD: Automated 3D solid reconstruction from 2D drawings using  OpenCV
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Harish%2C+A+B">Ajay B. Harish</a>, 
<a href="/search/cs?searchtype=author&query=Prasad%2C+A+R">Abhishek Rajendra Prasad</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Geometry (cs.CG)</span>; General Topology (math.GN)

</div>
</div>
</dd>
<dt><a name="item564">[564]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2103.07155" title="Abstract">arXiv:2103.07155</a> (replaced) [<a href="/pdf/2103.07155" title="Download PDF">pdf</a>, <a href="/format/2103.07155" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Explainable AI by BAPC -- Before and After correction Parameter  Comparison
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Sobieczky%2C+F">Florian Sobieczky</a>, 
<a href="/search/stat?searchtype=author&query=Gei%C3%9F%2C+M">Manuela Gei&#xdf;</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item565">[565]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2103.15292" title="Abstract">arXiv:2103.15292</a> (replaced) [<a href="/pdf/2103.15292" title="Download PDF">pdf</a>, <a href="/format/2103.15292" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deriving Laws for Developing Concurrent Programs in a Rely-Guarantee  Style
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hayes%2C+I+J">Ian J. Hayes</a>, 
<a href="/search/cs?searchtype=author&query=Meinicke%2C+L+A">Larissa A. Meinicke</a>, 
<a href="/search/cs?searchtype=author&query=Meiring%2C+P+A">Patrick A. Meiring</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>

</div>
</div>
</dd>
<dt><a name="item566">[566]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2105.10190" title="Abstract">arXiv:2105.10190</a> (replaced) [<a href="/pdf/2105.10190" title="Download PDF">pdf</a>, <a href="/format/2105.10190" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AngularGrad: A New Optimization Technique for Angular Convergence of  Convolutional Neural Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Roy%2C+S+K">S.K. Roy</a>, 
<a href="/search/cs?searchtype=author&query=Paoletti%2C+M+E">M.E. Paoletti</a>, 
<a href="/search/cs?searchtype=author&query=Haut%2C+J+M">J.M. Haut</a>, 
<a href="/search/cs?searchtype=author&query=Dubey%2C+S+R">S.R. Dubey</a>, 
<a href="/search/cs?searchtype=author&query=Kar%2C+P">P. Kar</a>, 
<a href="/search/cs?searchtype=author&query=Plaza%2C+A">A. Plaza</a>, 
<a href="/search/cs?searchtype=author&query=Chaudhuri%2C+B+B">B.B. Chaudhuri</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Neural and Evolutionary Computing (cs.NE); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item567">[567]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2107.04553" title="Abstract">arXiv:2107.04553</a> (replaced) [<a href="/pdf/2107.04553" title="Download PDF">pdf</a>, <a href="/format/2107.04553" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Can Deep Neural Networks Predict Data Correlations from Column Names?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Trummer%2C+I">Immanuel Trummer</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Databases (cs.DB)</span>; Computation and Language (cs.CL)

</div>
</div>
</dd>
<dt><a name="item568">[568]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2107.08195" title="Abstract">arXiv:2107.08195</a> (replaced) [<a href="/pdf/2107.08195" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Complexity-Optimized Sparse Bayesian Learning for Scalable  Classification Tasks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Luo%2C+J">Jiahua Luo</a>, 
<a href="/search/cs?searchtype=author&query=Wong%2C+C">Chi-Man Wong</a>, 
<a href="/search/cs?searchtype=author&query=Vong%2C+C">Chi-Man Vong</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages,5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item569">[569]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2108.00925" title="Abstract">arXiv:2108.00925</a> (replaced) [<a href="/pdf/2108.00925" title="Download PDF">pdf</a>, <a href="/format/2108.00925" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Control Design of Dynamic Virtual Power Plants: An Adaptive  Divide-and-Conquer Approach
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=H%C3%A4berle%2C+V">Verena H&#xe4;berle</a>, 
<a href="/search/eess?searchtype=author&query=Fisher%2C+M+W">Michael W. Fisher</a>, 
<a href="/search/eess?searchtype=author&query=Prieto-Araujo%2C+E">Eduardo Prieto-Araujo</a>, 
<a href="/search/eess?searchtype=author&query=D%C3%B6rfler%2C+F">Florian D&#xf6;rfler</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, 16 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
</div>
</dd>
<dt><a name="item570">[570]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2108.07746" title="Abstract">arXiv:2108.07746</a> (replaced) [<a href="/pdf/2108.07746" title="Download PDF">pdf</a>, <a href="/ps/2108.07746" title="Download PostScript">ps</a>, <a href="/format/2108.07746" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> K&#xe4;hler information manifolds of signal processing filters in weighted  Hardy spaces
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Choi%2C+J">Jaehyung Choi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 22 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Differential Geometry (math.DG)

</div>
</div>
</dd>
<dt><a name="item571">[571]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2108.11635" title="Abstract">arXiv:2108.11635</a> (replaced) [<a href="/pdf/2108.11635" title="Download PDF">pdf</a>, <a href="/format/2108.11635" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MCML: A Novel Memory-based Contrastive Meta-Learning Method for Few Shot  Slot Tagging
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Hongru Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zezhong Wang</a>, 
<a href="/search/cs?searchtype=author&query=Kwan%2C+W+C">Wai Chung Kwan</a>, 
<a href="/search/cs?searchtype=author&query=Wong%2C+K">Kam-Fai Wong</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
</div>
</dd>
<dt><a name="item572">[572]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2110.00269" title="Abstract">arXiv:2110.00269</a> (replaced) [<a href="/pdf/2110.00269" title="Download PDF">pdf</a>, <a href="/format/2110.00269" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Survey of Knowledge Enhanced Pre-trained Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+J">Jian Yang</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+X">Xinyu Hu</a>, 
<a href="/search/cs?searchtype=author&query=Xiao%2C+G">Gang Xiao</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+Y">Yulong Shen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 32 pages, 15 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item573">[573]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2110.04149" title="Abstract">arXiv:2110.04149</a> (replaced) [<a href="/pdf/2110.04149" title="Download PDF">pdf</a>, <a href="/format/2110.04149" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> KPop Fandoms drive COVID-19 Public Health Messaging on Social Media
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chang%2C+H+H">Ho-Chun Herbert Chang</a>, 
<a href="/search/cs?searchtype=author&query=Pham%2C+B">Becky Pham</a>, 
<a href="/search/cs?searchtype=author&query=Ferrara%2C+E">Emilio Ferrara</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 2 figures, 2 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>; Computers and Society (cs.CY)

</div>
</div>
</dd>
<dt><a name="item574">[574]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2110.04763" title="Abstract">arXiv:2110.04763</a> (replaced) [<a href="/pdf/2110.04763" title="Download PDF">pdf</a>, <a href="/ps/2110.04763" title="Download PostScript">ps</a>, <a href="/format/2110.04763" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fat-Shattering Dimension of $k$-fold Aggregations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Attias%2C+I">Idan Attias</a>, 
<a href="/search/math?searchtype=author&query=Kontorovich%2C+A">Aryeh Kontorovich</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Functional Analysis (math.FA)</span>; Machine Learning (cs.LG); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item575">[575]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2110.05351" title="Abstract">arXiv:2110.05351</a> (replaced) [<a href="/pdf/2110.05351" title="Download PDF">pdf</a>, <a href="/format/2110.05351" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Sparse recovery of elliptic solvers from matrix-vector products
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Sch%C3%A4fer%2C+F">Florian Sch&#xe4;fer</a>, 
<a href="/search/math?searchtype=author&query=Owhadi%2C+H">Houman Owhadi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
</div>
</dd>
<dt><a name="item576">[576]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2110.06081" title="Abstract">arXiv:2110.06081</a> (replaced) [<a href="/pdf/2110.06081" title="Download PDF">pdf</a>, <a href="/format/2110.06081" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On Expressivity and Trainability of Quadratic Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fan%2C+F">Feng-Lei Fan</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+M">Mengzhou Li</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+F">Fei Wang</a>, 
<a href="/search/cs?searchtype=author&query=Lai%2C+R">Rongjie Lai</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+G">Ge Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV); Neural and Evolutionary Computing (cs.NE)

</div>
</div>
</dd>
<dt><a name="item577">[577]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2111.05114" title="Abstract">arXiv:2111.05114</a> (replaced) [<a href="/pdf/2111.05114" title="Download PDF">pdf</a>, <a href="/format/2111.05114" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Attack time analysis in dynamic attack trees via integer linear  programming
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lopuha%C3%A4-Zwakenberg%2C+M">Milan Lopuha&#xe4;-Zwakenberg</a>, 
<a href="/search/cs?searchtype=author&query=Stoelinga%2C+M">Mari&#xeb;lle Stoelinga</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
</div>
</dd>
<dt><a name="item578">[578]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2111.10330" title="Abstract">arXiv:2111.10330</a> (replaced) [<a href="/pdf/2111.10330" title="Download PDF">pdf</a>, <a href="/ps/2111.10330" title="Download PostScript">ps</a>, <a href="/format/2111.10330" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Data-driven verification and synthesis of stochastic systems via barrier  certificates
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Salamati%2C+A">Ali Salamati</a>, 
<a href="/search/eess?searchtype=author&query=Lavaei%2C+A">Abolfazl Lavaei</a>, 
<a href="/search/eess?searchtype=author&query=Soudjani%2C+S">Sadegh Soudjani</a>, 
<a href="/search/eess?searchtype=author&query=Zamani%2C+M">Majid Zamani</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
</div>
</dd>
<dt><a name="item579">[579]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2112.00234" title="Abstract">arXiv:2112.00234</a> (replaced) [<a href="/pdf/2112.00234" title="Download PDF">pdf</a>, <a href="/format/2112.00234" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MC-Blur: A Comprehensive Benchmark for Image Deblurring
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+K">Kaihao Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+T">Tao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+W">Wenhan Luo</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+B">Boheng Chen</a>, 
<a href="/search/cs?searchtype=author&query=Ren%2C+W">Wenqi Ren</a>, 
<a href="/search/cs?searchtype=author&query=Stenger%2C+B">Bjorn Stenger</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+W">Wei Liu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Hongdong Li</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+M">Ming-Hsuan Yang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To appear in IEEE TCSVT
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item580">[580]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2112.08958" title="Abstract">arXiv:2112.08958</a> (replaced) [<a href="/pdf/2112.08958" title="Download PDF">pdf</a>, <a href="/format/2112.08958" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Utility maximizing load balancing policies
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Goldsztajn%2C+D">Diego Goldsztajn</a>, 
<a href="/search/math?searchtype=author&query=Borst%2C+S+C">Sem C. Borst</a>, 
<a href="/search/math?searchtype=author&query=van+Leeuwaarden%2C+J+S+H">Johan S.H. van Leeuwaarden</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 73 pages, 6 figures
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Stochastic systems, 13(2):211-246, 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Probability (math.PR)</span>; Performance (cs.PF)

</div>
</div>
</dd>
<dt><a name="item581">[581]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2112.09976" title="Abstract">arXiv:2112.09976</a> (replaced) [<a href="/pdf/2112.09976" title="Download PDF">pdf</a>, <a href="/format/2112.09976" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Tell me what you see: A zero-shot action recognition method based on  natural language descriptions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Estevam%2C+V">Valter Estevam</a>, 
<a href="/search/cs?searchtype=author&query=Laroca%2C+R">Rayson Laroca</a>, 
<a href="/search/cs?searchtype=author&query=Menotti%2C+D">David Menotti</a>, 
<a href="/search/cs?searchtype=author&query=Pedrini%2C+H">Helio Pedrini</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Published at Multimedia Tools and Applications
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item582">[582]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2201.00910" title="Abstract">arXiv:2201.00910</a> (replaced) [<a href="/pdf/2201.00910" title="Download PDF">pdf</a>, <a href="/ps/2201.00910" title="Download PostScript">ps</a>, <a href="/format/2201.00910" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Energy-based Proportional Fairness in Cooperative Edge Computing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Vu%2C+T+T">Thai T. Vu</a>, 
<a href="/search/cs?searchtype=author&query=Hoang%2C+D+T">Dinh Thai Hoang</a>, 
<a href="/search/cs?searchtype=author&query=Phan%2C+K+T">Khoa T. Phan</a>, 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+D+N">Diep N. Nguyen</a>, 
<a href="/search/cs?searchtype=author&query=Dutkiewicz%2C+E">Eryk Dutkiewicz</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>

</div>
</div>
</dd>
<dt><a name="item583">[583]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2201.12874" title="Abstract">arXiv:2201.12874</a> (replaced) [<a href="/pdf/2201.12874" title="Download PDF">pdf</a>, <a href="/ps/2201.12874" title="Download PostScript">ps</a>, <a href="/format/2201.12874" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Comparison of Matrix Norm Sparsification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Krauthgamer%2C+R">Robert Krauthgamer</a>, 
<a href="/search/math?searchtype=author&query=Sapir%2C+S">Shay Sapir</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Data Structures and Algorithms (cs.DS)

</div>
</div>
</dd>
<dt><a name="item584">[584]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2201.13013" title="Abstract">arXiv:2201.13013</a> (replaced) [<a href="/pdf/2201.13013" title="Download PDF">pdf</a>, <a href="/format/2201.13013" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Simple And Effective Filtering Scheme For Improving Neural Fields
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhuang%2C+Y">Yixin Zhuang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to Computational Visual Media
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item585">[585]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2202.03558" title="Abstract">arXiv:2202.03558</a> (replaced) [<a href="/pdf/2202.03558" title="Download PDF">pdf</a>, <a href="/format/2202.03558" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Attacking c-MARL More Effectively: A Data Driven Approach
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pham%2C+N+H">Nhan H. Pham</a>, 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+L+M">Lam M. Nguyen</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Jie Chen</a>, 
<a href="/search/cs?searchtype=author&query=Lam%2C+H+T">Hoang Thanh Lam</a>, 
<a href="/search/cs?searchtype=author&query=Das%2C+S">Subhro Das</a>, 
<a href="/search/cs?searchtype=author&query=Weng%2C+T">Tsui-Wei Weng</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item586">[586]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2202.05073" title="Abstract">arXiv:2202.05073</a> (replaced) [<a href="/pdf/2202.05073" title="Download PDF">pdf</a>, <a href="/ps/2202.05073" title="Download PostScript">ps</a>, <a href="/format/2202.05073" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Computer Validation of Neural Network Dynamics: A First Case Study
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Kuehn%2C+C">Christian Kuehn</a>, 
<a href="/search/math?searchtype=author&query=Queirolo%2C+E">Elena Queirolo</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Dynamical Systems (math.DS)</span>; Numerical Analysis (math.NA)

</div>
</div>
</dd>
<dt><a name="item587">[587]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2202.06997" title="Abstract">arXiv:2202.06997</a> (replaced) [<a href="/pdf/2202.06997" title="Download PDF">pdf</a>, <a href="/format/2202.06997" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Cross-Modality Neuroimage Synthesis: A Survey
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Xie%2C+G">Guoyang Xie</a>, 
<a href="/search/eess?searchtype=author&query=Wang%2C+J">Jinbao Wang</a>, 
<a href="/search/eess?searchtype=author&query=Huang%2C+Y">Yawen Huang</a>, 
<a href="/search/eess?searchtype=author&query=Lyu%2C+J">Jiayi Lyu</a>, 
<a href="/search/eess?searchtype=author&query=Zheng%2C+F">Feng Zheng</a>, 
<a href="/search/eess?searchtype=author&query=Zheng%2C+Y">Yefeng Zheng</a>, 
<a href="/search/eess?searchtype=author&query=Jin%2C+Y">Yaochu Jin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item588">[588]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2202.11562" title="Abstract">arXiv:2202.11562</a> (replaced) [<a href="/pdf/2202.11562" title="Download PDF">pdf</a>, <a href="/format/2202.11562" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Transitions in Dynamic Point Labeling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Depian%2C+T">Thomas Depian</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+G">Guangping Li</a>, 
<a href="/search/cs?searchtype=author&query=N%C3%B6llenburg%2C+M">Martin N&#xf6;llenburg</a>, 
<a href="/search/cs?searchtype=author&query=Wulms%2C+J">Jules Wulms</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Geometry (cs.CG)</span>; Computational Complexity (cs.CC)

</div>
</div>
</dd>
<dt><a name="item589">[589]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2202.11885" title="Abstract">arXiv:2202.11885</a> (replaced) [<a href="/e-print/2202.11885" title="Download source">src</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Partition-and-Merge Algorithm for Solving the Steiner Tree Problem in  Large Graphs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+X">Xinyu Wu</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Y">Yi Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Hao%2C+J">Jin-Kao Hao</a>, 
<a href="/search/cs?searchtype=author&query=Fu%2C+Z">Zhang-Hua Fu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> The problem and techniques of our paper have been studied long ago, so it is currently meaningless. Therefore, we are preparing to withdraw the manuscript
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>

</div>
</div>
</dd>
<dt><a name="item590">[590]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2203.03234" title="Abstract">arXiv:2203.03234</a> (replaced) [<a href="/pdf/2203.03234" title="Download PDF">pdf</a>, <a href="/format/2203.03234" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A deep branching solver for fully nonlinear partial differential  equations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Nguwi%2C+J+Y">Jiang Yu Nguwi</a>, 
<a href="/search/math?searchtype=author&query=Penent%2C+G">Guillaume Penent</a>, 
<a href="/search/math?searchtype=author&query=Privault%2C+N">Nicolas Privault</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Machine Learning (cs.LG); Analysis of PDEs (math.AP); Probability (math.PR)

</div>
</div>
</dd>
<dt><a name="item591">[591]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2203.04802" title="Abstract">arXiv:2203.04802</a> (replaced) [<a href="/pdf/2203.04802" title="Download PDF">pdf</a>, <a href="/format/2203.04802" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> NeRF-Pose: A First-Reconstruct-Then-Regress Approach for  Weakly-supervised 6D Object Pose Estimation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+F">Fu Li</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+H">Hao Yu</a>, 
<a href="/search/cs?searchtype=author&query=Shugurov%2C+I">Ivan Shugurov</a>, 
<a href="/search/cs?searchtype=author&query=Busam%2C+B">Benjamin Busam</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+S">Shaowu Yang</a>, 
<a href="/search/cs?searchtype=author&query=Ilic%2C+S">Slobodan Ilic</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item592">[592]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2203.13278" title="Abstract">arXiv:2203.13278</a> (replaced) [<a href="/pdf/2203.13278" title="Download PDF">pdf</a>, <a href="/format/2203.13278" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Practical Blind Image Denoising via Swin-Conv-UNet and Data Synthesis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+K">Kai Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yawei Li</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+J">Jingyun Liang</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+J">Jiezhang Cao</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yulun Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+H">Hao Tang</a>, 
<a href="/search/cs?searchtype=author&query=Fan%2C+D">Deng-Ping Fan</a>, 
<a href="/search/cs?searchtype=author&query=Timofte%2C+R">Radu Timofte</a>, 
<a href="/search/cs?searchtype=author&query=Van+Gool%2C+L">Luc Van Gool</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Codes: <a href="https://github.com/cszn/SCUNet">this https URL</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Machine Intelligence Research, 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Graphics (cs.GR); Image and Video Processing (eess.IV)

</div>
</div>
</dd>
<dt><a name="item593">[593]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2203.14432" title="Abstract">arXiv:2203.14432</a> (replaced) [<a href="/pdf/2203.14432" title="Download PDF">pdf</a>, <a href="/format/2203.14432" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Encoding trade-offs and design toolkits in quantum algorithms for  discrete optimization: coloring, routing, scheduling, and other problems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Sawaya%2C+N+P">Nicolas PD Sawaya</a>, 
<a href="/search/quant-ph?searchtype=author&query=Schmitz%2C+A+T">Albert T Schmitz</a>, 
<a href="/search/quant-ph?searchtype=author&query=Hadfield%2C+S">Stuart Hadfield</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 48 pages; 11 figures; Accepted to Quantum Journal
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Discrete Mathematics (cs.DM)

</div>
</div>
</dd>
<dt><a name="item594">[594]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2204.02627" title="Abstract">arXiv:2204.02627</a> (replaced) [<a href="/pdf/2204.02627" title="Download PDF">pdf</a>, <a href="/ps/2204.02627" title="Download PostScript">ps</a>, <a href="/format/2204.02627" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Cluster Synchronization of Kuramoto Oscillators and the Method of  Averaging
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Kato%2C+R">Rui Kato</a>, 
<a href="/search/eess?searchtype=author&query=Ishii%2C+H">Hideaki Ishii</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
</div>
</dd>
<dt><a name="item595">[595]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2204.13304" title="Abstract">arXiv:2204.13304</a> (replaced) [<a href="/pdf/2204.13304" title="Download PDF">pdf</a>, <a href="/format/2204.13304" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Mat2Stencil: A Modular Matrix-Based DSL for Explicit and Implicit  Matrix-Free PDE Solvers on Structured Grid
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cao%2C+H">Huanqi Cao</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+S">Shizhi Tang</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+Q">Qianchao Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+B">Bowen Yu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+W">Wenguang Chen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>

</div>
</div>
</dd>
<dt><a name="item596">[596]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2205.01694" title="Abstract">arXiv:2205.01694</a> (replaced) [<a href="/pdf/2205.01694" title="Download PDF">pdf</a>, <a href="/format/2205.01694" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> End2End Multi-View Feature Matching with Differentiable Pose  Optimization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Roessle%2C+B">Barbara Roessle</a>, 
<a href="/search/cs?searchtype=author&query=Nie%C3%9Fner%2C+M">Matthias Nie&#xdf;ner</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ICCV 2023, project page: <a href="https://barbararoessle.github.io/e2e_multi_view_matching">this https URL</a> , video: <a href="https://youtu.be/uuLb6GfM9Cg">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item597">[597]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2205.07611" title="Abstract">arXiv:2205.07611</a> (replaced) [<a href="/pdf/2205.07611" title="Download PDF">pdf</a>, <a href="/format/2205.07611" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Noise-Tolerant Learning for Audio-Visual Action Recognition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Han%2C+H">Haochen Han</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+Q">Qinghua Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+M">Minnan Luo</a>, 
<a href="/search/cs?searchtype=author&query=Miao%2C+K">Kaiyao Miao</a>, 
<a href="/search/cs?searchtype=author&query=Tian%2C+F">Feng Tian</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yan Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Multimedia (cs.MM)

</div>
</div>
</dd>
<dt><a name="item598">[598]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2205.08187" title="Abstract">arXiv:2205.08187</a> (replaced) [<a href="/pdf/2205.08187" title="Download PDF">pdf</a>, <a href="/format/2205.08187" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deep neural networks with dependent weights: Gaussian Process mixture  limit, heavy tails, sparsity and compressibility
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Lee%2C+H">Hoil Lee</a>, 
<a href="/search/stat?searchtype=author&query=Ayed%2C+F">Fadhel Ayed</a>, 
<a href="/search/stat?searchtype=author&query=Jung%2C+P">Paul Jung</a>, 
<a href="/search/stat?searchtype=author&query=Lee%2C+J">Juho Lee</a>, 
<a href="/search/stat?searchtype=author&query=Yang%2C+H">Hongseok Yang</a>, 
<a href="/search/stat?searchtype=author&query=Caron%2C+F">Fran&#xe7;ois Caron</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 96 pages, 15 figures, 9 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG); Probability (math.PR); Statistics Theory (math.ST)

</div>
</div>
</dd>
<dt><a name="item599">[599]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2205.15279" title="Abstract">arXiv:2205.15279</a> (replaced) [<a href="/pdf/2205.15279" title="Download PDF">pdf</a>, <a href="/format/2205.15279" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The openESEA Modelling Language for Ethical, Social and Environmental  Accounting: Technical Report
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ramautar%2C+V">Vijanti Ramautar</a>, 
<a href="/search/cs?searchtype=author&query=Espa%C3%B1a%2C+S">Sergio Espa&#xf1;a</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Other Computer Science (cs.OH)</span>

</div>
</div>
</dd>
<dt><a name="item600">[600]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2206.00979" title="Abstract">arXiv:2206.00979</a> (replaced) [<a href="/pdf/2206.00979" title="Download PDF">pdf</a>, <a href="/format/2206.00979" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multi-scale Wasserstein Shortest-path Filtration Kernels on Graphs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ye%2C+W">Wei Ye</a>, 
<a href="/search/cs?searchtype=author&query=Tian%2C+H">Hao Tian</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Q">Qijun Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item601">[601]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2206.04231" title="Abstract">arXiv:2206.04231</a> (replaced) [<a href="/pdf/2206.04231" title="Download PDF">pdf</a>, <a href="/format/2206.04231" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> JNMR: Joint Non-linear Motion Regression for Video Frame Interpolation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+M">Meiqin Liu</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+C">Chenming Xu</a>, 
<a href="/search/cs?searchtype=author&query=Yao%2C+C">Chao Yao</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+C">Chunyu Lin</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Y">Yao Zhao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by IEEE Transactions on Image Processing (TIP)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item602">[602]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2206.14740" title="Abstract">arXiv:2206.14740</a> (replaced) [<a href="/pdf/2206.14740" title="Download PDF">pdf</a>, <a href="/ps/2206.14740" title="Download PostScript">ps</a>, <a href="/format/2206.14740" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Saturating systems and the rank covering radius
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Bonini%2C+M">Matteo Bonini</a>, 
<a href="/search/math?searchtype=author&query=Borello%2C+M">Martino Borello</a>, 
<a href="/search/math?searchtype=author&query=Byrne%2C+E">Eimear Byrne</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 26 pages, to appear in Journal of Algebraic Combinatorics
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Combinatorics (math.CO)</span>; Information Theory (cs.IT)

</div>
</div>
</dd>
<dt><a name="item603">[603]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2207.01545" title="Abstract">arXiv:2207.01545</a> (replaced) [<a href="/pdf/2207.01545" title="Download PDF">pdf</a>, <a href="/format/2207.01545" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Masked Autoencoders in 3D Point Cloud Representation Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jiang%2C+J">Jincen Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+X">Xuequan Lu</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+L">Lizhi Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Dazeley%2C+R">Richard Dazeley</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+M">Meili Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to IEEE Transactions on Multimedia
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item604">[604]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2207.06150" title="Abstract">arXiv:2207.06150</a> (replaced) [<a href="/pdf/2207.06150" title="Download PDF">pdf</a>, <a href="/format/2207.06150" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Estimating the Power Consumption of Heterogeneous Devices when  performing AI Inference
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Machado%2C+P">Pedro Machado</a>, 
<a href="/search/cs?searchtype=author&query=Matic%2C+I">Ivica Matic</a>, 
<a href="/search/cs?searchtype=author&query=de+Lemos%2C+F">Francisco de Lemos</a>, 
<a href="/search/cs?searchtype=author&query=Ihianle%2C+I+K">Isibor Kennedy Ihianle</a>, 
<a href="/search/cs?searchtype=author&query=Adama%2C+D+A">David Ada Adama</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Hardware Architecture (cs.AR)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV); Image and Video Processing (eess.IV)

</div>
</div>
</dd>
<dt><a name="item605">[605]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2207.09847" title="Abstract">arXiv:2207.09847</a> (replaced) [<a href="/pdf/2207.09847" title="Download PDF">pdf</a>, <a href="/format/2207.09847" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Predicting Word Learning in Children from the Performance of Computer  Vision Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rane%2C+S">Sunayana Rane</a>, 
<a href="/search/cs?searchtype=author&query=Nencheva%2C+M+L">Mira L. Nencheva</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zeyu Wang</a>, 
<a href="/search/cs?searchtype=author&query=Lew-Williams%2C+C">Casey Lew-Williams</a>, 
<a href="/search/cs?searchtype=author&query=Russakovsky%2C+O">Olga Russakovsky</a>, 
<a href="/search/cs?searchtype=author&query=Griffiths%2C+T+L">Thomas L. Griffiths</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> CogSci 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item606">[606]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2207.10665" title="Abstract">arXiv:2207.10665</a> (replaced) [<a href="/pdf/2207.10665" title="Download PDF">pdf</a>, <a href="/format/2207.10665" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> One-dimensional Tensor Network Recovery
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Chen%2C+Z">Ziang Chen</a>, 
<a href="/search/math?searchtype=author&query=Lu%2C+J">Jianfeng Lu</a>, 
<a href="/search/math?searchtype=author&query=Zhang%2C+A+R">Anru R. Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Statistics Theory (math.ST)

</div>
</div>
</dd>
<dt><a name="item607">[607]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2207.11581" title="Abstract">arXiv:2207.11581</a> (replaced) [<a href="/pdf/2207.11581" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Self-supervised contrastive learning of echocardiogram videos enables  label-efficient cardiac disease diagnosis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Holste%2C+G">Gregory Holste</a>, 
<a href="/search/cs?searchtype=author&query=Oikonomou%2C+E+K">Evangelos K. Oikonomou</a>, 
<a href="/search/cs?searchtype=author&query=Mortazavi%2C+B+J">Bobak J. Mortazavi</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zhangyang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Khera%2C+R">Rohan Khera</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item608">[608]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2208.02164" title="Abstract">arXiv:2208.02164</a> (replaced) [<a href="/pdf/2208.02164" title="Download PDF">pdf</a>, <a href="/ps/2208.02164" title="Download PostScript">ps</a>, <a href="/format/2208.02164" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Identity Problem in nilpotent groups of bounded class
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dong%2C+R">Ruiwen Dong</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 48 pages, title changed
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Discrete Mathematics (cs.DM)</span>; Group Theory (math.GR); Rings and Algebras (math.RA)

</div>
</div>
</dd>
<dt><a name="item609">[609]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2208.02785" title="Abstract">arXiv:2208.02785</a> (replaced) [<a href="/pdf/2208.02785" title="Download PDF">pdf</a>, <a href="/ps/2208.02785" title="Download PostScript">ps</a>, <a href="/format/2208.02785" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Notions, Stability, Existence, and Robustness of Limit Cycles in Hybrid  Dynamical Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Lou%2C+X">Xuyang Lou</a>, 
<a href="/search/eess?searchtype=author&query=Li%2C+Y">Yuchun Li</a>, 
<a href="/search/eess?searchtype=author&query=Sanfelice%2C+R+G">Ricardo G. Sanfelice</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 29 pages. Version submitted for review
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
</div>
</dd>
<dt><a name="item610">[610]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2208.03886" title="Abstract">arXiv:2208.03886</a> (replaced) [<a href="/pdf/2208.03886" title="Download PDF">pdf</a>, <a href="/ps/2208.03886" title="Download PostScript">ps</a>, <a href="/format/2208.03886" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> What can we know about that which we cannot even imagine?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Wolpert%2C+D+H">David H. Wolpert</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 38 pages, 9 pages are references
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">History and Philosophy of Physics (physics.hist-ph)</span>; Computation and Language (cs.CL)

</div>
</div>
</dd>
<dt><a name="item611">[611]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2208.04349" title="Abstract">arXiv:2208.04349</a> (replaced) [<a href="/pdf/2208.04349" title="Download PDF">pdf</a>, <a href="/format/2208.04349" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Coordinated Per-Antenna Power Minimization for Multicell Massive MIMO  Systems with Low-Resolution Data Converters
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Cho%2C+Y">Yunseong Cho</a>, 
<a href="/search/eess?searchtype=author&query=Choi%2C+J">Jinseok Choi</a>, 
<a href="/search/eess?searchtype=author&query=Evans%2C+B+L">Brian L. Evans</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> submitted for possible IEEE journal publication
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Information Theory (cs.IT)

</div>
</div>
</dd>
<dt><a name="item612">[612]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2208.11147" title="Abstract">arXiv:2208.11147</a> (replaced) [<a href="/e-print/2208.11147" title="Download source">src</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SoK: Content Moderation Schemes in End-to-End Encrypted Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rahalkar%2C+C">Chaitanya Rahalkar</a>, 
<a href="/search/cs?searchtype=author&query=Virgaonkar%2C+A">Anushka Virgaonkar</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Inaccuracies and inconsistencies in paper
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
</div>
</dd>
<dt><a name="item613">[613]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2208.13428" title="Abstract">arXiv:2208.13428</a> (replaced) [<a href="/pdf/2208.13428" title="Download PDF">pdf</a>, <a href="/format/2208.13428" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Constructive Many-one Reduction from the Halting Problem to  Semi-unification (Extended Version)
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dudenhefner%2C+A">Andrej Dudenhefner</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> CSL 2022 - LMCS special issue
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>

</div>
</div>
</dd>
<dt><a name="item614">[614]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2209.00283" title="Abstract">arXiv:2209.00283</a> (replaced) [<a href="/pdf/2209.00283" title="Download PDF">pdf</a>, <a href="/format/2209.00283" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Conditional graph entropy as an alternating minimization problem
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Harangi%2C+V">Viktor Harangi</a>, 
<a href="/search/cs?searchtype=author&query=Niu%2C+X">Xueyan Niu</a>, 
<a href="/search/cs?searchtype=author&query=Bai%2C+B">Bo Bai</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Combinatorics (math.CO)

</div>
</div>
</dd>
<dt><a name="item615">[615]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2209.04436" title="Abstract">arXiv:2209.04436</a> (replaced) [<a href="/pdf/2209.04436" title="Download PDF">pdf</a>, <a href="/format/2209.04436" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multi-NeuS: 3D Head Portraits from Single Image with Neural Implicit  Functions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Burkov%2C+E">Egor Burkov</a>, 
<a href="/search/cs?searchtype=author&query=Rakhimov%2C+R">Ruslan Rakhimov</a>, 
<a href="/search/cs?searchtype=author&query=Safin%2C+A">Aleksandr Safin</a>, 
<a href="/search/cs?searchtype=author&query=Burnaev%2C+E">Evgeny Burnaev</a>, 
<a href="/search/cs?searchtype=author&query=Lempitsky%2C+V">Victor Lempitsky</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> in IEEE Access, vol. 11, pp. 95681-95691, 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item616">[616]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2209.05108" title="Abstract">arXiv:2209.05108</a> (replaced) [<a href="/pdf/2209.05108" title="Download PDF">pdf</a>, <a href="/ps/2209.05108" title="Download PostScript">ps</a>, <a href="/format/2209.05108" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Reliable Reserve-Crew Scheduling for Airlines
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Schrotenboer%2C+A+H">Albert H. Schrotenboer</a>, 
<a href="/search/math?searchtype=author&query=Wenneker%2C+R">Rob Wenneker</a>, 
<a href="/search/math?searchtype=author&query=Ursavas%2C+E">Evrim Ursavas</a>, 
<a href="/search/math?searchtype=author&query=Zhu%2C+S+X">Stuart X. Zhu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Systems and Control (eess.SY)

</div>
</div>
</dd>
<dt><a name="item617">[617]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2209.09979" title="Abstract">arXiv:2209.09979</a> (replaced) [<a href="/pdf/2209.09979" title="Download PDF">pdf</a>, <a href="/ps/2209.09979" title="Download PostScript">ps</a>, <a href="/format/2209.09979" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> jsdp: a Java Stochastic DP Library
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rossi%2C+R">Roberto Rossi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Optimization and Control (math.OC)

</div>
</div>
</dd>
<dt><a name="item618">[618]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2209.10550" title="Abstract">arXiv:2209.10550</a> (replaced) [<a href="/pdf/2209.10550" title="Download PDF">pdf</a>, <a href="/format/2209.10550" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Postselected quantum hypothesis testing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Regula%2C+B">Bartosz Regula</a>, 
<a href="/search/quant-ph?searchtype=author&query=Lami%2C+L">Ludovico Lami</a>, 
<a href="/search/quant-ph?searchtype=author&query=Wilde%2C+M+M">Mark M. Wilde</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 31 pages. v2: corrected proof of Lemma 9, added minor clarifications. Close to published version
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Information Theory (cs.IT); Mathematical Physics (math-ph)

</div>
</div>
</dd>
<dt><a name="item619">[619]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2209.14355" title="Abstract">arXiv:2209.14355</a> (replaced) [<a href="/pdf/2209.14355" title="Download PDF">pdf</a>, <a href="/format/2209.14355" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Generalized Kernel Regularized Least Squares
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Chang%2C+Q">Qing Chang</a>, 
<a href="/search/stat?searchtype=author&query=Goplerud%2C+M">Max Goplerud</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted version available at DOI below; corrected small typos
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Political Analysis. 2023. FirstView
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG); Applications (stat.AP)

</div>
</div>
</dd>
<dt><a name="item620">[620]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2210.00654" title="Abstract">arXiv:2210.00654</a> (replaced) [<a href="/pdf/2210.00654" title="Download PDF">pdf</a>, <a href="/ps/2210.00654" title="Download PostScript">ps</a>, <a href="/format/2210.00654" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Relational Models for the Lambek Calculus with Intersection and  Constants
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kuznetsov%2C+S+L">Stepan L. Kuznetsov</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This article is an extended version of the conference paper presented at RAMiCS 2021
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>; Logic (math.LO)

</div>
</div>
</dd>
<dt><a name="item621">[621]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2210.03831" title="Abstract">arXiv:2210.03831</a> (replaced) [<a href="/pdf/2210.03831" title="Download PDF">pdf</a>, <a href="/ps/2210.03831" title="Download PostScript">ps</a>, <a href="/format/2210.03831" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> How to Make Your Approximation Algorithm Private: A Black-Box  Differentially-Private Transformation for Tunable Approximation Algorithms of  Functions with Low Sensitivity
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Blocki%2C+J">Jeremiah Blocki</a>, 
<a href="/search/cs?searchtype=author&query=Grigorescu%2C+E">Elena Grigorescu</a>, 
<a href="/search/cs?searchtype=author&query=Mukherjee%2C+T">Tamalika Mukherjee</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+S">Samson Zhou</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>; Cryptography and Security (cs.CR)

</div>
</div>
</dd>
<dt><a name="item622">[622]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2210.05918" title="Abstract">arXiv:2210.05918</a> (replaced) [<a href="/pdf/2210.05918" title="Download PDF">pdf</a>, <a href="/ps/2210.05918" title="Download PostScript">ps</a>, <a href="/format/2210.05918" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Finite time analysis of temporal difference learning with linear  function approximation: Tail averaging and regularisation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Patil%2C+G">Gandharv Patil</a>, 
<a href="/search/cs?searchtype=author&query=A.%2C+P+L">Prashanth L.A.</a>, 
<a href="/search/cs?searchtype=author&query=Nagaraj%2C+D">Dheeraj Nagaraj</a>, 
<a href="/search/cs?searchtype=author&query=Precup%2C+D">Doina Precup</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Proceedings of The 26th International Conference on Artificial
  Intelligence and Statistics, Proceedings of Machine Learning Research, 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Systems and Control (eess.SY); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item623">[623]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2210.06171" title="Abstract">arXiv:2210.06171</a> (replaced) [<a href="/pdf/2210.06171" title="Download PDF">pdf</a>, <a href="/format/2210.06171" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning to Optimize Quasi-Newton Methods
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liao%2C+I">Isaac Liao</a>, 
<a href="/search/cs?searchtype=author&query=Dangovski%2C+R+R">Rumen R. Dangovski</a>, 
<a href="/search/cs?searchtype=author&query=Foerster%2C+J+N">Jakob N. Foerster</a>, 
<a href="/search/cs?searchtype=author&query=Solja%C4%8Di%C4%87%2C+M">Marin Solja&#x10d;i&#x107;</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item624">[624]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2210.06788" title="Abstract">arXiv:2210.06788</a> (replaced) [<a href="/pdf/2210.06788" title="Download PDF">pdf</a>, <a href="/format/2210.06788" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> TiDAL: Learning Training Dynamics for Active Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kye%2C+S+M">Seong Min Kye</a>, 
<a href="/search/cs?searchtype=author&query=Choi%2C+K">Kwanghee Choi</a>, 
<a href="/search/cs?searchtype=author&query=Byun%2C+H">Hyeongmin Byun</a>, 
<a href="/search/cs?searchtype=author&query=Chang%2C+B">Buru Chang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ICCV 2023 Camera-Ready
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item625">[625]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2210.07285" title="Abstract">arXiv:2210.07285</a> (replaced) [<a href="/pdf/2210.07285" title="Download PDF">pdf</a>, <a href="/format/2210.07285" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> 3DEG: Data-Driven Descriptor Extraction for Global re-localization in  subterranean environments
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Stathoulopoulos%2C+N">Nikolaos Stathoulopoulos</a>, 
<a href="/search/cs?searchtype=author&query=Koval%2C+A">Anton Koval</a>, 
<a href="/search/cs?searchtype=author&query=Nikolakopoulos%2C+G">George Nikolakopoulos</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
</div>
</dd>
<dt><a name="item626">[626]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2210.10133" title="Abstract">arXiv:2210.10133</a> (replaced) [<a href="/pdf/2210.10133" title="Download PDF">pdf</a>, <a href="/format/2210.10133" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Efficient Privacy-Preserving Machine Learning with Lightweight Trusted  Hardware
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+P">Pengzhi Huang</a>, 
<a href="/search/cs?searchtype=author&query=Hoang%2C+T">Thang Hoang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yueying Li</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+E">Elaine Shi</a>, 
<a href="/search/cs?searchtype=author&query=Suh%2C+G+E">G. Edward Suh</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> IEEE S&amp;P'24 submitted
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
</div>
</dd>
<dt><a name="item627">[627]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2210.13532" title="Abstract">arXiv:2210.13532</a> (replaced) [<a href="/pdf/2210.13532" title="Download PDF">pdf</a>, <a href="/ps/2210.13532" title="Download PostScript">ps</a>, <a href="/format/2210.13532" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Adaptive Top-K in SGD for Communication-Efficient Distributed Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ruan%2C+M">Mengzhe Ruan</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+G">Guangfeng Yan</a>, 
<a href="/search/cs?searchtype=author&query=Xiao%2C+Y">Yuanzhang Xiao</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+L">Linqi Song</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+W">Weitao Xu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages, 10 figures, has been accepted by GlobeCom 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Distributed, Parallel, and Cluster Computing (cs.DC); Optimization and Control (math.OC)

</div>
</div>
</dd>
<dt><a name="item628">[628]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2210.15345" title="Abstract">arXiv:2210.15345</a> (replaced) [<a href="/pdf/2210.15345" title="Download PDF">pdf</a>, <a href="/format/2210.15345" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PopArt: Efficient Sparse Regression and Experimental Design for Optimal  Sparse Linear Bandits
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Jang%2C+K">Kyoungseok Jang</a>, 
<a href="/search/stat?searchtype=author&query=Zhang%2C+C">Chicheng Zhang</a>, 
<a href="/search/stat?searchtype=author&query=Jun%2C+K">Kwang-Sung Jun</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 1 figures, published in the 2022 Conference on Neural Information Processing Systems
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item629">[629]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2210.16719" title="Abstract">arXiv:2210.16719</a> (replaced) [<a href="/pdf/2210.16719" title="Download PDF">pdf</a>, <a href="/ps/2210.16719" title="Download PostScript">ps</a>, <a href="/format/2210.16719" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multi-view Multi-label Anomaly Network Traffic Classification based on  MLP-Mixer Neural Network
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zheng%2C+Y">Yu Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Dang%2C+Z">Zhangxuan Dang</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+C">Chunlei Peng</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+C">Chao Yang</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+X">Xinbo Gao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 17 pages,6 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item630">[630]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2210.17546" title="Abstract">arXiv:2210.17546</a> (replaced) [<a href="/pdf/2210.17546" title="Download PDF">pdf</a>, <a href="/format/2210.17546" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Preventing Verbatim Memorization in Language Models Gives a False Sense  of Privacy
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ippolito%2C+D">Daphne Ippolito</a>, 
<a href="/search/cs?searchtype=author&query=Tram%C3%A8r%2C+F">Florian Tram&#xe8;r</a>, 
<a href="/search/cs?searchtype=author&query=Nasr%2C+M">Milad Nasr</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+C">Chiyuan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Jagielski%2C+M">Matthew Jagielski</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+K">Katherine Lee</a>, 
<a href="/search/cs?searchtype=author&query=Choquette-Choo%2C+C+A">Christopher A. Choquette-Choo</a>, 
<a href="/search/cs?searchtype=author&query=Carlini%2C+N">Nicholas Carlini</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computation and Language (cs.CL)

</div>
</div>
</dd>
<dt><a name="item631">[631]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2211.00711" title="Abstract">arXiv:2211.00711</a> (replaced) [<a href="/pdf/2211.00711" title="Download PDF">pdf</a>, <a href="/ps/2211.00711" title="Download PostScript">ps</a>, <a href="/format/2211.00711" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Alternative polynomial-time algorithm for Bipartite Matching
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Guillemot%2C+S">Sylvain Guillemot</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>; Discrete Mathematics (cs.DM); Computer Science and Game Theory (cs.GT)

</div>
</div>
</dd>
<dt><a name="item632">[632]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2211.01120" title="Abstract">arXiv:2211.01120</a> (replaced) [<a href="/pdf/2211.01120" title="Download PDF">pdf</a>, <a href="/format/2211.01120" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Variational Hierarchical Mixtures for Probabilistic Learning of Inverse  Dynamics
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Abdulsamad%2C+H">Hany Abdulsamad</a>, 
<a href="/search/cs?searchtype=author&query=Nickl%2C+P">Peter Nickl</a>, 
<a href="/search/cs?searchtype=author&query=Klink%2C+P">Pascal Klink</a>, 
<a href="/search/cs?searchtype=author&query=Peters%2C+J">Jan Peters</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: text overlap with <a href="/abs/2011.05217">arXiv:2011.05217</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Robotics (cs.RO)

</div>
</div>
</dd>
<dt><a name="item633">[633]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2211.02678" title="Abstract">arXiv:2211.02678</a> (replaced) [<a href="/pdf/2211.02678" title="Download PDF">pdf</a>, <a href="/ps/2211.02678" title="Download PostScript">ps</a>, <a href="/format/2211.02678" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Efficient ECG-based Atrial Fibrillation Detection via Parameterised  Hypercomplex Neural Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Basso%2C+L">Leonie Basso</a>, 
<a href="/search/eess?searchtype=author&query=Ren%2C+Z">Zhao Ren</a>, 
<a href="/search/eess?searchtype=author&query=Nejdl%2C+W">Wolfgang Nejdl</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Published at EUSIPCO 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item634">[634]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2211.03685" title="Abstract">arXiv:2211.03685</a> (replaced) [<a href="/pdf/2211.03685" title="Download PDF">pdf</a>, <a href="/format/2211.03685" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On a Network Centrality Maximization Game
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Catalano%2C+C">Costanza Catalano</a>, 
<a href="/search/cs?searchtype=author&query=Castaldo%2C+M">Maria Castaldo</a>, 
<a href="/search/cs?searchtype=author&query=Como%2C+G">Giacomo Como</a>, 
<a href="/search/cs?searchtype=author&query=Fagnani%2C+F">Fabio Fagnani</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 42 pages, 11 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>; Computer Science and Game Theory (cs.GT); Systems and Control (eess.SY); Probability (math.PR)

</div>
</div>
</dd>
<dt><a name="item635">[635]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2211.04476" title="Abstract">arXiv:2211.04476</a> (replaced) [<a href="/pdf/2211.04476" title="Download PDF">pdf</a>, <a href="/format/2211.04476" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Discover, Explanation, Improvement: An Automatic Slice Detection  Framework for Natural Language Processing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hua%2C+W">Wenyue Hua</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+L">Lifeng Jin</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+L">Linfeng Song</a>, 
<a href="/search/cs?searchtype=author&query=Mi%2C+H">Haitao Mi</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yongfeng Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+D">Dong Yu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 15 pages, 5 figures, accepted by Transactions of the Association for Computational Linguistics
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item636">[636]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2211.06797" title="Abstract">arXiv:2211.06797</a> (replaced) [<a href="/pdf/2211.06797" title="Download PDF">pdf</a>, <a href="/format/2211.06797" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Perceptual Video Coding for Machines via Satisfied Machine Ratio  Modeling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Q">Qi Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Shanshe Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xinfeng Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Jia%2C+C">Chuanmin Jia</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zhao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+S">Siwei Ma</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+W">Wen Gao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item637">[637]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2211.06897" title="Abstract">arXiv:2211.06897</a> (replaced) [<a href="/pdf/2211.06897" title="Download PDF">pdf</a>, <a href="/format/2211.06897" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Batch-based Model Registration for Fast 3D Sherd Reconstruction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jiepeng Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+C">Congyi Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+P">Peng Wang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xin Li</a>, 
<a href="/search/cs?searchtype=author&query=Cobb%2C+P+J">Peter J. Cobb</a>, 
<a href="/search/cs?searchtype=author&query=Theobalt%2C+C">Christian Theobalt</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+W">Wenping Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project page: <a href="https://jiepengwang.github.io/FIRES/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item638">[638]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2211.07108" title="Abstract">arXiv:2211.07108</a> (replaced) [<a href="/pdf/2211.07108" title="Download PDF">pdf</a>, <a href="/format/2211.07108" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Recursive Cross-View: Use Only 2D Detectors to Achieve 3D Object  Detection without 3D Annotations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gui%2C+S">Shun Gui</a>, 
<a href="/search/cs?searchtype=author&query=Luximon%2C+Y">Yan Luximon</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 7 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item639">[639]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2211.08796" title="Abstract">arXiv:2211.08796</a> (replaced) [<a href="/pdf/2211.08796" title="Download PDF">pdf</a>, <a href="/format/2211.08796" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Model Based Residual Policy Learning with Applications to Antenna  Control
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=M%C3%B6llerstedt%2C+V+E">Viktor Eriksson M&#xf6;llerstedt</a>, 
<a href="/search/cs?searchtype=author&query=Russo%2C+A">Alessio Russo</a>, 
<a href="/search/cs?searchtype=author&query=Bouton%2C+M">Maxime Bouton</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Systems and Control (eess.SY)

</div>
</div>
</dd>
<dt><a name="item640">[640]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2211.08843" title="Abstract">arXiv:2211.08843</a> (replaced) [<a href="/pdf/2211.08843" title="Download PDF">pdf</a>, <a href="/format/2211.08843" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Improving Speech Emotion Recognition with Unsupervised Speaking Style  Transfer
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Qu%2C+L">Leyuan Qu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+W">Wei Wang</a>, 
<a href="/search/cs?searchtype=author&query=Weber%2C+C">Cornelius Weber</a>, 
<a href="/search/cs?searchtype=author&query=Yue%2C+P">Pengcheng Yue</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+T">Taihao Li</a>, 
<a href="/search/cs?searchtype=author&query=Wermter%2C+S">Stefan Wermter</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Artificial Intelligence (cs.AI); Audio and Speech Processing (eess.AS)

</div>
</div>
</dd>
<dt><a name="item641">[641]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2211.09172" title="Abstract">arXiv:2211.09172</a> (replaced) [<a href="/pdf/2211.09172" title="Download PDF">pdf</a>, <a href="/format/2211.09172" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deep Emotion Recognition in Textual Conversations: A Survey
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pereira%2C+P">Patr&#xed;cia Pereira</a>, 
<a href="/search/cs?searchtype=author&query=Moniz%2C+H">Helena Moniz</a>, 
<a href="/search/cs?searchtype=author&query=Carvalho%2C+J+P">Joao Paulo Carvalho</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item642">[642]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2211.12769" title="Abstract">arXiv:2211.12769</a> (replaced) [<a href="/pdf/2211.12769" title="Download PDF">pdf</a>, <a href="/ps/2211.12769" title="Download PostScript">ps</a>, <a href="/format/2211.12769" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Byzantine Multiple Access Channels -- Part I: Reliable Communication
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sangwan%2C+N">Neha Sangwan</a>, 
<a href="/search/cs?searchtype=author&query=Bakshi%2C+M">Mayank Bakshi</a>, 
<a href="/search/cs?searchtype=author&query=Dey%2C+B+K">Bikash Kumar Dey</a>, 
<a href="/search/cs?searchtype=author&query=Prabhakaran%2C+V+M">Vinod M. Prabhakaran</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This supercedes Part I of arxiv:<a href="/abs/1904.11925">1904.11925</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>

</div>
</div>
</dd>
<dt><a name="item643">[643]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2211.12875" title="Abstract">arXiv:2211.12875</a> (replaced) [<a href="/pdf/2211.12875" title="Download PDF">pdf</a>, <a href="/format/2211.12875" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Survey of Deep Graph Clustering: Taxonomy, Challenge, Application, and  Open Resource
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yue Liu</a>, 
<a href="/search/cs?searchtype=author&query=Xia%2C+J">Jun Xia</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+S">Sihang Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+X">Xihong Yang</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+K">Ke Liang</a>, 
<a href="/search/cs?searchtype=author&query=Fan%2C+C">Chenchen Fan</a>, 
<a href="/search/cs?searchtype=author&query=Zhuang%2C+Y">Yan Zhuang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+S+Z">Stan Z. Li</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xinwang Liu</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+K">Kunlun He</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 20 pages, 14 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item644">[644]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2211.12891" title="Abstract">arXiv:2211.12891</a> (replaced) [<a href="/pdf/2211.12891" title="Download PDF">pdf</a>, <a href="/ps/2211.12891" title="Download PostScript">ps</a>, <a href="/format/2211.12891" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Integrated Sensing and Communication: Joint Pilot and Transmission  Design
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hua%2C+M">Meng Hua</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Q">Qingqing Wu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+W">Wen Chen</a>, 
<a href="/search/cs?searchtype=author&query=Jamalipour%2C+A">Abbas Jamalipour</a>, 
<a href="/search/cs?searchtype=author&query=Dobre%2C+O+A">Octavia A. Dobre</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This papar answers the optimal space code-time design for supporting ISAC
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
</div>
</dd>
<dt><a name="item645">[645]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2211.14049" title="Abstract">arXiv:2211.14049</a> (replaced) [<a href="/pdf/2211.14049" title="Download PDF">pdf</a>, <a href="/format/2211.14049" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Task-Oriented Communication for Edge Video Analytics
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Shao%2C+J">Jiawei Shao</a>, 
<a href="/search/eess?searchtype=author&query=Zhang%2C+X">Xinjie Zhang</a>, 
<a href="/search/eess?searchtype=author&query=Zhang%2C+J">Jun Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This paper was accepted to IEEE Transactions on Wireless Communications (TWC)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item646">[646]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2211.14096" title="Abstract">arXiv:2211.14096</a> (replaced) [<a href="/pdf/2211.14096" title="Download PDF">pdf</a>, <a href="/format/2211.14096" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deep grading for MRI-based differential diagnosis of Alzheimer&#x27;s disease  and Frontotemporal dementia
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Nguyen%2C+H">Huy-Dung Nguyen</a>, 
<a href="/search/eess?searchtype=author&query=Cl%C3%A9ment%2C+M">Micha&#xeb;l Cl&#xe9;ment</a>, 
<a href="/search/eess?searchtype=author&query=Planche%2C+V">Vincent Planche</a>, 
<a href="/search/eess?searchtype=author&query=Mansencal%2C+B">Boris Mansencal</a>, 
<a href="/search/eess?searchtype=author&query=Coup%C3%A9%2C+P">Pierrick Coup&#xe9;</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item647">[647]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2211.14456" title="Abstract">arXiv:2211.14456</a> (replaced) [<a href="/pdf/2211.14456" title="Download PDF">pdf</a>, <a href="/format/2211.14456" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> TetraSphere: A Neural Descriptor for O(3)-Invariant Point Cloud Analysis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Melnyk%2C+P">Pavlo Melnyk</a>, 
<a href="/search/cs?searchtype=author&query=Robinson%2C+A">Andreas Robinson</a>, 
<a href="/search/cs?searchtype=author&query=Wadenb%C3%A4ck%2C+M">M&#xe5;rten Wadenb&#xe4;ck</a>, 
<a href="/search/cs?searchtype=author&query=Felsberg%2C+M">Michael Felsberg</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item648">[648]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2211.14574" title="Abstract">arXiv:2211.14574</a> (replaced) [<a href="/pdf/2211.14574" title="Download PDF">pdf</a>, <a href="/format/2211.14574" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Very High-Order A-stable Stiffly Accurate Diagonally Implicit  Runge-Kutta Methods with Error Estimators
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Alamri%2C+Y">Yousef Alamri</a>, 
<a href="/search/math?searchtype=author&query=Ketcheson%2C+D+I">David I. Ketcheson</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
</div>
</dd>
<dt><a name="item649">[649]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2212.00330" title="Abstract">arXiv:2212.00330</a> (replaced) [<a href="/pdf/2212.00330" title="Download PDF">pdf</a>, <a href="/format/2212.00330" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Reliable Joint Segmentation of Retinal Edema Lesions in OCT Images
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Wang%2C+M">Meng Wang</a>, 
<a href="/search/eess?searchtype=author&query=Yu%2C+K">Kai Yu</a>, 
<a href="/search/eess?searchtype=author&query=Feng%2C+C">Chun-Mei Feng</a>, 
<a href="/search/eess?searchtype=author&query=Zou%2C+K">Ke Zou</a>, 
<a href="/search/eess?searchtype=author&query=Xu%2C+Y">Yanyu Xu</a>, 
<a href="/search/eess?searchtype=author&query=Meng%2C+Q">Qingquan Meng</a>, 
<a href="/search/eess?searchtype=author&query=Goh%2C+R+S+M">Rick Siow Mong Goh</a>, 
<a href="/search/eess?searchtype=author&query=Liu%2C+Y">Yong Liu</a>, 
<a href="/search/eess?searchtype=author&query=Xu%2C+X">Xinxing Xu</a>, 
<a href="/search/eess?searchtype=author&query=Fu%2C+H">Huazhu Fu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item650">[650]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2212.01173" title="Abstract">arXiv:2212.01173</a> (replaced) [<a href="/pdf/2212.01173" title="Download PDF">pdf</a>, <a href="/format/2212.01173" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DWRSeg: Rethinking Efficient Acquisition of Multi-scale Contextual  Information for Real-time Semantic Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wei%2C+H">Haoran Wei</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xu Liu</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+S">Shouchun Xu</a>, 
<a href="/search/cs?searchtype=author&query=Dai%2C+Z">Zhongjian Dai</a>, 
<a href="/search/cs?searchtype=author&query=Dai%2C+Y">Yaping Dai</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+X">Xiangyang Xu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item651">[651]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2212.01833" title="Abstract">arXiv:2212.01833</a> (replaced) [<a href="/pdf/2212.01833" title="Download PDF">pdf</a>, <a href="/format/2212.01833" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Understanding Sinusoidal Neural Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Novello%2C+T">Tiago Novello</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item652">[652]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2212.02626" title="Abstract">arXiv:2212.02626</a> (replaced) [<a href="/pdf/2212.02626" title="Download PDF">pdf</a>, <a href="/format/2212.02626" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Generic Methodology for the Modular Verification of Security Protocol  Implementations (extended version)
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Arquint%2C+L">Linard Arquint</a>, 
<a href="/search/cs?searchtype=author&query=Schwerhoff%2C+M">Malte Schwerhoff</a>, 
<a href="/search/cs?searchtype=author&query=Mehta%2C+V">Vaibhav Mehta</a>, 
<a href="/search/cs?searchtype=author&query=M%C3%BCller%2C+P">Peter M&#xfc;ller</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Programming Languages (cs.PL)

</div>
</div>
</dd>
<dt><a name="item653">[653]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2212.05102" title="Abstract">arXiv:2212.05102</a> (replaced) [<a href="/pdf/2212.05102" title="Download PDF">pdf</a>, <a href="/format/2212.05102" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A soft nearest-neighbor framework for continual semi-supervised learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kang%2C+Z">Zhiqi Kang</a>, 
<a href="/search/cs?searchtype=author&query=Fini%2C+E">Enrico Fini</a>, 
<a href="/search/cs?searchtype=author&query=Nabi%2C+M">Moin Nabi</a>, 
<a href="/search/cs?searchtype=author&query=Ricci%2C+E">Elisa Ricci</a>, 
<a href="/search/cs?searchtype=author&query=Alahari%2C+K">Karteek Alahari</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at ICCV 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item654">[654]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2212.07761" title="Abstract">arXiv:2212.07761</a> (replaced) [<a href="/pdf/2212.07761" title="Download PDF">pdf</a>, <a href="/ps/2212.07761" title="Download PostScript">ps</a>, <a href="/format/2212.07761" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Successive Interference Cancellation for Bandlimited Channels with  Direct Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Prinz%2C+T">Tobias Prinz</a>, 
<a href="/search/cs?searchtype=author&query=Plabst%2C+D">Daniel Plabst</a>, 
<a href="/search/cs?searchtype=author&query=Wiegart%2C+T">Thomas Wiegart</a>, 
<a href="/search/cs?searchtype=author&query=Calabr%C3%B2%2C+S">Stefano Calabr&#xf2;</a>, 
<a href="/search/cs?searchtype=author&query=Hanik%2C+N">Norbert Hanik</a>, 
<a href="/search/cs?searchtype=author&query=Kramer%2C+G">Gerhard Kramer</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to IEEE Journal of Lightwave Technology on December 15, 2022; Resubmitted to IEEE Transactions on Communications on September 9, 2023;
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>

</div>
</div>
</dd>
<dt><a name="item655">[655]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2212.07935" title="Abstract">arXiv:2212.07935</a> (replaced) [<a href="/pdf/2212.07935" title="Download PDF">pdf</a>, <a href="/ps/2212.07935" title="Download PostScript">ps</a>, <a href="/format/2212.07935" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Strong-AI Autoepistemic Robots Build on Intensional First Order Logic
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Majkic%2C+Z">Zoran Majkic</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 25 pages, 2 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Logic in Computer Science (cs.LO); Robotics (cs.RO)

</div>
</div>
</dd>
<dt><a name="item656">[656]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2212.09746" title="Abstract">arXiv:2212.09746</a> (replaced) [<a href="/pdf/2212.09746" title="Download PDF">pdf</a>, <a href="/format/2212.09746" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Evaluating Human-Language Model Interaction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lee%2C+M">Mina Lee</a>, 
<a href="/search/cs?searchtype=author&query=Srivastava%2C+M">Megha Srivastava</a>, 
<a href="/search/cs?searchtype=author&query=Hardy%2C+A">Amelia Hardy</a>, 
<a href="/search/cs?searchtype=author&query=Thickstun%2C+J">John Thickstun</a>, 
<a href="/search/cs?searchtype=author&query=Durmus%2C+E">Esin Durmus</a>, 
<a href="/search/cs?searchtype=author&query=Paranjape%2C+A">Ashwin Paranjape</a>, 
<a href="/search/cs?searchtype=author&query=Gerard-Ursin%2C+I">Ines Gerard-Ursin</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X+L">Xiang Lisa Li</a>, 
<a href="/search/cs?searchtype=author&query=Ladhak%2C+F">Faisal Ladhak</a>, 
<a href="/search/cs?searchtype=author&query=Rong%2C+F">Frieda Rong</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+R+E">Rose E. Wang</a>, 
<a href="/search/cs?searchtype=author&query=Kwon%2C+M">Minae Kwon</a>, 
<a href="/search/cs?searchtype=author&query=Park%2C+J+S">Joon Sung Park</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+H">Hancheng Cao</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+T">Tony Lee</a>, 
<a href="/search/cs?searchtype=author&query=Bommasani%2C+R">Rishi Bommasani</a>, 
<a href="/search/cs?searchtype=author&query=Bernstein%2C+M">Michael Bernstein</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+P">Percy Liang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Authored by the Center for Research on Foundation Models (CRFM) at the Stanford Institute for Human-Centered Artificial Intelligence (HAI)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item657">[657]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2212.12024" title="Abstract">arXiv:2212.12024</a> (replaced) [<a href="/pdf/2212.12024" title="Download PDF">pdf</a>, <a href="/ps/2212.12024" title="Download PostScript">ps</a>, <a href="/format/2212.12024" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Playing Safe, Ten Years Later
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Colcombet%2C+T">Thomas Colcombet</a>, 
<a href="/search/cs?searchtype=author&query=Fijalkow%2C+N">Nathana&#xeb;l Fijalkow</a>, 
<a href="/search/cs?searchtype=author&query=Horn%2C+F">Florian Horn</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>; Formal Languages and Automata Theory (cs.FL)

</div>
</div>
</dd>
<dt><a name="item658">[658]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.00387" title="Abstract">arXiv:2301.00387</a> (replaced) [<a href="/pdf/2301.00387" title="Download PDF">pdf</a>, <a href="/ps/2301.00387" title="Download PostScript">ps</a>, <a href="/format/2301.00387" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exactly Hittable Interval Graphs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dhannya%2C+S+M">S.M. Dhannya</a>, 
<a href="/search/cs?searchtype=author&query=Narayanaswamy%2C+N+S">N.S. Narayanaswamy</a>, 
<a href="/search/cs?searchtype=author&query=Nisha%2C+K+K">K.K. Nisha</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 17 pages. arXiv admin note: text overlap with <a href="/abs/1707.05071">arXiv:1707.05071</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>

</div>
</div>
</dd>
<dt><a name="item659">[659]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.00776" title="Abstract">arXiv:2301.00776</a> (replaced) [<a href="/pdf/2301.00776" title="Download PDF">pdf</a>, <a href="/format/2301.00776" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Physics-Informed Neural Networks for Prognostics and Health Management  of Lithium-Ion Batteries
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Wen%2C+P">Pengfei Wen</a>, 
<a href="/search/eess?searchtype=author&query=Ye%2C+Z">Zhi-Sheng Ye</a>, 
<a href="/search/eess?searchtype=author&query=Li%2C+Y">Yong Li</a>, 
<a href="/search/eess?searchtype=author&query=Chen%2C+S">Shaowei Chen</a>, 
<a href="/search/eess?searchtype=author&query=Xie%2C+P">Pu Xie</a>, 
<a href="/search/eess?searchtype=author&query=Zhao%2C+S">Shuai Zhao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages, 10 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item660">[660]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.00794" title="Abstract">arXiv:2301.00794</a> (replaced) [<a href="/pdf/2301.00794" title="Download PDF">pdf</a>, <a href="/format/2301.00794" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> STEPs: Self-Supervised Key Step Extraction and Localization from  Unlabeled Procedural Videos
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shah%2C+A">Anshul Shah</a>, 
<a href="/search/cs?searchtype=author&query=Lundell%2C+B">Benjamin Lundell</a>, 
<a href="/search/cs?searchtype=author&query=Sawhney%2C+H">Harpreet Sawhney</a>, 
<a href="/search/cs?searchtype=author&query=Chellappa%2C+R">Rama Chellappa</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at ICCV 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item661">[661]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.01430" title="Abstract">arXiv:2301.01430</a> (replaced) [<a href="/pdf/2301.01430" title="Download PDF">pdf</a>, <a href="/format/2301.01430" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multi-Task System Identification of Similar Linear Time-Invariant  Dynamical Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Chen%2C+Y">Yiting Chen</a>, 
<a href="/search/eess?searchtype=author&query=Ospina%2C+A+M">Ana M. Ospina</a>, 
<a href="/search/eess?searchtype=author&query=Pasqualetti%2C+F">Fabio Pasqualetti</a>, 
<a href="/search/eess?searchtype=author&query=Dall%27Anese%2C+E">Emiliano Dall&#x27;Anese</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Paper to appear in the proceedings of 62nd IEEE Conference on Decision and Control (CDC 2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Optimization and Control (math.OC)

</div>
</div>
</dd>
<dt><a name="item662">[662]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.02275" title="Abstract">arXiv:2301.02275</a> (replaced) [<a href="/pdf/2301.02275" title="Download PDF">pdf</a>, <a href="/format/2301.02275" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Language as a Latent Sequence: deep latent variable models for  semi-supervised paraphrase generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yu%2C+J">Jialin Yu</a>, 
<a href="/search/cs?searchtype=author&query=Cristea%2C+A+I">Alexandra I. Cristea</a>, 
<a href="/search/cs?searchtype=author&query=Harit%2C+A">Anoushka Harit</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+Z">Zhongtian Sun</a>, 
<a href="/search/cs?searchtype=author&query=Aduragba%2C+O+T">Olanrewaju Tahir Aduragba</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+L">Lei Shi</a>, 
<a href="/search/cs?searchtype=author&query=Moubayed%2C+N+A">Noura Al Moubayed</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item663">[663]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.03102" title="Abstract">arXiv:2301.03102</a> (replaced) [<a href="/pdf/2301.03102" title="Download PDF">pdf</a>, <a href="/format/2301.03102" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Open World NeRF-Based SLAM
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lisus%2C+D">Daniil Lisus</a>, 
<a href="/search/cs?searchtype=author&query=Holmes%2C+C">Connor Holmes</a>, 
<a href="/search/cs?searchtype=author&query=Waslander%2C+S">Steven Waslander</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Presented at Conference on Robots and Vision (CRV) 2023. 8 pages, 2 figures, 2 tables
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> 2023 20th Conference on Robots and Vision (CRV), Montreal, QC,
  Canada, 2023, pp. 37-44
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
</div>
</dd>
<dt><a name="item664">[664]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.06136" title="Abstract">arXiv:2301.06136</a> (replaced) [<a href="/pdf/2301.06136" title="Download PDF">pdf</a>, <a href="/format/2301.06136" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Quantitative Verification with Neural Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Abate%2C+A">Alessandro Abate</a>, 
<a href="/search/cs?searchtype=author&query=Edwards%2C+A">Alec Edwards</a>, 
<a href="/search/cs?searchtype=author&query=Giacobbe%2C+M">Mirco Giacobbe</a>, 
<a href="/search/cs?searchtype=author&query=Punchihewa%2C+H">Hashan Punchihewa</a>, 
<a href="/search/cs?searchtype=author&query=Roy%2C+D">Diptarko Roy</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> The conference version of this manuscript appeared at CONCUR 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>; Programming Languages (cs.PL); Systems and Control (eess.SY)

</div>
</div>
</dd>
<dt><a name="item665">[665]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.07362" title="Abstract">arXiv:2301.07362</a> (replaced) [<a href="/pdf/2301.07362" title="Download PDF">pdf</a>, <a href="/format/2301.07362" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A light- and heat-seeking vine-inspired robot with material-level  responsiveness
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Deglurkar%2C+S">Shivani Deglurkar</a>, 
<a href="/search/cs?searchtype=author&query=Xiao%2C+C">Charles Xiao</a>, 
<a href="/search/cs?searchtype=author&query=Gockowski%2C+L+F">Luke F. Gockowski</a>, 
<a href="/search/cs?searchtype=author&query=Valentine%2C+M+T">Megan T. Valentine</a>, 
<a href="/search/cs?searchtype=author&query=Hawkes%2C+E+W">Elliot W. Hawkes</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
</div>
</dd>
<dt><a name="item666">[666]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.07390" title="Abstract">arXiv:2301.07390</a> (replaced) [<a href="/pdf/2301.07390" title="Download PDF">pdf</a>, <a href="/format/2301.07390" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Relativistic Digital Twin: Bringing the IoT to the Future
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sciullo%2C+L">Luca Sciullo</a>, 
<a href="/search/cs?searchtype=author&query=De+Marchi%2C+A">Alberto De Marchi</a>, 
<a href="/search/cs?searchtype=author&query=Trotta%2C+A">Angelo Trotta</a>, 
<a href="/search/cs?searchtype=author&query=Montori%2C+F">Federico Montori</a>, 
<a href="/search/cs?searchtype=author&query=Bononi%2C+L">Luciano Bononi</a>, 
<a href="/search/cs?searchtype=author&query=Di+Felice%2C+M">Marco Di Felice</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 17 pages, 10 figures, 4 tables, 6 listings
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>; Machine Learning (cs.LG); Optimization and Control (math.OC)

</div>
</div>
</dd>
<dt><a name="item667">[667]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.07670" title="Abstract">arXiv:2301.07670</a> (replaced) [<a href="/pdf/2301.07670" title="Download PDF">pdf</a>, <a href="/format/2301.07670" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Active learning for medical image segmentation with stochastic batches
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gaillochet%2C+M">M&#xe9;lanie Gaillochet</a>, 
<a href="/search/cs?searchtype=author&query=Desrosiers%2C+C">Christian Desrosiers</a>, 
<a href="/search/cs?searchtype=author&query=Lombaert%2C+H">Herv&#xe9; Lombaert</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to Medical Image Analysis, 17 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item668">[668]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.08360" title="Abstract">arXiv:2301.08360</a> (replaced) [<a href="/pdf/2301.08360" title="Download PDF">pdf</a>, <a href="/format/2301.08360" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Domain-adapted Learning and Imitation: DRL for Power Arbitrage
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-fin?searchtype=author&query=Wang%2C+Y">Yuanrong Wang</a>, 
<a href="/search/q-fin?searchtype=author&query=Swaminathan%2C+V+R">Vignesh Raja Swaminathan</a>, 
<a href="/search/q-fin?searchtype=author&query=Granger%2C+N+P">Nikita P. Granger</a>, 
<a href="/search/q-fin?searchtype=author&query=Perez%2C+C+R">Carlos Ros Perez</a>, 
<a href="/search/q-fin?searchtype=author&query=Michler%2C+C">Christian Michler</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Trading and Market Microstructure (q-fin.TR)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item669">[669]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.08374" title="Abstract">arXiv:2301.08374</a> (replaced) [<a href="/pdf/2301.08374" title="Download PDF">pdf</a>, <a href="/format/2301.08374" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Projective Integral Updates for High-Dimensional Variational Inference
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Duersch%2C+J+A">Jed A. Duersch</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item670">[670]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.08568" title="Abstract">arXiv:2301.08568</a> (replaced) [<a href="/pdf/2301.08568" title="Download PDF">pdf</a>, <a href="/format/2301.08568" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Physics-guided neural networks for feedforward control with  input-to-state stability guarantees
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Bolderman%2C+M">Max Bolderman</a>, 
<a href="/search/eess?searchtype=author&query=Butler%2C+H">Hans Butler</a>, 
<a href="/search/eess?searchtype=author&query=Koekebakker%2C+S">Sjirk Koekebakker</a>, 
<a href="/search/eess?searchtype=author&query=van+Horssen%2C+E">Eelco van Horssen</a>, 
<a href="/search/eess?searchtype=author&query=Kamidi%2C+R">Ramidin Kamidi</a>, 
<a href="/search/eess?searchtype=author&query=Spaan-Burke%2C+T">Theresa Spaan-Burke</a>, 
<a href="/search/eess?searchtype=author&query=Strijbosch%2C+N">Nard Strijbosch</a>, 
<a href="/search/eess?searchtype=author&query=Lazar%2C+M">Mircea Lazar</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
</div>
</dd>
<dt><a name="item671">[671]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.09164" title="Abstract">arXiv:2301.09164</a> (replaced) [<a href="/pdf/2301.09164" title="Download PDF">pdf</a>, <a href="/format/2301.09164" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Unifying Synergies between Self-supervised Learning and Dynamic  Computation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Krishna%2C+T">Tarun Krishna</a>, 
<a href="/search/cs?searchtype=author&query=Rai%2C+A+K">Ayush K Rai</a>, 
<a href="/search/cs?searchtype=author&query=Drimbarean%2C+A">Alexandru Drimbarean</a>, 
<a href="/search/cs?searchtype=author&query=Arazo%2C+E">Eric Arazo</a>, 
<a href="/search/cs?searchtype=author&query=Albert%2C+P">Paul Albert</a>, 
<a href="/search/cs?searchtype=author&query=Smeaton%2C+A+F">Alan F Smeaton</a>, 
<a href="/search/cs?searchtype=author&query=McGuinness%2C+K">Kevin McGuinness</a>, 
<a href="/search/cs?searchtype=author&query=O%27Connor%2C+N+E">Noel E O&#x27;Connor</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted in BMVC 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item672">[672]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.09806" title="Abstract">arXiv:2301.09806</a> (replaced) [<a href="/pdf/2301.09806" title="Download PDF">pdf</a>, <a href="/format/2301.09806" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Unveiling the Risks of NFT Promotion Scams
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Roy%2C+S+S">Sayak Saha Roy</a>, 
<a href="/search/cs?searchtype=author&query=Das%2C+D">Dipanjan Das</a>, 
<a href="/search/cs?searchtype=author&query=Bose%2C+P">Priyanka Bose</a>, 
<a href="/search/cs?searchtype=author&query=Kruegel%2C+C">Christopher Kruegel</a>, 
<a href="/search/cs?searchtype=author&query=Vigna%2C+G">Giovanni Vigna</a>, 
<a href="/search/cs?searchtype=author&query=Nilizadeh%2C+S">Shirin Nilizadeh</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Computers and Society (cs.CY)

</div>
</div>
</dd>
<dt><a name="item673">[673]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.11824" title="Abstract">arXiv:2301.11824</a> (replaced) [<a href="/pdf/2301.11824" title="Download PDF">pdf</a>, <a href="/format/2301.11824" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PECAN: A Deterministic Certified Defense Against Backdoor Attacks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yuhao Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Albarghouthi%2C+A">Aws Albarghouthi</a>, 
<a href="/search/cs?searchtype=author&query=D%27Antoni%2C+L">Loris D&#x27;Antoni</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item674">[674]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.11936" title="Abstract">arXiv:2301.11936</a> (replaced) [<a href="/pdf/2301.11936" title="Download PDF">pdf</a>, <a href="/format/2301.11936" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Quantum Ridgelet Transform: Winning Lottery Ticket of Neural Networks  with Quantum Computation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Yamasaki%2C+H">Hayata Yamasaki</a>, 
<a href="/search/quant-ph?searchtype=author&query=Subramanian%2C+S">Sathyawageeswar Subramanian</a>, 
<a href="/search/quant-ph?searchtype=author&query=Hayakawa%2C+S">Satoshi Hayakawa</a>, 
<a href="/search/quant-ph?searchtype=author&query=Sonoda%2C+S">Sho Sonoda</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 27 pages, 4 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Machine Learning (cs.LG); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item675">[675]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.12503" title="Abstract">arXiv:2301.12503</a> (replaced) [<a href="/pdf/2301.12503" title="Download PDF">pdf</a>, <a href="/format/2301.12503" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AudioLDM: Text-to-Audio Generation with Latent Diffusion Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+H">Haohe Liu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Z">Zehua Chen</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+Y">Yi Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Mei%2C+X">Xinhao Mei</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xubo Liu</a>, 
<a href="/search/cs?searchtype=author&query=Mandic%2C+D">Danilo Mandic</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+W">Wenwu Wang</a>, 
<a href="/search/cs?searchtype=author&query=Plumbley%2C+M+D">Mark D. Plumbley</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by ICML 2023. Demo and implementation at <a href="https://audioldm.github.io.">this https URL</a> Evaluation toolbox at <a href="https://github.com/haoheliu/audioldm_eval">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Artificial Intelligence (cs.AI); Multimedia (cs.MM); Audio and Speech Processing (eess.AS); Signal Processing (eess.SP)

</div>
</div>
</dd>
<dt><a name="item676">[676]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.00911" title="Abstract">arXiv:2302.00911</a> (replaced) [<a href="/pdf/2302.00911" title="Download PDF">pdf</a>, <a href="/format/2302.00911" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Conditional expectation with regularization for missing data imputation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Vu%2C+M+A">Mai Anh Vu</a>, 
<a href="/search/stat?searchtype=author&query=Nguyen%2C+T">Thu Nguyen</a>, 
<a href="/search/stat?searchtype=author&query=Do%2C+T+T">Tu T. Do</a>, 
<a href="/search/stat?searchtype=author&query=Phan%2C+N">Nhan Phan</a>, 
<a href="/search/stat?searchtype=author&query=Chawla%2C+N+V">Nitesh V. Chawla</a>, 
<a href="/search/stat?searchtype=author&query=Halvorsen%2C+P">P&#xe5;l Halvorsen</a>, 
<a href="/search/stat?searchtype=author&query=Riegler%2C+M+A">Michael A. Riegler</a>, 
<a href="/search/stat?searchtype=author&query=Nguyen%2C+B+T">Binh T. Nguyen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item677">[677]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.01497" title="Abstract">arXiv:2302.01497</a> (replaced) [<a href="/pdf/2302.01497" title="Download PDF">pdf</a>, <a href="/format/2302.01497" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Gradient Estimation for Unseen Domain Risk Minimization with Pre-Trained  Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lew%2C+B">Byounggyu Lew</a>, 
<a href="/search/cs?searchtype=author&query=Son%2C+D">Donghyun Son</a>, 
<a href="/search/cs?searchtype=author&query=Chang%2C+B">Buru Chang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ICCV2023 Workshop Version
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item678">[678]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.02522" title="Abstract">arXiv:2302.02522</a> (replaced) [<a href="/pdf/2302.02522" title="Download PDF">pdf</a>, <a href="/format/2302.02522" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Prior Density Learning in Variational Bayesian Phylogenetic Parameters  Inference
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-bio?searchtype=author&query=Remita%2C+A+M">Amine M. Remita</a>, 
<a href="/search/q-bio?searchtype=author&query=Vitae%2C+G">Golrokh Vitae</a>, 
<a href="/search/q-bio?searchtype=author&query=Diallo%2C+A+B">Abdoulaye Banir&#xe9; Diallo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted as a full paper for publication at RECOMB-CG 2023 (LNBI proof version). 15 pages (excluding references), 6 tables and 1 figure
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> In Jahn, K., Vina\v{r}, T. (eds) Comparative Genomics. RECOMB-CG
  2023. Lecture Notes in Computer Science, vol 13883. Springer, Cham
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Populations and Evolution (q-bio.PE)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item679">[679]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.03506" title="Abstract">arXiv:2302.03506</a> (replaced) [<a href="/pdf/2302.03506" title="Download PDF">pdf</a>, <a href="/format/2302.03506" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Dynamic Training of Liquid State Machines
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Koralalage%2C+P">Pavithra Koralalage</a>, 
<a href="/search/cs?searchtype=author&query=Fakeye%2C+I">Ireoluwa Fakeye</a>, 
<a href="/search/cs?searchtype=author&query=Machado%2C+P">Pedro Machado</a>, 
<a href="/search/cs?searchtype=author&query=Smith%2C+J">Jason Smith</a>, 
<a href="/search/cs?searchtype=author&query=Ihianle%2C+I+K">Isibor Kennedy Ihianle</a>, 
<a href="/search/cs?searchtype=author&query=Yahaya%2C+S+W">Salisu Wada Yahaya</a>, 
<a href="/search/cs?searchtype=author&query=Oikonomou%2C+A">Andreas Oikonomou</a>, 
<a href="/search/cs?searchtype=author&query=Lotfi%2C+A">Ahmad Lotfi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neural and Evolutionary Computing (cs.NE)</span>

</div>
</div>
</dd>
<dt><a name="item680">[680]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.06900" title="Abstract">arXiv:2302.06900</a> (replaced) [<a href="/pdf/2302.06900" title="Download PDF">pdf</a>, <a href="/format/2302.06900" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Over-Sampling Strategy in Feature Space for Graphs based  Class-imbalanced Bot Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shi%2C+S">Shuhao Shi</a>, 
<a href="/search/cs?searchtype=author&query=Qiao%2C+K">Kai Qiao</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+J">Jie Yang</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+B">Baojie Song</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Jian Chen</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+B">Bin Yan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages, 4 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item681">[681]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.07854" title="Abstract">arXiv:2302.07854</a> (replaced) [<a href="/pdf/2302.07854" title="Download PDF">pdf</a>, <a href="/format/2302.07854" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Benchmarking Continuous Time Models for Predicting Multiple Sclerosis  Progression
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Norcliffe%2C+A">Alexander Norcliffe</a>, 
<a href="/search/cs?searchtype=author&query=Proleev%2C+L">Lev Proleev</a>, 
<a href="/search/cs?searchtype=author&query=Mincu%2C+D">Diana Mincu</a>, 
<a href="/search/cs?searchtype=author&query=Hartsell%2C+F+L">Fletcher Lee Hartsell</a>, 
<a href="/search/cs?searchtype=author&query=Heller%2C+K">Katherine Heller</a>, 
<a href="/search/cs?searchtype=author&query=Roy%2C+S">Subhrajit Roy</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 32 pages, 2 figures, 17 tables, published in TMLR 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item682">[682]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.08837" title="Abstract">arXiv:2302.08837</a> (replaced) [<a href="/pdf/2302.08837" title="Download PDF">pdf</a>, <a href="/format/2302.08837" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Type-Theoretic Signatures for Algebraic Theories and Inductive Types
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kov%C3%A1cs%2C+A">Andr&#xe1;s Kov&#xe1;cs</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>

</div>
</div>
</dd>
<dt><a name="item683">[683]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.09187" title="Abstract">arXiv:2302.09187</a> (replaced) [<a href="/pdf/2302.09187" title="Download PDF">pdf</a>, <a href="/format/2302.09187" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Video Action Recognition Collaborative Learning with Dynamics via  PSO-ConvNet Transformer
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Phong%2C+N+H">Nguyen Huu Phong</a>, 
<a href="/search/cs?searchtype=author&query=Ribeiro%2C+B">Bernardete Ribeiro</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 18 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item684">[684]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.09700" title="Abstract">arXiv:2302.09700</a> (replaced) [<a href="/pdf/2302.09700" title="Download PDF">pdf</a>, <a href="/format/2302.09700" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Leveraging Reviews: Learning to Price with Buyer and Seller Uncertainty
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Guo%2C+W">Wenshuo Guo</a>, 
<a href="/search/cs?searchtype=author&query=Haghtalab%2C+N">Nika Haghtalab</a>, 
<a href="/search/cs?searchtype=author&query=Kandasamy%2C+K">Kirthevasan Kandasamy</a>, 
<a href="/search/cs?searchtype=author&query=Vitercik%2C+E">Ellen Vitercik</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item685">[685]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.09893" title="Abstract">arXiv:2302.09893</a> (replaced) [<a href="/pdf/2302.09893" title="Download PDF">pdf</a>, <a href="/format/2302.09893" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Efficient Generator of Mathematical Expressions for Symbolic Regression
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Me%C5%BEnar%2C+S">Sebastian Me&#x17e;nar</a>, 
<a href="/search/cs?searchtype=author&query=D%C5%BEeroski%2C+S">Sa&#x161;o D&#x17e;eroski</a>, 
<a href="/search/cs?searchtype=author&query=Todorovski%2C+L">Ljup&#x10d;o Todorovski</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 35 pages, 11 tables, 7 multi-part figures, Machine learning (Springer) and journal track of ECML/PKDD 2023
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Mach Learn (2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item686">[686]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.11704" title="Abstract">arXiv:2302.11704</a> (replaced) [<a href="/pdf/2302.11704" title="Download PDF">pdf</a>, <a href="/format/2302.11704" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Mitigating Adversarial Attacks in Deepfake Detection: An Exploration of  Perturbation and AI Techniques
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dhesi%2C+S">Saminder Dhesi</a>, 
<a href="/search/cs?searchtype=author&query=Fontes%2C+L">Laura Fontes</a>, 
<a href="/search/cs?searchtype=author&query=Machado%2C+P">Pedro Machado</a>, 
<a href="/search/cs?searchtype=author&query=Ihianle%2C+I+K">Isibor Kennedy Ihianle</a>, 
<a href="/search/cs?searchtype=author&query=Tash%2C+F+F">Farhad Fassihi Tash</a>, 
<a href="/search/cs?searchtype=author&query=Adama%2C+D+A">David Ada Adama</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Cryptography and Security (cs.CR)

</div>
</div>
</dd>
<dt><a name="item687">[687]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.13156" title="Abstract">arXiv:2302.13156</a> (replaced) [<a href="/pdf/2302.13156" title="Download PDF">pdf</a>, <a href="/format/2302.13156" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Why Do Facial Deepfake Detectors Fail?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Le%2C+B">Binh Le</a>, 
<a href="/search/cs?searchtype=author&query=Tariq%2C+S">Shahroz Tariq</a>, 
<a href="/search/cs?searchtype=author&query=Abuadbba%2C+A">Alsharif Abuadbba</a>, 
<a href="/search/cs?searchtype=author&query=Moore%2C+K">Kristen Moore</a>, 
<a href="/search/cs?searchtype=author&query=Woo%2C+S">Simon Woo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages, ACM ASIACCS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item688">[688]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.13351" title="Abstract">arXiv:2302.13351</a> (replaced) [<a href="/pdf/2302.13351" title="Download PDF">pdf</a>, <a href="/ps/2302.13351" title="Download PostScript">ps</a>, <a href="/format/2302.13351" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Optimal local identifying and local locating-dominating codes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Herva%2C+P">Pyry Herva</a>, 
<a href="/search/cs?searchtype=author&query=Laihonen%2C+T">Tero Laihonen</a>, 
<a href="/search/cs?searchtype=author&query=Lehtil%C3%A4%2C+T">Tuomo Lehtil&#xe4;</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Discrete Mathematics (cs.DM)</span>; Combinatorics (math.CO)

</div>
</div>
</dd>
<dt><a name="item689">[689]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.14627" title="Abstract">arXiv:2302.14627</a> (replaced) [<a href="/pdf/2302.14627" title="Download PDF">pdf</a>, <a href="/format/2302.14627" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DNA Digital Data Storage and Retrieval using algebraic codes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=G%2C+N">NallappaBhavithran G</a>, 
<a href="/search/cs?searchtype=author&query=R%2C+S">Selvakumar R</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, 3 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>

</div>
</div>
</dd>
<dt><a name="item690">[690]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.03038" title="Abstract">arXiv:2303.03038</a> (replaced) [<a href="/pdf/2303.03038" title="Download PDF">pdf</a>, <a href="/format/2303.03038" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Topological Distance between Multi-fields based on Multi-Dimensional  Persistence Diagrams
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ramamurthi%2C+Y">Yashwanth Ramamurthi</a>, 
<a href="/search/cs?searchtype=author&query=Chattopadhyay%2C+A">Amit Chattopadhyay</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Acepted in the IEEE Transactions on Visualization and Computer Graphics
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Graphics (cs.GR)</span>; Computational Geometry (cs.CG)

</div>
</div>
</dd>
<dt><a name="item691">[691]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.03650" title="Abstract">arXiv:2303.03650</a> (replaced) [<a href="/pdf/2303.03650" title="Download PDF">pdf</a>, <a href="/format/2303.03650" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Systematic approaches to generate reversiblizations of Markov chains
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Choi%2C+M+C+H">Michael C.H. Choi</a>, 
<a href="/search/math?searchtype=author&query=Wolfer%2C+G">Geoffrey Wolfer</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 33 pages, 1 figure. To appear in IEEE Trans. Inform. Theory
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Probability (math.PR)</span>; Information Theory (cs.IT); Computation (stat.CO)

</div>
</div>
</dd>
<dt><a name="item692">[692]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.03787" title="Abstract">arXiv:2303.03787</a> (replaced) [<a href="/pdf/2303.03787" title="Download PDF">pdf</a>, <a href="/format/2303.03787" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Sample-efficient Real-time Planning with Curiosity Cross-Entropy Method  and Contrastive Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kotb%2C+M">Mostafa Kotb</a>, 
<a href="/search/cs?searchtype=author&query=Weber%2C+C">Cornelius Weber</a>, 
<a href="/search/cs?searchtype=author&query=Wermter%2C+S">Stefan Wermter</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, 4 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item693">[693]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.04313" title="Abstract">arXiv:2303.04313</a> (replaced) [<a href="/pdf/2303.04313" title="Download PDF">pdf</a>, <a href="/format/2303.04313" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Online Control Barrier Functions for Decentralized Multi-Agent  Navigation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gao%2C+Z">Zhan Gao</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+G">Guang Yang</a>, 
<a href="/search/cs?searchtype=author&query=Prorok%2C+A">Amanda Prorok</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Machine Learning (cs.LG); Multiagent Systems (cs.MA)

</div>
</div>
</dd>
<dt><a name="item694">[694]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.06015" title="Abstract">arXiv:2303.06015</a> (replaced) [<a href="/pdf/2303.06015" title="Download PDF">pdf</a>, <a href="/format/2303.06015" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Dynamic Y-KD: A Hybrid Approach to Continual Instance Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pag%C3%A9-Fortin%2C+M">Mathieu Pag&#xe9;-Fortin</a>, 
<a href="/search/cs?searchtype=author&query=Chaib-draa%2C+B">Brahim Chaib-draa</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item695">[695]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.06053" title="Abstract">arXiv:2303.06053</a> (replaced) [<a href="/pdf/2303.06053" title="Download PDF">pdf</a>, <a href="/format/2303.06053" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> TSMixer: An All-MLP Architecture for Time Series Forecasting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+S">Si-An Chen</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+C">Chun-Liang Li</a>, 
<a href="/search/cs?searchtype=author&query=Yoder%2C+N">Nate Yoder</a>, 
<a href="/search/cs?searchtype=author&query=Arik%2C+S+O">Sercan O. Arik</a>, 
<a href="/search/cs?searchtype=author&query=Pfister%2C+T">Tomas Pfister</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Transactions on Machine Learning Research (TMLR), 09/2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item696">[696]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.06460" title="Abstract">arXiv:2303.06460</a> (replaced) [<a href="/pdf/2303.06460" title="Download PDF">pdf</a>, <a href="/format/2303.06460" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GeoCamera: Telling Stories in Geographic Visualizations with Camera  Movements
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+W">Wenchao Li</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zhan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yun Wang</a>, 
<a href="/search/cs?searchtype=author&query=Weng%2C+D">Di Weng</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+L">Liwenhan Xie</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+S">Siming Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Haidong Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Qu%2C+H">Huamin Qu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 15 pages. Published as a conference paper at the ACM Conference on Human Factors in Computing Systems (CHI) 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
</div>
</dd>
<dt><a name="item697">[697]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.06587" title="Abstract">arXiv:2303.06587</a> (replaced) [<a href="/pdf/2303.06587" title="Download PDF">pdf</a>, <a href="/format/2303.06587" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FabricFolding: Learning Efficient Fabric Folding without Expert  Demonstrations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=He%2C+C">Can He</a>, 
<a href="/search/cs?searchtype=author&query=Meng%2C+L">Lingxiao Meng</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+Z">Zhirui Sun</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jiankun Wang</a>, 
<a href="/search/cs?searchtype=author&query=Meng%2C+M+Q+-">Max Q.-H. Meng</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
</div>
</dd>
<dt><a name="item698">[698]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.07356" title="Abstract">arXiv:2303.07356</a> (replaced) [<a href="/pdf/2303.07356" title="Download PDF">pdf</a>, <a href="/format/2303.07356" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Recovering Zipf&#x27;s law in intercontinental scientific collaboration
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Krawczyk%2C+M+J">Malgorzata J. Krawczyk</a>, 
<a href="/search/cs?searchtype=author&query=Malarz%2C+K">Krzysztof Malarz</a> (AGH University)
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages, 2 figures, 4 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Digital Libraries (cs.DL)</span>

</div>
</div>
</dd>
<dt><a name="item699">[699]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.07928" title="Abstract">arXiv:2303.07928</a> (replaced) [<a href="/pdf/2303.07928" title="Download PDF">pdf</a>, <a href="/format/2303.07928" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Review of the Exponential and Cayley Map on SE(3) as relevant for Lie  Group Integration of the Generalized Poisson Equation and Flexible Multibody  Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Mueller%2C+A">Andreas Mueller</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Proc. Royal Soc. A, Vol. 477, 2021
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Differential Geometry (math.DG)</span>; Robotics (cs.RO); Mathematical Physics (math-ph); Computational Physics (physics.comp-ph)

</div>
</div>
</dd>
<dt><a name="item700">[700]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.08387" title="Abstract">arXiv:2303.08387</a> (replaced) [<a href="/pdf/2303.08387" title="Download PDF">pdf</a>, <a href="/format/2303.08387" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning to Place Unseen Objects Stably using a Large-scale Simulation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Noh%2C+S">Sangjun Noh</a>, 
<a href="/search/cs?searchtype=author&query=Kang%2C+R">Raeyoung Kang</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+T">Taewon Kim</a>, 
<a href="/search/cs?searchtype=author&query=Back%2C+S">Seunghyeok Back</a>, 
<a href="/search/cs?searchtype=author&query=Bak%2C+S">Seongho Bak</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+K">Kyoobin Lee</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages (main)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
</div>
</dd>
<dt><a name="item701">[701]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.08416" title="Abstract">arXiv:2303.08416</a> (replaced) [<a href="/pdf/2303.08416" title="Download PDF">pdf</a>, <a href="/format/2303.08416" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Lung Nodule Segmentation and Uncertain Region Prediction with an  Uncertainty-Aware Attention Mechanism
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Yang%2C+H">Han Yang</a>, 
<a href="/search/eess?searchtype=author&query=Wang%2C+Q">Qiuli Wang</a>, 
<a href="/search/eess?searchtype=author&query=Zhang%2C+Y">Yue Zhang</a>, 
<a href="/search/eess?searchtype=author&query=An%2C+Z">Zhulin An</a>, 
<a href="/search/eess?searchtype=author&query=Liu%2C+C">Chen Liu</a>, 
<a href="/search/eess?searchtype=author&query=Zhang%2C+X">Xiaohong Zhang</a>, 
<a href="/search/eess?searchtype=author&query=Zhou%2C+S+K">S. Kevin Zhou</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 10 figures. We have reported a preliminary version of this work in MICCAI 2022
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item702">[702]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.08888" title="Abstract">arXiv:2303.08888</a> (replaced) [<a href="/pdf/2303.08888" title="Download PDF">pdf</a>, <a href="/format/2303.08888" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Stochastic Segmentation with Conditional Categorical Diffusion Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zbinden%2C+L">Lukas Zbinden</a>, 
<a href="/search/cs?searchtype=author&query=Doorenbos%2C+L">Lars Doorenbos</a>, 
<a href="/search/cs?searchtype=author&query=Pissas%2C+T">Theodoros Pissas</a>, 
<a href="/search/cs?searchtype=author&query=Huber%2C+A+T">Adrian Thomas Huber</a>, 
<a href="/search/cs?searchtype=author&query=Sznitman%2C+R">Raphael Sznitman</a>, 
<a href="/search/cs?searchtype=author&query=M%C3%A1rquez-Neila%2C+P">Pablo M&#xe1;rquez-Neila</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at ICCV 2023. Code available at <a href="https://github.com/LarsDoorenbos/ccdm-stochastic-segmentation">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item703">[703]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.09248" title="Abstract">arXiv:2303.09248</a> (replaced) [<a href="/pdf/2303.09248" title="Download PDF">pdf</a>, <a href="/format/2303.09248" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Cross-Dimensional Refined Learning for Real-Time 3D Visual Perception  from Monocular Video
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hong%2C+Z">Ziyang Hong</a>, 
<a href="/search/cs?searchtype=author&query=Yue%2C+C+P">C. Patrick Yue</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accpeted to ICCV 2023 Workshops. Project page: <a href="https://hafred.github.io/cdrnet/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Image and Video Processing (eess.IV)

</div>
</div>
</dd>
<dt><a name="item704">[704]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.10285" title="Abstract">arXiv:2303.10285</a> (replaced) [<a href="/pdf/2303.10285" title="Download PDF">pdf</a>, <a href="/format/2303.10285" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exact and optimal quadratization of nonlinear finite-dimensional  non-autonomous dynamical systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bychkov%2C+A">Andrey Bychkov</a>, 
<a href="/search/cs?searchtype=author&query=Issan%2C+O">Opal Issan</a>, 
<a href="/search/cs?searchtype=author&query=Pogudin%2C+G">Gleb Pogudin</a>, 
<a href="/search/cs?searchtype=author&query=Kramer%2C+B">Boris Kramer</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Symbolic Computation (cs.SC)</span>; Dynamical Systems (math.DS); Numerical Analysis (math.NA)

</div>
</div>
</dd>
<dt><a name="item705">[705]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.11114" title="Abstract">arXiv:2303.11114</a> (replaced) [<a href="/pdf/2303.11114" title="Download PDF">pdf</a>, <a href="/format/2303.11114" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SeiT: Storage-Efficient Vision Training with Tokens Using 1% of Pixel  Storage
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Park%2C+S">Song Park</a>, 
<a href="/search/cs?searchtype=author&query=Chun%2C+S">Sanghyuk Chun</a>, 
<a href="/search/cs?searchtype=author&query=Heo%2C+B">Byeongho Heo</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+W">Wonjae Kim</a>, 
<a href="/search/cs?searchtype=author&query=Yun%2C+S">Sangdoo Yun</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ICCV 2023; First two authors contributed equally; code url: <a href="https://github.com/naver-ai/seit">this https URL</a>; 17 pages, 1.2MB
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item706">[706]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.11989" title="Abstract">arXiv:2303.11989</a> (replaced) [<a href="/pdf/2303.11989" title="Download PDF">pdf</a>, <a href="/format/2303.11989" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Text2Room: Extracting Textured 3D Meshes from 2D Text-to-Image Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=H%C3%B6llein%2C+L">Lukas H&#xf6;llein</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+A">Ang Cao</a>, 
<a href="/search/cs?searchtype=author&query=Owens%2C+A">Andrew Owens</a>, 
<a href="/search/cs?searchtype=author&query=Johnson%2C+J">Justin Johnson</a>, 
<a href="/search/cs?searchtype=author&query=Nie%C3%9Fner%2C+M">Matthias Nie&#xdf;ner</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to ICCV 2023 (Oral) video: <a href="https://youtu.be/fjRnFL91EZc">this https URL</a> project page: <a href="https://lukashoel.github.io/text-to-room/">this https URL</a> code: <a href="https://github.com/lukasHoel/text2room">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item707">[707]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.12074" title="Abstract">arXiv:2303.12074</a> (replaced) [<a href="/pdf/2303.12074" title="Download PDF">pdf</a>, <a href="/format/2303.12074" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CC3D: Layout-Conditioned Generation of Compositional 3D Scenes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bahmani%2C+S">Sherwin Bahmani</a>, 
<a href="/search/cs?searchtype=author&query=Park%2C+J+J">Jeong Joon Park</a>, 
<a href="/search/cs?searchtype=author&query=Paschalidou%2C+D">Despoina Paschalidou</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+X">Xingguang Yan</a>, 
<a href="/search/cs?searchtype=author&query=Wetzstein%2C+G">Gordon Wetzstein</a>, 
<a href="/search/cs?searchtype=author&query=Guibas%2C+L">Leonidas Guibas</a>, 
<a href="/search/cs?searchtype=author&query=Tagliasacchi%2C+A">Andrea Tagliasacchi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ICCV 2023; Webpage: <a href="https://sherwinbahmani.github.io/cc3d/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item708">[708]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.12118" title="Abstract">arXiv:2303.12118</a> (replaced) [<a href="/pdf/2303.12118" title="Download PDF">pdf</a>, <a href="/format/2303.12118" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Examining the Impact of Provenance-Enabled Media on Trust and Accuracy  Perceptions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Feng%2C+K+J+K">K. J. Kevin Feng</a>, 
<a href="/search/cs?searchtype=author&query=Ritchie%2C+N">Nick Ritchie</a>, 
<a href="/search/cs?searchtype=author&query=Blumenthal%2C+P">Pia Blumenthal</a>, 
<a href="/search/cs?searchtype=author&query=Parsons%2C+A">Andy Parsons</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+A+X">Amy X. Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to CSCW 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Social and Information Networks (cs.SI)

</div>
</div>
</dd>
<dt><a name="item709">[709]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.13405" title="Abstract">arXiv:2303.13405</a> (replaced) [<a href="/pdf/2303.13405" title="Download PDF">pdf</a>, <a href="/format/2303.13405" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SC-MIL: Supervised Contrastive Multiple Instance Learning for Imbalanced  Classification in Pathology
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Juyal%2C+D">Dinkar Juyal</a>, 
<a href="/search/cs?searchtype=author&query=Shingi%2C+S">Siddhant Shingi</a>, 
<a href="/search/cs?searchtype=author&query=Javed%2C+S+A">Syed Ashar Javed</a>, 
<a href="/search/cs?searchtype=author&query=Padigela%2C+H">Harshith Padigela</a>, 
<a href="/search/cs?searchtype=author&query=Shah%2C+C">Chintan Shah</a>, 
<a href="/search/cs?searchtype=author&query=Sampat%2C+A">Anand Sampat</a>, 
<a href="/search/cs?searchtype=author&query=Khosla%2C+A">Archit Khosla</a>, 
<a href="/search/cs?searchtype=author&query=Abel%2C+J">John Abel</a>, 
<a href="/search/cs?searchtype=author&query=Taylor-Weiner%2C+A">Amaro Taylor-Weiner</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item710">[710]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.14612" title="Abstract">arXiv:2303.14612</a> (replaced) [<a href="/pdf/2303.14612" title="Download PDF">pdf</a>, <a href="/format/2303.14612" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deepfake in the Metaverse: Security Implications for Virtual Gaming,  Meetings, and Offices
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tariq%2C+S">Shahroz Tariq</a>, 
<a href="/search/cs?searchtype=author&query=Abuadbba%2C+A">Alsharif Abuadbba</a>, 
<a href="/search/cs?searchtype=author&query=Moore%2C+K">Kristen Moore</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 3 pages. Published to ACM ASIACCS 2023 workshop - The 2nd security implications of Deepfakes and Cheapfakes
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item711">[711]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.14623" title="Abstract">arXiv:2303.14623</a> (replaced) [<a href="/pdf/2303.14623" title="Download PDF">pdf</a>, <a href="/format/2303.14623" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Inverse Reinforcement Learning without Reinforcement Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Swamy%2C+G">Gokul Swamy</a>, 
<a href="/search/cs?searchtype=author&query=Choudhury%2C+S">Sanjiban Choudhury</a>, 
<a href="/search/cs?searchtype=author&query=Bagnell%2C+J+A">J. Andrew Bagnell</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Z+S">Zhiwei Steven Wu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item712">[712]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.16774" title="Abstract">arXiv:2303.16774</a> (replaced) [<a href="/pdf/2303.16774" title="Download PDF">pdf</a>, <a href="/format/2303.16774" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Polarization and multiscale structural balance in signed networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Talaga%2C+S">Szymon Talaga</a>, 
<a href="/search/physics?searchtype=author&query=Stella%2C+M">Massimo Stella</a>, 
<a href="/search/physics?searchtype=author&query=Swanson%2C+T+J">Trevor James Swanson</a>, 
<a href="/search/physics?searchtype=author&query=Teixeira%2C+A+S">Andreia Sofia Teixeira</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 35 pages; 10 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Physics and Society (physics.soc-ph)</span>; Social and Information Networks (cs.SI)

</div>
</div>
</dd>
<dt><a name="item713">[713]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.17086" title="Abstract">arXiv:2303.17086</a> (replaced) [<a href="/pdf/2303.17086" title="Download PDF">pdf</a>, <a href="/ps/2303.17086" title="Download PostScript">ps</a>, <a href="/format/2303.17086" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Modularized Control Synthesis for Complex Signal Temporal Logic  Specifications
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Zhang%2C+Z">Zengjie Zhang</a>, 
<a href="/search/eess?searchtype=author&query=Haesaert%2C+S">Sofie Haesaert</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
</div>
</dd>
<dt><a name="item714">[714]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.17155" title="Abstract">arXiv:2303.17155</a> (replaced) [<a href="/pdf/2303.17155" title="Download PDF">pdf</a>, <a href="/format/2303.17155" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Discriminative Class Tokens for Text-to-Image Diffusion Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Schwartz%2C+I">Idan Schwartz</a>, 
<a href="/search/cs?searchtype=author&query=Sn%C3%A6bjarnarson%2C+V">V&#xe9;steinn Sn&#xe6;bjarnarson</a>, 
<a href="/search/cs?searchtype=author&query=Chefer%2C+H">Hila Chefer</a>, 
<a href="/search/cs?searchtype=author&query=Cotterell%2C+R">Ryan Cotterell</a>, 
<a href="/search/cs?searchtype=author&query=Belongie%2C+S">Serge Belongie</a>, 
<a href="/search/cs?searchtype=author&query=Wolf%2C+L">Lior Wolf</a>, 
<a href="/search/cs?searchtype=author&query=Benaim%2C+S">Sagie Benaim</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ICCV 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item715">[715]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.17368" title="Abstract">arXiv:2303.17368</a> (replaced) [<a href="/pdf/2303.17368" title="Download PDF">pdf</a>, <a href="/format/2303.17368" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SynBody: Synthetic Dataset with Layered Human Models for 3D Human  Perception and Modeling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+Z">Zhitao Yang</a>, 
<a href="/search/cs?searchtype=author&query=Cai%2C+Z">Zhongang Cai</a>, 
<a href="/search/cs?searchtype=author&query=Mei%2C+H">Haiyi Mei</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+S">Shuai Liu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Z">Zhaoxi Chen</a>, 
<a href="/search/cs?searchtype=author&query=Xiao%2C+W">Weiye Xiao</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+Y">Yukun Wei</a>, 
<a href="/search/cs?searchtype=author&query=Qing%2C+Z">Zhongfei Qing</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+C">Chen Wei</a>, 
<a href="/search/cs?searchtype=author&query=Dai%2C+B">Bo Dai</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+W">Wayne Wu</a>, 
<a href="/search/cs?searchtype=author&query=Qian%2C+C">Chen Qian</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+D">Dahua Lin</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Ziwei Liu</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+L">Lei Yang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by ICCV 2023. Project webpage: <a href="https://synbody.github.io/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item716">[716]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.00372" title="Abstract">arXiv:2304.00372</a> (replaced) [<a href="/pdf/2304.00372" title="Download PDF">pdf</a>, <a href="/format/2304.00372" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Auxiliary-Variable Adaptive Control Barrier Functions for Safety  Critical Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Liu%2C+S">Shuo Liu</a>, 
<a href="/search/math?searchtype=author&query=Xiao%2C+W">Wei Xiao</a>, 
<a href="/search/math?searchtype=author&query=Belta%2C+C+A">Calin A. Belta</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 4 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Robotics (cs.RO); Systems and Control (eess.SY); Dynamical Systems (math.DS)

</div>
</div>
</dd>
<dt><a name="item717">[717]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.00790" title="Abstract">arXiv:2304.00790</a> (replaced) [<a href="/pdf/2304.00790" title="Download PDF">pdf</a>, <a href="/format/2304.00790" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Efficient LQR-CBF-RRT*: Safe and Optimal Motion Planning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+G">Guang Yang</a>, 
<a href="/search/cs?searchtype=author&query=Cai%2C+M">Mingyu Cai</a>, 
<a href="/search/cs?searchtype=author&query=Ahmad%2C+A">Ahmad Ahmad</a>, 
<a href="/search/cs?searchtype=author&query=Prorok%2C+A">Amanda Prorok</a>, 
<a href="/search/cs?searchtype=author&query=Belta%2C+C">Calin Belta</a>, 
<a href="/search/cs?searchtype=author&query=Tron%2C+R">Roberto Tron</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Systems and Control (eess.SY)

</div>
</div>
</dd>
<dt><a name="item718">[718]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.01395" title="Abstract">arXiv:2304.01395</a> (replaced) [<a href="/pdf/2304.01395" title="Download PDF">pdf</a>, <a href="/ps/2304.01395" title="Download PostScript">ps</a>, <a href="/format/2304.01395" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning Personalized Models with Clustered System Identification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Toso%2C+L+F">Leonardo F. Toso</a>, 
<a href="/search/math?searchtype=author&query=Wang%2C+H">Han Wang</a>, 
<a href="/search/math?searchtype=author&query=Anderson%2C+J">James Anderson</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Machine Learning (cs.LG); Systems and Control (eess.SY)

</div>
</div>
</dd>
<dt><a name="item719">[719]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.02129" title="Abstract">arXiv:2304.02129</a> (replaced) [<a href="/pdf/2304.02129" title="Download PDF">pdf</a>, <a href="/format/2304.02129" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Proprioception and reaction for walking among entanglements
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yim%2C+J+K">Justin K. Yim</a>, 
<a href="/search/cs?searchtype=author&query=Ren%2C+J">Jiming Ren</a>, 
<a href="/search/cs?searchtype=author&query=Ologan%2C+D">David Ologan</a>, 
<a href="/search/cs?searchtype=author&query=Gonzalez%2C+S+G">Selvin Garcia Gonzalez</a>, 
<a href="/search/cs?searchtype=author&query=Johnson%2C+A+M">Aaron M. Johnson</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 2023 IEEE/RSJ International Conference on Intelligent Robots and Systems
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
</div>
</dd>
<dt><a name="item720">[720]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.04321" title="Abstract">arXiv:2304.04321</a> (replaced) [<a href="/pdf/2304.04321" title="Download PDF">pdf</a>, <a href="/format/2304.04321" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ARNOLD: A Benchmark for Language-Grounded Task Learning With Continuous  States in Realistic 3D Scenes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gong%2C+R">Ran Gong</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+J">Jiangyong Huang</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Y">Yizhou Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Geng%2C+H">Haoran Geng</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+X">Xiaofeng Gao</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Q">Qingyang Wu</a>, 
<a href="/search/cs?searchtype=author&query=Ai%2C+W">Wensi Ai</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Z">Ziheng Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Terzopoulos%2C+D">Demetri Terzopoulos</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+S">Song-Chun Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Jia%2C+B">Baoxiong Jia</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+S">Siyuan Huang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> The first two authors contributed equally; 20 pages; 17 figures; project availalbe: <a href="https://arnold-benchmark.github.io/">this https URL</a> ICCV 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computation and Language (cs.CL); Computer Vision and Pattern Recognition (cs.CV); Robotics (cs.RO)

</div>
</div>
</dd>
<dt><a name="item721">[721]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.04505" title="Abstract">arXiv:2304.04505</a> (replaced) [<a href="/pdf/2304.04505" title="Download PDF">pdf</a>, <a href="/format/2304.04505" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Inner approximations of stochastic programs for data-driven stochastic  barrier function design
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Mathiesen%2C+F+B">Frederik Baymler Mathiesen</a>, 
<a href="/search/eess?searchtype=author&query=Romao%2C+L">Licio Romao</a>, 
<a href="/search/eess?searchtype=author&query=Calvert%2C+S+C">Simeon C. Calvert</a>, 
<a href="/search/eess?searchtype=author&query=Abate%2C+A">Alessandro Abate</a>, 
<a href="/search/eess?searchtype=author&query=Laurenti%2C+L">Luca Laurenti</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
</div>
</dd>
<dt><a name="item722">[722]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.04939" title="Abstract">arXiv:2304.04939</a> (replaced) [<a href="/pdf/2304.04939" title="Download PDF">pdf</a>, <a href="/format/2304.04939" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Universal dual-port grid-forming control: bridging the gap between  grid-forming and grid-following control
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Suboti%C4%87%2C+I">Irina Suboti&#x107;</a>, 
<a href="/search/eess?searchtype=author&query=Gro%C3%9F%2C+a+D">and Dominic Gro&#xdf;</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
</div>
</dd>
<dt><a name="item723">[723]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.06197" title="Abstract">arXiv:2304.06197</a> (replaced) [<a href="/pdf/2304.06197" title="Download PDF">pdf</a>, <a href="/format/2304.06197" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SURFSUP: Learning Fluid Simulation for Novel Surfaces
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mani%2C+A">Arjun Mani</a>, 
<a href="/search/cs?searchtype=author&query=Chandratreya%2C+I+P">Ishaan Preetam Chandratreya</a>, 
<a href="/search/cs?searchtype=author&query=Creager%2C+E">Elliot Creager</a>, 
<a href="/search/cs?searchtype=author&query=Vondrick%2C+C">Carl Vondrick</a>, 
<a href="/search/cs?searchtype=author&query=Zemel%2C+R">Richard Zemel</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Website: <a href="https://surfsup.cs.columbia.edu/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Fluid Dynamics (physics.flu-dyn)

</div>
</div>
</dd>
<dt><a name="item724">[724]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.06619" title="Abstract">arXiv:2304.06619</a> (replaced) [<a href="/pdf/2304.06619" title="Download PDF">pdf</a>, <a href="/format/2304.06619" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Class-Incremental Learning of Plant and Disease Detection: Growing  Branches with Knowledge Distillation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fortin%2C+M+P">Mathieu Pag&#xe9; Fortin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at CVPPA'23
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item725">[725]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.06977" title="Abstract">arXiv:2304.06977</a> (replaced) [<a href="/pdf/2304.06977" title="Download PDF">pdf</a>, <a href="/format/2304.06977" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DeePoint: Visual Pointing Recognition and Direction Estimation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nakamura%2C+S">Shu Nakamura</a>, 
<a href="/search/cs?searchtype=author&query=Kawanishi%2C+Y">Yasutomo Kawanishi</a>, 
<a href="/search/cs?searchtype=author&query=Nobuhara%2C+S">Shohei Nobuhara</a>, 
<a href="/search/cs?searchtype=author&query=Nishino%2C+K">Ko Nishino</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> to be published in ICCV 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item726">[726]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.07037" title="Abstract">arXiv:2304.07037</a> (replaced) [<a href="/pdf/2304.07037" title="Download PDF">pdf</a>, <a href="/format/2304.07037" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> No Easy Way Out: the Effectiveness of Deplatforming an Extremist Forum  to Suppress Hate and Harassment
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Vu%2C+A+V">Anh V. Vu</a>, 
<a href="/search/cs?searchtype=author&query=Hutchings%2C+A">Alice Hutchings</a>, 
<a href="/search/cs?searchtype=author&query=Anderson%2C+R">Ross Anderson</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Computers and Society (cs.CY)

</div>
</div>
</dd>
<dt><a name="item727">[727]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.07619" title="Abstract">arXiv:2304.07619</a> (replaced) [<a href="/pdf/2304.07619" title="Download PDF">pdf</a>, <a href="/format/2304.07619" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Can ChatGPT Forecast Stock Price Movements? Return Predictability and  Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-fin?searchtype=author&query=Lopez-Lira%2C+A">Alejandro Lopez-Lira</a>, 
<a href="/search/q-fin?searchtype=author&query=Tang%2C+Y">Yuehua Tang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Previously posted in SSRN <a href="https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4412788">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Statistical Finance (q-fin.ST)</span>; Computation and Language (cs.CL)

</div>
</div>
</dd>
<dt><a name="item728">[728]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.08267" title="Abstract">arXiv:2304.08267</a> (replaced) [<a href="/pdf/2304.08267" title="Download PDF">pdf</a>, <a href="/ps/2304.08267" title="Download PostScript">ps</a>, <a href="/format/2304.08267" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Structural Subtyping as Parametric Polymorphism
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tang%2C+W">Wenhao Tang</a>, 
<a href="/search/cs?searchtype=author&query=Hillerstr%C3%B6m%2C+D">Daniel Hillerstr&#xf6;m</a>, 
<a href="/search/cs?searchtype=author&query=McKinna%2C+J">James McKinna</a>, 
<a href="/search/cs?searchtype=author&query=Steuwer%2C+M">Michel Steuwer</a>, 
<a href="/search/cs?searchtype=author&query=Dardha%2C+O">Ornela Dardha</a>, 
<a href="/search/cs?searchtype=author&query=Fu%2C+R">Rongxiao Fu</a>, 
<a href="/search/cs?searchtype=author&query=Lindley%2C+S">Sam Lindley</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 47 pages, accepted by OOPSLA 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Programming Languages (cs.PL)</span>

</div>
</div>
</dd>
<dt><a name="item729">[729]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.08495" title="Abstract">arXiv:2304.08495</a> (replaced) [<a href="/e-print/2304.08495" title="Download source">src</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Optimizing Group Utility in Itinerary Planning: A Strategic and  Crowd-Aware Approach
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Junhua Liu</a>, 
<a href="/search/cs?searchtype=author&query=Lim%2C+K+H">Kwan Hui Lim</a>, 
<a href="/search/cs?searchtype=author&query=Wood%2C+K+L">Kristin L. Wood</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+M">Menglin Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Will be going through major revision
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Multiagent Systems (cs.MA)

</div>
</div>
</dd>
<dt><a name="item730">[730]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.10711" title="Abstract">arXiv:2304.10711</a> (replaced) [<a href="/pdf/2304.10711" title="Download PDF">pdf</a>, <a href="/format/2304.10711" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> EulerNet: Adaptive Feature Interaction Learning via Euler&#x27;s Formula for  CTR Prediction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tian%2C+Z">Zhen Tian</a>, 
<a href="/search/cs?searchtype=author&query=Bai%2C+T">Ting Bai</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+W+X">Wayne Xin Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Wen%2C+J">Ji-Rong Wen</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+Z">Zhao Cao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 7 figures, accepted for publication in SIGIR'23
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>

</div>
</div>
</dd>
<dt><a name="item731">[731]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.10749" title="Abstract">arXiv:2304.10749</a> (replaced) [<a href="/pdf/2304.10749" title="Download PDF">pdf</a>, <a href="/format/2304.10749" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multi-scale Evolutionary Neural Architecture Search for Deep Spiking  Neural Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pan%2C+W">Wenxuan Pan</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+F">Feifei Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+G">Guobin Shen</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+B">Bing Han</a>, 
<a href="/search/cs?searchtype=author&query=Zeng%2C+Y">Yi Zeng</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neural and Evolutionary Computing (cs.NE)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item732">[732]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.12635" title="Abstract">arXiv:2304.12635</a> (replaced) [<a href="/pdf/2304.12635" title="Download PDF">pdf</a>, <a href="/format/2304.12635" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LMSFC: A Novel Multidimensional Index based on Learned Monotonic Space  Filling Curves
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gao%2C+J">Jian Gao</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+X">Xin Cao</a>, 
<a href="/search/cs?searchtype=author&query=Yao%2C+X">Xin Yao</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+G">Gong Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+W">Wei Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Extended Version. Accepted by VLDB 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Databases (cs.DB)</span>

</div>
</div>
</dd>
<dt><a name="item733">[733]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.13000" title="Abstract">arXiv:2304.13000</a> (replaced) [<a href="/pdf/2304.13000" title="Download PDF">pdf</a>, <a href="/format/2304.13000" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Segment anything, from space?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ren%2C+S">Simiao Ren</a>, 
<a href="/search/cs?searchtype=author&query=Luzi%2C+F">Francesco Luzi</a>, 
<a href="/search/cs?searchtype=author&query=Lahrichi%2C+S">Saad Lahrichi</a>, 
<a href="/search/cs?searchtype=author&query=Kassaw%2C+K">Kaleb Kassaw</a>, 
<a href="/search/cs?searchtype=author&query=Collins%2C+L+M">Leslie M. Collins</a>, 
<a href="/search/cs?searchtype=author&query=Bradbury%2C+K">Kyle Bradbury</a>, 
<a href="/search/cs?searchtype=author&query=Malof%2C+J+M">Jordan M. Malof</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Image and Video Processing (eess.IV)

</div>
</div>
</dd>
<dt><a name="item734">[734]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.14298" title="Abstract">arXiv:2304.14298</a> (replaced) [<a href="/pdf/2304.14298" title="Download PDF">pdf</a>, <a href="/format/2304.14298" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Instance Segmentation in the Dark
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+L">Linwei Chen</a>, 
<a href="/search/cs?searchtype=author&query=Fu%2C+Y">Ying Fu</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+K">Kaixuan Wei</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+D">Dezhi Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Heide%2C+F">Felix Heide</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by International Journal of Computer Vision (IJCV) 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item735">[735]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.04032" title="Abstract">arXiv:2305.04032</a> (replaced) [<a href="/pdf/2305.04032" title="Download PDF">pdf</a>, <a href="/format/2305.04032" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ToolCoder: Teach Code Generation Models to use API search tools
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+K">Kechi Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Huangzhao Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+G">Ge Li</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jia Li</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zhuo Li</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+Z">Zhi Jin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
</div>
</dd>
<dt><a name="item736">[736]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.04081" title="Abstract">arXiv:2305.04081</a> (replaced) [<a href="/pdf/2305.04081" title="Download PDF">pdf</a>, <a href="/format/2305.04081" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Portfolio-Based Incentive Mechanism Design for Cross-Device Federated  Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+J">Jiaxi Yang</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+S">Sheng Cao</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+C">Cuifang Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Niu%2C+W">Weina Niu</a>, 
<a href="/search/cs?searchtype=author&query=Tsai%2C+L">Li-Chuan Tsai</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>

</div>
</div>
</dd>
<dt><a name="item737">[737]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.04087" title="Abstract">arXiv:2305.04087</a> (replaced) [<a href="/pdf/2305.04087" title="Download PDF">pdf</a>, <a href="/format/2305.04087" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Self-Edit: Fault-Aware Code Editor for Code Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+K">Kechi Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zhuo Li</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jia Li</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+G">Ge Li</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+Z">Zhi Jin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by ACL2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>; Computation and Language (cs.CL)

</div>
</div>
</dd>
<dt><a name="item738">[738]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.04151" title="Abstract">arXiv:2305.04151</a> (replaced) [<a href="/pdf/2305.04151" title="Download PDF">pdf</a>, <a href="/format/2305.04151" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Context-Aware Chart Element Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yan%2C+P">Pengyu Yan</a>, 
<a href="/search/cs?searchtype=author&query=Ahmed%2C+S">Saleem Ahmed</a>, 
<a href="/search/cs?searchtype=author&query=Doermann%2C+D">David Doermann</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Published in ICDAR 2023. Code and model are available at <a href="https://github.com/pengyu965/ChartDete">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item739">[739]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.04940" title="Abstract">arXiv:2305.04940</a> (replaced) [<a href="/pdf/2305.04940" title="Download PDF">pdf</a>, <a href="/format/2305.04940" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The EarlyBIRD Catches the Bug: On Exploiting Early Layers of Encoder  Models for More Efficient Code Classification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Grishina%2C+A">Anastasiia Grishina</a>, 
<a href="/search/cs?searchtype=author&query=Hort%2C+M">Max Hort</a>, 
<a href="/search/cs?searchtype=author&query=Moonen%2C+L">Leon Moonen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> The content in this pre-print is the same as in the CRC accepted for publication in the ACM Joint European Software Engineering Conference and Symposium on the Foundations of Software Engineering (ESEC/FSE 2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item740">[740]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.05294" title="Abstract">arXiv:2305.05294</a> (replaced) [<a href="/pdf/2305.05294" title="Download PDF">pdf</a>, <a href="/format/2305.05294" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Construction of Control Barrier Functions Using Predictions with Finite  Horizon
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Wiltz%2C+A">Adrian Wiltz</a>, 
<a href="/search/eess?searchtype=author&query=Tan%2C+X">Xiao Tan</a>, 
<a href="/search/eess?searchtype=author&query=Dimarogonas%2C+D+V">Dimos V. Dimarogonas</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, accepted for publication at IEEE CDC 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
</div>
</dd>
<dt><a name="item741">[741]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.05411" title="Abstract">arXiv:2305.05411</a> (replaced) [<a href="/pdf/2305.05411" title="Download PDF">pdf</a>, <a href="/ps/2305.05411" title="Download PostScript">ps</a>, <a href="/format/2305.05411" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> 4/3-Approximation of Graphic TSP
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=%C3%87ivril%2C+A">Ali &#xc7;ivril</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, decomposition specified more carefully, Lemma 3 (now Lemma 2) corrected
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>

</div>
</div>
</dd>
<dt><a name="item742">[742]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.06480" title="Abstract">arXiv:2305.06480</a> (replaced) [<a href="/pdf/2305.06480" title="Download PDF">pdf</a>, <a href="/format/2305.06480" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ST-GIN: An Uncertainty Quantification Approach in Traffic Data  Imputation with Spatio-temporal Graph Attention and Bidirectional Recurrent  United Neural Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zepu Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhuang%2C+D">Dingyi Zhuang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yankai Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+J">Jinhua Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+P">Peng Sun</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Shenhao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+Y">Yulin Hu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by IEEE-ITSC 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item743">[743]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.07247" title="Abstract">arXiv:2305.07247</a> (replaced) [<a href="/pdf/2305.07247" title="Download PDF">pdf</a>, <a href="/format/2305.07247" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Provably Convergent Schr&#xf6;dinger Bridge with Applications to  Probabilistic Time Series Imputation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yu Chen</a>, 
<a href="/search/cs?searchtype=author&query=Deng%2C+W">Wei Deng</a>, 
<a href="/search/cs?searchtype=author&query=Fang%2C+S">Shikai Fang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+F">Fengpei Li</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+N+T">Nicole Tianjiao Yang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yikai Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Rasul%2C+K">Kashif Rasul</a>, 
<a href="/search/cs?searchtype=author&query=Zhe%2C+S">Shandian Zhe</a>, 
<a href="/search/cs?searchtype=author&query=Schneider%2C+A">Anderson Schneider</a>, 
<a href="/search/cs?searchtype=author&query=Nevmyvaka%2C+Y">Yuriy Nevmyvaka</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by ICML 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item744">[744]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.08455" title="Abstract">arXiv:2305.08455</a> (replaced) [<a href="/pdf/2305.08455" title="Download PDF">pdf</a>, <a href="/format/2305.08455" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Document Understanding Dataset and Evaluation (DUDE)
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Van+Landeghem%2C+J">Jordy Van Landeghem</a>, 
<a href="/search/cs?searchtype=author&query=Tito%2C+R">Rub&#xe9;n Tito</a>, 
<a href="/search/cs?searchtype=author&query=Borchmann%2C+%C5%81">&#x141;ukasz Borchmann</a>, 
<a href="/search/cs?searchtype=author&query=Pietruszka%2C+M">Micha&#x142; Pietruszka</a>, 
<a href="/search/cs?searchtype=author&query=J%C3%B3ziak%2C+P">Pawe&#x142; J&#xf3;ziak</a>, 
<a href="/search/cs?searchtype=author&query=Powalski%2C+R">Rafa&#x142; Powalski</a>, 
<a href="/search/cs?searchtype=author&query=Jurkiewicz%2C+D">Dawid Jurkiewicz</a>, 
<a href="/search/cs?searchtype=author&query=Coustaty%2C+M">Micka&#xeb;l Coustaty</a>, 
<a href="/search/cs?searchtype=author&query=Ackaert%2C+B">Bertrand Ackaert</a>, 
<a href="/search/cs?searchtype=author&query=Valveny%2C+E">Ernest Valveny</a>, 
<a href="/search/cs?searchtype=author&query=Blaschko%2C+M">Matthew Blaschko</a>, 
<a href="/search/cs?searchtype=author&query=Moens%2C+S">Sien Moens</a>, 
<a href="/search/cs?searchtype=author&query=Stanis%C5%82awek%2C+T">Tomasz Stanis&#x142;awek</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at ICCV 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Computation and Language (cs.CL); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item745">[745]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.10761" title="Abstract">arXiv:2305.10761</a> (replaced) [<a href="/pdf/2305.10761" title="Download PDF">pdf</a>, <a href="/format/2305.10761" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Noise-Aware Speech Separation with Contrastive Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zizheng Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+C">Chen Chen</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+H">Hsin-Hung Chen</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xiang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+Y">Yuchen Hu</a>, 
<a href="/search/cs?searchtype=author&query=Chng%2C+E+S">Eng Siong Chng</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Audio and Speech Processing (eess.AS)

</div>
</div>
</dd>
<dt><a name="item746">[746]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.11290" title="Abstract">arXiv:2305.11290</a> (replaced) [<a href="/pdf/2305.11290" title="Download PDF">pdf</a>, <a href="/format/2305.11290" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Massively Scalable Inverse Reinforcement Learning in Google Maps
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Barnes%2C+M">Matt Barnes</a>, 
<a href="/search/cs?searchtype=author&query=Abueg%2C+M">Matthew Abueg</a>, 
<a href="/search/cs?searchtype=author&query=Lange%2C+O+F">Oliver F. Lange</a>, 
<a href="/search/cs?searchtype=author&query=Deeds%2C+M">Matt Deeds</a>, 
<a href="/search/cs?searchtype=author&query=Trader%2C+J">Jason Trader</a>, 
<a href="/search/cs?searchtype=author&query=Molitor%2C+D">Denali Molitor</a>, 
<a href="/search/cs?searchtype=author&query=Wulfmeier%2C+M">Markus Wulfmeier</a>, 
<a href="/search/cs?searchtype=author&query=O%27Banion%2C+S">Shawn O&#x27;Banion</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item747">[747]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.13065" title="Abstract">arXiv:2305.13065</a> (replaced) [<a href="/pdf/2305.13065" title="Download PDF">pdf</a>, <a href="/format/2305.13065" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On improving the efficiency of ADER methods
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Veiga%2C+M+H">Maria Han Veiga</a>, 
<a href="/search/math?searchtype=author&query=Micalizzi%2C+L">Lorenzo Micalizzi</a>, 
<a href="/search/math?searchtype=author&query=Torlo%2C+D">Davide Torlo</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
</div>
</dd>
<dt><a name="item748">[748]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.13248" title="Abstract">arXiv:2305.13248</a> (replaced) [<a href="/pdf/2305.13248" title="Download PDF">pdf</a>, <a href="/format/2305.13248" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Bayesian Numerical Integration with Neural Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Ott%2C+K">Katharina Ott</a>, 
<a href="/search/stat?searchtype=author&query=Tiemann%2C+M">Michael Tiemann</a>, 
<a href="/search/stat?searchtype=author&query=Hennig%2C+P">Philipp Hennig</a>, 
<a href="/search/stat?searchtype=author&query=Briol%2C+F">Fran&#xe7;ois-Xavier Briol</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> PMLR 216:1606-1617, 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item749">[749]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.15070" title="Abstract">arXiv:2305.15070</a> (replaced) [<a href="/pdf/2305.15070" title="Download PDF">pdf</a>, <a href="/format/2305.15070" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Annotation Imputation to Individualize Predictions: Initial Studies on  Distribution Dynamics and Model Predictions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lowmanstone%2C+L">London Lowmanstone</a>, 
<a href="/search/cs?searchtype=author&query=Wan%2C+R">Ruyuan Wan</a>, 
<a href="/search/cs?searchtype=author&query=Owan%2C+R">Risako Owan</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+J">Jaehyung Kim</a>, 
<a href="/search/cs?searchtype=author&query=Kang%2C+D">Dongyeop Kang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> NLPerspectives 2023 Conference, 39 pages, 13 figures, 13 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item750">[750]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.15277" title="Abstract">arXiv:2305.15277</a> (replaced) [<a href="/pdf/2305.15277" title="Download PDF">pdf</a>, <a href="/format/2305.15277" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Successor-Predecessor Intrinsic Exploration
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yu%2C+C">Changmin Yu</a>, 
<a href="/search/cs?searchtype=author&query=Burgess%2C+N">Neil Burgess</a>, 
<a href="/search/cs?searchtype=author&query=Sahani%2C+M">Maneesh Sahani</a>, 
<a href="/search/cs?searchtype=author&query=Gershman%2C+S">Sam Gershman</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item751">[751]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.15775" title="Abstract">arXiv:2305.15775</a> (replaced) [<a href="/pdf/2305.15775" title="Download PDF">pdf</a>, <a href="/format/2305.15775" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Concept-Centric Transformers: Enhancing Model Interpretability through  Object-Centric Concept Learning within a Shared Global Workspace
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hong%2C+J">Jinyung Hong</a>, 
<a href="/search/cs?searchtype=author&query=Park%2C+K+H">Keun Hee Park</a>, 
<a href="/search/cs?searchtype=author&query=Pavlic%2C+T+P">Theodore P. Pavlic</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 21 pages, 9 tables, 13 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item752">[752]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.16325" title="Abstract">arXiv:2305.16325</a> (replaced) [<a href="/pdf/2305.16325" title="Download PDF">pdf</a>, <a href="/format/2305.16325" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Graph Neural Network Interatomic Potential Ensembles with Calibrated  Aleatoric and Epistemic Uncertainty on Energy and Forces
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Busk%2C+J">Jonas Busk</a>, 
<a href="/search/physics?searchtype=author&query=Schmidt%2C+M+N">Mikkel N. Schmidt</a>, 
<a href="/search/physics?searchtype=author&query=Winther%2C+O">Ole Winther</a>, 
<a href="/search/physics?searchtype=author&query=Vegge%2C+T">Tejs Vegge</a>, 
<a href="/search/physics?searchtype=author&query=J%C3%B8rgensen%2C+P+B">Peter Bj&#xf8;rn J&#xf8;rgensen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Chemical Physics (physics.chem-ph)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item753">[753]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.17256" title="Abstract">arXiv:2305.17256</a> (replaced) [<a href="/pdf/2305.17256" title="Download PDF">pdf</a>, <a href="/format/2305.17256" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Large Language Models Can be Lazy Learners: Analyze Shortcuts in  In-Context Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tang%2C+R">Ruixiang Tang</a>, 
<a href="/search/cs?searchtype=author&query=Kong%2C+D">Dehan Kong</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+L">Longtao Huang</a>, 
<a href="/search/cs?searchtype=author&query=Xue%2C+H">Hui Xue</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item754">[754]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.18365" title="Abstract">arXiv:2305.18365</a> (replaced) [<a href="/pdf/2305.18365" title="Download PDF">pdf</a>, <a href="/format/2305.18365" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> What can Large Language Models do in chemistry? A comprehensive  benchmark on eight tasks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Guo%2C+T">Taicheng Guo</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+K">Kehan Guo</a>, 
<a href="/search/cs?searchtype=author&query=Nan%2C+B">Bozhao Nan</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+Z">Zhenwen Liang</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+Z">Zhichun Guo</a>, 
<a href="/search/cs?searchtype=author&query=Chawla%2C+N+V">Nitesh V. Chawla</a>, 
<a href="/search/cs?searchtype=author&query=Wiest%2C+O">Olaf Wiest</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xiangliang Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Add extra LLMs experiments; more baselines and more investigations on SELFIES, label interpretation, etc
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item755">[755]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.18928" title="Abstract">arXiv:2305.18928</a> (replaced) [<a href="/pdf/2305.18928" title="Download PDF">pdf</a>, <a href="/format/2305.18928" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Reviewing BPMN as a Modeling Notation for CACAO Security Playbooks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zych%2C+M">Mateusz Zych</a>, 
<a href="/search/cs?searchtype=author&query=Mavroeidis%2C+V">Vasileios Mavroeidis</a>, 
<a href="/search/cs?searchtype=author&query=Fysarakis%2C+K">Konstantinos Fysarakis</a>, 
<a href="/search/cs?searchtype=author&query=Athanatos%2C+M">Manos Athanatos</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
</div>
</dd>
<dt><a name="item756">[756]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.19862" title="Abstract">arXiv:2305.19862</a> (replaced) [<a href="/pdf/2305.19862" title="Download PDF">pdf</a>, <a href="/format/2305.19862" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Self-supervised Learning to Bring Dual Reversed Rolling Shutter Images  Alive
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shang%2C+W">Wei Shang</a>, 
<a href="/search/cs?searchtype=author&query=Ren%2C+D">Dongwei Ren</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+C">Chaoyu Feng</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xiaotao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Lei%2C+L">Lei Lei</a>, 
<a href="/search/cs?searchtype=author&query=Zuo%2C+W">Wangmeng Zuo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 pages, 16 figures, available at <a href="https://github.com/shangwei5/SelfDRSC">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item757">[757]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.19958" title="Abstract">arXiv:2305.19958</a> (replaced) [<a href="/pdf/2305.19958" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Analysing high resolution digital Mars images using machine learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/astro-ph?searchtype=author&query=Gerg%C3%A1cz%2C+M">Mira Gerg&#xe1;cz</a>, 
<a href="/search/astro-ph?searchtype=author&query=Kereszturi%2C+%C3%81">&#xc1;kos Kereszturi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Earth and Planetary Astrophysics (astro-ph.EP)</span>; Instrumentation and Methods for Astrophysics (astro-ph.IM); Machine Learning (cs.LG); Image and Video Processing (eess.IV)

</div>
</div>
</dd>
<dt><a name="item758">[758]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.01102" title="Abstract">arXiv:2306.01102</a> (replaced) [<a href="/pdf/2306.01102" title="Download PDF">pdf</a>, <a href="/format/2306.01102" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LLMatic: Neural Architecture Search via Large Language Models and  Quality Diversity Optimization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nasir%2C+M+U">Muhammad U. Nasir</a>, 
<a href="/search/cs?searchtype=author&query=Earle%2C+S">Sam Earle</a>, 
<a href="/search/cs?searchtype=author&query=Togelius%2C+J">Julian Togelius</a>, 
<a href="/search/cs?searchtype=author&query=James%2C+S">Steven James</a>, 
<a href="/search/cs?searchtype=author&query=Cleghorn%2C+C">Christopher Cleghorn</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neural and Evolutionary Computing (cs.NE)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL)

</div>
</div>
</dd>
<dt><a name="item759">[759]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.02253" title="Abstract">arXiv:2306.02253</a> (replaced) [<a href="/pdf/2306.02253" title="Download PDF">pdf</a>, <a href="/ps/2306.02253" title="Download PostScript">ps</a>, <a href="/format/2306.02253" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Tight Cell-Probe Lower Bounds for Dynamic Succinct Dictionaries
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+T">Tianxiao Li</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+J">Jingxun Liang</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+H">Huacheng Yu</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+R">Renfei Zhou</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 38 pages; in FOCS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>; Computational Complexity (cs.CC)

</div>
</div>
</dd>
<dt><a name="item760">[760]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.03825" title="Abstract">arXiv:2306.03825</a> (replaced) [<a href="/pdf/2306.03825" title="Download PDF">pdf</a>, <a href="/format/2306.03825" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Interest-disclosing Mechanisms for Advertising are Privacy-Exposing (not  Preserving)
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Beugin%2C+Y">Yohan Beugin</a>, 
<a href="/search/cs?searchtype=author&query=McDaniel%2C+P">Patrick McDaniel</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> PoPETS (Proceedings on Privacy Enhancing Technologies Symposium) 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
</div>
</dd>
<dt><a name="item761">[761]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.04784" title="Abstract">arXiv:2306.04784</a> (replaced) [<a href="/pdf/2306.04784" title="Download PDF">pdf</a>, <a href="/format/2306.04784" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Framework for Designing Anthropomorphic Soft Hands through Interaction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mannam%2C+P">Pragna Mannam</a>, 
<a href="/search/cs?searchtype=author&query=Shaw%2C+K">Kenneth Shaw</a>, 
<a href="/search/cs?searchtype=author&query=Bauer%2C+D">Dominik Bauer</a>, 
<a href="/search/cs?searchtype=author&query=Oh%2C+J">Jean Oh</a>, 
<a href="/search/cs?searchtype=author&query=Pathak%2C+D">Deepak Pathak</a>, 
<a href="/search/cs?searchtype=author&query=Pollard%2C+N">Nancy Pollard</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
</div>
</dd>
<dt><a name="item762">[762]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.06299" title="Abstract">arXiv:2306.06299</a> (replaced) [<a href="/pdf/2306.06299" title="Download PDF">pdf</a>, <a href="/format/2306.06299" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Front-running Attack in Sharded Blockchains and Fair Cross-shard  Consensus
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jianting Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+W">Wuhui Chen</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+S">Sifu Luo</a>, 
<a href="/search/cs?searchtype=author&query=Gong%2C+T">Tiantian Gong</a>, 
<a href="/search/cs?searchtype=author&query=Hong%2C+Z">Zicong Hong</a>, 
<a href="/search/cs?searchtype=author&query=Kate%2C+A">Aniket Kate</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
</div>
</dd>
<dt><a name="item763">[763]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.06385" title="Abstract">arXiv:2306.06385</a> (replaced) [<a href="/pdf/2306.06385" title="Download PDF">pdf</a>, <a href="/format/2306.06385" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Continually learning out-of-distribution spatiotemporal data for robust  energy forecasting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Prabowo%2C+A">Arian Prabowo</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+K">Kaixuan Chen</a>, 
<a href="/search/cs?searchtype=author&query=Xue%2C+H">Hao Xue</a>, 
<a href="/search/cs?searchtype=author&query=Sethuvenkatraman%2C+S">Subbu Sethuvenkatraman</a>, 
<a href="/search/cs?searchtype=author&query=Salim%2C+F+D">Flora D. Salim</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 15 pages, 3 figures, ECML PKDD ADS 2023. 2023 09 09 edit: repeated column in tab 3. in previous version
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item764">[764]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.06622" title="Abstract">arXiv:2306.06622</a> (replaced) [<a href="/pdf/2306.06622" title="Download PDF">pdf</a>, <a href="/format/2306.06622" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Weakly Supervised Visual Question Answer Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Alampalle%2C+C">Charani Alampalle</a>, 
<a href="/search/cs?searchtype=author&query=Hegde%2C+S">Shamanthak Hegde</a>, 
<a href="/search/cs?searchtype=author&query=Jahagirdar%2C+S">Soumya Jahagirdar</a>, 
<a href="/search/cs?searchtype=author&query=Gangisetty%2C+S">Shankar Gangisetty</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Proceedings of the IEEE/CVF Conference on Computer Vision and
  Pattern Recognition, Pages: 5588-5596, 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item765">[765]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.06871" title="Abstract">arXiv:2306.06871</a> (replaced) [<a href="/pdf/2306.06871" title="Download PDF">pdf</a>, <a href="/format/2306.06871" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Improving Offline-to-Online Reinforcement Learning with Q-Ensembles
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhao%2C+K">Kai Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+Y">Yi Ma</a>, 
<a href="/search/cs?searchtype=author&query=Hao%2C+J">Jianye Hao</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jinyi Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+Y">Yan Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Meng%2C+Z">Zhaopeng Meng</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Robotics (cs.RO)

</div>
</div>
</dd>
<dt><a name="item766">[766]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.08330" title="Abstract">arXiv:2306.08330</a> (replaced) [<a href="/pdf/2306.08330" title="Download PDF">pdf</a>, <a href="/format/2306.08330" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multimodal Optimal Transport-based Co-Attention Transformer with Global  Structure Consistency for Survival Prediction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+Y">Yingxue Xu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+H">Hao Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages, 4 figures, accepted by ICCV 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item767">[767]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.08853" title="Abstract">arXiv:2306.08853</a> (replaced) [<a href="/pdf/2306.08853" title="Download PDF">pdf</a>, <a href="/format/2306.08853" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> In Search of netUnicorn: A Data-Collection Platform to Develop  Generalizable ML Models for Network Security Problems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Beltiukov%2C+R">Roman Beltiukov</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+W">Wenbo Guo</a>, 
<a href="/search/cs?searchtype=author&query=Gupta%2C+A">Arpit Gupta</a>, 
<a href="/search/cs?searchtype=author&query=Willinger%2C+W">Walter Willinger</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>; Cryptography and Security (cs.CR); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item768">[768]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.10966" title="Abstract">arXiv:2306.10966</a> (replaced) [<a href="/pdf/2306.10966" title="Download PDF">pdf</a>, <a href="/format/2306.10966" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Overcoming the order barrier two in splitting methods when applied to  semilinear parabolic problems with non-periodic boundary conditions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=H%C3%A4berli%2C+R">Ramona H&#xe4;berli</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
</div>
</dd>
<dt><a name="item769">[769]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.11677" title="Abstract">arXiv:2306.11677</a> (replaced) [<a href="/pdf/2306.11677" title="Download PDF">pdf</a>, <a href="/format/2306.11677" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Pseudorandom unitaries are neither real nor sparse nor noise-robust
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Haug%2C+T">Tobias Haug</a>, 
<a href="/search/quant-ph?searchtype=author&query=Bharti%2C+K">Kishor Bharti</a>, 
<a href="/search/quant-ph?searchtype=author&query=Koh%2C+D+E">Dax Enshan Koh</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 25 pages, 3 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Computational Complexity (cs.CC); Cryptography and Security (cs.CR)

</div>
</div>
</dd>
<dt><a name="item770">[770]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.12001" title="Abstract">arXiv:2306.12001</a> (replaced) [<a href="/pdf/2306.12001" title="Download PDF">pdf</a>, <a href="/format/2306.12001" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An Overview of Catastrophic AI Risks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hendrycks%2C+D">Dan Hendrycks</a>, 
<a href="/search/cs?searchtype=author&query=Mazeika%2C+M">Mantas Mazeika</a>, 
<a href="/search/cs?searchtype=author&query=Woodside%2C+T">Thomas Woodside</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item771">[771]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.13047" title="Abstract">arXiv:2306.13047</a> (replaced) [<a href="/pdf/2306.13047" title="Download PDF">pdf</a>, <a href="/format/2306.13047" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CamChoice: A Corpus of Multiple Choice Questions and Candidate Response  Distributions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liusie%2C+A">Adian Liusie</a>, 
<a href="/search/cs?searchtype=author&query=Raina%2C+V">Vatsal Raina</a>, 
<a href="/search/cs?searchtype=author&query=Mullooly%2C+A">Andrew Mullooly</a>, 
<a href="/search/cs?searchtype=author&query=Knill%2C+K">Kate Knill</a>, 
<a href="/search/cs?searchtype=author&query=Gales%2C+M+J+F">Mark J. F. Gales</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item772">[772]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.13681" title="Abstract">arXiv:2306.13681</a> (replaced) [<a href="/pdf/2306.13681" title="Download PDF">pdf</a>, <a href="/format/2306.13681" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Estimating the Value of Evidence-Based Decision Making
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Abadie%2C+A">Alberto Abadie</a>, 
<a href="/search/stat?searchtype=author&query=Agarwal%2C+A">Anish Agarwal</a>, 
<a href="/search/stat?searchtype=author&query=Imbens%2C+G">Guido Imbens</a>, 
<a href="/search/stat?searchtype=author&query=Jia%2C+S">Siwei Jia</a>, 
<a href="/search/stat?searchtype=author&query=McQueen%2C+J">James McQueen</a>, 
<a href="/search/stat?searchtype=author&query=Stepaniants%2C+S">Serguei Stepaniants</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Methodology (stat.ME)</span>; Machine Learning (cs.LG); Econometrics (econ.EM); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item773">[773]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.13793" title="Abstract">arXiv:2306.13793</a> (replaced) [<a href="/pdf/2306.13793" title="Download PDF">pdf</a>, <a href="/format/2306.13793" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> QNNRepair: Quantized Neural Network Repair
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Song%2C+X">Xidan Song</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+Y">Youcheng Sun</a>, 
<a href="/search/cs?searchtype=author&query=Mustafa%2C+M+A">Mustafa A. Mustafa</a>, 
<a href="/search/cs?searchtype=author&query=Cordeiro%2C+L+C">Lucas C. Cordeiro</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Neural and Evolutionary Computing (cs.NE)

</div>
</div>
</dd>
<dt><a name="item774">[774]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.13830" title="Abstract">arXiv:2306.13830</a> (replaced) [<a href="/pdf/2306.13830" title="Download PDF">pdf</a>, <a href="/format/2306.13830" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Improved Aircraft Environmental Impact Segmentation via Metric Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gao%2C+Z">Zhenyu Gao</a>, 
<a href="/search/cs?searchtype=author&query=Mavris%2C+D+N">Dimitri N. Mavris</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 32 pages, 11 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Applications (stat.AP)

</div>
</div>
</dd>
<dt><a name="item775">[775]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.14115" title="Abstract">arXiv:2306.14115</a> (replaced) [<a href="/pdf/2306.14115" title="Download PDF">pdf</a>, <a href="/format/2306.14115" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Trustworthy Explanation: On Causal Rationalization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+W">Wenbo Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+T">Tong Wu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yunlong Wang</a>, 
<a href="/search/cs?searchtype=author&query=Cai%2C+Y">Yong Cai</a>, 
<a href="/search/cs?searchtype=author&query=Cai%2C+H">Hengrui Cai</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> In Proceedings of the 40th International Conference on Machine Learning (ICML) GitHub Repository: <a href="https://github.com/onepounchman/Causal-Retionalization">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Methodology (stat.ME); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item776">[776]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.14192" title="Abstract">arXiv:2306.14192</a> (replaced) [<a href="/pdf/2306.14192" title="Download PDF">pdf</a>, <a href="/ps/2306.14192" title="Download PostScript">ps</a>, <a href="/format/2306.14192" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> $&#x3b1;$-$&#x3b2;$-Factorization and the Binary Case of Simon&#x27;s Congruence
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Fleischmann%2C+P">Pamela Fleischmann</a>, 
<a href="/search/math?searchtype=author&query=H%C3%B6fer%2C+J">Jonas H&#xf6;fer</a>, 
<a href="/search/math?searchtype=author&query=Huch%2C+A">Annika Huch</a>, 
<a href="/search/math?searchtype=author&query=Nowotka%2C+D">Dirk Nowotka</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Combinatorics (math.CO)</span>; Computation and Language (cs.CL)

</div>
</div>
</dd>
<dt><a name="item777">[777]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.15878" title="Abstract">arXiv:2306.15878</a> (replaced) [<a href="/e-print/2306.15878" title="Download source">src</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Diamond Model Analysis on Twitter&#x27;s Biggest Hack
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rahalkar%2C+C">Chaitanya Rahalkar</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Discrepancies in the paper
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
</div>
</dd>
<dt><a name="item778">[778]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.15925" title="Abstract">arXiv:2306.15925</a> (replaced) [<a href="/pdf/2306.15925" title="Download PDF">pdf</a>, <a href="/format/2306.15925" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Subclass-balancing Contrastive Learning for Long-tailed Recognition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hou%2C+C">Chengkai Hou</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jieyu Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Haonan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+T">Tianyi Zhou</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item779">[779]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.15931" title="Abstract">arXiv:2306.15931</a> (replaced) [<a href="/pdf/2306.15931" title="Download PDF">pdf</a>, <a href="/format/2306.15931" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Boosting Adversarial Transferability with Learnable Patch-wise Masks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wei%2C+X">Xingxing Wei</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+S">Shiji Zhao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item780">[780]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.17427" title="Abstract">arXiv:2306.17427</a> (replaced) [<a href="/pdf/2306.17427" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Modeling and parametric optimization of 3D tendon-sheath actuator system  for upper limb soft exosuit
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yadav%2C+A">Amit Yadav</a>, 
<a href="/search/cs?searchtype=author&query=Kumar%2C+N">Nitesh Kumar</a>, 
<a href="/search/cs?searchtype=author&query=Surana%2C+S">Shaurya Surana</a>, 
<a href="/search/cs?searchtype=author&query=Ramasamy%2C+A">Aravind Ramasamy</a>, 
<a href="/search/cs?searchtype=author&query=Pal%2C+A+R">Abhishek Rudra Pal</a>, 
<a href="/search/cs?searchtype=author&query=Santapuri%2C+S">Sushma Santapuri</a>, 
<a href="/search/cs?searchtype=author&query=Kumar%2C+L">Lalan Kumar</a>, 
<a href="/search/cs?searchtype=author&query=Muthukrishnan%2C+S+P">Suriya Prakash Muthukrishnan</a>, 
<a href="/search/cs?searchtype=author&query=Bhasin%2C+S">Shubhendu Bhasin</a>, 
<a href="/search/cs?searchtype=author&query=Roy%2C+S">Sitikantha Roy</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
</div>
</dd>
<dt><a name="item781">[781]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.00586" title="Abstract">arXiv:2307.00586</a> (replaced) [<a href="/pdf/2307.00586" title="Download PDF">pdf</a>, <a href="/format/2307.00586" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ClipSitu: Effectively Leveraging CLIP for Conditional Predictions in  Situation Recognition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Roy%2C+D">Debaditya Roy</a>, 
<a href="/search/cs?searchtype=author&query=Verma%2C+D">Dhruv Verma</a>, 
<a href="/search/cs?searchtype=author&query=Fernando%2C+B">Basura Fernando</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> State-of-the-art results on Grounded Situation Recognition
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item782">[782]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.01666" title="Abstract">arXiv:2307.01666</a> (replaced) [<a href="/pdf/2307.01666" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Sensors and Systems for Monitoring Mental Fatigue: A systematic review
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sharma%2C+P">Prabin Sharma</a>, 
<a href="/search/cs?searchtype=author&query=Justus%2C+J+C">Joanna C. Justus</a>, 
<a href="/search/cs?searchtype=author&query=Thapa%2C+M">Megha Thapa</a>, 
<a href="/search/cs?searchtype=author&query=Poudel%2C+G+R">Govinda R. Poudel</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 19 Pages, 3 Figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item783">[783]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.03941" title="Abstract">arXiv:2307.03941</a> (replaced) [<a href="/pdf/2307.03941" title="Download PDF">pdf</a>, <a href="/format/2307.03941" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Right to be Forgotten in the Era of Large Language Models: Implications,  Challenges, and Solutions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+D">Dawen Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Finckenberg-Broman%2C+P">Pamela Finckenberg-Broman</a>, 
<a href="/search/cs?searchtype=author&query=Hoang%2C+T">Thong Hoang</a>, 
<a href="/search/cs?searchtype=author&query=Pan%2C+S">Shidong Pan</a>, 
<a href="/search/cs?searchtype=author&query=Xing%2C+Z">Zhenchang Xing</a>, 
<a href="/search/cs?searchtype=author&query=Staples%2C+M">Mark Staples</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+X">Xiwei Xu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> The new version made the following changes: 1. added an "on-going discussion" section and relevant references 2. added a stream of solutions (privacy-preserving machine learning) to technical solutions section 3. made minor changes on descriptions of certain technical terms 4. added references to some recent law proposals and court rulings
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL)

</div>
</div>
</dd>
<dt><a name="item784">[784]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.04087" title="Abstract">arXiv:2307.04087</a> (replaced) [<a href="/pdf/2307.04087" title="Download PDF">pdf</a>, <a href="/format/2307.04087" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SVIT: Scaling up Visual Instruction Tuning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhao%2C+B">Bo Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+B">Boya Wu</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+T">Tiejun Huang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item785">[785]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.04504" title="Abstract">arXiv:2307.04504</a> (replaced) [<a href="/pdf/2307.04504" title="Download PDF">pdf</a>, <a href="/ps/2307.04504" title="Download PostScript">ps</a>, <a href="/format/2307.04504" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An Algorithm with Optimal Dimension-Dependence for Zero-Order Nonsmooth  Nonconvex Stochastic Optimization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Kornowski%2C+G">Guy Kornowski</a>, 
<a href="/search/math?searchtype=author&query=Shamir%2C+O">Ohad Shamir</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Fixed hyperparameter assignments in main theorems (results unaffected); some minor edits
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item786">[786]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.05232" title="Abstract">arXiv:2307.05232</a> (replaced) [<a href="/pdf/2307.05232" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Survey From Distributed Machine Learning to Distributed Deep Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dehghani%2C+M">Mohammad Dehghani</a>, 
<a href="/search/cs?searchtype=author&query=Yazdanparast%2C+Z">Zahra Yazdanparast</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Distributed, Parallel, and Cluster Computing (cs.DC)

</div>
</div>
</dd>
<dt><a name="item787">[787]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.05775" title="Abstract">arXiv:2307.05775</a> (replaced) [<a href="/pdf/2307.05775" title="Download PDF">pdf</a>, <a href="/format/2307.05775" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Weisfeiler and Lehman Go Measurement Modeling: Probing the Validity of  the WL Test
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Subramonian%2C+A">Arjun Subramonian</a>, 
<a href="/search/cs?searchtype=author&query=Williams%2C+A">Adina Williams</a>, 
<a href="/search/cs?searchtype=author&query=Nickel%2C+M">Maximilian Nickel</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+Y">Yizhou Sun</a>, 
<a href="/search/cs?searchtype=author&query=Sagun%2C+L">Levent Sagun</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Social and Information Networks (cs.SI)

</div>
</div>
</dd>
<dt><a name="item788">[788]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.05878" title="Abstract">arXiv:2307.05878</a> (replaced) [<a href="/pdf/2307.05878" title="Download PDF">pdf</a>, <a href="/format/2307.05878" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exponential relaxation data analysis by parametrized regularization of  severely ill-posed Fredholm integral equations of the first kind
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Kryzhniy%2C+V+V">Vladimir V Kryzhniy</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This version clarifies the main point of previous manuscript. The paper has been completely rewritten: new title, new figures, more sections
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
</div>
</dd>
<dt><a name="item789">[789]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.05900" title="Abstract">arXiv:2307.05900</a> (replaced) [<a href="/pdf/2307.05900" title="Download PDF">pdf</a>, <a href="/ps/2307.05900" title="Download PostScript">ps</a>, <a href="/format/2307.05900" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On Compatible Transfer Operators in Nonsymmetric Algebraic Multigrid
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Southworth%2C+B+S">Ben S. Southworth</a>, 
<a href="/search/math?searchtype=author&query=Manteuffel%2C+T+A">Thomas A. Manteuffel</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
</div>
</dd>
<dt><a name="item790">[790]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.06868" title="Abstract">arXiv:2307.06868</a> (replaced) [<a href="/pdf/2307.06868" title="Download PDF">pdf</a>, <a href="/format/2307.06868" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Open Source Reconfigurable Intelligent Surface for the Frequency Range  of 5 GHz WiFi
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Heinrichs%2C+M">Markus Heinrichs</a>, 
<a href="/search/cs?searchtype=author&query=Sezgin%2C+A">Aydin Sezgin</a>, 
<a href="/search/cs?searchtype=author&query=Kronberger%2C+R">Rainer Kronberger</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>; Systems and Control (eess.SY)

</div>
</div>
</dd>
<dt><a name="item791">[791]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.07268" title="Abstract">arXiv:2307.07268</a> (replaced) [<a href="/pdf/2307.07268" title="Download PDF">pdf</a>, <a href="/format/2307.07268" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An Online Learning Analysis of Minimax Adaptive Control
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Renganathan%2C+V">Venkatraman Renganathan</a>, 
<a href="/search/eess?searchtype=author&query=Iannelli%2C+A">Andrea Iannelli</a>, 
<a href="/search/eess?searchtype=author&query=Rantzer%2C+A">Anders Rantzer</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
</div>
</dd>
<dt><a name="item792">[792]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.07686" title="Abstract">arXiv:2307.07686</a> (replaced) [<a href="/pdf/2307.07686" title="Download PDF">pdf</a>, <a href="/format/2307.07686" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Creating a Dataset for High-Performance Computing Code Translation using  LLMs: A Bridge Between OpenMP Fortran and C++
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lei%2C+B">Bin Lei</a>, 
<a href="/search/cs?searchtype=author&query=Ding%2C+C">Caiwen Ding</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+L">Le Chen</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+P">Pei-Hung Lin</a>, 
<a href="/search/cs?searchtype=author&query=Liao%2C+C">Chunhua Liao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item793">[793]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.07940" title="Abstract">arXiv:2307.07940</a> (replaced) [<a href="/pdf/2307.07940" title="Download PDF">pdf</a>, <a href="/format/2307.07940" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deduplicating and Ranking Solution Programs for Suggesting Reference  Solutions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shirafuji%2C+A">Atsushi Shirafuji</a>, 
<a href="/search/cs?searchtype=author&query=Watanobe%2C+Y">Yutaka Watanobe</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, 5 figures, accepted to ASSE 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>; Computation and Language (cs.CL); Programming Languages (cs.PL)

</div>
</div>
</dd>
<dt><a name="item794">[794]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.09236" title="Abstract">arXiv:2307.09236</a> (replaced) [<a href="/pdf/2307.09236" title="Download PDF">pdf</a>, <a href="/ps/2307.09236" title="Download PostScript">ps</a>, <a href="/format/2307.09236" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A discontinuity and cusp capturing PINN for Stokes interface problems  with discontinuous viscosity and singular forces
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Tseng%2C+Y">Yu-Hau Tseng</a>, 
<a href="/search/math?searchtype=author&query=Lai%2C+M">Ming-Chih Lai</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
</div>
</dd>
<dt><a name="item795">[795]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.10404" title="Abstract">arXiv:2307.10404</a> (replaced) [<a href="/pdf/2307.10404" title="Download PDF">pdf</a>, <a href="/format/2307.10404" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Interpreting and Correcting Medical Image Classification with PIP-Net
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nauta%2C+M">Meike Nauta</a>, 
<a href="/search/cs?searchtype=author&query=Hegeman%2C+J+H">Johannes H. Hegeman</a>, 
<a href="/search/cs?searchtype=author&query=Geerdink%2C+J">Jeroen Geerdink</a>, 
<a href="/search/cs?searchtype=author&query=Schl%C3%B6tterer%2C+J">J&#xf6;rg Schl&#xf6;tterer</a>, 
<a href="/search/cs?searchtype=author&query=van+Keulen%2C+M">Maurice van Keulen</a>, 
<a href="/search/cs?searchtype=author&query=Seifert%2C+C">Christin Seifert</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to the International Workshop on Explainable and Interpretable Machine Learning (XI-ML), co-located with ECAI 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item796">[796]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.11788" title="Abstract">arXiv:2307.11788</a> (replaced) [<a href="/pdf/2307.11788" title="Download PDF">pdf</a>, <a href="/format/2307.11788" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Applying QNLP to sentiment analysis in finance
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Stein%2C+J">Jonas Stein</a>, 
<a href="/search/cs?searchtype=author&query=Christ%2C+I">Ivo Christ</a>, 
<a href="/search/cs?searchtype=author&query=Kraus%2C+N">Nicolas Kraus</a>, 
<a href="/search/cs?searchtype=author&query=Mansky%2C+M+B">Maximilian Balthasar Mansky</a>, 
<a href="/search/cs?searchtype=author&query=M%C3%BCller%2C+R">Robert M&#xfc;ller</a>, 
<a href="/search/cs?searchtype=author&query=Linnhoff-Popien%2C+C">Claudia Linnhoff-Popien</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Quantum Physics (quant-ph)

</div>
</div>
</dd>
<dt><a name="item797">[797]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.12186" title="Abstract">arXiv:2307.12186</a> (replaced) [<a href="/pdf/2307.12186" title="Download PDF">pdf</a>, <a href="/format/2307.12186" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Inferring epidemic dynamics using Gaussian process emulation of  agent-based simulations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ahmed%2C+A+A">Abdulrahman A. Ahmed</a>, 
<a href="/search/cs?searchtype=author&query=Rahimian%2C+M+A">M. Amin Rahimian</a>, 
<a href="/search/cs?searchtype=author&query=Roberts%2C+M+S">Mark S. Roberts</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To be presented in Winter Simulation Conference 2023, repository link: <a href="https://github.com/abdulrahmanfci/gpr-abm">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Multiagent Systems (cs.MA)</span>; Social and Information Networks (cs.SI); Applications (stat.AP)

</div>
</div>
</dd>
<dt><a name="item798">[798]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.12586" title="Abstract">arXiv:2307.12586</a> (replaced) [<a href="/pdf/2307.12586" title="Download PDF">pdf</a>, <a href="/format/2307.12586" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> InVAErt networks: a data-driven framework for model synthesis and  identifiability analysis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tong%2C+G+G">Guoxiang Grayson Tong</a>, 
<a href="/search/cs?searchtype=author&query=Long%2C+C+A+S">Carlos A. Sing Long</a>, 
<a href="/search/cs?searchtype=author&query=Schiavazzi%2C+D+E">Daniele E. Schiavazzi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Numerical Analysis (math.NA); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item799">[799]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.13387" title="Abstract">arXiv:2307.13387</a> (replaced) [<a href="/pdf/2307.13387" title="Download PDF">pdf</a>, <a href="/ps/2307.13387" title="Download PostScript">ps</a>, <a href="/format/2307.13387" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Positivity conditions on the annulus via the double-layer potential  kernel
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Jury%2C+M+T">Michael T. Jury</a>, 
<a href="/search/math?searchtype=author&query=Tsikalas%2C+G">Georgios Tsikalas</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Subsection 5.1 revised. Minor tweaks throughout
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Functional Analysis (math.FA)</span>; Numerical Analysis (math.NA); Operator Algebras (math.OA); Spectral Theory (math.SP)

</div>
</div>
</dd>
<dt><a name="item800">[800]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.14611" title="Abstract">arXiv:2307.14611</a> (replaced) [<a href="/pdf/2307.14611" title="Download PDF">pdf</a>, <a href="/format/2307.14611" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> TextManiA: Enriching Visual Feature by Text-driven Manifold Augmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ye-Bin%2C+M">Moon Ye-Bin</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+J">Jisoo Kim</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+H">Hongyeob Kim</a>, 
<a href="/search/cs?searchtype=author&query=Son%2C+K">Kilho Son</a>, 
<a href="/search/cs?searchtype=author&query=Oh%2C+T">Tae-Hyun Oh</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at ICCV 2023. [Project Pages] <a href="https://textmania.github.io/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item801">[801]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.15217" title="Abstract">arXiv:2307.15217</a> (replaced) [<a href="/pdf/2307.15217" title="Download PDF">pdf</a>, <a href="/format/2307.15217" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Open Problems and Fundamental Limitations of Reinforcement Learning from  Human Feedback
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Casper%2C+S">Stephen Casper</a>, 
<a href="/search/cs?searchtype=author&query=Davies%2C+X">Xander Davies</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+C">Claudia Shi</a>, 
<a href="/search/cs?searchtype=author&query=Gilbert%2C+T+K">Thomas Krendl Gilbert</a>, 
<a href="/search/cs?searchtype=author&query=Scheurer%2C+J">J&#xe9;r&#xe9;my Scheurer</a>, 
<a href="/search/cs?searchtype=author&query=Rando%2C+J">Javier Rando</a>, 
<a href="/search/cs?searchtype=author&query=Freedman%2C+R">Rachel Freedman</a>, 
<a href="/search/cs?searchtype=author&query=Korbak%2C+T">Tomasz Korbak</a>, 
<a href="/search/cs?searchtype=author&query=Lindner%2C+D">David Lindner</a>, 
<a href="/search/cs?searchtype=author&query=Freire%2C+P">Pedro Freire</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+T">Tony Wang</a>, 
<a href="/search/cs?searchtype=author&query=Marks%2C+S">Samuel Marks</a>, 
<a href="/search/cs?searchtype=author&query=Segerie%2C+C">Charbel-Rapha&#xeb;l Segerie</a>, 
<a href="/search/cs?searchtype=author&query=Carroll%2C+M">Micah Carroll</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+A">Andi Peng</a>, 
<a href="/search/cs?searchtype=author&query=Christoffersen%2C+P">Phillip Christoffersen</a>, 
<a href="/search/cs?searchtype=author&query=Damani%2C+M">Mehul Damani</a>, 
<a href="/search/cs?searchtype=author&query=Slocum%2C+S">Stewart Slocum</a>, 
<a href="/search/cs?searchtype=author&query=Anwar%2C+U">Usman Anwar</a>, 
<a href="/search/cs?searchtype=author&query=Siththaranjan%2C+A">Anand Siththaranjan</a>, 
<a href="/search/cs?searchtype=author&query=Nadeau%2C+M">Max Nadeau</a>, 
<a href="/search/cs?searchtype=author&query=Michaud%2C+E+J">Eric J. Michaud</a>, 
<a href="/search/cs?searchtype=author&query=Pfau%2C+J">Jacob Pfau</a>, 
<a href="/search/cs?searchtype=author&query=Krasheninnikov%2C+D">Dmitrii Krasheninnikov</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+X">Xin Chen</a>, 
<a href="/search/cs?searchtype=author&query=Langosco%2C+L">Lauro Langosco</a>, 
<a href="/search/cs?searchtype=author&query=Hase%2C+P">Peter Hase</a>, 
<a href="/search/cs?searchtype=author&query=B%C4%B1y%C4%B1k%2C+E">Erdem B&#x131;y&#x131;k</a>, 
<a href="/search/cs?searchtype=author&query=Dragan%2C+A">Anca Dragan</a>, 
<a href="/search/cs?searchtype=author&query=Krueger%2C+D">David Krueger</a>, 
<a href="/search/cs?searchtype=author&query=Sadigh%2C+D">Dorsa Sadigh</a>, 
<a href="/search/cs?searchtype=author&query=Hadfield-Menell%2C+D">Dylan Hadfield-Menell</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computation and Language (cs.CL); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item802">[802]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.15453" title="Abstract">arXiv:2307.15453</a> (replaced) [<a href="/pdf/2307.15453" title="Download PDF">pdf</a>, <a href="/format/2307.15453" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> From Probabilistic Programming to Complexity-based Programming
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sileno%2C+G">Giovanni Sileno</a>, 
<a href="/search/cs?searchtype=author&query=Dessalles%2C+J">Jean-Louis Dessalles</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> paper accepted at HYDRA workshop at ECAI 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computation and Language (cs.CL)

</div>
</div>
</dd>
<dt><a name="item803">[803]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.15898" title="Abstract">arXiv:2307.15898</a> (replaced) [<a href="/pdf/2307.15898" title="Download PDF">pdf</a>, <a href="/format/2307.15898" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> UniBriVL: Robust Universal Representation and Generation of Audio Driven  Diffusion Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fang%2C+S">Sen Fang</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+B">Bowen Gao</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Y">Yangjian Wu</a>, 
<a href="/search/cs?searchtype=author&query=Teoh%2C+T+T">Teik Toe Teoh</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Voice-Text fusion input; The first work of audio driven diffusion model. arXiv admin note: text overlap with <a href="/abs/2303.04585">arXiv:2303.04585</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Artificial Intelligence (cs.AI); Audio and Speech Processing (eess.AS)

</div>
</div>
</dd>
<dt><a name="item804">[804]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.16262" title="Abstract">arXiv:2307.16262</a> (replaced) [<a href="/pdf/2307.16262" title="Download PDF">pdf</a>, <a href="/format/2307.16262" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An objective validation of polyp and instrument segmentation methods in  colonoscopy through Medico 2020 polyp segmentation and MedAI 2021  transparency challenges
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Jha%2C+D">Debesh Jha</a>, 
<a href="/search/eess?searchtype=author&query=Sharma%2C+V">Vanshali Sharma</a>, 
<a href="/search/eess?searchtype=author&query=Banik%2C+D">Debapriya Banik</a>, 
<a href="/search/eess?searchtype=author&query=Bhattacharya%2C+D">Debayan Bhattacharya</a>, 
<a href="/search/eess?searchtype=author&query=Roy%2C+K">Kaushiki Roy</a>, 
<a href="/search/eess?searchtype=author&query=Hicks%2C+S+A">Steven A. Hicks</a>, 
<a href="/search/eess?searchtype=author&query=Tomar%2C+N+K">Nikhil Kumar Tomar</a>, 
<a href="/search/eess?searchtype=author&query=Thambawita%2C+V">Vajira Thambawita</a>, 
<a href="/search/eess?searchtype=author&query=Krenzer%2C+A">Adrian Krenzer</a>, 
<a href="/search/eess?searchtype=author&query=Ji%2C+G">Ge-Peng Ji</a>, 
<a href="/search/eess?searchtype=author&query=Poudel%2C+S">Sahadev Poudel</a>, 
<a href="/search/eess?searchtype=author&query=Batchkala%2C+G">George Batchkala</a>, 
<a href="/search/eess?searchtype=author&query=Alam%2C+S">Saruar Alam</a>, 
<a href="/search/eess?searchtype=author&query=Ahmed%2C+A+M+A">Awadelrahman M. A. Ahmed</a>, 
<a href="/search/eess?searchtype=author&query=Trinh%2C+Q">Quoc-Huy Trinh</a>, 
<a href="/search/eess?searchtype=author&query=Khan%2C+Z">Zeshan Khan</a>, 
<a href="/search/eess?searchtype=author&query=Nguyen%2C+T">Tien-Phat Nguyen</a>, 
<a href="/search/eess?searchtype=author&query=Shrestha%2C+S">Shruti Shrestha</a>, 
<a href="/search/eess?searchtype=author&query=Nathan%2C+S">Sabari Nathan</a>, 
<a href="/search/eess?searchtype=author&query=Gwak%2C+J">Jeonghwan Gwak</a>, 
<a href="/search/eess?searchtype=author&query=Jha%2C+R+K">Ritika K. Jha</a>, 
<a href="/search/eess?searchtype=author&query=Zhang%2C+Z">Zheyuan Zhang</a>, 
<a href="/search/eess?searchtype=author&query=Schlaefer%2C+A">Alexander Schlaefer</a>, 
<a href="/search/eess?searchtype=author&query=Bhattacharjee%2C+D">Debotosh Bhattacharjee</a>, 
<a href="/search/eess?searchtype=author&query=Bhuyan%2C+M+K">M.K. Bhuyan</a>, 
<a href="/search/eess?searchtype=author&query=Das%2C+P+K">Pradip K. Das</a>, 
<a href="/search/eess?searchtype=author&query=Fan%2C+D">Deng-Ping Fan</a>, 
<a href="/search/eess?searchtype=author&query=Parsa%2C+S">Sravanthi Parsa</a>, 
<a href="/search/eess?searchtype=author&query=Ali%2C+S">Sharib Ali</a>, 
<a href="/search/eess?searchtype=author&query=Riegler%2C+M+A">Michael A. Riegler</a>, 
<a href="/search/eess?searchtype=author&query=Halvorsen%2C+P">P&#xe5;l Halvorsen</a>, 
<a href="/search/eess?searchtype=author&query=De+Lange%2C+T">Thomas De Lange</a>, 
<a href="/search/eess?searchtype=author&query=Bagci%2C+U">Ulas Bagci</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item805">[805]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.16446" title="Abstract">arXiv:2307.16446</a> (replaced) [<a href="/pdf/2307.16446" title="Download PDF">pdf</a>, <a href="/format/2307.16446" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Power Transfer between Two Antenna Arrays in the Near Field
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Tiwari%2C+K+K">Krishan Kumar Tiwari</a>, 
<a href="/search/eess?searchtype=author&query=Caire%2C+G">Giuseppe Caire</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Systems and Control (eess.SY)

</div>
</div>
</dd>
<dt><a name="item806">[806]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.16517" title="Abstract">arXiv:2307.16517</a> (replaced) [<a href="/pdf/2307.16517" title="Download PDF">pdf</a>, <a href="/format/2307.16517" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Select2Col: Leveraging Spatial-Temporal Importance of Semantic  Information for Efficient Collaborative Perception
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yuntao Liu</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+Q">Qian Huang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+R">Rongpeng Li</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+X">Xianfu Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Z">Zhifeng Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+S">Shuyuan Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+Y">Yongdong Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Honggang Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item807">[807]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.16771" title="Abstract">arXiv:2307.16771</a> (replaced) [<a href="/pdf/2307.16771" title="Download PDF">pdf</a>, <a href="/format/2307.16771" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the Complexity of Algorithms with Predictions for Dynamic Graph  Problems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Henzinger%2C+M">Monika Henzinger</a>, 
<a href="/search/cs?searchtype=author&query=Saha%2C+B">Barna Saha</a>, 
<a href="/search/cs?searchtype=author&query=Seybold%2C+M+P">Martin P. Seybold</a>, 
<a href="/search/cs?searchtype=author&query=Ye%2C+C">Christopher Ye</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Abstract shortened to meet arXiv requirements
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>

</div>
</div>
</dd>
<dt><a name="item808">[808]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.00292" title="Abstract">arXiv:2308.00292</a> (replaced) [<a href="/pdf/2308.00292" title="Download PDF">pdf</a>, <a href="/format/2308.00292" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Dual-space Multilevel Kernel-splitting Framework for Discrete and  Continuous Convolution
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Jiang%2C+S">Shidong Jiang</a>, 
<a href="/search/math?searchtype=author&query=Greengard%2C+L">Leslie Greengard</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 53 pages, 15 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
</div>
</dd>
<dt><a name="item809">[809]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.00994" title="Abstract">arXiv:2308.00994</a> (replaced) [<a href="/pdf/2308.00994" title="Download PDF">pdf</a>, <a href="/format/2308.00994" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SYNAuG: Exploiting Synthetic Data for Data Imbalance Problems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ye-Bin%2C+M">Moon Ye-Bin</a>, 
<a href="/search/cs?searchtype=author&query=Hyeon-Woo%2C+N">Nam Hyeon-Woo</a>, 
<a href="/search/cs?searchtype=author&query=Choi%2C+W">Wonseok Choi</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+N">Nayeong Kim</a>, 
<a href="/search/cs?searchtype=author&query=Kwak%2C+S">Suha Kwak</a>, 
<a href="/search/cs?searchtype=author&query=Oh%2C+T">Tae-Hyun Oh</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item810">[810]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.01738" title="Abstract">arXiv:2308.01738</a> (replaced) [<a href="/pdf/2308.01738" title="Download PDF">pdf</a>, <a href="/format/2308.01738" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Enhancing Visibility in Nighttime Haze Images Using Guided APSF and  Gradient Adaptive Convolution
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jin%2C+Y">Yeying Jin</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+B">Beibei Lin</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+W">Wending Yan</a>, 
<a href="/search/cs?searchtype=author&query=Ye%2C+W">Wei Ye</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+Y">Yuan Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Tan%2C+R+T">Robby T. Tan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to ACM'MM2023, <a href="https://github.com/jinyeying/nighttime_dehaze">this https URL</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Published in ACM'MM2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item811">[811]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.02295" title="Abstract">arXiv:2308.02295</a> (replaced) [<a href="/e-print/2308.02295" title="Download source">src</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> IRS-Enabled Covert and Reliable Communications: How Many Reflection  Elements are Required?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+M">Manlin Wang</a>, 
<a href="/search/cs?searchtype=author&query=Xia%2C+B">Bin Xia</a>, 
<a href="/search/cs?searchtype=author&query=Yao%2C+Y">Yao Yao</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Z">Zhiyong Chen</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jiangzhou Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> The paper has some shortcomings in the theoretical analysis. And it will not be published at the conference, as clamied in last comments
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
</div>
</dd>
<dt><a name="item812">[812]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.02946" title="Abstract">arXiv:2308.02946</a> (replaced) [<a href="/pdf/2308.02946" title="Download PDF">pdf</a>, <a href="/ps/2308.02946" title="Download PostScript">ps</a>, <a href="/format/2308.02946" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the expected efficiency of branch and bound for the asymmetric TSP
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Frieze%2C+A">Alan Frieze</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Fixed minor error
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>; Combinatorics (math.CO)

</div>
</div>
</dd>
<dt><a name="item813">[813]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.03135" title="Abstract">arXiv:2308.03135</a> (replaced) [<a href="/pdf/2308.03135" title="Download PDF">pdf</a>, <a href="/format/2308.03135" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> E-CLIP: Towards Label-efficient Event-based Open-world Understanding by  CLIP
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhou%2C+J">Jiazhou Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+X">Xu Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Lyu%2C+Y">Yuanhuiyi Lyu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+L">Lin Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Jounal version with supplementary material
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item814">[814]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.03801" title="Abstract">arXiv:2308.03801</a> (replaced) [<a href="/pdf/2308.03801" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On problematic practice of using normalization in  Self-modeling/Multivariate Curve Resolution (S/MCR)
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Rajk%C3%B3%2C+R">R&#xf3;bert Rajk&#xf3;</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Methodology (stat.ME)</span>; Numerical Analysis (math.NA)

</div>
</div>
</dd>
<dt><a name="item815">[815]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.03929" title="Abstract">arXiv:2308.03929</a> (replaced) [<a href="/pdf/2308.03929" title="Download PDF">pdf</a>, <a href="/format/2308.03929" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Challenging the Machinery of Generative AI with Fact-Checking:  Ontology-Driven Biological Graphs for Verifying Human Disease-Gene Links
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hamed%2C+A+A">Ahmed Abdeen Hamed</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+B+S">Byung Suk Lee</a>, 
<a href="/search/cs?searchtype=author&query=Crimi%2C+A">Alessandro Crimi</a>, 
<a href="/search/cs?searchtype=author&query=Misiak%2C+M+M">Magdalena M. Misiak</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 Pages, 3 algorithms, 5 tables, and 8 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computation and Language (cs.CL)

</div>
</div>
</dd>
<dt><a name="item816">[816]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.04650" title="Abstract">arXiv:2308.04650</a> (replaced) [<a href="/pdf/2308.04650" title="Download PDF">pdf</a>, <a href="/format/2308.04650" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deep Metric Learning for the Hemodynamics Inference with  Electrocardiogram Signals
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jeong%2C+H">Hyewon Jeong</a>, 
<a href="/search/cs?searchtype=author&query=Stultz%2C+C+M">Collin M. Stultz</a>, 
<a href="/search/cs?searchtype=author&query=Ghassemi%2C+M">Marzyeh Ghassemi</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> MLHC 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Signal Processing (eess.SP); Quantitative Methods (q-bio.QM)

</div>
</div>
</dd>
<dt><a name="item817">[817]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.04699" title="Abstract">arXiv:2308.04699</a> (replaced) [<a href="/pdf/2308.04699" title="Download PDF">pdf</a>, <a href="/format/2308.04699" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GIFD: A Generative Gradient Inversion Method with Feature Domain  Optimization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fang%2C+H">Hao Fang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+B">Bin Chen</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xuan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zhi Wang</a>, 
<a href="/search/cs?searchtype=author&query=Xia%2C+S">Shu-Tao Xia</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ICCV 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Cryptography and Security (cs.CR)

</div>
</div>
</dd>
<dt><a name="item818">[818]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.05734" title="Abstract">arXiv:2308.05734</a> (replaced) [<a href="/pdf/2308.05734" title="Download PDF">pdf</a>, <a href="/format/2308.05734" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AudioLDM 2: Learning Holistic Audio Generation with Self-supervised  Pretraining
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+H">Haohe Liu</a>, 
<a href="/search/cs?searchtype=author&query=Tian%2C+Q">Qiao Tian</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+Y">Yi Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xubo Liu</a>, 
<a href="/search/cs?searchtype=author&query=Mei%2C+X">Xinhao Mei</a>, 
<a href="/search/cs?searchtype=author&query=Kong%2C+Q">Qiuqiang Kong</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yuping Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+W">Wenwu Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yuxuan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Plumbley%2C+M+D">Mark D. Plumbley</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> AudioLDM 2 project page is <a href="https://audioldm.github.io/audioldm2">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Artificial Intelligence (cs.AI); Multimedia (cs.MM); Audio and Speech Processing (eess.AS); Signal Processing (eess.SP)

</div>
</div>
</dd>
<dt><a name="item819">[819]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.05783" title="Abstract">arXiv:2308.05783</a> (replaced) [<a href="/pdf/2308.05783" title="Download PDF">pdf</a>, <a href="/format/2308.05783" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Toward Globally Optimal State Estimation Using Automatically Tightened  Semidefinite Relaxations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=D%C3%BCmbgen%2C+F">Frederike D&#xfc;mbgen</a>, 
<a href="/search/cs?searchtype=author&query=Holmes%2C+C">Connor Holmes</a>, 
<a href="/search/cs?searchtype=author&query=Agro%2C+B">Ben Agro</a>, 
<a href="/search/cs?searchtype=author&query=Barfoot%2C+T+D">Timothy D. Barfoot</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 18 pages, 20 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
</div>
</dd>
<dt><a name="item820">[820]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.06791" title="Abstract">arXiv:2308.06791</a> (replaced) [<a href="/pdf/2308.06791" title="Download PDF">pdf</a>, <a href="/format/2308.06791" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PV-SSD: A Projection and Voxel-based Double Branch Single-Stage 3D  Object Detector
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shao%2C+Y">Yongxin Shao</a>, 
<a href="/search/cs?searchtype=author&query=Tan%2C+A">Aihong Tan</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+Z">Zhetao Sun</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+E">Enhui Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+T">Tianhong Yan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item821">[821]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.07187" title="Abstract">arXiv:2308.07187</a> (replaced) [<a href="/pdf/2308.07187" title="Download PDF">pdf</a>, <a href="/ps/2308.07187" title="Download PostScript">ps</a>, <a href="/format/2308.07187" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Asymptotic nonnegative rank of matrices
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Le%2C+Q">Quoc-Tung Le</a>, 
<a href="/search/cs?searchtype=author&query=Ta%2C+H">Hoang Ta</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Computational Complexity (cs.CC); Commutative Algebra (math.AC)

</div>
</div>
</dd>
<dt><a name="item822">[822]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.07327" title="Abstract">arXiv:2308.07327</a> (replaced) [<a href="/pdf/2308.07327" title="Download PDF">pdf</a>, <a href="/format/2308.07327" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PokerKit: A Comprehensive Python Library for Fine-Grained Multi-Variant  Poker Game Simulations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kim%2C+J">Juho Kim</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages, 1 figure, submission to IEEE Transactions on Games
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
</div>
</dd>
<dt><a name="item823">[823]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.07491" title="Abstract">arXiv:2308.07491</a> (replaced) [<a href="/pdf/2308.07491" title="Download PDF">pdf</a>, <a href="/format/2308.07491" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Adaptive Tracking of a Single-Rigid-Body Character in Various  Environments
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kwon%2C+T">Taesoo Kwon</a>, 
<a href="/search/cs?searchtype=author&query=Gu%2C+T">Taehong Gu</a>, 
<a href="/search/cs?searchtype=author&query=Ahn%2C+J">Jaewon Ahn</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+Y">Yoonsang Lee</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Graphics (cs.GR); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item824">[824]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.07896" title="Abstract">arXiv:2308.07896</a> (replaced) [<a href="/pdf/2308.07896" title="Download PDF">pdf</a>, <a href="/format/2308.07896" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SciRE-Solver: Accelerating Diffusion Models Sampling by Score-integrand  Solver with Recursive Difference
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Li%2C+S">Shigui Li</a>, 
<a href="/search/stat?searchtype=author&query=Chen%2C+W">Wei Chen</a>, 
<a href="/search/stat?searchtype=author&query=Zeng%2C+D">Delu Zeng</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG); Dynamical Systems (math.DS); Computation (stat.CO)

</div>
</div>
</dd>
<dt><a name="item825">[825]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.08197" title="Abstract">arXiv:2308.08197</a> (replaced) [<a href="/pdf/2308.08197" title="Download PDF">pdf</a>, <a href="/format/2308.08197" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Self-Reference Deep Adaptive Curve Estimation for Low-Light Image  Enhancement
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Wen%2C+J">Jianyu Wen</a>, 
<a href="/search/eess?searchtype=author&query=Wu%2C+C">Chenhao Wu</a>, 
<a href="/search/eess?searchtype=author&query=Zhang%2C+T">Tong Zhang</a>, 
<a href="/search/eess?searchtype=author&query=Yu%2C+Y">Yixuan Yu</a>, 
<a href="/search/eess?searchtype=author&query=Swierczynski%2C+P">Piotr Swierczynski</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item826">[826]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.09262" title="Abstract">arXiv:2308.09262</a> (replaced) [<a href="/pdf/2308.09262" title="Download PDF">pdf</a>, <a href="/format/2308.09262" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multi-Task Pseudo-Label Learning for Non-Intrusive Speech Quality  Assessment Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Zezario%2C+R+E">Ryandhimas E. Zezario</a>, 
<a href="/search/eess?searchtype=author&query=Bai%2C+B+B">Bo-Ren Brian Bai</a>, 
<a href="/search/eess?searchtype=author&query=Fuh%2C+C">Chiou-Shann Fuh</a>, 
<a href="/search/eess?searchtype=author&query=Wang%2C+H">Hsin-Min Wang</a>, 
<a href="/search/eess?searchtype=author&query=Tsao%2C+Y">Yu Tsao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Machine Learning (cs.LG); Sound (cs.SD)

</div>
</div>
</dd>
<dt><a name="item827">[827]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10417" title="Abstract">arXiv:2308.10417</a> (replaced) [<a href="/pdf/2308.10417" title="Download PDF">pdf</a>, <a href="/format/2308.10417" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Change You Want to See (Now in 3D)
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sachdeva%2C+R">Ragav Sachdeva</a>, 
<a href="/search/cs?searchtype=author&query=Zisserman%2C+A">Andrew Zisserman</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item828">[828]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10697" title="Abstract">arXiv:2308.10697</a> (replaced) [<a href="/pdf/2308.10697" title="Download PDF">pdf</a>, <a href="/format/2308.10697" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Beyond expectations: Residual Dynamic Mode Decomposition and Variance  for Stochastic Dynamical Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Colbrook%2C+M+J">Matthew J. Colbrook</a>, 
<a href="/search/math?searchtype=author&query=Li%2C+Q">Qin Li</a>, 
<a href="/search/math?searchtype=author&query=Raut%2C+R+V">Ryan V. Raut</a>, 
<a href="/search/math?searchtype=author&query=Townsend%2C+A">Alex Townsend</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Dynamical Systems (math.DS)</span>; Machine Learning (cs.LG); Numerical Analysis (math.NA); Spectral Theory (math.SP); Chaotic Dynamics (nlin.CD)

</div>
</div>
</dd>
<dt><a name="item829">[829]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.11224" title="Abstract">arXiv:2308.11224</a> (replaced) [<a href="/pdf/2308.11224" title="Download PDF">pdf</a>, <a href="/format/2308.11224" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Evaluating Large Language Models on Graphs: Performance Insights and  Comparative Analysis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+C">Chang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+B">Bo Wu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 1 figure
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computation and Language (cs.CL)

</div>
</div>
</dd>
<dt><a name="item830">[830]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.11241" title="Abstract">arXiv:2308.11241</a> (replaced) [<a href="/pdf/2308.11241" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An Effective Transformer-based Contextual Model and Temporal Gate  Pooling for Speaker Identification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kawano%2C+H">Harunori Kawano</a>, 
<a href="/search/cs?searchtype=author&query=Shimizu%2C+S">Sota Shimizu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages, 3 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Audio and Speech Processing (eess.AS)

</div>
</div>
</dd>
<dt><a name="item831">[831]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.11257" title="Abstract">arXiv:2308.11257</a> (replaced) [<a href="/pdf/2308.11257" title="Download PDF">pdf</a>, <a href="/format/2308.11257" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> HopPG: Self-Iterative Program Generation for Multi-Hop Question  Answering over Heterogeneous Knowledge
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yingyao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Y">Yongwei Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Duan%2C+C">Chaoqun Duan</a>, 
<a href="/search/cs?searchtype=author&query=Bao%2C+J">Junwei Bao</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+T">Tiejun Zhao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item832">[832]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.11974" title="Abstract">arXiv:2308.11974</a> (replaced) [<a href="/pdf/2308.11974" title="Download PDF">pdf</a>, <a href="/format/2308.11974" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Blending-NeRF: Text-Driven Localized Editing in Neural Radiance Fields
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Song%2C+H">Hyeonseop Song</a>, 
<a href="/search/cs?searchtype=author&query=Choi%2C+S">Seokhun Choi</a>, 
<a href="/search/cs?searchtype=author&query=Do%2C+H">Hoseok Do</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+C">Chul Lee</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+T">Taehyeong Kim</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to ICCV 2023. The first two authors contributed equally to this work
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Graphics (cs.GR)

</div>
</div>
</dd>
<dt><a name="item833">[833]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.12006" title="Abstract">arXiv:2308.12006</a> (replaced) [<a href="/pdf/2308.12006" title="Download PDF">pdf</a>, <a href="/format/2308.12006" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multi-stage Factorized Spatio-Temporal Representation for RGB-D Action  and Gesture Recognition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ma%2C+Y">Yujun Ma</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+B">Benjia Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+R">Ruili Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+P">Pichao Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ACM MM'23
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item834">[834]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.12714" title="Abstract">arXiv:2308.12714</a> (replaced) [<a href="/pdf/2308.12714" title="Download PDF">pdf</a>, <a href="/format/2308.12714" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> VIGC: Visual Instruction Generation and Correction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+B">Bin Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+F">Fan Wu</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+X">Xiao Han</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+J">Jiahui Peng</a>, 
<a href="/search/cs?searchtype=author&query=Zhong%2C+H">Huaping Zhong</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+P">Pan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+X">Xiaoyi Dong</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+W">Weijia Li</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+W">Wei Li</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jiaqi Wang</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+C">Conghui He</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project Website: <a href="https://opendatalab.github.io/VIGC">this https URL</a>, Code and Pretrained Model: <a href="https://github.com/opendatalab/VIGC">this https URL</a>, Dataset: <a href="https://opendatalab.com/OpenDataLab/VIGC-InstData">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item835">[835]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.13032" title="Abstract">arXiv:2308.13032</a> (replaced) [<a href="/pdf/2308.13032" title="Download PDF">pdf</a>, <a href="/format/2308.13032" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Financial News Analytics Using Fine-Tuned Llama 2 GPT Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pavlyshenko%2C+B+M">Bohdan M. Pavlyshenko</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Computational Engineering, Finance, and Science (cs.CE); Information Retrieval (cs.IR); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item836">[836]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.13066" title="Abstract">arXiv:2308.13066</a> (replaced) [<a href="/pdf/2308.13066" title="Download PDF">pdf</a>, <a href="/format/2308.13066" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Objective-Agnostic Enhancement of Molecule Properties via Multi-Stage  VAE
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhou%2C+C">Chenghui Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Poczos%2C+B">Barnabas Poczos</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: text overlap with <a href="/abs/2212.02750">arXiv:2212.02750</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Quantitative Methods (q-bio.QM)

</div>
</div>
</dd>
<dt><a name="item837">[837]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.13369" title="Abstract">arXiv:2308.13369</a> (replaced) [<a href="/pdf/2308.13369" title="Download PDF">pdf</a>, <a href="/format/2308.13369" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Distribution-Aligned Diffusion for Human Mesh Recovery
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Foo%2C+L+G">Lin Geng Foo</a>, 
<a href="/search/cs?searchtype=author&query=Gong%2C+J">Jia Gong</a>, 
<a href="/search/cs?searchtype=author&query=Rahmani%2C+H">Hossein Rahmani</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jun Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to ICCV 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item838">[838]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.13425" title="Abstract">arXiv:2308.13425</a> (replaced) [<a href="/pdf/2308.13425" title="Download PDF">pdf</a>, <a href="/format/2308.13425" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Safe and Quasi-Optimal Autonomous Navigation in Environments with Convex  Obstacles
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Cheniouni%2C+I">Ishak Cheniouni</a>, 
<a href="/search/eess?searchtype=author&query=Berkane%2C+S">Soulaimane Berkane</a>, 
<a href="/search/eess?searchtype=author&query=Tayebi%2C+A">Abdelhamid Tayebi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: substantial text overlap with <a href="/abs/2302.12309">arXiv:2302.12309</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
</div>
</dd>
<dt><a name="item839">[839]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.13451" title="Abstract">arXiv:2308.13451</a> (replaced) [<a href="/pdf/2308.13451" title="Download PDF">pdf</a>, <a href="/format/2308.13451" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Gotta match &#x27;em all: Solution diversification in graph matching matched  filters
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Li%2C+Z">Zhirui Li</a>, 
<a href="/search/stat?searchtype=author&query=Johnson%2C+B">Ben Johnson</a>, 
<a href="/search/stat?searchtype=author&query=Sussman%2C+D+L">Daniel L. Sussman</a>, 
<a href="/search/stat?searchtype=author&query=Priebe%2C+C+E">Carey E. Priebe</a>, 
<a href="/search/stat?searchtype=author&query=Lyzinski%2C+V">Vince Lyzinski</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 36 pages, 12 figures, 1 table
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG); Combinatorics (math.CO); Applications (stat.AP); Methodology (stat.ME)

</div>
</div>
</dd>
<dt><a name="item840">[840]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.13566" title="Abstract">arXiv:2308.13566</a> (replaced) [<a href="/pdf/2308.13566" title="Download PDF">pdf</a>, <a href="/format/2308.13566" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MLLM-DataEngine: An Iterative Refinement Approach for MLLM
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Z">Zhiyuan Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Ouyang%2C+L">Linke Ouyang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+B">Bin Wang</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+S">Siyuan Huang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+P">Pan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+X">Xiaoyi Dong</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jiaqi Wang</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+C">Conghui He</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Code and models are available at <a href="https://github.com/opendatalab/MLLM-DataEngine">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item841">[841]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.13570" title="Abstract">arXiv:2308.13570</a> (replaced) [<a href="/pdf/2308.13570" title="Download PDF">pdf</a>, <a href="/format/2308.13570" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Stochastic Configuration Machines for Industrial Artificial Intelligence
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+D">Dianhui Wang</a>, 
<a href="/search/cs?searchtype=author&query=Felicetti%2C+M+J">Matthew J. Felicetti</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 23 pages, 7 figures, 12 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Neural and Evolutionary Computing (cs.NE)

</div>
</div>
</dd>
<dt><a name="item842">[842]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.13916" title="Abstract">arXiv:2308.13916</a> (replaced) [<a href="/pdf/2308.13916" title="Download PDF">pdf</a>, <a href="/format/2308.13916" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exploring Large Language Models for Knowledge Graph Completion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yao%2C+L">Liang Yao</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+J">Jiazhen Peng</a>, 
<a href="/search/cs?searchtype=author&query=Mao%2C+C">Chengsheng Mao</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+Y">Yuan Luo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Work in progress
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item843">[843]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.14004" title="Abstract">arXiv:2308.14004</a> (replaced) [<a href="/pdf/2308.14004" title="Download PDF">pdf</a>, <a href="/ps/2308.14004" title="Download PostScript">ps</a>, <a href="/format/2308.14004" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Online GentleAdaBoost -- Technical Report
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Siu%2C+C">Chapman Siu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item844">[844]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.14129" title="Abstract">arXiv:2308.14129</a> (replaced) [<a href="/pdf/2308.14129" title="Download PDF">pdf</a>, <a href="/format/2308.14129" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SPEED: Streaming Partition and Parallel Acceleration for Temporal  Interaction Graph Embedding
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+X">Xi Chen</a>, 
<a href="/search/cs?searchtype=author&query=Liao%2C+Y">Yongxiang Liao</a>, 
<a href="/search/cs?searchtype=author&query=Xiong%2C+Y">Yun Xiong</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yao Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+S">Siwei Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jiawei Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+Y">Yiheng Sun</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, 8 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Distributed, Parallel, and Cluster Computing (cs.DC); Social and Information Networks (cs.SI)

</div>
</div>
</dd>
<dt><a name="item845">[845]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.14177" title="Abstract">arXiv:2308.14177</a> (replaced) [<a href="/pdf/2308.14177" title="Download PDF">pdf</a>, <a href="/format/2308.14177" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AIGC for Various Data Modalities: A Survey
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Foo%2C+L+G">Lin Geng Foo</a>, 
<a href="/search/cs?searchtype=author&query=Rahmani%2C+H">Hossein Rahmani</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jun Liu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item846">[846]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.14448" title="Abstract">arXiv:2308.14448</a> (replaced) [<a href="/pdf/2308.14448" title="Download PDF">pdf</a>, <a href="/format/2308.14448" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ExpCLIP: Bridging Text and Facial Expressions via Semantic Alignment
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhong%2C+Y">Yicheng Zhong</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+H">Huawei Wei</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+P">Peiji Yang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zhisheng Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item847">[847]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.15272" title="Abstract">arXiv:2308.15272</a> (replaced) [<a href="/pdf/2308.15272" title="Download PDF">pdf</a>, <a href="/format/2308.15272" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Empowering LLM to use Smartphone for Intelligent Task Automation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wen%2C+H">Hao Wen</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yuanchun Li</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+G">Guohong Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+S">Shanhui Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+T">Tao Yu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+T+J">Toby Jia-Jun Li</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+S">Shiqi Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yunhao Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yaqin Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yunxin Liu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Software Engineering (cs.SE)

</div>
</div>
</dd>
<dt><a name="item848">[848]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.15514" title="Abstract">arXiv:2308.15514</a> (replaced) [<a href="/pdf/2308.15514" title="Download PDF">pdf</a>, <a href="/format/2308.15514" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> International Governance of Civilian AI: A Jurisdictional Certification  Approach
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Trager%2C+R">Robert Trager</a>, 
<a href="/search/cs?searchtype=author&query=Harack%2C+B">Ben Harack</a>, 
<a href="/search/cs?searchtype=author&query=Reuel%2C+A">Anka Reuel</a>, 
<a href="/search/cs?searchtype=author&query=Carnegie%2C+A">Allison Carnegie</a>, 
<a href="/search/cs?searchtype=author&query=Heim%2C+L">Lennart Heim</a>, 
<a href="/search/cs?searchtype=author&query=Ho%2C+L">Lewis Ho</a>, 
<a href="/search/cs?searchtype=author&query=Kreps%2C+S">Sarah Kreps</a>, 
<a href="/search/cs?searchtype=author&query=Lall%2C+R">Ranjit Lall</a>, 
<a href="/search/cs?searchtype=author&query=Larter%2C+O">Owen Larter</a>, 
<a href="/search/cs?searchtype=author&query=h%C3%89igeartaigh%2C+S+%C3%93">Se&#xe1;n &#xd3; h&#xc9;igeartaigh</a>, 
<a href="/search/cs?searchtype=author&query=Staffell%2C+S">Simon Staffell</a>, 
<a href="/search/cs?searchtype=author&query=Villalobos%2C+J+J">Jos&#xe9; Jaime Villalobos</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
</div>
</dd>
<dt><a name="item849">[849]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.15772" title="Abstract">arXiv:2308.15772</a> (replaced) [<a href="/pdf/2308.15772" title="Download PDF">pdf</a>, <a href="/format/2308.15772" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Task-Based MoE for Multitask Multilingual Machine Translation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pham%2C+H">Hai Pham</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+Y+J">Young Jin Kim</a>, 
<a href="/search/cs?searchtype=author&query=Mukherjee%2C+S">Subhabrata Mukherjee</a>, 
<a href="/search/cs?searchtype=author&query=Woodruff%2C+D+P">David P. Woodruff</a>, 
<a href="/search/cs?searchtype=author&query=Poczos%2C+B">Barnabas Poczos</a>, 
<a href="/search/cs?searchtype=author&query=Awadalla%2C+H+H">Hany Hassan Awadalla</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item850">[850]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.16518" title="Abstract">arXiv:2308.16518</a> (replaced) [<a href="/pdf/2308.16518" title="Download PDF">pdf</a>, <a href="/format/2308.16518" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MS23D: A 3D Object Detection Method Using Multi-Scale Semantic Feature  Points to Construct 3D Feature Layer
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shao%2C+Y">Yongxin Shao</a>, 
<a href="/search/cs?searchtype=author&query=Tan%2C+A">Aihong Tan</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+T">Tianhong Yan</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+Z">Zhetao Sun</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item851">[851]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.16582" title="Abstract">arXiv:2308.16582</a> (replaced) [<a href="/pdf/2308.16582" title="Download PDF">pdf</a>, <a href="/format/2308.16582" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Any-Size-Diffusion: Toward Efficient Text-Driven Synthesis for Any-Size  HD Images
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zheng%2C+Q">Qingping Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+Y">Yuanfan Guo</a>, 
<a href="/search/cs?searchtype=author&query=Deng%2C+J">Jiankang Deng</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+J">Jianhua Han</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Ying Li</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+S">Songcen Xu</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+H">Hang Xu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item852">[852]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.16775" title="Abstract">arXiv:2308.16775</a> (replaced) [<a href="/pdf/2308.16775" title="Download PDF">pdf</a>, <a href="/format/2308.16775" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Efficacy of Neural Prediction-Based Zero-Shot NAS
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Le%2C+M">Minh Le</a>, 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+N">Nhan Nguyen</a>, 
<a href="/search/cs?searchtype=author&query=Luong%2C+N+H">Ngoc Hoang Luong</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 6 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item853">[853]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.00417" title="Abstract">arXiv:2309.00417</a> (replaced) [<a href="/pdf/2309.00417" title="Download PDF">pdf</a>, <a href="/format/2309.00417" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Area-norm COBRA on Conditional Survival Prediction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Goswami%2C+R">Rahul Goswami</a>, 
<a href="/search/cs?searchtype=author&query=Dey%2C+A+K">Arabin Kr. Dey</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Quantitative Methods (q-bio.QM); Computation (stat.CO); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item854">[854]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.00559" title="Abstract">arXiv:2309.00559</a> (replaced) [<a href="/pdf/2309.00559" title="Download PDF">pdf</a>, <a href="/format/2309.00559" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Signal Processing and Learning for Next Generation Multiple Access in 6G
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Chen%2C+W">Wei Chen</a>, 
<a href="/search/eess?searchtype=author&query=Liu%2C+Y">Yuanwei Liu</a>, 
<a href="/search/eess?searchtype=author&query=Jafarkhani%2C+H">Hamid Jafarkhani</a>, 
<a href="/search/eess?searchtype=author&query=Eldar%2C+Y+C">Yonina C. Eldar</a>, 
<a href="/search/eess?searchtype=author&query=Zhu%2C+P">Peiying Zhu</a>, 
<a href="/search/eess?searchtype=author&query=Letaief%2C+K+B">Khaled B Letaief</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Information Theory (cs.IT)

</div>
</div>
</dd>
<dt><a name="item855">[855]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.00831" title="Abstract">arXiv:2309.00831</a> (replaced) [<a href="/pdf/2309.00831" title="Download PDF">pdf</a>, <a href="/format/2309.00831" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multi-scale, Data-driven and Anatomically Constrained Deep Learning  Image Registration for Adult and Fetal Echocardiography
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Hasan%2C+M+K">Md. Kamrul Hasan</a>, 
<a href="/search/eess?searchtype=author&query=Zhu%2C+H">Haobo Zhu</a>, 
<a href="/search/eess?searchtype=author&query=Yang%2C+G">Guang Yang</a>, 
<a href="/search/eess?searchtype=author&query=Yap%2C+C+H">Choon Hwai Yap</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Our data-driven and anatomically constrained DLIR method's source code will be publicly available at <a href="https://github.com/kamruleee51/DdC-AC-DLIR">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item856">[856]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01007" title="Abstract">arXiv:2309.01007</a> (replaced) [<a href="/pdf/2309.01007" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Comparative Analysis of Deep Learning Architectures for Breast Cancer  Diagnosis Using the BreaKHis Dataset
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Say%C4%B1n%2C+%C4%B0">&#x130;rem Say&#x131;n</a>, 
<a href="/search/eess?searchtype=author&query=Soyda%C5%9F%2C+M+A">Muhammed Ali Soyda&#x15f;</a>, 
<a href="/search/eess?searchtype=author&query=Mert%2C+Y+E">Yunus Emre Mert</a>, 
<a href="/search/eess?searchtype=author&query=Yarkata%C5%9F%2C+A">Arda Yarkata&#x15f;</a>, 
<a href="/search/eess?searchtype=author&query=Ergun%2C+B">Berk Ergun</a>, 
<a href="/search/eess?searchtype=author&query=Yeh%2C+S+S">Selma S&#xf6;zen Yeh</a>, 
<a href="/search/eess?searchtype=author&query=%C3%9Cvet%2C+H">H&#xfc;seyin &#xdc;vet</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, 1 figure, 2 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item857">[857]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01199" title="Abstract">arXiv:2309.01199</a> (replaced) [<a href="/pdf/2309.01199" title="Download PDF">pdf</a>, <a href="/format/2309.01199" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DKWS: A Distributed System for Keyword Search on Massive Graphs  (Complete Version)
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jiang%2C+J">Jiaxin Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Choi%2C+B">Byron Choi</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+X">Xin Huang</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+J">Jianliang Xu</a>, 
<a href="/search/cs?searchtype=author&query=Bhowmick%2C+S+S">Sourav S Bhowmick</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Databases (cs.DB)</span>

</div>
</div>
</dd>
<dt><a name="item858">[858]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01237" title="Abstract">arXiv:2309.01237</a> (replaced) [<a href="/pdf/2309.01237" title="Download PDF">pdf</a>, <a href="/format/2309.01237" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Information Geometry of UMAP
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kolpakov%2C+A">Alexander Kolpakov</a>, 
<a href="/search/cs?searchtype=author&query=Rocke%2C+A">Aidan Rocke</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 2 figures; Github repo (<a href="https://github.com/sashakolpakov/info-geometry-umap">this https URL</a>)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Geometry (cs.CG)</span>; Discrete Mathematics (cs.DM); Information Theory (cs.IT); Geometric Topology (math.GT)

</div>
</div>
</dd>
<dt><a name="item859">[859]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01361" title="Abstract">arXiv:2309.01361</a> (replaced) [<a href="/pdf/2309.01361" title="Download PDF">pdf</a>, <a href="/format/2309.01361" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> High Frequency, High Accuracy Pointing onboard Nanosats using  Neuromorphic Event Sensing and Piezoelectric Actuation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Latif%2C+Y">Yasir Latif</a>, 
<a href="/search/cs?searchtype=author&query=Anastasiou%2C+P">Peter Anastasiou</a>, 
<a href="/search/cs?searchtype=author&query=Ng%2C+Y">Yonhon Ng</a>, 
<a href="/search/cs?searchtype=author&query=Prime%2C+Z">Zebb Prime</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+T">Tien-Fu Lu</a>, 
<a href="/search/cs?searchtype=author&query=Tetlow%2C+M">Matthew Tetlow</a>, 
<a href="/search/cs?searchtype=author&query=Mahony%2C+R">Robert Mahony</a>, 
<a href="/search/cs?searchtype=author&query=Chin%2C+T">Tat-Jun Chin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Emerging Technologies (cs.ET)</span>; Computer Vision and Pattern Recognition (cs.CV); Robotics (cs.RO)

</div>
</div>
</dd>
<dt><a name="item860">[860]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01380" title="Abstract">arXiv:2309.01380</a> (replaced) [<a href="/pdf/2309.01380" title="Download PDF">pdf</a>, <a href="/format/2309.01380" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Understanding Video Scenes through Text: Insights from Text-based Video  Question Answering
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jahagirdar%2C+S">Soumya Jahagirdar</a>, 
<a href="/search/cs?searchtype=author&query=Mathew%2C+M">Minesh Mathew</a>, 
<a href="/search/cs?searchtype=author&query=Karatzas%2C+D">Dimosthenis Karatzas</a>, 
<a href="/search/cs?searchtype=author&query=Jawahar%2C+C+V">C. V. Jawahar</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item861">[861]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01592" title="Abstract">arXiv:2309.01592</a> (replaced) [<a href="/pdf/2309.01592" title="Download PDF">pdf</a>, <a href="/format/2309.01592" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Les Houches Lectures on Deep Learning at Large &amp; Infinite Width
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Bahri%2C+Y">Yasaman Bahri</a>, 
<a href="/search/stat?searchtype=author&query=Hanin%2C+B">Boris Hanin</a>, 
<a href="/search/stat?searchtype=author&query=Brossollet%2C+A">Antonin Brossollet</a>, 
<a href="/search/stat?searchtype=author&query=Erba%2C+V">Vittorio Erba</a>, 
<a href="/search/stat?searchtype=author&query=Keup%2C+C">Christian Keup</a>, 
<a href="/search/stat?searchtype=author&query=Pacelli%2C+R">Rosalba Pacelli</a>, 
<a href="/search/stat?searchtype=author&query=Simon%2C+J+B">James B. Simon</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> These are notes from lectures delivered by Yasaman Bahri and Boris Hanin at the 2022 Les Houches Summer School on Statistics Physics and Machine Learning and a first version of them were transcribed by Antonin Brossollet, Vittorio Erba, Christian Keup, Rosalba Pacelli, James B. Simon
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); High Energy Physics - Theory (hep-th); Probability (math.PR)

</div>
</div>
</dd>
<dt><a name="item862">[862]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01655" title="Abstract">arXiv:2309.01655</a> (replaced) [<a href="/pdf/2309.01655" title="Download PDF">pdf</a>, <a href="/ps/2309.01655" title="Download PostScript">ps</a>, <a href="/format/2309.01655" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Rate-Splitting and Sum-DoF for the K-User MISO Broadcast Channel with  Mixed CSIT and Order-(K-1) Messages
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zheng%2C+S">Shuo Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+T">Tong Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jingfu Li</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Shuai Wang</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+W">Weijie Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+G">Gaojie Chen</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+R">Rui Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This work has been accepted by VTC2023-Fall
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>

</div>
</div>
</dd>
<dt><a name="item863">[863]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01717" title="Abstract">arXiv:2309.01717</a> (replaced) [<a href="/pdf/2309.01717" title="Download PDF">pdf</a>, <a href="/format/2309.01717" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Interdisciplinary Fairness in Imbalanced Research Proposal Topic  Inference: A Hierarchical Transformer-based Method with Selective  Interpolation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xiao%2C+M">Meng Xiao</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+M">Min Wu</a>, 
<a href="/search/cs?searchtype=author&query=Qiao%2C+Z">Ziyue Qiao</a>, 
<a href="/search/cs?searchtype=author&query=Fu%2C+Y">Yanjie Fu</a>, 
<a href="/search/cs?searchtype=author&query=Ning%2C+Z">Zhiyuan Ning</a>, 
<a href="/search/cs?searchtype=author&query=Du%2C+Y">Yi Du</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Y">Yuanchun Zhou</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 19 pages, Under review. arXiv admin note: text overlap with <a href="/abs/2209.13912">arXiv:2209.13912</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item864">[864]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01791" title="Abstract">arXiv:2309.01791</a> (replaced) [<a href="/pdf/2309.01791" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Non-Transitivity of the Win Ratio and the Area Under the Receiver  Operating Characteristics Curve (AUC): a case for evaluating the strength of  stochastic comparisons
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Demler%2C+O+V">Olga V. Demler</a>, 
<a href="/search/stat?searchtype=author&query=Demler%2C+I+A">Ilona A. Demler</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Methodology (stat.ME)</span>; Performance (cs.PF); Econometrics (econ.EM); Statistics Theory (math.ST); Applications (stat.AP)

</div>
</div>
</dd>
<dt><a name="item865">[865]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01838" title="Abstract">arXiv:2309.01838</a> (replaced) [<a href="/pdf/2309.01838" title="Download PDF">pdf</a>, <a href="/format/2309.01838" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Efficient Defense Against Model Stealing Attacks on Convolutional Neural  Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Khaled%2C+K">Kacem Khaled</a>, 
<a href="/search/cs?searchtype=author&query=Dhaouadi%2C+M">Mouna Dhaouadi</a>, 
<a href="/search/cs?searchtype=author&query=de+Magalh%C3%A3es%2C+F+G">Felipe Gohring de Magalh&#xe3;es</a>, 
<a href="/search/cs?searchtype=author&query=Nicolescu%2C+G">Gabriela Nicolescu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted for publication at 2023 International Conference on Machine Learning and Applications (ICMLA). Proceedings of ICMLA, Florida, USA \c{opyright}2023 IEEE
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Cryptography and Security (cs.CR)

</div>
</div>
</dd>
<dt><a name="item866">[866]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01920" title="Abstract">arXiv:2309.01920</a> (replaced) [<a href="/pdf/2309.01920" title="Download PDF">pdf</a>, <a href="/format/2309.01920" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Dual Auction Mechanism for Transaction Forwarding and Validation in  Complex Wireless Blockchain Network
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+W">Weiyi Wang</a>, 
<a href="/search/cs?searchtype=author&query=Jiao%2C+Y">Yutao Jiao</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Jin Chen</a>, 
<a href="/search/cs?searchtype=author&query=Dai%2C+W">Wenting Dai</a>, 
<a href="/search/cs?searchtype=author&query=Kang%2C+J">Jiawen Kang</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+Y">Yuhua Xu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>; Computer Science and Game Theory (cs.GT)

</div>
</div>
</dd>
<dt><a name="item867">[867]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01940" title="Abstract">arXiv:2309.01940</a> (replaced) [<a href="/pdf/2309.01940" title="Download PDF">pdf</a>, <a href="/format/2309.01940" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CodeApex: A Bilingual Programming Evaluation Benchmark for Large  Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fu%2C+L">Lingyue Fu</a>, 
<a href="/search/cs?searchtype=author&query=Chai%2C+H">Huacan Chai</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+S">Shuang Luo</a>, 
<a href="/search/cs?searchtype=author&query=Du%2C+K">Kounianhua Du</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+W">Weiming Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Fan%2C+L">Longteng Fan</a>, 
<a href="/search/cs?searchtype=author&query=Lei%2C+J">Jiayi Lei</a>, 
<a href="/search/cs?searchtype=author&query=Rui%2C+R">Renting Rui</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+J">Jianghao Lin</a>, 
<a href="/search/cs?searchtype=author&query=Fang%2C+Y">Yuchen Fang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yifan Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jingkuan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Qi%2C+S">Siyuan Qi</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+K">Kangning Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+W">Weinan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+Y">Yong Yu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 21 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item868">[868]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01961" title="Abstract">arXiv:2309.01961</a> (replaced) [<a href="/pdf/2309.01961" title="Download PDF">pdf</a>, <a href="/format/2309.01961" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> NICE: CVPR 2023 Challenge on Zero-shot Image Captioning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kim%2C+T">Taehoon Kim</a>, 
<a href="/search/cs?searchtype=author&query=Ahn%2C+P">Pyunghwan Ahn</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+S">Sangyun Kim</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+S">Sihaeng Lee</a>, 
<a href="/search/cs?searchtype=author&query=Marsden%2C+M">Mark Marsden</a>, 
<a href="/search/cs?searchtype=author&query=Sala%2C+A">Alessandra Sala</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+S+H">Seung Hwan Kim</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+B">Bohyung Han</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+K+M">Kyoung Mu Lee</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+H">Honglak Lee</a>, 
<a href="/search/cs?searchtype=author&query=Bae%2C+K">Kyounghoon Bae</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+X">Xiangyu Wu</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+Y">Yi Gao</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Hailiang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yang Yang</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+W">Weili Guo</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+J">Jianfeng Lu</a>, 
<a href="/search/cs?searchtype=author&query=Oh%2C+Y">Youngtaek Oh</a>, 
<a href="/search/cs?searchtype=author&query=Cho%2C+J+W">Jae Won Cho</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+D">Dong-jin Kim</a>, 
<a href="/search/cs?searchtype=author&query=Kweon%2C+I+S">In So Kweon</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+J">Junmo Kim</a>, 
<a href="/search/cs?searchtype=author&query=Kang%2C+W">Wooyoung Kang</a>, 
<a href="/search/cs?searchtype=author&query=Jhoo%2C+W+Y">Won Young Jhoo</a>, 
<a href="/search/cs?searchtype=author&query=Roh%2C+B">Byungseok Roh</a>, 
<a href="/search/cs?searchtype=author&query=Mun%2C+J">Jonghwan Mun</a>, 
<a href="/search/cs?searchtype=author&query=Oh%2C+S">Solgil Oh</a>, 
<a href="/search/cs?searchtype=author&query=Ak%2C+K+E">Kenan Emir Ak</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+G">Gwang-Gook Lee</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+Y">Yan Xu</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+M">Mingwei Shen</a>, 
<a href="/search/cs?searchtype=author&query=Hwang%2C+K">Kyomin Hwang</a>, 
<a href="/search/cs?searchtype=author&query=Shin%2C+W">Wonsik Shin</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+K">Kamin Lee</a>, 
<a href="/search/cs?searchtype=author&query=Park%2C+W">Wonhark Park</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+D">Dongkwan Lee</a>, 
<a href="/search/cs?searchtype=author&query=Kwak%2C+N">Nojun Kwak</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yujin Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yimu Wang</a>, 
<a href="/search/cs?searchtype=author&query=Gu%2C+T">Tiancheng Gu</a>, 
<a href="/search/cs?searchtype=author&query=Lv%2C+X">Xingchang Lv</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+M">Mingmao Sun</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Tech report, project page <a href="https://nice.lgresearch.ai/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item869">[869]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.02247" title="Abstract">arXiv:2309.02247</a> (replaced) [<a href="/pdf/2309.02247" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Autonomous Cyber Operation Agents: Exploring the Red Case
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+L">Li Li</a>, 
<a href="/search/cs?searchtype=author&query=Rami%2C+J+S+E">Jean-Pierre S. El Rami</a>, 
<a href="/search/cs?searchtype=author&query=Kerr%2C+R">Ryan Kerr</a>, 
<a href="/search/cs?searchtype=author&query=Taylor%2C+A">Adrian Taylor</a>, 
<a href="/search/cs?searchtype=author&query=Vandenberghe%2C+G">Grant Vandenberghe</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Presented at 2nd International Workshop on Adaptive Cyber Defense, 2023 (<a href="/abs/2308.09520">arXiv:2308.09520</a>)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
</div>
</dd>
<dt><a name="item870">[870]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.02567" title="Abstract">arXiv:2309.02567</a> (replaced) [<a href="/pdf/2309.02567" title="Download PDF">pdf</a>, <a href="/format/2309.02567" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Symbolic Music Representations for Classification Tasks: A Systematic  Evaluation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Zhang%2C+H">Huan Zhang</a>, 
<a href="/search/eess?searchtype=author&query=Karystinaios%2C+E">Emmanouil Karystinaios</a>, 
<a href="/search/eess?searchtype=author&query=Dixon%2C+S">Simon Dixon</a>, 
<a href="/search/eess?searchtype=author&query=Widmer%2C+G">Gerhard Widmer</a>, 
<a href="/search/eess?searchtype=author&query=Cancino-Chac%C3%B3n%2C+C+E">Carlos Eduardo Cancino-Chac&#xf3;n</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To be published in the Proceedings of the 24th International Society for Music Information Retrieval Conference (ISMIR 2023), Milan, Italy
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Proceedings of the 24th International Society for Music
  Information Retrieval Conference (ISMIR 2023), Milan, Italy
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Multimedia (cs.MM); Sound (cs.SD)

</div>
</div>
</dd>
<dt><a name="item871">[871]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.02612" title="Abstract">arXiv:2309.02612</a> (replaced) [<a href="/pdf/2309.02612" title="Download PDF">pdf</a>, <a href="/format/2309.02612" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Music Source Separation with Band-Split RoPE Transformer
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lu%2C+W">Wei-Tsung Lu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Ju-Chiang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Kong%2C+Q">Qiuqiang Kong</a>, 
<a href="/search/cs?searchtype=author&query=Hung%2C+Y">Yun-Ning Hung</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This paper explains the SAMI-ByteDance MSS system submitted to Sound Demixing Challenge (SDX23) Music Separation Track. Version 2 of paper fixed some typos
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Audio and Speech Processing (eess.AS)

</div>
</div>
</dd>
<dt><a name="item872">[872]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.02780" title="Abstract">arXiv:2309.02780</a> (replaced) [<a href="/pdf/2309.02780" title="Download PDF">pdf</a>, <a href="/format/2309.02780" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GRASS: Unified Generation Model for Speech-to-Semantic Tasks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xia%2C+A">Aobo Xia</a>, 
<a href="/search/cs?searchtype=author&query=Lei%2C+S">Shuyu Lei</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yushu Yang</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+X">Xiang Guo</a>, 
<a href="/search/cs?searchtype=author&query=Chai%2C+H">Hua Chai</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Sound (cs.SD); Audio and Speech Processing (eess.AS)

</div>
</div>
</dd>
<dt><a name="item873">[873]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.02869" title="Abstract">arXiv:2309.02869</a> (replaced) [<a href="/pdf/2309.02869" title="Download PDF">pdf</a>, <a href="/format/2309.02869" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On Reducing Undesirable Behavior in Deep Reinforcement Learning Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Carmel%2C+O+M">Ophir M. Carmel</a>, 
<a href="/search/cs?searchtype=author&query=Katz%2C+G">Guy Katz</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item874">[874]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.02968" title="Abstract">arXiv:2309.02968</a> (replaced) [<a href="/pdf/2309.02968" title="Download PDF">pdf</a>, <a href="/format/2309.02968" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CR-VAE: Contrastive Regularization on Variational Autoencoders for  Preventing Posterior Collapse
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lygerakis%2C+F">Fotios Lygerakis</a>, 
<a href="/search/cs?searchtype=author&query=Rueckert%2C+E">Elmar Rueckert</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item875">[875]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.03028" title="Abstract">arXiv:2309.03028</a> (replaced) [<a href="/pdf/2309.03028" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A high-performance deep reservoir computing experimentally demonstrated  with ion-gating reservoirs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Nishioka%2C+D">Daiki Nishioka</a>, 
<a href="/search/physics?searchtype=author&query=Tsuchiya%2C+T">Takashi Tsuchiya</a>, 
<a href="/search/physics?searchtype=author&query=Imura%2C+M">Masataka Imura</a>, 
<a href="/search/physics?searchtype=author&query=Koide%2C+Y">Yasuo Koide</a>, 
<a href="/search/physics?searchtype=author&query=Higuchi%2C+T">Tohru Higuchi</a>, 
<a href="/search/physics?searchtype=author&query=Terabe%2C+K">Kazuya Terabe</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 21 pages, 6 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Applied Physics (physics.app-ph)</span>; Emerging Technologies (cs.ET)

</div>
</div>
</dd>
<dt><a name="item876">[876]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.03038" title="Abstract">arXiv:2309.03038</a> (replaced) [<a href="/pdf/2309.03038" title="Download PDF">pdf</a>, <a href="/format/2309.03038" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Cellular Wireless Networks in the Upper Mid-Band
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kang%2C+S">Seongjoon Kang</a>, 
<a href="/search/cs?searchtype=author&query=Mezzavilla%2C+M">Marco Mezzavilla</a>, 
<a href="/search/cs?searchtype=author&query=Rangan%2C+S">Sundeep Rangan</a>, 
<a href="/search/cs?searchtype=author&query=Madanayake%2C+A">Arjuna Madanayake</a>, 
<a href="/search/cs?searchtype=author&query=Venkatakrishnan%2C+S+B">Satheesh Bojja Venkatakrishnan</a>, 
<a href="/search/cs?searchtype=author&query=Hellbourg%2C+G">Gregory Hellbourg</a>, 
<a href="/search/cs?searchtype=author&query=Ghosh%2C+M">Monisha Ghosh</a>, 
<a href="/search/cs?searchtype=author&query=Rahmani%2C+H">Hamed Rahmani</a>, 
<a href="/search/cs?searchtype=author&query=Dhananjay%2C+A">Aditya Dhananjay</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>; Signal Processing (eess.SP)

</div>
</div>
</dd>
<dt><a name="item877">[877]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.03048" title="Abstract">arXiv:2309.03048</a> (replaced) [<a href="/pdf/2309.03048" title="Download PDF">pdf</a>, <a href="/format/2309.03048" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exploring Semantic Consistency in Unpaired Image Translation to Generate  Data for Surgical Applications
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Venkatesh%2C+D+K">Danush Kumar Venkatesh</a>, 
<a href="/search/cs?searchtype=author&query=Rivoir%2C+D">Dominik Rivoir</a>, 
<a href="/search/cs?searchtype=author&query=Pfeiffer%2C+M">Micha Pfeiffer</a>, 
<a href="/search/cs?searchtype=author&query=Kolbinger%2C+F">Fiona Kolbinger</a>, 
<a href="/search/cs?searchtype=author&query=Distler%2C+M">Marius Distler</a>, 
<a href="/search/cs?searchtype=author&query=Weitz%2C+J">J&#xfc;rgen Weitz</a>, 
<a href="/search/cs?searchtype=author&query=Speidel%2C+S">Stefanie Speidel</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item878">[878]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.03224" title="Abstract">arXiv:2309.03224</a> (replaced) [<a href="/pdf/2309.03224" title="Download PDF">pdf</a>, <a href="/format/2309.03224" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> No Train Still Gain. Unleash Mathematical Reasoning of Large Language  Models with Monte Carlo Tree Search Guided by Energy Function
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+H">Haotian Xu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> still in progress
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item879">[879]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.03307" title="Abstract">arXiv:2309.03307</a> (replaced) [<a href="/pdf/2309.03307" title="Download PDF">pdf</a>, <a href="/format/2309.03307" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Several fitness functions and entanglement gates in quantum kernel  generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Wang%2C+H">Haiyan Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item880">[880]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.03808" title="Abstract">arXiv:2309.03808</a> (replaced) [<a href="/pdf/2309.03808" title="Download PDF">pdf</a>, <a href="/format/2309.03808" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Improved theoretical guarantee for rank aggregation via spectral method
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Zhong%2C+Z+S">Ziliang Samuel Zhong</a>, 
<a href="/search/stat?searchtype=author&query=Ling%2C+S">Shuyang Ling</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 29 pages, 6 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG); Optimization and Control (math.OC)

</div>
</div>
</dd>
<dt><a name="item881">[881]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.03984" title="Abstract">arXiv:2309.03984</a> (replaced) [<a href="/pdf/2309.03984" title="Download PDF">pdf</a>, <a href="/format/2309.03984" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Enhancing accuracy for solving American CEV model with high-order  compact scheme and adaptive time stepping
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-fin?searchtype=author&query=Nwankwo%2C+C">Chinonso Nwankwo</a>, 
<a href="/search/q-fin?searchtype=author&query=Dai%2C+W">Weizhong Dai</a>, 
<a href="/search/q-fin?searchtype=author&query=Ware%2C+T">Tony Ware</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Finance (q-fin.CP)</span>; Numerical Analysis (math.NA); Mathematical Finance (q-fin.MF); Pricing of Securities (q-fin.PR)

</div>
</div>
</dd>
<dt><a name="item882">[882]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.04077" title="Abstract">arXiv:2309.04077</a> (replaced) [<a href="/pdf/2309.04077" title="Download PDF">pdf</a>, <a href="/format/2309.04077" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SayNav: Grounding Large Language Models for Dynamic Planning to  Navigation in New Environments
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rajvanshi%2C+A">Abhinav Rajvanshi</a>, 
<a href="/search/cs?searchtype=author&query=Sikka%2C+K">Karan Sikka</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+X">Xiao Lin</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+B">Bhoram Lee</a>, 
<a href="/search/cs?searchtype=author&query=Chiu%2C+H">Han-Pang Chiu</a>, 
<a href="/search/cs?searchtype=author&query=Velasquez%2C+A">Alvaro Velasquez</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item883">[883]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.04154" title="Abstract">arXiv:2309.04154</a> (replaced) [<a href="/pdf/2309.04154" title="Download PDF">pdf</a>, <a href="/format/2309.04154" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A novel model for layer jamming-based continuum robots
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yi%2C+B">Bowen Yi</a>, 
<a href="/search/cs?searchtype=author&query=Fan%2C+Y">Yeman Fan</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+D">Dikai Liu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Systems and Control (eess.SY)

</div>
</div>
</dd>
<dt><a name="item884">[884]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.04190" title="Abstract">arXiv:2309.04190</a> (replaced) [<a href="/pdf/2309.04190" title="Download PDF">pdf</a>, <a href="/format/2309.04190" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SegmentAnything helps microscopy images based automatic and quantitative  organoid detection and analysis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Xing%2C+X">Xiaodan Xing</a>, 
<a href="/search/eess?searchtype=author&query=Tang%2C+C">Chunling Tang</a>, 
<a href="/search/eess?searchtype=author&query=Guo%2C+Y">Yunzhe Guo</a>, 
<a href="/search/eess?searchtype=author&query=Kurniawan%2C+N">Nicholas Kurniawan</a>, 
<a href="/search/eess?searchtype=author&query=Yang%2C+G">Guang Yang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> submitted to SPIE: Medical Imaging 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV); Quantitative Methods (q-bio.QM)

</div>
</div>
</dd>
<dt><a name="item885">[885]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.04389" title="Abstract">arXiv:2309.04389</a> (replaced) [<a href="/pdf/2309.04389" title="Download PDF">pdf</a>, <a href="/format/2309.04389" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CSPRD: A Financial Policy Retrieval Dataset for Chinese Stock Market
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jinyuan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+H">Hai Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zhong Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+Z">Zeyang Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+J">Jinhao Xie</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+Y">Yong Yu</a>, 
<a href="/search/cs?searchtype=author&query=Fei%2C+Y">Yongjian Fei</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+Y">Yue Huang</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+D">Dawei Cheng</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Computational Engineering, Finance, and Science (cs.CE)

</div>
</div>
</dd>
</dl>
<ul>
<li><a href="/list/cs/new?skip=0&amp;show=2000">New submissions</a></li>
<li><a href="#item487">Cross-lists</a></li>
<li><a href="#item551">Replacements</a></li>
</ul>
<small>[ total of 885 entries:  <b>1-885</b>  ]</small><br />
<small>[ showing up to 2000 entries per page:  <a href="/list/cs/new?skip=0&amp;show=1000">fewer</a> |  <font color="#999999">more</font> ]</small><br />
</div>
<br/><small><a id="mathjax_toggle" href="javascript:setMathjaxCookie()">Disable MathJax</a> (<a href="/help/mathjax">What is MathJax?</a>)</small><script type="text/javascript" language="javascript">mathjaxToggle();</script>

<hr />
<p>Links to:
<a href="/" accesskey="a">arXiv</a>,
<a href="/form/cs">form interface</a>,
<a href="/find/cs">find</a>,
<a href="/archive/cs">cs</a>, <a href="/list/cs/recent">recent</a>, <a href="/list/cs/2309">2309</a>,
<a href="/help/contact">contact</a>,
<a href="/help/" accesskey="h"><span class="accesskey">h</span>elp</a>&nbsp;
<small>(<a href="/help/accesskeys">Access key</a> information)</small>
</p>
<hr />
</div>
</div>
 <footer style="clear: both;">
      <div class="columns is-desktop" role="navigation" aria-label="Secondary" style="margin: -0.75em -0.75em 0.75em -0.75em">
        <!-- Macro-Column 1 -->
        <div class="column" style="padding: 0;">
          <div class="columns">
            <div class="column">
              <ul style="list-style: none; line-height: 2;">
                <li><a href="https://arxiv.org/about">About</a></li>
                <li><a href="https://arxiv.org/help">Help</a></li>
              </ul>
            </div>
            <div class="column">
              <ul style="list-style: none; line-height: 2;">
                <li>
                  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon filter-black" role="presentation"><title>contact arXiv</title><desc>Click here to contact arXiv</desc><path d="M502.3 190.8c3.9-3.1 9.7-.2 9.7 4.7V400c0 26.5-21.5 48-48 48H48c-26.5 0-48-21.5-48-48V195.6c0-5 5.7-7.8 9.7-4.7 22.4 17.4 52.1 39.5 154.1 113.6 21.1 15.4 56.7 47.8 92.2 47.6 35.7.3 72-32.8 92.3-47.6 102-74.1 131.6-96.3 154-113.7zM256 320c23.2.4 56.6-29.2 73.4-41.4 132.7-96.3 142.8-104.7 173.4-128.7 5.8-4.5 9.2-11.5 9.2-18.9v-19c0-26.5-21.5-48-48-48H48C21.5 64 0 85.5 0 112v19c0 7.4 3.4 14.3 9.2 18.9 30.6 23.9 40.7 32.4 173.4 128.7 16.8 12.2 50.2 41.8 73.4 41.4z"/></svg>
                  <a href="https://arxiv.org/help/contact"> Contact</a>
                </li>
                <li>
                  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon filter-black" role="presentation"><title>subscribe to arXiv mailings</title><desc>Click here to subscribe</desc><path d="M476 3.2L12.5 270.6c-18.1 10.4-15.8 35.6 2.2 43.2L121 358.4l287.3-253.2c5.5-4.9 13.3 2.6 8.6 8.3L176 407v80.5c0 23.6 28.5 32.9 42.5 15.8L282 426l124.6 52.2c14.2 6 30.4-2.9 33-18.2l72-432C515 7.8 493.3-6.8 476 3.2z"/></svg>
                  <a href="https://arxiv.org/help/subscribe"> Subscribe</a>
                </li>
              </ul>
            </div>
          </div>
        </div>
        <!-- End Macro-Column 1 -->
        <!-- Macro-Column 2 -->
        <div class="column" style="padding: 0;">
          <div class="columns">
            <div class="column">
              <ul style="list-style: none; line-height: 2;">
                <li><a href="https://arxiv.org/help/license">Copyright</a></li>
                <li><a href="https://arxiv.org/help/policies/privacy_policy">Privacy Policy</a></li>
              </ul>
            </div>
            <div class="column sorry-app-links">
              <ul style="list-style: none; line-height: 2;">
                <li><a href="https://arxiv.org/help/web_accessibility">Web Accessibility Assistance</a></li>
                <li>
                  <p class="help">
                    <a class="a11y-main-link" href="https://status.arxiv.org" target="_blank">arXiv Operational Status <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 256 512" class="icon filter-dark_grey" role="presentation"><path d="M224.3 273l-136 136c-9.4 9.4-24.6 9.4-33.9 0l-22.6-22.6c-9.4-9.4-9.4-24.6 0-33.9l96.4-96.4-96.4-96.4c-9.4-9.4-9.4-24.6 0-33.9L54.3 103c9.4-9.4 24.6-9.4 33.9 0l136 136c9.5 9.4 9.5 24.6.1 34z"/></svg></a><br>
                    Get status notifications via
                    <a class="is-link" href="https://subscribe.sorryapp.com/24846f03/email/new" target="_blank"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon filter-black" role="presentation"><path d="M502.3 190.8c3.9-3.1 9.7-.2 9.7 4.7V400c0 26.5-21.5 48-48 48H48c-26.5 0-48-21.5-48-48V195.6c0-5 5.7-7.8 9.7-4.7 22.4 17.4 52.1 39.5 154.1 113.6 21.1 15.4 56.7 47.8 92.2 47.6 35.7.3 72-32.8 92.3-47.6 102-74.1 131.6-96.3 154-113.7zM256 320c23.2.4 56.6-29.2 73.4-41.4 132.7-96.3 142.8-104.7 173.4-128.7 5.8-4.5 9.2-11.5 9.2-18.9v-19c0-26.5-21.5-48-48-48H48C21.5 64 0 85.5 0 112v19c0 7.4 3.4 14.3 9.2 18.9 30.6 23.9 40.7 32.4 173.4 128.7 16.8 12.2 50.2 41.8 73.4 41.4z"/></svg>email</a>
                    or <a class="is-link" href="https://subscribe.sorryapp.com/24846f03/slack/new" target="_blank"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512" class="icon filter-black" role="presentation"><path d="M94.12 315.1c0 25.9-21.16 47.06-47.06 47.06S0 341 0 315.1c0-25.9 21.16-47.06 47.06-47.06h47.06v47.06zm23.72 0c0-25.9 21.16-47.06 47.06-47.06s47.06 21.16 47.06 47.06v117.84c0 25.9-21.16 47.06-47.06 47.06s-47.06-21.16-47.06-47.06V315.1zm47.06-188.98c-25.9 0-47.06-21.16-47.06-47.06S139 32 164.9 32s47.06 21.16 47.06 47.06v47.06H164.9zm0 23.72c25.9 0 47.06 21.16 47.06 47.06s-21.16 47.06-47.06 47.06H47.06C21.16 243.96 0 222.8 0 196.9s21.16-47.06 47.06-47.06H164.9zm188.98 47.06c0-25.9 21.16-47.06 47.06-47.06 25.9 0 47.06 21.16 47.06 47.06s-21.16 47.06-47.06 47.06h-47.06V196.9zm-23.72 0c0 25.9-21.16 47.06-47.06 47.06-25.9 0-47.06-21.16-47.06-47.06V79.06c0-25.9 21.16-47.06 47.06-47.06 25.9 0 47.06 21.16 47.06 47.06V196.9zM283.1 385.88c25.9 0 47.06 21.16 47.06 47.06 0 25.9-21.16 47.06-47.06 47.06-25.9 0-47.06-21.16-47.06-47.06v-47.06h47.06zm0-23.72c-25.9 0-47.06-21.16-47.06-47.06 0-25.9 21.16-47.06 47.06-47.06h117.84c25.9 0 47.06 21.16 47.06 47.06 0 25.9-21.16 47.06-47.06 47.06H283.1z"/></svg>slack</a>
                  </p>
                </li>
              </ul>
            </div>
          </div>
        </div> <!-- end MetaColumn 2 -->
        <!-- End Macro-Column 2 -->
      </div>
    </footer>
</body>
</html>
