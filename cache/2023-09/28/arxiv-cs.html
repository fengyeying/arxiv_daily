<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en">
<head>
<title>Computer Science  authors/titles &quot;new&quot;</title>
<link rel="shortcut icon" href="/favicon.ico" type="image/x-icon" />
<link rel="stylesheet" type="text/css" media="screen" href="//static.arxiv.org/static/browse/0.3.2.8/css/arXiv.css?v=20220215" />
<link rel="stylesheet" type="text/css" media="screen" href="/bibex/bibex.css?20181009">
<link rel="stylesheet" type="text/css" media="screen" href="https://static.arxiv.org/static/browse/0.3.8/css/browse_search.css" />
<link rel="alternate" type="application/rss+xml" title="Computer Science " href="http://arxiv.org/rss/cs"/>
<script src="/js/mathjaxToggle.min.js" type="text/javascript"></script>


</head>
<body class="with-cu-identity">

<div id="cu-identity">
<div id="cu-logo">
<a href="https://www.cornell.edu/"><img src="//static.arxiv.org/icons/cu/cornell-reduced-white-SMALL.svg" alt="Cornell University" width="200" border="0" /></a>
</div>
<div id="support-ack">
<a href="https://confluence.cornell.edu/x/ALlRF">We gratefully acknowledge support from<br /> the Simons Foundation and member institutions.</a>
</div>
</div>
<div id="header">
<h1 class="header-breadcrumbs"><a href="/"><img src="//static.arxiv.org/images/arxiv-logo-one-color-white.svg" aria-label="logo" alt="arxiv logo" width="85" style="width:85px;margin-right:8px;"></a> <span>&gt;</span> <a href="/list/cs/recent">cs</a></h1>
<div class="search-block level-right">
<form class="level-item mini-search" method="GET" action="https://arxiv.org/search" _lpchecked="1">
<div class="field has-addons">
<div class="control">
<input class="input is-small" type="text" name="query" placeholder="Search..." aria-label="Search term or terms" data-com.agilebits.onepassword.user-edited="yes">
<p class="help"><a href="https://arxiv.org/help">Help</a> | <a href="https://arxiv.org/search/advanced">Advanced Search</a></p>
</div>
<div class="control">
<div class="select is-small">
<select name="searchtype" aria-label="Field to search">
<option value="all" selected="selected">All fields</option>
<option value="title">Title</option>
<option value="author">Author</option>
<option value="abstract">Abstract</option>
<option value="comments">Comments</option>
<option value="journal_ref">Journal reference</option>
<option value="acm_class">ACM classification</option>
<option value="msc_class">MSC classification</option>
<option value="report_num">Report number</option>
<option value="paper_id">arXiv identifier</option>
<option value="doi">DOI</option>
<option value="orcid">ORCID</option>
<option value="author_id">arXiv author ID</option>
<option value="help">Help pages</option>
<option value="full_text">Full text</option>
</select>
</div>
</div>
<button class="button is-small is-cul-darker">Search</button>
</div>
</form>
</div>
</div>
<div id="content">
<div id="dlpage">
<h1>Computer Science </h1>
<h2>New submissions</h2>
<div class="list-dateline">Submissions received from  Tue 26 Sep 23  to  Wed 27 Sep 23, announced Thu, 28 Sep 23</div>
<ul>
<li><a href="/list/cs/new?skip=0&amp;show=2000">New submissions</a></li>
<li><a href="#item288">Cross-lists</a></li>
<li><a href="#item331">Replacements</a></li>
</ul>
<small>[ total of 539 entries:  <b>1-539</b>  ]</small><br />
<small>[ showing up to 2000 entries per page:  <a href="/list/cs/new?skip=0&amp;show=1000">fewer</a> |  <font color="#999999">more</font> ]</small><br />
<h3>New submissions for Thu, 28 Sep 23</h3>
<dl>
<dt><a name="item1">[1]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15128" title="Abstract">arXiv:2309.15128</a> [<a href="/pdf/2309.15128" title="Download PDF">pdf</a>, <a href="/format/2309.15128" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DPA-WNO: A gray box model for a class of stochastic mechanics problem
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tushar">Tushar</a>, 
<a href="/search/cs?searchtype=author&query=Chakraborty%2C+S">Souvik Chakraborty</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">The well-known governing physics in science and engineering is often based on
certain assumptions and approximations. Therefore, analyses and designs carried
out based on these equations are also approximate. The emergence of data-driven
models has, to a certain degree, addressed this challenge; however, the purely
data-driven models often (a) lack interpretability, (b) are data-hungry, and
(c) do not generalize beyond the training window. Operator learning has
recently been proposed as a potential alternative to address the aforementioned
challenges; however, the challenges are still persistent. We here argue that
one of the possible solutions resides in data-physics fusion, where the
data-driven model is used to correct/identify the missing physics. To that end,
we propose a novel Differentiable Physics Augmented Wavelet Neural Operator
(DPA-WNO). The proposed DPA-WNO blends a differentiable physics solver with the
Wavelet Neural Operator (WNO), where the role of WNO is to model the missing
physics. This empowers the proposed framework to exploit the capability of WNO
to learn from data while retaining the interpretability and generalizability
associated with physics-based solvers. We illustrate the applicability of the
proposed approach in solving time-dependent uncertainty quantification problems
due to randomness in the initial condition. Four benchmark uncertainty
quantification and reliability analysis examples from various fields of science
and engineering are solved using the proposed approach. The results presented
</p>
</div>
</dd>
<dt><a name="item2">[2]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15129" title="Abstract">arXiv:2309.15129</a> [<a href="/pdf/2309.15129" title="Download PDF">pdf</a>, <a href="/format/2309.15129" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Evaluating Cognitive Maps and Planning in Large Language Models with  CogEval
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Momennejad%2C+I">Ida Momennejad</a>, 
<a href="/search/cs?searchtype=author&query=Hasanbeig%2C+H">Hosein Hasanbeig</a>, 
<a href="/search/cs?searchtype=author&query=Vieira%2C+F">Felipe Vieira</a>, 
<a href="/search/cs?searchtype=author&query=Sharma%2C+H">Hiteshi Sharma</a>, 
<a href="/search/cs?searchtype=author&query=Ness%2C+R+O">Robert Osazuwa Ness</a>, 
<a href="/search/cs?searchtype=author&query=Jojic%2C+N">Nebojsa Jojic</a>, 
<a href="/search/cs?searchtype=author&query=Palangi%2C+H">Hamid Palangi</a>, 
<a href="/search/cs?searchtype=author&query=Larson%2C+J">Jonathan Larson</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computation and Language (cs.CL); Machine Learning (cs.LG)

</div>
<p class="mathjax">Recently an influx of studies claim emergent cognitive abilities in large
language models (LLMs). Yet, most rely on anecdotes, overlook contamination of
training sets, or lack systematic Evaluation involving multiple tasks, control
conditions, multiple iterations, and statistical robustness tests. Here we make
two major contributions. First, we propose CogEval, a cognitive
science-inspired protocol for the systematic evaluation of cognitive capacities
in Large Language Models. The CogEval protocol can be followed for the
evaluation of various abilities. Second, here we follow CogEval to
systematically evaluate cognitive maps and planning ability across eight LLMs
(OpenAI GPT-4, GPT-3.5-turbo-175B, davinci-003-175B, Google Bard,
Cohere-xlarge-52.4B, Anthropic Claude-1-52B, LLaMA-13B, and Alpaca-7B). We base
our task prompts on human experiments, which offer both established construct
validity for evaluating planning, and are absent from LLM training sets. We
find that, while LLMs show apparent competence in a few planning tasks with
simpler structures, systematic evaluation reveals striking failure modes in
planning tasks, including hallucinations of invalid trajectories and getting
trapped in loops. These findings do not support the idea of emergent
out-of-the-box planning ability in LLMs. This could be because LLMs do not
understand the latent relational structures underlying planning problems, known
as cognitive maps, and fail at unrolling goal-directed trajectories based on
the underlying structure. Implications for application and future directions
are discussed.
</p>
</div>
</dd>
<dt><a name="item3">[3]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15133" title="Abstract">arXiv:2309.15133</a> [<a href="/pdf/2309.15133" title="Download PDF">pdf</a>, <a href="/format/2309.15133" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> From Asset Flow to Status, Action and Intention Discovery: Early Malice  Detection in Cryptocurrency
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cheng%2C+L">Ling Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+F">Feida Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yong Wang</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+R">Ruicheng Liang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+H">Huiwen Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by TKDD. arXiv admin note: substantial text overlap with <a href="/abs/2209.12001">arXiv:2209.12001</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Cryptocurrency has been subject to illicit activities probably more often
than traditional financial assets due to the pseudo-anonymous nature of its
transacting entities. An ideal detection model is expected to achieve all three
critical properties of (I) early detection, (II) good interpretability, and
(III) versatility for various illicit activities. However, existing solutions
cannot meet all these requirements, as most of them heavily rely on deep
learning without interpretability and are only available for retrospective
analysis of a specific illicit type. To tackle all these challenges, we propose
Intention-Monitor for early malice detection in Bitcoin (BTC), where the
on-chain record data for a certain address are much scarcer than other
cryptocurrency platforms. We first define asset transfer paths with the
Decision-Tree based feature Selection and Complement (DT-SC) to build different
feature sets for different malice types. Then, the Status/Action Proposal
Module (S/A-PM) and the Intention-VAE module generate the status, action,
intent-snippet, and hidden intent-snippet embedding. With all these modules,
our model is highly interpretable and can detect various illegal activities.
Moreover, well-designed loss functions further enhance the prediction speed and
model's interpretability. Extensive experiments on three real-world datasets
demonstrate that our proposed algorithm outperforms the state-of-the-art
methods. Furthermore, additional case studies justify our model can not only
explain existing illicit patterns but can also find new suspicious characters.
</p>
</div>
</dd>
<dt><a name="item4">[4]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15135" title="Abstract">arXiv:2309.15135</a> [<a href="/pdf/2309.15135" title="Download PDF">pdf</a>, <a href="/format/2309.15135" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Contrastive Continual Multi-view Clustering with Filtered Structural  Fusion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wan%2C+X">Xinhang Wan</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jiyuan Liu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+A">Ao Li</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xinwang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+E">En Zhu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Multi-view clustering thrives in applications where views are collected in
advance by extracting consistent and complementary information among views.
However, it overlooks scenarios where data views are collected sequentially,
i.e., real-time data. Due to privacy issues or memory burden, previous views
are not available with time in these situations. Some methods are proposed to
handle it but are trapped in a stability-plasticity dilemma. In specific, these
methods undergo a catastrophic forgetting of prior knowledge when a new view is
attained. Such a catastrophic forgetting problem (CFP) would cause the
consistent and complementary information hard to get and affect the clustering
performance. To tackle this, we propose a novel method termed Contrastive
Continual Multi-view Clustering with Filtered Structural Fusion (CCMVC-FSF).
Precisely, considering that data correlations play a vital role in clustering
and prior knowledge ought to guide the clustering process of a new view, we
develop a data buffer with fixed size to store filtered structural information
and utilize it to guide the generation of a robust partition matrix via
contrastive learning. Furthermore, we theoretically connect CCMVC-FSF with
semi-supervised learning and knowledge distillation. Extensive experiments
exhibit the excellence of the proposed method.
</p>
</div>
</dd>
<dt><a name="item5">[5]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15137" title="Abstract">arXiv:2309.15137</a> [<a href="/pdf/2309.15137" title="Download PDF">pdf</a>, <a href="/format/2309.15137" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deep Generative Methods for Producing Forecast Trajectories in Power  Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Weill%2C+N">Nathan Weill</a>, 
<a href="/search/cs?searchtype=author&query=Dumas%2C+J">Jonathan Dumas</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submited to PSCC 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">With the expansion of renewables in the electricity mix, power grid
variability will increase, hence a need to robustify the system to guarantee
its security. Therefore, Transport System Operators (TSOs) must conduct
analyses to simulate the future functioning of power systems. Then, these
simulations are used as inputs in decision-making processes. In this context,
we investigate using deep learning models to generate energy production and
load forecast trajectories. To capture the spatiotemporal correlations in these
multivariate time series, we adapt autoregressive networks and normalizing
flows, demonstrating their effectiveness against the current copula-based
statistical approach. We conduct extensive experiments on the French TSO RTE
wind forecast data and compare the different models with \textit{ad hoc}
evaluation metrics for time series generation.
</p>
</div>
</dd>
<dt><a name="item6">[6]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15139" title="Abstract">arXiv:2309.15139</a> [<a href="/pdf/2309.15139" title="Download PDF">pdf</a>, <a href="/format/2309.15139" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PINF: Continuous Normalizing Flows for Physics-Constrained Deep Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+F">Feng Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+F">Faguo Wu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xiao Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 3 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">The normalization constraint on probability density poses a significant
challenge for solving the Fokker-Planck equation. Normalizing Flow, an
invertible generative model leverages the change of variables formula to ensure
probability density conservation and enable the learning of complex data
distributions. In this paper, we introduce Physics-Informed Normalizing Flows
(PINF), a novel extension of continuous normalizing flows, incorporating
diffusion through the method of characteristics. Our method, which is mesh-free
and causality-free, can efficiently solve high dimensional time-dependent and
steady-state Fokker-Planck equations.
</p>
</div>
</dd>
<dt><a name="item7">[7]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15140" title="Abstract">arXiv:2309.15140</a> [<a href="/pdf/2309.15140" title="Download PDF">pdf</a>, <a href="/format/2309.15140" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Review on AI Algorithms for Energy Management in E-Mobility Services
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yan%2C+S">Sen Yan</a>, 
<a href="/search/cs?searchtype=author&query=Shah%2C+M+H">Maqsood Hussain Shah</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Ji Li</a>, 
<a href="/search/cs?searchtype=author&query=O%27Connor%2C+N">Noel O&#x27;Connor</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+M">Mingming Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 4 tables, 1 figure
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Systems and Control (eess.SY)

</div>
<p class="mathjax">E-mobility, or electric mobility, has emerged as a pivotal solution to
address pressing environmental and sustainability concerns in the
transportation sector. The depletion of fossil fuels, escalating greenhouse gas
emissions, and the imperative to combat climate change underscore the
significance of transitioning to electric vehicles (EVs). This paper seeks to
explore the potential of artificial intelligence (AI) in addressing various
challenges related to effective energy management in e-mobility systems (EMS).
These challenges encompass critical factors such as range anxiety, charge rate
optimization, and the longevity of energy storage in EVs. By analyzing existing
literature, we delve into the role that AI can play in tackling these
challenges and enabling efficient energy management in EMS. Our objectives are
twofold: to provide an overview of the current state-of-the-art in this
research domain and propose effective avenues for future investigations.
Through this analysis, we aim to contribute to the advancement of sustainable
and efficient e-mobility solutions, shaping a greener and more sustainable
future for transportation.
</p>
</div>
</dd>
<dt><a name="item8">[8]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15164" title="Abstract">arXiv:2309.15164</a> [<a href="/pdf/2309.15164" title="Download PDF">pdf</a>, <a href="/format/2309.15164" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> 3D Reconstruction with Generalizable Neural Fields using Scene Priors
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fu%2C+Y">Yang Fu</a>, 
<a href="/search/cs?searchtype=author&query=De+Mello%2C+S">Shalini De Mello</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xueting Li</a>, 
<a href="/search/cs?searchtype=author&query=Kulkarni%2C+A">Amey Kulkarni</a>, 
<a href="/search/cs?searchtype=author&query=Kautz%2C+J">Jan Kautz</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xiaolong Wang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+S">Sifei Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project Page: <a href="https://oasisyang.github.io/neural-prior">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">High-fidelity 3D scene reconstruction has been substantially advanced by
recent progress in neural fields. However, most existing methods train a
separate network from scratch for each individual scene. This is not scalable,
inefficient, and unable to yield good results given limited views. While
learning-based multi-view stereo methods alleviate this issue to some extent,
their multi-view setting makes it less flexible to scale up and to broad
applications. Instead, we introduce training generalizable Neural Fields
incorporating scene Priors (NFPs). The NFP network maps any single-view RGB-D
image into signed distance and radiance values. A complete scene can be
reconstructed by merging individual frames in the volumetric space WITHOUT a
fusion module, which provides better flexibility. The scene priors can be
trained on large-scale datasets, allowing for fast adaptation to the
reconstruction of a new scene with fewer views. NFP not only demonstrates SOTA
scene reconstruction performance and efficiency, but it also supports
single-image novel-view synthesis, which is underexplored in neural fields.
More qualitative results are available at:
https://oasisyang.github.io/neural-prior
</p>
</div>
</dd>
<dt><a name="item9">[9]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15169" title="Abstract">arXiv:2309.15169</a> [<a href="/pdf/2309.15169" title="Download PDF">pdf</a>, <a href="/format/2309.15169" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Revealing the Power of Spatial-Temporal Masked Autoencoders in  Multivariate Time Series Forecasting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sun%2C+J">Jiarui Sun</a>, 
<a href="/search/cs?searchtype=author&query=Fan%2C+Y">Yujie Fan</a>, 
<a href="/search/cs?searchtype=author&query=Yeh%2C+C+M">Chin-Chia Michael Yeh</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+W">Wei Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Chowdhary%2C+G">Girish Chowdhary</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Multivariate time series (MTS) forecasting involves predicting future time
series data based on historical observations. Existing research primarily
emphasizes the development of complex spatial-temporal models that capture
spatial dependencies and temporal correlations among time series variables
explicitly. However, recent advances have been impeded by challenges relating
to data scarcity and model robustness. To address these issues, we propose
Spatial-Temporal Masked Autoencoders (STMAE), an MTS forecasting framework that
leverages masked autoencoders to enhance the performance of spatial-temporal
baseline models. STMAE consists of two learning stages. In the pretraining
stage, an encoder-decoder architecture is employed. The encoder processes the
partially visible MTS data produced by a novel dual-masking strategy, including
biased random walk-based spatial masking and patch-based temporal masking.
Subsequently, the decoders aim to reconstruct the masked counterparts from both
spatial and temporal perspectives. The pretraining stage establishes a
challenging pretext task, compelling the encoder to learn robust
spatial-temporal patterns. In the fine-tuning stage, the pretrained encoder is
retained, and the original decoder from existing spatial-temporal models is
appended for forecasting. Extensive experiments are conducted on multiple MTS
benchmarks. The promising results demonstrate that integrating STMAE into
various spatial-temporal models can largely enhance their MTS forecasting
capability.
</p>
</div>
</dd>
<dt><a name="item10">[10]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15172" title="Abstract">arXiv:2309.15172</a> [<a href="/pdf/2309.15172" title="Download PDF">pdf</a>, <a href="/ps/2309.15172" title="Download PostScript">ps</a>, <a href="/format/2309.15172" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Unbalanced Job Approximation using Taylor Series Expansion and Review of  Performance Bounds
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Thomasian%2C+A">Alexander Thomasian</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Performance (cs.PF)</span>

</div>
<p class="mathjax">Unbalanced Job Approximation - UJA is a family of low-cost formulas to obtain
the throughput of Queueing Networks - QNs with fixed rate servers using Taylor
series expansion of job loadings with respect to the mean loading. UJA with one
term yields the same throughput as optimistic Balanced Job Bound - BJB, which
at some point exceeds the maximum asymptotic throughput. The accuracy of the
estimated throughput increases with more terms in the Taylor series. UJA can be
used in parametric studies by reducing the cost of solving large QNs by
aggregating stations into a single Flow-Equivalent Service Center - FESCs
defined by its throughput characteristic. While UJA has been extended to two
classes it may be applied to more classes by job class aggregation. BJB has
been extended to QNs with delay servers and multiple jobs classes by Eager and
Sevcik, throughput bounds by Eager and Sevcik, Kriz, Proportional Bound - PB
and Prop. Approximation Bound - PAM by Hsieh and Lam and Geometric Bound - GB
by Casale et al. are reviewed.
</p>
</div>
</dd>
<dt><a name="item11">[11]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15175" title="Abstract">arXiv:2309.15175</a> [<a href="/pdf/2309.15175" title="Download PDF">pdf</a>, <a href="/format/2309.15175" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Large scale reuse of microservices using DevOps and InnerSource  practices -- A longitudinal case study
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Badampudi%2C+D">Deepika Badampudi</a>, 
<a href="/search/cs?searchtype=author&query=Usman%2C+M">Muhammad Usman</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+X">Xingru Chen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
<p class="mathjax">Contemporary practices such as InnerSource and DevOps promote software reuse.
This study investigates the implications of using contemporary practices on
software reuse. In particular, we investigate the costs, benefits, challenges,
and potential improvements in contemporary reuse at Ericsson. We performed the
study in two phases: a) the initial data collection based on a combination of
data collection methods (e.g., interviews, discussions, company portals), and
b) a follow-up group discussion after a year to understand the status of the
challenges and improvements identified in the first phase. Our results indicate
that developing reusable assets resulted in upfront costs, such as additional
effort in ensuring compliance. Furthermore, development with reuse also
resulted in additional effort, for example, in integrating and understanding
reusable assets. Ericsson perceived the additional effort as an investment
resulting in long-term benefits such as improved quality, productivity,
customer experience, and way of working. Ericsson's main challenge was
increased pressure on the producers of reusable assets, which was mitigated by
scaling the InnerSource adoption. InnerSource success is evident from the
increase in the contributions to reusable assets. In addition, Ericsson
implemented measures such as automating the compliance check, which enhanced
the maturity of reusable assets and resulted in increased reuse.
</p>
</div>
</dd>
<dt><a name="item12">[12]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15176" title="Abstract">arXiv:2309.15176</a> [<a href="/pdf/2309.15176" title="Download PDF">pdf</a>, <a href="/format/2309.15176" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> STANCE-C3: Domain-adaptive Cross-target Stance Detection via Contrastive  Learning and Counterfactual Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kim%2C+N">Nayoung Kim</a>, 
<a href="/search/cs?searchtype=author&query=Mosallanezhad%2C+D">David Mosallanezhad</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+L">Lu Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Mancenido%2C+M+V">Michelle V. Mancenido</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+H">Huan Liu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Social and Information Networks (cs.SI)

</div>
<p class="mathjax">Stance detection is the process of inferring a person's position or
standpoint on a specific issue to deduce prevailing perceptions toward topics
of general or controversial interest, such as health policies during the
COVID-19 pandemic. Existing models for stance detection are trained to perform
well for a single domain (e.g., COVID-19) and a specific target topic (e.g.,
masking protocols), but are generally ineffectual in other domains or targets
due to distributional shifts in the data. However, constructing
high-performing, domain-specific stance detection models requires an extensive
corpus of labeled data relevant to the targeted domain, yet such datasets are
not readily available. This poses a challenge as the process of annotating data
is costly and time-consuming. To address these challenges, we introduce a novel
stance detection model coined domain-adaptive Cross-target STANCE detection via
Contrastive learning and Counterfactual generation (STANCE-C3) that uses
counterfactual data augmentation to enhance domain-adaptive training by
enriching the target domain dataset during the training process and requiring
significantly less information from the new domain. We also propose a modified
self-supervised contrastive learning as a component of STANCE-C3 to prevent
overfitting for the existing domain and target and enable cross-target stance
detection. Through experiments on various datasets, we show that STANCE-C3
shows performance improvement over existing state-of-the-art methods.
</p>
</div>
</dd>
<dt><a name="item13">[13]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15178" title="Abstract">arXiv:2309.15178</a> [<a href="/pdf/2309.15178" title="Download PDF">pdf</a>, <a href="/format/2309.15178" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Conservative World Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jeen%2C+S">Scott Jeen</a>, 
<a href="/search/cs?searchtype=author&query=Bewley%2C+T">Tom Bewley</a>, 
<a href="/search/cs?searchtype=author&query=Cullen%2C+J+M">Jonathan M. Cullen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project page: <a href="https://enjeeneer.io/projects/conservative-world-models/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Zero-shot reinforcement learning (RL) promises to provide agents that can
perform any task in an environment after an offline pre-training phase.
Forward-backward (FB) representations represent remarkable progress towards
this ideal, achieving 85% of the performance of task-specific agents in this
setting. However, such performance is contingent on access to large and diverse
datasets for pre-training, which cannot be expected for most real problems.
Here, we explore how FB performance degrades when trained on small datasets
that lack diversity, and mitigate it with conservatism, a well-established
feature of performant offline RL algorithms. We evaluate our family of methods
across various datasets, domains and tasks, reaching 150% of vanilla FB
performance in aggregate. Somewhat surprisingly, conservative FB algorithms
also outperform the task-specific baseline, despite lacking access to reward
labels and being required to maintain policies for all tasks. Conservative FB
algorithms perform no worse than FB on full datasets, and so present little
downside over their predecessor. Our code is available open-source via
https://enjeeneer.io/projects/conservative-world-models/.
</p>
</div>
</dd>
<dt><a name="item14">[14]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15183" title="Abstract">arXiv:2309.15183</a> [<a href="/pdf/2309.15183" title="Download PDF">pdf</a>, <a href="/format/2309.15183" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Shortest Route Is Not Always the Fastest: Probability-Modeled  Stereoscopic Eye Movement Completion Time in VR
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Duinkharjav%2C+B">Budmonde Duinkharjav</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+B">Benjamin Liang</a>, 
<a href="/search/cs?searchtype=author&query=Patney%2C+A">Anjul Patney</a>, 
<a href="/search/cs?searchtype=author&query=Brown%2C+R">Rachel Brown</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+Q">Qi Sun</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Graphics (cs.GR)</span>; Human-Computer Interaction (cs.HC)

</div>
<p class="mathjax">Speed and consistency of target-shifting play a crucial role in human ability
to perform complex tasks. Shifting our gaze between objects of interest quickly
and consistently requires changes both in depth and direction. Gaze changes in
depth are driven by slow, inconsistent vergence movements which rotate the eyes
in opposite directions, while changes in direction are driven by ballistic,
consistent movements called saccades, which rotate the eyes in the same
direction. In the natural world, most of our eye movements are a combination of
both types. While scientific consensus on the nature of saccades exists,
vergence and combined movements remain less understood and agreed upon.
<br />We eschew the lack of scientific consensus in favor of proposing an
operationalized computational model which predicts the speed of any type of
gaze movement during target-shifting in 3D. To this end, we conduct a
psychophysical study in a stereo VR environment to collect more than 12,000
gaze movement trials, analyze the temporal distribution of the observed gaze
movements, and fit a probabilistic model to the data. We perform a series of
objective measurements and user studies to validate the model. The results
demonstrate its predictive accuracy, generalization, as well as applications
for optimizing visual performance by altering content placement. Lastly, we
leverage the model to measure differences in human target-changing time
relative to the natural world, as well as suggest scene-aware projection depth.
By incorporating the complexities and randomness of human oculomotor control,
we hope this research will support new behavior-aware metrics for VR/AR display
design, interface layout, and gaze-contingent rendering.
</p>
</div>
</dd>
<dt><a name="item15">[15]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15187" title="Abstract">arXiv:2309.15187</a> [<a href="/pdf/2309.15187" title="Download PDF">pdf</a>, <a href="/format/2309.15187" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Monitoring Machine Learning Models: Online Detection of Relevant  Deviations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Heinrichs%2C+F">Florian Heinrichs</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 32 pages, 7 tables, 8 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Applications (stat.AP); Machine Learning (stat.ML)

</div>
<p class="mathjax">Machine learning models are essential tools in various domains, but their
performance can degrade over time due to changes in data distribution or other
factors. On one hand, detecting and addressing such degradations is crucial for
maintaining the models' reliability. On the other hand, given enough data, any
arbitrary small change of quality can be detected. As interventions, such as
model re-training or replacement, can be expensive, we argue that they should
only be carried out when changes exceed a given threshold. We propose a
sequential monitoring scheme to detect these relevant changes. The proposed
method reduces unnecessary alerts and overcomes the multiple testing problem by
accounting for temporal dependence of the measured model quality. Conditions
for consistency and specified asymptotic levels are provided. Empirical
validation using simulated and real data demonstrates the superiority of our
approach in detecting relevant changes in model quality compared to benchmark
methods. Our research contributes a practical solution for distinguishing
between minor fluctuations and meaningful degradations in machine learning
model performance, ensuring their reliability in dynamic environments.
</p>
</div>
</dd>
<dt><a name="item16">[16]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15188" title="Abstract">arXiv:2309.15188</a> [<a href="/pdf/2309.15188" title="Download PDF">pdf</a>, <a href="/format/2309.15188" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ICML 2023 Topological Deep Learning Challenge : Design and Results
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Papillon%2C+M">Mathilde Papillon</a>, 
<a href="/search/cs?searchtype=author&query=Hajij%2C+M">Mustafa Hajij</a>, 
<a href="/search/cs?searchtype=author&query=Frantzen%2C+F">Florian Frantzen</a>, 
<a href="/search/cs?searchtype=author&query=Hoppe%2C+J">Josef Hoppe</a>, 
<a href="/search/cs?searchtype=author&query=Jenne%2C+H">Helen Jenne</a>, 
<a href="/search/cs?searchtype=author&query=Mathe%2C+J">Johan Mathe</a>, 
<a href="/search/cs?searchtype=author&query=Myers%2C+A">Audun Myers</a>, 
<a href="/search/cs?searchtype=author&query=Papamarkou%2C+T">Theodore Papamarkou</a>, 
<a href="/search/cs?searchtype=author&query=Schaub%2C+M+T">Michael T. Schaub</a>, 
<a href="/search/cs?searchtype=author&query=Zamzmi%2C+G">Ghada Zamzmi</a>, 
<a href="/search/cs?searchtype=author&query=Birdal%2C+T">Tolga Birdal</a>, 
<a href="/search/cs?searchtype=author&query=Dey%2C+T">Tamal Dey</a>, 
<a href="/search/cs?searchtype=author&query=Doster%2C+T">Tim Doster</a>, 
<a href="/search/cs?searchtype=author&query=Emerson%2C+T">Tegan Emerson</a>, 
<a href="/search/cs?searchtype=author&query=Gopalakrishnan%2C+G">Gurusankar Gopalakrishnan</a>, 
<a href="/search/cs?searchtype=author&query=Govil%2C+D">Devendra Govil</a>, 
<a href="/search/cs?searchtype=author&query=Grande%2C+V">Vincent Grande</a>, 
<a href="/search/cs?searchtype=author&query=Guzm%C3%A1n-S%C3%A1enz%2C+A">Aldo Guzm&#xe1;n-S&#xe1;enz</a>, 
<a href="/search/cs?searchtype=author&query=Kvinge%2C+H">Henry Kvinge</a>, 
<a href="/search/cs?searchtype=author&query=Livesay%2C+N">Neal Livesay</a>, 
<a href="/search/cs?searchtype=author&query=Meisner%2C+J">Jan Meisner</a>, 
<a href="/search/cs?searchtype=author&query=Mukherjee%2C+S">Soham Mukherjee</a>, 
<a href="/search/cs?searchtype=author&query=Samaga%2C+S+N">Shreyas N. Samaga</a>, 
<a href="/search/cs?searchtype=author&query=Ramamurthy%2C+K+N">Karthikeyan Natesan Ramamurthy</a>, 
<a href="/search/cs?searchtype=author&query=Karri%2C+M+R">Maneel Reddy Karri</a>, 
<a href="/search/cs?searchtype=author&query=Rosen%2C+P">Paul Rosen</a>, 
<a href="/search/cs?searchtype=author&query=Sanborn%2C+S">Sophia Sanborn</a>, 
<a href="/search/cs?searchtype=author&query=Scholkemper%2C+M">Michael Scholkemper</a>, 
<a href="/search/cs?searchtype=author&query=Walters%2C+R">Robin Walters</a>, 
<a href="/search/cs?searchtype=author&query=Agerberg%2C+J">Jens Agerberg</a>, 
<a href="/search/cs?searchtype=author&query=B%C3%B6kman%2C+G">Georg B&#xf6;kman</a>, 
<a href="/search/cs?searchtype=author&query=Barikbin%2C+S">Sadrodin Barikbin</a>, 
<a href="/search/cs?searchtype=author&query=Battiloro%2C+C">Claudio Battiloro</a>, 
<a href="/search/cs?searchtype=author&query=Bazhenov%2C+G">Gleb Bazhenov</a>, 
<a href="/search/cs?searchtype=author&query=Bernardez%2C+G">Guillermo Bernardez</a>, 
<a href="/search/cs?searchtype=author&query=Brent%2C+A">Aiden Brent</a>, 
<a href="/search/cs?searchtype=author&query=Escalera%2C+S">Sergio Escalera</a>, 
<a href="/search/cs?searchtype=author&query=Fiorellino%2C+S">Simone Fiorellino</a>, 
<a href="/search/cs?searchtype=author&query=Gavrilev%2C+D">Dmitrii Gavrilev</a>, 
<a href="/search/cs?searchtype=author&query=Hassanin%2C+M">Mohammed Hassanin</a>, 
<a href="/search/cs?searchtype=author&query=H%C3%A4usner%2C+P">Paul H&#xe4;usner</a>, 
<a href="/search/cs?searchtype=author&query=Gardaa%2C+O+H">Odin Hoff Gardaa</a>, 
<a href="/search/cs?searchtype=author&query=Khamis%2C+A">Abdelwahed Khamis</a>, 
<a href="/search/cs?searchtype=author&query=Lecha%2C+M">Manuel Lecha</a>, 
<a href="/search/cs?searchtype=author&query=Magai%2C+G">German Magai</a>, 
<a href="/search/cs?searchtype=author&query=Malygina%2C+T">Tatiana Malygina</a>, 
<a href="/search/cs?searchtype=author&query=Melnyk%2C+P">Pavlo Melnyk</a>,  et al. (18 additional authors not shown)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">This paper presents the computational challenge on topological deep learning
that was hosted within the ICML 2023 Workshop on Topology and Geometry in
Machine Learning. The competition asked participants to provide open-source
implementations of topological neural networks from the literature by
contributing to the python packages TopoNetX (data processing) and TopoModelX
(deep learning). The challenge attracted twenty-eight qualifying submissions in
its two-month duration. This paper describes the design of the challenge and
summarizes its main findings.
</p>
</div>
</dd>
<dt><a name="item17">[17]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15191" title="Abstract">arXiv:2309.15191</a> [<a href="/pdf/2309.15191" title="Download PDF">pdf</a>, <a href="/format/2309.15191" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning Optimal Trajectories for Quadrotors
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+Y">Yuwei Wu</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+X">Xiatao Sun</a>, 
<a href="/search/cs?searchtype=author&query=Spasojevic%2C+I">Igor Spasojevic</a>, 
<a href="/search/cs?searchtype=author&query=Kumar%2C+V">Vijay Kumar</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">This paper presents a novel learning-based trajectory planning framework for
quadrotors that combines model-based optimization techniques with deep
learning. Specifically, we formulate the trajectory optimization problem as a
quadratic programming (QP) problem with dynamic and collision-free constraints
using piecewise trajectory segments through safe flight corridors [1]. We train
neural networks to directly learn the time allocation for each segment to
generate optimal smooth and fast trajectories. Furthermore, the constrained
optimization problem is applied as a separate implicit layer for
back-propagating in the network, for which the differential loss function can
be obtained. We introduce an additional penalty function to penalize time
allocations which result in solutions that violate the constraints to
accelerate the training process and increase the success rate of the original
optimization problem. To this end, we enable a flexible number of sequences of
piece-wise trajectories by adding an extra end-of-sentence token during
training. We illustrate the performance of the proposed method via extensive
simulation and experimentation and show that it works in real time in diverse,
cluttered environments.
</p>
</div>
</dd>
<dt><a name="item18">[18]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15197" title="Abstract">arXiv:2309.15197</a> [<a href="/pdf/2309.15197" title="Download PDF">pdf</a>, <a href="/format/2309.15197" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Tale of Two Cultures: Comparing Interpersonal Information Disclosure  Norms on Twitter
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mondal%2C+M">Mainack Mondal</a>, 
<a href="/search/cs?searchtype=author&query=Punuru%2C+A">Anju Punuru</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+T+S">Tyng-Wen Scott Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Vargas%2C+K">Kenneth Vargas</a>, 
<a href="/search/cs?searchtype=author&query=Gundry%2C+C">Chaz Gundry</a>, 
<a href="/search/cs?searchtype=author&query=Driggs%2C+N+S">Nathan S Driggs</a>, 
<a href="/search/cs?searchtype=author&query=Schill%2C+N">Noah Schill</a>, 
<a href="/search/cs?searchtype=author&query=Carlson%2C+N">Nathaniel Carlson</a>, 
<a href="/search/cs?searchtype=author&query=Bedwell%2C+J">Josh Bedwell</a>, 
<a href="/search/cs?searchtype=author&query=Lorenc%2C+J+Q">Jaden Q Lorenc</a>, 
<a href="/search/cs?searchtype=author&query=Ghosh%2C+I">Isha Ghosh</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yao Li</a>, 
<a href="/search/cs?searchtype=author&query=Fulda%2C+N">Nancy Fulda</a>, 
<a href="/search/cs?searchtype=author&query=Page%2C+X">Xinru Page</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This work will be presented at the 26th ACM Conference on Computer-Supported Cooperative Work and Social Computing (CSCW 2023). This paper will also be published in The Proceedings of the ACM on Human Computer Interaction
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Computers and Society (cs.CY); Social and Information Networks (cs.SI)

</div>
<p class="mathjax">We present an exploration of cultural norms surrounding online disclosure of
information about one's interpersonal relationships (such as information about
family members, colleagues, friends, or lovers) on Twitter. The literature
identifies the cultural dimension of individualism versus collectivism as being
a major determinant of offline communication differences in terms of emotion,
topic, and content disclosed. We decided to study whether such differences also
occur online in context of Twitter when comparing tweets posted in an
individualistic (U.S.) versus a collectivist (India) society. We collected more
than 2 million tweets posted in the U.S. and India over a 3 month period which
contain interpersonal relationship keywords. A card-sort study was used to
develop this culturally-sensitive saturated taxonomy of keywords that represent
interpersonal relationships (e.g., ma, mom, mother). Then we developed a
high-accuracy interpersonal disclosure detector based on dependency-parsing
(F1-score: 86%) to identify when the words refer to a personal relationship of
the poster (e.g., "my mom" as opposed to "a mom"). This allowed us to identify
the 400K+ tweets in our data set which actually disclose information about the
poster's interpersonal relationships. We used a mixed methods approach to
analyze these tweets (e.g., comparing the amount of joy expressed about one's
family) and found differences in emotion, topic, and content disclosed between
tweets from the U.S. versus India. Our analysis also reveals how a combination
of qualitative and quantitative methods are needed to uncover these
differences; Using just one or the other can be misleading. This study extends
the prior literature on Multi-Party Privacy and provides guidance for
researchers and designers of culturally-sensitive systems.
</p>
</div>
</dd>
<dt><a name="item19">[19]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15199" title="Abstract">arXiv:2309.15199</a> [<a href="/pdf/2309.15199" title="Download PDF">pdf</a>, <a href="/format/2309.15199" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Generalised 3D Morton and Hilbert Orderings
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Walker%2C+D">David Walker</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Geometry (cs.CG)</span>; Data Structures and Algorithms (cs.DS)

</div>
<p class="mathjax">This document describes algorithms for generating general Morton and Hilbert
orderings for three-dimensional data volumes.
</p>
</div>
</dd>
<dt><a name="item20">[20]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15203" title="Abstract">arXiv:2309.15203</a> [<a href="/pdf/2309.15203" title="Download PDF">pdf</a>, <a href="/format/2309.15203" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Eve Said Yes: AirBone Authentication for Head-Wearable Smart Voice  Assistant
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+C">Chenpei Huang</a>, 
<a href="/search/cs?searchtype=author&query=Zhong%2C+H">Hui Zhong</a>, 
<a href="/search/cs?searchtype=author&query=Lian%2C+J">Jie Lian</a>, 
<a href="/search/cs?searchtype=author&query=Prakash%2C+P">Pavana Prakash</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+D">Dian Shi</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+Y">Yuan Xu</a>, 
<a href="/search/cs?searchtype=author&query=Pan%2C+M">Miao Pan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, 12 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Human-Computer Interaction (cs.HC); Signal Processing (eess.SP)

</div>
<p class="mathjax">Recent advances in machine learning and natural language processing have
fostered the enormous prosperity of smart voice assistants and their services,
e.g., Alexa, Google Home, Siri, etc. However, voice spoofing attacks are deemed
to be one of the major challenges of voice control security, and never stop
evolving such as deep-learning-based voice conversion and speech synthesis
techniques. To solve this problem outside the acoustic domain, we focus on
head-wearable devices, such as earbuds and virtual reality (VR) headsets, which
are feasible to continuously monitor the bone-conducted voice in the vibration
domain. Specifically, we identify that air and bone conduction (AC/BC) from the
same vocalization are coupled (or concurrent) and user-level unique, which
makes them suitable behavior and biometric factors for multi-factor
authentication (MFA). The legitimate user can defeat acoustic domain and even
cross-domain spoofing samples with the proposed two-stage AirBone
authentication. The first stage answers \textit{whether air and bone conduction
utterances are time domain consistent (TC)} and the second stage runs
\textit{bone conduction speaker recognition (BC-SR)}. The security level is
hence increased for two reasons: (1) current acoustic attacks on smart voice
assistants cannot affect bone conduction, which is in the vibration domain; (2)
even for advanced cross-domain attacks, the unique bone conduction features can
detect adversary's impersonation and machine-induced vibration. Finally,
AirBone authentication has good usability (the same level as voice
authentication) compared with traditional MFA and those specially designed to
enhance smart voice security. Our experimental results show that the proposed
AirBone authentication is usable and secure, and can be easily equipped by
commercial off-the-shelf head wearables with good user experience.
</p>
</div>
</dd>
<dt><a name="item21">[21]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15204" title="Abstract">arXiv:2309.15204</a> [<a href="/pdf/2309.15204" title="Download PDF">pdf</a>, <a href="/format/2309.15204" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CLRmatchNet: Enhancing Curved Lane Detection with Deep Matching Process
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kontente%2C+S">Sapir Kontente</a>, 
<a href="/search/cs?searchtype=author&query=Orfaig%2C+R">Roy Orfaig</a>, 
<a href="/search/cs?searchtype=author&query=Bobrovsky%2C+B">Ben-Zion Bobrovsky</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Lane detection plays a crucial role in autonomous driving by providing vital
data to ensure safe navigation. Modern algorithms rely on anchor-based
detectors, which are then followed by a label assignment process to categorize
training detections as positive or negative instances based on learned
geometric attributes. The current methods, however, have limitations and might
not be optimal since they rely on predefined classical cost functions that are
based on a low-dimensional model. Our research introduces MatchNet, a deep
learning sub-module-based approach aimed at enhancing the label assignment
process. Integrated into a state-of-the-art lane detection network like the
Cross Layer Refinement Network for Lane Detection (CLRNet), MatchNet replaces
the conventional label assignment process with a sub-module network. This
integration results in significant improvements in scenarios involving curved
lanes, with remarkable improvement across all backbones of +2.8% for ResNet34,
+2.3% for ResNet101, and +2.96% for DLA34. In addition, it maintains or even
improves comparable results in other sections. Our method boosts the confidence
level in lane detection, allowing an increase in the confidence threshold. The
code will be available soon: https://github.com/sapirkontente/CLRmatchNet.git
</p>
</div>
</dd>
<dt><a name="item22">[22]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15207" title="Abstract">arXiv:2309.15207</a> [<a href="/pdf/2309.15207" title="Download PDF">pdf</a>, <a href="/format/2309.15207" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Balancing Computational Efficiency and Forecast Error in Machine  Learning-based Time-Series Forecasting: Insights from Live Experiments on  Meteorological Nowcasting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=T%C3%B6rnquist%2C+E">Elin T&#xf6;rnquist</a>, 
<a href="/search/cs?searchtype=author&query=Santos%2C+W+C">Wagner Costa Santos</a>, 
<a href="/search/cs?searchtype=author&query=Pogue%2C+T">Timothy Pogue</a>, 
<a href="/search/cs?searchtype=author&query=Wingle%2C+N">Nicholas Wingle</a>, 
<a href="/search/cs?searchtype=author&query=Caulk%2C+R+A">Robert A. Caulk</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 26 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Machine learning for time-series forecasting remains a key area of research.
Despite successful application of many machine learning techniques, relating
computational efficiency to forecast error remains an under-explored domain.
This paper addresses this topic through a series of real-time experiments to
quantify the relationship between computational cost and forecast error using
meteorological nowcasting as an example use-case. We employ a variety of
popular regression techniques (XGBoost, FC-MLP, Transformer, and LSTM) for
multi-horizon, short-term forecasting of three variables (temperature, wind
speed, and cloud cover) for multiple locations. During a 5-day live experiment,
4000 data sources were streamed for training and inferencing 144 models per
hour. These models were parameterized to explore forecast error for two
computational cost minimization methods: a novel auto-adaptive data reduction
technique (Variance Horizon) and a performance-based concept drift-detection
mechanism. Forecast error of all model variations were benchmarked in real-time
against a state-of-the-art numerical weather prediction model. Performance was
assessed using classical and novel evaluation metrics. Results indicate that
using the Variance Horizon reduced computational usage by more than 50\%, while
increasing between 0-15\% in error. Meanwhile, performance-based retraining
reduced computational usage by up to 90\% while \emph{also} improving forecast
error by up to 10\%. Finally, the combination of both the Variance Horizon and
performance-based retraining outperformed other model configurations by up to
99.7\% when considering error normalized to computational usage.
</p>
</div>
</dd>
<dt><a name="item23">[23]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15214" title="Abstract">arXiv:2309.15214</a> [<a href="/pdf/2309.15214" title="Download PDF">pdf</a>, <a href="/format/2309.15214" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Generative Residual Diffusion Modeling for Km-scale Atmospheric  Downscaling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mardani%2C+M">Morteza Mardani</a>, 
<a href="/search/cs?searchtype=author&query=Brenowitz%2C+N">Noah Brenowitz</a>, 
<a href="/search/cs?searchtype=author&query=Cohen%2C+Y">Yair Cohen</a>, 
<a href="/search/cs?searchtype=author&query=Pathak%2C+J">Jaideep Pathak</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+C">Chieh-Yu Chen</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+C">Cheng-Chin Liu</a>, 
<a href="/search/cs?searchtype=author&query=Vahdat%2C+A">Arash Vahdat</a>, 
<a href="/search/cs?searchtype=author&query=Kashinath%2C+K">Karthik Kashinath</a>, 
<a href="/search/cs?searchtype=author&query=Kautz%2C+J">Jan Kautz</a>, 
<a href="/search/cs?searchtype=author&query=Pritchard%2C+M">Mike Pritchard</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Atmospheric and Oceanic Physics (physics.ao-ph)

</div>
<p class="mathjax">The state of the art for physical hazard prediction from weather and climate
requires expensive km-scale numerical simulations driven by coarser resolution
global inputs. Here, a km-scale downscaling diffusion model is presented as a
cost effective alternative. The model is trained from a regional
high-resolution weather model over Taiwan, and conditioned on ERA5 reanalysis
data. To address the downscaling uncertainties, large resolution ratios (25km
to 2km), different physics involved at different scales and predict channels
that are not in the input data, we employ a two-step approach
(\textit{ResDiff}) where a (UNet) regression predicts the mean in the first
step and a diffusion model predicts the residual in the second step.
\textit{ResDiff} exhibits encouraging skill in bulk RMSE and CRPS scores. The
predicted spectra and distributions from ResDiff faithfully recover important
power law relationships regulating damaging wind and rain extremes. Case
studies of coherent weather phenomena reveal appropriate multivariate
relationships reminiscent of learnt physics. This includes the sharp wind and
temperature variations that co-locate with intense rainfall in a cold front,
and the extreme winds and rainfall bands that surround the eyewall of typhoons.
Some evidence of simultaneous bias correction is found. A first attempt at
downscaling directly from an operational global forecast model successfully
retains many of these benefits. The implication is that a new era of fully
end-to-end, global-to-regional machine learning weather prediction is likely
near at hand.
</p>
</div>
</dd>
<dt><a name="item24">[24]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15216" title="Abstract">arXiv:2309.15216</a> [<a href="/pdf/2309.15216" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Auto-grading C programming assignments with CodeBERT and Random Forest  Regressor
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Muddaluru%2C+R+V">Roshan Vasu Muddaluru</a>, 
<a href="/search/cs?searchtype=author&query=Thoguluva%2C+S+R">Sharvaani Ravikumar Thoguluva</a>, 
<a href="/search/cs?searchtype=author&query=Prabha%2C+S">Shruti Prabha</a>, 
<a href="/search/cs?searchtype=author&query=Pati%2C+D+P+B">Dr. Peeta Basa Pati</a>, 
<a href="/search/cs?searchtype=author&query=Balakrishnan%2C+M+R+M">Ms. Roshni M Balakrishnan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages, 6 figures, conference, presented at 14th ICCCNT
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Grading coding assignments manually is challenging due to complexity and
subjectivity. However, auto-grading with deep learning simplifies the task. It
objectively assesses code quality, detects errors, and assigns marks
accurately, reducing the burden on instructors while ensuring efficient and
fair assessment. This study provides an analysis of auto-grading of the C
programming assignments using machine learning and deep learning approaches
like regression, convolutional neural networks (CNN) and long short-term memory
(LSTM). Using a code-based transformer word embedding model called CodeBERT,
the textual code inputs were transformed into vectors, and the vectors were
then fed into several models. The testing findings demonstrated the efficacy of
the suggested strategy with a root mean squared error (RMSE) of 1.89. The
contrast between statistical methods and deep learning techniques is discussed
in the study.
</p>
</div>
</dd>
<dt><a name="item25">[25]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15217" title="Abstract">arXiv:2309.15217</a> [<a href="/pdf/2309.15217" title="Download PDF">pdf</a>, <a href="/format/2309.15217" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> RAGAS: Automated Evaluation of Retrieval Augmented Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Es%2C+S">Shahul Es</a>, 
<a href="/search/cs?searchtype=author&query=James%2C+J">Jithin James</a>, 
<a href="/search/cs?searchtype=author&query=Espinosa-Anke%2C+L">Luis Espinosa-Anke</a>, 
<a href="/search/cs?searchtype=author&query=Schockaert%2C+S">Steven Schockaert</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Reference-free (not tied to having ground truth available) evaluation framework for retrieval agumented generation
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">We introduce RAGAs (Retrieval Augmented Generation Assessment), a framework
for reference-free evaluation of Retrieval Augmented Generation (RAG)
pipelines. RAG systems are composed of a retrieval and an LLM based generation
module, and provide LLMs with knowledge from a reference textual database,
which enables them to act as a natural language layer between a user and
textual databases, reducing the risk of hallucinations. Evaluating RAG
architectures is, however, challenging because there are several dimensions to
consider: the ability of the retrieval system to identify relevant and focused
context passages, the ability of the LLM to exploit such passages in a faithful
way, or the quality of the generation itself. With RAGAs, we put forward a
suite of metrics which can be used to evaluate these different dimensions
\textit{without having to rely on ground truth human annotations}. We posit
that such a framework can crucially contribute to faster evaluation cycles of
RAG architectures, which is especially important given the fast adoption of
LLMs.
</p>
</div>
</dd>
<dt><a name="item26">[26]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15223" title="Abstract">arXiv:2309.15223</a> [<a href="/pdf/2309.15223" title="Download PDF">pdf</a>, <a href="/format/2309.15223" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Low-rank Adaptation of Large Language Model Rescoring for  Parameter-Efficient Speech Recognition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yu%2C+Y">Yu Yu</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+C+H">Chao-Han Huck Yang</a>, 
<a href="/search/cs?searchtype=author&query=Kolehmainen%2C+J">Jari Kolehmainen</a>, 
<a href="/search/cs?searchtype=author&query=Shivakumar%2C+P+G">Prashanth G. Shivakumar</a>, 
<a href="/search/cs?searchtype=author&query=Gu%2C+Y">Yile Gu</a>, 
<a href="/search/cs?searchtype=author&query=Ryu%2C+S">Sungho Ryu</a>, 
<a href="/search/cs?searchtype=author&query=Ren%2C+R">Roger Ren</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+Q">Qi Luo</a>, 
<a href="/search/cs?searchtype=author&query=Gourav%2C+A">Aditya Gourav</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+I">I-Fan Chen</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yi-Chieh Liu</a>, 
<a href="/search/cs?searchtype=author&query=Dinh%2C+T">Tuan Dinh</a>, 
<a href="/search/cs?searchtype=author&query=Gandhe%2C+A">Ankur Gandhe</a>, 
<a href="/search/cs?searchtype=author&query=Filimonov%2C+D">Denis Filimonov</a>, 
<a href="/search/cs?searchtype=author&query=Ghosh%2C+S">Shalini Ghosh</a>, 
<a href="/search/cs?searchtype=author&query=Stolcke%2C+A">Andreas Stolcke</a>, 
<a href="/search/cs?searchtype=author&query=Rastow%2C+A">Ariya Rastow</a>, 
<a href="/search/cs?searchtype=author&query=Bulyko%2C+I">Ivan Bulyko</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to IEEE ASRU 2023. Internal Review Approved
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Neural and Evolutionary Computing (cs.NE); Sound (cs.SD); Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">We propose a neural language modeling system based on low-rank adaptation
(LoRA) for speech recognition output rescoring. Although pretrained language
models (LMs) like BERT have shown superior performance in second-pass
rescoring, the high computational cost of scaling up the pretraining stage and
adapting the pretrained models to specific domains limit their practical use in
rescoring. Here we present a method based on low-rank decomposition to train a
rescoring BERT model and adapt it to new domains using only a fraction (0.08%)
of the pretrained parameters. These inserted matrices are optimized through a
discriminative training objective along with a correlation-based regularization
loss. The proposed low-rank adaptation Rescore-BERT (LoRB) architecture is
evaluated on LibriSpeech and internal datasets with decreased training times by
factors between 5.4 and 3.6.
</p>
</div>
</dd>
<dt><a name="item27">[27]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15225" title="Abstract">arXiv:2309.15225</a> [<a href="/pdf/2309.15225" title="Download PDF">pdf</a>, <a href="/format/2309.15225" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Cross-Validation for Training and Testing Co-occurrence Network  Inference Algorithms
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Agyapong%2C+D">Daniel Agyapong</a>, 
<a href="/search/cs?searchtype=author&query=Propster%2C+J+R">Jeffrey Ryan Propster</a>, 
<a href="/search/cs?searchtype=author&query=Marks%2C+J">Jane Marks</a>, 
<a href="/search/cs?searchtype=author&query=Hocking%2C+T+D">Toby Dylan Hocking</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Quantitative Methods (q-bio.QM)

</div>
<p class="mathjax">Microorganisms are found in almost every environment, including the soil,
water, air, and inside other organisms, like animals and plants. While some
microorganisms cause diseases, most of them help in biological processes such
as decomposition, fermentation and nutrient cycling. A lot of research has gone
into studying microbial communities in various environments and how their
interactions and relationships can provide insights into various diseases.
Co-occurrence network inference algorithms help us understand the complex
associations of micro-organisms, especially bacteria. Existing network
inference algorithms employ techniques such as correlation, regularized linear
regression, and conditional dependence, which have different hyper-parameters
that determine the sparsity of the network. Previous methods for evaluating the
quality of the inferred network include using external data, and network
consistency across sub-samples, both which have several drawbacks that limit
their applicability in real microbiome composition data sets. We propose a
novel cross-validation method to evaluate co-occurrence network inference
algorithms, and new methods for applying existing algorithms to predict on test
data. Our empirical study shows that the proposed method is useful for
hyper-parameter selection (training) and comparing the quality of the inferred
networks between different algorithms (testing).
</p>
</div>
</dd>
<dt><a name="item28">[28]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15232" title="Abstract">arXiv:2309.15232</a> [<a href="/pdf/2309.15232" title="Download PDF">pdf</a>, <a href="/format/2309.15232" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Critical Infrastructure Security Goes to Space: Leveraging Lessons  Learned on the Ground
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ellis%2C+T">Tim Ellis</a>, 
<a href="/search/cs?searchtype=author&query=Hitaj%2C+B">Briland Hitaj</a>, 
<a href="/search/cs?searchtype=author&query=Lindqvist%2C+U">Ulf Lindqvist</a>, 
<a href="/search/cs?searchtype=author&query=Shands%2C+D">Deborah Shands</a>, 
<a href="/search/cs?searchtype=author&query=Tinnel%2C+L">Laura Tinnel</a>, 
<a href="/search/cs?searchtype=author&query=DeBruhl%2C+B">Bruce DeBruhl</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Position paper: To appear in the 2023 Accelerating Space Commerce, Exploration, and New Discovery (ASCEND) conference, Las Vegas, Nevada, USA
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Systems and Control (eess.SY)

</div>
<p class="mathjax">Space systems enable essential communications, navigation, imaging and
sensing for a variety of domains, including agriculture, commerce,
transportation, and emergency operations by first responders. Protecting the
cybersecurity of these critical infrastructure systems is essential. While the
space environment brings unique constraints to managing cybersecurity risks,
lessons learned about risks and effective defenses in other critical
infrastructure domains can help us to design effective defenses for space
systems. In particular, discoveries regarding cybersecurity for industrial
control systems (ICS) for energy, manufacturing, transportation, and the
consumer and industrial Internet of Things (IoT) offer insights into
cybersecurity for the space domain. This paper provides an overview of ICS and
space system commonalities, lessons learned about cybersecurity for ICS that
can be applied to space systems, and recommendations for future research and
development to secure increasingly critical space systems.
</p>
</div>
</dd>
<dt><a name="item29">[29]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15234" title="Abstract">arXiv:2309.15234</a> [<a href="/pdf/2309.15234" title="Download PDF">pdf</a>, <a href="/format/2309.15234" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multi-Robot Cooperative Socially-Aware Navigation Using Multi-Agent  Reinforcement Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+W">Weizheng Wang</a>, 
<a href="/search/cs?searchtype=author&query=Mao%2C+L">Le Mao</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+R">Ruiqi Wang</a>, 
<a href="/search/cs?searchtype=author&query=Min%2C+B">Byung-Cheol Min</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">In public spaces shared with humans, ensuring multi-robot systems navigate
without collisions while respecting social norms is challenging, particularly
with limited communication. Although current robot social navigation techniques
leverage advances in reinforcement learning and deep learning, they frequently
overlook robot dynamics in simulations, leading to a simulation-to-reality gap.
In this paper, we bridge this gap by presenting a new multi-robot social
navigation environment crafted using Dec-POSMDP and multi-agent reinforcement
learning. Furthermore, we introduce SAMARL: a novel benchmark for cooperative
multi-robot social navigation. SAMARL employs a unique spatial-temporal
transformer combined with multi-agent reinforcement learning. This approach
effectively captures the complex interactions between robots and humans, thus
promoting cooperative tendencies in multi-robot systems. Our extensive
experiments reveal that SAMARL outperforms existing baseline and ablation
models in our designed environment. Demo videos for this work can be found at:
https://sites.google.com/view/samarl
</p>
</div>
</dd>
<dt><a name="item30">[30]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15237" title="Abstract">arXiv:2309.15237</a> [<a href="/pdf/2309.15237" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> User Experience Design Professionals&#x27; Perceptions of Generative  Artificial Intelligence
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jie Li</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+H">Hancheng Cao</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+L">Laura Lin</a>, 
<a href="/search/cs?searchtype=author&query=Hou%2C+Y">Youyang Hou</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+R">Ruihao Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Ali%2C+A+E">Abdallah El Ali</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>; Artificial Intelligence (cs.AI); Emerging Technologies (cs.ET); Human-Computer Interaction (cs.HC)

</div>
<p class="mathjax">Among creative professionals, Generative Artificial Intelligence (GenAI) has
sparked excitement over its capabilities and fear over unanticipated
consequences. How does GenAI impact User Experience Design (UXD) practice, and
are fears warranted? We interviewed 20 UX Designers, with diverse experience
and across companies (startups to large enterprises). We probed them to
characterize their practices, and sample their attitudes, concerns, and
expectations. We found that experienced designers are confident in their
originality, creativity, and empathic skills, and find GenAI's role as
assistive. They emphasized the unique human factors of "enjoyment" and
"agency", where humans remain the arbiters of "AI alignment". However, skill
degradation, job replacement, and creativity exhaustion can adversely impact
junior designers. We discuss implications for human-GenAI collaboration,
specifically copyright and ownership, human creativity and agency, and AI
literacy and access. Through the lens of responsible and participatory AI, we
contribute a deeper understanding of GenAI fears and opportunities for UXD.
</p>
</div>
</dd>
<dt><a name="item31">[31]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15238" title="Abstract">arXiv:2309.15238</a> [<a href="/pdf/2309.15238" title="Download PDF">pdf</a>, <a href="/format/2309.15238" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning Using Generated Privileged Information by Text-to-Image  Diffusion Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Menadil%2C+R">Rafael-Edy Menadil</a>, 
<a href="/search/cs?searchtype=author&query=Georgescu%2C+M">Mariana-Iuliana Georgescu</a>, 
<a href="/search/cs?searchtype=author&query=Ionescu%2C+R+T">Radu Tudor Ionescu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Learning Using Privileged Information is a particular type of knowledge
distillation where the teacher model benefits from an additional data
representation during training, called privileged information, improving the
student model, which does not see the extra representation. However, privileged
information is rarely available in practice. To this end, we propose a text
classification framework that harnesses text-to-image diffusion models to
generate artificial privileged information. The generated images and the
original text samples are further used to train multimodal teacher models based
on state-of-the-art transformer-based architectures. Finally, the knowledge
from multimodal teachers is distilled into a text-based (unimodal) student.
Hence, by employing a generative model to produce synthetic data as privileged
information, we guide the training of the student model. Our framework, called
Learning Using Generated Privileged Information (LUGPI), yields noticeable
performance gains on four text classification data sets, demonstrating its
potential in text classification without any additional cost during inference.
</p>
</div>
</dd>
<dt><a name="item32">[32]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15240" title="Abstract">arXiv:2309.15240</a> [<a href="/pdf/2309.15240" title="Download PDF">pdf</a>, <a href="/format/2309.15240" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Modifying twist algorithms for determining the key length of a  Vigen&#xe8;re cipher
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Millichap%2C+C">Christian Millichap</a>, 
<a href="/search/cs?searchtype=author&query=Yau%2C+Y">Yeeka Yau</a>, 
<a href="/search/cs?searchtype=author&query=Pate%2C+A">Alyssa Pate</a>, 
<a href="/search/cs?searchtype=author&query=Carns%2C+M">Morgan Carns</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">In this article, we analyze and improve upon the twist-based algorithms
introduced by Barr--Simoson and Park--Kim--Cho--Yum for determining the key
length of a Vigen\`{e}re cipher. We provide an in-depth discussion on how the
domain of the twist index affects the accuracy of these algorithms along with
supporting experimental evidence. We also introduce a new twist-based
algorithm, the twist$^{++}$ algorithm, and show this algorithm is more accurate
than the twist$^{+}$ algorithm for a wide range of key lengths and text
lengths.
</p>
</div>
</dd>
<dt><a name="item33">[33]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15242" title="Abstract">arXiv:2309.15242</a> [<a href="/pdf/2309.15242" title="Download PDF">pdf</a>, <a href="/format/2309.15242" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PlotMap: Automated Layout Design for Building Game Worlds
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yi Wang</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+J">Jieliang Luo</a>, 
<a href="/search/cs?searchtype=author&query=Gaier%2C+A">Adam Gaier</a>, 
<a href="/search/cs?searchtype=author&query=Atherton%2C+E">Evan Atherton</a>, 
<a href="/search/cs?searchtype=author&query=Koch%2C+H">Hilmar Koch</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
<p class="mathjax">World-building, the process of developing both the narrative and physical
world of a game, plays a vital role in the game's experience. Critically
acclaimed independent and AAA video games are praised for strong world
building, with game maps that masterfully intertwine with and elevate the
narrative, captivating players and leaving a lasting impression. However,
designing game maps that support a desired narrative is challenging, as it
requires satisfying complex constraints from various considerations. Most
existing map generation methods focus on considerations about gameplay
mechanics or map topography, while the need to support the story is typically
neglected. As a result, extensive manual adjustment is still required to design
a game world that facilitates particular stories. In this work, we approach
this problem by introducing an extra layer of plot facility layout design that
is independent of the underlying map generation method in a world-building
pipeline. Concretely, we present a system that leverages Reinforcement Learning
(RL) to automatically assign concrete locations on a game map to abstract
locations mentioned in a given story (plot facilities), following spatial
constraints derived from the story. A decision-making agent moves the plot
facilities around, considering their relationship to the map and each other, to
locations on the map that best satisfy the constraints of the story. Our system
considers input from multiple modalities: map images as pixels, facility
locations as real values, and story constraints expressed in natural language.
We develop a method of generating datasets of facility layout tasks, create an
RL environment to train and evaluate RL models, and further analyze the
behaviors of the agents through a group of comprehensive experiments and
ablation studies, aiming to provide insights for RL-based plot facility layout
design.
</p>
</div>
</dd>
<dt><a name="item34">[34]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15244" title="Abstract">arXiv:2309.15244</a> [<a href="/pdf/2309.15244" title="Download PDF">pdf</a>, <a href="/format/2309.15244" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Homotopy Relaxation Training Algorithms for Infinite-Width Two-Layer  ReLU Neural Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yahong Yang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Q">Qipin Chen</a>, 
<a href="/search/cs?searchtype=author&query=Hao%2C+W">Wenrui Hao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Optimization and Control (math.OC)

</div>
<p class="mathjax">In this paper, we present a novel training approach called the Homotopy
Relaxation Training Algorithm (HRTA), aimed at accelerating the training
process in contrast to traditional methods. Our algorithm incorporates two key
mechanisms: one involves building a homotopy activation function that
seamlessly connects the linear activation function with the ReLU activation
function; the other technique entails relaxing the homotopy parameter to
enhance the training refinement process. We have conducted an in-depth analysis
of this novel method within the context of the neural tangent kernel (NTK),
revealing significantly improved convergence rates. Our experimental results,
especially when considering networks with larger widths, validate the
theoretical conclusions. This proposed HRTA exhibits the potential for other
activation functions and deep neural networks.
</p>
</div>
</dd>
<dt><a name="item35">[35]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15245" title="Abstract">arXiv:2309.15245</a> [<a href="/pdf/2309.15245" title="Download PDF">pdf</a>, <a href="/format/2309.15245" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SeMAnD: Self-Supervised Anomaly Detection in Multimodal Geospatial  Datasets
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Reshetova%2C+D">Daria Reshetova</a>, 
<a href="/search/cs?searchtype=author&query=Ganguli%2C+S">Swetava Ganguli</a>, 
<a href="/search/cs?searchtype=author&query=Iyer%2C+C+V+K">C. V. Krishnakumar Iyer</a>, 
<a href="/search/cs?searchtype=author&query=Pandey%2C+V">Vipul Pandey</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Extended version of the accepted research track paper at the 31st ACM SIGSPATIAL International Conference on Advances in Geographic Information Systems (ACM SIGSPATIAL 2023), Hamburg, Germany. 11 pages, 8 figures, 6 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
<p class="mathjax">We propose a Self-supervised Anomaly Detection technique, called SeMAnD, to
detect geometric anomalies in Multimodal geospatial datasets. Geospatial data
comprises of acquired and derived heterogeneous data modalities that we
transform to semantically meaningful, image-like tensors to address the
challenges of representation, alignment, and fusion of multimodal data. SeMAnD
is comprised of (i) a simple data augmentation strategy, called
RandPolyAugment, capable of generating diverse augmentations of vector
geometries, and (ii) a self-supervised training objective with three components
that incentivize learning representations of multimodal data that are
discriminative to local changes in one modality which are not corroborated by
the other modalities. Detecting local defects is crucial for geospatial anomaly
detection where even small anomalies (e.g., shifted, incorrectly connected,
malformed, or missing polygonal vector geometries like roads, buildings,
landcover, etc.) are detrimental to the experience and safety of users of
geospatial applications like mapping, routing, search, and recommendation
systems. Our empirical study on test sets of different types of real-world
geometric geospatial anomalies across 3 diverse geographical regions
demonstrates that SeMAnD is able to detect real-world defects and outperforms
domain-agnostic anomaly detection strategies by 4.8-19.7% as measured using
anomaly classification AUC. We also show that model performance increases (i)
up to 20.4% as the number of input modalities increase and (ii) up to 22.9% as
the diversity and strength of training data augmentations increase.
</p>
</div>
</dd>
<dt><a name="item36">[36]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15251" title="Abstract">arXiv:2309.15251</a> [<a href="/pdf/2309.15251" title="Download PDF">pdf</a>, <a href="/format/2309.15251" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> VPA: Fully Test-Time Visual Prompt Adaptation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sun%2C+J">Jiachen Sun</a>, 
<a href="/search/cs?searchtype=author&query=Ibrahim%2C+M">Mark Ibrahim</a>, 
<a href="/search/cs?searchtype=author&query=Hall%2C+M">Melissa Hall</a>, 
<a href="/search/cs?searchtype=author&query=Evtimov%2C+I">Ivan Evtimov</a>, 
<a href="/search/cs?searchtype=author&query=Mao%2C+Z+M">Z. Morley Mao</a>, 
<a href="/search/cs?searchtype=author&query=Ferrer%2C+C+C">Cristian Canton Ferrer</a>, 
<a href="/search/cs?searchtype=author&query=Hazirbas%2C+C">Caner Hazirbas</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Textual prompt tuning has demonstrated significant performance improvements
in adapting natural language processing models to a variety of downstream tasks
by treating hand-engineered prompts as trainable parameters. Inspired by the
success of textual prompting, several studies have investigated the efficacy of
visual prompt tuning. In this work, we present Visual Prompt Adaptation (VPA),
the first framework that generalizes visual prompting with test-time
adaptation. VPA introduces a small number of learnable tokens, enabling fully
test-time and storage-efficient adaptation without necessitating source-domain
information. We examine our VPA design under diverse adaptation settings,
encompassing single-image, batched-image, and pseudo-label adaptation. We
evaluate VPA on multiple tasks, including out-of-distribution (OOD)
generalization, corruption robustness, and domain adaptation. Experimental
results reveal that VPA effectively enhances OOD generalization by 3.3% across
various models, surpassing previous test-time approaches. Furthermore, we show
that VPA improves corruption robustness by 6.5% compared to strong baselines.
Finally, we demonstrate that VPA also boosts domain adaptation performance by
relatively 5.2%. Our VPA also exhibits marked effectiveness in improving the
robustness of zero-shot recognition for vision-language models.
</p>
</div>
</dd>
<dt><a name="item37">[37]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15252" title="Abstract">arXiv:2309.15252</a> [<a href="/pdf/2309.15252" title="Download PDF">pdf</a>, <a href="/format/2309.15252" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> V2X-Lead: LiDAR-based End-to-End Autonomous Driving with  Vehicle-to-Everything Communication Integration
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Deng%2C+Z">Zhiyun Deng</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+Y">Yanjun Shi</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+W">Weiming Shen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To be published in IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">This paper presents a LiDAR-based end-to-end autonomous driving method with
Vehicle-to-Everything (V2X) communication integration, termed V2X-Lead, to
address the challenges of navigating unregulated urban scenarios under
mixed-autonomy traffic conditions. The proposed method aims to handle imperfect
partial observations by fusing the onboard LiDAR sensor and V2X communication
data. A model-free and off-policy deep reinforcement learning (DRL) algorithm
is employed to train the driving agent, which incorporates a carefully designed
reward function and multi-task learning technique to enhance generalization
across diverse driving tasks and scenarios. Experimental results demonstrate
the effectiveness of the proposed approach in improving safety and efficiency
in the task of traversing unsignalized intersections in mixed-autonomy traffic,
and its generalizability to previously unseen scenarios, such as roundabouts.
The integration of V2X communication offers a significant data source for
autonomous vehicles (AVs) to perceive their surroundings beyond onboard
sensors, resulting in a more accurate and comprehensive perception of the
driving environment and more safe and robust driving behavior.
</p>
</div>
</dd>
<dt><a name="item38">[38]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15253" title="Abstract">arXiv:2309.15253</a> [<a href="/pdf/2309.15253" title="Download PDF">pdf</a>, <a href="/format/2309.15253" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Method and Validation for Optimal Lineup Creation for Daily Fantasy  Football Using Machine Learning and Linear Programming
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=M%2C+J">Joseph M</a>, 
<a href="/search/cs?searchtype=author&query=Mahoney">Mahoney</a>, 
<a href="/search/cs?searchtype=author&query=Paniak%2C+T+B">Tomasz B. Paniak</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 32 pages, 12 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Daily fantasy sports (DFS) are weekly or daily online contests where
real-game performances of individual players are converted to fantasy points
(FPTS). Users select players for their lineup to maximize their FPTS within a
set player salary cap. This paper focuses on (1) the development of a method to
forecast NFL player performance under uncertainty and (2) determining an
optimal lineup to maximize FPTS under a set salary limit. A supervised learning
neural network was created and used to project FPTS based on past player
performance (2018 NFL regular season for this work) prior to the upcoming week.
These projected FPTS were used in a mixed integer linear program to find the
optimal lineup. The performance of resultant lineups was compared to
randomly-created lineups. On average, the optimal lineups outperformed the
random lineups. The generated lineups were then compared to real-world lineups
from users on DraftKings. The generated lineups generally fell in approximately
the 31st percentile (median). The FPTS methods and predictions presented here
can be further improved using this study as a baseline comparison.
</p>
</div>
</dd>
<dt><a name="item39">[39]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15257" title="Abstract">arXiv:2309.15257</a> [<a href="/pdf/2309.15257" title="Download PDF">pdf</a>, <a href="/format/2309.15257" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> STARC: A General Framework For Quantifying Differences Between Reward  Functions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Skalse%2C+J">Joar Skalse</a>, 
<a href="/search/cs?searchtype=author&query=Farnik%2C+L">Lucy Farnik</a>, 
<a href="/search/cs?searchtype=author&query=Motwani%2C+S+R">Sumeet Ramesh Motwani</a>, 
<a href="/search/cs?searchtype=author&query=Jenner%2C+E">Erik Jenner</a>, 
<a href="/search/cs?searchtype=author&query=Gleave%2C+A">Adam Gleave</a>, 
<a href="/search/cs?searchtype=author&query=Abate%2C+A">Alessandro Abate</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">In order to solve a task using reinforcement learning, it is necessary to
first formalise the goal of that task as a reward function. However, for many
real-world tasks, it is very difficult to manually specify a reward function
that never incentivises undesirable behaviour. As a result, it is increasingly
popular to use reward learning algorithms, which attempt to learn a reward
function from data. However, the theoretical foundations of reward learning are
not yet well-developed. In particular, it is typically not known when a given
reward learning algorithm with high probability will learn a reward function
that is safe to optimise. This means that reward learning algorithms generally
must be evaluated empirically, which is expensive, and that their failure modes
are difficult to predict in advance. One of the roadblocks to deriving better
theoretical guarantees is the lack of good methods for quantifying the
difference between reward functions. In this paper we provide a solution to
this problem, in the form of a class of pseudometrics on the space of all
reward functions that we call STARC (STAndardised Reward Comparison) metrics.
We show that STARC metrics induce both an upper and a lower bound on worst-case
regret, which implies that our metrics are tight, and that any metric with the
same properties must be bilipschitz equivalent to ours. Moreover, we also
identify a number of issues with reward metrics proposed by earlier works.
Finally, we evaluate our metrics empirically, to demonstrate their practical
efficacy. STARC metrics can be used to make both theoretical and empirical
analysis of reward learning algorithms both easier and more principled.
</p>
</div>
</dd>
<dt><a name="item40">[40]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15265" title="Abstract">arXiv:2309.15265</a> [<a href="/pdf/2309.15265" title="Download PDF">pdf</a>, <a href="/format/2309.15265" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Finding Biomechanically Safe Trajectories for Robot Manipulation of the  Human Body in a Search and Rescue Scenario
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Peiros%2C+E">Elizabeth Peiros</a>, 
<a href="/search/cs?searchtype=author&query=Chiu%2C+Z">Zih-Yun Chiu</a>, 
<a href="/search/cs?searchtype=author&query=Zhi%2C+Y">Yuheng Zhi</a>, 
<a href="/search/cs?searchtype=author&query=Shinde%2C+N">Nikhil Shinde</a>, 
<a href="/search/cs?searchtype=author&query=Yip%2C+M+C">Michael C. Yip</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">There has been increasing awareness of the difficulties in reaching and
extracting people from mass casualty scenarios, such as those arising from
natural disasters. While platforms have been designed to consider reaching
casualties and even carrying them out of harm's way, the challenge of
repositioning a casualty from its found configuration to one suitable for
extraction has not been explicitly explored. Furthermore, this planning problem
needs to incorporate biomechanical safety considerations for the casualty.
Thus, we present a first solution to biomechanically safe trajectory generation
for repositioning limbs of unconscious human casualties. We describe
biomechanical safety as mathematical constraints, mechanical descriptions of
the dynamics for the robot-human coupled system, and the planning and
trajectory optimization process that considers this coupled and constrained
system. We finally evaluate our approach over several variations of the problem
and demonstrate it on a real robot and human subject. This work provides a
crucial part of search and rescue that can be used in conjunction with past and
present works involving robots and vision systems designed for search and
rescue.
</p>
</div>
</dd>
<dt><a name="item41">[41]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15268" title="Abstract">arXiv:2309.15268</a> [<a href="/pdf/2309.15268" title="Download PDF">pdf</a>, <a href="/format/2309.15268" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ObVi-SLAM: Long-Term Object-Visual SLAM
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Adkins%2C+A">Amanda Adkins</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+T">Taijing Chen</a>, 
<a href="/search/cs?searchtype=author&query=Biswas%2C+J">Joydeep Biswas</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 7 figures, 1 table
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Robots responsible for tasks over long time scales must be able to localize
consistently and scalably amid geometric, viewpoint, and appearance changes.
Existing visual SLAM approaches rely on low-level feature descriptors that are
not robust to such environmental changes and result in large map sizes that
scale poorly over long-term deployments. In contrast, object detections are
robust to environmental variations and lead to more compact representations,
but most object-based SLAM systems target short-term indoor deployments with
close objects. In this paper, we introduce ObVi-SLAM to overcome these
challenges by leveraging the best of both approaches. ObVi-SLAM uses low-level
visual features for high-quality short-term visual odometry; and to ensure
global, long-term consistency, ObVi-SLAM builds an uncertainty-aware long-term
map of persistent objects and updates it after every deployment. By evaluating
ObVi-SLAM on data from 16 deployment sessions spanning different weather and
lighting conditions, we empirically show that ObVi-SLAM generates accurate
localization estimates consistent over long-time scales in spite of varying
appearance conditions.
</p>
</div>
</dd>
<dt><a name="item42">[42]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15270" title="Abstract">arXiv:2309.15270</a> [<a href="/pdf/2309.15270" title="Download PDF">pdf</a>, <a href="/format/2309.15270" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Consistent Query Answering for Primary Keys on Path Queries
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Koutris%2C+P">Paraschos Koutris</a>, 
<a href="/search/cs?searchtype=author&query=Ouyang%2C+X">Xiating Ouyang</a>, 
<a href="/search/cs?searchtype=author&query=Wijsen%2C+J">Jef Wijsen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> An evolved version of a paper published at PODS'21
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Databases (cs.DB)</span>

</div>
<p class="mathjax">We study the data complexity of consistent query answering (CQA) on databases
that may violate the primary key constraints. A repair is a maximal consistent
subset of the database. For a Boolean query $q$, the problem
$\mathsf{CERTAINTY}(q)$ takes a database as input, and asks whether or not each
repair satisfies $q$. It is known that for any self-join-free Boolean
conjunctive query $q$, $\mathsf{CERTAINTY}(q)$ is in $\mathbf{FO}$,
$\mathbf{LSPACE}$-complete, or $\mathbf{coNP}$-complete. In particular,
$\mathsf{CERTAINTY}(q)$ is in $\mathbf{FO}$ for any self-join-free Boolean path
query $q$. In this paper, we show that if self-joins are allowed, the
complexity of $\mathsf{CERTAINTY}(q)$ for Boolean path queries $q$ exhibits a
tetrachotomy between $\mathbf{FO}$, $\mathbf{NL}$-complete,
$\mathbf{PTIME}$-complete, and $\mathbf{coNP}$-complete. Moreover, it is
decidable, in polynomial time in the size of the query~$q$, which of the four
cases applies.
</p>
</div>
</dd>
<dt><a name="item43">[43]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15271" title="Abstract">arXiv:2309.15271</a> [<a href="/pdf/2309.15271" title="Download PDF">pdf</a>, <a href="/format/2309.15271" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Kinematic Modularity of Elementary Dynamic Actions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nah%2C+M+C">Moses C. Nah</a>, 
<a href="/search/cs?searchtype=author&query=Lachner%2C+J">Johannes Lachner</a>, 
<a href="/search/cs?searchtype=author&query=Tessari%2C+F">Federico Tessari</a>, 
<a href="/search/cs?searchtype=author&query=Hogan%2C+N">Neville Hogan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages (without references), 4 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">In this paper, a kinematically modular approach to robot control is
presented. The method involves structures called Elementary Dynamic Actions and
a network model combining these elements. With this control framework, a rich
repertoire of movements can be generated by combination of basic kinematic
modules. Each module can be learned by Imitation Learning, thereby resulting in
a modular learning strategy for robot control. The theoretical foundations and
their real robot implementation are presented. Using a KUKA LBR iiwa14 robot,
three tasks were considered: (1) generating a sequence of discrete movements,
(2) generating a combination of discrete and rhythmic movements, and (3) a
drawing and erasing task. The obtained results indicate that this modular
approach has the potential to simplify the generation of a diverse range of
robot actions.
</p>
</div>
</dd>
<dt><a name="item44">[44]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15272" title="Abstract">arXiv:2309.15272</a> [<a href="/pdf/2309.15272" title="Download PDF">pdf</a>, <a href="/format/2309.15272" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Zero-Shot Constrained Motion Planning Transformers Using Learned  Sampling Dictionaries
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Johnson%2C+J+J">Jacob J. Johnson</a>, 
<a href="/search/cs?searchtype=author&query=Qureshi%2C+A+H">Ahmed H. Qureshi</a>, 
<a href="/search/cs?searchtype=author&query=Yip%2C+M+C">Michael C. Yip</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Constrained robot motion planning is a ubiquitous need for robots interacting
with everyday environments, but it is a notoriously difficult problem to solve.
Many sampled points in a sample-based planner need to be rejected as they fall
outside the constraint manifold, or require significant iterative effort to
correct. Given this, few solutions exist that present a constraint-satisfying
trajectory for robots, in reasonable time and of low path cost. In this work,
we present a transformer-based model for motion planning with task space
constraints for manipulation systems. Vector Quantized-Motion Planning
Transformer (VQ-MPT) is a recent learning-based model that reduces the search
space for unconstrained planning for sampling-based motion planners. We propose
to adapt a pre-trained VQ-MPT model to reduce the search space for constraint
planning without retraining or finetuning the model. We also propose to update
the neural network output to move sampling regions closer to the constraint
manifold. Our experiments show how VQ-MPT improves planning times and accuracy
compared to traditional planners in simulated and real-world environments.
Unlike previous learning methods, which require task-related data, our method
uses pre-trained neural network models and requires no additional data for
training and finetuning the model making this a \textit{one-shot} process. We
also tested our method on a physical Franka Panda robot with real-world sensor
data, demonstrating the generalizability of our algorithm. We anticipate this
approach to be an accessible and broadly useful for transferring learned neural
planners to various robotic-environment interaction scenarios.
</p>
</div>
</dd>
<dt><a name="item45">[45]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15273" title="Abstract">arXiv:2309.15273</a> [<a href="/pdf/2309.15273" title="Download PDF">pdf</a>, <a href="/format/2309.15273" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DECO: Dense Estimation of 3D Human-Scene Contact In The Wild
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tripathi%2C+S">Shashank Tripathi</a>, 
<a href="/search/cs?searchtype=author&query=Chatterjee%2C+A">Agniv Chatterjee</a>, 
<a href="/search/cs?searchtype=author&query=Passy%2C+J">Jean-Claude Passy</a>, 
<a href="/search/cs?searchtype=author&query=Yi%2C+H">Hongwei Yi</a>, 
<a href="/search/cs?searchtype=author&query=Tzionas%2C+D">Dimitrios Tzionas</a>, 
<a href="/search/cs?searchtype=author&query=Black%2C+M+J">Michael J. Black</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted as Oral in ICCV'23. Project page: <a href="https://deco.is.tue.mpg.de">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Understanding how humans use physical contact to interact with the world is
key to enabling human-centric artificial intelligence. While inferring 3D
contact is crucial for modeling realistic and physically-plausible human-object
interactions, existing methods either focus on 2D, consider body joints rather
than the surface, use coarse 3D body regions, or do not generalize to
in-the-wild images. In contrast, we focus on inferring dense, 3D contact
between the full body surface and objects in arbitrary images. To achieve this,
we first collect DAMON, a new dataset containing dense vertex-level contact
annotations paired with RGB images containing complex human-object and
human-scene contact. Second, we train DECO, a novel 3D contact detector that
uses both body-part-driven and scene-context-driven attention to estimate
vertex-level contact on the SMPL body. DECO builds on the insight that human
observers recognize contact by reasoning about the contacting body parts, their
proximity to scene objects, and the surrounding scene context. We perform
extensive evaluations of our detector on DAMON as well as on the RICH and
BEHAVE datasets. We significantly outperform existing SOTA methods across all
benchmarks. We also show qualitatively that DECO generalizes well to diverse
and challenging real-world human interactions in natural images. The code,
data, and models are available at https://deco.is.tue.mpg.de.
</p>
</div>
</dd>
<dt><a name="item46">[46]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15274" title="Abstract">arXiv:2309.15274</a> [<a href="/pdf/2309.15274" title="Download PDF">pdf</a>, <a href="/format/2309.15274" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Memory-Efficient Continual Learning Object Segmentation for Long Video
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nazemi%2C+A">Amir Nazemi</a>, 
<a href="/search/cs?searchtype=author&query=Shafiee%2C+M+J">Mohammad Javad Shafiee</a>, 
<a href="/search/cs?searchtype=author&query=Gharaee%2C+Z">Zahra Gharaee</a>, 
<a href="/search/cs?searchtype=author&query=Fieguth%2C+P">Paul Fieguth</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Recent state-of-the-art semi-supervised Video Object Segmentation (VOS)
methods have shown significant improvements in target object segmentation
accuracy when information from preceding frames is used in undertaking
segmentation on the current frame. In particular, such memory-based approaches
can help a model to more effectively handle appearance changes (representation
drift) or occlusions. Ideally, for maximum performance, online VOS methods
would need all or most of the preceding frames (or their extracted information)
to be stored in memory and be used for online learning in consecutive frames.
Such a solution is not feasible for long videos, as the required memory size
would grow without bound. On the other hand, these methods can fail when memory
is limited and a target object experiences repeated representation drifts
throughout a video.
<br />We propose two novel techniques to reduce the memory requirement of online
VOS methods while improving modeling accuracy and generalization on long
videos. Motivated by the success of continual learning techniques in preserving
previously-learned knowledge, here we propose Gated-Regularizer Continual
Learning (GRCL), which improves the performance of any online VOS subject to
limited memory, and a Reconstruction-based Memory Selection Continual Learning
(RMSCL) which empowers online VOS methods to efficiently benefit from stored
information in memory.
<br />Experimental results show that the proposed methods improve the performance
of online VOS models up to 10 %, and boosts their robustness on long-video
datasets while maintaining comparable performance on short-video datasets
DAVIS16 and DAVIS17.
</p>
</div>
</dd>
<dt><a name="item47">[47]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15275" title="Abstract">arXiv:2309.15275</a> [<a href="/pdf/2309.15275" title="Download PDF">pdf</a>, <a href="/format/2309.15275" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Efficient Low-rank Backpropagation for Vision Transformer Adaptation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yuedong Yang</a>, 
<a href="/search/cs?searchtype=author&query=Chiang%2C+H">Hung-Yueh Chiang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+G">Guihong Li</a>, 
<a href="/search/cs?searchtype=author&query=Marculescu%2C+D">Diana Marculescu</a>, 
<a href="/search/cs?searchtype=author&query=Marculescu%2C+R">Radu Marculescu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 37th Conference on Neural Information Processing Systems (NeurIPS 2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">The increasing scale of vision transformers (ViT) has made the efficient
fine-tuning of these large models for specific needs a significant challenge in
various applications. This issue originates from the computationally demanding
matrix multiplications required during the backpropagation process through
linear layers in ViT. In this paper, we tackle this problem by proposing a new
Low-rank BackPropagation via Walsh-Hadamard Transformation (LBP-WHT) method.
Intuitively, LBP-WHT projects the gradient into a low-rank space and carries
out backpropagation. This approach substantially reduces the computation needed
for adapting ViT, as matrix multiplication in the low-rank space is far less
resource-intensive. We conduct extensive experiments with different models
(ViT, hybrid convolution-ViT model) on multiple datasets to demonstrate the
effectiveness of our method. For instance, when adapting an EfficientFormer-L1
model on CIFAR100, our LBP-WHT achieves 10.4% higher accuracy than the
state-of-the-art baseline, while requiring 9 MFLOPs less computation. As the
first work to accelerate ViT adaptation with low-rank backpropagation, our
LBP-WHT method is complementary to many prior efforts and can be combined with
them for better performance.
</p>
</div>
</dd>
<dt><a name="item48">[48]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15276" title="Abstract">arXiv:2309.15276</a> [<a href="/pdf/2309.15276" title="Download PDF">pdf</a>, <a href="/format/2309.15276" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Topological Machine Learning Pipeline for Classification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Conti%2C+F">Francesco Conti</a>, 
<a href="/search/cs?searchtype=author&query=Moroni%2C+D">Davide Moroni</a>, 
<a href="/search/cs?searchtype=author&query=Pascali%2C+M+A">Maria Antonietta Pascali</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Mathematics 2022, 10(17), 3086
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Algebraic Topology (math.AT)

</div>
<p class="mathjax">In this work, we develop a pipeline that associates Persistence Diagrams to
digital data via the most appropriate filtration for the type of data
considered. Using a grid search approach, this pipeline determines optimal
representation methods and parameters. The development of such a topological
pipeline for Machine Learning involves two crucial steps that strongly affect
its performance: firstly, digital data must be represented as an algebraic
object with a proper associated filtration in order to compute its topological
summary, the Persistence Diagram. Secondly, the persistence diagram must be
transformed with suitable representation methods in order to be introduced in a
Machine Learning algorithm. We assess the performance of our pipeline, and in
parallel, we compare the different representation methods on popular benchmark
datasets. This work is a first step toward both an easy and ready-to-use
pipeline for data classification using persistent homology and Machine
Learning, and to understand the theoretical reasons why, given a dataset and a
task to be performed, a pair (filtration, topological representation) is better
than another.
</p>
</div>
</dd>
<dt><a name="item49">[49]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15277" title="Abstract">arXiv:2309.15277</a> [<a href="/pdf/2309.15277" title="Download PDF">pdf</a>, <a href="/format/2309.15277" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Boosting High Resolution Image Classification with Scaling-up  Transformers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yi Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Technical report. 4 pages, 2 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">We present a holistic approach for high resolution image classification that
won second place in the ICCV/CVPPA2023 Deep Nutrient Deficiency Challenge. The
approach consists of a full pipeline of: 1) data distribution analysis to check
potential domain shift, 2) backbone selection for a strong baseline model that
scales up for high resolution input, 3) transfer learning that utilizes
published pretrained models and continuous fine-tuning on small sub-datasets,
4) data augmentation for the diversity of training data and to prevent
overfitting, 5) test-time augmentation to improve the prediction's robustness,
and 6) "data soups" that conducts cross-fold model prediction average for
smoothened final test results.
</p>
</div>
</dd>
<dt><a name="item50">[50]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15278" title="Abstract">arXiv:2309.15278</a> [<a href="/pdf/2309.15278" title="Download PDF">pdf</a>, <a href="/format/2309.15278" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Out of Sight, Still in Mind: Reasoning and Planning about Unobserved  Objects with Video Tracking Enabled Memory Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+Y">Yixuan Huang</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+J">Jialin Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+C">Chanho Kim</a>, 
<a href="/search/cs?searchtype=author&query=Pradhan%2C+P">Pupul Pradhan</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+B">Bryan Chen</a>, 
<a href="/search/cs?searchtype=author&query=Fuxin%2C+L">Li Fuxin</a>, 
<a href="/search/cs?searchtype=author&query=Hermans%2C+T">Tucker Hermans</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Under review
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
<p class="mathjax">Robots need to have a memory of previously observed, but currently occluded
objects to work reliably in realistic environments. We investigate the problem
of encoding object-oriented memory into a multi-object manipulation reasoning
and planning framework. We propose DOOM and LOOM, which leverage transformer
relational dynamics to encode the history of trajectories given partial-view
point clouds and an object discovery and tracking engine. Our approaches can
perform multiple challenging tasks including reasoning with occluded objects,
novel objects appearance, and object reappearance. Throughout our extensive
simulation and real-world experiments, we find that our approaches perform well
in terms of different numbers of objects and different numbers of distractor
actions. Furthermore, we show our approaches outperform an implicit memory
baseline.
</p>
</div>
</dd>
<dt><a name="item51">[51]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15283" title="Abstract">arXiv:2309.15283</a> [<a href="/pdf/2309.15283" title="Download PDF">pdf</a>, <a href="/format/2309.15283" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multi-Modal Planning on Regrasping for Stable Manipulation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hu%2C+J">Jiaming Hu</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+Z">Zhao Tang</a>, 
<a href="/search/cs?searchtype=author&query=Christensen%2C+H+I">Henrik I. Christensen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Nowadays, a number of grasping algorithms have been proposed, that can
predict a candidate of grasp poses, even for unseen objects. This enables a
robotic manipulator to pick-and-place such objects. However, some of the
predicted grasp poses to stably lift a target object may not be directly
approachable due to workspace limitations. In such cases, the robot will need
to re-grasp the desired object to enable successful grasping on it. This
involves planning a sequence of continuous actions such as sliding,
re-grasping, and transferring. To address this multi-modal problem, we propose
a Markov-Decision Process-based multi-modal planner that can rearrange the
object into a position suitable for stable manipulation. We demonstrate
improved performance in both simulation and the real world for pick-and-place
tasks.
</p>
</div>
</dd>
<dt><a name="item52">[52]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15284" title="Abstract">arXiv:2309.15284</a> [<a href="/pdf/2309.15284" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Physics Enhanced Residual Learning (PERL) Framework for Traffic State  Prediction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Long%2C+K">Keke Long</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+H">Haotian Shi</a>, 
<a href="/search/cs?searchtype=author&query=Sheng%2C+Z">Zihao Sheng</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xiaopeng Li</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+S">Sikai Chen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">In vehicle trajectory prediction, physics models and data-driven models are
two predominant methodologies. However, each approach presents its own set of
challenges: physics models fall short in predictability, while data-driven
models lack interpretability. Addressing these identified shortcomings, this
paper proposes a novel framework, the Physics-Enhanced Residual Learning (PERL)
model. PERL integrates the strengths of physics-based and data-driven methods
for traffic state prediction. PERL contains a physics model and a residual
learning model. Its prediction is the sum of the physics model result and a
predicted residual as a correction to it. It preserves the interpretability
inherent to physics-based models and has reduced data requirements compared to
data-driven methods. Experiments were conducted using a real-world vehicle
trajectory dataset. We proposed a PERL model, with the Intelligent Driver Model
(IDM) as its physics car-following model and Long Short-Term Memory (LSTM) as
its residual learning model. We compare this PERL model with the physics
car-following model, data-driven model, and other physics-informed neural
network (PINN) models. The result reveals that PERL achieves better prediction
with a small dataset, compared to the physics model, data-driven model, and
PINN model. Second, the PERL model showed faster convergence during training,
offering comparable performance with fewer training samples than the
data-driven model and PINN model. Sensitivity analysis also proves comparable
performance of PERL using another residual learning model and a physics
car-following model.
</p>
</div>
</dd>
<dt><a name="item53">[53]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15286" title="Abstract">arXiv:2309.15286</a> [<a href="/pdf/2309.15286" title="Download PDF">pdf</a>, <a href="/format/2309.15286" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Composable Coresets for Determinant Maximization: Greedy is Almost  Optimal
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gollapudi%2C+S">Siddharth Gollapudi</a>, 
<a href="/search/cs?searchtype=author&query=Mahabadi%2C+S">Sepideh Mahabadi</a>, 
<a href="/search/cs?searchtype=author&query=Sivashankar%2C+V">Varun Sivashankar</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Given a set of $n$ vectors in $\mathbb{R}^d$, the goal of the
\emph{determinant maximization} problem is to pick $k$ vectors with the maximum
volume. Determinant maximization is the MAP-inference task for determinantal
point processes (DPP) and has recently received considerable attention for
modeling diversity. As most applications for the problem use large amounts of
data, this problem has been studied in the relevant \textit{composable coreset}
setting. In particular, [Indyk-Mahabadi-OveisGharan-Rezaei--SODA'20, ICML'19]
showed that one can get composable coresets with optimal approximation factor
of $\tilde O(k)^k$ for the problem, and that a local search algorithm achieves
an almost optimal approximation guarantee of $O(k)^{2k}$. In this work, we show
that the widely-used Greedy algorithm also provides composable coresets with an
almost optimal approximation factor of $O(k)^{3k}$, which improves over the
previously known guarantee of $C^{k^2}$, and supports the prior experimental
results showing the practicality of the greedy algorithm as a coreset. Our main
result follows by showing a local optimality property for Greedy: swapping a
single point from the greedy solution with a vector that was not picked by the
greedy algorithm can increase the volume by a factor of at most $(1+\sqrt{k})$.
This is tight up to the additive constant $1$. Finally, our experiments show
that the local optimality of the greedy algorithm is even lower than the
theoretical bound on real data sets.
</p>
</div>
</dd>
<dt><a name="item54">[54]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15289" title="Abstract">arXiv:2309.15289</a> [<a href="/pdf/2309.15289" title="Download PDF">pdf</a>, <a href="/format/2309.15289" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SEPT: Towards Efficient Scene Representation Learning for Motion  Prediction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lan%2C+Z">Zhiqian Lan</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+Y">Yuxuan Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Mu%2C+Y">Yao Mu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+C">Chen Chen</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+S+E">Shengbo Eben Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+H">Hang Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+K">Keqiang Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Motion prediction is crucial for autonomous vehicles to operate safely in
complex traffic environments. Extracting effective spatiotemporal relationships
among traffic elements is key to accurate forecasting. Inspired by the
successful practice of pretrained large language models, this paper presents
SEPT, a modeling framework that leverages self-supervised learning to develop
powerful spatiotemporal understanding for complex traffic scenes. Specifically,
our approach involves three masking-reconstruction modeling tasks on scene
inputs including agents' trajectories and road network, pretraining the scene
encoder to capture kinematics within trajectory, spatial structure of road
network, and interactions among roads and agents. The pretrained encoder is
then finetuned on the downstream forecasting task. Extensive experiments
demonstrate that SEPT, without elaborate architectural design or manual feature
engineering, achieves state-of-the-art performance on the Argoverse 1 and
Argoverse 2 motion forecasting benchmarks, outperforming previous methods on
all main metrics by a large margin.
</p>
</div>
</dd>
<dt><a name="item55">[55]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15292" title="Abstract">arXiv:2309.15292</a> [<a href="/pdf/2309.15292" title="Download PDF">pdf</a>, <a href="/format/2309.15292" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Scaling Representation Learning from Ubiquitous ECG with State-Space  Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Avramidis%2C+K">Kleanthis Avramidis</a>, 
<a href="/search/cs?searchtype=author&query=Kunc%2C+D">Dominika Kunc</a>, 
<a href="/search/cs?searchtype=author&query=Perz%2C+B">Bartosz Perz</a>, 
<a href="/search/cs?searchtype=author&query=Adsul%2C+K">Kranti Adsul</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+T">Tiantian Feng</a>, 
<a href="/search/cs?searchtype=author&query=Kazienko%2C+P">Przemys&#x142;aw Kazienko</a>, 
<a href="/search/cs?searchtype=author&query=Saganowski%2C+S">Stanis&#x142;aw Saganowski</a>, 
<a href="/search/cs?searchtype=author&query=Narayanan%2C+S">Shrikanth Narayanan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Pre-print, currently under review
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">Ubiquitous sensing from wearable devices in the wild holds promise for
enhancing human well-being, from diagnosing clinical conditions and measuring
stress to building adaptive health promoting scaffolds. But the large volumes
of data therein across heterogeneous contexts pose challenges for conventional
supervised learning approaches. Representation Learning from biological signals
is an emerging realm catalyzed by the recent advances in computational modeling
and the abundance of publicly shared databases. The electrocardiogram (ECG) is
the primary researched modality in this context, with applications in health
monitoring, stress and affect estimation. Yet, most studies are limited by
small-scale controlled data collection and over-parameterized architecture
choices. We introduce \textbf{WildECG}, a pre-trained state-space model for
representation learning from ECG signals. We train this model in a
self-supervised manner with 275,000 10s ECG recordings collected in the wild
and evaluate it on a range of downstream tasks. The proposed model is a robust
backbone for ECG analysis, providing competitive performance on most of the
tasks considered, while demonstrating efficacy in low-resource regimes. The
code and pre-trained weights are shared publicly at
https://github.com/klean2050/tiles_ecg_model.
</p>
</div>
</dd>
<dt><a name="item56">[56]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15293" title="Abstract">arXiv:2309.15293</a> [<a href="/pdf/2309.15293" title="Download PDF">pdf</a>, <a href="/format/2309.15293" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Maximum Diffusion Reinforcement Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Berrueta%2C+T+A">Thomas A. Berrueta</a>, 
<a href="/search/cs?searchtype=author&query=Pinosky%2C+A">Allison Pinosky</a>, 
<a href="/search/cs?searchtype=author&query=Murphey%2C+T+D">Todd D. Murphey</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> For Supplementary Movies, see <a href="https://youtube.com/playlist?list=PLO5AGPa3klrCTSO-t7HZsVNQinHXFQmn9">this https URL</a>&amp;si=cICRyEuRWy565_36
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Statistical Mechanics (cond-mat.stat-mech); Artificial Intelligence (cs.AI); Robotics (cs.RO)

</div>
<p class="mathjax">The assumption that data are independent and identically distributed
underpins all machine learning. When data are collected sequentially from agent
experiences this assumption does not generally hold, as in reinforcement
learning. Here, we derive a method that overcomes these limitations by
exploiting the statistical mechanics of ergodic processes, which we term
maximum diffusion reinforcement learning. By decorrelating agent experiences,
our approach provably enables agents to learn continually in single-shot
deployments regardless of how they are initialized. Moreover, we prove our
approach generalizes well-known maximum entropy techniques, and show that it
robustly exceeds state-of-the-art performance across popular benchmarks. Our
results at the nexus of physics, learning, and control pave the way towards
more transparent and reliable decision-making in reinforcement learning agents,
such as locomoting robots and self-driving cars.
</p>
</div>
</dd>
<dt><a name="item57">[57]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15302" title="Abstract">arXiv:2309.15302</a> [<a href="/pdf/2309.15302" title="Download PDF">pdf</a>, <a href="/format/2309.15302" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Self-Supervised Terrain Representation Learning from Unconstrained Robot  Experience
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Karnan%2C+H">Haresh Karnan</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+E">Elvin Yang</a>, 
<a href="/search/cs?searchtype=author&query=Farkash%2C+D">Daniel Farkash</a>, 
<a href="/search/cs?searchtype=author&query=Warnell%2C+G">Garrett Warnell</a>, 
<a href="/search/cs?searchtype=author&query=Biswas%2C+J">Joydeep Biswas</a>, 
<a href="/search/cs?searchtype=author&query=Stone%2C+P">Peter Stone</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Conference on Robot Learning (CoRL 2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
<p class="mathjax">Terrain awareness, i.e., the ability to identify and distinguish different
types of terrain, is a critical ability that robots must have to succeed at
autonomous off-road navigation. Current approaches that provide robots with
this awareness either rely on labeled data which is expensive to collect,
engineered features and cost functions that may not generalize, or expert human
demonstrations which may not be available. Towards endowing robots with terrain
awareness without these limitations, we introduce Self-supervised TErrain
Representation LearnING (STERLING), a novel approach for learning terrain
representations that relies solely on easy-to-collect, unconstrained (e.g.,
non-expert), and unlabelled robot experience, with no additional constraints on
data collection. STERLING employs a novel multi-modal self-supervision
objective through non-contrastive representation learning to learn relevant
terrain representations for terrain-aware navigation. Through physical robot
experiments in off-road environments, we evaluate STERLING features on the task
of preference-aligned visual navigation and find that STERLING features perform
on par with fully supervised approaches and outperform other state-of-the-art
methods with respect to preference alignment. Additionally, we perform a
large-scale experiment of autonomously hiking a 3-mile long trail which
STERLING completes successfully with only two manual interventions,
demonstrating its robustness to real-world off-road conditions.
</p>
</div>
</dd>
<dt><a name="item58">[58]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15311" title="Abstract">arXiv:2309.15311</a> [<a href="/pdf/2309.15311" title="Download PDF">pdf</a>, <a href="/format/2309.15311" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Importance of Multimodal Emotion Conditioning and Affect Consistency  for Embodied Conversational Agents
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chang%2C+C">Che-Jui Chang</a>, 
<a href="/search/cs?searchtype=author&query=Sohn%2C+S+S">Samuel S. Sohn</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+S">Sen Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Jayashankar%2C+R">Rajath Jayashankar</a>, 
<a href="/search/cs?searchtype=author&query=Usman%2C+M">Muhammad Usman</a>, 
<a href="/search/cs?searchtype=author&query=Kapadia%2C+M">Mubbasir Kapadia</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Artificial Intelligence (cs.AI); Graphics (cs.GR)

</div>
<p class="mathjax">Previous studies regarding the perception of emotions for embodied virtual
agents have shown the effectiveness of using virtual characters in conveying
emotions through interactions with humans. However, creating an autonomous
embodied conversational agent with expressive behaviors presents two major
challenges. The first challenge is the difficulty of synthesizing the
conversational behaviors for each modality that are as expressive as real human
behaviors. The second challenge is that the affects are modeled independently,
which makes it difficult to generate multimodal responses with consistent
emotions across all modalities. In this work, we propose a conceptual
framework, ACTOR (Affect-Consistent mulTimodal behaviOR generation), that aims
to increase the perception of affects by generating multimodal behaviors
conditioned on a consistent driving affect. We have conducted a user study with
199 participants to assess how the average person judges the affects perceived
from multimodal behaviors that are consistent and inconsistent with respect to
a driving affect. The result shows that among all model conditions, our
affect-consistent framework receives the highest Likert scores for the
perception of driving affects. Our statistical analysis suggests that making a
modality affect-inconsistent significantly decreases the perception of driving
affects. We also observe that multimodal behaviors conditioned on consistent
affects are more expressive compared to behaviors with inconsistent affects.
Therefore, we conclude that multimodal emotion conditioning and affect
consistency are vital to enhancing the perception of affects for embodied
conversational agents.
</p>
</div>
</dd>
<dt><a name="item59">[59]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15312" title="Abstract">arXiv:2309.15312</a> [<a href="/pdf/2309.15312" title="Download PDF">pdf</a>, <a href="/format/2309.15312" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MAPTree: Beating &quot;Optimal&quot; Decision Trees with Bayesian Decision Trees
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sullivan%2C+C">Colin Sullivan</a>, 
<a href="/search/cs?searchtype=author&query=Tiwari%2C+M">Mo Tiwari</a>, 
<a href="/search/cs?searchtype=author&query=Thrun%2C+S">Sebastian Thrun</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 19 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Decision trees remain one of the most popular machine learning models today,
largely due to their out-of-the-box performance and interpretability. In this
work, we present a Bayesian approach to decision tree induction via maximum a
posteriori inference of a posterior distribution over trees. We first
demonstrate a connection between maximum a posteriori inference of decision
trees and AND/OR search. Using this connection, we propose an AND/OR search
algorithm, dubbed MAPTree, which is able to recover the maximum a posteriori
tree. Lastly, we demonstrate the empirical performance of the maximum a
posteriori tree both on synthetic data and in real world settings. On 16 real
world datasets, MAPTree either outperforms baselines or demonstrates comparable
performance but with much smaller trees. On a synthetic dataset, MAPTree also
demonstrates greater robustness to noise and better generalization than
existing approaches. Finally, MAPTree recovers the maxiumum a posteriori tree
faster than existing sampling approaches and, in contrast with those
algorithms, is able to provide a certificate of optimality. The code for our
experiments is available at https://github.com/ThrunGroup/maptree.
</p>
</div>
</dd>
<dt><a name="item60">[60]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15313" title="Abstract">arXiv:2309.15313</a> [<a href="/pdf/2309.15313" title="Download PDF">pdf</a>, <a href="/format/2309.15313" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> M$^{3}$3D: Learning 3D priors using Multi-Modal Masked Autoencoders for  2D image and video understanding
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jamal%2C+M+A">Muhammad Abdullah Jamal</a>, 
<a href="/search/cs?searchtype=author&query=Mohareri%2C+O">Omid Mohareri</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">We present a new pre-training strategy called M$^{3}$3D
($\underline{M}$ulti-$\underline{M}$odal $\underline{M}$asked $\underline{3D}$)
built based on Multi-modal masked autoencoders that can leverage 3D priors and
learned cross-modal representations in RGB-D data. We integrate two major
self-supervised learning frameworks; Masked Image Modeling (MIM) and
contrastive learning; aiming to effectively embed masked 3D priors and modality
complementary features to enhance the correspondence between modalities. In
contrast to recent approaches which are either focusing on specific downstream
tasks or require multi-view correspondence, we show that our pre-training
strategy is ubiquitous, enabling improved representation learning that can
transfer into improved performance on various downstream tasks such as video
action recognition, video action detection, 2D semantic segmentation and depth
estimation. Experiments show that M$^{3}$3D outperforms the existing
state-of-the-art approaches on ScanNet, NYUv2, UCF-101 and OR-AR, particularly
with an improvement of +1.3\% mIoU against Mask3D on ScanNet semantic
segmentation. We further evaluate our method on low-data regime and demonstrate
its superior data efficiency compared to current state-of-the-art approaches.
</p>
</div>
</dd>
<dt><a name="item61">[61]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15317" title="Abstract">arXiv:2309.15317</a> [<a href="/pdf/2309.15317" title="Download PDF">pdf</a>, <a href="/format/2309.15317" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> joint prediction and denoising for large-scale multilingual  self-supervised learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+W">William Chen</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+J">Jiatong Shi</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+B">Brian Yan</a>, 
<a href="/search/cs?searchtype=author&query=Berrebbi%2C+D">Dan Berrebbi</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+W">Wangyou Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+Y">Yifan Peng</a>, 
<a href="/search/cs?searchtype=author&query=Chang%2C+X">Xuankai Chang</a>, 
<a href="/search/cs?searchtype=author&query=Maiti%2C+S">Soumi Maiti</a>, 
<a href="/search/cs?searchtype=author&query=Watanabe%2C+S">Shinji Watanabe</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to ASRU 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Sound (cs.SD); Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">Multilingual self-supervised learning (SSL) has often lagged behind
state-of-the-art (SOTA) methods due to the expenses and complexity required to
handle many languages. This further harms the reproducibility of SSL, which is
already limited to few research groups due to its resource usage. We show that
more powerful techniques can actually lead to more efficient pre-training,
opening SSL to more research groups. We propose WavLabLM, which extends WavLM's
joint prediction and denoising to 40k hours of data across 136 languages. To
build WavLabLM, we devise a novel multi-stage pre-training method, designed to
address the language imbalance of multilingual data. WavLabLM achieves
comparable performance to XLS-R on ML-SUPERB with less than 10% of the training
data, making SSL realizable with academic compute. We show that further
efficiency can be achieved with a vanilla HuBERT Base model, which can maintain
94% of XLS-R's performance with only 3% of the data, 4 GPUs, and limited
trials. We open-source all code and models in ESPnet.
</p>
</div>
</dd>
<dt><a name="item62">[62]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15319" title="Abstract">arXiv:2309.15319</a> [<a href="/pdf/2309.15319" title="Download PDF">pdf</a>, <a href="/format/2309.15319" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DeepROCK: Error-controlled interaction detection in deep neural networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+W">Winston Chen</a>, 
<a href="/search/cs?searchtype=author&query=Noble%2C+W+S">William Stafford Noble</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+Y+Y">Yang Young Lu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Quantitative Methods (q-bio.QM)

</div>
<p class="mathjax">The complexity of deep neural networks (DNNs) makes them powerful but also
makes them challenging to interpret, hindering their applicability in
error-intolerant domains. Existing methods attempt to reason about the internal
mechanism of DNNs by identifying feature interactions that influence prediction
outcomes. However, such methods typically lack a systematic strategy to
prioritize interactions while controlling confidence levels, making them
difficult to apply in practice for scientific discovery and hypothesis
validation. In this paper, we introduce a method, called DeepROCK, to address
this limitation by using knockoffs, which are dummy variables that are designed
to mimic the dependence structure of a given set of features while being
conditionally independent of the response. Together with a novel DNN
architecture involving a pairwise-coupling layer, DeepROCK jointly controls the
false discovery rate (FDR) and maximizes statistical power. In addition, we
identify a challenge in correctly controlling FDR using off-the-shelf feature
interaction importance measures. DeepROCK overcomes this challenge by proposing
a calibration procedure applied to existing interaction importance measures to
make the FDR under control at a target level. Finally, we validate the
effectiveness of DeepROCK through extensive experiments on simulated and real
datasets.
</p>
</div>
</dd>
<dt><a name="item63">[63]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15322" title="Abstract">arXiv:2309.15322</a> [<a href="/pdf/2309.15322" title="Download PDF">pdf</a>, <a href="/ps/2309.15322" title="Download PostScript">ps</a>, <a href="/format/2309.15322" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the Power of SVD in the Stochastic Block Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mao%2C+X">Xinyu Mao</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jiapeng Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Data Structures and Algorithms (cs.DS); Probability (math.PR)

</div>
<p class="mathjax">A popular heuristic method for improving clustering results is to apply
dimensionality reduction before running clustering algorithms. It has been
observed that spectral-based dimensionality reduction tools, such as PCA or
SVD, improve the performance of clustering algorithms in many applications.
This phenomenon indicates that spectral method not only serves as a
dimensionality reduction tool, but also contributes to the clustering procedure
in some sense. It is an interesting question to understand the behavior of
spectral steps in clustering problems.
<br />As an initial step in this direction, this paper studies the power of
vanilla-SVD algorithm in the stochastic block model (SBM). We show that, in the
symmetric setting, vanilla-SVD algorithm recovers all clusters correctly. This
result answers an open question posed by Van Vu (Combinatorics Probability and
Computing, 2018) in the symmetric setting.
</p>
</div>
</dd>
<dt><a name="item64">[64]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15324" title="Abstract">arXiv:2309.15324</a> [<a href="/pdf/2309.15324" title="Download PDF">pdf</a>, <a href="/format/2309.15324" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DefectHunter: A Novel LLM-Driven Boosted-Conformer-based Code  Vulnerability Detection Mechanism
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jin Wang</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+Z">Zishan Huang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+H">Hengli Liu</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+N">Nianyi Yang</a>, 
<a href="/search/cs?searchtype=author&query=Xiao%2C+Y">Yinhao Xiao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">One of the most pressing threats to computing systems is software
vulnerabilities, which can compromise both hardware and software components.
Existing methods for vulnerability detection remain suboptimal. Traditional
techniques are both time-consuming and labor-intensive, while
machine-learning-based approaches often underperform when applied to complex
datasets, due to their inability to capture high-dimensional relationships.
Previous deep-learning strategies also fall short in capturing sufficient
feature information. Although self-attention mechanisms can process information
over long distances, they fail to capture structural information. In this
paper, we introduce DefectHunter, an innovative model for vulnerability
identification that employs the Conformer mechanism. This mechanism fuses
self-attention with convolutional networks to capture both local, position-wise
features and global, content-based interactions. Furthermore, we optimize the
self-attention mechanisms to mitigate the issue of excessive attention heads
introducing extraneous noise by adjusting the denominator. We evaluated
DefectHunter against ten baseline methods using six industrial and two highly
complex datasets. On the QEMU dataset, DefectHunter exhibited a 20.62\%
improvement in accuracy over Pongo-70B, and for the CWE-754 dataset, its
accuracy was 14.64\% higher. To investigate how DefectHunter comprehends
vulnerabilities, we conducted a case study, which revealed that our model
effectively understands the mechanisms underlying vulnerabilities.
</p>
</div>
</dd>
<dt><a name="item65">[65]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15325" title="Abstract">arXiv:2309.15325</a> [<a href="/pdf/2309.15325" title="Download PDF">pdf</a>, <a href="/format/2309.15325" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Neural Operators for Accelerating Scientific Simulations and Design
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Azzizadenesheli%2C+K">Kamyar Azzizadenesheli</a>, 
<a href="/search/cs?searchtype=author&query=Kovachki%2C+N">Nikola Kovachki</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zongyi Li</a>, 
<a href="/search/cs?searchtype=author&query=Liu-Schiaffini%2C+M">Miguel Liu-Schiaffini</a>, 
<a href="/search/cs?searchtype=author&query=Kossaifi%2C+J">Jean Kossaifi</a>, 
<a href="/search/cs?searchtype=author&query=Anandkumar%2C+A">Anima Anandkumar</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computational Physics (physics.comp-ph)

</div>
<p class="mathjax">Scientific discovery and engineering design are currently limited by the time
and cost of physical experiments, selected mostly through trial-and-error and
intuition that require deep domain expertise. Numerical simulations present an
alternative to physical experiments, but are usually infeasible for complex
real-world domains due to the computational requirements of existing numerical
methods. Artificial intelligence (AI) presents a potential paradigm shift
through the development of fast data-driven surrogate models. In particular, an
AI framework, known as neural operators, presents a principled framework for
learning mappings between functions defined on continuous domains, e.g.,
spatiotemporal processes and partial differential equations (PDE). They can
extrapolate and predict solutions at new locations unseen during training,
i.e., perform zero-shot super-resolution. Neural operators can augment or even
replace existing simulators in many applications, such as computational fluid
dynamics, weather forecasting, and material modeling, while being 4-5 orders of
magnitude faster. Further, neural operators can be integrated with physics and
other domain constraints enforced at finer resolutions to obtain high-fidelity
solutions and good generalization. Since neural operators are differentiable,
they can directly optimize parameters for inverse design and other inverse
problems. We believe that neural operators present a transformative approach to
simulation and design, enabling rapid research and development.
</p>
</div>
</dd>
<dt><a name="item66">[66]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15328" title="Abstract">arXiv:2309.15328</a> [<a href="/pdf/2309.15328" title="Download PDF">pdf</a>, <a href="/format/2309.15328" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exploring Learned Representations of Neural Networks with Principal  Component Analysis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Harlev%2C+A">Amit Harlev</a>, 
<a href="/search/cs?searchtype=author&query=Engel%2C+A">Andrew Engel</a>, 
<a href="/search/cs?searchtype=author&query=Stinis%2C+P">Panos Stinis</a>, 
<a href="/search/cs?searchtype=author&query=Chiang%2C+T">Tony Chiang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages, 3 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Understanding feature representation for deep neural networks (DNNs) remains
an open question within the general field of explainable AI. We use principal
component analysis (PCA) to study the performance of a k-nearest neighbors
classifier (k-NN), nearest class-centers classifier (NCC), and support vector
machines on the learned layer-wise representations of a ResNet-18 trained on
CIFAR-10. We show that in certain layers, as little as 20% of the intermediate
feature-space variance is necessary for high-accuracy classification and that
across all layers, the first ~100 PCs completely determine the performance of
the k-NN and NCC classifiers. We relate our findings to neural collapse and
provide partial evidence for the related phenomenon of intermediate neural
collapse. Our preliminary work provides three distinct yet interpretable
surrogate models for feature representation with an affine linear model the
best performing. We also show that leveraging several surrogate models affords
us a clever method to estimate where neural collapse may initially occur within
the DNN.
</p>
</div>
</dd>
<dt><a name="item67">[67]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15329" title="Abstract">arXiv:2309.15329</a> [<a href="/pdf/2309.15329" title="Download PDF">pdf</a>, <a href="/format/2309.15329" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> BASED: Bundle-Adjusting Surgical Endoscopic Dynamic Video Reconstruction  using Neural Radiance Fields
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Saha%2C+S">Shreya Saha</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+S">Sainan Liu</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+S">Shan Lin</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+J">Jingpei Lu</a>, 
<a href="/search/cs?searchtype=author&query=Yip%2C+M">Michael Yip</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Reconstruction of deformable scenes from endoscopic videos is important for
many applications such as intraoperative navigation, surgical visual
perception, and robotic surgery. It is a foundational requirement for realizing
autonomous robotic interventions for minimally invasive surgery. However,
previous approaches in this domain have been limited by their modular nature
and are confined to specific camera and scene settings. Our work adopts the
Neural Radiance Fields (NeRF) approach to learning 3D implicit representations
of scenes that are both dynamic and deformable over time, and furthermore with
unknown camera poses. We demonstrate this approach on endoscopic surgical
scenes from robotic surgery. This work removes the constraints of known camera
poses and overcomes the drawbacks of the state-of-the-art unstructured dynamic
scene reconstruction technique, which relies on the static part of the scene
for accurate reconstruction. Through several experimental datasets, we
demonstrate the versatility of our proposed model to adapt to diverse camera
and scene settings, and show its promise for both current and future robotic
surgical systems.
</p>
</div>
</dd>
<dt><a name="item68">[68]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15332" title="Abstract">arXiv:2309.15332</a> [<a href="/pdf/2309.15332" title="Download PDF">pdf</a>, <a href="/format/2309.15332" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multimodal Dataset for Localization, Mapping and Crop Monitoring in  Citrus Tree Farms
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Teng%2C+H">Hanzhe Teng</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yipeng Wang</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+X">Xiaoao Song</a>, 
<a href="/search/cs?searchtype=author&query=Karydis%2C+K">Konstantinos Karydis</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to the 18th International Symposium on Visual Computing (ISVC 2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">In this work we introduce the CitrusFarm dataset, a comprehensive multimodal
sensory dataset collected by a wheeled mobile robot operating in agricultural
fields. The dataset offers stereo RGB images with depth information, as well as
monochrome, near-infrared and thermal images, presenting diverse spectral
responses crucial for agricultural research. Furthermore, it provides a range
of navigational sensor data encompassing wheel odometry, LiDAR, inertial
measurement unit (IMU), and GNSS with Real-Time Kinematic (RTK) as the
centimeter-level positioning ground truth. The dataset comprises seven
sequences collected in three fields of citrus trees, featuring various tree
species at different growth stages, distinctive planting patterns, as well as
varying daylight conditions. It spans a total operation time of 1.7 hours,
covers a distance of 7.5 km, and constitutes 1.3 TB of data. We anticipate that
this dataset can facilitate the development of autonomous robot systems
operating in agricultural tree environments, especially for localization,
mapping and crop monitoring tasks. Moreover, the rich sensing modalities
offered in this dataset can also support research in a range of robotics and
computer vision tasks, such as place recognition, scene understanding, object
detection and segmentation, and multimodal learning. The dataset, in
conjunction with related tools and resources, is made publicly available at
https://github.com/UCR-Robotics/Citrus-Farm-Dataset.
</p>
</div>
</dd>
<dt><a name="item69">[69]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15334" title="Abstract">arXiv:2309.15334</a> [<a href="/pdf/2309.15334" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> C3Net: interatomic potential neural network for prediction of  physicochemical properties in heterogenous systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lee%2C+S">Sehan Lee</a>, 
<a href="/search/cs?searchtype=author&query=Lim%2C+J">Jaechang Lim</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+W+Y">Woo Youn Kim</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, 6 figures, 2 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Understanding the interactions of a solute with its environment is of
fundamental importance in chemistry and biology. In this work, we propose a
deep neural network architecture for atom type embeddings in its molecular
context and interatomic potential that follows fundamental physical laws. The
architecture is applied to predict physicochemical properties in heterogeneous
systems including solvation in diverse solvents, 1-octanol-water partitioning,
and PAMPA with a single set of network weights. We show that our architecture
is generalized well to the physicochemical properties and outperforms
state-of-the-art approaches based on quantum mechanics and neural networks in
the task of solvation free energy prediction. The interatomic potentials at
each atom in a solute obtained from the model allow quantitative analysis of
the physicochemical properties at atomic resolution consistent with chemical
and physical reasoning. The software is available at
https://github.com/SehanLee/C3Net.
</p>
</div>
</dd>
<dt><a name="item70">[70]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15337" title="Abstract">arXiv:2309.15337</a> [<a href="/pdf/2309.15337" title="Download PDF">pdf</a>, <a href="/format/2309.15337" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Beyond the Chat: Executable and Verifiable Text-Editing with LLMs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Laban%2C+P">Philippe Laban</a>, 
<a href="/search/cs?searchtype=author&query=Vig%2C+J">Jesse Vig</a>, 
<a href="/search/cs?searchtype=author&query=Hearst%2C+M+A">Marti A. Hearst</a>, 
<a href="/search/cs?searchtype=author&query=Xiong%2C+C">Caiming Xiong</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+C">Chien-Sheng Wu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Human-Computer Interaction (cs.HC)

</div>
<p class="mathjax">Conversational interfaces powered by Large Language Models (LLMs) have
recently become a popular way to obtain feedback during document editing.
However, standard chat-based conversational interfaces do not support
transparency and verifiability of the editing changes that they suggest. To
give the author more agency when editing with an LLM, we present InkSync, an
editing interface that suggests executable edits directly within the document
being edited. Because LLMs are known to introduce factual errors, Inksync also
supports a 3-stage approach to mitigate this risk: Warn authors when a
suggested edit introduces new information, help authors Verify the new
information's accuracy through external search, and allow an auditor to perform
an a-posteriori verification by Auditing the document via a trace of all
auto-generated content. Two usability studies confirm the effectiveness of
InkSync's components when compared to standard LLM-based chat interfaces,
leading to more accurate, more efficient editing, and improved user experience.
</p>
</div>
</dd>
<dt><a name="item71">[71]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15340" title="Abstract">arXiv:2309.15340</a> [<a href="/pdf/2309.15340" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Evaluation and Analysis of Standard Security Technology in V2X  Communication -- Exploring ECQV Implicit Certificate Cracking
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+A+C+H">Abel C. H. Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> in Chinese language
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Networking and Internet Architecture (cs.NI)

</div>
<p class="mathjax">In IEEE 1609.2 and IEEE 1609.2.1 standards for Vehicle-to-everything (V2X)
secure communication, various security algorithms based on Elliptic Curve
Cryptography (ECC) have been adopted and designed. To enhance the efficiency of
the Security Credential Management System (SCMS), this study evaluates the
computational time for key generation, key expansion, signature generation, and
signature verification under different security strengths. This study discusses
relevant techniques based on Elliptic Curve Qu-Vanstone (ECQV) implicit
certificates, analyzes the length of uncompressed elliptic curve points,
compressed elliptic curve points, explicit certificates, and implicit
certificates. Furthermore, this study proposes mathematical models to
demonstrate the probability of ECQV cracking and provides suggestions for
mitigating ECQV cracking risks.
</p>
</div>
</dd>
<dt><a name="item72">[72]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15346" title="Abstract">arXiv:2309.15346</a> [<a href="/pdf/2309.15346" title="Download PDF">pdf</a>, <a href="/ps/2309.15346" title="Download PostScript">ps</a>, <a href="/format/2309.15346" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Efficient implementation of the hybridized Raviart-Thomas mixed method  by converting flux subspaces into stabilizations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Anantharamu%2C+S">Sreevatsa Anantharamu</a>, 
<a href="/search/math?searchtype=author&query=Cockburn%2C+B">Bernardo Cockburn</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">We show how to reduce the computational time of the practical implementation
of the Raviart-Thomas mixed method for second-order elliptic problems. The
implementation takes advantage of a recent result which states that certain
local subspaces of the vector unknown can be eliminated from the equations by
transforming them into stabilization functions; see the paper published online
in JJIAM on August 10, 2023. We describe in detail the new implementation (in
MATLAB and a laptop with Intel(R) Core (TM) i7-8700 processor which has six
cores and hyperthreading) and present numerical results showing 10 to 20%
reduction in the computational time for the Raviart-Thomas method of index $k$,
with $k$ ranging from 1 to 20, applied to a model problem.
</p>
</div>
</dd>
<dt><a name="item73">[73]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15348" title="Abstract">arXiv:2309.15348</a> [<a href="/pdf/2309.15348" title="Download PDF">pdf</a>, <a href="/format/2309.15348" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multi-dimensional Data Quick Query for Blockchain-based Federated  Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+J">Jiaxi Yang</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+S">Sheng Cao</a>, 
<a href="/search/cs?searchtype=author&query=xiangLi%2C+P">Peng xiangLi</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xiong Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xiaosong Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>; Cryptography and Security (cs.CR); Databases (cs.DB)

</div>
<p class="mathjax">Due to the drawbacks of Federated Learning (FL) such as vulnerability of a
single central server, centralized federated learning is shifting to
decentralized federated learning, a paradigm which takes the advantages of
blockchain. A key enabler for adoption of blockchain-based federated learning
is how to select suitable participants to train models collaboratively.
Selecting participants by storing and querying the metadata of data owners on
blockchain could ensure the reliability of selected data owners, which is
helpful to obtain high-quality models in FL. However, querying
multi-dimensional metadata on blockchain needs to traverse every transaction in
each block, making the query time-consuming. An efficient query method for
multi-dimensional metadata in the blockchain for selecting participants in FL
is absent and challenging. In this paper, we propose a novel data structure to
improve the query efficiency within each block named MerkleRB-Tree. In detail,
we leverage Minimal Bounding Rectangle(MBR) and bloom-filters for the query
process of multi-dimensional continuous-valued attributes and discrete-valued
attributes respectively. Furthermore, we migrate the idea of the skip list
along with an MBR and a bloom filter at the head of each block to enhance the
query efficiency for inter-blocks. The performance analysis and extensive
evaluation results on the benchmark dataset demonstrate the superiority of our
method in blockchain-based FL.
</p>
</div>
</dd>
<dt><a name="item74">[74]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15358" title="Abstract">arXiv:2309.15358</a> [<a href="/pdf/2309.15358" title="Download PDF">pdf</a>, <a href="/format/2309.15358" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Foundation Models Learned from Anatomy in Medical Imaging via  Self-Supervision
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Taher%2C+M+R+H">Mohammad Reza Hosseinzadeh Taher</a>, 
<a href="/search/cs?searchtype=author&query=Gotway%2C+M+B">Michael B. Gotway</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+J">Jianming Liang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> International Conference on Medical Image Computing and Computer Assisted Intervention (MICCAI 2023)---Domain Adaptation and Representation Transfer
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Human anatomy is the foundation of medical imaging and boasts one striking
characteristic: its hierarchy in nature, exhibiting two intrinsic properties:
(1) locality: each anatomical structure is morphologically distinct from the
others; and (2) compositionality: each anatomical structure is an integrated
part of a larger whole. We envision a foundation model for medical imaging that
is consciously and purposefully developed upon this foundation to gain the
capability of "understanding" human anatomy and to possess the fundamental
properties of medical imaging. As our first step in realizing this vision
towards foundation models in medical imaging, we devise a novel self-supervised
learning (SSL) strategy that exploits the hierarchical nature of human anatomy.
Our extensive experiments demonstrate that the SSL pretrained model, derived
from our training strategy, not only outperforms state-of-the-art (SOTA)
fully/self-supervised baselines but also enhances annotation efficiency,
offering potential few-shot segmentation capabilities with performance
improvements ranging from 9% to 30% for segmentation tasks compared to SSL
baselines. This performance is attributed to the significance of anatomy
comprehension via our learning strategy, which encapsulates the intrinsic
attributes of anatomical structures-locality and compositionality-within the
embedding space, yet overlooked in existing SSL methods. All code and
pretrained models are available at https://github.com/JLiangLab/Eden.
</p>
</div>
</dd>
<dt><a name="item75">[75]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15363" title="Abstract">arXiv:2309.15363</a> [<a href="/pdf/2309.15363" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LD4MRec: Simplifying and Powering Diffusion Model for Multimedia  Recommendation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yu%2C+P">Penghang Yu</a>, 
<a href="/search/cs?searchtype=author&query=Tan%2C+Z">Zhiyi Tan</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+G">Guanming Lu</a>, 
<a href="/search/cs?searchtype=author&query=Bao%2C+B">Bing-Kun Bao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>

</div>
<p class="mathjax">Multimedia recommendation aims to predict users' future behaviors based on
historical behavioral data and item's multimodal information. However, noise
inherent in behavioral data, arising from unintended user interactions with
uninteresting items, detrimentally impacts recommendation performance.
Recently, diffusion models have achieved high-quality information generation,
in which the reverse process iteratively infers future information based on the
corrupted state. It meets the need of predictive tasks under noisy conditions,
and inspires exploring their application to predicting user behaviors.
Nonetheless, several challenges must be addressed: 1) Classical diffusion
models require excessive computation, which does not meet the efficiency
requirements of recommendation systems. 2) Existing reverse processes are
mainly designed for continuous data, whereas behavioral information is discrete
in nature. Therefore, an effective method is needed for the generation of
discrete behavioral information.
<br />To tackle the aforementioned issues, we propose a Light Diffusion model for
Multimedia Recommendation. First, to reduce computational complexity, we
simplify the formula of the reverse process, enabling one-step inference
instead of multi-step inference. Second, to achieve effective behavioral
information generation, we propose a novel Conditional neural Network. It maps
the discrete behavior data into a continuous latent space, and generates
behaviors with the guidance of collaborative signals and user multimodal
preference. Additionally, considering that completely clean behavior data is
inaccessible, we introduce a soft behavioral reconstruction constraint during
model training, facilitating behavior prediction with noisy data. Empirical
studies conducted on three public datasets demonstrate the effectiveness of
LD4MRec.
</p>
</div>
</dd>
<dt><a name="item76">[76]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15367" title="Abstract">arXiv:2309.15367</a> [<a href="/pdf/2309.15367" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Analysis on Multi-robot Relative 6-DOF Pose Estimation Error Based on  UWB Range
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xinran Li</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+S">Shuaikang Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+P">Pengcheng Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Haifeng Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zhitian Li</a>, 
<a href="/search/cs?searchtype=author&query=Zou%2C+X">Xudong Zou</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, 9 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Systems and Control (eess.SY)

</div>
<p class="mathjax">Relative pose estimation is the foundational requirement for multi-robot
system, while it is a challenging research topic in infrastructure-free scenes.
In this study, we analyze the relative 6-DOF pose estimation error of
multi-robot system in GNSS-denied and anchor-free environment. An analytical
lower bound of position and orientation estimation error is given under the
assumption that distance between the nodes are far more than the size of
robotic platform. Through simulation, impact of distance between nodes,
altitudes and circumradius of tag simplex on pose estimation accuracy is
discussed, which verifies the analysis results. Our analysis is expected to
determine parameters (e.g. deployment of tags) of UWB based multi-robot
systems.
</p>
</div>
</dd>
<dt><a name="item77">[77]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15369" title="Abstract">arXiv:2309.15369</a> [<a href="/pdf/2309.15369" title="Download PDF">pdf</a>, <a href="/format/2309.15369" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Joint Computing, Pushing, and Caching Optimization for Mobile Edge  Computing Networks via Soft Actor-Critic Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gao%2C+X">Xiangyu Gao</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+Y">Yaping Sun</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+H">Hao Chen</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+X">Xiaodong Xu</a>, 
<a href="/search/cs?searchtype=author&query=Cui%2C+S">Shuguang Cui</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages. arXiv admin note: text overlap with <a href="/abs/2305.12099">arXiv:2305.12099</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> IEEE IoT Journal 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>

</div>
<p class="mathjax">Mobile edge computing (MEC) networks bring computing and storage capabilities
closer to edge devices, which reduces latency and improves network performance.
However, to further reduce transmission and computation costs while satisfying
user-perceived quality of experience, a joint optimization in computing,
pushing, and caching is needed. In this paper, we formulate the joint-design
problem in MEC networks as an infinite-horizon discounted-cost Markov decision
process and solve it using a deep reinforcement learning (DRL)-based framework
that enables the dynamic orchestration of computing, pushing, and caching.
Through the deep networks embedded in the DRL structure, our framework can
implicitly predict user future requests and push or cache the appropriate
content to effectively enhance system performance. One issue we encountered
when considering three functions collectively is the curse of dimensionality
for the action space. To address it, we relaxed the discrete action space into
a continuous space and then adopted soft actor-critic learning to solve the
optimization problem, followed by utilizing a vector quantization method to
obtain the desired discrete action. Additionally, an action correction method
was proposed to compress the action space further and accelerate the
convergence. Our simulations under the setting of a general single-user,
single-server MEC network with dynamic transmission link quality demonstrate
that the proposed framework effectively decreases transmission bandwidth and
computing cost by proactively pushing data on future demand to users and
jointly optimizing the three functions. We also conduct extensive parameter
tuning analysis, which shows that our approach outperforms the baselines under
various parameter settings.
</p>
</div>
</dd>
<dt><a name="item78">[78]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15372" title="Abstract">arXiv:2309.15372</a> [<a href="/pdf/2309.15372" title="Download PDF">pdf</a>, <a href="/format/2309.15372" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Seeing Beyond the Patch: Scale-Adaptive Semantic Segmentation of  High-resolution Remote Sensing Imagery based on Reinforcement Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yinhe Liu</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+S">Sunan Shi</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Junjue Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhong%2C+Y">Yanfei Zhong</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">In remote sensing imagery analysis, patch-based methods have limitations in
capturing information beyond the sliding window. This shortcoming poses a
significant challenge in processing complex and variable geo-objects, which
results in semantic inconsistency in segmentation results. To address this
challenge, we propose a dynamic scale perception framework, named GeoAgent,
which adaptively captures appropriate scale context information outside the
image patch based on the different geo-objects. In GeoAgent, each image patch's
states are represented by a global thumbnail and a location mask. The global
thumbnail provides context beyond the patch, and the location mask guides the
perceived spatial relationships. The scale-selection actions are performed
through a Scale Control Agent (SCA). A feature indexing module is proposed to
enhance the ability of the agent to distinguish the current image patch's
location. The action switches the patch scale and context branch of a
dual-branch segmentation network that extracts and fuses the features of
multi-scale patches. The GeoAgent adjusts the network parameters to perform the
appropriate scale-selection action based on the reward received for the
selected scale. The experimental results, using two publicly available datasets
and our newly constructed dataset WUSU, demonstrate that GeoAgent outperforms
previous segmentation methods, particularly for large-scale mapping
applications.
</p>
</div>
</dd>
<dt><a name="item79">[79]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15373" title="Abstract">arXiv:2309.15373</a> [<a href="/pdf/2309.15373" title="Download PDF">pdf</a>, <a href="/format/2309.15373" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Human-robot Matching and Routing for Multi-robot Tour Guiding under Time  Uncertainty
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fu%2C+B">Bo Fu</a>, 
<a href="/search/cs?searchtype=author&query=Kathuria%2C+T">Tribhi Kathuria</a>, 
<a href="/search/cs?searchtype=author&query=Rizzo%2C+D">Denise Rizzo</a>, 
<a href="/search/cs?searchtype=author&query=Castanier%2C+M">Matthew Castanier</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+X+J">X. Jessie Yang</a>, 
<a href="/search/cs?searchtype=author&query=Ghaffari%2C+M">Maani Ghaffari</a>, 
<a href="/search/cs?searchtype=author&query=Barton%2C+K">Kira Barton</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ICRA 2022 Workshop Paper (<a href="https://sites.google.com/view/icra22ws-cor-wotf/accepted-papers">this https URL</a>). arXiv admin note: substantial text overlap with <a href="/abs/2201.10635">arXiv:2201.10635</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Multiagent Systems (cs.MA)

</div>
<p class="mathjax">This work presents a framework for multi-robot tour guidance in a partially
known environment with uncertainty, such as a museum. A simultaneous matching
and routing problem (SMRP) is formulated to match the humans with robot guides
according to their requested places of interest (POIs) and generate the routes
for the robots according to uncertain time estimation. A large neighborhood
search algorithm is developed to efficiently find sub-optimal low-cost
solutions for the SMRP. The scalability and optimality of the multi-robot
planner are evaluated computationally. The largest case tested involves 50
robots, 250 humans, and 50 POIs. A photo-realistic multi-robot simulation was
developed to verify the tour guiding performance in an uncertain indoor
environment.
</p>
</div>
</dd>
<dt><a name="item80">[80]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15375" title="Abstract">arXiv:2309.15375</a> [<a href="/pdf/2309.15375" title="Download PDF">pdf</a>, <a href="/format/2309.15375" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PPG to ECG Signal Translation for Continuous Atrial Fibrillation  Detection via Attention-based Deep State-Space Modeling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Vo%2C+K">Khuong Vo</a>, 
<a href="/search/cs?searchtype=author&query=El-Khamy%2C+M">Mostafa El-Khamy</a>, 
<a href="/search/cs?searchtype=author&query=Choi%2C+Y">Yoojin Choi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">An electrocardiogram (ECG or EKG) is a medical test that measures the heart's
electrical activity. ECGs are often used to diagnose and monitor a wide range
of heart conditions, including arrhythmias, heart attacks, and heart failure.
On the one hand, the conventional ECG requires clinical measurement, which
restricts its deployment to medical facilities. On the other hand, single-lead
ECG has become popular on wearable devices using administered procedures. An
alternative to ECG is Photoplethysmography (PPG), which uses non-invasive,
low-cost optical methods to measure cardiac physiology, making it a suitable
option for capturing vital heart signs in daily life. As a result, it has
become increasingly popular in health monitoring and is used in various
clinical and commercial wearable devices. While ECG and PPG correlate strongly,
the latter does not offer significant clinical diagnostic value. Here, we
propose a subject-independent attention-based deep state-space model to
translate PPG signals to corresponding ECG waveforms. The model is highly
data-efficient by incorporating prior knowledge in terms of probabilistic
graphical models. Notably, the model enables the detection of atrial
fibrillation (AFib), the most common heart rhythm disorder in adults, by
complementing ECG's accuracy with continuous PPG monitoring. We evaluated the
model on 55 subjects from the MIMIC III database. Quantitative and qualitative
experimental results demonstrate the effectiveness and efficiency of our
approach.
</p>
</div>
</dd>
<dt><a name="item81">[81]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15376" title="Abstract">arXiv:2309.15376</a> [<a href="/pdf/2309.15376" title="Download PDF">pdf</a>, <a href="/format/2309.15376" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ADGym: Design Choices for Deep Anomaly Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jiang%2C+M">Minqi Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Hou%2C+C">Chaochuan Hou</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+A">Ao Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+S">Songqiao Han</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+H">Hailiang Huang</a>, 
<a href="/search/cs?searchtype=author&query=Wen%2C+Q">Qingsong Wen</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+X">Xiyang Hu</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Y">Yue Zhao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> NeurIPS 2023. The first three authors contribute equally. Code available at <a href="https://github.com/Minqi824/ADGym">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Deep learning (DL) techniques have recently been applied to anomaly detection
(AD), yielding successful outcomes in areas such as finance, medical services,
and cloud computing. However, much of the current research evaluates a deep AD
algorithm holistically, failing to understand the contributions of individual
design choices like loss functions and network architectures. Consequently, the
importance of prerequisite steps, such as preprocessing, might be overshadowed
by the spotlight on novel loss functions and architectures. In this paper, we
address these oversights by posing two questions: (i) Which components (i.e.,
design choices) of deep AD methods are pivotal in detecting anomalies? (ii) How
can we construct tailored AD algorithms for specific datasets by selecting the
best design choices automatically, rather than relying on generic, pre-existing
solutions? To this end, we introduce ADGym, the first platform designed for
comprehensive evaluation and automatic selection of AD design elements in deep
methods. Extensive experiments reveal that merely adopting existing leading
methods is not ideal. Models crafted using ADGym markedly surpass current
state-of-the-art techniques.
</p>
</div>
</dd>
<dt><a name="item82">[82]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15378" title="Abstract">arXiv:2309.15378</a> [<a href="/pdf/2309.15378" title="Download PDF">pdf</a>, <a href="/format/2309.15378" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Adversarial Object Rearrangement in Constrained Environments with  Heterogeneous Graph Neural Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lou%2C+X">Xibai Lou</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+H">Houjian Yu</a>, 
<a href="/search/cs?searchtype=author&query=Worobel%2C+R">Ross Worobel</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yang Yang</a>, 
<a href="/search/cs?searchtype=author&query=Choi%2C+C">Changhyun Choi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted for publication in IROS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Adversarial object rearrangement in the real world (e.g., previously unseen
or oversized items in kitchens and stores) could benefit from understanding
task scenes, which inherently entail heterogeneous components such as current
objects, goal objects, and environmental constraints. The semantic
relationships among these components are distinct from each other and crucial
for multi-skilled robots to perform efficiently in everyday scenarios. We
propose a hierarchical robotic manipulation system that learns the underlying
relationships and maximizes the collaborative power of its diverse skills
(e.g., pick-place, push) for rearranging adversarial objects in constrained
environments. The high-level coordinator employs a heterogeneous graph neural
network (HetGNN), which reasons about the current objects, goal objects, and
environmental constraints; the low-level 3D Convolutional Neural Network-based
actors execute the action primitives. Our approach is trained entirely in
simulation, and achieved an average success rate of 87.88% and a planning cost
of 12.82 in real-world experiments, surpassing all baseline methods.
Supplementary material is available at
https://sites.google.com/umn.edu/versatile-rearrangement.
</p>
</div>
</dd>
<dt><a name="item83">[83]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15379" title="Abstract">arXiv:2309.15379</a> [<a href="/pdf/2309.15379" title="Download PDF">pdf</a>, <a href="/format/2309.15379" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Content-Driven Micro-Video Recommendation Dataset at Scale
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ni%2C+Y">Yongxin Ni</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+Y">Yu Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xiangyan Liu</a>, 
<a href="/search/cs?searchtype=author&query=Fu%2C+J">Junchen Fu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Youhua Li</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+X">Xiangnan He</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yongfeng Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+F">Fajie Yuan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>

</div>
<p class="mathjax">Micro-videos have recently gained immense popularity, sparking critical
research in micro-video recommendation with significant implications for the
entertainment, advertising, and e-commerce industries. However, the lack of
large-scale public micro-video datasets poses a major challenge for developing
effective recommender systems. To address this challenge, we introduce a very
large micro-video recommendation dataset, named "MicroLens", consisting of one
billion user-item interaction behaviors, 34 million users, and one million
micro-videos. This dataset also contains various raw modality information about
videos, including titles, cover images, audio, and full-length videos.
MicroLens serves as a benchmark for content-driven micro-video recommendation,
enabling researchers to utilize various modalities of video information for
recommendation, rather than relying solely on item IDs or off-the-shelf video
features extracted from a pre-trained network. Our benchmarking of multiple
recommender models and video encoders on MicroLens has yielded valuable
insights into the performance of micro-video recommendation. We believe that
this dataset will not only benefit the recommender system community but also
promote the development of the video understanding field. Our datasets and code
are available at https://github.com/westlake-repl/MicroLens.
</p>
</div>
</dd>
<dt><a name="item84">[84]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15381" title="Abstract">arXiv:2309.15381</a> [<a href="/pdf/2309.15381" title="Download PDF">pdf</a>, <a href="/format/2309.15381" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Subjective Face Transform using Human First Impressions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Roygaga%2C+C">Chaitanya Roygaga</a>, 
<a href="/search/cs?searchtype=author&query=Krinsky%2C+J">Joshua Krinsky</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+K">Kai Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Kwok%2C+K">Kenny Kwok</a>, 
<a href="/search/cs?searchtype=author&query=Bharati%2C+A">Aparna Bharati</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Humans tend to form quick subjective first impressions of non-physical
attributes when seeing someone's face, such as perceived trustworthiness or
attractiveness. To understand what variations in a face lead to different
subjective impressions, this work uses generative models to find semantically
meaningful edits to a face image that change perceived attributes. Unlike prior
work that relied on statistical manipulation in feature space, our end-to-end
framework considers trade-offs between preserving identity and changing
perceptual attributes. It maps identity-preserving latent space directions to
changes in attribute scores, enabling transformation of any input face along an
attribute axis according to a target change. We train on real and synthetic
faces, evaluate for in-domain and out-of-domain images using predictive models
and human ratings, demonstrating the generalizability of our approach.
Ultimately, such a framework can be used to understand and explain biases in
subjective interpretation of faces that are not dependent on the identity.
</p>
</div>
</dd>
<dt><a name="item85">[85]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15383" title="Abstract">arXiv:2309.15383</a> [<a href="/pdf/2309.15383" title="Download PDF">pdf</a>, <a href="/format/2309.15383" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Intelligent trading strategy based on improved directional change and  regime change detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+B">Bing Wu</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+X">Xiangzu Han</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 22 pages, 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Engineering, Finance, and Science (cs.CE)</span>

</div>
<p class="mathjax">Previous research primarily characterized price movements according to time
intervals, resulting in temporal discontinuity and overlooking crucial
activities in financial markets. Directional Change (DC) is an alternative
approach to sampling price data, highlighting significant points while blurring
out noise details in price movements. However, traditional DC treated the
thresholds of upward and downward trends with distinct intrinsic patterns as
equivalent and preset them as fixed values, which are dependent on the
subjective judgment of traders. To enhance the generalization performance of
this methodology, we improved DC by introducing a modified threshold selection
technique. Specifically, we addressed upward and downward trends distinctly by
incorporating a decay coefficient. Further, we simultaneously optimized the
threshold and decay coefficient using the Bayesian Optimization Algorithm
(BOA). Additionally, we recognized the abnormal market state by regime change
detection based on the Hidden Markov Model (RCD-HMM) to reduce the risk. Our
Intelligent Trading Algorithm (ITA) was constructed based on above methods and
the experiments were carried out on tick data from diverse currency pairs in
the forex market. The experimental results showed a significant increase in
profit and reduction in risk of DC-based trading strategies, which demonstrated
the effectiveness of our proposed methods.
</p>
</div>
</dd>
<dt><a name="item86">[86]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15386" title="Abstract">arXiv:2309.15386</a> [<a href="/pdf/2309.15386" title="Download PDF">pdf</a>, <a href="/format/2309.15386" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Neural Stochastic Differential Equations for Robust and Explainable  Analysis of Electromagnetic Unintended Radiated Emissions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jha%2C+S+K">Sumit Kumar Jha</a>, 
<a href="/search/cs?searchtype=author&query=Jha%2C+S">Susmit Jha</a>, 
<a href="/search/cs?searchtype=author&query=Ewetz%2C+R">Rickard Ewetz</a>, 
<a href="/search/cs?searchtype=author&query=Velasquez%2C+A">Alvaro Velasquez</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages, 3 figures, 4 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">We present a comprehensive evaluation of the robustness and explainability of
ResNet-like models in the context of Unintended Radiated Emission (URE)
classification and suggest a new approach leveraging Neural Stochastic
Differential Equations (SDEs) to address identified limitations. We provide an
empirical demonstration of the fragility of ResNet-like models to Gaussian
noise perturbations, where the model performance deteriorates sharply and its
F1-score drops to near insignificance at 0.008 with a Gaussian noise of only
0.5 standard deviation. We also highlight a concerning discrepancy where the
explanations provided by ResNet-like models do not reflect the inherent
periodicity in the input data, a crucial attribute in URE detection from stable
devices. In response to these findings, we propose a novel application of
Neural SDEs to build models for URE classification that are not only robust to
noise but also provide more meaningful and intuitive explanations. Neural SDE
models maintain a high F1-score of 0.93 even when exposed to Gaussian noise
with a standard deviation of 0.5, demonstrating superior resilience to ResNet
models. Neural SDE models successfully recover the time-invariant or periodic
horizontal bands from the input data, a feature that was conspicuously missing
in the explanations generated by ResNet-like models. This advancement presents
a small but significant step in the development of robust and interpretable
models for real-world URE applications where data is inherently noisy and
assurance arguments demand interpretable machine learning predictions.
</p>
</div>
</dd>
<dt><a name="item87">[87]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15390" title="Abstract">arXiv:2309.15390</a> [<a href="/pdf/2309.15390" title="Download PDF">pdf</a>, <a href="/format/2309.15390" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MINS: Efficient and Robust Multisensor-aided Inertial Navigation System
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lee%2C+W">Woosik Lee</a>, 
<a href="/search/cs?searchtype=author&query=Geneva%2C+P">Patrick Geneva</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+C">Chuchu Chen</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+G">Guoquan Huang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 29 pages, 16 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Robust multisensor fusion of multi-modal measurements such as IMUs, wheel
encoders, cameras, LiDARs, and GPS holds great potential due to its innate
ability to improve resilience to sensor failures and measurement outliers,
thereby enabling robust autonomy. To the best of our knowledge, this work is
among the first to develop a consistent tightly-coupled Multisensor-aided
Inertial Navigation System (MINS) that is capable of fusing the most common
navigation sensors in an efficient filtering framework, by addressing the
particular challenges of computational complexity, sensor asynchronicity, and
intra-sensor calibration. In particular, we propose a consistent high-order
on-manifold interpolation scheme to enable efficient asynchronous sensor fusion
and state management strategy (i.e. dynamic cloning). The proposed dynamic
cloning leverages motion-induced information to adaptively select interpolation
orders to control computational complexity while minimizing trajectory
representation errors. We perform online intrinsic and extrinsic
(spatiotemporal) calibration of all onboard sensors to compensate for poor
prior calibration and/or degraded calibration varying over time. Additionally,
we develop an initialization method with only proprioceptive measurements of
IMU and wheel encoders, instead of exteroceptive sensors, which is shown to be
less affected by the environment and more robust in highly dynamic scenarios.
We extensively validate the proposed MINS in simulations and large-scale
challenging real-world datasets, outperforming the existing state-of-the-art
methods, in terms of localization accuracy, consistency, and computation
efficiency. We have also open-sourced our algorithm, simulator, and evaluation
toolbox for the benefit of the community: https://github.com/rpng/mins.
</p>
</div>
</dd>
<dt><a name="item88">[88]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15394" title="Abstract">arXiv:2309.15394</a> [<a href="/pdf/2309.15394" title="Download PDF">pdf</a>, <a href="/format/2309.15394" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> KDD-LOAM: Jointly Learned Keypoint Detector and Descriptors Assisted  LiDAR Odometry and Mapping
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+R">Renlang Huang</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+M">Minglei Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Jiming Chen</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+L">Liang Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Sparse keypoint matching based on distinct 3D feature representations can
improve the efficiency and robustness of point cloud registration. Existing
learning-based 3D descriptors and keypoint detectors are either independent or
loosely coupled, so they cannot fully adapt to each other. In this work, we
propose a tightly coupled keypoint detector and descriptor (TCKDD) based on a
multi-task fully convolutional network with a probabilistic detection loss. In
particular, this self-supervised detection loss fully adapts the keypoint
detector to any jointly learned descriptors and benefits the self-supervised
learning of descriptors. Extensive experiments on both indoor and outdoor
datasets show that our TCKDD achieves state-of-the-art performance in point
cloud registration. Furthermore, we design a keypoint detector and
descriptors-assisted LiDAR odometry and mapping framework (KDD-LOAM), whose
real-time odometry relies on keypoint descriptor matching-based RANSAC. The
sparse keypoints are further used for efficient scan-to-map registration and
mapping. Experiments on KITTI dataset demonstrate that KDD-LOAM significantly
surpasses LOAM and shows competitive performance in odometry.
</p>
</div>
</dd>
<dt><a name="item89">[89]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15395" title="Abstract">arXiv:2309.15395</a> [<a href="/pdf/2309.15395" title="Download PDF">pdf</a>, <a href="/format/2309.15395" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Model-Free, Regret-Optimal Best Policy Identification in Online CMDPs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Z">Zihan Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+H">Honghao Wei</a>, 
<a href="/search/cs?searchtype=author&query=Ying%2C+L">Lei Ying</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">This paper considers the best policy identification (BPI) problem in online
Constrained Markov Decision Processes (CMDPs). We are interested in algorithms
that are model-free, have low regret, and identify an optimal policy with a
high probability. Existing model-free algorithms for online CMDPs with
sublinear regret and constraint violation do not provide any convergence
guarantee to an optimal policy and provide only average performance guarantees
when a policy is uniformly sampled at random from all previously used policies.
In this paper, we develop a new algorithm, named
Pruning-Refinement-Identification (PRI), based on a fundamental structural
property of CMDPs we discover, called limited stochasticity. The property says
for a CMDP with $N$ constraints, there exists an optimal policy with at most
$N$ stochastic decisions.
<br />The proposed algorithm first identifies at which step and in which state a
stochastic decision has to be taken and then fine-tunes the distributions of
these stochastic decisions. PRI achieves trio objectives: (i) PRI is a
model-free algorithm; and (ii) it outputs a near-optimal policy with a high
probability at the end of learning; and (iii) in the tabular setting, PRI
guarantees $\tilde{\mathcal{O}}(\sqrt{K})$ regret and constraint violation,
which significantly improves the best existing regret bound
$\tilde{\mathcal{O}}(K^{\frac{4}{5}})$ under a mode-free algorithm, where $K$
is the total number of episodes.
</p>
</div>
</dd>
<dt><a name="item90">[90]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15402" title="Abstract">arXiv:2309.15402</a> [<a href="/pdf/2309.15402" title="Download PDF">pdf</a>, <a href="/format/2309.15402" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Survey of Chain of Thought Reasoning: Advances, Frontiers and Future
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chu%2C+Z">Zheng Chu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Jingchang Chen</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Q">Qianglong Chen</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+W">Weijiang Yu</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+T">Tao He</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Haotian Wang</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+W">Weihua Peng</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+M">Ming Liu</a>, 
<a href="/search/cs?searchtype=author&query=Qin%2C+B">Bing Qin</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+T">Ting Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Resources are available at <a href="https://github.com/zchuz/CoT-Reasoning-Survey">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Chain-of-thought reasoning, a cognitive process fundamental to human
intelligence, has garnered significant attention in the realm of artificial
intelligence and natural language processing. However, there still remains a
lack of a comprehensive survey for this arena. To this end, we take the first
step and present a thorough survey of this research field carefully and widely.
We use X-of-Thought to refer to Chain-of-Thought in a broad sense. In detail,
we systematically organize the current research according to the taxonomies of
methods, including XoT construction, XoT structure variants, and enhanced XoT.
Additionally, we describe XoT with frontier applications, covering planning,
tool use, and distillation. Furthermore, we address challenges and discuss some
future directions, including faithfulness, multi-modal, and theory. We hope
this survey serves as a valuable resource for researchers seeking to innovate
within the domain of chain-of-thought reasoning.
</p>
</div>
</dd>
<dt><a name="item91">[91]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15405" title="Abstract">arXiv:2309.15405</a> [<a href="/pdf/2309.15405" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Teach and Repeat Navigation: A Robust Control Approach
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nourizadeh%2C+P">Payam Nourizadeh</a>, 
<a href="/search/cs?searchtype=author&query=Milford%2C+M">Michael Milford</a>, 
<a href="/search/cs?searchtype=author&query=Fischer%2C+T">Tobias Fischer</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Systems and Control (eess.SY)

</div>
<p class="mathjax">Robot navigation requires an autonomy pipeline that is robust to
environmental changes and effective in varying conditions. Teach and Repeat
(T&amp;R) navigation has shown high performance in autonomous repeated tasks under
challenging circumstances, but research within T&amp;R has predominantly focused on
motion planning as opposed to motion control. In this paper, we propose a novel
T&amp;R system based on a robust motion control technique for a skid-steering
mobile robot using sliding-mode control that effectively handles uncertainties
that are particularly pronounced in the T&amp;R task, where sensor noises,
parametric uncertainties, and wheel-terrain interaction are common challenges.
We first theoretically demonstrate that the proposed T&amp;R system is globally
stable and robust while considering the uncertainties of the closed-loop
system. When deployed on a Clearpath Jackal robot, we then show the global
stability of the proposed system in both indoor and outdoor environments
covering different terrains, outperforming previous state-of-the-art methods in
terms of mean average trajectory error and stability in these challenging
environments. This paper makes an important step towards long-term autonomous
T&amp;R navigation with ensured safety guarantees.
</p>
</div>
</dd>
<dt><a name="item92">[92]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15406" title="Abstract">arXiv:2309.15406</a> [<a href="/pdf/2309.15406" title="Download PDF">pdf</a>, <a href="/ps/2309.15406" title="Download PostScript">ps</a>, <a href="/format/2309.15406" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SOCI^+: An Enhanced Toolkit for Secure OutsourcedComputation on Integers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhao%2C+B">Bowen Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Deng%2C+W">Weiquan Deng</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xiaoguo Li</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Ximeng Liu</a>, 
<a href="/search/cs?searchtype=author&query=Pei%2C+Q">Qingqi Pei</a>, 
<a href="/search/cs?searchtype=author&query=Deng%2C+R+H">Robert H. Deng</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">Secure outsourced computation is critical for cloud computing to safeguard
data confidentiality and ensure data usability. Recently, secure outsourced
computation schemes following a twin-server architecture based on partially
homomorphic cryptosystems have received increasing attention. The Secure
Outsourced Computation on Integers (SOCI) [1] toolkit is the state-of-the-art
among these schemes which can perform secure computation on integers without
requiring the costly bootstrapping operation as in fully homomorphic
encryption; however, SOCI suffers from relatively large computation and
communication overhead. In this paper, we propose SOCI+ which significantly
improves the performance of SOCI. Specifically, SOCI+ employs a novel (2,
2)-threshold Paillier cryptosystem with fast encryption and decryption as its
cryptographic primitive, and supports a suite of efficient secure arithmetic
computation on integers protocols, including a secure multiplication protocol
(SMUL), a secure comparison protocol (SCMP), a secure sign bit-acquisition
protocol (SSBA), and a secure division protocol (SDIV), all based on the (2,
2)-threshold Paillier cryptosystem with fast encryption and decryption. In
addition, SOCI+ incorporates an offline and online computation mechanism to
further optimize its performance. We perform rigorous theoretical analysis to
prove the correctness and security of SOCI+. Compared with SOCI, our
experimental evaluation shows that SOCI+ is up to 5.4 times more efficient in
computation and 40% less in communication overhead.
</p>
</div>
</dd>
<dt><a name="item93">[93]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15411" title="Abstract">arXiv:2309.15411</a> [<a href="/pdf/2309.15411" title="Download PDF">pdf</a>, <a href="/format/2309.15411" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> 3D Multiple Object Tracking on Autonomous Driving: A Literature Review
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+P">Peng Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xin Li</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+L">Liang He</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+X">Xin Lin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 28 pages, 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">3D multi-object tracking (3D MOT) stands as a pivotal domain within
autonomous driving, experiencing a surge in scholarly interest and commercial
promise over recent years. Despite its paramount significance, 3D MOT confronts
a myriad of formidable challenges, encompassing abrupt alterations in object
appearances, pervasive occlusion, the presence of diminutive targets, data
sparsity, missed detections, and the unpredictable initiation and termination
of object motion trajectories. Countless methodologies have emerged to grapple
with these issues, yet 3D MOT endures as a formidable problem that warrants
further exploration. This paper undertakes a comprehensive examination,
assessment, and synthesis of the research landscape in this domain, remaining
attuned to the latest developments in 3D MOT while suggesting prospective
avenues for future investigation. Our exploration commences with a systematic
exposition of key facets of 3D MOT and its associated domains, including
problem delineation, classification, methodological approaches, fundamental
principles, and empirical investigations. Subsequently, we categorize these
methodologies into distinct groups, dissecting each group meticulously with
regard to its challenges, underlying rationale, progress, merits, and demerits.
Furthermore, we present a concise recapitulation of experimental metrics and
offer an overview of prevalent datasets, facilitating a quantitative comparison
for a more intuitive assessment. Lastly, our deliberations culminate in a
discussion of the prevailing research landscape, highlighting extant challenges
and charting possible directions for 3D MOT research. We present a structured
and lucid road-map to guide forthcoming endeavors in this field.
</p>
</div>
</dd>
<dt><a name="item94">[94]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15413" title="Abstract">arXiv:2309.15413</a> [<a href="/pdf/2309.15413" title="Download PDF">pdf</a>, <a href="/format/2309.15413" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Inherit with Distillation and Evolve with Contrast: Exploring Class  Incremental Semantic Segmentation Without Exemplar Memory
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhao%2C+D">Danpei Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+B">Bo Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+Z">Zhenwei Shi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">As a front-burner problem in incremental learning, class incremental semantic
segmentation (CISS) is plagued by catastrophic forgetting and semantic drift.
Although recent methods have utilized knowledge distillation to transfer
knowledge from the old model, they are still unable to avoid pixel confusion,
which results in severe misclassification after incremental steps due to the
lack of annotations for past and future classes. Meanwhile data-replay-based
approaches suffer from storage burdens and privacy concerns. In this paper, we
propose to address CISS without exemplar memory and resolve catastrophic
forgetting as well as semantic drift synchronously. We present Inherit with
Distillation and Evolve with Contrast (IDEC), which consists of a Dense
Knowledge Distillation on all Aspects (DADA) manner and an Asymmetric
Region-wise Contrastive Learning (ARCL) module. Driven by the devised dynamic
class-specific pseudo-labelling strategy, DADA distils intermediate-layer
features and output-logits collaboratively with more emphasis on
semantic-invariant knowledge inheritance. ARCL implements region-wise
contrastive learning in the latent space to resolve semantic drift among known
classes, current classes, and unknown classes. We demonstrate the effectiveness
of our method on multiple CISS tasks by state-of-the-art performance, including
Pascal VOC 2012, ADE20K and ISPRS datasets. Our method also shows superior
anti-forgetting ability, particularly in multi-step CISS tasks.
</p>
</div>
</dd>
<dt><a name="item95">[95]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15414" title="Abstract">arXiv:2309.15414</a> [<a href="/pdf/2309.15414" title="Download PDF">pdf</a>, <a href="/format/2309.15414" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Competitive Auctions with Imperfect Predictions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lu%2C+P">Pinyan Lu</a>, 
<a href="/search/cs?searchtype=author&query=Wan%2C+Z">Zongqi Wan</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jialin Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 30 pages, 2 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>

</div>
<p class="mathjax">The competitive auction was first proposed by Goldberg, Hartline, and Wright.
In their paper, they introduce the competitive analysis framework of online
algorithm designing into the traditional revenue-maximizing auction design
problem. While the competitive analysis framework only cares about the
worst-case bound, a growing body of work in the online algorithm community
studies the learning-augmented framework. In this framework, designers are
allowed to leverage imperfect machine-learned predictions of unknown
information and pursue better theoretical guarantees when the prediction is
accurate(consistency). Meanwhile, designers also need to maintain a
nearly-optimal worst-case ratio(robustness).
<br />In this work, we revisit the competitive auctions in the learning-augmented
setting. We leverage the imperfect predictions of the private value of the
bidders and design the learning-augmented mechanisms for several competitive
auctions with different constraints, including digital good auctions,
limited-supply auctions, and general downward-closed permutation environments.
For all these auction environments, our mechanisms enjoy $1$-consistency
against the strongest benchmark $OPT$, which is impossible to achieve
$O(1)$-competitive without predictions. At the same time, our mechanisms also
maintain the $O(1)$-robustness against all benchmarks considered in the
traditional competitive analysis. Considering the possible inaccuracy of the
predictions, we provide a reduction that transforms our learning-augmented
mechanisms into an error-tolerant version, which enables the learning-augmented
mechanism to ensure satisfactory revenue in scenarios where the prediction
error is moderate.
</p>
</div>
</dd>
<dt><a name="item96">[96]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15416" title="Abstract">arXiv:2309.15416</a> [<a href="/pdf/2309.15416" title="Download PDF">pdf</a>, <a href="/ps/2309.15416" title="Download PostScript">ps</a>, <a href="/format/2309.15416" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Design and Implementation of an Extensible System Meta-Programming  Language
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Salgado%2C+R">Ronie Salgado</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Programming Languages (cs.PL)</span>; Software Engineering (cs.SE)

</div>
<p class="mathjax">System programming languages are typically compiled in a linear pipeline
process, which is a completely opaque and isolated to end-users. This limits
the possibilities of performing meta-programming in the same language and
environment, and the extensibility of the compiler itself by end-users. We
propose a novel redefinition of the compilation process in terms of
interpreting the program definition as a script. This evaluation is performed
in an environment where the full compilation pipeline is implemented and
exposed to the user via a meta-object protocol, which forms the basis for a
meta-circular definition and implementation of the programming language itself.
We demonstrate the feasibility of this approach by bootstrapping a
self-compiling implementation of Sysmel, a static and dynamic typed Smalltalk
and C++ inspired programming language.
</p>
</div>
</dd>
<dt><a name="item97">[97]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15417" title="Abstract">arXiv:2309.15417</a> [<a href="/pdf/2309.15417" title="Download PDF">pdf</a>, <a href="/format/2309.15417" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Parallel local time stepping for rigid bodies represented by  triangulated meshes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Noble%2C+P">Peter Noble</a>, 
<a href="/search/cs?searchtype=author&query=Weinzierl%2C+T">Tobias Weinzierl</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Mathematical Software (cs.MS)</span>

</div>
<p class="mathjax">Discrete Element Methods (DEM), i.e.~the simulation of many rigid particles,
suffer from very stiff differential equations plus multiscale challenges in
space and time. The particles move smoothly through space until they interact
almost instantaneously due to collisions. Dense particle packings hence require
tiny time step sizes, while free particles can advance with large time steps.
Admissible time step sizes can span multiple orders of magnitudes. We propose
an adaptive local time stepping algorithm which identifies clusters of
particles that can be updated independently, advances them optimistically and
independently in time, determines collision time stamps in space-time such that
we maximise the time step sizes used, and resolves the momentum exchange
implicitly. It is combined with various acceleration techniques which exploit
multiscale geometry representations and multiscale behaviour in time. The
collision time stamp detection in space-time in combination with the implicit
solve of the actual collision equations avoids that particles get locked into
tiny time step sizes, the clustering yields a high concurrency level, and the
acceleration techniques plus local time stepping avoid unnecessary
computations. This brings a scaling, adaptive time stepping for DEM for
real-world challenges into reach.
</p>
</div>
</dd>
<dt><a name="item98">[98]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15418" title="Abstract">arXiv:2309.15418</a> [<a href="/pdf/2309.15418" title="Download PDF">pdf</a>, <a href="/format/2309.15418" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Automatic Feature Fairness in Recommendation via Adversaries
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hu%2C+H">Hengchang Hu</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+Y">Yiming Cao</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+Z">Zhankui He</a>, 
<a href="/search/cs?searchtype=author&query=Tan%2C+S">Samson Tan</a>, 
<a href="/search/cs?searchtype=author&query=Kan%2C+M">Min-Yen Kan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> SIGIR-AP'23
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Fairness is a widely discussed topic in recommender systems, but its
practical implementation faces challenges in defining sensitive features while
maintaining recommendation accuracy. We propose feature fairness as the
foundation to achieve equitable treatment across diverse groups defined by
various feature combinations. This improves overall accuracy through balanced
feature generalizability. We introduce unbiased feature learning through
adversarial training, using adversarial perturbation to enhance feature
representation. The adversaries improve model generalization for
under-represented features. We adapt adversaries automatically based on two
forms of feature biases: frequency and combination variety of feature values.
This allows us to dynamically adjust perturbation strengths and adversarial
training weights. Stronger perturbations are applied to feature values with
fewer combination varieties to improve generalization, while higher weights for
low-frequency features address training imbalances. We leverage the Adaptive
Adversarial perturbation based on the widely-applied Factorization Machine
(AAFM) as our backbone model. In experiments, AAFM surpasses strong baselines
in both fairness and accuracy measures. AAFM excels in providing item- and
user-fairness for single- and multi-feature tasks, showcasing their versatility
and scalability. To maintain good accuracy, we find that adversarial
perturbation must be well-managed: during training, perturbations should not
overly persist and their strengths should decay.
</p>
</div>
</dd>
<dt><a name="item99">[99]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15419" title="Abstract">arXiv:2309.15419</a> [<a href="/pdf/2309.15419" title="Download PDF">pdf</a>, <a href="/format/2309.15419" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Hypergraph $p$-Laplacians, Scale Spaces, and Information Flow in  Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fazeny%2C+A">Ariane Fazeny</a>, 
<a href="/search/cs?searchtype=author&query=Tenbrinck%2C+D">Daniel Tenbrinck</a>, 
<a href="/search/cs?searchtype=author&query=Burger%2C+M">Martin Burger</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, 4 figures, published in International Conference on Scale Space and Variational Methods in Computer Vision proceedings
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> In: Scale Space and Variational Methods in Computer Vision. SSVM
  2023. Lecture Notes in Computer Science, vol 14009. Springer, Cham (2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>; Combinatorics (math.CO)

</div>
<p class="mathjax">This paper models opinion formation in social networks using oriented
hypergraphs and it defines gradient flows in the form of diffusion equations on
oriented hypergraphs. Therefore, this paper uses the gradient, adjoint and
$p$-Laplacian definitions for oriented hypergraphs, introduced in
<a href="/abs/2304.06468">arXiv:2304.06468v1</a>, and applies them to modelling group dynamics and
information flow in social networks.
</p>
</div>
</dd>
<dt><a name="item100">[100]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15420" title="Abstract">arXiv:2309.15420</a> [<a href="/pdf/2309.15420" title="Download PDF">pdf</a>, <a href="/format/2309.15420" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Triad of Failure Modes and a Possible Way Out
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sansone%2C+E">Emanuele Sansone</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: substantial text overlap with <a href="/abs/2304.11357">arXiv:2304.11357</a>, <a href="/abs/2212.13425">arXiv:2212.13425</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">We present a novel objective function for cluster-based self-supervised
learning (SSL) that is designed to circumvent the triad of failure modes,
namely representation collapse, cluster collapse, and the problem of invariance
to permutations of cluster assignments. This objective consists of three key
components: (i) A generative term that penalizes representation collapse, (ii)
a term that promotes invariance to data augmentations, thereby addressing the
issue of label permutations and (ii) a uniformity term that penalizes cluster
collapse. Additionally, our proposed objective possesses two notable
advantages. Firstly, it can be interpreted from a Bayesian perspective as a
lower bound on the data log-likelihood. Secondly, it enables the training of a
standard backbone architecture without the need for asymmetric elements like
stop gradients, momentum encoders, or specialized clustering layers. Due to its
simplicity and theoretical foundation, our proposed objective is well-suited
for optimization. Experiments on both toy and real world data demonstrate its
effectiveness
</p>
</div>
</dd>
<dt><a name="item101">[101]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15421" title="Abstract">arXiv:2309.15421</a> [<a href="/pdf/2309.15421" title="Download PDF">pdf</a>, <a href="/format/2309.15421" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deep Learning in Deterministic Computational Mechanics
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Herrmann%2C+L">Leon Herrmann</a>, 
<a href="/search/cs?searchtype=author&query=Kollmannsberger%2C+S">Stefan Kollmannsberger</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">The rapid growth of deep learning research, including within the field of
computational mechanics, has resulted in an extensive and diverse body of
literature. To help researchers identify key concepts and promising
methodologies within this field, we provide an overview of deep learning in
deterministic computational mechanics. Five main categories are identified and
explored: simulation substitution, simulation enhancement, discretizations as
neural networks, generative approaches, and deep reinforcement learning. This
review focuses on deep learning methods rather than applications for
computational mechanics, thereby enabling researchers to explore this field
more effectively. As such, the review is not necessarily aimed at researchers
with extensive knowledge of deep learning -- instead, the primary audience is
researchers at the verge of entering this field or those who attempt to gain an
overview of deep learning in computational mechanics. The discussed concepts
are, therefore, explained as simple as possible.
</p>
</div>
</dd>
<dt><a name="item102">[102]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15422" title="Abstract">arXiv:2309.15422</a> [<a href="/pdf/2309.15422" title="Download PDF">pdf</a>, <a href="/ps/2309.15422" title="Download PostScript">ps</a>, <a href="/format/2309.15422" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Computing Permanents and Counting Hamiltonian Cycles Faster
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+B">Baitian Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>

</div>
<p class="mathjax">We show that the permanent of an $n\times n$ matrix of
$\operatorname{poly}(n)$-bit integers and the number of Hamiltonian cycles of
an $n$-vertex graph can both be computed in time $2^{n-\Omega(\sqrt{n})}$,
improving an earlier algorithm of Bj\"orklund, Kaski, and Williams
(Algorithmica 2019) that runs in time $2^{n - \Omega\left(\sqrt{n/\log \log
n}\right)}$.
<br />A key tool of our approach is to design a data structure that supports fast
"$r$-order evaluation" of permanent and Hamiltonian cycles, which cooperates
with the new approach on multivariate multipoint evaluation by Bhargava, Ghosh,
Guo, Kumar, and Umans (FOCS 2022).
</p>
</div>
</dd>
<dt><a name="item103">[103]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15423" title="Abstract">arXiv:2309.15423</a> [<a href="/pdf/2309.15423" title="Download PDF">pdf</a>, <a href="/format/2309.15423" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Prosumers Participation in Markets: A Scalar-Parameterized Function  Bidding Approach
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Alawad%2C+A">Abdullah Alawad</a>, 
<a href="/search/cs?searchtype=author&query=Zaman%2C+M+A+u">Muhammad Aneeq uz Zaman</a>, 
<a href="/search/cs?searchtype=author&query=Alshehri%2C+K">Khaled Alshehri</a>, 
<a href="/search/cs?searchtype=author&query=Ba%C5%9Far%2C+T">Tamer Ba&#x15f;ar</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>; Systems and Control (eess.SY)

</div>
<p class="mathjax">In uniform-price markets, suppliers compete to supply a resource to
consumers, resulting in a single market price determined by their competition.
For sufficient flexibility, producers and consumers prefer to commit to a
function as their strategies, indicating their preferred quantity at any given
market price. Producers and consumers may wish to act as both, i.e., prosumers.
In this paper, we examine the behavior of profit-maximizing prosumers in a
uniform-price market for resource allocation with the objective of maximizing
the social welfare. We propose a scalar-parameterized function bidding
mechanism for the prosumers, in which we establish the existence and uniqueness
of Nash equilibrium. Furthermore, we provide an efficient way to compute the
Nash equilibrium through the computation of the market allocation at the Nash
equilibrium. Finally, we present a case study to illustrate the welfare loss
under different variations of market parameters, such as the market's supply
capacity and inelastic demand.
</p>
</div>
</dd>
<dt><a name="item104">[104]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15426" title="Abstract">arXiv:2309.15426</a> [<a href="/pdf/2309.15426" title="Download PDF">pdf</a>, <a href="/format/2309.15426" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> NeuRBF: A Neural Fields Representation with Adaptive Radial Basis  Functions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+Z">Zhang Chen</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zhong Li</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+L">Liangchen Song</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+L">Lele Chen</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+J">Jingyi Yu</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+J">Junsong Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+Y">Yi Xu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to ICCV 2023 Oral. Project page: <a href="https://oppo-us-research.github.io/NeuRBF-website/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Graphics (cs.GR); Machine Learning (cs.LG)

</div>
<p class="mathjax">We present a novel type of neural fields that uses general radial bases for
signal representation. State-of-the-art neural fields typically rely on
grid-based representations for storing local neural features and N-dimensional
linear kernels for interpolating features at continuous query points. The
spatial positions of their neural features are fixed on grid nodes and cannot
well adapt to target signals. Our method instead builds upon general radial
bases with flexible kernel position and shape, which have higher spatial
adaptivity and can more closely fit target signals. To further improve the
channel-wise capacity of radial basis functions, we propose to compose them
with multi-frequency sinusoid functions. This technique extends a radial basis
to multiple Fourier radial bases of different frequency bands without requiring
extra parameters, facilitating the representation of details. Moreover, by
marrying adaptive radial bases with grid-based ones, our hybrid combination
inherits both adaptivity and interpolation smoothness. We carefully designed
weighting schemes to let radial bases adapt to different types of signals
effectively. Our experiments on 2D image and 3D signed distance field
representation demonstrate the higher accuracy and compactness of our method
than prior arts. When applied to neural radiance field reconstruction, our
method achieves state-of-the-art rendering quality, with small model size and
comparable training speed.
</p>
</div>
</dd>
<dt><a name="item105">[105]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15427" title="Abstract">arXiv:2309.15427</a> [<a href="/pdf/2309.15427" title="Download PDF">pdf</a>, <a href="/format/2309.15427" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Graph Neural Prompting with Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tian%2C+Y">Yijun Tian</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+H">Huan Song</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zichen Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Haozhu Wang</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+Z">Ziqing Hu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+F">Fang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Chawla%2C+N+V">Nitesh V. Chawla</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+P">Panpan Xu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Large Language Models (LLMs) have shown remarkable generalization capability
with exceptional performance in various language modeling tasks. However, they
still exhibit inherent limitations in precisely capturing and returning
grounded knowledge. While existing work has explored utilizing knowledge graphs
to enhance language modeling via joint training and customized model
architectures, applying this to LLMs is problematic owing to their large number
of parameters and high computational cost. In addition, how to leverage the
pre-trained LLMs and avoid training a customized model from scratch remains an
open question. In this work, we propose Graph Neural Prompting (GNP), a novel
plug-and-play method to assist pre-trained LLMs in learning beneficial
knowledge from KGs. GNP encompasses various designs, including a standard graph
neural network encoder, a cross-modality pooling module, a domain projector,
and a self-supervised link prediction objective. Extensive experiments on
multiple datasets demonstrate the superiority of GNP on both commonsense and
biomedical reasoning tasks across different LLM sizes and settings.
</p>
</div>
</dd>
<dt><a name="item106">[106]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15430" title="Abstract">arXiv:2309.15430</a> [<a href="/pdf/2309.15430" title="Download PDF">pdf</a>, <a href="/format/2309.15430" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Evaluation of Constrained Reinforcement Learning Algorithms for Legged  Locomotion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lee%2C+J">Joonho Lee</a>, 
<a href="/search/cs?searchtype=author&query=Schroth%2C+L">Lukas Schroth</a>, 
<a href="/search/cs?searchtype=author&query=Klemm%2C+V">Victor Klemm</a>, 
<a href="/search/cs?searchtype=author&query=Bjelonic%2C+M">Marko Bjelonic</a>, 
<a href="/search/cs?searchtype=author&query=Reske%2C+A">Alexander Reske</a>, 
<a href="/search/cs?searchtype=author&query=Hutter%2C+M">Marco Hutter</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Systems and Control (eess.SY)

</div>
<p class="mathjax">Shifting from traditional control strategies to Deep Reinforcement Learning
(RL) for legged robots poses inherent challenges, especially when addressing
real-world physical constraints during training. While high-fidelity
simulations provide significant benefits, they often bypass these essential
physical limitations. In this paper, we experiment with the Constrained Markov
Decision Process (CMDP) framework instead of the conventional unconstrained RL
for robotic applications. We perform a comparative study of different
constrained policy optimization algorithms to identify suitable methods for
practical implementation. Our robot experiments demonstrate the critical role
of incorporating physical constraints, yielding successful sim-to-real
transfers, and reducing operational errors on physical systems. The CMDP
formulation streamlines the training process by separately handling constraints
from rewards. Our findings underscore the potential of constrained RL for the
effective development and deployment of learned controllers in robotics.
</p>
</div>
</dd>
<dt><a name="item107">[107]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15431" title="Abstract">arXiv:2309.15431</a> [<a href="/pdf/2309.15431" title="Download PDF">pdf</a>, <a href="/format/2309.15431" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Local Compressed Video Stream Learning for Generic Event Boundary  Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+L">Libo Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Gu%2C+X">Xin Gu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+C">Congcong Li</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+T">Tiejian Luo</a>, 
<a href="/search/cs?searchtype=author&query=Fan%2C+H">Heng Fan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by IJCV. arXiv admin note: substantial text overlap with <a href="/abs/2203.15336">arXiv:2203.15336</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Generic event boundary detection aims to localize the generic, taxonomy-free
event boundaries that segment videos into chunks. Existing methods typically
require video frames to be decoded before feeding into the network, which
contains significant spatio-temporal redundancy and demands considerable
computational power and storage space. To remedy these issues, we propose a
novel compressed video representation learning method for event boundary
detection that is fully end-to-end leveraging rich information in the
compressed domain, i.e., RGB, motion vectors, residuals, and the internal group
of pictures (GOP) structure, without fully decoding the video. Specifically, we
use lightweight ConvNets to extract features of the P-frames in the GOPs and
spatial-channel attention module (SCAM) is designed to refine the feature
representations of the P-frames based on the compressed information with
bidirectional information flow. To learn a suitable representation for boundary
detection, we construct the local frames bag for each candidate frame and use
the long short-term memory (LSTM) module to capture temporal relationships. We
then compute frame differences with group similarities in the temporal domain.
This module is only applied within a local window, which is critical for event
boundary detection. Finally a simple classifier is used to determine the event
boundaries of video sequences based on the learned feature representation. To
remedy the ambiguities of annotations and speed up the training process, we use
the Gaussian kernel to preprocess the ground-truth event boundaries. Extensive
experiments conducted on the Kinetics-GEBD and TAPOS datasets demonstrate that
the proposed method achieves considerable improvements compared to previous
end-to-end approach while running at the same speed. The code is available at
https://github.com/GX77/LCVSL.
</p>
</div>
</dd>
<dt><a name="item108">[108]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15432" title="Abstract">arXiv:2309.15432</a> [<a href="/pdf/2309.15432" title="Download PDF">pdf</a>, <a href="/format/2309.15432" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ComPile: A Large IR Dataset from Production Sources
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Grossman%2C+A">Aiden Grossman</a>, 
<a href="/search/cs?searchtype=author&query=Paehler%2C+L">Ludger Paehler</a>, 
<a href="/search/cs?searchtype=author&query=Parasyris%2C+K">Konstantinos Parasyris</a>, 
<a href="/search/cs?searchtype=author&query=Ben-Nun%2C+T">Tal Ben-Nun</a>, 
<a href="/search/cs?searchtype=author&query=Hegna%2C+J">Jacob Hegna</a>, 
<a href="/search/cs?searchtype=author&query=Moses%2C+W">William Moses</a>, 
<a href="/search/cs?searchtype=author&query=Diaz%2C+J+M+M">Jose M Monsalve Diaz</a>, 
<a href="/search/cs?searchtype=author&query=Trofin%2C+M">Mircea Trofin</a>, 
<a href="/search/cs?searchtype=author&query=Doerfert%2C+J">Johannes Doerfert</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Programming Languages (cs.PL)</span>

</div>
<p class="mathjax">Code is increasingly becoming a core data modality of modern machine learning
research impacting not only the way we write code with conversational agents
like OpenAI's ChatGPT, Google's Bard, or Anthropic's Claude, the way we
translate code from one language into another, but also the compiler
infrastructure underlying the language. While modeling approaches may vary and
representations differ, the targeted tasks often remain the same within the
individual classes of models. Relying solely on the ability of modern models to
extract information from unstructured code does not take advantage of 70 years
of programming language and compiler development by not utilizing the structure
inherent to programs in the data collection. This detracts from the performance
of models working over a tokenized representation of input code and precludes
the use of these models in the compiler itself. To work towards the first
intermediate representation (IR) based models, we fully utilize the LLVM
compiler infrastructure, shared by a number of languages, to generate a 182B
token dataset of LLVM IR. We generated this dataset from programming languages
built on the shared LLVM infrastructure, including Rust, Swift, Julia, and
C/C++, by hooking into LLVM code generation either through the language's
package manager or the compiler directly to extract the dataset of intermediate
representations from production grade programs. Statistical analysis proves the
utility of our dataset not only for large language model training, but also for
the introspection into the code generation process itself with the dataset
showing great promise for machine-learned compiler components.
</p>
</div>
</dd>
<dt><a name="item109">[109]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15433" title="Abstract">arXiv:2309.15433</a> [<a href="/pdf/2309.15433" title="Download PDF">pdf</a>, <a href="/format/2309.15433" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Cardinality Estimation of Subgraph Matching: A Filtering-Sampling  Approach
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shin%2C+W">Wonseok Shin</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+S">Siwoo Song</a>, 
<a href="/search/cs?searchtype=author&query=Park%2C+K">Kunsoo Park</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+W">Wook-Shin Han</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Databases (cs.DB)</span>

</div>
<p class="mathjax">Subgraph counting is a fundamental problem in understanding and analyzing
graph structured data, yet computationally challenging. This calls for an
accurate and efficient algorithm for Subgraph Cardinality Estimation, which is
to estimate the number of all isomorphic embeddings of a query graph in a data
graph. We present FaSTest, a novel algorithm that combines (1) a powerful
filtering technique to significantly reduce the sample space, (2) an adaptive
tree sampling algorithm for accurate and efficient estimation, and (3) a
worst-case optimal stratified graph sampling algorithm for difficult instances.
Extensive experiments on real-world datasets show that FaSTest outperforms
state-of-the-art sampling-based methods by up to two orders of magnitude and
GNN-based methods by up to three orders of magnitude in terms of accuracy.
</p>
</div>
</dd>
<dt><a name="item110">[110]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15435" title="Abstract">arXiv:2309.15435</a> [<a href="/pdf/2309.15435" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Semantics-Driven Cloud-Edge Collaborative Inference
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gao%2C+Y">Yuche Gao</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+B">Beibei Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages, 7 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">With the proliferation of video data in smart city applications like
intelligent transportation, efficient video analytics has become crucial but
also challenging. This paper proposes a semantics-driven cloud-edge
collaborative approach for accelerating video inference, using license plate
recognition as a case study. The method separates semantics extraction and
recognition, allowing edge servers to only extract visual semantics (license
plate patches) from video frames and offload computation-intensive recognition
to the cloud or neighboring edges based on load. This segmented processing
coupled with a load-aware work distribution strategy aims to reduce end-to-end
latency and improve throughput. Experiments demonstrate significant
improvements in end-to-end inference speed (up to 5x faster), throughput (up to
9 FPS), and reduced traffic volumes (50% less) compared to cloud-only or
edge-only processing, validating the efficiency of the proposed approach. The
cloud-edge collaborative framework with semantics-driven work partitioning
provides a promising solution for scaling video analytics in smart cities.
</p>
</div>
</dd>
<dt><a name="item111">[111]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15442" title="Abstract">arXiv:2309.15442</a> [<a href="/pdf/2309.15442" title="Download PDF">pdf</a>, <a href="/format/2309.15442" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Template Model Inspired Task Space Learning for Robust Bipedal  Locomotion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Castillo%2C+G+A">Guillermo A. Castillo</a>, 
<a href="/search/cs?searchtype=author&query=Weng%2C+B">Bowen Weng</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+S">Shunpeng Yang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+W">Wei Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Hereid%2C+A">Ayonga Hereid</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at 2023 International Conference on Intelligent Robots and Systems (IROS). Supplemental Video: <a href="https://youtu.be/YTjMgGka4Ig">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">This work presents a hierarchical framework for bipedal locomotion that
combines a Reinforcement Learning (RL)-based high-level (HL) planner policy for
the online generation of task space commands with a model-based low-level (LL)
controller to track the desired task space trajectories. Different from
traditional end-to-end learning approaches, our HL policy takes insights from
the angular momentum-based linear inverted pendulum (ALIP) to carefully design
the observation and action spaces of the Markov Decision Process (MDP). This
simple yet effective design creates an insightful mapping between a
low-dimensional state that effectively captures the complex dynamics of bipedal
locomotion and a set of task space outputs that shape the walking gait of the
robot. The HL policy is agnostic to the task space LL controller, which
increases the flexibility of the design and generalization of the framework to
other bipedal robots. This hierarchical design results in a learning-based
framework with improved performance, data efficiency, and robustness compared
with the ALIP model-based approach and state-of-the-art learning-based
frameworks for bipedal locomotion. The proposed hierarchical controller is
tested in three different robots, Rabbit, a five-link underactuated planar
biped; Walker2D, a seven-link fully-actuated planar biped; and Digit, a 3D
humanoid robot with 20 actuated joints. The trained policy naturally learns
human-like locomotion behaviors and is able to effectively track a wide range
of walking speeds while preserving the robustness and stability of the walking
gait even under adversarial conditions.
</p>
</div>
</dd>
<dt><a name="item112">[112]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15454" title="Abstract">arXiv:2309.15454</a> [<a href="/pdf/2309.15454" title="Download PDF">pdf</a>, <a href="/format/2309.15454" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The $st$-Planar Edge Completion Problem is Fixed-Parameter Tractable
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Khazaliya%2C+L">Liana Khazaliya</a>, 
<a href="/search/cs?searchtype=author&query=Kindermann%2C+P">Philipp Kindermann</a>, 
<a href="/search/cs?searchtype=author&query=Liotta%2C+G">Giuseppe Liotta</a>, 
<a href="/search/cs?searchtype=author&query=Montecchiani%2C+F">Fabrizio Montecchiani</a>, 
<a href="/search/cs?searchtype=author&query=Simonov%2C+K">Kirill Simonov</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>; Computational Geometry (cs.CG)

</div>
<p class="mathjax">The problem of deciding whether a biconnected planar digraph $G=(V,E)$ can be
augmented to become an $st$-planar graph by adding a set of oriented edges $E'
\subseteq V \times V$ is known to be NP-complete. We show that the problem is
fixed-parameter tractable when parameterized by the size of the set $E'$.
</p>
</div>
</dd>
<dt><a name="item113">[113]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15455" title="Abstract">arXiv:2309.15455</a> [<a href="/pdf/2309.15455" title="Download PDF">pdf</a>, <a href="/format/2309.15455" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> In-Hand Re-grasp Manipulation with Passive Dynamic Actions via Imitation  Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wei%2C+D">Dehao Wei</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+G">Guokang Sun</a>, 
<a href="/search/cs?searchtype=author&query=Ren%2C+Z">Zeyu Ren</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+S">Shuang Li</a>, 
<a href="/search/cs?searchtype=author&query=Shao%2C+Z">Zhufeng Shao</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xiang Li</a>, 
<a href="/search/cs?searchtype=author&query=Tsagarakis%2C+N">Nikos Tsagarakis</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+S">Shaohua Ma</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: text overlap with <a href="/abs/2110.00336">arXiv:2110.00336</a> by other authors
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Re-grasp manipulation leverages on ergonomic tools to assist humans in
accomplishing diverse tasks. In certain scenarios, humans often employ external
forces to effortlessly and precisely re-grasp tools like a hammer. Previous
development on controllers for in-grasp sliding motion using passive dynamic
actions (e.g.,gravity) relies on apprehension of finger-object contact
information, and requires customized design for individual objects with varied
geometry and weight distribution. It limits their adaptability to diverse
objects. In this paper, we propose an end-to-end sliding motion controller
based on imitation learning (IL) that necessitates minimal prior knowledge of
object mechanics, relying solely on object position information. To expedite
training convergence, we utilize a data glove to collect expert data
trajectories and train the policy through Generative Adversarial Imitation
Learning (GAIL). Simulation results demonstrate the controller's versatility in
performing in-hand sliding tasks with objects of varying friction coefficients,
geometric shapes, and masses. By migrating to a physical system using visual
position estimation, the controller demonstrated an average success rate of
86%, surpassing the baseline algorithm's success rate of 35% of Behavior
Cloning(BC) and 20% of Proximal Policy Optimization (PPO).
</p>
</div>
</dd>
<dt><a name="item114">[114]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15458" title="Abstract">arXiv:2309.15458</a> [<a href="/pdf/2309.15458" title="Download PDF">pdf</a>, <a href="/format/2309.15458" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LogicMP: A Neuro-symbolic Approach for Encoding First-order Logic  Constraints
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+W">Weidi Xu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jingwei Wang</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+L">Lele Xie</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+J">Jianshan He</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+H">Hongting Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+T">Taifeng Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wan%2C+X">Xiaopei Wan</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Jingdong Chen</a>, 
<a href="/search/cs?searchtype=author&query=Qu%2C+C">Chao Qu</a>, 
<a href="/search/cs?searchtype=author&query=Chu%2C+W">Wei Chu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 28 pages, 14 figures, 12 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Symbolic Computation (cs.SC)

</div>
<p class="mathjax">Integrating first-order logic constraints (FOLCs) with neural networks is a
crucial but challenging problem since it involves modeling intricate
correlations to satisfy the constraints. This paper proposes a novel neural
layer, LogicMP, whose layers perform mean-field variational inference over an
MLN. It can be plugged into any off-the-shelf neural network to encode FOLCs
while retaining modularity and efficiency. By exploiting the structure and
symmetries in MLNs, we theoretically demonstrate that our well-designed,
efficient mean-field iterations effectively mitigate the difficulty of MLN
inference, reducing the inference from sequential calculation to a series of
parallel tensor operations. Empirical results in three kinds of tasks over
graphs, images, and text show that LogicMP outperforms advanced competitors in
both performance and efficiency.
</p>
</div>
</dd>
<dt><a name="item115">[115]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15459" title="Abstract">arXiv:2309.15459</a> [<a href="/pdf/2309.15459" title="Download PDF">pdf</a>, <a href="/format/2309.15459" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GAMMA: Graspability-Aware Mobile MAnipulation Policy Learning based on  Online Grasping Pose Fusion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jiazhao Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Gireesh%2C+N">Nandiraju Gireesh</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jilong Wang</a>, 
<a href="/search/cs?searchtype=author&query=Fang%2C+X">Xiaomeng Fang</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+C">Chaoyi Xu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+W">Weiguang Chen</a>, 
<a href="/search/cs?searchtype=author&query=Dai%2C+L">Liu Dai</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">He Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Mobile manipulation constitutes a fundamental task for robotic assistants and
garners significant attention within the robotics community. A critical
challenge inherent in mobile manipulation is the effective observation of the
target while approaching it for grasping. In this work, we propose a
graspability-aware mobile manipulation approach powered by an online grasping
pose fusion framework that enables a temporally consistent grasping
observation. Specifically, the predicted grasping poses are online organized to
eliminate the redundant, outlier grasping poses, which can be encoded as a
grasping pose observation state for reinforcement learning. Moreover,
on-the-fly fusing the grasping poses enables a direct assessment of
graspability, encompassing both the quantity and quality of grasping poses.
</p>
</div>
</dd>
<dt><a name="item116">[116]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15461" title="Abstract">arXiv:2309.15461</a> [<a href="/pdf/2309.15461" title="Download PDF">pdf</a>, <a href="/format/2309.15461" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ChatCounselor: A Large Language Models for Mental Health Support
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+J+M">June M. Liu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+D">Donghao Li</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+H">He Cao</a>, 
<a href="/search/cs?searchtype=author&query=Ren%2C+T">Tianhe Ren</a>, 
<a href="/search/cs?searchtype=author&query=Liao%2C+Z">Zeyi Liao</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+J">Jiamin Wu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">This paper presents ChatCounselor, a large language model (LLM) solution
designed to provide mental health support. Unlike generic chatbots,
ChatCounselor is distinguished by its foundation in real conversations between
consulting clients and professional psychologists, enabling it to possess
specialized knowledge and counseling skills in the field of psychology. The
training dataset, Psych8k, was constructed from 260 in-depth interviews, each
spanning an hour. To assess the quality of counseling responses, the counseling
Bench was devised. Leveraging GPT-4 and meticulously crafted prompts based on
seven metrics of psychological counseling assessment, the model underwent
evaluation using a set of real-world counseling questions. Impressively,
ChatCounselor surpasses existing open-source models in the counseling Bench and
approaches the performance level of ChatGPT, showcasing the remarkable
enhancement in model capability attained through high-quality domain-specific
data.
</p>
</div>
</dd>
<dt><a name="item117">[117]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15462" title="Abstract">arXiv:2309.15462</a> [<a href="/pdf/2309.15462" title="Download PDF">pdf</a>, <a href="/format/2309.15462" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DTC: Deep Tracking Control -- A Unifying Approach to Model-Based  Planning and Reinforcement-Learning for Versatile and Robust Locomotion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jenelten%2C+F">Fabian Jenelten</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+J">Junzhe He</a>, 
<a href="/search/cs?searchtype=author&query=Farshidian%2C+F">Farbod Farshidian</a>, 
<a href="/search/cs?searchtype=author&query=Hutter%2C+M">Marco Hutter</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Legged locomotion is a complex control problem that requires both accuracy
and robustness to cope with real-world challenges. Legged systems have
traditionally been controlled using trajectory optimization with inverse
dynamics. Such hierarchical model-based methods are appealing due to intuitive
cost function tuning, accurate planning, and most importantly, the insightful
understanding gained from more than one decade of extensive research. However,
model mismatch and violation of assumptions are common sources of faulty
operation and may hinder successful sim-to-real transfer. Simulation-based
reinforcement learning, on the other hand, results in locomotion policies with
unprecedented robustness and recovery skills. Yet, all learning algorithms
struggle with sparse rewards emerging from environments where valid footholds
are rare, such as gaps or stepping stones. In this work, we propose a hybrid
control architecture that combines the advantages of both worlds to
simultaneously achieve greater robustness, foot-placement accuracy, and terrain
generalization. Our approach utilizes a model-based planner to roll out a
reference motion during training. A deep neural network policy is trained in
simulation, aiming to track the optimized footholds. We evaluate the accuracy
of our locomotion pipeline on sparse terrains, where pure data-driven methods
are prone to fail. Furthermore, we demonstrate superior robustness in the
presence of slippery or deformable ground when compared to model-based
counterparts. Finally, we show that our proposed tracking controller
generalizes across different trajectory optimization methods not seen during
training. In conclusion, our work unites the predictive capabilities and
optimality guarantees of online planning with the inherent robustness
attributed to offline learning.
</p>
</div>
</dd>
<dt><a name="item118">[118]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15465" title="Abstract">arXiv:2309.15465</a> [<a href="/pdf/2309.15465" title="Download PDF">pdf</a>, <a href="/format/2309.15465" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Cross-Dataset Experimental Study of Radar-Camera Fusion in Bird&#x27;s-Eye  View
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=St%C3%A4cker%2C+L">Lukas St&#xe4;cker</a>, 
<a href="/search/cs?searchtype=author&query=Heidenreich%2C+P">Philipp Heidenreich</a>, 
<a href="/search/cs?searchtype=author&query=Rambach%2C+J">Jason Rambach</a>, 
<a href="/search/cs?searchtype=author&query=Stricker%2C+D">Didier Stricker</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> EUSIPCO 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">By exploiting complementary sensor information, radar and camera fusion
systems have the potential to provide a highly robust and reliable perception
system for advanced driver assistance systems and automated driving functions.
Recent advances in camera-based object detection offer new radar-camera fusion
possibilities with bird's eye view feature maps. In this work, we propose a
novel and flexible fusion network and evaluate its performance on two datasets:
nuScenes and View-of-Delft. Our experiments reveal that while the camera branch
needs large and diverse training data, the radar branch benefits more from a
high-performance radar. Using transfer learning, we improve the camera's
performance on the smaller dataset. Our results further demonstrate that the
radar-camera fusion approach significantly outperforms the camera-only and
radar-only baselines.
</p>
</div>
</dd>
<dt><a name="item119">[119]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15467" title="Abstract">arXiv:2309.15467</a> [<a href="/pdf/2309.15467" title="Download PDF">pdf</a>, <a href="/format/2309.15467" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Enabling Resource-efficient AIoT System with Cross-level Optimization: A  survey
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+S">Sicong Liu</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+B">Bin Guo</a>, 
<a href="/search/cs?searchtype=author&query=Fang%2C+C">Cheng Fang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Ziqi Wang</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+S">Shiyan Luo</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Z">Zimu Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+Z">Zhiwen Yu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Distributed, Parallel, and Cluster Computing (cs.DC)

</div>
<p class="mathjax">The emerging field of artificial intelligence of things (AIoT, AI+IoT) is
driven by the widespread use of intelligent infrastructures and the impressive
success of deep learning (DL). With the deployment of DL on various intelligent
infrastructures featuring rich sensors and weak DL computing capabilities, a
diverse range of AIoT applications has become possible. However, DL models are
notoriously resource-intensive. Existing research strives to realize
near-/realtime inference of AIoT live data and low-cost training using AIoT
datasets on resource-scare infrastructures. Accordingly, the accuracy and
responsiveness of DL models are bounded by resource availability. To this end,
the algorithm-system co-design that jointly optimizes the resource-friendly DL
models and model-adaptive system scheduling improves the runtime resource
availability and thus pushes the performance boundary set by the standalone
level. Unlike previous surveys on resource-friendly DL models or hand-crafted
DL compilers/frameworks with partially fine-tuned components, this survey aims
to provide a broader optimization space for more free resource-performance
tradeoffs. The cross-level optimization landscape involves various granularity,
including the DL model, computation graph, operator, memory schedule, and
hardware instructor in both on-device and distributed paradigms. Furthermore,
due to the dynamic nature of AIoT context, which includes heterogeneous
hardware, agnostic sensing data, varying user-specified performance demands,
and resource constraints, this survey explores the context-aware
inter-/intra-device controllers for automatic cross-level adaptation.
Additionally, we identify some potential directions for resource-efficient AIoT
systems. By consolidating problems and techniques scattered over diverse
levels, we aim to help readers understand their connections and stimulate
further discussions.
</p>
</div>
</dd>
<dt><a name="item120">[120]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15468" title="Abstract">arXiv:2309.15468</a> [<a href="/pdf/2309.15468" title="Download PDF">pdf</a>, <a href="/format/2309.15468" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Patterns Induce Injectivity: A New Thinking in Constructing Injective  Local Rules of 1D Cellular Automata over $\mathbb{F}_2$
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lin%2C+D">Defu Lin</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+W">Weilin Chen</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+C">Chen Wang</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+J">Junchi Ma</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+C">Chao Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Complexity (cs.CC)</span>; Cellular Automata and Lattice Gases (nlin.CG)

</div>
<p class="mathjax">We discovered that certain patterns called injective patterns remain stable
during the revolution process, allowing us to create many reversible CA simply
by using them to design the revolution rules. By examining injective patterns,
we investigated their structural stability during revolutions. This led us to
discover extended patterns and pattern mixtures that can create more reversible
cellular automata. Furthermore, our research proposed a new way to study the
reversibility of CA by observing the structure of local rule $f$. In this
paper, we will explicate our study and propose an efficient method for finding
the injective patterns. Our algorithms can find injective rules and generate
local rule $f$ by traversing $2^{N}$, instead of $2^{2^{N}}$ to check all
injective rules and pick the injective ones.
</p>
</div>
</dd>
<dt><a name="item121">[121]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15471" title="Abstract">arXiv:2309.15471</a> [<a href="/pdf/2309.15471" title="Download PDF">pdf</a>, <a href="/format/2309.15471" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ProFaaStinate: Delaying Serverless Function Calls to Optimize Platform  Performance
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Schirmer%2C+T">Trever Schirmer</a>, 
<a href="/search/cs?searchtype=author&query=Carl%2C+V">Valentin Carl</a>, 
<a href="/search/cs?searchtype=author&query=Pfandzelter%2C+T">Tobias Pfandzelter</a>, 
<a href="/search/cs?searchtype=author&query=Bermbach%2C+D">David Bermbach</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages, 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>

</div>
<p class="mathjax">Function-as-a-Service (FaaS) enables developers to run serverless
applications without managing operational tasks. In current FaaS platforms,
both synchronous and asynchronous calls are executed immediately. In this
paper, we present ProFaaStinate, which extends serverless platforms to enable
delayed execution of asynchronous function calls. This allows platforms to
execute calls at convenient times with higher resource availability or lower
load. ProFaaStinate is able to optimize performance without requiring deep
integration into the rest of the platform, or a complex systems model. In our
evaluation, our prototype built on top of Nuclio can reduce request response
latency and workflow duration while also preventing the system from being
overloaded during load peaks. Using a document preparation use case, we show a
54% reduction in average request response latency. This reduction in resource
usage benefits both platforms and users as cost savings.
</p>
</div>
</dd>
<dt><a name="item122">[122]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15472" title="Abstract">arXiv:2309.15472</a> [<a href="/pdf/2309.15472" title="Download PDF">pdf</a>, <a href="/format/2309.15472" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Voxel Graph Operators: Topological Voxelization, Graph Generation, and  Derivation of Discrete Differential Operators from Voxel Complexes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nourian%2C+P">Pirouz Nourian</a>, 
<a href="/search/cs?searchtype=author&query=Azadi%2C+S">Shervin Azadi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 23 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Graphics (cs.GR)</span>; Computational Geometry (cs.CG); Discrete Mathematics (cs.DM); Analysis of PDEs (math.AP); Geometric Topology (math.GT)

</div>
<p class="mathjax">In this paper, we present a novel workflow consisting of algebraic algorithms
and data structures for fast and topologically accurate conversion of vector
data models such as Boundary Representations into voxels (topological
voxelization); spatially indexing them; constructing connectivity graphs from
voxels; and constructing a coherent set of multivariate differential and
integral operators from these graphs. Topological Voxelization is revisited and
presented in the paper as a reversible mapping of geometric models from
$\mathbb{R}^3$ to $\mathbb{Z}^3$ to $\mathbb{N}^3$ and eventually to an index
space created by Morton Codes in $\mathbb{N}$ while ensuring the topological
validity of the voxel models; namely their topological thinness and their
geometrical consistency. In addition, we present algorithms for constructing
graphs and hyper-graph connectivity models on voxel data for graph traversal
and field interpolations and utilize them algebraically in elegantly
discretizing differential and integral operators for geometric, graphical, or
spatial analyses and digital simulations. The multi-variate differential and
integral operators presented in this paper can be used particularly in the
formulation of Partial Differential Equations for physics simulations.
</p>
</div>
</dd>
<dt><a name="item123">[123]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15474" title="Abstract">arXiv:2309.15474</a> [<a href="/pdf/2309.15474" title="Download PDF">pdf</a>, <a href="/format/2309.15474" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CCBERT: Self-Supervised Code Change Representation Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhou%2C+X">Xin Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+B">Bowen Xu</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+D">DongGyun Han</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Z">Zhou Yang</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+J">Junda He</a>, 
<a href="/search/cs?searchtype=author&query=Lo%2C+D">David Lo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 Pages; Accepted in the Main Track of The International Conference on Software Maintenance and Evolution (ICSME) 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
<p class="mathjax">Numerous code changes are made by developers in their daily work, and a
superior representation of code changes is desired for effective code change
analysis. Recently, Hoang et al. proposed CC2Vec, a neural network-based
approach that learns a distributed representation of code changes to capture
the semantic intent of the changes. Despite demonstrated effectiveness in
multiple tasks, CC2Vec has several limitations: 1) it considers only
coarse-grained information about code changes, and 2) it relies on log messages
rather than the self-contained content of the code changes. In this work, we
propose CCBERT (\underline{C}ode \underline{C}hange \underline{BERT}), a new
Transformer-based pre-trained model that learns a generic representation of
code changes based on a large-scale dataset containing massive unlabeled code
changes. CCBERT is pre-trained on four proposed self-supervised objectives that
are specialized for learning code change representations based on the contents
of code changes. CCBERT perceives fine-grained code changes at the token level
by learning from the old and new versions of the content, along with the edit
actions. Our experiments demonstrate that CCBERT significantly outperforms
CC2Vec or the state-of-the-art approaches of the downstream tasks by
7.7\%--14.0\% in terms of different metrics and tasks. CCBERT consistently
outperforms large pre-trained code models, such as CodeBERT, while requiring
6--10$\times$ less training time, 5--30$\times$ less inference time, and
7.9$\times$ less GPU memory.
</p>
</div>
</dd>
<dt><a name="item124">[124]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15476" title="Abstract">arXiv:2309.15476</a> [<a href="/pdf/2309.15476" title="Download PDF">pdf</a>, <a href="/format/2309.15476" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Dynamic Multi-Scale Context Aggregation for Conversational Aspect-Based  Sentiment Quadruple Analysis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yuqing Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+W">Wenyuan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+B">Binbin Li</a>, 
<a href="/search/cs?searchtype=author&query=Jia%2C+S">Siyu Jia</a>, 
<a href="/search/cs?searchtype=author&query=Qi%2C+Z">Zisen Qi</a>, 
<a href="/search/cs?searchtype=author&query=Tan%2C+X">Xingbang Tan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Conversational aspect-based sentiment quadruple analysis (DiaASQ) aims to
extract the quadruple of target-aspect-opinion-sentiment within a dialogue. In
DiaASQ, a quadruple's elements often cross multiple utterances. This situation
complicates the extraction process, emphasizing the need for an adequate
understanding of conversational context and interactions. However, existing
work independently encodes each utterance, thereby struggling to capture
long-range conversational context and overlooking the deep inter-utterance
dependencies. In this work, we propose a novel Dynamic Multi-scale Context
Aggregation network (DMCA) to address the challenges. Specifically, we first
utilize dialogue structure to generate multi-scale utterance windows for
capturing rich contextual information. After that, we design a Dynamic
Hierarchical Aggregation module (DHA) to integrate progressive cues between
them. In addition, we form a multi-stage loss strategy to improve model
performance and generalization ability. Extensive experimental results show
that the DMCA model outperforms baselines significantly and achieves
state-of-the-art performance.
</p>
</div>
</dd>
<dt><a name="item125">[125]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15477" title="Abstract">arXiv:2309.15477</a> [<a href="/pdf/2309.15477" title="Download PDF">pdf</a>, <a href="/format/2309.15477" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Tutorial on Uniform B-Spline
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Y">Yi Zhou</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Graphics (cs.GR)</span>; Computer Vision and Pattern Recognition (cs.CV); Robotics (cs.RO)

</div>
<p class="mathjax">This document facilitates understanding of core concepts about uniform
B-spline and its matrix representation.
</p>
</div>
</dd>
<dt><a name="item126">[126]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15478" title="Abstract">arXiv:2309.15478</a> [<a href="/pdf/2309.15478" title="Download PDF">pdf</a>, <a href="/format/2309.15478" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Robust Semantic Segmentation UNCV2023 Challenge Results
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yu%2C+X">Xuanlong Yu</a>, 
<a href="/search/cs?searchtype=author&query=Zuo%2C+Y">Yi Zuo</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zitao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xiaowen Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+J">Jiaxuan Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yuting Yang</a>, 
<a href="/search/cs?searchtype=author&query=Jiao%2C+L">Licheng Jiao</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+R">Rui Peng</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xinyi Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Junpei Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+K">Kexin Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+F">Fang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Alcover-Couso%2C+R">Roberto Alcover-Couso</a>, 
<a href="/search/cs?searchtype=author&query=SanMiguel%2C+J+C">Juan C. SanMiguel</a>, 
<a href="/search/cs?searchtype=author&query=Escudero-Vi%C3%B1olo%2C+M">Marcos Escudero-Vi&#xf1;olo</a>, 
<a href="/search/cs?searchtype=author&query=Tian%2C+H">Hanlin Tian</a>, 
<a href="/search/cs?searchtype=author&query=Matsui%2C+K">Kenta Matsui</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+T">Tianhao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Adan%2C+F">Fahmy Adan</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+Z">Zhitong Gao</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+X">Xuming He</a>, 
<a href="/search/cs?searchtype=author&query=Bouniot%2C+Q">Quentin Bouniot</a>, 
<a href="/search/cs?searchtype=author&query=Moghaddam%2C+H">Hossein Moghaddam</a>, 
<a href="/search/cs?searchtype=author&query=Rai%2C+S+N">Shyam Nandan Rai</a>, 
<a href="/search/cs?searchtype=author&query=Cermelli%2C+F">Fabio Cermelli</a>, 
<a href="/search/cs?searchtype=author&query=Masone%2C+C">Carlo Masone</a>, 
<a href="/search/cs?searchtype=author&query=Pilzer%2C+A">Andrea Pilzer</a>, 
<a href="/search/cs?searchtype=author&query=Ricci%2C+E">Elisa Ricci</a>, 
<a href="/search/cs?searchtype=author&query=Bursuc%2C+A">Andrei Bursuc</a>, 
<a href="/search/cs?searchtype=author&query=Solin%2C+A">Arno Solin</a>, 
<a href="/search/cs?searchtype=author&query=Trapp%2C+M">Martin Trapp</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+R">Rui Li</a>, 
<a href="/search/cs?searchtype=author&query=Yao%2C+A">Angela Yao</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+W">Wenlong Chen</a>, 
<a href="/search/cs?searchtype=author&query=Simpson%2C+I">Ivor Simpson</a>, 
<a href="/search/cs?searchtype=author&query=Campbell%2C+N+D+F">Neill D. F. Campbell</a>, 
<a href="/search/cs?searchtype=author&query=Franchi%2C+G">Gianni Franchi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages, 4 figures, accepted at ICCV 2023 UNCV workshop
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">This paper outlines the winning solutions employed in addressing the MUAD
uncertainty quantification challenge held at ICCV 2023. The challenge was
centered around semantic segmentation in urban environments, with a particular
focus on natural adversarial scenarios. The report presents the results of 19
submitted entries, with numerous techniques drawing inspiration from
cutting-edge uncertainty quantification methodologies presented at prominent
conferences in the fields of computer vision and machine learning and journals
over the past few years. Within this document, the challenge is introduced,
shedding light on its purpose and objectives, which primarily revolved around
enhancing the robustness of semantic segmentation in urban scenes under varying
natural adversarial conditions. The report then delves into the top-performing
solutions. Moreover, the document aims to provide a comprehensive overview of
the diverse solutions deployed by all participants. By doing so, it seeks to
offer readers a deeper insight into the array of strategies that can be
leveraged to effectively handle the inherent uncertainties associated with
autonomous driving and semantic segmentation, especially within urban
environments.
</p>
</div>
</dd>
<dt><a name="item127">[127]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15479" title="Abstract">arXiv:2309.15479</a> [<a href="/pdf/2309.15479" title="Download PDF">pdf</a>, <a href="/format/2309.15479" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fast Locality Sensitive Hashing with Theoretical Guarantee
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tan%2C+Z">Zongyuan Tan</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Hongya Wang</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+B">Bo Xu</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+M">Minjie Luo</a>, 
<a href="/search/cs?searchtype=author&query=Du%2C+M">Ming Du</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Data Structures and Algorithms (cs.DS)

</div>
<p class="mathjax">Locality-sensitive hashing (LSH) is an effective randomized technique widely
used in many machine learning tasks. The cost of hashing is proportional to
data dimensions, and thus often the performance bottleneck when dimensionality
is high and the number of hash functions involved is large. Surprisingly,
however, little work has been done to improve the efficiency of LSH
computation. In this paper, we design a simple yet efficient LSH scheme, named
FastLSH, under l2 norm. By combining random sampling and random projection,
FastLSH reduces the time complexity from O(n) to O(m) (m&lt;n), where n is the
data dimensionality and m is the number of sampled dimensions. Moreover,
FastLSH has provable LSH property, which distinguishes it from the non-LSH fast
sketches. We conduct comprehensive experiments over a collection of real and
synthetic datasets for the nearest neighbor search task. Experimental results
demonstrate that FastLSH is on par with the state-of-the-arts in terms of
answer quality, space occupation and query efficiency, while enjoying up to 80x
speedup in hash function evaluation. We believe that FastLSH is a promising
alternative to the classic LSH scheme.
</p>
</div>
</dd>
<dt><a name="item128">[128]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15483" title="Abstract">arXiv:2309.15483</a> [<a href="/pdf/2309.15483" title="Download PDF">pdf</a>, <a href="/ps/2309.15483" title="Download PostScript">ps</a>, <a href="/format/2309.15483" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Energy-Efficient Precoding Designs for Multi-User Visible Light  Communication Systems with Confidential Messages
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Duong%2C+S+T">Son T. Duong</a>, 
<a href="/search/cs?searchtype=author&query=Pham%2C+T+V">Thanh V. Pham</a>, 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+C+T">Chuyen T. Nguyen</a>, 
<a href="/search/cs?searchtype=author&query=Pham%2C+A+T">Anh T. Pham</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Systems and Control (eess.SY)

</div>
<p class="mathjax">This paper studies energy-efficient precoding designs for multi-user visible
light communication (VLC) systems from the perspective of physical layer
security where users' messages must be kept mutually confidential. For such
systems, we first derive a lower bound on the achievable secrecy rate of each
user. Next, the total power consumption for illumination and data transmission
is thoroughly analyzed. We then tackle the problem of maximizing energy
efficiency, given that each user's secrecy rate satisfies a certain threshold.
The design problem is shown to be non-convex fractional programming, which
renders finding the optimal solution computationally prohibitive. Our aim in
this paper is, therefore, to find sub-optimal yet low complexity solutions. For
this purpose, the traditional Dinkelbach algorithm is first employed to
reformulate the original problem to a non-fractional parameterized one. Two
different approaches based on the convex-concave procedure (CCCP) and
Semidefinite Relaxation (SDR) are utilized to solve the non-convex
parameterized problem. In addition, to further reduce the complexity, we
investigate a design using the zero-forcing (ZF) technique. Numerical results
are conducted to show the feasibility, convergence, and performance of the
proposed algorithms depending on different parameters of the system.
</p>
</div>
</dd>
<dt><a name="item129">[129]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15484" title="Abstract">arXiv:2309.15484</a> [<a href="/pdf/2309.15484" title="Download PDF">pdf</a>, <a href="/format/2309.15484" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Human-Like RL: Taming Non-Naturalistic Behavior in Deep RL via  Adaptive Behavioral Costs in 3D Games
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ho%2C+K">Kuo-Hao Ho</a>, 
<a href="/search/cs?searchtype=author&query=Hsieh%2C+P">Ping-Chun Hsieh</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+C">Chiu-Chou Lin</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+Y">You-Ren Luo</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+F">Feng-Jian Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+I">I-Chen Wu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
<p class="mathjax">In this paper, we propose a new approach called Adaptive Behavioral Costs in
Reinforcement Learning (ABC-RL) for training a human-like agent with
competitive strength. While deep reinforcement learning agents have recently
achieved superhuman performance in various video games, some of these
unconstrained agents may exhibit actions, such as shaking and spinning, that
are not typically observed in human behavior, resulting in peculiar gameplay
experiences. To behave like humans and retain similar performance, ABC-RL
augments behavioral limitations as cost signals in reinforcement learning with
dynamically adjusted weights. Unlike traditional constrained policy
optimization, we propose a new formulation that minimizes the behavioral costs
subject to a constraint of the value function. By leveraging the augmented
Lagrangian, our approach is an approximation of the Lagrangian adjustment,
which handles the trade-off between the performance and the human-like
behavior. Through experiments conducted on 3D games in DMLab-30 and Unity
ML-Agents Toolkit, we demonstrate that ABC-RL achieves the same performance
level while significantly reducing instances of shaking and spinning. These
findings underscore the effectiveness of our proposed approach in promoting
more natural and human-like behavior during gameplay.
</p>
</div>
</dd>
<dt><a name="item130">[130]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15486" title="Abstract">arXiv:2309.15486</a> [<a href="/pdf/2309.15486" title="Download PDF">pdf</a>, <a href="/format/2309.15486" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Transferability of Representations Learned using Supervised Contrastive  Learning Trained on a Multi-Domain Dataset
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=De+Jun+Tan%2C+A">Alvin De Jun Tan</a>, 
<a href="/search/cs?searchtype=author&query=Tan%2C+C">Clement Tan</a>, 
<a href="/search/cs?searchtype=author&query=Yeo%2C+C+K">Chai Kiat Yeo</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Contrastive learning has shown to learn better quality representations than
models trained using cross-entropy loss. They also transfer better to
downstream datasets from different domains. However, little work has been done
to explore the transferability of representations learned using contrastive
learning when trained on a multi-domain dataset. In this paper, a study has
been conducted using the Supervised Contrastive Learning framework to learn
representations from the multi-domain DomainNet dataset and then evaluate the
transferability of the representations learned on other downstream datasets.
The fixed feature linear evaluation protocol will be used to evaluate the
transferability on 7 downstream datasets that were chosen across different
domains. The results obtained are compared to a baseline model that was trained
using the widely used cross-entropy loss. Empirical results from the
experiments showed that on average, the Supervised Contrastive Learning model
performed 6.05% better than the baseline model on the 7 downstream datasets.
The findings suggest that Supervised Contrastive Learning models can
potentially learn more robust representations that transfer better across
domains than cross-entropy models when trained on a multi-domain dataset.
</p>
</div>
</dd>
<dt><a name="item131">[131]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15487" title="Abstract">arXiv:2309.15487</a> [<a href="/pdf/2309.15487" title="Download PDF">pdf</a>, <a href="/format/2309.15487" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Tackling VQA with Pretrained Foundation Models without Further Training
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=De+Jun+Tan%2C+A">Alvin De Jun Tan</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+B">Bingquan Shen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Large language models (LLMs) have achieved state-of-the-art results in many
natural language processing tasks. They have also demonstrated ability to adapt
well to different tasks through zero-shot or few-shot settings. With the
capability of these LLMs, researchers have looked into how to adopt them for
use with Visual Question Answering (VQA). Many methods require further training
to align the image and text embeddings. However, these methods are
computationally expensive and requires large scale image-text dataset for
training. In this paper, we explore a method of combining pretrained LLMs and
other foundation models without further training to solve the VQA problem. The
general idea is to use natural language to represent the images such that the
LLM can understand the images. We explore different decoding strategies for
generating textual representation of the image and evaluate their performance
on the VQAv2 dataset.
</p>
</div>
</dd>
<dt><a name="item132">[132]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15490" title="Abstract">arXiv:2309.15490</a> [<a href="/pdf/2309.15490" title="Download PDF">pdf</a>, <a href="/format/2309.15490" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Survey on Deep Face Restoration: From Non-blind to Blind and Beyond
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+W">Wenjie Li</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+M">Mei Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+K">Kai Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Juncheng Li</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xiaoming Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yuhang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+G">Guangwei Gao</a>, 
<a href="/search/cs?searchtype=author&query=Deng%2C+W">Weihong Deng</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+C">Chia-Wen Lin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Face restoration, Survey, Deep learning, Non-blind/Blind, Joint restoration tasks, Facial priors
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Face restoration (FR) is a specialized field within image restoration that
aims to recover low-quality (LQ) face images into high-quality (HQ) face
images. Recent advances in deep learning technology have led to significant
progress in FR methods. In this paper, we begin by examining the prevalent
factors responsible for real-world LQ images and introduce degradation
techniques used to synthesize LQ images. We also discuss notable benchmarks
commonly utilized in the field. Next, we categorize FR methods based on
different tasks and explain their evolution over time. Furthermore, we explore
the various facial priors commonly utilized in the restoration process and
discuss strategies to enhance their effectiveness. In the experimental section,
we thoroughly evaluate the performance of state-of-the-art FR methods across
various tasks using a unified benchmark. We analyze their performance from
different perspectives. Finally, we discuss the challenges faced in the field
of FR and propose potential directions for future advancements. The open-source
repository corresponding to this work can be found at https:// github.com/
24wenjie-li/ Awesome-Face-Restoration.
</p>
</div>
</dd>
<dt><a name="item133">[133]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15492" title="Abstract">arXiv:2309.15492</a> [<a href="/pdf/2309.15492" title="Download PDF">pdf</a>, <a href="/format/2309.15492" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> EDGAR: An Autonomous Driving Research Platform -- From Feature  Development to Real-World Application
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Karle%2C+P">Phillip Karle</a>, 
<a href="/search/cs?searchtype=author&query=Betz%2C+T">Tobias Betz</a>, 
<a href="/search/cs?searchtype=author&query=Bosk%2C+M">Marcin Bosk</a>, 
<a href="/search/cs?searchtype=author&query=Fent%2C+F">Felix Fent</a>, 
<a href="/search/cs?searchtype=author&query=Gehrke%2C+N">Nils Gehrke</a>, 
<a href="/search/cs?searchtype=author&query=Geisslinger%2C+M">Maximilian Geisslinger</a>, 
<a href="/search/cs?searchtype=author&query=Gressenbuch%2C+L">Luis Gressenbuch</a>, 
<a href="/search/cs?searchtype=author&query=Hafemann%2C+P">Philipp Hafemann</a>, 
<a href="/search/cs?searchtype=author&query=Huber%2C+S">Sebastian Huber</a>, 
<a href="/search/cs?searchtype=author&query=H%C3%BCbner%2C+M">Maximilian H&#xfc;bner</a>, 
<a href="/search/cs?searchtype=author&query=Huch%2C+S">Sebastian Huch</a>, 
<a href="/search/cs?searchtype=author&query=Kaljavesi%2C+G">Gemb Kaljavesi</a>, 
<a href="/search/cs?searchtype=author&query=Kerbl%2C+T">Tobias Kerbl</a>, 
<a href="/search/cs?searchtype=author&query=Kulmer%2C+D">Dominik Kulmer</a>, 
<a href="/search/cs?searchtype=author&query=Mascetta%2C+T">Tobias Mascetta</a>, 
<a href="/search/cs?searchtype=author&query=Maierhofer%2C+S">Sebastian Maierhofer</a>, 
<a href="/search/cs?searchtype=author&query=Pfab%2C+F">Florian Pfab</a>, 
<a href="/search/cs?searchtype=author&query=Rezabek%2C+F">Filip Rezabek</a>, 
<a href="/search/cs?searchtype=author&query=Rivera%2C+E">Esteban Rivera</a>, 
<a href="/search/cs?searchtype=author&query=Sagmeister%2C+S">Simon Sagmeister</a>, 
<a href="/search/cs?searchtype=author&query=Seidlitz%2C+L">Leander Seidlitz</a>, 
<a href="/search/cs?searchtype=author&query=Sauerbeck%2C+F">Florian Sauerbeck</a>, 
<a href="/search/cs?searchtype=author&query=Tahiraj%2C+I">Ilir Tahiraj</a>, 
<a href="/search/cs?searchtype=author&query=Trauth%2C+R">Rainer Trauth</a>, 
<a href="/search/cs?searchtype=author&query=Uhlemann%2C+N">Nico Uhlemann</a>, 
<a href="/search/cs?searchtype=author&query=W%C3%BCrsching%2C+G">Gerald W&#xfc;rsching</a>, 
<a href="/search/cs?searchtype=author&query=Zarrouki%2C+B">Baha Zarrouki</a>, 
<a href="/search/cs?searchtype=author&query=Althoff%2C+M">Matthias Althoff</a>, 
<a href="/search/cs?searchtype=author&query=Betz%2C+J">Johannes Betz</a>, 
<a href="/search/cs?searchtype=author&query=Bengler%2C+K">Klaus Bengler</a>, 
<a href="/search/cs?searchtype=author&query=Carle%2C+G">Georg Carle</a>, 
<a href="/search/cs?searchtype=author&query=Diermeyer%2C+F">Frank Diermeyer</a>, 
<a href="/search/cs?searchtype=author&query=Ott%2C+J">J&#xf6;rg Ott</a>, 
<a href="/search/cs?searchtype=author&query=Lienkamp%2C+M">Markus Lienkamp</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">While current research and development of autonomous driving primarily
focuses on developing new features and algorithms, the transfer from isolated
software components into an entire software stack has been covered sparsely.
Besides that, due to the complexity of autonomous software stacks and public
road traffic, the optimal validation of entire stacks is an open research
problem. Our paper targets these two aspects. We present our autonomous
research vehicle EDGAR and its digital twin, a detailed virtual duplication of
the vehicle. While the vehicle's setup is closely related to the state of the
art, its virtual duplication is a valuable contribution as it is crucial for a
consistent validation process from simulation to real-world tests. In addition,
different development teams can work with the same model, making integration
and testing of the software stacks much easier, significantly accelerating the
development process. The real and virtual vehicles are embedded in a
comprehensive development environment, which is also introduced. All parameters
of the digital twin are provided open-source at
https://github.com/TUMFTM/edgar_digital_twin.
</p>
</div>
</dd>
<dt><a name="item134">[134]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15493" title="Abstract">arXiv:2309.15493</a> [<a href="/pdf/2309.15493" title="Download PDF">pdf</a>, <a href="/format/2309.15493" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CauDR: A Causality-inspired Domain Generalization Framework for  Fundus-based Diabetic Retinopathy Grading
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wei%2C+H">Hao Wei</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+P">Peilun Shi</a>, 
<a href="/search/cs?searchtype=author&query=Miao%2C+J">Juzheng Miao</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+M">Minqing Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Bai%2C+G">Guitao Bai</a>, 
<a href="/search/cs?searchtype=author&query=Qiu%2C+J">Jianing Qiu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+F">Furui Liu</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+W">Wu Yuan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, 9 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Diabetic retinopathy (DR) is the most common diabetic complication, which
usually leads to retinal damage, vision loss, and even blindness. A
computer-aided DR grading system has a significant impact on helping
ophthalmologists with rapid screening and diagnosis. Recent advances in fundus
photography have precipitated the development of novel retinal imaging cameras
and their subsequent implementation in clinical practice. However, most deep
learning-based algorithms for DR grading demonstrate limited generalization
across domains. This inferior performance stems from variance in imaging
protocols and devices inducing domain shifts. We posit that declining model
performance between domains arises from learning spurious correlations in the
data. Incorporating do-operations from causality analysis into model
architectures may mitigate this issue and improve generalizability.
Specifically, a novel universal structural causal model (SCM) was proposed to
analyze spurious correlations in fundus imaging. Building on this, a
causality-inspired diabetic retinopathy grading framework named CauDR was
developed to eliminate spurious correlations and achieve more generalizable DR
diagnostics. Furthermore, existing datasets were reorganized into 4DR benchmark
for DG scenario. Results demonstrate the effectiveness and the state-of-the-art
(SOTA) performance of CauDR.
</p>
</div>
</dd>
<dt><a name="item135">[135]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15494" title="Abstract">arXiv:2309.15494</a> [<a href="/pdf/2309.15494" title="Download PDF">pdf</a>, <a href="/format/2309.15494" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> VideoAdviser: Video Knowledge Distillation for Multimodal Transfer  Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yanan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zeng%2C+D">Donghuo Zeng</a>, 
<a href="/search/cs?searchtype=author&query=Wada%2C+S">Shinya Wada</a>, 
<a href="/search/cs?searchtype=author&query=Kurihara%2C+S">Satoshi Kurihara</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by IEEE Access
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> in IEEE Access, vol. 11, pp. 51229-51240, 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Computation and Language (cs.CL)

</div>
<p class="mathjax">Multimodal transfer learning aims to transform pretrained representations of
diverse modalities into a common domain space for effective multimodal fusion.
However, conventional systems are typically built on the assumption that all
modalities exist, and the lack of modalities always leads to poor inference
performance. Furthermore, extracting pretrained embeddings for all modalities
is computationally inefficient for inference. In this work, to achieve high
efficiency-performance multimodal transfer learning, we propose VideoAdviser, a
video knowledge distillation method to transfer multimodal knowledge of
video-enhanced prompts from a multimodal fundamental model (teacher) to a
specific modal fundamental model (student). With an intuition that the best
learning performance comes with professional advisers and smart students, we
use a CLIP-based teacher model to provide expressive multimodal knowledge
supervision signals to a RoBERTa-based student model via optimizing a
step-distillation objective loss -- first step: the teacher distills multimodal
knowledge of video-enhanced prompts from classification logits to a regression
logit -- second step: the multimodal knowledge is distilled from the regression
logit of the teacher to the student. We evaluate our method in two challenging
multimodal tasks: video-level sentiment analysis (MOSI and MOSEI datasets) and
audio-visual retrieval (VEGAS dataset). The student (requiring only the text
modality as input) achieves an MAE score improvement of up to 12.3% for MOSI
and MOSEI. Our method further enhances the state-of-the-art method by 3.4% mAP
score for VEGAS without additional computations for inference. These results
suggest the strengths of our method for achieving high efficiency-performance
multimodal transfer learning.
</p>
</div>
</dd>
<dt><a name="item136">[136]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15495" title="Abstract">arXiv:2309.15495</a> [<a href="/pdf/2309.15495" title="Download PDF">pdf</a>, <a href="/format/2309.15495" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Investigating the changes in BOLD responses during viewing of images  with varied complexity: An fMRI time-series based analysis on human vision
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kanigiri%2C+N">Naveen Kanigiri</a>, 
<a href="/search/cs?searchtype=author&query=Suggula%2C+M">Manohar Suggula</a>, 
<a href="/search/cs?searchtype=author&query=Bhattacharya%2C+D">Debanjali Bhattacharya</a>, 
<a href="/search/cs?searchtype=author&query=Sinha%2C+N">Neelam Sinha</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> The paper is accepted for publication in 3rd International Conference on AI-ML Systems (AIMLSystems 2023), to be held on 25-28 October 2023, Bengaluru, India. arXiv admin note: text overlap with <a href="/abs/2309.03590">arXiv:2309.03590</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">Functional MRI (fMRI) is widely used to examine brain functionality by
detecting alteration in oxygenated blood flow that arises with brain activity.
This work aims to investigate the neurological variation of human brain
responses during viewing of images with varied complexity using fMRI time
series (TS) analysis. Publicly available BOLD5000 dataset is used for this
purpose which contains fMRI scans while viewing 5254 distinct images of diverse
categories, drawn from three standard computer vision datasets: COCO, Imagenet
and SUN. To understand vision, it is important to study how brain functions
while looking at images of diverse complexities. Our first study employs
classical machine learning and deep learning strategies to classify image
complexity-specific fMRI TS, represents instances when images from COCO,
Imagenet and SUN datasets are seen. The implementation of this classification
across visual datasets holds great significance, as it provides valuable
insights into the fluctuations in BOLD signals when perceiving images of
varying complexities. Subsequently, temporal semantic segmentation is also
performed on whole fMRI TS to segment these time instances. The obtained result
of this analysis has established a baseline in studying how differently human
brain functions while looking into images of diverse complexities. Therefore,
accurate identification and distinguishing of variations in BOLD signals from
fMRI TS data serves as a critical initial step in vision studies, providing
insightful explanations for how static images with diverse complexities are
perceived.
</p>
</div>
</dd>
<dt><a name="item137">[137]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15499" title="Abstract">arXiv:2309.15499</a> [<a href="/pdf/2309.15499" title="Download PDF">pdf</a>, <a href="/format/2309.15499" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Bayesian Personalized Federated Learning with Shared and Personalized  Uncertainty Representations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+H">Hui Chen</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+H">Hengyu Liu</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+L">Longbing Cao</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+T">Tiancheng Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Bayesian personalized federated learning (BPFL) addresses challenges in
existing personalized FL (PFL). BPFL aims to quantify the uncertainty and
heterogeneity within and across clients towards uncertainty representations by
addressing the statistical heterogeneity of client data. In PFL, some recent
preliminary work proposes to decompose hidden neural representations into
shared and local components and demonstrates interesting results. However, most
of them do not address client uncertainty and heterogeneity in FL systems,
while appropriately decoupling neural representations is challenging and often
ad hoc. In this paper, we make the first attempt to introduce a general BPFL
framework to decompose and jointly learn shared and personalized uncertainty
representations on statistically heterogeneous client data over time. A
Bayesian federated neural network BPFed instantiates BPFL by jointly learning
cross-client shared uncertainty and client-specific personalized uncertainty
over statistically heterogeneous and randomly participating clients. We further
involve continual updating of prior distribution in BPFed to speed up the
convergence and avoid catastrophic forgetting. Theoretical analysis and
guarantees are provided in addition to the experimental evaluation of BPFed
against the diversified baselines.
</p>
</div>
</dd>
<dt><a name="item138">[138]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15500" title="Abstract">arXiv:2309.15500</a> [<a href="/pdf/2309.15500" title="Download PDF">pdf</a>, <a href="/format/2309.15500" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AdaEvo: Edge-Assisted Continuous and Timely DNN Model Evolution for  Mobile Devices
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+L">Lehao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+Z">Zhiwen Yu</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+H">Haoyi Yu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+S">Sicong Liu</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+Y">Yaxiong Xie</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+B">Bin Guo</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yunxin Liu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>

</div>
<p class="mathjax">Mobile video applications today have attracted significant attention. Deep
learning model (e.g. deep neural network, DNN) compression is widely used to
enable on-device inference for facilitating robust and private mobile video
applications. The compressed DNN, however, is vulnerable to the agnostic data
drift of the live video captured from the dynamically changing mobile
scenarios. To combat the data drift, mobile ends rely on edge servers to
continuously evolve and re-compress the DNN with freshly collected data. We
design a framework, AdaEvo, that efficiently supports the resource-limited edge
server handling mobile DNN evolution tasks from multiple mobile ends. The key
goal of AdaEvo is to maximize the average quality of experience (QoE), e.g. the
proportion of high-quality DNN service time to the entire life cycle, for all
mobile ends. Specifically, it estimates the DNN accuracy drops at the mobile
end without labels and performs a dedicated video frame sampling strategy to
control the size of retraining data. In addition, it balances the limited
computing and memory resources on the edge server and the competition between
asynchronous tasks initiated by different mobile users. With an extensive
evaluation of real-world videos from mobile scenarios and across four diverse
mobile tasks, experimental results show that AdaEvo enables up to 34% accuracy
improvement and 32% average QoE improvement.
</p>
</div>
</dd>
<dt><a name="item139">[139]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15501" title="Abstract">arXiv:2309.15501</a> [<a href="/pdf/2309.15501" title="Download PDF">pdf</a>, <a href="/format/2309.15501" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Overcoming the Fear of the Dark: Occlusion-Aware Model-Predictive  Planning for Automated Vehicles Using Risk Fields
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=van+der+Ploeg%2C+C">Chris van der Ploeg</a>, 
<a href="/search/cs?searchtype=author&query=Nyberg%2C+T">Truls Nyberg</a>, 
<a href="/search/cs?searchtype=author&query=S%C3%A1nchez%2C+J+M+G">Jos&#xe9; Manuel Gaspar S&#xe1;nchez</a>, 
<a href="/search/cs?searchtype=author&query=Silvas%2C+E">Emilia Silvas</a>, 
<a href="/search/cs?searchtype=author&query=van+de+Wouw%2C+N">Nathan van de Wouw</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to the IEEE Transactions on Intelligent Transportation Systems (T-ITS); 14 pages, 11 figures, 1 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Optimization and Control (math.OC)

</div>
<p class="mathjax">As vehicle automation advances, motion planning algorithms face escalating
challenges in achieving safe and efficient navigation. Existing Advanced Driver
Assistance Systems (ADAS) primarily focus on basic tasks, leaving unexpected
scenarios for human intervention, which can be error-prone. Motion planning
approaches for higher levels of automation in the state-of-the-art are
primarily oriented toward the use of risk- or anti-collision constraints, using
over-approximates of the shapes and sizes of other road users to prevent
collisions. These methods however suffer from conservative behavior and the
risk of infeasibility in high-risk initial conditions. In contrast, our work
introduces a novel multi-objective trajectory generation approach. We propose
an innovative method for constructing risk fields that accommodates diverse
entity shapes and sizes, which allows us to also account for the presence of
potentially occluded objects. This methodology is integrated into an
occlusion-aware trajectory generator, enabling dynamic and safe maneuvering
through intricate environments while anticipating (potentially hidden) road
users and traveling along the infrastructure toward a specific goal. Through
theoretical underpinnings and simulations, we validate the effectiveness of our
approach. This paper bridges crucial gaps in motion planning for automated
vehicles, offering a pathway toward safer and more adaptable autonomous
navigation in complex urban contexts.
</p>
</div>
</dd>
<dt><a name="item140">[140]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15505" title="Abstract">arXiv:2309.15505</a> [<a href="/pdf/2309.15505" title="Download PDF">pdf</a>, <a href="/format/2309.15505" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Finite Scalar Quantization: VQ-VAE Made Simple
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mentzer%2C+F">Fabian Mentzer</a>, 
<a href="/search/cs?searchtype=author&query=Minnen%2C+D">David Minnen</a>, 
<a href="/search/cs?searchtype=author&query=Agustsson%2C+E">Eirikur Agustsson</a>, 
<a href="/search/cs?searchtype=author&query=Tschannen%2C+M">Michael Tschannen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">We propose to replace vector quantization (VQ) in the latent representation
of VQ-VAEs with a simple scheme termed finite scalar quantization (FSQ), where
we project the VAE representation down to a few dimensions (typically less than
10). Each dimension is quantized to a small set of fixed values, leading to an
(implicit) codebook given by the product of these sets. By appropriately
choosing the number of dimensions and values each dimension can take, we obtain
the same codebook size as in VQ. On top of such discrete representations, we
can train the same models that have been trained on VQ-VAE representations. For
example, autoregressive and masked transformer models for image generation,
multimodal generation, and dense prediction computer vision tasks. Concretely,
we employ FSQ with MaskGIT for image generation, and with UViM for depth
estimation, colorization, and panoptic segmentation. Despite the much simpler
design of FSQ, we obtain competitive performance in all these tasks. We
emphasize that FSQ does not suffer from codebook collapse and does not need the
complex machinery employed in VQ (commitment losses, codebook reseeding, code
splitting, entropy penalties, etc.) to learn expressive discrete
representations.
</p>
</div>
</dd>
<dt><a name="item141">[141]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15507" title="Abstract">arXiv:2309.15507</a> [<a href="/pdf/2309.15507" title="Download PDF">pdf</a>, <a href="/format/2309.15507" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Approximate Message Passing with Rigorous Guarantees for Pooled Data and  Quantitative Group Testing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tan%2C+N">Nelvin Tan</a>, 
<a href="/search/cs?searchtype=author&query=Scarlett%2C+J">Jonathan Scarlett</a>, 
<a href="/search/cs?searchtype=author&query=Venkataramanan%2C+R">Ramji Venkataramanan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 52 pages, 10 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">In the pooled data problem, the goal is to identify the categories associated
with a large collection of items via a sequence of pooled tests. Each pooled
test reveals the number of items of each category within the pool. We study an
approximate message passing (AMP) algorithm for estimating the categories and
rigorously characterize its performance, in both the noiseless and noisy
settings. For the noiseless setting, we show that the AMP algorithm is
equivalent to one recently proposed by El Alaoui et al. Our results provide a
rigorous version of their performance guarantees, previously obtained via
non-rigorous techniques. For the case of pooled data with two categories, known
as quantitative group testing (QGT), we use the AMP guarantees to compute
precise limiting values of the false positive rate and the false negative rate.
Though the pooled data problem and QGT are both instances of estimation in a
linear model, existing AMP theory cannot be directly applied since the design
matrices are binary valued. The key technical ingredient in our result is a
rigorous analysis of AMP for generalized linear models defined via generalized
white noise design matrices. This result, established using a recent
universality result of Wang et al., is of independent interest. Our theoretical
results are validated by numerical simulations. For comparison, we propose
estimators based on convex relaxation and iterative thresholding, without
providing theoretical guarantees. Our simulations indicate that AMP outperforms
the convex programming estimator for a range of QGT scenarios, but the convex
program performs better for pooled data with three categories.
</p>
</div>
</dd>
<dt><a name="item142">[142]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15508" title="Abstract">arXiv:2309.15508</a> [<a href="/pdf/2309.15508" title="Download PDF">pdf</a>, <a href="/format/2309.15508" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DreamCom: Finetuning Text-guided Inpainting Model for Image Composition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lu%2C+L">Lingxiao Lu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+B">Bo Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Niu%2C+L">Li Niu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">The goal of image composition is merging a foreground object into a
background image to obtain a realistic composite image. Recently, generative
composition methods are built on large pretrained diffusion models, due to
their unprecedented image generation ability. They train a model on abundant
pairs of foregrounds and backgrounds, so that it can be directly applied to a
new pair of foreground and background at test time. However, the generated
results often lose the foreground details and exhibit noticeable artifacts. In
this work, we propose an embarrassingly simple approach named DreamCom inspired
by DreamBooth. Specifically, given a few reference images for a subject, we
finetune text-guided inpainting diffusion model to associate this subject with
a special token and inpaint this subject in the specified bounding box. We also
construct a new dataset named MureCom well-tailored for this task.
</p>
</div>
</dd>
<dt><a name="item143">[143]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15512" title="Abstract">arXiv:2309.15512</a> [<a href="/pdf/2309.15512" title="Download PDF">pdf</a>, <a href="/format/2309.15512" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> High-Fidelity Speech Synthesis with Minimal Supervision: All Using  Diffusion Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Qiang%2C+C">Chunyu Qiang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Hao Li</a>, 
<a href="/search/cs?searchtype=author&query=Tian%2C+Y">Yixin Tian</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Y">Yi Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Ying Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+L">Longbiao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Dang%2C+J">Jianwu Dang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: substantial text overlap with <a href="/abs/2307.15484">arXiv:2307.15484</a>; text overlap with <a href="/abs/2309.00424">arXiv:2309.00424</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">Text-to-speech (TTS) methods have shown promising results in voice cloning,
but they require a large number of labeled text-speech pairs.
Minimally-supervised speech synthesis decouples TTS by combining two types of
discrete speech representations(semantic \&amp; acoustic) and using two
sequence-to-sequence tasks to enable training with minimal supervision.
However, existing methods suffer from information redundancy and dimension
explosion in semantic representation, and high-frequency waveform distortion in
discrete acoustic representation. Autoregressive frameworks exhibit typical
instability and uncontrollability issues. And non-autoregressive frameworks
suffer from prosodic averaging caused by duration prediction models. To address
these issues, we propose a minimally-supervised high-fidelity speech synthesis
method, where all modules are constructed based on the diffusion models. The
non-autoregressive framework enhances controllability, and the duration
diffusion model enables diversified prosodic expression. Contrastive
Token-Acoustic Pretraining (CTAP) is used as an intermediate semantic
representation to solve the problems of information redundancy and dimension
explosion in existing semantic coding methods. Mel-spectrogram is used as the
acoustic representation. Both semantic and acoustic representations are
predicted by continuous variable regression tasks to solve the problem of
high-frequency fine-grained waveform distortion. Experimental results show that
our proposed method outperforms the baseline method. We provide audio samples
on our website.
</p>
</div>
</dd>
<dt><a name="item144">[144]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15515" title="Abstract">arXiv:2309.15515</a> [<a href="/pdf/2309.15515" title="Download PDF">pdf</a>, <a href="/format/2309.15515" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GNN4EEG: A Benchmark and Toolkit for Electroencephalography  Classification with Graph Neural Network
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+K">Kaiyuan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Ye%2C+Z">Ziyi Ye</a>, 
<a href="/search/cs?searchtype=author&query=Ai%2C+Q">Qingyao Ai</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+X">Xiaohui Xie</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yiqun Liu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Multimedia (cs.MM)

</div>
<p class="mathjax">Electroencephalography(EEG) classification is a crucial task in neuroscience,
neural engineering, and several commercial applications. Traditional EEG
classification models, however, have often overlooked or inadequately leveraged
the brain's topological information. Recognizing this shortfall, there has been
a burgeoning interest in recent years in harnessing the potential of Graph
Neural Networks (GNN) to exploit the topological information by modeling
features selected from each EEG channel in a graph structure. To further
facilitate research in this direction, we introduce GNN4EEG, a versatile and
user-friendly toolkit for GNN-based modeling of EEG signals. GNN4EEG comprises
three components: (i)A large benchmark constructed with four EEG classification
tasks based on EEG data collected from 123 participants. (ii)Easy-to-use
implementations on various state-of-the-art GNN-based EEG classification
models, e.g., DGCNN, RGNN, etc. (iii)Implementations of comprehensive
experimental settings and evaluation protocols, e.g., data splitting protocols,
and cross-validation protocols. GNN4EEG is publicly released at
https://github.com/Miracle-2001/GNN4EEG.
</p>
</div>
</dd>
<dt><a name="item145">[145]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15516" title="Abstract">arXiv:2309.15516</a> [<a href="/pdf/2309.15516" title="Download PDF">pdf</a>, <a href="/format/2309.15516" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Teaching Text-to-Image Models to Communicate
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sun%2C+X">Xiaowen Sun</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+J">Jiazhan Feng</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yuxuan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Lai%2C+Y">Yuxuan Lai</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+X">Xingyu Shen</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+D">Dongyan Zhao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Work in progress
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Various works have been extensively studied in the research of text-to-image
generation. Although existing models perform well in text-to-image generation,
there are significant challenges when directly employing them to generate
images in dialogs. In this paper, we first highlight a new problem:
dialog-to-image generation, that is, given the dialog context, the model should
generate a realistic image which is consistent with the specified conversation
as response. To tackle the problem, we propose an efficient approach for
dialog-to-image generation without any intermediate translation, which
maximizes the extraction of the semantic information contained in the dialog.
Considering the characteristics of dialog structure, we put segment token
before each sentence in a turn of a dialog to differentiate different speakers.
Then, we fine-tune pre-trained text-to-image models to enable them to generate
images conditioning on processed dialog context. After fine-tuning, our
approach can consistently improve the performance of various models across
multiple metrics. Experimental results on public benchmark demonstrate the
effectiveness and practicability of our method.
</p>
</div>
</dd>
<dt><a name="item146">[146]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15517" title="Abstract">arXiv:2309.15517</a> [<a href="/pdf/2309.15517" title="Download PDF">pdf</a>, <a href="/format/2309.15517" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Residual Scheduling: A New Reinforcement Learning Approach to Solving  Job Shop Scheduling Problem
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ho%2C+K">Kuo-Hao Ho</a>, 
<a href="/search/cs?searchtype=author&query=Jheng%2C+R">Ruei-Yu Jheng</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+J">Ji-Han Wu</a>, 
<a href="/search/cs?searchtype=author&query=Chiang%2C+F">Fan Chiang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yen-Chi Chen</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Y">Yuan-Yu Wu</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+I">I-Chen Wu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
<p class="mathjax">Job-shop scheduling problem (JSP) is a mathematical optimization problem
widely used in industries like manufacturing, and flexible JSP (FJSP) is also a
common variant. Since they are NP-hard, it is intractable to find the optimal
solution for all cases within reasonable times. Thus, it becomes important to
develop efficient heuristics to solve JSP/FJSP. A kind of method of solving
scheduling problems is construction heuristics, which constructs scheduling
solutions via heuristics. Recently, many methods for construction heuristics
leverage deep reinforcement learning (DRL) with graph neural networks (GNN). In
this paper, we propose a new approach, named residual scheduling, to solving
JSP/FJSP. In this new approach, we remove irrelevant machines and jobs such as
those finished, such that the states include the remaining (or relevant)
machines and jobs only. Our experiments show that our approach reaches
state-of-the-art (SOTA) among all known construction heuristics on most
well-known open JSP and FJSP benchmarks. In addition, we also observe that even
though our model is trained for scheduling problems of smaller sizes, our
method still performs well for scheduling problems of large sizes.
Interestingly in our experiments, our approach even reaches zero gap for 49
among 50 JSP instances whose job numbers are more than 150 on 20 machines.
</p>
</div>
</dd>
<dt><a name="item147">[147]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15518" title="Abstract">arXiv:2309.15518</a> [<a href="/pdf/2309.15518" title="Download PDF">pdf</a>, <a href="/format/2309.15518" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Raij&#x16b;: Reinforcement Learning-Guided Post-Exploitation for Automating  Security Assessment of Network Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pham%2C+V">Van-Hau Pham</a>, 
<a href="/search/cs?searchtype=author&query=Hoang%2C+H+D">Hien Do Hoang</a>, 
<a href="/search/cs?searchtype=author&query=Trung%2C+P+T">Phan Thanh Trung</a>, 
<a href="/search/cs?searchtype=author&query=Quoc%2C+V+D">Van Dinh Quoc</a>, 
<a href="/search/cs?searchtype=author&query=To%2C+T">Trong-Nghia To</a>, 
<a href="/search/cs?searchtype=author&query=Duy%2C+P+T">Phan The Duy</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">In order to assess the risks of a network system, it is important to
investigate the behaviors of attackers after successful exploitation, which is
called post-exploitation. Although there are various efficient tools supporting
post-exploitation implementation, no application can automate this process.
Most of the steps of this process are completed by experts who have profound
knowledge of security, known as penetration testers or pen-testers. To this
end, our study proposes the Raij\=u framework, a Reinforcement Learning
(RL)-driven automation approach that assists pen-testers in quickly
implementing the process of post-exploitation for security-level evaluation in
network systems. We implement two RL algorithms, Advantage Actor-Critic (A2C)
and Proximal Policy Optimization (PPO), to train specialized agents capable of
making intelligent actions, which are Metasploit modules to automatically
launch attacks of privileges escalation, gathering hashdump, and lateral
movement. By leveraging RL, we aim to empower these agents with the ability to
autonomously select and execute actions that can exploit vulnerabilities in
target systems. This approach allows us to automate certain aspects of the
penetration testing workflow, making it more efficient and responsive to
emerging threats and vulnerabilities. The experiments are performed in four
real environments with agents trained in thousands of episodes. The agents
automatically select actions and launch attacks on the environments and achieve
over 84\% of successful attacks with under 55 attack steps given. Moreover, the
A2C algorithm has proved extremely effective in the selection of proper actions
for automation of post-exploitation.
</p>
</div>
</dd>
<dt><a name="item148">[148]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15519" title="Abstract">arXiv:2309.15519</a> [<a href="/pdf/2309.15519" title="Download PDF">pdf</a>, <a href="/format/2309.15519" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Defending Against Physical Adversarial Patch Attacks on Infrared Human  Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Strack%2C+L">Lukas Strack</a>, 
<a href="/search/cs?searchtype=author&query=Waseda%2C+F">Futa Waseda</a>, 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+H+H">Huy H. Nguyen</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+Y">Yinqiang Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Echizen%2C+I">Isao Echizen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Lukas Strack and Futa Waseda contributed equally. 4 pages, 2 figures, Under-review
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Infrared detection is an emerging technique for safety-critical tasks owing
to its remarkable anti-interference capability. However, recent studies have
revealed that it is vulnerable to physically-realizable adversarial patches,
posing risks in its real-world applications. To address this problem, we are
the first to investigate defense strategies against adversarial patch attacks
on infrared detection, especially human detection. We have devised a
straightforward defense strategy, patch-based occlusion-aware detection (POD),
which efficiently augments training samples with random patches and
subsequently detects them. POD not only robustly detects people but also
identifies adversarial patch locations. Surprisingly, while being extremely
computationally efficient, POD easily generalizes to state-of-the-art
adversarial patch attacks that are unseen during training. Furthermore, POD
improves detection precision even in a clean (i.e., no-patch) situation due to
the data augmentation effect. Evaluation demonstrated that POD is robust to
adversarial patches of various shapes and sizes. The effectiveness of our
baseline approach is shown to be a viable defense mechanism for real-world
infrared human detection systems, paving the way for exploring future research
directions.
</p>
</div>
</dd>
<dt><a name="item149">[149]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15520" title="Abstract">arXiv:2309.15520</a> [<a href="/pdf/2309.15520" title="Download PDF">pdf</a>, <a href="/format/2309.15520" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SAF-Net: Self-Attention Fusion Network for Myocardial Infarction  Detection using Multi-View Echocardiography
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Adalioglu%2C+I">Ilke Adalioglu</a>, 
<a href="/search/cs?searchtype=author&query=Ahisali%2C+M">Mete Ahisali</a>, 
<a href="/search/cs?searchtype=author&query=Degerli%2C+A">Aysen Degerli</a>, 
<a href="/search/cs?searchtype=author&query=Kiranyaz%2C+S">Serkan Kiranyaz</a>, 
<a href="/search/cs?searchtype=author&query=Gabbouj%2C+M">Moncef Gabbouj</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 4 pages, 3 figures, Computing in Cardiology (CinC) 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV); Image and Video Processing (eess.IV)

</div>
<p class="mathjax">Myocardial infarction (MI) is a severe case of coronary artery disease (CAD)
and ultimately, its detection is substantial to prevent progressive damage to
the myocardium. In this study, we propose a novel view-fusion model named
self-attention fusion network (SAF-Net) to detect MI from multi-view
echocardiography recordings. The proposed framework utilizes apical 2-chamber
(A2C) and apical 4-chamber (A4C) view echocardiography recordings for
classification. Three reference frames are extracted from each recording of
both views and deployed pre-trained deep networks to extract highly
representative features. The SAF-Net model utilizes a self-attention mechanism
to learn dependencies in extracted feature vectors. The proposed model is
computationally efficient thanks to its compact architecture having three main
parts: a feature embedding to reduce dimensionality, self-attention for
view-pooling, and dense layers for the classification. Experimental evaluation
is performed using the HMC-QU-TAU dataset which consists of 160 patients with
A2C and A4C view echocardiography recordings. The proposed SAF-Net model
achieves a high-performance level with 88.26% precision, 77.64% sensitivity,
and 78.13% accuracy. The results demonstrate that the SAF-Net model achieves
the most accurate MI detection over multi-view echocardiography recordings.
</p>
</div>
</dd>
<dt><a name="item150">[150]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15521" title="Abstract">arXiv:2309.15521</a> [<a href="/pdf/2309.15521" title="Download PDF">pdf</a>, <a href="/format/2309.15521" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MLOps for Scarce Image Data: A Use Case in Microscopic Image Analysis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sitcheu%2C+A+Y">Angelo Yamachui Sitcheu</a>, 
<a href="/search/cs?searchtype=author&query=Friederich%2C+N">Nils Friederich</a>, 
<a href="/search/cs?searchtype=author&query=Baeuerle%2C+S">Simon Baeuerle</a>, 
<a href="/search/cs?searchtype=author&query=Neumann1%2C+O">Oliver Neumann1</a>, 
<a href="/search/cs?searchtype=author&query=Reischl%2C+M">Markus Reischl</a>, 
<a href="/search/cs?searchtype=author&query=Mikut%2C+R">Ralf Mikut</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 21 pages, 5 figures , 33. Workshop on Computational Intelligence Berlin Germany
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV); Image and Video Processing (eess.IV)

</div>
<p class="mathjax">Nowadays, Machine Learning (ML) is experiencing tremendous popularity that
has never been seen before. The operationalization of ML models is governed by
a set of concepts and methods referred to as Machine Learning Operations
(MLOps). Nevertheless, researchers, as well as professionals, often focus more
on the automation aspect and neglect the continuous deployment and monitoring
aspects of MLOps. As a result, there is a lack of continuous learning through
the flow of feedback from production to development, causing unexpected model
deterioration over time due to concept drifts, particularly when dealing with
scarce data. This work explores the complete application of MLOps in the
context of scarce data analysis. The paper proposes a new holistic approach to
enhance biomedical image analysis. Our method includes: a fingerprinting
process that enables selecting the best models, datasets, and model development
strategy relative to the image analysis task at hand; an automated model
development stage; and a continuous deployment and monitoring process to ensure
continuous learning. For preliminary results, we perform a proof of concept for
fingerprinting in microscopic image datasets.
</p>
</div>
</dd>
<dt><a name="item151">[151]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15522" title="Abstract">arXiv:2309.15522</a> [<a href="/pdf/2309.15522" title="Download PDF">pdf</a>, <a href="/ps/2309.15522" title="Download PostScript">ps</a>, <a href="/format/2309.15522" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Robust Internal Representations for Domain Generalization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rostami%2C+M">Mohammad Rostami</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> to appear in AI Magazine Winter 2023 Issue
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">This paper which is part of the New Faculty Highlights Invited Speaker
Program of AAAI'23, serves as a comprehensive survey of my research in transfer
learning by utilizing embedding spaces. The work reviewed in this paper
specifically revolves around the inherent challenges associated with continual
learning and limited availability of labeled data. By providing an overview of
my past and ongoing contributions, this paper aims to present a holistic
understanding of my research, paving the way for future explorations and
advancements in the field. My research delves into the various settings of
transfer learning, including, few-shot learning, zero-shot learning, continual
learning, domain adaptation, and distributed learning. I hope this survey
provides a forward-looking perspective for researchers who would like to focus
on similar research directions.
</p>
</div>
</dd>
<dt><a name="item152">[152]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15523" title="Abstract">arXiv:2309.15523</a> [<a href="/pdf/2309.15523" title="Download PDF">pdf</a>, <a href="/format/2309.15523" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Improving Facade Parsing with Vision Transformers and Line Integration
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+B">Bowen Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jiaxing Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+R">Ran Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yunqin Li</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+L">Liangzhi Li</a>, 
<a href="/search/cs?searchtype=author&query=Nakashima%2C+Y">Yuta Nakashima</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, 7 figures, 9 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Facade parsing stands as a pivotal computer vision task with far-reaching
applications in areas like architecture, urban planning, and energy efficiency.
Despite the recent success of deep learning-based methods in yielding
impressive results on certain open-source datasets, their viability for
real-world applications remains uncertain. Real-world scenarios are
considerably more intricate, demanding greater computational efficiency.
Existing datasets often fall short in representing these settings, and previous
methods frequently rely on extra models to enhance accuracy, which requires
much computation cost. In this paper, we introduce Comprehensive Facade Parsing
(CFP), a dataset meticulously designed to encompass the intricacies of
real-world facade parsing tasks. Comprising a total of 602 high-resolution
street-view images, this dataset captures a diverse array of challenging
scenarios, including sloping angles and densely clustered buildings, with
painstakingly curated annotations for each image. We introduce a new pipeline
known as Revision-based Transformer Facade Parsing (RTFP). This marks the
pioneering utilization of Vision Transformers (ViT) in facade parsing, and our
experimental results definitively substantiate its merit. We also design Line
Acquisition, Filtering, and Revision (LAFR), an efficient yet accurate revision
algorithm that can improve the segment result solely from simple line detection
using prior knowledge of the facade. In ECP 2011, RueMonge 2014, and our CFP,
we evaluate the superiority of our method. The dataset and code are available
at https://github.com/wbw520/RTFP.
</p>
</div>
</dd>
<dt><a name="item153">[153]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15525" title="Abstract">arXiv:2309.15525</a> [<a href="/pdf/2309.15525" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Cyber Security Requirements for Platforms Enhancing AI Reproducibility
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Falade%2C+P+V">Polra Victor Falade</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> IEEE-SEM, Volume 11, Issue 9, September-2023 ISSN 2320-9151
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Scientific research is increasingly reliant on computational methods, posing
challenges for ensuring research reproducibility. This study focuses on the
field of artificial intelligence (AI) and introduces a new framework for
evaluating AI platforms for reproducibility from a cyber security standpoint to
address the security challenges associated with AI research. Using this
framework, five popular AI reproducibility platforms; Floydhub, BEAT, Codalab,
Kaggle, and OpenML were assessed. The analysis revealed that none of these
platforms fully incorporates the necessary cyber security measures essential
for robust reproducibility. Kaggle and Codalab, however, performed better in
terms of implementing cyber security measures covering aspects like security,
privacy, usability, and trust. Consequently, the study provides tailored
recommendations for different user scenarios, including individual researchers,
small laboratories, and large corporations. It emphasizes the importance of
integrating specific cyber security features into AI platforms to address the
challenges associated with AI reproducibility, ultimately advancing
reproducibility in this field. Moreover, the proposed framework can be applied
beyond AI platforms, serving as a versatile tool for evaluating a wide range of
systems and applications from a cyber security perspective.
</p>
</div>
</dd>
<dt><a name="item154">[154]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15526" title="Abstract">arXiv:2309.15526</a> [<a href="/pdf/2309.15526" title="Download PDF">pdf</a>, <a href="/format/2309.15526" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> P2I-NET: Mapping Camera Pose to Image via Adversarial Learning for New  View Synthesis in Real Indoor Environments
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kang%2C+X">Xujie Kang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+K">Kanglin Liu</a>, 
<a href="/search/cs?searchtype=author&query=Duan%2C+J">Jiang Duan</a>, 
<a href="/search/cs?searchtype=author&query=Gong%2C+Y">Yuanhao Gong</a>, 
<a href="/search/cs?searchtype=author&query=Qiu%2C+G">Guoping Qiu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Given a new $6DoF$ camera pose in an indoor environment, we study the
challenging problem of predicting the view from that pose based on a set of
reference RGBD views. Existing explicit or implicit 3D geometry construction
methods are computationally expensive while those based on learning have
predominantly focused on isolated views of object categories with regular
geometric structure. Differing from the traditional \textit{render-inpaint}
approach to new view synthesis in the real indoor environment, we propose a
conditional generative adversarial neural network (P2I-NET) to directly predict
the new view from the given pose. P2I-NET learns the conditional distribution
of the images of the environment for establishing the correspondence between
the camera pose and its view of the environment, and achieves this through a
number of innovative designs in its architecture and training lost function.
Two auxiliary discriminator constraints are introduced for enforcing the
consistency between the pose of the generated image and that of the
corresponding real world image in both the latent feature space and the real
world pose space. Additionally a deep convolutional neural network (CNN) is
introduced to further reinforce this consistency in the pixel space. We have
performed extensive new view synthesis experiments on real indoor datasets.
Results show that P2I-NET has superior performance against a number of NeRF
based strong baseline models. In particular, we show that P2I-NET is 40 to 100
times faster than these competitor techniques while synthesising similar
quality images. Furthermore, we contribute a new publicly available indoor
environment dataset containing 22 high resolution RGBD videos where each frame
also has accurate camera pose parameters.
</p>
</div>
</dd>
<dt><a name="item155">[155]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15531" title="Abstract">arXiv:2309.15531</a> [<a href="/pdf/2309.15531" title="Download PDF">pdf</a>, <a href="/format/2309.15531" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Rethinking Channel Dimensions to Isolate Outliers for Low-bit Weight  Quantization of Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Heo%2C+J+H">Jung Hwan Heo</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+J">Jeonghoon Kim</a>, 
<a href="/search/cs?searchtype=author&query=Kwon%2C+B">Beomseok Kwon</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+B">Byeongwook Kim</a>, 
<a href="/search/cs?searchtype=author&query=Kwon%2C+S+J">Se Jung Kwon</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+D">Dongsoo Lee</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 17 pages, 10 figures, 7 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Large Language Models (LLMs) have recently demonstrated a remarkable success
across various tasks. However, efficiently serving LLMs has been a challenge
due to its large memory bottleneck, specifically in small batch inference
settings (e.g. mobile devices). Weight-only quantization can be a promising
approach, but sub-4 bit quantization remains a challenge due to large-magnitude
activation outliers. To mitigate the undesirable outlier effect, we first
propose per-IC quantization, a simple yet effective method that creates
quantization groups within each input channel (IC) rather than the conventional
per-output channel (OC). Our method is motivated by the observation that
activation outliers affect the input dimension of the weight matrix, so
similarly grouping the weights in the IC direction can isolate outliers to be
within a group. We also find that activation outliers do not dictate
quantization difficulty, and inherent weight sensitivities also exist. With
per-IC quantization as a new outlier-friendly scheme, we then propose Adaptive
Dimensions (AdaDim), a versatile quantization framework that can adapt to
various weight sensitivity patterns. We demonstrate the effectiveness of AdaDim
by augmenting prior methods such as Round-To-Nearest and GPTQ, showing
significant improvements across various language modeling benchmarks for both
base (up to +4.7% on MMLU) and instruction-tuned (up to +10% on HumanEval)
LLMs.
</p>
</div>
</dd>
<dt><a name="item156">[156]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15533" title="Abstract">arXiv:2309.15533</a> [<a href="/pdf/2309.15533" title="Download PDF">pdf</a>, <a href="/format/2309.15533" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Uncertainty Quantification via Neural Posterior Principal Components
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nehme%2C+E">Elias Nehme</a>, 
<a href="/search/cs?searchtype=author&query=Yair%2C+O">Omer Yair</a>, 
<a href="/search/cs?searchtype=author&query=Michaeli%2C+T">Tomer Michaeli</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to NeurIPS 2023, webpage at <a href="https://eliasnehme.github.io/NPPC/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG); Image and Video Processing (eess.IV); Machine Learning (stat.ML)

</div>
<p class="mathjax">Uncertainty quantification is crucial for the deployment of image restoration
models in safety-critical domains, like autonomous driving and biological
imaging. To date, methods for uncertainty visualization have mainly focused on
per-pixel estimates. However, a heatmap of per-pixel variances is typically of
little practical use, as it does not capture the strong correlations between
pixels. A more natural measure of uncertainty corresponds to the variances
along the principal components (PCs) of the posterior distribution.
Theoretically, the PCs can be computed by applying PCA on samples generated
from a conditional generative model for the input image. However, this requires
generating a very large number of samples at test time, which is painfully slow
with the current state-of-the-art (diffusion) models. In this work, we present
a method for predicting the PCs of the posterior distribution for any input
image, in a single forward pass of a neural network. Our method can either wrap
around a pre-trained model that was trained to minimize the mean square error
(MSE), or can be trained from scratch to output both a predicted image and the
posterior PCs. We showcase our method on multiple inverse problems in imaging,
including denoising, inpainting, super-resolution, and biological
image-to-image translation. Our method reliably conveys instance-adaptive
uncertainty directions, achieving uncertainty quantification comparable with
posterior samplers while being orders of magnitude faster. Examples are
available at https://eliasnehme.github.io/NPPC/
</p>
</div>
</dd>
<dt><a name="item157">[157]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15535" title="Abstract">arXiv:2309.15535</a> [<a href="/pdf/2309.15535" title="Download PDF">pdf</a>, <a href="/format/2309.15535" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> From LAION-5B to LAION-EO: Filtering Billions of Images Using Anchor  Datasets for Satellite Image Extraction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Czerkawski%2C+M">Mikolaj Czerkawski</a>, 
<a href="/search/cs?searchtype=author&query=Francis%2C+A">Alistair Francis</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at the ICCV 2023 Workshop "Towards the Next Generation of Computer Vision Datasets: DataComp Track"
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Large datasets, such as LAION-5B, contain a diverse distribution of images
shared online. However, extraction of domain-specific subsets of large image
corpora is challenging. The extraction approach based on an anchor dataset,
combined with further filtering, is proposed here and demonstrated for the
domain of satellite imagery. This results in the release of LAION-EO, a dataset
sourced from the web containing pairs of text and satellite images in high
(pixel-wise) resolution. The paper outlines the acquisition procedure as well
as some of the features of the dataset.
</p>
</div>
</dd>
<dt><a name="item158">[158]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15551" title="Abstract">arXiv:2309.15551</a> [<a href="/pdf/2309.15551" title="Download PDF">pdf</a>, <a href="/format/2309.15551" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Identifying confounders in deep-learning-based model predictions using  DeepRepViz
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rane%2C+R+P">Roshan Prakash Rane</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+J">JiHoon Kim</a>, 
<a href="/search/cs?searchtype=author&query=Umesha%2C+A">Arjun Umesha</a>, 
<a href="/search/cs?searchtype=author&query=Stark%2C+D">Didem Stark</a>, 
<a href="/search/cs?searchtype=author&query=Schulz%2C+M">Marc-Andr&#xe9; Schulz</a>, 
<a href="/search/cs?searchtype=author&query=Ritter%2C+K">Kerstin Ritter</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Deep Learning (DL) models are increasingly used to analyze neuroimaging data
and uncover insights about the brain, brain pathologies, and psychological
traits. However, extraneous `confounders' variables such as the age of the
participants, sex, or imaging artifacts can bias model predictions, preventing
the models from learning relevant brain-phenotype relationships. In this study,
we provide a solution called the `DeepRepViz' framework that enables
researchers to systematically detect confounders in their DL model predictions.
The framework consists of (1) a metric that quantifies the effect of potential
confounders and (2) a visualization tool that allows researchers to
qualitatively inspect what the DL model is learning. By performing experiments
on simulated and neuroimaging datasets, we demonstrate the benefits of using
DeepRepViz in combination with DL models. For example, experiments on the
neuroimaging datasets reveal that sex is a significant confounder in a DL model
predicting chronic alcohol users (Con-score=0.35). Similarly, DeepRepViz
identifies age as a confounder in a DL model predicting participants'
performance on a cognitive task (Con-score=0.3). Overall, DeepRepViz enables
researchers to systematically test for potential confounders and expose DL
models that rely on extraneous information such as age, sex, or imaging
artifacts.
</p>
</div>
</dd>
<dt><a name="item159">[159]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15552" title="Abstract">arXiv:2309.15552</a> [<a href="/pdf/2309.15552" title="Download PDF">pdf</a>, <a href="/format/2309.15552" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Startup success prediction and VC portfolio simulation using CrunchBase  data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Potanin%2C+M">Mark Potanin</a>, 
<a href="/search/cs?searchtype=author&query=Chertok%2C+A">Andrey Chertok</a>, 
<a href="/search/cs?searchtype=author&query=Zorin%2C+K">Konstantin Zorin</a>, 
<a href="/search/cs?searchtype=author&query=Shtabtsovsky%2C+C">Cyril Shtabtsovsky</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, preprint
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computational Engineering, Finance, and Science (cs.CE); Computational Finance (q-fin.CP)

</div>
<p class="mathjax">Predicting startup success presents a formidable challenge due to the
inherently volatile landscape of the entrepreneurial ecosystem. The advent of
extensive databases like Crunchbase jointly with available open data enables
the application of machine learning and artificial intelligence for more
accurate predictive analytics. This paper focuses on startups at their Series B
and Series C investment stages, aiming to predict key success milestones such
as achieving an Initial Public Offering (IPO), attaining unicorn status, or
executing a successful Merger and Acquisition (M\&amp;A). We introduce novel deep
learning model for predicting startup success, integrating a variety of factors
such as funding metrics, founder features, industry category. A distinctive
feature of our research is the use of a comprehensive backtesting algorithm
designed to simulate the venture capital investment process. This simulation
allows for a robust evaluation of our model's performance against historical
data, providing actionable insights into its practical utility in real-world
investment contexts. Evaluating our model on Crunchbase's, we achieved a 14
times capital growth and successfully identified on B round high-potential
startups including Revolut, DigitalOcean, Klarna, Github and others. Our
empirical findings illuminate the importance of incorporating diverse feature
sets in enhancing the model's predictive accuracy. In summary, our work
demonstrates the considerable promise of deep learning models and alternative
unstructured data in predicting startup success and sets the stage for future
advancements in this research area.
</p>
</div>
</dd>
<dt><a name="item160">[160]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15554" title="Abstract">arXiv:2309.15554</a> [<a href="/pdf/2309.15554" title="Download PDF">pdf</a>, <a href="/format/2309.15554" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Direct Models for Simultaneous Translation and Automatic Subtitling:  FBK@IWSLT2023
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Papi%2C+S">Sara Papi</a>, 
<a href="/search/cs?searchtype=author&query=Gaido%2C+M">Marco Gaido</a>, 
<a href="/search/cs?searchtype=author&query=Negri%2C+M">Matteo Negri</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Published at IWSTL 2023
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Proceedings of the 20th International Conference on Spoken
  Language Translation (IWSLT 2023), pages 159-168, Toronto, Canada (in-person
  and online). Association for Computational Linguistics
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Sound (cs.SD); Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">This paper describes the FBK's participation in the Simultaneous Translation
and Automatic Subtitling tracks of the IWSLT 2023 Evaluation Campaign. Our
submission focused on the use of direct architectures to perform both tasks:
for the simultaneous one, we leveraged the knowledge already acquired by
offline-trained models and directly applied a policy to obtain the real-time
inference; for the subtitling one, we adapted the direct ST model to produce
well-formed subtitles and exploited the same architecture to produce timestamps
needed for the subtitle synchronization with audiovisual content. Our
English-German SimulST system shows a reduced computational-aware latency
compared to the one achieved by the top-ranked systems in the 2021 and 2022
rounds of the task, with gains of up to 3.5 BLEU. Our automatic subtitling
system outperforms the only existing solution based on a direct system by 3.7
and 1.7 SubER in English-German and English-Spanish respectively.
</p>
</div>
</dd>
<dt><a name="item161">[161]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15555" title="Abstract">arXiv:2309.15555</a> [<a href="/pdf/2309.15555" title="Download PDF">pdf</a>, <a href="/format/2309.15555" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Low Latency of object detection for spikng neural network
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Qiu%2C+N">Nemin Qiu</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+C">Chuang Zhu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Spiking Neural Networks, as a third-generation neural network, are
well-suited for edge AI applications due to their binary spike nature. However,
when it comes to complex tasks like object detection, SNNs often require a
substantial number of time steps to achieve high performance. This limitation
significantly hampers the widespread adoption of SNNs in latency-sensitive edge
devices. In this paper, our focus is on generating highly accurate and
low-latency SNNs specifically for object detection. Firstly, we systematically
derive the conversion between SNNs and ANNs and analyze how to improve the
consistency between them: improving the spike firing rate and reducing the
quantization error. Then we propose a structural replacement, quantization of
ANN activation and residual fix to allevicate the disparity. We evaluate our
method on challenging dataset MS COCO, PASCAL VOC and our spike dataset. The
experimental results show that the proposed method achieves higher accuracy and
lower latency compared to previous work Spiking-YOLO. The advantages of SNNs
processing of spike signals are also demonstrated.
</p>
</div>
</dd>
<dt><a name="item162">[162]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15556" title="Abstract">arXiv:2309.15556</a> [<a href="/pdf/2309.15556" title="Download PDF">pdf</a>, <a href="/format/2309.15556" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning Dense Flow Field for Highly-accurate Cross-view Camera  Localization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Song%2C+Z">Zhenbo Song</a>, 
<a href="/search/cs?searchtype=author&query=Ze%2C+X">Xianghui Ze</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+J">Jianfeng Lu</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+Y">Yujiao Shi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">This paper addresses the problem of estimating the 3-DoF camera pose for a
ground-level image with respect to a satellite image that encompasses the local
surroundings. We propose a novel end-to-end approach that leverages the
learning of dense pixel-wise flow fields in pairs of ground and satellite
images to calculate the camera pose. Our approach differs from existing methods
by constructing the feature metric at the pixel level, enabling full-image
supervision for learning distinctive geometric configurations and visual
appearances across views. Specifically, our method employs two distinct
convolution networks for ground and satellite feature extraction. Then, we
project the ground feature map to the bird's eye view (BEV) using a fixed
camera height assumption to achieve preliminary geometric alignment. To further
establish content association between the BEV and satellite features, we
introduce a residual convolution block to refine the projected BEV feature.
Optical flow estimation is performed on the refined BEV feature map and the
satellite feature map using flow decoder networks based on RAFT. After
obtaining dense flow correspondences, we apply the least square method to
filter matching inliers and regress the ground camera pose. Extensive
experiments demonstrate significant improvements compared to state-of-the-art
methods. Notably, our approach reduces the median localization error by 89%,
19%, 80% and 35% on the KITTI, Ford multi-AV, VIGOR and Oxford RobotCar
datasets, respectively.
</p>
</div>
</dd>
<dt><a name="item163">[163]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15559" title="Abstract">arXiv:2309.15559</a> [<a href="/pdf/2309.15559" title="Download PDF">pdf</a>, <a href="/format/2309.15559" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Faithful Neural Network Intrinsic Interpretation with Shapley  Additive Self-Attribution
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sun%2C+Y">Ying Sun</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+H">Hengshu Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Xiong%2C+H">Hui Xiong</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Self-interpreting neural networks have garnered significant interest in
research. Existing works in this domain often (1) lack a solid theoretical
foundation ensuring genuine interpretability or (2) compromise model
expressiveness. In response, we formulate a generic Additive Self-Attribution
(ASA) framework. Observing the absence of Shapley value in Additive
Self-Attribution, we propose Shapley Additive Self-Attributing Neural Network
(SASANet), with theoretical guarantees for the self-attribution value equal to
the output's Shapley values. Specifically, SASANet uses a marginal
contribution-based sequential schema and internal distillation-based training
strategies to model meaningful outputs for any number of features, resulting in
un-approximated meaningful value function. Our experimental results indicate
SASANet surpasses existing self-attributing models in performance and rivals
black-box models. Moreover, SASANet is shown more precise and efficient than
post-hoc methods in interpreting its own predictions.
</p>
</div>
</dd>
<dt><a name="item164">[164]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15560" title="Abstract">arXiv:2309.15560</a> [<a href="/pdf/2309.15560" title="Download PDF">pdf</a>, <a href="/format/2309.15560" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Identifiability Matters: Revealing the Hidden Recoverable Condition in  Unbiased Learning to Rank
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+M">Mouxiang Chen</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+C">Chenghao Liu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zemin Liu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zhuo Li</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+J">Jianling Sun</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">The application of Unbiased Learning to Rank (ULTR) is widespread in modern
systems for training unbiased ranking models from biased click logs. The key is
to explicitly model a generation process for user behavior and fit click data
based on examination hypothesis. Previous research found empirically that the
true latent relevance can be recovered in most cases as long as the clicks are
perfectly fitted. However, we demonstrate that this is not always achievable,
resulting in a significant reduction in ranking performance. In this work, we
aim to answer if or when the true relevance can be recovered from click data,
which is a foundation issue for ULTR field. We first define a ranking model as
identifiable if it can recover the true relevance up to a scaling
transformation, which is enough for pairwise ranking objective. Then we explore
an equivalent condition for identifiability that can be novely expressed as a
graph connectivity test problem: if and only if a graph (namely identifiability
graph, or IG) constructed on the underlying structure of the dataset is
connected, we can guarantee that the relevance can be correctly recovered. When
the IG is not connected, there may be bad cases leading to poor ranking
performance. To address this issue, we propose two methods, namely node
intervention and node merging, to modify the dataset and restore connectivity
of the IG. Empirical results obtained on a simulation dataset and two LTR
benchmark datasets confirm the validity of our proposed theorems and show the
effectiveness of our methods in mitigating data bias when the relevance model
is unidentifiable.
</p>
</div>
</dd>
<dt><a name="item165">[165]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15562" title="Abstract">arXiv:2309.15562</a> [<a href="/pdf/2309.15562" title="Download PDF">pdf</a>, <a href="/format/2309.15562" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning from SAM: Harnessing a Segmentation Foundation Model for  Sim2Real Domain Adaptation through Regularization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bonani%2C+M+E">Mayara E. Bonani</a>, 
<a href="/search/cs?searchtype=author&query=Schwarz%2C+M">Max Schwarz</a>, 
<a href="/search/cs?searchtype=author&query=Behnke%2C+S">Sven Behnke</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Domain adaptation is especially important for robotics applications, where
target domain training data is usually scarce and annotations are costly to
obtain. We present a method for self-supervised domain adaptation for the
scenario where annotated source domain data (e.g. from synthetic generation) is
available, but the target domain data is completely unannotated. Our method
targets the semantic segmentation task and leverages a segmentation foundation
model (Segment Anything Model) to obtain segment information on unannotated
data. We take inspiration from recent advances in unsupervised local feature
learning and propose an invariance-variance loss structure over the detected
segments for regularizing feature representations in the target domain.
Crucially, this loss structure and network architecture can handle overlapping
segments and oversegmentation as produced by Segment Anything. We demonstrate
the advantage of our method on the challenging YCB-Video and HomebrewedDB
datasets and show that it outperforms prior work and, on YCB-Video, even a
network trained with real annotations.
</p>
</div>
</dd>
<dt><a name="item166">[166]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15563" title="Abstract">arXiv:2309.15563</a> [<a href="/pdf/2309.15563" title="Download PDF">pdf</a>, <a href="/format/2309.15563" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Guided Frequency Loss for Image Restoration
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Benjdiraa%2C+B">Bilel Benjdiraa</a>, 
<a href="/search/cs?searchtype=author&query=Alia%2C+A+M">Anas M. Alia</a>, 
<a href="/search/cs?searchtype=author&query=Koubaa%2C+A">Anis Koubaa</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Image and Video Processing (eess.IV)

</div>
<p class="mathjax">Image Restoration has seen remarkable progress in recent years. Many
generative models have been adapted to tackle the known restoration cases of
images. However, the interest in benefiting from the frequency domain is not
well explored despite its major factor in these particular cases of image
synthesis. In this study, we propose the Guided Frequency Loss (GFL), which
helps the model to learn in a balanced way the image's frequency content
alongside the spatial content. It aggregates three major components that work
in parallel to enhance learning efficiency; a Charbonnier component, a
Laplacian Pyramid component, and a Gradual Frequency component. We tested GFL
on the Super Resolution and the Denoising tasks. We used three different
datasets and three different architectures for each of them. We found that the
GFL loss improved the PSNR metric in most implemented experiments. Also, it
improved the training of the Super Resolution models in both SwinIR and SRGAN.
In addition, the utility of the GFL loss increased better on constrained data
due to the less stochasticity in the high frequencies' components among
samples.
</p>
</div>
</dd>
<dt><a name="item167">[167]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15564" title="Abstract">arXiv:2309.15564</a> [<a href="/pdf/2309.15564" title="Download PDF">pdf</a>, <a href="/format/2309.15564" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Jointly Training Large Autoregressive Multimodal Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Aiello%2C+E">Emanuele Aiello</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+L">Lili Yu</a>, 
<a href="/search/cs?searchtype=author&query=Nie%2C+Y">Yixin Nie</a>, 
<a href="/search/cs?searchtype=author&query=Aghajanyan%2C+A">Armen Aghajanyan</a>, 
<a href="/search/cs?searchtype=author&query=Oguz%2C+B">Barlas Oguz</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computation and Language (cs.CL); Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">In recent years, advances in the large-scale pretraining of language and
text-to-image models have revolutionized the field of machine learning. Yet,
integrating these two modalities into a single, robust model capable of
generating seamless multimodal outputs remains a significant challenge. To
address this gap, we present the Joint Autoregressive Mixture (JAM) framework,
a modular approach that systematically fuses existing text and image generation
models. We also introduce a specialized, data-efficient instruction-tuning
strategy, tailored for mixed-modal generation tasks. Our final instruct-tuned
model demonstrates unparalleled performance in generating high-quality
multimodal outputs and represents the first model explicitly designed for this
purpose.
</p>
</div>
</dd>
<dt><a name="item168">[168]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15569" title="Abstract">arXiv:2309.15569</a> [<a href="/pdf/2309.15569" title="Download PDF">pdf</a>, <a href="/format/2309.15569" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Grain-128PLE: Generic Physical-Layer Encryption for IoT Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=de+Ree%2C+M">Marcus de Ree</a>, 
<a href="/search/cs?searchtype=author&query=Mantas%2C+G">Georgios Mantas</a>, 
<a href="/search/cs?searchtype=author&query=Rodriguez%2C+J">Jonathan Rodriguez</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Paper accepted to the GLOBECOM 2023 conference
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">Physical layer security (PLS) encompasses techniques proposed at the physical
layer to achieve information security objectives while requiring a minimal
resource footprint. The channel coding-based secrecy and signal
modulation-based encryption approaches are reliant on certain channel
conditions or a certain communications protocol stack to operate on, which
prevents them from being a generic solution. This paper presents Grain-128PLE,
a lightweight physical layer encryption (PLE) scheme that is derived from the
Grain-128AEAD v2 stream cipher. The Grain-128PLE stream cipher performs
encryption and decryption at the physical layer, in between the channel coding
and signal modulation processes. This placement, like that of the A5 stream
cipher that had been used in the GSM communications standard, makes it a
generic solution for providing data confidentiality in IoT networks. The design
of Grain-128PLE maintains the structure of the main building blocks of the
original Grain-128AEAD v2 stream cipher, evaluated for its security strength
during NIST's recent Lightweight Cryptography competition, and is therefore
expected to achieve similar levels of security.
</p>
</div>
</dd>
<dt><a name="item169">[169]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15572" title="Abstract">arXiv:2309.15572</a> [<a href="/pdf/2309.15572" title="Download PDF">pdf</a>, <a href="/format/2309.15572" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> HPL-ViT: A Unified Perception Framework for Heterogeneous Parallel  LiDARs in V2V
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yuhang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+B">Boyi Sun</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yuke Li</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+Y">Yuzheng Hu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+F">Fei-Yue Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">To develop the next generation of intelligent LiDARs, we propose a novel
framework of parallel LiDARs and construct a hardware prototype in our
experimental platform, DAWN (Digital Artificial World for Natural). It
emphasizes the tight integration of physical and digital space in LiDAR
systems, with networking being one of its supported core features. In the
context of autonomous driving, V2V (Vehicle-to-Vehicle) technology enables
efficient information sharing between different agents which significantly
promotes the development of LiDAR networks. However, current research operates
under an ideal situation where all vehicles are equipped with identical LiDAR,
ignoring the diversity of LiDAR categories and operating frequencies. In this
paper, we first utilize OpenCDA and RLS (Realistic LiDAR Simulation) to
construct a novel heterogeneous LiDAR dataset named OPV2V-HPL. Additionally, we
present HPL-ViT, a pioneering architecture designed for robust feature fusion
in heterogeneous and dynamic scenarios. It uses a graph-attention Transformer
to extract domain-specific features for each agent, coupled with a
cross-attention mechanism for the final fusion. Extensive experiments on
OPV2V-HPL demonstrate that HPL-ViT achieves SOTA (state-of-the-art) performance
in all settings and exhibits outstanding generalization capabilities.
</p>
</div>
</dd>
<dt><a name="item170">[170]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15573" title="Abstract">arXiv:2309.15573</a> [<a href="/pdf/2309.15573" title="Download PDF">pdf</a>, <a href="/format/2309.15573" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Maximum Cover with Rotating Field of View
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Potapov%2C+I">Igor Potapov</a>, 
<a href="/search/cs?searchtype=author&query=Ralph%2C+J">Jason Ralph</a>, 
<a href="/search/cs?searchtype=author&query=Triommatis%2C+T">Theofilos Triommatis</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Geometry (cs.CG)</span>; Computer Vision and Pattern Recognition (cs.CV); Algebraic Geometry (math.AG)

</div>
<p class="mathjax">Imagine a polygon-shaped platform $P$ and only one static spotlight outside
$P$; which direction should the spotlight face to light most of $P$? This
problem occurs in maximising the visibility, as well as in limiting the
uncertainty in localisation problems. More formally, we define the following
maximum cover problem: "Given a convex polygon $P$ and a Field Of View (FOV)
with a given centre and inner angle $\phi$; find the direction (an angle of
rotation $\theta$) of the FOV such that the intersection between the FOV and
$P$ has the maximum area". In this paper, we provide the theoretical foundation
for the analysis of the maximum cover with a rotating field of view. The main
challenge is that the function of the area $A_{\phi}(\theta)$, with the angle
of rotation $\theta$ and the fixed inner angle $\phi$, cannot be approximated
directly. We found an alternative way to express it by various compositions of
a function $A_{\theta}(\phi)$ (with a restricted inner angle $\phi$ and a fixed
direction $\theta$). We show that $A_{\theta}(\phi)$ has an analytical solution
in the special case of a two-sector intersection and later provides a
constrictive solution for the original problem. Since the optimal solution is a
real number, we develop an algorithm that approximates the direction of the
field of view, with precision $\varepsilon$, and complexity
$\mathcal{O}(n(\log{n}+(\log{\varepsilon})/\phi))$.
</p>
</div>
</dd>
<dt><a name="item171">[171]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15575" title="Abstract">arXiv:2309.15575</a> [<a href="/pdf/2309.15575" title="Download PDF">pdf</a>, <a href="/format/2309.15575" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Confidence-based Visual Dispersal for Few-shot Unsupervised Domain  Adaptation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xiong%2C+Y">Yizhe Xiong</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+H">Hui Chen</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+Z">Zijia Lin</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+S">Sicheng Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Ding%2C+G">Guiguang Ding</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted as ICCV 2023 poster
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Unsupervised domain adaptation aims to transfer knowledge from a
fully-labeled source domain to an unlabeled target domain. However, in
real-world scenarios, providing abundant labeled data even in the source domain
can be infeasible due to the difficulty and high expense of annotation. To
address this issue, recent works consider the Few-shot Unsupervised Domain
Adaptation (FUDA) where only a few source samples are labeled, and conduct
knowledge transfer via self-supervised learning methods. Yet existing methods
generally overlook that the sparse label setting hinders learning reliable
source knowledge for transfer. Additionally, the learning difficulty difference
in target samples is different but ignored, leaving hard target samples poorly
classified. To tackle both deficiencies, in this paper, we propose a novel
Confidence-based Visual Dispersal Transfer learning method (C-VisDiT) for FUDA.
Specifically, C-VisDiT consists of a cross-domain visual dispersal strategy
that transfers only high-confidence source knowledge for model adaptation and
an intra-domain visual dispersal strategy that guides the learning of hard
target samples with easy ones. We conduct extensive experiments on Office-31,
Office-Home, VisDA-C, and DomainNet benchmark datasets and the results
demonstrate that the proposed C-VisDiT significantly outperforms
state-of-the-art FUDA methods. Our code is available at
https://github.com/Bostoncake/C-VisDiT.
</p>
</div>
</dd>
<dt><a name="item172">[172]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15576" title="Abstract">arXiv:2309.15576</a> [<a href="/pdf/2309.15576" title="Download PDF">pdf</a>, <a href="/format/2309.15576" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning Spatial-Temporal Regularized Tensor Sparse RPCA for Background  Subtraction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Alawode%2C+B">Basit Alawode</a>, 
<a href="/search/cs?searchtype=author&query=Javed%2C+S">Sajid Javed</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Under review
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Video background subtraction is one of the fundamental problems in computer
vision that aims to segment all moving objects. Robust principal component
analysis has been identified as a promising unsupervised paradigm for
background subtraction tasks in the last decade thanks to its competitive
performance in a number of benchmark datasets. Tensor robust principal
component analysis variations have improved background subtraction performance
further. However, because moving object pixels in the sparse component are
treated independently and do not have to adhere to spatial-temporal
structured-sparsity constraints, performance is reduced for sequences with
dynamic backgrounds, camouflaged, and camera jitter problems. In this work, we
present a spatial-temporal regularized tensor sparse RPCA algorithm for precise
background subtraction. Within the sparse component, we impose spatial-temporal
regularizations in the form of normalized graph-Laplacian matrices. To do this,
we build two graphs, one across the input tensor spatial locations and the
other across its frontal slices in the time domain. While maximizing the
objective function, we compel the tensor sparse component to serve as the
spatiotemporal eigenvectors of the graph-Laplacian matrices. The disconnected
moving object pixels in the sparse component are preserved by the proposed
graph-based regularizations since they both comprise of spatiotemporal
subspace-based structure. Additionally, we propose a unique objective function
that employs batch and online-based optimization methods to jointly maximize
the background-foreground and spatial-temporal regularization components.
Experiments are performed on six publicly available background subtraction
datasets that demonstrate the superior performance of the proposed algorithm
compared to several existing methods. Our source code will be available very
soon.
</p>
</div>
</dd>
<dt><a name="item173">[173]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15577" title="Abstract">arXiv:2309.15577</a> [<a href="/pdf/2309.15577" title="Download PDF">pdf</a>, <a href="/format/2309.15577" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An Evaluation of ChatGPT-4&#x27;s Qualitative Spatial Reasoning Capabilities  in RCC-8
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cohn%2C+A+G">Anthony G Cohn</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 figures. 8 pages. Accepted for presentation at 36th International Workshop on Qualitative Reasoning (QR-23), in conjunction with ECAI2023 in Krakow, Poland
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
<p class="mathjax">Qualitative Spatial Reasoning (QSR) is well explored area of Commonsense
Reasoning and has multiple applications ranging from Geographical Information
Systems to Robotics and Computer Vision. Recently many claims have been made
for the capabilities of Large Language Models (LLMs). In this paper we
investigate the extent to which one particular LLM can perform classical
qualitative spatial reasoning tasks on the mereotopological calculus, RCC-8.
</p>
</div>
</dd>
<dt><a name="item174">[174]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15578" title="Abstract">arXiv:2309.15578</a> [<a href="/pdf/2309.15578" title="Download PDF">pdf</a>, <a href="/ps/2309.15578" title="Download PostScript">ps</a>, <a href="/format/2309.15578" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LivDet2023 -- Fingerprint Liveness Detection Competition: Advancing  Generalization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Micheletto%2C+M">Marco Micheletto</a>, 
<a href="/search/cs?searchtype=author&query=Casula%2C+R">Roberto Casula</a>, 
<a href="/search/cs?searchtype=author&query=Orr%C3%B9%2C+G">Giulia Orr&#xf9;</a>, 
<a href="/search/cs?searchtype=author&query=Carta%2C+S">Simone Carta</a>, 
<a href="/search/cs?searchtype=author&query=Concas%2C+S">Sara Concas</a>, 
<a href="/search/cs?searchtype=author&query=La+Cava%2C+S+M">Simone Maurizio La Cava</a>, 
<a href="/search/cs?searchtype=author&query=Fierrez%2C+J">Julian Fierrez</a>, 
<a href="/search/cs?searchtype=author&query=Marcialis%2C+G+L">Gian Luca Marcialis</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages, 10 tables, IEEE International Joint Conference on Biometrics (IJCB 2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">The International Fingerprint Liveness Detection Competition (LivDet) is a
biennial event that invites academic and industry participants to prove their
advancements in Fingerprint Presentation Attack Detection (PAD). This edition,
LivDet2023, proposed two challenges, Liveness Detection in Action and
Fingerprint Representation, to evaluate the efficacy of PAD embedded in
verification systems and the effectiveness and compactness of feature sets. A
third, hidden challenge is the inclusion of two subsets in the training set
whose sensor information is unknown, testing participants ability to generalize
their models. Only bona fide fingerprint samples were provided to participants,
and the competition reports and assesses the performance of their algorithms
suffering from this limitation in data availability.
</p>
</div>
</dd>
<dt><a name="item175">[175]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15588" title="Abstract">arXiv:2309.15588</a> [<a href="/pdf/2309.15588" title="Download PDF">pdf</a>, <a href="/ps/2309.15588" title="Download PostScript">ps</a>, <a href="/format/2309.15588" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Few-Shot Multi-Label Aspect Category Detection Utilizing Prototypical  Network with Sentence-Level Weighting and Label Augmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zeyu Wang</a>, 
<a href="/search/cs?searchtype=author&query=Iwaihara%2C+M">Mizuho Iwaihara</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> DEXA23
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Multi-label aspect category detection is intended to detect multiple aspect
categories occurring in a given sentence. Since aspect category detection often
suffers from limited datasets and data sparsity, the prototypical network with
attention mechanisms has been applied for few-shot aspect category detection.
Nevertheless, most of the prototypical networks used so far calculate the
prototypes by taking the mean value of all the instances in the support set.
This seems to ignore the variations between instances in multi-label aspect
category detection. Also, several related works utilize label text information
to enhance the attention mechanism. However, the label text information is
often short and limited, and not specific enough to discern categories. In this
paper, we first introduce support set attention along with the augmented label
information to mitigate the noise at word-level for each support set instance.
Moreover, we use a sentence-level attention mechanism that gives different
weights to each instance in the support set in order to compute prototypes by
weighted averaging. Finally, the calculated prototypes are further used in
conjunction with query instances to compute query attention and thereby
eliminate noises from the query set. Experimental results on the Yelp dataset
show that our proposed method is useful and outperforms all baselines in four
different scenarios.
</p>
</div>
</dd>
<dt><a name="item176">[176]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15589" title="Abstract">arXiv:2309.15589</a> [<a href="/pdf/2309.15589" title="Download PDF">pdf</a>, <a href="/format/2309.15589" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Domain generalization across tumor types, laboratories, and species --  insights from the 2022 edition of the Mitosis Domain Generalization Challenge
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Aubreville%2C+M">Marc Aubreville</a>, 
<a href="/search/cs?searchtype=author&query=Stathonikos%2C+N">Nikolas Stathonikos</a>, 
<a href="/search/cs?searchtype=author&query=Donovan%2C+T+A">Taryn A. Donovan</a>, 
<a href="/search/cs?searchtype=author&query=Klopfleisch%2C+R">Robert Klopfleisch</a>, 
<a href="/search/cs?searchtype=author&query=Ganz%2C+J">Jonathan Ganz</a>, 
<a href="/search/cs?searchtype=author&query=Ammeling%2C+J">Jonas Ammeling</a>, 
<a href="/search/cs?searchtype=author&query=Wilm%2C+F">Frauke Wilm</a>, 
<a href="/search/cs?searchtype=author&query=Veta%2C+M">Mitko Veta</a>, 
<a href="/search/cs?searchtype=author&query=Jabari%2C+S">Samir Jabari</a>, 
<a href="/search/cs?searchtype=author&query=Eckstein%2C+M">Markus Eckstein</a>, 
<a href="/search/cs?searchtype=author&query=Annuscheit%2C+J">Jonas Annuscheit</a>, 
<a href="/search/cs?searchtype=author&query=Krumnow%2C+C">Christian Krumnow</a>, 
<a href="/search/cs?searchtype=author&query=Bozaba%2C+E">Engin Bozaba</a>, 
<a href="/search/cs?searchtype=author&query=Cayir%2C+S">Sercan Cayir</a>, 
<a href="/search/cs?searchtype=author&query=Gu%2C+H">Hongyan Gu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+X+%27">Xiang &#x27;Anthony&#x27; Chen</a>, 
<a href="/search/cs?searchtype=author&query=Jahanifar%2C+M">Mostafa Jahanifar</a>, 
<a href="/search/cs?searchtype=author&query=Shephard%2C+A">Adam Shephard</a>, 
<a href="/search/cs?searchtype=author&query=Kondo%2C+S">Satoshi Kondo</a>, 
<a href="/search/cs?searchtype=author&query=Kasai%2C+S">Satoshi Kasai</a>, 
<a href="/search/cs?searchtype=author&query=Kotte%2C+S">Sujatha Kotte</a>, 
<a href="/search/cs?searchtype=author&query=Saipradeep%2C+V">VG Saipradeep</a>, 
<a href="/search/cs?searchtype=author&query=Lafarge%2C+M+W">Maxime W. Lafarge</a>, 
<a href="/search/cs?searchtype=author&query=Koelzer%2C+V+H">Viktor H. Koelzer</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Ziyue Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yongbing Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+S">Sen Yang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xiyue Wang</a>, 
<a href="/search/cs?searchtype=author&query=Breininger%2C+K">Katharina Breininger</a>, 
<a href="/search/cs?searchtype=author&query=Bertram%2C+C+A">Christof A. Bertram</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Recognition of mitotic figures in histologic tumor specimens is highly
relevant to patient outcome assessment. This task is challenging for algorithms
and human experts alike, with deterioration of algorithmic performance under
shifts in image representations. Considerable covariate shifts occur when
assessment is performed on different tumor types, images are acquired using
different digitization devices, or specimens are produced in different
laboratories. This observation motivated the inception of the 2022 challenge on
MItosis Domain Generalization (MIDOG 2022). The challenge provided annotated
histologic tumor images from six different domains and evaluated the
algorithmic approaches for mitotic figure detection provided by nine challenge
participants on ten independent domains. Ground truth for mitotic figure
detection was established in two ways: a three-expert consensus and an
independent, immunohistochemistry-assisted set of labels. This work represents
an overview of the challenge tasks, the algorithmic strategies employed by the
participants, and potential factors contributing to their success. With an
$F_1$ score of 0.764 for the top-performing team, we summarize that domain
generalization across various tumor domains is possible with today's deep
learning-based recognition pipelines. When assessed against the
immunohistochemistry-assisted reference standard, all methods resulted in
reduced recall scores, but with only minor changes in the order of participants
in the ranking.
</p>
</div>
</dd>
<dt><a name="item177">[177]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15595" title="Abstract">arXiv:2309.15595</a> [<a href="/pdf/2309.15595" title="Download PDF">pdf</a>, <a href="/format/2309.15595" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Advancing the distributed Multi-GPU ChASE library through algorithm  optimization and NCCL library
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+X">Xinzhe Wu</a> (1), 
<a href="/search/cs?searchtype=author&query=Di+Napoli%2C+E">Edoardo Di Napoli</a> (1) ((1) Juelich Supercomputing Centre, Forschungszentrum Juelich, Germany)
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, accepted at the proceedings of ScalAH23 workshop within the SC23 conference
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>; Computational Engineering, Finance, and Science (cs.CE)

</div>
<p class="mathjax">As supercomputers become larger with powerful Graphics Processing Unit (GPU),
traditional direct eigensolvers struggle to keep up with the hardware evolution
and scale efficiently due to communication and synchronization demands.
Conversely, subspace eigensolvers, like the Chebyshev Accelerated Subspace
Eigensolver (ChASE), have a simpler structure and can overcome communication
and synchronization bottlenecks. ChASE is a modern subspace eigensolver that
uses Chebyshev polynomials to accelerate the computation of extremal eigenpairs
of dense Hermitian eigenproblems. In this work we show how we have modified
ChASE by rethinking its memory layout, introducing a novel parallelization
scheme, switching to a more performing communication-avoiding algorithm for one
of its inner modules, and substituting the MPI library by the vendor-optimized
NCCL library. The resulting library can tackle dense problems with size up to
$N=\mathcal{O}(10^6)$, and scales effortlessly up to the full 900 nodes -- each
one powered by 4$\times$A100 NVIDIA GPUs -- of the JUWELS Booster hosted at the
J\"ulich Supercomputing Centre.
</p>
</div>
</dd>
<dt><a name="item178">[178]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15596" title="Abstract">arXiv:2309.15596</a> [<a href="/pdf/2309.15596" title="Download PDF">pdf</a>, <a href="/format/2309.15596" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PolarNet: 3D Point Clouds for Language-Guided Robotic Manipulation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+S">Shizhe Chen</a>, 
<a href="/search/cs?searchtype=author&query=Garcia%2C+R">Ricardo Garcia</a>, 
<a href="/search/cs?searchtype=author&query=Schmid%2C+C">Cordelia Schmid</a>, 
<a href="/search/cs?searchtype=author&query=Laptev%2C+I">Ivan Laptev</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to CoRL 2023. Project website: <a href="https://www.di.ens.fr/willow/research/polarnet/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">The ability for robots to comprehend and execute manipulation tasks based on
natural language instructions is a long-term goal in robotics. The dominant
approaches for language-guided manipulation use 2D image representations, which
face difficulties in combining multi-view cameras and inferring precise 3D
positions and relationships. To address these limitations, we propose a 3D
point cloud based policy called PolarNet for language-guided manipulation. It
leverages carefully designed point cloud inputs, efficient point cloud
encoders, and multimodal transformers to learn 3D point cloud representations
and integrate them with language instructions for action prediction. PolarNet
is shown to be effective and data efficient in a variety of experiments
conducted on the RLBench benchmark. It outperforms state-of-the-art 2D and 3D
approaches in both single-task and multi-task learning. It also achieves
promising results on a real robot.
</p>
</div>
</dd>
<dt><a name="item179">[179]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15599" title="Abstract">arXiv:2309.15599</a> [<a href="/pdf/2309.15599" title="Download PDF">pdf</a>, <a href="/format/2309.15599" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> OceanBench: The Sea Surface Height Edition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Johnson%2C+J+E">J. Emmanuel Johnson</a>, 
<a href="/search/cs?searchtype=author&query=Febvre%2C+Q">Quentin Febvre</a>, 
<a href="/search/cs?searchtype=author&query=Gorbunova%2C+A">Anastasia Gorbunova</a>, 
<a href="/search/cs?searchtype=author&query=Metref%2C+S">Sammy Metref</a>, 
<a href="/search/cs?searchtype=author&query=Ballarotta%2C+M">Maxime Ballarotta</a>, 
<a href="/search/cs?searchtype=author&query=Sommer%2C+J+L">Julien Le Sommer</a>, 
<a href="/search/cs?searchtype=author&query=Fablet%2C+R">Ronan Fablet</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> J. Emmanuel Johnson and Quentin Febvre contributed equally to this work
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Atmospheric and Oceanic Physics (physics.ao-ph)

</div>
<p class="mathjax">The ocean profoundly influences human activities and plays a critical role in
climate regulation. Our understanding has improved over the last decades with
the advent of satellite remote sensing data, allowing us to capture essential
quantities over the globe, e.g., sea surface height (SSH). However, ocean
satellite data presents challenges for information extraction due to their
sparsity and irregular sampling, signal complexity, and noise. Machine learning
(ML) techniques have demonstrated their capabilities in dealing with
large-scale, complex signals. Therefore we see an opportunity for ML models to
harness the information contained in ocean satellite data. However, data
representation and relevant evaluation metrics can be the defining factors when
determining the success of applied ML. The processing steps from the raw
observation data to a ML-ready state and from model outputs to interpretable
quantities require domain expertise, which can be a significant barrier to
entry for ML researchers. OceanBench is a unifying framework that provides
standardized processing steps that comply with domain-expert standards. It
provides plug-and-play data and pre-configured pipelines for ML researchers to
benchmark their models and a transparent configurable framework for researchers
to customize and extend the pipeline for their tasks. In this work, we
demonstrate the OceanBench framework through a first edition dedicated to SSH
interpolation challenges. We provide datasets and ML-ready benchmarking
pipelines for the long-standing problem of interpolating observations from
simulated ocean satellite data, multi-modal and multi-sensor fusion issues, and
transfer-learning to real ocean satellite observations. The OceanBench
framework is available at github.com/jejjohnson/oceanbench and the dataset
registry is available at github.com/quentinf00/oceanbench-data-registry.
</p>
</div>
</dd>
<dt><a name="item180">[180]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15601" title="Abstract">arXiv:2309.15601</a> [<a href="/pdf/2309.15601" title="Download PDF">pdf</a>, <a href="/format/2309.15601" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Study on Tiny YOLO for Resource Constrained Xray Threat Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ambati%2C+R">Raghav Ambati</a>, 
<a href="/search/cs?searchtype=author&query=Borthakur%2C+A">Ayon Borthakur</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Paper Under Review
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neural and Evolutionary Computing (cs.NE)</span>

</div>
<p class="mathjax">This paper implements and analyses multiple nets to determine their
suitability for edge devices to solve the problem of detecting Threat Objects
from X-ray security imaging data. There has been ongoing research on applying
Deep Learning techniques to solve this problem automatedly. We utilize an
alternative activation function calculated to have zero expected conversion
error with the activation of a spiking activation function, in the our tiny
YOLOv7 model. This QCFS version of the tiny YOLO replicates the activation of
ultra-low latency and high-efficiency SNN architecture and achieves
state-of-the-art performance on CLCXray which is another open-source XRay
Threat Detection dataset, hence making improvements in the field of using
spiking for object detection. We also analyze the performance of a Spiking YOLO
network by converting our QCFS network into a Spiking Network.
</p>
</div>
</dd>
<dt><a name="item181">[181]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15603" title="Abstract">arXiv:2309.15603</a> [<a href="/pdf/2309.15603" title="Download PDF">pdf</a>, <a href="/format/2309.15603" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Distill Knowledge in Multi-task Reinforcement Learning with  Optimal-Transport Regularization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Le%2C+B+G">Bang Giang Le</a>, 
<a href="/search/cs?searchtype=author&query=Ta%2C+V+C">Viet Cuong Ta</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages,
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> 2022 14th International Conference on Knowledge and Systems
  Engineering (KSE), Nha Trang, Vietnam, 2022, pp. 1-6,
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">In multi-task reinforcement learning, it is possible to improve the data
efficiency of training agents by transferring knowledge from other different
but related tasks. Because the experiences from different tasks are usually
biased toward the specific task goals. Traditional methods rely on
Kullback-Leibler regularization to stabilize the transfer of knowledge from one
task to the others. In this work, we explore the direction of replacing the
Kullback-Leibler divergence with a novel Optimal transport-based
regularization. By using the Sinkhorn mapping, we can approximate the Optimal
transport distance between the state distribution of tasks. The distance is
then used as an amortized reward to regularize the amount of sharing
information. We experiment our frameworks on several grid-based navigation
multi-goal to validate the effectiveness of the approach. The results show that
our added Optimal transport-based rewards are able to speed up the learning
process of agents and outperforms several baselines on multi-task learning.
</p>
</div>
</dd>
<dt><a name="item182">[182]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15604" title="Abstract">arXiv:2309.15604</a> [<a href="/pdf/2309.15604" title="Download PDF">pdf</a>, <a href="/format/2309.15604" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Entropic Matching for Expectation Propagation of Markov Jump Processes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Alt%2C+B">Bastian Alt</a>, 
<a href="/search/cs?searchtype=author&query=Koeppl%2C+H">Heinz Koeppl</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Molecular Networks (q-bio.MN); Quantitative Methods (q-bio.QM); Machine Learning (stat.ML)

</div>
<p class="mathjax">This paper addresses the problem of statistical inference for latent
continuous-time stochastic processes, which is often intractable, particularly
for discrete state space processes described by Markov jump processes. To
overcome this issue, we propose a new tractable inference scheme based on an
entropic matching framework that can be embedded into the well-known
expectation propagation algorithm. We demonstrate the effectiveness of our
method by providing closed-form results for a simple family of approximate
distributions and apply it to the general class of chemical reaction networks,
which are a crucial tool for modeling in systems biology. Moreover, we derive
closed form expressions for point estimation of the underlying parameters using
an approximate expectation maximization procedure. We evaluate the performance
of our method on various chemical reaction network instantiations, including a
stochastic Lotka-Voltera example, and discuss its limitations and potential for
future improvements. Our proposed approach provides a promising direction for
addressing complex continuous-time Bayesian inference problems.
</p>
</div>
</dd>
<dt><a name="item183">[183]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15606" title="Abstract">arXiv:2309.15606</a> [<a href="/pdf/2309.15606" title="Download PDF">pdf</a>, <a href="/format/2309.15606" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> From Misuse to Mastery: Enhancing Code Generation with Knowledge-Driven  AI Chaining
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ren%2C+X">Xiaoxue Ren</a>, 
<a href="/search/cs?searchtype=author&query=Ye%2C+X">Xinyuan Ye</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+D">Dehai Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Xing%2C+Z">Zhenchang Xing</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+X">Xiaohu Yang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by 38th IEEE/ACM International Conference on Automated Software Engineering (ASE 2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
<p class="mathjax">Large Language Models (LLMs) have shown promising results in automatic code
generation by improving coding efficiency to a certain extent. However,
generating high-quality and reliable code remains a formidable task because of
LLMs' lack of good programming practice, especially in exception handling. In
this paper, we first conduct an empirical study and summarise three crucial
challenges of LLMs in exception handling, i.e., incomplete exception handling,
incorrect exception handling and abuse of try-catch. We then try prompts with
different granularities to address such challenges, finding fine-grained
knowledge-driven prompts works best. Based on our empirical study, we propose a
novel Knowledge-driven Prompt Chaining-based code generation approach, name
KPC, which decomposes code generation into an AI chain with iterative
check-rewrite steps and chains fine-grained knowledge-driven prompts to assist
LLMs in considering exception-handling specifications. We evaluate our
KPC-based approach with 3,079 code generation tasks extracted from the Java
official API documentation. Extensive experimental results demonstrate that the
KPC-based approach has considerable potential to ameliorate the quality of code
generated by LLMs. It achieves this through proficiently managing exceptions
and obtaining remarkable enhancements of 109.86% and 578.57% with static
evaluation methods, as well as a reduction of 18 runtime bugs in the sampled
dataset with dynamic validation.
</p>
</div>
</dd>
<dt><a name="item184">[184]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15609" title="Abstract">arXiv:2309.15609</a> [<a href="/pdf/2309.15609" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Developing automatic verbatim transcripts for international multilingual  meetings: an end-to-end solution
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dewan%2C+A">Akshat Dewan</a>, 
<a href="/search/cs?searchtype=author&query=Ziemski%2C+M">Michal Ziemski</a>, 
<a href="/search/cs?searchtype=author&query=Meylan%2C+H">Henri Meylan</a>, 
<a href="/search/cs?searchtype=author&query=Concina%2C+L">Lorenzo Concina</a>, 
<a href="/search/cs?searchtype=author&query=Pouliquen%2C+B">Bruno Pouliquen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">This paper presents an end-to-end solution for the creation of fully
automated conference meeting transcripts and their machine translations into
various languages. This tool has been developed at the World Intellectual
Property Organization (WIPO) using in-house developed speech-to-text (S2T) and
machine translation (MT) components. Beyond describing data collection and
fine-tuning, resulting in a highly customized and robust system, this paper
describes the architecture and evolution of the technical components as well as
highlights the business impact and benefits from the user side. We also point
out particular challenges in the evolution and adoption of the system and how
the new approach created a new product and replaced existing established
workflows in conference management documentation.
</p>
</div>
</dd>
<dt><a name="item185">[185]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15612" title="Abstract">arXiv:2309.15612</a> [<a href="/pdf/2309.15612" title="Download PDF">pdf</a>, <a href="/format/2309.15612" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Illuminating Router Vendor Diversity Within Providers and Along Network  Paths
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Albakour%2C+T">Taha Albakour</a>, 
<a href="/search/cs?searchtype=author&query=Gasser%2C+O">Oliver Gasser</a>, 
<a href="/search/cs?searchtype=author&query=Beverly%2C+R">Robert Beverly</a>, 
<a href="/search/cs?searchtype=author&query=Smaragdakis%2C+G">Georgios Smaragdakis</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>

</div>
<p class="mathjax">The Internet architecture has facilitated a multi-party, distributed, and
heterogeneous physical infrastructure where routers from different vendors
connect and inter-operate via IP. Such vendor heterogeneity can have important
security and policy implications. For example, a security vulnerability may be
specific to a particular vendor and implementation, and thus will have a
disproportionate impact on particular networks and paths if exploited. From a
policy perspective, governments are now explicitly banning particular vendors,
or have threatened to do so. Despite these critical issues, the composition of
router vendors across the Internet remains largely opaque. Remotely identifying
router vendors is challenging due to their strict security posture,
indistinguishability due to code sharing across vendors, and noise due to
vendor mergers. We make progress in overcoming these challenges by developing
LFP, a tool that improves the coverage, accuracy, and efficiency of router
fingerprinting as compared to the current state-of-the-art. We leverage LFP to
characterize the degree of router vendor homogeneity within networks and the
regional distribution of vendors. We then take a path-centric view and apply
LFP to better understand the potential for correlated failures and
fate-sharing. Finally, we perform a case study on inter- and intra-United
States data paths to explore the feasibility to make vendor-based routing
policy decisions, i.e., whether it is possible to avoid a particular vendor
given the current infrastructure.
</p>
</div>
</dd>
<dt><a name="item186">[186]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15616" title="Abstract">arXiv:2309.15616</a> [<a href="/pdf/2309.15616" title="Download PDF">pdf</a>, <a href="/format/2309.15616" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Perception for Humanoid Robots
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Roychoudhury%2C+A">Arindam Roychoudhury</a>, 
<a href="/search/cs?searchtype=author&query=Khorshidi%2C+S">Shahram Khorshidi</a>, 
<a href="/search/cs?searchtype=author&query=Agrawal%2C+S">Subham Agrawal</a>, 
<a href="/search/cs?searchtype=author&query=Bennewitz%2C+M">Maren Bennewitz</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 20 pages, 4 figures. To be published in Current Robotics Reports (Springer Nature)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Purpose of Review: The field of humanoid robotics, perception plays a
fundamental role in enabling robots to interact seamlessly with humans and
their surroundings, leading to improved safety, efficiency, and user
experience. This scientific study investigates various perception modalities
and techniques employed in humanoid robots, including visual, auditory, and
tactile sensing by exploring recent state-of-the-art approaches for perceiving
and understanding the internal state, the environment, objects, and human
activities.
<br />Recent Findings: Internal state estimation makes extensive use of Bayesian
filtering methods and optimization techniques based on maximum a-posteriori
formulation by utilizing proprioceptive sensing. In the area of external
environment understanding, with an emphasis on robustness and adaptability to
dynamic, unforeseen environmental changes, the new slew of research discussed
in this study have focused largely on multi-sensor fusion and machine learning
in contrast to the use of hand-crafted, rule-based systems. Human robot
interaction methods have established the importance of contextual information
representation and memory for understanding human intentions.
<br />Summary: This review summarizes the recent developments and trends in the
field of perception in humanoid robots. Three main areas of application are
identified, namely, internal state estimation, external environment estimation,
and human robot interaction. The applications of diverse sensor modalities in
each of these areas are considered and recent significant works are discussed.
</p>
</div>
</dd>
<dt><a name="item187">[187]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15617" title="Abstract">arXiv:2309.15617</a> [<a href="/pdf/2309.15617" title="Download PDF">pdf</a>, <a href="/format/2309.15617" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> RapidEarth: A Search-by-Classification Engine for Large-Scale Geospatial  Imagery
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=L%C3%BClf%2C+C">Christian L&#xfc;lf</a>, 
<a href="/search/cs?searchtype=author&query=Martins%2C+D+M+L">Denis Mayr Lima Martins</a>, 
<a href="/search/cs?searchtype=author&query=Salles%2C+M+A+V">Marcos Antonio Vaz Salles</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Y">Yongluan Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Gieseke%2C+F">Fabian Gieseke</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Databases (cs.DB)</span>

</div>
<p class="mathjax">Data exploration and analysis in various domains often necessitate the search
for specific objects in massive databases. A common search strategy, often
known as search-by-classification, resorts to training machine learning models
on small sets of positive and negative samples and to performing inference on
the entire database to discover additional objects of interest. While such an
approach often yields very good results in terms of classification performance,
the entire database usually needs to be scanned, a process that can easily take
several hours even for medium-sized data catalogs. In this work, we present
RapidEarth, a geospatial search-by-classification engine that allows analysts
to rapidly search for interesting objects in very large data collections of
satellite imagery in a matter of seconds, without the need to scan the entire
data catalog. RapidEarth embodies a co-design of multidimensional indexing
structures and decision branches, a recently proposed variant of classical
decision trees. These decision branches allow RapidEarth to transform the
inference phase into a set of range queries, which can be efficiently processed
by leveraging the aforementioned multidimensional indexing structures. The main
contribution of this work is a geospatial search engine that implements these
technical findings.
</p>
</div>
</dd>
<dt><a name="item188">[188]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15619" title="Abstract">arXiv:2309.15619</a> [<a href="/pdf/2309.15619" title="Download PDF">pdf</a>, <a href="/format/2309.15619" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Utilization of machine learning for the detection of self-admitted  vulnerabilities
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mock%2C+M">Moritz Mock</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages, 1 figure
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
<p class="mathjax">Motivation: Technical debt is a metaphor that describes not-quite-right code
introduced for short-term needs. Developers are aware of it and admit it in
source code comments, which is called Self- Admitted Technical Debt (SATD).
Therefore, SATD indicates weak code that developers are aware of. Problem
statement: Inspecting source code is time-consuming; automatically inspecting
source code for its vulnerabilities is a crucial aspect of developing software.
It helps practitioners reduce the time-consuming process and focus on
vulnerable aspects of the source code. Proposal: Accurately identify and better
understand the semantics of self-admitted technical debt (SATD) by leveraging
NLP and NL-PL approaches to detect vulnerabilities and the related SATD.
Finally, a CI/CD pipeline will be proposed to make the vulnerability discovery
process easily accessible to practitioners.
</p>
</div>
</dd>
<dt><a name="item189">[189]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15621" title="Abstract">arXiv:2309.15621</a> [<a href="/pdf/2309.15621" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A City-centric Approach to Estimate and Evaluate Global Urban Air  Mobility Demand
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Asmer%2C+L">Lukas Asmer</a>, 
<a href="/search/eess?searchtype=author&query=Jaksche%2C+R">Roman Jaksche</a>, 
<a href="/search/eess?searchtype=author&query=Pak%2C+H">Henry Pak</a>, 
<a href="/search/eess?searchtype=author&query=Kokus%2C+P">Petra Kokus</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages, 16 figures, project HorizonUAM
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Physics and Society (physics.soc-ph)

</div>
<p class="mathjax">Urban Air Mobility (UAM) is expected to effectively complement the existing
transportation system by providing fast and safe travel options, contributing
to decarbonization, and providing benefits to citizens and communities. A
preliminary estimate of the potential global demand for UAM, the associated
aircraft movements, and the required vehicles is essential for the UAM industry
for their long-term planning, but also of interest to other stakeholders such
as governments and transportation planners to develop appropriate strategies
and actions to implement UAM. This paper proposes a city-centric forecasting
methodology that provides preliminary estimates of the potential global UAM
demand for intra-city air taxi services for 990 cities worldwide. By summing
all city-specific results, an estimate of the global UAM demand is obtained. By
varying the parameters of the UAM system, sensitivity studies and different
market scenarios are developed and analyzed. Sensitivity analyses show how
strongly demand decreases when air taxi ticket prices increase. Considering low
ticket prices and high vertiport densities, possible market development
scenarios show that there is a market potential for UAM in over 200 cities
worldwide by 2050. The study highlights the significant impact of low ticket
prices and the need for high vertiport densities to drive UAM demand. This
highlights the need for careful optimization of system components to minimize
costs and increase the quality of UAM services.
</p>
</div>
</dd>
<dt><a name="item190">[190]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15622" title="Abstract">arXiv:2309.15622</a> [<a href="/pdf/2309.15622" title="Download PDF">pdf</a>, <a href="/format/2309.15622" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Pushing Alias Resolution to the Limit
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Albakour%2C+T">Taha Albakour</a>, 
<a href="/search/cs?searchtype=author&query=Gasser%2C+O">Oliver Gasser</a>, 
<a href="/search/cs?searchtype=author&query=Smaragdakis%2C+G">Georgios Smaragdakis</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>

</div>
<p class="mathjax">In this paper, we show that utilizing multiple protocols offers a unique
opportunity to improve IP alias resolution and dual-stack inference
substantially. Our key observation is that prevalent protocols, e.g., SSH and
BGP, reply to unsolicited requests with a set of values that can be combined to
form a unique device identifier. More importantly, this is possible by just
completing the TCP hand-shake. Our empirical study shows that utilizing readily
available scans and our active measurements can double the discovered IPv4
alias sets and more than 30x the dual-stack sets compared to the
state-of-the-art techniques. We provide insights into our method's accuracy and
performance compared to popular techniques.
</p>
</div>
</dd>
<dt><a name="item191">[191]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15624" title="Abstract">arXiv:2309.15624</a> [<a href="/pdf/2309.15624" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Orientation Control with Variable Stiffness Dynamical Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Michel%2C+Y">Youssef Michel</a>, 
<a href="/search/cs?searchtype=author&query=Saveriano%2C+M">Matteo Saveriano</a>, 
<a href="/search/cs?searchtype=author&query=Abu-Dakka%2C+F+J">Fares J. Abu-Dakka</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+D">Dongheui Lee</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at the IEEE/RSJ International Conference on Intelligent Robots and Systems(IROS),2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Recently, several approaches have attempted to combine motion generation and
control in one loop to equip robots with reactive behaviors, that cannot be
achieved with traditional time-indexed tracking controllers. These approaches
however mainly focused on positions, neglecting the orientation part which can
be crucial to many tasks e.g. screwing. In this work, we propose a control
algorithm that adapts the robot's rotational motion and impedance in a
closed-loop manner. Given a first-order Dynamical System representing an
orientation motion plan and a desired rotational stiffness profile, our
approach enables the robot to follow the reference motion with an interactive
behavior specified by the desired stiffness, while always being aware of the
current orientation, represented as a Unit Quaternion (UQ). We rely on the Lie
algebra to formulate our algorithm, since unlike positions, UQ feature
constraints that should be respected in the devised controller. We validate our
proposed approach in multiple robot experiments, showcasing the ability of our
controller to follow complex orientation profiles, react safely to
perturbations, and fulfill physical interaction tasks.
</p>
</div>
</dd>
<dt><a name="item192">[192]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15625" title="Abstract">arXiv:2309.15625</a> [<a href="/pdf/2309.15625" title="Download PDF">pdf</a>, <a href="/format/2309.15625" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Leveraging Topology for Domain Adaptive Road Segmentation in Satellite  and Aerial Imagery
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Iqbal%2C+J">Javed Iqbal</a>, 
<a href="/search/cs?searchtype=author&query=Masood%2C+A">Aliza Masood</a>, 
<a href="/search/cs?searchtype=author&query=Sultani%2C+W">Waqas Sultani</a>, 
<a href="/search/cs?searchtype=author&query=Ali%2C+M">Mohsen Ali</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Image and Video Processing (eess.IV)

</div>
<p class="mathjax">Getting precise aspects of road through segmentation from remote sensing
imagery is useful for many real-world applications such as autonomous vehicles,
urban development and planning, and achieving sustainable development goals.
Roads are only a small part of the image, and their appearance, type, width,
elevation, directions, etc. exhibit large variations across geographical areas.
Furthermore, due to differences in urbanization styles, planning, and the
natural environments; regions along the roads vary significantly. Due to these
variations among the train and test domains, the road segmentation algorithms
fail to generalize to new geographical locations. Unlike the generic domain
alignment scenarios, road segmentation has no scene structure, and generic
domain adaptation methods are unable to enforce topological properties like
continuity, connectivity, smoothness, etc., thus resulting in degraded domain
alignment. In this work, we propose a topology-aware unsupervised domain
adaptation approach for road segmentation in remote sensing imagery.
Specifically, we predict road skeleton, an auxiliary task to impose the
topological constraints. To enforce consistent predictions of road and
skeleton, especially in the unlabeled target domain, the conformity loss is
defined across the skeleton prediction head and the road-segmentation head.
Furthermore, for self-training, we filter out the noisy pseudo-labels by using
a connectivity-based pseudo-labels refinement strategy, on both road and
skeleton segmentation heads, thus avoiding holes and discontinuities. Extensive
experiments on the benchmark datasets show the effectiveness of the proposed
approach compared to existing state-of-the-art methods. Specifically, for
SpaceNet to DeepGlobe adaptation, the proposed approach outperforms the
competing methods by a minimum margin of 6.6%, 6.7%, and 9.8% in IoU, F1-score,
and APLS, respectively.
</p>
</div>
</dd>
<dt><a name="item193">[193]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15627" title="Abstract">arXiv:2309.15627</a> [<a href="/pdf/2309.15627" title="Download PDF">pdf</a>, <a href="/format/2309.15627" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Neuromorphic Imaging and Classification with Graph Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+P">Pei Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+C">Chutian Wang</a>, 
<a href="/search/cs?searchtype=author&query=Lam%2C+E+Y">Edmund Y. Lam</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to Neurocomputing
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Bio-inspired neuromorphic cameras asynchronously record pixel brightness
changes and generate sparse event streams. They can capture dynamic scenes with
little motion blur and more details in extreme illumination conditions. Due to
the multidimensional address-event structure, most existing vision algorithms
cannot properly handle asynchronous event streams. While several event
representations and processing methods have been developed to address such an
issue, they are typically driven by a large number of events, leading to
substantial overheads in runtime and memory. In this paper, we propose a new
graph representation of the event data and couple it with a Graph Transformer
to perform accurate neuromorphic classification. Extensive experiments show
that our approach leads to better results and excels at the challenging
realistic situations where only a small number of events and limited
computational resources are available, paving the way for neuromorphic
applications embedded into mobile facilities.
</p>
</div>
</dd>
<dt><a name="item194">[194]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15630" title="Abstract">arXiv:2309.15630</a> [<a href="/pdf/2309.15630" title="Download PDF">pdf</a>, <a href="/format/2309.15630" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> NLPBench: Evaluating Large Language Models on Solving NLP Problems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Song%2C+L">Linxin Song</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jieyu Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+L">Lechao Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+P">Pengyuan Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+T">Tianyi Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+I">Irene Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Recent developments in large language models (LLMs) have shown promise in
enhancing the capabilities of natural language processing (NLP). Despite these
successes, there remains a dearth of research dedicated to the NLP
problem-solving abilities of LLMs. To fill the gap in this area, we present a
unique benchmarking dataset, NLPBench, comprising 378 college-level NLP
questions spanning various NLP topics sourced from Yale University's prior
final exams. NLPBench includes questions with context, in which multiple
sub-questions share the same public information, and diverse question types,
including multiple choice, short answer, and math. Our evaluation, centered on
LLMs such as GPT-3.5/4, PaLM-2, and LLAMA-2, incorporates advanced prompting
strategies like the chain-of-thought (CoT) and tree-of-thought (ToT). Our study
reveals that the effectiveness of the advanced prompting strategies can be
inconsistent, occasionally damaging LLM performance, especially in smaller
models like the LLAMA-2 (13b). Furthermore, our manual assessment illuminated
specific shortcomings in LLMs' scientific problem-solving skills, with
weaknesses in logical decomposition and reasoning notably affecting results.
</p>
</div>
</dd>
<dt><a name="item195">[195]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15631" title="Abstract">arXiv:2309.15631</a> [<a href="/pdf/2309.15631" title="Download PDF">pdf</a>, <a href="/format/2309.15631" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Design and Optimization of Residual Neural Network Accelerators for  Low-Power FPGAs Using High-Level Synthesis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Minnella%2C+F">Filippo Minnella</a>, 
<a href="/search/cs?searchtype=author&query=Urso%2C+T">Teodoro Urso</a>, 
<a href="/search/cs?searchtype=author&query=Lazarescu%2C+M+T">Mihai T. Lazarescu</a>, 
<a href="/search/cs?searchtype=author&query=Lavagno%2C+L">Luciano Lavagno</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Hardware Architecture (cs.AR)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">Residual neural networks are widely used in computer vision tasks. They
enable the construction of deeper and more accurate models by mitigating the
vanishing gradient problem. Their main innovation is the residual block which
allows the output of one layer to bypass one or more intermediate layers and be
added to the output of a later layer. Their complex structure and the buffering
required by the residual block make them difficult to implement on
resource-constrained platforms. We present a novel design flow for implementing
deep learning models for field programmable gate arrays optimized for ResNets,
using a strategy to reduce their buffering overhead to obtain a
resource-efficient implementation of the residual layer. Our high-level
synthesis (HLS)-based flow encompasses a thorough set of design principles and
optimization strategies, exploiting in novel ways standard techniques such as
temporal reuse and loop merging to efficiently map ResNet models, and
potentially other skip connection-based NN architectures, into FPGA. The models
are quantized to 8-bit integers for both weights and activations, 16-bit for
biases, and 32-bit for accumulations. The experimental results are obtained on
the CIFAR-10 dataset using ResNet8 and ResNet20 implemented with Xilinx FPGAs
using HLS on the Ultra96-V2 and Kria KV260 boards. Compared to the
state-of-the-art on the Kria KV260 board, our ResNet20 implementation achieves
2.88X speedup with 0.5% higher accuracy of 91.3%, while ResNet8 accuracy
improves by 2.8% to 88.7%. The throughputs of ResNet8 and ResNet20 are 12971
FPS and 3254 FPS on the Ultra96 board, and 30153 FPS and 7601 FPS on the Kria
KV26, respectively. They Pareto-dominate state-of-the-art solutions concerning
accuracy, throughput, and energy.
</p>
</div>
</dd>
<dt><a name="item196">[196]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15635" title="Abstract">arXiv:2309.15635</a> [<a href="/pdf/2309.15635" title="Download PDF">pdf</a>, <a href="/format/2309.15635" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Position and Orientation-Aware One-Shot Learning for Medical Action  Recognition from Signal Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xie%2C+L">Leiyu Xie</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yuxing Yang</a>, 
<a href="/search/cs?searchtype=author&query=Fu%2C+Z">Zeyu Fu</a>, 
<a href="/search/cs?searchtype=author&query=Naqvi%2C+S+M">Syed Mohsen Naqvi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">In this work, we propose a position and orientation-aware one-shot learning
framework for medical action recognition from signal data. The proposed
framework comprises two stages and each stage includes signal-level image
generation (SIG), cross-attention (CsA), dynamic time warping (DTW) modules and
the information fusion between the proposed privacy-preserved position and
orientation features. The proposed SIG method aims to transform the raw
skeleton data into privacy-preserved features for training. The CsA module is
developed to guide the network in reducing medical action recognition bias and
more focusing on important human body parts for each specific action, aimed at
addressing similar medical action related issues. Moreover, the DTW module is
employed to minimize temporal mismatching between instances and further improve
model performance. Furthermore, the proposed privacy-preserved
orientation-level features are utilized to assist the position-level features
in both of the two stages for enhancing medical action recognition performance.
Extensive experimental results on the widely-used and well-known NTU RGB+D 60,
NTU RGB+D 120, and PKU-MMD datasets all demonstrate the effectiveness of the
proposed method, which outperforms the other state-of-the-art methods with
general dataset partitioning by 2.7%, 6.2% and 4.1%, respectively.
</p>
</div>
</dd>
<dt><a name="item197">[197]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15639" title="Abstract">arXiv:2309.15639</a> [<a href="/pdf/2309.15639" title="Download PDF">pdf</a>, <a href="/format/2309.15639" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Enhancing Sharpness-Aware Optimization Through Variance Suppression
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+B">Bingcong Li</a>, 
<a href="/search/cs?searchtype=author&query=Giannakis%2C+G+B">Georgios B. Giannakis</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Sharpness-aware minimization (SAM) has well documented merits in enhancing
generalization of deep neural networks, even without sizable data augmentation.
Embracing the geometry of the loss function, where neighborhoods of 'flat
minima' heighten generalization ability, SAM seeks 'flat valleys' by minimizing
the maximum loss caused by an adversary perturbing parameters within the
neighborhood. Although critical to account for sharpness of the loss function,
such an 'over-friendly adversary' can curtail the outmost level of
generalization. The novel approach of this contribution fosters stabilization
of adversaries through variance suppression (VaSSO) to avoid such friendliness.
VaSSO's provable stability safeguards its numerical improvement over SAM in
model-agnostic tasks, including image classification and machine translation.
In addition, experiments confirm that VaSSO endows SAM with robustness against
high levels of label noise.
</p>
</div>
</dd>
<dt><a name="item198">[198]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15641" title="Abstract">arXiv:2309.15641</a> [<a href="/pdf/2309.15641" title="Download PDF">pdf</a>, <a href="/format/2309.15641" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Efficient Exact Subgraph Matching via GNN-based Path Dominance Embedding  (Technical Report)
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ye%2C+Y">Yutong Ye</a>, 
<a href="/search/cs?searchtype=author&query=Lian%2C+X">Xiang Lian</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+M">Mingsong Chen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Databases (cs.DB)</span>

</div>
<p class="mathjax">The classic problem of exact subgraph matching returns those subgraphs in a
large-scale data graph that are isomorphic to a given query graph, which has
gained increasing importance in many real-world applications such as social
network analysis, knowledge graph discovery in the Semantic Web,
bibliographical network mining, and so on. In this paper, we propose a novel
and effective \textit{graph neural network (GNN)-based path embedding
framework} (GNN-PE), which allows efficient exact subgraph matching without
introducing false dismissals. Unlike traditional GNN-based graph embeddings
that only produce approximate subgraph matching results, in this paper, we
carefully devise GNN-based embeddings for paths, such that: if two paths (and
1-hop neighbors of vertices on them) have the subgraph relationship, their
corresponding GNN-based embedding vectors will strictly follow the dominance
relationship. With such a newly designed property of path dominance embeddings,
we are able to propose effective pruning strategies based on path
label/dominance embeddings and guarantee no false dismissals for subgraph
matching. We build multidimensional indexes over path embedding vectors, and
develop an efficient subgraph matching algorithm by traversing indexes over
graph partitions in parallel and applying our pruning methods. We also propose
a cost-model-based query plan that obtains query paths from the query graph
with low query cost. Through extensive experiments, we confirm the efficiency
and effectiveness of our proposed GNN-PE approach for exact subgraph matching
on both real and synthetic graph data.
</p>
</div>
</dd>
<dt><a name="item199">[199]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15645" title="Abstract">arXiv:2309.15645</a> [<a href="/pdf/2309.15645" title="Download PDF">pdf</a>, <a href="/format/2309.15645" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Sidestepping Barriers for Dominating Set in Parameterized Complexity
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Koutis%2C+I">Ioannis Koutis</a>, 
<a href="/search/cs?searchtype=author&query=W%C5%82odarczyk%2C+M">Micha&#x142; W&#x142;odarczyk</a>, 
<a href="/search/cs?searchtype=author&query=Zehavi%2C+M">Meirav Zehavi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to IPEC'23
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>

</div>
<p class="mathjax">We study the classic {\sc Dominating Set} problem with respect to several
prominent parameters. Specifically, we present algorithmic results that
sidestep time complexity barriers by the incorporation of either approximation
or larger parameterization. Our results span several parameterization regimes,
including: (i,ii,iii) time/ratio-tradeoff for the parameters {\em treewidth},
{\em vertex modulator to constant treewidth} and {\em solution size}; (iv,v)
FPT-algorithms for the parameters {\em vertex cover number} and {\em feedback
edge set number}; and (vi) compression for the parameter {\em feedback edge set
number}.
</p>
</div>
</dd>
<dt><a name="item200">[200]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15646" title="Abstract">arXiv:2309.15646</a> [<a href="/pdf/2309.15646" title="Download PDF">pdf</a>, <a href="/format/2309.15646" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Cold &amp; Warm Net: Addressing Cold-Start Users in Recommender Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xiangyu Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Kuang%2C+Z">Zongqiang Kuang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zehao Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+F">Fan Huang</a>, 
<a href="/search/cs?searchtype=author&query=Tan%2C+X">Xianfeng Tan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Cold-start recommendation is one of the major challenges faced by recommender
systems (RS). Herein, we focus on the user cold-start problem. Recently,
methods utilizing side information or meta-learning have been used to model
cold-start users. However, it is difficult to deploy these methods to
industrial RS. There has not been much research that pays attention to the user
cold-start problem in the matching stage. In this paper, we propose Cold &amp; Warm
Net based on expert models who are responsible for modeling cold-start and
warm-up users respectively. A gate network is applied to incorporate the
results from two experts. Furthermore, dynamic knowledge distillation acting as
a teacher selector is introduced to assist experts in better learning user
representation. With comprehensive mutual information, features highly relevant
to user behavior are selected for the bias net which explicitly models user
behavior bias. Finally, we evaluate our Cold &amp; Warm Net on public datasets in
comparison to models commonly applied in the matching stage and it outperforms
other models on all user types. The proposed model has also been deployed on an
industrial short video platform and achieves a significant increase in app
dwell time and user retention rate.
</p>
</div>
</dd>
<dt><a name="item201">[201]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15647" title="Abstract">arXiv:2309.15647</a> [<a href="/pdf/2309.15647" title="Download PDF">pdf</a>, <a href="/ps/2309.15647" title="Download PostScript">ps</a>, <a href="/format/2309.15647" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Black-Box Identity Testing of Noncommutative Rational Formulas in  Deterministic Quasipolynomial Time
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Arvind%2C+V">V. Arvind</a>, 
<a href="/search/cs?searchtype=author&query=Chatterjee%2C+A">Abhranil Chatterjee</a>, 
<a href="/search/cs?searchtype=author&query=Mukhopadhyay%2C+P">Partha Mukhopadhyay</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Complexity (cs.CC)</span>; Data Structures and Algorithms (cs.DS)

</div>
<p class="mathjax">Rational Identity Testing (RIT) is the decision problem of determining
whether or not a given noncommutative rational formula computes zero in the
free skew field. It admits a deterministic polynomial-time white-box algorithm
[Garg et al., 2016; Ivanyos et. al., 2018; Hamada and Hirai, 2021], and a
randomized polynomial-time black-box algorithm [Derksen and Makam, 2017] via
singularity testing of linear matrices over the free skew field.
<br />Designing a subexponential-time deterministic RIT algorithm in black-box is a
major open problem in this area. Despite being open for several years, this
question has seen very limited progress. In fact, the only known result in this
direction is the construction of a quasipolynomial-size hitting set for
rational formulas of only inversion height two [Arvind et al., 2022].
<br />In this paper, we settle this problem and obtain a deterministic
quasipolynomial-time RIT algorithm for the general case in the black-box
setting. Our algorithm uses ideas from the theory of finite dimensional
division algebras, algebraic complexity theory, and the theory of generalized
formal power series.
</p>
</div>
</dd>
<dt><a name="item202">[202]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15648" title="Abstract">arXiv:2309.15648</a> [<a href="/pdf/2309.15648" title="Download PDF">pdf</a>, <a href="/format/2309.15648" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SANGEA: Scalable and Attributed Network Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lemaire%2C+V">Valentin Lemaire</a>, 
<a href="/search/cs?searchtype=author&query=Achenchabe%2C+Y">Youssef Achenchabe</a>, 
<a href="/search/cs?searchtype=author&query=Ody%2C+L">Lucas Ody</a>, 
<a href="/search/cs?searchtype=author&query=Souid%2C+H+E">Houssem Eddine Souid</a>, 
<a href="/search/cs?searchtype=author&query=Aversano%2C+G">Gianmarco Aversano</a>, 
<a href="/search/cs?searchtype=author&query=Posocco%2C+N">Nicolas Posocco</a>, 
<a href="/search/cs?searchtype=author&query=Skhiri%2C+S">Sabri Skhiri</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 15 pages, 1 figure, 2 algorithms, 4 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">The topic of synthetic graph generators (SGGs) has recently received much
attention due to the wave of the latest breakthroughs in generative modelling.
However, many state-of-the-art SGGs do not scale well with the graph size.
Indeed, in the generation process, all the possible edges for a fixed number of
nodes must often be considered, which scales in $\mathcal{O}(N^2)$, with $N$
being the number of nodes in the graph. For this reason, many state-of-the-art
SGGs are not applicable to large graphs. In this paper, we present SANGEA, a
sizeable synthetic graph generation framework which extends the applicability
of any SGG to large graphs. By first splitting the large graph into
communities, SANGEA trains one SGG per community, then links the community
graphs back together to create a synthetic large graph. Our experiments show
that the graphs generated by SANGEA have high similarity to the original graph,
in terms of both topology and node feature distribution. Additionally, these
generated graphs achieve high utility on downstream tasks such as link
prediction. Finally, we provide a privacy assessment of the generated graphs to
show that, even though they have excellent utility, they also achieve
reasonable privacy scores.
</p>
</div>
</dd>
<dt><a name="item203">[203]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15649" title="Abstract">arXiv:2309.15649</a> [<a href="/pdf/2309.15649" title="Download PDF">pdf</a>, <a href="/format/2309.15649" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Generative Speech Recognition Error Correction with Large Language  Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+C+H">Chao-Han Huck Yang</a>, 
<a href="/search/cs?searchtype=author&query=Gu%2C+Y">Yile Gu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yi-Chieh Liu</a>, 
<a href="/search/cs?searchtype=author&query=Ghosh%2C+S">Shalini Ghosh</a>, 
<a href="/search/cs?searchtype=author&query=Bulyko%2C+I">Ivan Bulyko</a>, 
<a href="/search/cs?searchtype=author&query=Stolcke%2C+A">Andreas Stolcke</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to IEEE Automatic Speech Recognition and Understanding (ASRU) 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Sound (cs.SD); Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">We explore the ability of large language models (LLMs) to act as ASR
post-processors that perform rescoring and error correction. Our focus is on
instruction prompting to let LLMs perform these task without fine-tuning, for
which we evaluate different prompting schemes, both zero- and few-shot
in-context learning, and a novel task-activating prompting (TAP) method that
combines instruction and demonstration. Using a pre-trained first-pass system
and rescoring output on two out-of-domain tasks (ATIS and WSJ), we show that
rescoring only by in-context learning with frozen LLMs achieves results that
are competitive with rescoring by domain-tuned LMs. By combining prompting
techniques with fine-tuning we achieve error rates below the N-best oracle
level, showcasing the generalization power of the LLMs.
</p>
</div>
</dd>
<dt><a name="item204">[204]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15656" title="Abstract">arXiv:2309.15656</a> [<a href="/pdf/2309.15656" title="Download PDF">pdf</a>, <a href="/format/2309.15656" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Conversational Feedback in Scripted versus Spontaneous Dialogues: A  Comparative Analysis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pil%C3%A1n%2C+I">Ildik&#xf3; Pil&#xe1;n</a>, 
<a href="/search/cs?searchtype=author&query=Pr%C3%A9vot%2C+L">Laurent Pr&#xe9;vot</a>, 
<a href="/search/cs?searchtype=author&query=Buschmeier%2C+H">Hendrik Buschmeier</a>, 
<a href="/search/cs?searchtype=author&query=Lison%2C+P">Pierre Lison</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Scripted dialogues such as movie and TV subtitles constitute a widespread
source of training data for conversational NLP models. However, the linguistic
characteristics of those dialogues are notably different from those observed in
corpora of spontaneous interactions. This difference is particularly marked for
communicative feedback and grounding phenomena such as backchannels,
acknowledgments, or clarification requests. Such signals are known to
constitute a key part of the conversation flow and are used by the dialogue
participants to provide feedback to one another on their perception of the
ongoing interaction. This paper presents a quantitative analysis of such
communicative feedback phenomena in both subtitles and spontaneous
conversations. Based on dialogue data in English, French, German, Hungarian,
Italian, Japanese, Norwegian and Chinese, we extract both lexical statistics
and classification outputs obtained with a neural dialogue act tagger. Two main
findings of this empirical study are that (1) conversational feedback is
markedly less frequent in subtitles than in spontaneous dialogues and (2)
subtitles contain a higher proportion of negative feedback. Furthermore, we
show that dialogue responses generated by large language models also follow the
same underlying trends and include comparatively few occurrences of
communicative feedback, except when those models are explicitly fine-tuned on
spontaneous dialogues.
</p>
</div>
</dd>
<dt><a name="item205">[205]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15659" title="Abstract">arXiv:2309.15659</a> [<a href="/pdf/2309.15659" title="Download PDF">pdf</a>, <a href="/format/2309.15659" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Federated Deep Equilibrium Learning: A Compact Shared Representation for  Edge Communication Efficiency
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Le%2C+L+T">Long Tan Le</a>, 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+T+D">Tuan Dung Nguyen</a>, 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+T">Tung-Anh Nguyen</a>, 
<a href="/search/cs?searchtype=author&query=Hong%2C+C+S">Choong Seon Hong</a>, 
<a href="/search/cs?searchtype=author&query=Tran%2C+N+H">Nguyen H. Tran</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Distributed, Parallel, and Cluster Computing (cs.DC)

</div>
<p class="mathjax">Federated Learning (FL) is a prominent distributed learning paradigm
facilitating collaboration among nodes within an edge network to co-train a
global model without centralizing data. By shifting computation to the network
edge, FL offers robust and responsive edge-AI solutions and enhance
privacy-preservation. However, deploying deep FL models within edge
environments is often hindered by communication bottlenecks, data
heterogeneity, and memory limitations. To address these challenges jointly, we
introduce FeDEQ, a pioneering FL framework that effectively employs deep
equilibrium learning and consensus optimization to exploit a compact shared
data representation across edge nodes, allowing the derivation of personalized
models specific to each node. We delve into a unique model structure composed
of an equilibrium layer followed by traditional neural network layers. Here,
the equilibrium layer functions as a global feature representation that edge
nodes can adapt to personalize their local layers. Capitalizing on FeDEQ's
compactness and representation power, we present a novel distributed algorithm
rooted in the alternating direction method of multipliers (ADMM) consensus
optimization and theoretically establish its convergence for smooth objectives.
Experiments across various benchmarks demonstrate that FeDEQ achieves
performance comparable to state-of-the-art personalized methods while employing
models of up to 4 times smaller in communication size and 1.5 times lower
memory footprint during training.
</p>
</div>
</dd>
<dt><a name="item206">[206]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15660" title="Abstract">arXiv:2309.15660</a> [<a href="/pdf/2309.15660" title="Download PDF">pdf</a>, <a href="/format/2309.15660" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Enhanced Frequency Containment Reserve Provision from Battery Hybridized  Hydropower Plants: Theory and Experimental Validation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Gerini%2C+F">Francesco Gerini</a>, 
<a href="/search/eess?searchtype=author&query=Vagnoni%2C+E">Elena Vagnoni</a>, 
<a href="/search/eess?searchtype=author&query=Seydoux%2C+M">Martin Seydoux</a>, 
<a href="/search/eess?searchtype=author&query=Cherkaoui%2C+R">Rachid Cherkaoui</a>, 
<a href="/search/eess?searchtype=author&query=Paolone%2C+M">Mario Paolone</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to PSCC2024, Power Systems Computation Conference, Paris, France
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">This paper presents a solution to address wear and tear of Run-of-River (RoR)
Hydropower Plants (HPPs) providing enhanced Frequency Containment Reserve
(FCR). In this respect, the study proposes the integration of a Battery Energy
Storage System (BESS) with RoR HPPs controlled by a double-layer Model
Predictive Control (MPC). The upper layer MPC acts as a state of energy manager
for the BESS, employing a forecast of the required regulating energy for the
next hour. The lower-layer MPC optimally allocates the power set-point between
the turbine and the BESS. Reduced-scale experiments are performed on a
one-of-a-kind testing platform to validate the proposed MPC- based control
considering a comparison with different control strategies and different BESS
sizes. The results demonstrate superior performance of the proposed framework,
compared to simpler techniques like dead-band control or to the standalone RoR
scenario, leading to improved FCR provision, reduced servomechanism stress, and
extended hydropower asset lifespan.
</p>
</div>
</dd>
<dt><a name="item207">[207]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15662" title="Abstract">arXiv:2309.15662</a> [<a href="/pdf/2309.15662" title="Download PDF">pdf</a>, <a href="/format/2309.15662" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Human Kinematics-inspired Skeleton-based Video Anomaly Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xiao%2C+J">Jian Xiao</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+T">Tianyuan Liu</a>, 
<a href="/search/cs?searchtype=author&query=Ji%2C+G">Genlin Ji</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Previous approaches to detecting human anomalies in videos have typically
relied on implicit modeling by directly applying the model to video or skeleton
data, potentially resulting in inaccurate modeling of motion information. In
this paper, we conduct an exploratory study and introduce a new idea called
HKVAD (Human Kinematic-inspired Video Anomaly Detection) for video anomaly
detection, which involves the explicit use of human kinematic features to
detect anomalies. To validate the effectiveness and potential of this
perspective, we propose a pilot method that leverages the kinematic features of
the skeleton pose, with a specific focus on the walking stride, skeleton
displacement at feet level, and neck level. Following this, the method employs
a normalizing flow model to estimate density and detect anomalies based on the
estimated density. Based on the number of kinematic features used, we have
devised three straightforward variant methods and conducted experiments on two
highly challenging public datasets, ShanghaiTech and UBnormal. Our method
achieves good results with minimal computational resources, validating its
effectiveness and potential.
</p>
</div>
</dd>
<dt><a name="item208">[208]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15664" title="Abstract">arXiv:2309.15664</a> [<a href="/pdf/2309.15664" title="Download PDF">pdf</a>, <a href="/format/2309.15664" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Dynamic Prompt Learning: Addressing Cross-Attention Leakage for  Text-Based Image Editing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+K">Kai Wang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+F">Fei Yang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+S">Shiqi Yang</a>, 
<a href="/search/cs?searchtype=author&query=Butt%2C+M+A">Muhammad Atif Butt</a>, 
<a href="/search/cs?searchtype=author&query=van+de+Weijer%2C+J">Joost van de Weijer</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Neurips 2023. The code page: <a href="https://github.com/wangkai930418/DPL">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Large-scale text-to-image generative models have been a ground-breaking
development in generative AI, with diffusion models showing their astounding
ability to synthesize convincing images following an input text prompt. The
goal of image editing research is to give users control over the generated
images by modifying the text prompt. Current image editing techniques are
susceptible to unintended modifications of regions outside the targeted area,
such as on the background or on distractor objects which have some semantic or
visual relationship with the targeted object. According to our experimental
findings, inaccurate cross-attention maps are at the root of this problem.
Based on this observation, we propose Dynamic Prompt Learning (DPL) to force
cross-attention maps to focus on correct noun words in the text prompt. By
updating the dynamic tokens for nouns in the textual input with the proposed
leakage repairment losses, we achieve fine-grained image editing over
particular objects while preventing undesired changes to other image regions.
Our method DPL, based on the publicly available Stable Diffusion, is
extensively evaluated on a wide range of images, and consistently obtains
superior results both quantitatively (CLIP score, Structure-Dist) and
qualitatively (on user-evaluation). We show improved prompt editing results for
Word-Swap, Prompt Refinement, and Attention Re-weighting, especially for
complex multi-object scenes.
</p>
</div>
</dd>
<dt><a name="item209">[209]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15667" title="Abstract">arXiv:2309.15667</a> [<a href="/pdf/2309.15667" title="Download PDF">pdf</a>, <a href="/ps/2309.15667" title="Download PostScript">ps</a>, <a href="/format/2309.15667" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Uniform Poincar&#xe9; inequalities for the Discrete de Rham complex on  general domains
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Di+Pietro%2C+D+A">Daniele A. Di Pietro</a>, 
<a href="/search/math?searchtype=author&query=Hanot%2C+M">Marien-Lorenzo Hanot</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 24 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">In this paper we prove Poincar\'e inequalities for the Discrete de Rham (DDR)
sequence on a general connected polyhedral domain $\Omega$ of $\mathbb{R}^3$.
We unify the ideas behind the inequalities for all three operators in the
sequence, deriving new proofs for the Poincar\'e inequalities for the gradient
and the divergence, and extending the available Poincar\'e inequality for the
curl to domains with arbitrary second Betti numbers. A key preliminary step
consists in deriving "mimetic" Poincar\'e inequalities giving the existence and
stability of the solutions to topological balance problems useful in general
discrete geometric settings. As an example of application, we study the
stability of a novel DDR scheme for the magnetostatics problem on domains with
general topology.
</p>
</div>
</dd>
<dt><a name="item210">[210]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15668" title="Abstract">arXiv:2309.15668</a> [<a href="/pdf/2309.15668" title="Download PDF">pdf</a>, <a href="/format/2309.15668" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A New Centralized Multi-Node Repair Scheme of MSR codes with  Error-Correcting Capability
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+S">Shenghua Li</a>, 
<a href="/search/cs?searchtype=author&query=Gadouleau%2C+M">Maximilien Gadouleau</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jiaojiao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+D">Dabin Zheng</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Networking and Internet Architecture (cs.NI)

</div>
<p class="mathjax">Minimum storage regenerating (MSR) codes, with the MDS property and the
optimal repair bandwidth, are widely used in distributed storage systems (DSS)
for data recovery. In this paper, we consider the construction of $(n,k,l)$ MSR
codes in the centralized model that can repair $h$ failed nodes simultaneously
with $e$ out $d$ helper nodes providing erroneous information. We first propose
the new repair scheme, and give a complete proof of the lower bound on the
amount of symbols downloaded from the helped nodes, provided that some of
helper nodes provide erroneous information. Then we focus on two explicit
constructions with the repair scheme proposed. For $2\leq h\leq n-k$, $k+2e\leq
d \leq n-h$ and $d\equiv k+2e \;(\mod{h})$, the first one has the UER $(h,
d)$-optimal repair property, and the second one has the UER $(h, d)$-optimal
access property. Compared with the original constructions (Ye and Barg, IEEE
Tran. Inf. Theory, Vol. 63, April 2017), our constructions have improvements in
three aspects: 1) The proposed repair scheme is more feasible than the
one-by-one scheme presented by Ye and Barg in a parallel data system; 2) The
sub-packetization is reduced from $\left(\operatorname{lcm}(d-k+1,
d-k+2,\cdots, d-k+h)\right)^n$ to $\left((d-2e-k+h)/h\right)^n$, which reduces
at least by a factor of $(h(d-k+h))^n$; 3) The field size of the first
construction is reduced to $|\mathbb{F}| \geq n(d-2e-k+h)/h$, which reduces at
least by a factor of $h(d-k+h)$. Small sub-packetization and small field size
are preferred in practice due to the limited storage capacity and low
computation complexity in the process of encoding, decoding and repairing.
</p>
</div>
</dd>
<dt><a name="item211">[211]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15669" title="Abstract">arXiv:2309.15669</a> [<a href="/pdf/2309.15669" title="Download PDF">pdf</a>, <a href="/format/2309.15669" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On Computational Entanglement and Its Interpretation in Adversarial  Machine Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lai%2C+Y">YenLung Lai</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+X">Xingbo Dong</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+Z">Zhe Jin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Information Theory (cs.IT); Computational Physics (physics.comp-ph)

</div>
<p class="mathjax">Adversarial examples in machine learning has emerged as a focal point of
research due to their remarkable ability to deceive models with seemingly
inconspicuous input perturbations, potentially resulting in severe
consequences. In this study, we embark on a comprehensive exploration of
adversarial machine learning models, shedding light on their intrinsic
complexity and interpretability. Our investigation reveals intriguing links
between machine learning model complexity and Einstein's theory of special
relativity, through the concept of entanglement. More specific, we define
entanglement computationally and demonstrate that distant feature samples can
exhibit strong correlations, akin to entanglement in quantum realm. This
revelation challenges conventional perspectives in describing the phenomenon of
adversarial transferability observed in contemporary machine learning models.
By drawing parallels with the relativistic effects of time dilation and length
contraction during computation, we gain deeper insights into adversarial
machine learning, paving the way for more robust and interpretable models in
this rapidly evolving field.
</p>
</div>
</dd>
<dt><a name="item212">[212]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15670" title="Abstract">arXiv:2309.15670</a> [<a href="/pdf/2309.15670" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MONOVAB : An Annotated Corpus for Bangla Multi-label Emotion Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Banshal%2C+S+K">Sumit Kumar Banshal</a>, 
<a href="/search/cs?searchtype=author&query=Das%2C+S">Sajal Das</a>, 
<a href="/search/cs?searchtype=author&query=Shammi%2C+S+A">Shumaiya Akter Shammi</a>, 
<a href="/search/cs?searchtype=author&query=Chakraborty%2C+N+R">Narayan Ranjan Chakraborty</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computation and Language (cs.CL)

</div>
<p class="mathjax">In recent years, Sentiment Analysis (SA) and Emotion Recognition (ER) have
been increasingly popular in the Bangla language, which is the seventh most
spoken language throughout the entire world. However, the language is
structurally complicated, which makes this field arduous to extract emotions in
an accurate manner. Several distinct approaches such as the extraction of
positive and negative sentiments as well as multiclass emotions, have been
implemented in this field of study. Nevertheless, the extraction of multiple
sentiments is an almost untouched area in this language. Which involves
identifying several feelings based on a single piece of text. Therefore, this
study demonstrates a thorough method for constructing an annotated corpus based
on scrapped data from Facebook to bridge the gaps in this subject area to
overcome the challenges. To make this annotation more fruitful, the
context-based approach has been used. Bidirectional Encoder Representations
from Transformers (BERT), a well-known methodology of transformers, have been
shown the best results of all methods implemented. Finally, a web application
has been developed to demonstrate the performance of the pre-trained
top-performer model (BERT) for multi-label ER in Bangla.
</p>
</div>
</dd>
<dt><a name="item213">[213]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15674" title="Abstract">arXiv:2309.15674</a> [<a href="/pdf/2309.15674" title="Download PDF">pdf</a>, <a href="/format/2309.15674" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Speech collage: code-switched audio generation by collaging monolingual  corpora
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hussein%2C+A">Amir Hussein</a>, 
<a href="/search/cs?searchtype=author&query=Zeinali%2C+D">Dorsa Zeinali</a>, 
<a href="/search/cs?searchtype=author&query=Klejch%2C+O">Ond&#x159;ej Klejch</a>, 
<a href="/search/cs?searchtype=author&query=Wiesner%2C+M">Matthew Wiesner</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+B">Brian Yan</a>, 
<a href="/search/cs?searchtype=author&query=Chowdhury%2C+S">Shammur Chowdhury</a>, 
<a href="/search/cs?searchtype=author&query=Ali%2C+A">Ahmed Ali</a>, 
<a href="/search/cs?searchtype=author&query=Watanabe%2C+S">Shinji Watanabe</a>, 
<a href="/search/cs?searchtype=author&query=Khudanpur%2C+S">Sanjeev Khudanpur</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Computation and Language (cs.CL); Machine Learning (cs.LG); Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">Designing effective automatic speech recognition (ASR) systems for
Code-Switching (CS) often depends on the availability of the transcribed CS
resources. To address data scarcity, this paper introduces Speech Collage, a
method that synthesizes CS data from monolingual corpora by splicing audio
segments. We further improve the smoothness quality of audio generation using
an overlap-add approach. We investigate the impact of generated data on speech
recognition in two scenarios: using in-domain CS text and a zero-shot approach
with synthesized CS text. Empirical results highlight up to 34.4% and 16.2%
relative reductions in Mixed-Error Rate and Word-Error Rate for in-domain and
zero-shot scenarios, respectively. Lastly, we demonstrate that CS augmentation
bolsters the model's code-switching inclination and reduces its monolingual
bias.
</p>
</div>
</dd>
<dt><a name="item214">[214]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15675" title="Abstract">arXiv:2309.15675</a> [<a href="/pdf/2309.15675" title="Download PDF">pdf</a>, <a href="/format/2309.15675" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SJTU-TMQA: A quality assessment database for static mesh with texture  map
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cui%2C+B">Bingyang Cui</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Q">Qi Yang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+K">Kaifa Yang</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+Y">Yiling Xu</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+X">Xiaozhong Xu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+S">Shan Liu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">In recent years, static meshes with texture maps have become one of the most
prevalent digital representations of 3D shapes in various applications, such as
animation, gaming, medical imaging, and cultural heritage applications.
However, little research has been done on the quality assessment of textured
meshes, which hinders the development of quality-oriented applications, such as
mesh compression and enhancement. In this paper, we create a large-scale
textured mesh quality assessment database, namely SJTU-TMQA, which includes 21
reference meshes and 945 distorted samples. The meshes are rendered into
processed video sequences and then conduct subjective experiments to obtain
mean opinion scores (MOS). The diversity of content and accuracy of MOS has
been shown to validate its heterogeneity and reliability. The impact of various
types of distortion on human perception is demonstrated. 13 state-of-the-art
objective metrics are evaluated on SJTU-TMQA. The results report the highest
correlation of around 0.6, indicating the need for more effective objective
metrics. The SJTU-TMQA is available at https://ccccby.github.io
</p>
</div>
</dd>
<dt><a name="item215">[215]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15676" title="Abstract">arXiv:2309.15676</a> [<a href="/pdf/2309.15676" title="Download PDF">pdf</a>, <a href="/format/2309.15676" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Joint Sampling and Optimisation for Inverse Rendering
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Balint%2C+M">Martin Balint</a>, 
<a href="/search/cs?searchtype=author&query=Myszkowski%2C+K">Karol Myszkowski</a>, 
<a href="/search/cs?searchtype=author&query=Seidel%2C+H">Hans-Peter Seidel</a>, 
<a href="/search/cs?searchtype=author&query=Singh%2C+G">Gurprit Singh</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> SIGGRAPH Asia 2023 Conference Papers
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Graphics (cs.GR)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">When dealing with difficult inverse problems such as inverse rendering, using
Monte Carlo estimated gradients to optimise parameters can slow down
convergence due to variance. Averaging many gradient samples in each iteration
reduces this variance trivially. However, for problems that require thousands
of optimisation iterations, the computational cost of this approach rises
quickly.
<br />We derive a theoretical framework for interleaving sampling and optimisation.
We update and reuse past samples with low-variance finite-difference estimators
that describe the change in the estimated gradients between each iteration. By
combining proportional and finite-difference samples, we continuously reduce
the variance of our novel gradient meta-estimators throughout the optimisation
process. We investigate how our estimator interlinks with Adam and derive a
stable combination.
<br />We implement our method for inverse path tracing and demonstrate how our
estimator speeds up convergence on difficult optimisation tasks.
</p>
</div>
</dd>
<dt><a name="item216">[216]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15681" title="Abstract">arXiv:2309.15681</a> [<a href="/pdf/2309.15681" title="Download PDF">pdf</a>, <a href="/format/2309.15681" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Tactile-based Active Inference for Force-Controlled Peg-in-Hole  Insertions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kamijo%2C+T">Tatsuya Kamijo</a>, 
<a href="/search/cs?searchtype=author&query=Ramirez-Alpizar%2C+I+G">Ixchel G. Ramirez-Alpizar</a>, 
<a href="/search/cs?searchtype=author&query=Coronado%2C+E">Enrique Coronado</a>, 
<a href="/search/cs?searchtype=author&query=Venture%2C+G">Gentiane Venture</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, 4 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Reinforcement Learning (RL) has shown great promise for efficiently learning
force control policies in peg-in-hole tasks. However, robots often face
difficulties due to visual occlusions by the gripper and uncertainties in the
initial grasping pose of the peg. These challenges often restrict
force-controlled insertion policies to situations where the peg is rigidly
fixed to the end-effector. While vision-based tactile sensors offer rich
tactile feedback that could potentially address these issues, utilizing them to
learn effective tactile policies is both computationally intensive and
difficult to generalize. In this paper, we propose a robust tactile insertion
policy that can align the tilted peg with the hole using active inference,
without the need for extensive training on large datasets. Our approach employs
a dual-policy architecture: one policy focuses on insertion, integrating force
control and RL to guide the object into the hole, while the other policy
performs active inference based on tactile feedback to align the tilted peg
with the hole. In real-world experiments, our dual-policy architecture achieved
90% success rate into a hole with a clearance of less than 0.1 mm,
significantly outperforming previous methods that lack tactile sensory feedback
(5%). To assess the generalizability of our alignment policy, we conducted
experiments with five different pegs, demonstrating its effective adaptation to
multiple objects.
</p>
</div>
</dd>
<dt><a name="item217">[217]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15683" title="Abstract">arXiv:2309.15683</a> [<a href="/pdf/2309.15683" title="Download PDF">pdf</a>, <a href="/format/2309.15683" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> End-to-End Streaming Video Temporal Action Segmentation with Reinforce  Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wen%2C+W">Wujun Wen</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jinrong Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+S">Shenglan Liu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yunheng Li</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Q">Qifeng Li</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+L">Lin Feng</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 23pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Temporal Action Segmentation (TAS) from video is a kind of frame recognition
task for long video with multiple action classes. As an video understanding
task for long videos, current methods typically combine multi-modality action
recognition models with temporal models to convert feature sequences to label
sequences. This approach can only be applied to offline scenarios, which
severely limits the TAS application. Therefore, this paper proposes an
end-to-end Streaming Video Temporal Action Segmentation with Reinforce Learning
(SVTAS-RL). The end-to-end SVTAS which regard TAS as an action segment
clustering task can expand the application scenarios of TAS; and RL is used to
alleviate the problem of inconsistent optimization objective and direction.
Through extensive experiments, the SVTAS-RL model achieves a competitive
performance to the state-of-the-art model of TAS on multiple datasets, and
shows greater advantages on the ultra-long video dataset EGTEA. This indicates
that our method can replace all current TAS models end-to-end and SVTAS-RL is
more suitable for long video TAS. Code is availabel at
https://github.com/Thinksky5124/SVTAS.
</p>
</div>
</dd>
<dt><a name="item218">[218]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15685" title="Abstract">arXiv:2309.15685</a> [<a href="/pdf/2309.15685" title="Download PDF">pdf</a>, <a href="/format/2309.15685" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Improving Autonomous Driving Safety with POP: A Framework for Accurate  Partially Observed Trajectory Predictions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Sheng Wang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yingbing Chen</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+J">Jie Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Mei%2C+X">Xiaodong Mei</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+Y">Yongkang Song</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+M">Ming Liu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Accurate trajectory prediction is crucial for safe and efficient autonomous
driving, but handling partial observations presents significant challenges. To
address this, we propose a novel trajectory prediction framework called Partial
Observations Prediction (POP) for congested urban road scenarios. The framework
consists of two stages: self-supervised learning (SSL) and feature
distillation. In SSL, a reconstruction branch reconstructs the hidden history
of partial observations using a mask procedure and reconstruction head. The
feature distillation stage transfers knowledge from a fully observed teacher
model to a partially observed student model, improving prediction accuracy. POP
achieves comparable results to top-performing methods in open-loop experiments
and outperforms the baseline method in closed-loop simulations, including
safety metrics. Qualitative results illustrate the superiority of POP in
providing reasonable and safe trajectory predictions.
</p>
</div>
</dd>
<dt><a name="item219">[219]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15686" title="Abstract">arXiv:2309.15686</a> [<a href="/pdf/2309.15686" title="Download PDF">pdf</a>, <a href="/format/2309.15686" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Enhancing End-to-End Conversational Speech Translation Through Target  Language Context Utilization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hussein%2C+A">Amir Hussein</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+B">Brian Yan</a>, 
<a href="/search/cs?searchtype=author&query=Anastasopoulos%2C+A">Antonios Anastasopoulos</a>, 
<a href="/search/cs?searchtype=author&query=Watanabe%2C+S">Shinji Watanabe</a>, 
<a href="/search/cs?searchtype=author&query=Khudanpur%2C+S">Sanjeev Khudanpur</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Sound (cs.SD); Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">Incorporating longer context has been shown to benefit machine translation,
but the inclusion of context in end-to-end speech translation (E2E-ST) remains
under-studied. To bridge this gap, we introduce target language context in
E2E-ST, enhancing coherence and overcoming memory constraints of extended audio
segments. Additionally, we propose context dropout to ensure robustness to the
absence of context, and further improve performance by adding speaker
information. Our proposed contextual E2E-ST outperforms the isolated
utterance-based E2E-ST approach. Lastly, we demonstrate that in conversational
speech, contextual information primarily contributes to capturing context
style, as well as resolving anaphora and named entities.
</p>
</div>
</dd>
<dt><a name="item220">[220]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15687" title="Abstract">arXiv:2309.15687</a> [<a href="/pdf/2309.15687" title="Download PDF">pdf</a>, <a href="/format/2309.15687" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Breaking NoC Anonymity using Flow Correlation Attack
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Weerasena%2C+H">Hansika Weerasena</a>, 
<a href="/search/cs?searchtype=author&query=Zhixin%2C+P">Pan Zhixin</a>, 
<a href="/search/cs?searchtype=author&query=Rani%2C+K">Khushboo Rani</a>, 
<a href="/search/cs?searchtype=author&query=Mishra%2C+P">Prabhat Mishra</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Hardware Architecture (cs.AR); Machine Learning (cs.LG)

</div>
<p class="mathjax">Network-on-Chip (NoC) is widely used as the internal communication fabric in
today's multicore System-on-Chip (SoC) designs. Security of the on-chip
communication is crucial because exploiting any vulnerability in shared NoC
would be a goldmine for an attacker. NoC security relies on effective
countermeasures against diverse attacks. We investigate the security strength
of existing anonymous routing protocols in NoC architectures. Specifically,
this paper makes two important contributions. We show that the existing
anonymous routing is vulnerable to machine learning (ML) based flow correlation
attacks on NoCs. We propose a lightweight anonymous routing that use traffic
obfuscation techniques which can defend against ML-based flow correlation
attacks. Experimental studies using both real and synthetic traffic reveal that
our proposed attack is successful against state-of-the-art anonymous routing in
NoC architectures with a high accuracy (up to 99%) for diverse traffic
patterns, while our lightweight countermeasure can defend against ML-based
attacks with minor hardware and performance overhead.
</p>
</div>
</dd>
<dt><a name="item221">[221]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15696" title="Abstract">arXiv:2309.15696</a> [<a href="/pdf/2309.15696" title="Download PDF">pdf</a>, <a href="/format/2309.15696" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Unified View of Differentially Private Deep Generative Modeling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+D">Dingfan Chen</a>, 
<a href="/search/cs?searchtype=author&query=Kerkouche%2C+R">Raouf Kerkouche</a>, 
<a href="/search/cs?searchtype=author&query=Fritz%2C+M">Mario Fritz</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">The availability of rich and vast data sources has greatly advanced machine
learning applications in various domains. However, data with privacy concerns
comes with stringent regulations that frequently prohibited data access and
data sharing. Overcoming these obstacles in compliance with privacy
considerations is key for technological progress in many real-world application
scenarios that involve privacy sensitive data. Differentially private (DP) data
publishing provides a compelling solution, where only a sanitized form of the
data is publicly released, enabling privacy-preserving downstream analysis and
reproducible research in sensitive domains. In recent years, various approaches
have been proposed for achieving privacy-preserving high-dimensional data
generation by private training on top of deep neural networks. In this paper,
we present a novel unified view that systematizes these approaches. Our view
provides a joint design space for systematically deriving methods that cater to
different use cases. We then discuss the strengths, limitations, and inherent
correlations between different approaches, aiming to shed light on crucial
aspects and inspire future research. We conclude by presenting potential paths
forward for the field of DP data generation, with the aim of steering the
community toward making the next important steps in advancing
privacy-preserving learning.
</p>
</div>
</dd>
<dt><a name="item222">[222]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15697" title="Abstract">arXiv:2309.15697</a> [<a href="/pdf/2309.15697" title="Download PDF">pdf</a>, <a href="/format/2309.15697" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Physics Inspired Hybrid Attention for SAR Target Recognition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+Z">Zhongling Huang</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+C">Chong Wu</a>, 
<a href="/search/cs?searchtype=author&query=Yao%2C+X">Xiwen Yao</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Z">Zhicheng Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+X">Xiankai Huang</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+J">Junwei Han</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Image and Video Processing (eess.IV)

</div>
<p class="mathjax">There has been a recent emphasis on integrating physical models and deep
neural networks (DNNs) for SAR target recognition, to improve performance and
achieve a higher level of physical interpretability. The attributed scattering
center (ASC) parameters garnered the most interest, being considered as
additional input data or features for fusion in most methods. However, the
performance greatly depends on the ASC optimization result, and the fusion
strategy is not adaptable to different types of physical information.
Meanwhile, the current evaluation scheme is inadequate to assess the model's
robustness and generalizability. Thus, we propose a physics inspired hybrid
attention (PIHA) mechanism and the once-for-all (OFA) evaluation protocol to
address the above issues. PIHA leverages the high-level semantics of physical
information to activate and guide the feature group aware of local semantics of
target, so as to re-weight the feature importance based on knowledge prior. It
is flexible and generally applicable to various physical models, and can be
integrated into arbitrary DNNs without modifying the original architecture. The
experiments involve a rigorous assessment using the proposed OFA, which entails
training and validating a model on either sufficient or limited data and
evaluating on multiple test sets with different data distributions. Our method
outperforms other state-of-the-art approaches in 12 test scenarios with same
ASC parameters. Moreover, we analyze the working mechanism of PIHA and evaluate
various PIHA enabled DNNs. The experiments also show PIHA is effective for
different physical information. The source code together with the adopted
physical information is available at https://github.com/XAI4SAR.
</p>
</div>
</dd>
<dt><a name="item223">[223]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15698" title="Abstract">arXiv:2309.15698</a> [<a href="/pdf/2309.15698" title="Download PDF">pdf</a>, <a href="/format/2309.15698" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deep Model Fusion: A Survey
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+W">Weishi Li</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+Y">Yong Peng</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+M">Miao Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Ding%2C+L">Liang Ding</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+H">Han Hu</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+L">Li Shen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 46 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Deep model fusion/merging is an emerging technique that merges the parameters
or predictions of multiple deep learning models into a single one. It combines
the abilities of different models to make up for the biases and errors of a
single model to achieve better performance. However, deep model fusion on
large-scale deep learning models (e.g., LLMs and foundation models) faces
several challenges, including high computational cost, high-dimensional
parameter space, interference between different heterogeneous models, etc.
Although model fusion has attracted widespread attention due to its potential
to solve complex real-world tasks, there is still a lack of complete and
detailed survey research on this technique. Accordingly, in order to understand
the model fusion method better and promote its development, we present a
comprehensive survey to summarize the recent progress. Specifically, we
categorize existing deep model fusion methods as four-fold: (1) "Mode
connectivity", which connects the solutions in weight space via a path of
non-increasing loss, in order to obtain better initialization for model fusion;
(2) "Alignment" matches units between neural networks to create better
conditions for fusion; (3) "Weight average", a classical model fusion method,
averages the weights of multiple models to obtain more accurate results closer
to the optimal solution; (4) "Ensemble learning" combines the outputs of
diverse models, which is a foundational technique for improving the accuracy
and robustness of the final model. In addition, we analyze the challenges faced
by deep model fusion and propose possible research directions for model fusion
in the future. Our review is helpful in deeply understanding the correlation
between different model fusion methods and practical application methods, which
can enlighten the research in the field of deep model fusion.
</p>
</div>
</dd>
<dt><a name="item224">[224]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15700" title="Abstract">arXiv:2309.15700</a> [<a href="/pdf/2309.15700" title="Download PDF">pdf</a>, <a href="/format/2309.15700" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Tracking Snake-like Robots in the Wild Using Only a Single Camera
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lu%2C+J">Jingpei Lu</a>, 
<a href="/search/cs?searchtype=author&query=Richter%2C+F">Florian Richter</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+S">Shan Lin</a>, 
<a href="/search/cs?searchtype=author&query=Yip%2C+M+C">Michael C. Yip</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Robot navigation within complex environments requires precise state
estimation and localization to ensure robust and safe operations. For
ambulating mobile robots like robot snakes, traditional methods for sensing
require multiple embedded sensors or markers, leading to increased complexity,
cost, and increased points of failure. Alternatively, deploying an external
camera in the environment is very easy to do, and marker-less state estimation
of the robot from this camera's images is an ideal solution: both simple and
cost-effective. However, the challenge in this process is in tracking the robot
under larger environments where the cameras may be moved around without
extrinsic calibration, or maybe when in motion (e.g., a drone following the
robot). The scenario itself presents a complex challenge: single-image
reconstruction of robot poses under noisy observations. In this paper, we
address the problem of tracking ambulatory mobile robots from a single camera.
The method combines differentiable rendering with the Kalman filter. This
synergy allows for simultaneous estimation of the robot's joint angle and pose
while also providing state uncertainty which could be used later on for robust
control. We demonstrate the efficacy of our approach on a snake-like robot in
both stationary and non-stationary (moving) cameras, validating its performance
in both structured and unstructured scenarios. The results achieved show an
average error of 0.05 m in localizing the robot's base position and 6 degrees
in joint state estimation. We believe this novel technique opens up
possibilities for enhanced robot mobility and navigation in future exploratory
and search-and-rescue missions.
</p>
</div>
</dd>
<dt><a name="item225">[225]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15701" title="Abstract">arXiv:2309.15701</a> [<a href="/pdf/2309.15701" title="Download PDF">pdf</a>, <a href="/format/2309.15701" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> HyPoradise: An Open Baseline for Generative Speech Recognition with  Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+C">Chen Chen</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+Y">Yuchen Hu</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+C+H">Chao-Han Huck Yang</a>, 
<a href="/search/cs?searchtype=author&query=Siniscalchi%2C+S+M">Sabato Macro Siniscalchi</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+P">Pin-Yu Chen</a>, 
<a href="/search/cs?searchtype=author&query=Chng%2C+E+S">Eng Siong Chng</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to NeurIPS 2023, 24 pages. Datasets and Benchmarks Track
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Sound (cs.SD); Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">Advancements in deep neural networks have allowed automatic speech
recognition (ASR) systems to attain human parity on several publicly available
clean speech datasets. However, even state-of-the-art ASR systems experience
performance degradation when confronted with adverse conditions, as a
well-trained acoustic model is sensitive to variations in the speech domain,
e.g., background noise. Intuitively, humans address this issue by relying on
their linguistic knowledge: the meaning of ambiguous spoken terms is usually
inferred from contextual cues thereby reducing the dependency on the auditory
system. Inspired by this observation, we introduce the first open-source
benchmark to utilize external large language models (LLMs) for ASR error
correction, where N-best decoding hypotheses provide informative elements for
true transcription prediction. This approach is a paradigm shift from the
traditional language model rescoring strategy that can only select one
candidate hypothesis as the output transcription. The proposed benchmark
contains a novel dataset, HyPoradise (HP), encompassing more than 334,000 pairs
of N-best hypotheses and corresponding accurate transcriptions across prevalent
speech domains. Given this dataset, we examine three types of error correction
techniques based on LLMs with varying amounts of labeled
hypotheses-transcription pairs, which gains a significant word error rate (WER)
reduction. Experimental evidence demonstrates the proposed technique achieves a
breakthrough by surpassing the upper bound of traditional re-ranking based
methods. More surprisingly, LLM with reasonable prompt and its generative
capability can even correct those tokens that are missing in N-best list. We
make our results publicly accessible for reproducible pipelines with released
pre-trained models, thus providing a new evaluation paradigm for ASR error
correction with LLMs.
</p>
</div>
</dd>
<dt><a name="item226">[226]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15702" title="Abstract">arXiv:2309.15702</a> [<a href="/pdf/2309.15702" title="Download PDF">pdf</a>, <a href="/format/2309.15702" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SGRec3D: Self-Supervised 3D Scene Graph Learning via Object-Level Scene  Reconstruction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Koch%2C+S">Sebastian Koch</a>, 
<a href="/search/cs?searchtype=author&query=Hermosilla%2C+P">Pedro Hermosilla</a>, 
<a href="/search/cs?searchtype=author&query=Vaskevicius%2C+N">Narunas Vaskevicius</a>, 
<a href="/search/cs?searchtype=author&query=Colosi%2C+M">Mirco Colosi</a>, 
<a href="/search/cs?searchtype=author&query=Ropinski%2C+T">Timo Ropinski</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 4 figures, 6 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">In the field of 3D scene understanding, 3D scene graphs have emerged as a new
scene representation that combines geometric and semantic information about
objects and their relationships. However, learning semantic 3D scene graphs in
a fully supervised manner is inherently difficult as it requires not only
object-level annotations but also relationship labels. While pre-training
approaches have helped to boost the performance of many methods in various
fields, pre-training for 3D scene graph prediction has received little
attention. Furthermore, we find in this paper that classical contrastive point
cloud-based pre-training approaches are ineffective for 3D scene graph
learning. To this end, we present SGRec3D, a novel self-supervised pre-training
method for 3D scene graph prediction. We propose to reconstruct the 3D input
scene from a graph bottleneck as a pretext task. Pre-training SGRec3D does not
require object relationship labels, making it possible to exploit large-scale
3D scene understanding datasets, which were off-limits for 3D scene graph
learning before. Our experiments demonstrate that in contrast to recent point
cloud-based pre-training approaches, our proposed pre-training improves the 3D
scene graph prediction considerably, which results in SOTA performance,
outperforming other 3D scene graph models by +10% on object prediction and +4%
on relationship prediction. Additionally, we show that only using a small
subset of 10% labeled data during fine-tuning is sufficient to outperform the
same model without pre-training.
</p>
</div>
</dd>
<dt><a name="item227">[227]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15703" title="Abstract">arXiv:2309.15703</a> [<a href="/pdf/2309.15703" title="Download PDF">pdf</a>, <a href="/format/2309.15703" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Physics-Based Rigid Body Object Tracking and Friction Filtering From  RGB-D Videos
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kandukuri%2C+R+K">Rama Krishna Kandukuri</a>, 
<a href="/search/cs?searchtype=author&query=Strecke%2C+M">Michael Strecke</a>, 
<a href="/search/cs?searchtype=author&query=Stueckler%2C+J">Joerg Stueckler</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Physics-based understanding of object interactions from sensory observations
is an essential capability in augmented reality and robotics. It enables
capturing the properties of a scene for simulation and control. In this paper,
we propose a novel approach for real-to-sim which tracks rigid objects in 3D
from RGB-D images and infers physical properties of the objects. We use a
differentiable physics simulation as state-transition model in an Extended
Kalman Filter which can model contact and friction for arbitrary mesh-based
shapes and in this way estimate physically plausible trajectories. We
demonstrate that our approach can filter position, orientation, velocities, and
concurrently can estimate the coefficient of friction of the objects. We
analyse our approach on various sliding scenarios in synthetic image sequences
of single objects and colliding objects. We also demonstrate and evaluate our
approach on a real-world dataset. We will make our novel benchmark datasets
publicly available to foster future research in this novel problem setting and
comparison with our method.
</p>
</div>
</dd>
<dt><a name="item228">[228]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15704" title="Abstract">arXiv:2309.15704</a> [<a href="/pdf/2309.15704" title="Download PDF">pdf</a>, <a href="/format/2309.15704" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Maximum Weight Entropy
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=de+Mathelin%2C+A">Antoine de Mathelin</a>, 
<a href="/search/cs?searchtype=author&query=Deheeger%2C+F">Fran&#xe7;ois Deheeger</a>, 
<a href="/search/cs?searchtype=author&query=Mougeot%2C+M">Mathilde Mougeot</a>, 
<a href="/search/cs?searchtype=author&query=Vayatis%2C+N">Nicolas Vayatis</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 60 pages, 9 figures, 6 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">This paper deals with uncertainty quantification and out-of-distribution
detection in deep learning using Bayesian and ensemble methods. It proposes a
practical solution to the lack of prediction diversity observed recently for
standard approaches when used out-of-distribution (Ovadia et al., 2019; Liu et
al., 2021). Considering that this issue is mainly related to a lack of weight
diversity, we claim that standard methods sample in "over-restricted" regions
of the weight space due to the use of "over-regularization" processes, such as
weight decay and zero-mean centered Gaussian priors. We propose to solve the
problem by adopting the maximum entropy principle for the weight distribution,
with the underlying idea to maximize the weight diversity. Under this paradigm,
the epistemic uncertainty is described by the weight distribution of maximal
entropy that produces neural networks "consistent" with the training
observations. Considering stochastic neural networks, a practical optimization
is derived to build such a distribution, defined as a trade-off between the
average empirical risk and the weight distribution entropy. We develop a novel
weight parameterization for the stochastic model, based on the singular value
decomposition of the neural network's hidden representations, which enables a
large increase of the weight entropy for a small empirical risk penalization.
We provide both theoretical and numerical results to assess the efficiency of
the approach. In particular, the proposed algorithm appears in the top three
best methods in all configurations of an extensive out-of-distribution
detection benchmark including more than thirty competitors.
</p>
</div>
</dd>
<dt><a name="item229">[229]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15709" title="Abstract">arXiv:2309.15709</a> [<a href="/pdf/2309.15709" title="Download PDF">pdf</a>, <a href="/ps/2309.15709" title="Download PostScript">ps</a>, <a href="/format/2309.15709" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Distributed Pilot Assignment for Distributed Massive-MIMO Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Khan%2C+M+S+A">Mohd Saif Ali Khan</a>, 
<a href="/search/cs?searchtype=author&query=Agnihotri%2C+S">Samar Agnihotri</a>, 
<a href="/search/cs?searchtype=author&query=M%2C+K+R">Karthik R.M</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>; Information Theory (cs.IT)

</div>
<p class="mathjax">Pilot contamination is a critical issue in distributed massive MIMO networks,
where the reuse of pilot sequences due to limited availability of orthogonal
pilots for channel estimation leads to performance degradation. In this work,
we propose a novel distributed pilot assignment scheme to effectively mitigate
the impact of pilot contamination. Our proposed scheme not only reduces
signaling overhead, but it also enhances fault-tolerance. Extensive numerical
simulations are conducted to evaluate the performance of the proposed scheme.
Our results establish that the proposed scheme outperforms existing centralized
and distributed schemes in terms of mitigating pilot contamination and
significantly enhancing network throughput.
</p>
</div>
</dd>
<dt><a name="item230">[230]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15714" title="Abstract">arXiv:2309.15714</a> [<a href="/pdf/2309.15714" title="Download PDF">pdf</a>, <a href="/format/2309.15714" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ChatGPT-BCI: Word-Level Neural State Classification Using GPT, EEG, and  Eye-Tracking Biomarkers in Semantic Inference Reading Comprehension
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yuhong Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Q">Qin Li</a>, 
<a href="/search/cs?searchtype=author&query=Nahata%2C+S">Sujal Nahata</a>, 
<a href="/search/cs?searchtype=author&query=Jamal%2C+T">Tasnia Jamal</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+S">Shih-kuen Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Cauwenberghs%2C+G">Gert Cauwenberghs</a>, 
<a href="/search/cs?searchtype=author&query=Jung%2C+T">Tzyy-Ping Jung</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">With the recent explosion of large language models (LLMs), such as Generative
Pretrained Transformers (GPT), the need to understand the ability of humans and
machines to comprehend semantic language meaning has entered a new phase. This
requires interdisciplinary research that bridges the fields of cognitive
science and natural language processing (NLP). This pilot study aims to provide
insights into individuals' neural states during a semantic relation
reading-comprehension task. We propose jointly analyzing LLMs, eye-gaze, and
electroencephalographic (EEG) data to study how the brain processes words with
varying degrees of relevance to a keyword during reading. We also use a feature
engineering approach to improve the fixation-related EEG data classification
while participants read words with high versus low relevance to the keyword.
The best validation accuracy in this word-level classification is over 60\%
across 12 subjects. Words of high relevance to the inference keyword had
significantly more eye fixations per word: 1.0584 compared to 0.6576 when
excluding no-fixation words, and 1.5126 compared to 1.4026 when including them.
This study represents the first attempt to classify brain states at a word
level using LLM knowledge. It provides valuable insights into human cognitive
abilities and the realm of Artificial General Intelligence (AGI), and offers
guidance for developing potential reading-assisted technologies.
</p>
</div>
</dd>
<dt><a name="item231">[231]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15719" title="Abstract">arXiv:2309.15719</a> [<a href="/pdf/2309.15719" title="Download PDF">pdf</a>, <a href="/format/2309.15719" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Model Share AI: An Integrated Toolkit for Collaborative Machine Learning  Model Development, Provenance Tracking, and Deployment in Python
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Peters%2C+H">Heinrich Peters</a>, 
<a href="/search/cs?searchtype=author&query=Parrott%2C+M">Michael Parrott</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Machine learning (ML) has the potential to revolutionize a wide range of
research areas and industries, but many ML projects never progress past the
proof-of-concept stage. To address this issue, we introduce Model Share AI
(AIMS), an easy-to-use MLOps platform designed to streamline collaborative
model development, model provenance tracking, and model deployment, as well as
a host of other functions aiming to maximize the real-world impact of ML
research. AIMS features collaborative project spaces and a standardized model
evaluation process that ranks model submissions based on their performance on
unseen evaluation data, enabling collaborative model development and
crowd-sourcing. Model performance and various model metadata are automatically
captured to facilitate provenance tracking and allow users to learn from and
build on previous submissions. Additionally, AIMS allows users to deploy ML
models built in Scikit-Learn, TensorFlow Keras, PyTorch, and ONNX into live
REST APIs and automatically generated web apps with minimal code. The ability
to deploy models with minimal effort and to make them accessible to
non-technical end-users through web apps has the potential to make ML research
more applicable to real-world challenges.
</p>
</div>
</dd>
<dt><a name="item232">[232]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15723" title="Abstract">arXiv:2309.15723</a> [<a href="/pdf/2309.15723" title="Download PDF">pdf</a>, <a href="/format/2309.15723" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Where Are We So Far? Understanding Data Storytelling Tools from the  Perspective of Human-AI Collaboration
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Haotian Li</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yun Wang</a>, 
<a href="/search/cs?searchtype=author&query=Qu%2C+H">Huamin Qu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Data storytelling is powerful for communicating data insights, but it
requires diverse skills and considerable effort from human creators. Recent
research has widely explored the potential for artificial intelligence (AI) to
support and augment humans in data storytelling. However, there lacks a
systematic review to understand data storytelling tools from the perspective of
human-AI collaboration, which hinders researchers from reflecting on the
existing collaborative tool designs that promote humans' and AI's advantages
and mitigate their shortcomings. This paper investigated existing tools with a
framework from two perspectives: the stages in the storytelling workflow where
a tool serves, including analysis, planning, implementation, and communication,
and the roles of humans and AI in each stage, such as creators, assistants,
optimizers, and reviewers. Through our analysis, we recognize the common
collaboration patterns in existing tools, summarize lessons learned from these
patterns, and further illustrate research opportunities for human-AI
collaboration in data storytelling.
</p>
</div>
</dd>
<dt><a name="item233">[233]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15724" title="Abstract">arXiv:2309.15724</a> [<a href="/pdf/2309.15724" title="Download PDF">pdf</a>, <a href="/ps/2309.15724" title="Download PostScript">ps</a>, <a href="/format/2309.15724" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Making Logical Relations More Relatable (Proof Pearl)
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Acevedo%2C+E+S">Emmanuel Su&#xe1;rez Acevedo</a>, 
<a href="/search/cs?searchtype=author&query=Weirich%2C+S">Stephanie Weirich</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted for publication
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Programming Languages (cs.PL)</span>

</div>
<p class="mathjax">Mechanical proofs by logical relations often involve tedious reasoning about
substitution. In this paper, we show that this is not necessarily the case, by
developing, in Agda, a proof that all simply typed lambda calculus expressions
evaluate to values. A formalization of the proof is remarkably short (~40 lines
of code), making for an excellent introduction to the technique of proofs by
logical relations not only on paper but also in a mechanized setting. We then
show that this process extends to more sophisticated reasoning by also proving
the totality of normalization by evaluation. Although these proofs are not new,
we believe presenting them will empower both new and experienced programming
language theorists in their use of logical relations.
</p>
</div>
</dd>
<dt><a name="item234">[234]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15726" title="Abstract">arXiv:2309.15726</a> [<a href="/pdf/2309.15726" title="Download PDF">pdf</a>, <a href="/format/2309.15726" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Factorized Diffusion Architectures for Unsupervised Image Generation and  Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yuan%2C+X">Xin Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Maire%2C+M">Michael Maire</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">We develop a neural network architecture which, trained in an unsupervised
manner as a denoising diffusion model, simultaneously learns to both generate
and segment images. Learning is driven entirely by the denoising diffusion
objective, without any annotation or prior knowledge about regions during
training. A computational bottleneck, built into the neural architecture,
encourages the denoising network to partition an input into regions, denoise
them in parallel, and combine the results. Our trained model generates both
synthetic images and, by simple examination of its internal predicted
partitions, a semantic segmentation of those images. Without any finetuning, we
directly apply our unsupervised model to the downstream task of segmenting real
images via noising and subsequently denoising them. Experiments demonstrate
that our model achieves accurate unsupervised image segmentation and
high-quality synthetic image generation across multiple datasets.
</p>
</div>
</dd>
<dt><a name="item235">[235]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15727" title="Abstract">arXiv:2309.15727</a> [<a href="/pdf/2309.15727" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Scalable FMI-based Co-simulation of Wind Energy Systems Using  PowerFactory
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=van+der+Meer%2C+A+A">Arjen A van der Meer</a>, 
<a href="/search/eess?searchtype=author&query=Bhandia%2C+R">Rishabh Bhandia</a>, 
<a href="/search/eess?searchtype=author&query=Widl%2C+E">Edmund Widl</a>, 
<a href="/search/eess?searchtype=author&query=Heussen%2C+K">Kai Heussen</a>, 
<a href="/search/eess?searchtype=author&query=Steinbrink%2C+C">Cornelius Steinbrink</a>, 
<a href="/search/eess?searchtype=author&query=Chodura%2C+P">Przemyslaw Chodura</a>, 
<a href="/search/eess?searchtype=author&query=Strasser%2C+T+I">Thomas I. Strasser</a>, 
<a href="/search/eess?searchtype=author&query=Palensky%2C+P">Peter Palensky</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 2019 IEEE PES Innovative Smart Grid Technologies Europe (ISGT-Europe)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">Due to the increased deployment of renewable energy sources and intelligent
components the electric power system will exhibit a large degree of
heterogeneity, which requires inclusive and multi-disciplinary system
assessment. The concept of co-simulation is a very attractive option to achieve
this; each domain-specific subsystem can be addressed via its own specialized
simulation tool. The applicability, however, depends on aspects like
standardised interfaces, automated case creation, initialisation, and the
scalability of the co-simulation itself. This work deals with the inclusion of
the Functional Mock-up Interface for co-simulation into the DIgSILENT
PowerFactory simulator, and tests its accuracy, implementation, and scalability
for the grid connection study of a wind power plant. The coupling between the
RMS mode of PowerFactory and MATLAB/Simulink in a standardised manner is shown.
This approach allows a straightforward inclusion of black-boxed modelling, is
easily scalable in size, quantity, and component type.
</p>
</div>
</dd>
<dt><a name="item236">[236]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15728" title="Abstract">arXiv:2309.15728</a> [<a href="/pdf/2309.15728" title="Download PDF">pdf</a>, <a href="/format/2309.15728" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Line Graph Neural Networks for Link Weight Prediction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liang%2C+J">Jinbi Liang</a>, 
<a href="/search/cs?searchtype=author&query=Pu%2C+C">Cunlai Pu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>

</div>
<p class="mathjax">Link weight prediction is of great practical importance, since real-world
networks are often weighted networks. Previous studies have mainly used shallow
graph features for link weight prediction, which limits the prediction
performance. In this paper, we propose a new link weight prediction algorithm,
namely Line Graph Neural Networks for Link Weight Prediction (LGLWP), which
learns deeper graph features through deep learning. In our algorithm, we first
extract the enclosing subgraph around a target link, and then employ a weighted
graph labeling algorithm to label the subgraph nodes. Next, we transform the
subgraph into a line graph and apply the graph convolution neural networks to
learn the node embedding in the line graph, which can represent the links in
the original subgraph. Finally, the link feature vectors are put into a
fully-connected neural network to predict the weight of the target link. Our
algorithm directly obtain the feature vectors of the target links in the
original graph, which is better than the previous methods that splice the node
feature vectors for link weight prediction. Experiments results on six real
datasets of various network sizes and types show that our algorithm has better
prediction performance than the state-of-art methods, while it has fewer
parameters and high training efficiency.
</p>
</div>
</dd>
<dt><a name="item237">[237]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15729" title="Abstract">arXiv:2309.15729</a> [<a href="/pdf/2309.15729" title="Download PDF">pdf</a>, <a href="/format/2309.15729" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MindGPT: Interpreting What You See with Non-invasive Brain Recordings
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Jiaxuan Chen</a>, 
<a href="/search/cs?searchtype=author&query=Qi%2C+Y">Yu Qi</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yueming Wang</a>, 
<a href="/search/cs?searchtype=author&query=Pan%2C+G">Gang Pan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, 6 figures, submitted to anonymous conference
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Decoding of seen visual contents with non-invasive brain recordings has
important scientific and practical values. Efforts have been made to recover
the seen images from brain signals. However, most existing approaches cannot
faithfully reflect the visual contents due to insufficient image quality or
semantic mismatches. Compared with reconstructing pixel-level visual images,
speaking is a more efficient and effective way to explain visual information.
Here we introduce a non-invasive neural decoder, termed as MindGPT, which
interprets perceived visual stimuli into natural languages from fMRI signals.
Specifically, our model builds upon a visually guided neural encoder with a
cross-attention mechanism, which permits us to guide latent neural
representations towards a desired language semantic direction in an end-to-end
manner by the collaborative use of the large language model GPT. By doing so,
we found that the neural representations of the MindGPT are explainable, which
can be used to evaluate the contributions of visual properties to language
semantics. Our experiments show that the generated word sequences truthfully
represented the visual information (with essential details) conveyed in the
seen stimuli. The results also suggested that with respect to language decoding
tasks, the higher visual cortex (HVC) is more semantically informative than the
lower visual cortex (LVC), and using only the HVC can recover most of the
semantic information. The code of the MindGPT model will be publicly available
at https://github.com/JxuanC/MindGPT.
</p>
</div>
</dd>
<dt><a name="item238">[238]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15730" title="Abstract">arXiv:2309.15730</a> [<a href="/pdf/2309.15730" title="Download PDF">pdf</a>, <a href="/format/2309.15730" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Temporal graph models fail to capture global temporal dynamics
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Daniluk%2C+M">Micha&#x142; Daniluk</a>, 
<a href="/search/cs?searchtype=author&query=D%C4%85browski%2C+J">Jacek D&#x105;browski</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">A recently released Temporal Graph Benchmark is analyzed in the context of
Dynamic Link Property Prediction. We outline our observations and propose a
trivial optimization-free baseline of "recently popular nodes" outperforming
other methods on all medium and large-size datasets in the Temporal Graph
Benchmark. We propose two measures based on Wasserstein distance which can
quantify the strength of short-term and long-term global dynamics of datasets.
By analyzing our unexpectedly strong baseline, we show how standard negative
sampling evaluation can be unsuitable for datasets with strong temporal
dynamics. We also show how simple negative-sampling can lead to model
degeneration during training, resulting in impossible to rank, fully saturated
predictions of temporal graph networks. We propose improved negative sampling
schemes for both training and evaluation and prove their usefulness. We conduct
a comparison with a model trained non-contrastively without negative sampling.
Our results provide a challenging baseline and indicate that temporal graph
network architectures need deep rethinking for usage in problems with
significant global dynamics, such as social media, cryptocurrency markets or
e-commerce. We open-source the code for baselines, measures and proposed
negative sampling schemes.
</p>
</div>
</dd>
<dt><a name="item239">[239]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15731" title="Abstract">arXiv:2309.15731</a> [<a href="/pdf/2309.15731" title="Download PDF">pdf</a>, <a href="/format/2309.15731" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A user study of visualisations of spatio-temporal eye tracking data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Claus%2C+M">Marcel Claus</a>, 
<a href="/search/cs?searchtype=author&query=Hermens%2C+F">Frouke Hermens</a>, 
<a href="/search/cs?searchtype=author&query=Bromuri%2C+S">Stefano Bromuri</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 pages, 8 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">Eye movements have a spatial (where people look), but also a temporal (when
people look) component. Various types of visualizations have been proposed that
take this spatio-temporal nature of the data into account, but it is unclear
how well each one can be interpreted and whether such interpretation depends on
the question asked about the data or the nature of the data-set that is being
visualised. In this study, four spatio-temporal visualization techniques for
eye movements (chord diagram, scanpath, scarfplot, space-time cube) were
compared in a user study. Participants (N = 25) answered three questions (what
region first, what region most, which regions most between) about each
visualization, which was based on two types of data-sets (eye movements towards
adverts, eye movements towards pairs of gambles). Accuracy of the answers
depended on a combination of the data-set, the question that needed to
answered, and the type of visualization. For most questions, the scanpath,
which did not use area of interest (AOI) information, resulted in lower
accuracy than the other graphs. This suggests that AOIs improve the information
conveyed by graphs. No effects of experience with reading graphs (for work or
not for work) or education on accuracy of the answer was found. The results
therefore suggest that there is no single best visualisation of the
spatio-temporal aspects of eye movements. When visualising eye movement data, a
user study may therefore be beneficial to determine the optimal visualization
of the data-set and research question at hand.
</p>
</div>
</dd>
<dt><a name="item240">[240]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15732" title="Abstract">arXiv:2309.15732</a> [<a href="/pdf/2309.15732" title="Download PDF">pdf</a>, <a href="/ps/2309.15732" title="Download PostScript">ps</a>, <a href="/format/2309.15732" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deep Learning-based Analysis of Basins of Attraction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Valle%2C+D">David Valle</a>, 
<a href="/search/cs?searchtype=author&query=Wagemakers%2C+A">Alexandre Wagemakers</a>, 
<a href="/search/cs?searchtype=author&query=Sanju%C3%A1n%2C+M+A+F">Miguel A.F. Sanju&#xe1;n</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">This study showcases the effectiveness of convolutional neural networks
(CNNs) in characterizing the complexity and unpredictability of basins of
attraction for diverse dynamical systems. This novel method is optimal for
exploring different parameters of dynamical systems since the conventional
methods are computationally expensive for characterizing multiple basins of
attraction. Additionally, our research includes a comparison of different CNN
architectures for this task showing the superiority of our proposed
characterization method over the conventional methods, even with obsolete
architectures.
</p>
</div>
</dd>
<dt><a name="item241">[241]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15734" title="Abstract">arXiv:2309.15734</a> [<a href="/pdf/2309.15734" title="Download PDF">pdf</a>, <a href="/format/2309.15734" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Synthetic Latent Fingerprint Generation Using Style Transfer
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Joshi%2C+A+S">Amol S. Joshi</a>, 
<a href="/search/cs?searchtype=author&query=Dabouei%2C+A">Ali Dabouei</a>, 
<a href="/search/cs?searchtype=author&query=Nasrabadi%2C+N">Nasser Nasrabadi</a>, 
<a href="/search/cs?searchtype=author&query=Dawson%2C+J">Jeremy Dawson</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Limited data availability is a challenging problem in the latent fingerprint
domain. Synthetically generated fingerprints are vital for training data-hungry
neural network-based algorithms. Conventional methods distort clean
fingerprints to generate synthetic latent fingerprints. We propose a simple and
effective approach using style transfer and image blending to synthesize
realistic latent fingerprints. Our evaluation criteria and experiments
demonstrate that the generated synthetic latent fingerprints preserve the
identity information from the input contact-based fingerprints while possessing
similar characteristics as real latent fingerprints. Additionally, we show that
the generated fingerprints exhibit several qualities and styles, suggesting
that the proposed method can generate multiple samples from a single
fingerprint.
</p>
</div>
</dd>
<dt><a name="item242">[242]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15737" title="Abstract">arXiv:2309.15737</a> [<a href="/pdf/2309.15737" title="Download PDF">pdf</a>, <a href="/format/2309.15737" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Provably Efficient Exploration in Constrained Reinforcement  Learning:Posterior Sampling Is All You Need
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Provodin%2C+D">Danil Provodin</a>, 
<a href="/search/cs?searchtype=author&query=Gajane%2C+P">Pratik Gajane</a>, 
<a href="/search/cs?searchtype=author&query=Pechenizkiy%2C+M">Mykola Pechenizkiy</a>, 
<a href="/search/cs?searchtype=author&query=Kaptein%2C+M">Maurits Kaptein</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">We present a new algorithm based on posterior sampling for learning in
constrained Markov decision processes (CMDP) in the infinite-horizon
undiscounted setting. The algorithm achieves near-optimal regret bounds while
being advantageous empirically compared to the existing algorithms. Our main
theoretical result is a Bayesian regret bound for each cost component of
\tilde{O} (HS \sqrt{AT}) for any communicating CMDP with S states, A actions,
and bound on the hitting time H. This regret bound matches the lower bound in
order of time horizon T and is the best-known regret bound for communicating
CMDPs in the infinite-horizon undiscounted setting. Empirical results show
that, despite its simplicity, our posterior sampling algorithm outperforms the
existing algorithms for constrained reinforcement learning.
</p>
</div>
</dd>
<dt><a name="item243">[243]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15739" title="Abstract">arXiv:2309.15739</a> [<a href="/pdf/2309.15739" title="Download PDF">pdf</a>, <a href="/format/2309.15739" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Experience and Evidence are the eyes of an excellent summarizer! Towards  Knowledge Infused Multi-modal Clinical Conversation Summarization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tiwari%2C+A">Abhisek Tiwari</a>, 
<a href="/search/cs?searchtype=author&query=Saha%2C+A">Anisha Saha</a>, 
<a href="/search/cs?searchtype=author&query=Saha%2C+S">Sriparna Saha</a>, 
<a href="/search/cs?searchtype=author&query=Bhattacharyya%2C+P">Pushpak Bhattacharyya</a>, 
<a href="/search/cs?searchtype=author&query=Dhar%2C+M">Minakshi Dhar</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">With the advancement of telemedicine, both researchers and medical
practitioners are working hand-in-hand to develop various techniques to
automate various medical operations, such as diagnosis report generation. In
this paper, we first present a multi-modal clinical conversation summary
generation task that takes a clinician-patient interaction (both textual and
visual information) and generates a succinct synopsis of the conversation. We
propose a knowledge-infused, multi-modal, multi-tasking medical domain
identification and clinical conversation summary generation
(MM-CliConSummation) framework. It leverages an adapter to infuse knowledge and
visual features and unify the fused feature vector using a gated mechanism.
Furthermore, we developed a multi-modal, multi-intent clinical conversation
summarization corpus annotated with intent, symptom, and summary. The extensive
set of experiments, both quantitatively and qualitatively, led to the following
findings: (a) critical significance of visuals, (b) more precise and medical
entity preserving summary with additional knowledge infusion, and (c) a
correlation between medical department identification and clinical synopsis
generation. Furthermore, the dataset and source code are available at
https://github.com/NLP-RL/MM-CliConSummation.
</p>
</div>
</dd>
<dt><a name="item244">[244]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15740" title="Abstract">arXiv:2309.15740</a> [<a href="/pdf/2309.15740" title="Download PDF">pdf</a>, <a href="/format/2309.15740" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Data-Driven Latent Space Representation for Robust Bipedal Locomotion  Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Castillo%2C+G+A">Guillermo A. Castillo</a>, 
<a href="/search/cs?searchtype=author&query=Weng%2C+B">Bowen Weng</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+W">Wei Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Hereid%2C+A">Ayonga Hereid</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Supplemental video: <a href="https://youtu.be/SUIkrigsrao">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">This paper presents a novel framework for learning robust bipedal walking by
combining a data-driven state representation with a Reinforcement Learning (RL)
based locomotion policy. The framework utilizes an autoencoder to learn a
low-dimensional latent space that captures the complex dynamics of bipedal
locomotion from existing locomotion data. This reduced dimensional state
representation is then used as states for training a robust RL-based gait
policy, eliminating the need for heuristic state selections or the use of
template models for gait planning. The results demonstrate that the learned
latent variables are disentangled and directly correspond to different gaits or
speeds, such as moving forward, backward, or walking in place. Compared to
traditional template model-based approaches, our framework exhibits superior
performance and robustness in simulation. The trained policy effectively tracks
a wide range of walking speeds and demonstrates good generalization
capabilities to unseen scenarios.
</p>
</div>
</dd>
<dt><a name="item245">[245]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15742" title="Abstract">arXiv:2309.15742</a> [<a href="/pdf/2309.15742" title="Download PDF">pdf</a>, <a href="/format/2309.15742" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> T5APR: Empowering Automated Program Repair across Languages through  Checkpoint Ensemble
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gharibi%2C+R">Reza Gharibi</a>, 
<a href="/search/cs?searchtype=author&query=Sadreddini%2C+M+H">Mohammad Hadi Sadreddini</a>, 
<a href="/search/cs?searchtype=author&query=Fakhrahmad%2C+S+M">Seyed Mostafa Fakhrahmad</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
<p class="mathjax">Automated program repair (APR) using deep learning techniques has become an
important area of research in recent years, aiming to automatically generate
bug-fixing patches that can improve software reliability and maintainability.
However, most existing methods either target a single language or require high
computational resources to train multilingual models. In this paper, we propose
T5APR, a novel neural program repair approach that provides a unified solution
for bug fixing across multiple programming languages. T5APR leverages CodeT5, a
powerful pre-trained text-to-text transformer model, and adopts a checkpoint
ensemble strategy to improve patch recommendation. We conduct comprehensive
evaluations on six well-known benchmarks in four programming languages (Java,
Python, C, JavaScript), demonstrating T5APR's competitiveness against
state-of-the-art techniques. T5APR correctly fixes 1,985 bugs, including 1,442
bugs that none of the compared techniques has fixed. We further support the
effectiveness of our approach by conducting detailed analyses, such as
comparing the correct patch ranking among different techniques. The findings of
this study demonstrate the potential of T5APR for use in real-world
applications and highlight the importance of multilingual approaches in the
field of APR.
</p>
</div>
</dd>
<dt><a name="item246">[246]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15746" title="Abstract">arXiv:2309.15746</a> [<a href="/pdf/2309.15746" title="Download PDF">pdf</a>, <a href="/format/2309.15746" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Faster Relative Entropy Coding with Greedy Rejection Coding
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Flamich%2C+G">Gergely Flamich</a>, 
<a href="/search/cs?searchtype=author&query=Markou%2C+S">Stratis Markou</a>, 
<a href="/search/cs?searchtype=author&query=Lobato%2C+J+M+H">Jose Miguel Hernandez Lobato</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>

</div>
<p class="mathjax">Relative entropy coding (REC) algorithms encode a sample from a target
distribution $Q$ using a proposal distribution $P$ using as few bits as
possible. Unlike entropy coding, REC does not assume discrete distributions or
require quantisation. As such, it can be naturally integrated into
communication pipelines such as learnt compression and differentially private
federated learning. Unfortunately, despite their practical benefits, REC
algorithms have not seen widespread application, due to their prohibitively
slow runtimes or restrictive assumptions. In this paper, we make progress
towards addressing these issues. We introduce Greedy Rejection Coding (GRC),
which generalises the rejection based-algorithm of Harsha et al. (2007) to
arbitrary probability spaces and partitioning schemes. We first show that GRC
terminates almost surely and returns unbiased samples from $Q$, after which we
focus on two of its variants: GRCS and GRCD. We show that for continuous $Q$
and $P$ over $\mathbb{R}$ with unimodal density ratio $dQ/dP$, the expected
runtime of GRCS is upper bounded by $\beta D_{KL}[Q || P] + O(1)$ where $\beta
\approx 4.82$, and its expected codelength is optimal. This makes GRCS the
first REC algorithm with guaranteed optimal runtime for this class of
distributions, up to the multiplicative constant $\beta$. This significantly
improves upon the previous state-of-the-art method, A* coding (Flamich et al.,
2022). Under the same assumptions, we experimentally observe and conjecture
that the expected runtime and codelength of GRCD are upper bounded by $D_{KL}[Q
|| P] + O(1)$. Finally, we evaluate GRC in a variational autoencoder-based
compression pipeline on MNIST, and show that a modified ELBO and an
index-compression method can further improve compression efficiency.
</p>
</div>
</dd>
<dt><a name="item247">[247]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15751" title="Abstract">arXiv:2309.15751</a> [<a href="/pdf/2309.15751" title="Download PDF">pdf</a>, <a href="/format/2309.15751" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> InfraParis: A multi-modal and multi-task autonomous driving dataset
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Franchi%2C+G">Gianni Franchi</a>, 
<a href="/search/cs?searchtype=author&query=Hariat%2C+M">Marwane Hariat</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+X">Xuanlong Yu</a>, 
<a href="/search/cs?searchtype=author&query=Belkhir%2C+N">Nacim Belkhir</a>, 
<a href="/search/cs?searchtype=author&query=Manzanera%2C+A">Antoine Manzanera</a>, 
<a href="/search/cs?searchtype=author&query=Filliat%2C+D">David Filliat</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 15 pages, 7 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Current deep neural networks (DNNs) for autonomous driving computer vision
are typically trained on specific datasets that only involve a single type of
data and urban scenes. Consequently, these models struggle to handle new
objects, noise, nighttime conditions, and diverse scenarios, which is essential
for safety-critical applications. Despite ongoing efforts to enhance the
resilience of computer vision DNNs, progress has been sluggish, partly due to
the absence of benchmarks featuring multiple modalities. We introduce a novel
and versatile dataset named InfraParis that supports multiple tasks across
three modalities: RGB, depth, and infrared. We assess various state-of-the-art
baseline techniques, encompassing models for the tasks of semantic
segmentation, object detection, and depth estimation.
</p>
</div>
</dd>
<dt><a name="item248">[248]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15755" title="Abstract">arXiv:2309.15755</a> [<a href="/pdf/2309.15755" title="Download PDF">pdf</a>, <a href="/format/2309.15755" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CAIT: Triple-Win Compression towards High Accuracy, Fast Inference, and  Favorable Transferability For ViTs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+A">Ao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+H">Hui Chen</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+Z">Zijia Lin</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+S">Sicheng Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+J">Jungong Han</a>, 
<a href="/search/cs?searchtype=author&query=Ding%2C+G">Guiguang Ding</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Vision Transformers (ViTs) have emerged as state-of-the-art models for
various vision tasks recently. However, their heavy computation costs remain
daunting for resource-limited devices. Consequently, researchers have dedicated
themselves to compressing redundant information in ViTs for acceleration.
However, they generally sparsely drop redundant image tokens by token pruning
or brutally remove channels by channel pruning, leading to a sub-optimal
balance between model performance and inference speed. They are also
disadvantageous in transferring compressed models to downstream vision tasks
that require the spatial structure of images, such as semantic segmentation. To
tackle these issues, we propose a joint compression method for ViTs that offers
both high accuracy and fast inference speed, while also maintaining favorable
transferability to downstream tasks (CAIT). Specifically, we introduce an
asymmetric token merging (ATME) strategy to effectively integrate neighboring
tokens. It can successfully compress redundant token information while
preserving the spatial structure of images. We further employ a consistent
dynamic channel pruning (CDCP) strategy to dynamically prune unimportant
channels in ViTs. Thanks to CDCP, insignificant channels in multi-head
self-attention modules of ViTs can be pruned uniformly, greatly enhancing the
model compression. Extensive experiments on benchmark datasets demonstrate that
our proposed method can achieve state-of-the-art performance across various
ViTs. For example, our pruned DeiT-Tiny and DeiT-Small achieve speedups of
1.7$\times$ and 1.9$\times$, respectively, without accuracy drops on ImageNet.
On the ADE20k segmentation dataset, our method can enjoy up to 1.31$\times$
speedups with comparable mIoU. Our code will be publicly available.
</p>
</div>
</dd>
<dt><a name="item249">[249]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15756" title="Abstract">arXiv:2309.15756</a> [<a href="/pdf/2309.15756" title="Download PDF">pdf</a>, <a href="/format/2309.15756" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Development of a Whole-body Work Imitation Learning System by a Biped  and Bi-armed Humanoid
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Matsuura%2C+Y">Yutaro Matsuura</a>, 
<a href="/search/cs?searchtype=author&query=Kawaharazuka%2C+K">Kento Kawaharazuka</a>, 
<a href="/search/cs?searchtype=author&query=Hiraoka%2C+N">Naoki Hiraoka</a>, 
<a href="/search/cs?searchtype=author&query=Kojima%2C+K">Kunio Kojima</a>, 
<a href="/search/cs?searchtype=author&query=Okada%2C+K">Kei Okada</a>, 
<a href="/search/cs?searchtype=author&query=Inaba%2C+M">Masayuki Inaba</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> accepted at IROS2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Imitation learning has been actively studied in recent years. In particular,
skill acquisition by a robot with a fixed body, whose root link position and
posture and camera angle of view do not change, has been realized in many
cases. On the other hand, imitation of the behavior of robots with floating
links, such as humanoid robots, is still a difficult task. In this study, we
develop an imitation learning system using a biped robot with a floating link.
There are two main problems in developing such a system. The first is a
teleoperation device for humanoids, and the second is a control system that can
withstand heavy workloads and long-term data collection. For the first point,
we use the whole body control device TABLIS. It can control not only the arms
but also the legs and can perform bilateral control with the robot. By
connecting this TABLIS with the high-power humanoid robot JAXON, we construct a
control system for imitation learning. For the second point, we will build a
system that can collect long-term data based on posture optimization, and can
simultaneously move the robot's limbs. We combine high-cycle posture generation
with posture optimization methods, including whole-body joint torque
minimization and contact force optimization. We designed an integrated system
with the above two features to achieve various tasks through imitation
learning. Finally, we demonstrate the effectiveness of this system by
experiments of manipulating flexible fabrics such that not only the hands but
also the head and waist move simultaneously, manipulating objects using legs
characteristic of humanoids, and lifting heavy objects that require large
forces.
</p>
</div>
</dd>
<dt><a name="item250">[250]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15757" title="Abstract">arXiv:2309.15757</a> [<a href="/pdf/2309.15757" title="Download PDF">pdf</a>, <a href="/format/2309.15757" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Latent Graph Powered Semi-Supervised Learning on Biomedical Tabular Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Koloski%2C+B">Boshko Koloski</a>, 
<a href="/search/cs?searchtype=author&query=%C5%A0krlj%2C+B">Bla&#x17e; &#x160;krlj</a>, 
<a href="/search/cs?searchtype=author&query=%C4%B1nst%7B1%7D%2C+S+P">Senja Pollak &#x131;nst{1}</a>, 
<a href="/search/cs?searchtype=author&query=Lavra%C4%8D%2C+N">Nada Lavra&#x10d;</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">In the domain of semi-supervised learning, the current approaches
insufficiently exploit the potential of considering inter-instance
relationships among (un)labeled data. In this work, we address this limitation
by providing an approach for inferring latent graphs that capture the intrinsic
data relationships. By leveraging graph-based representations, our approach
facilitates the seamless propagation of information throughout the graph,
enabling the effective incorporation of global and local knowledge. Through
evaluations on biomedical tabular datasets, we compare the capabilities of our
approach to other contemporary methods. Our work demonstrates the significance
of inter-instance relationship discovery as practical means for constructing
robust latent graphs to enhance semi-supervised learning techniques. Our method
achieves state-of-the-art results on three biomedical datasets.
</p>
</div>
</dd>
<dt><a name="item251">[251]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15759" title="Abstract">arXiv:2309.15759</a> [<a href="/pdf/2309.15759" title="Download PDF">pdf</a>, <a href="/format/2309.15759" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Recycling MMGKS for large-scale dynamic and streaming data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Pasha%2C+M">Mirjeta Pasha</a>, 
<a href="/search/math?searchtype=author&query=de+Sturler%2C+E">Eric de Sturler</a>, 
<a href="/search/math?searchtype=author&query=Kilmer%2C+M+E">Misha E. Kilmer</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 25 pages, 13 figures, 3 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">Reconstructing high-quality images with sharp edges requires the use of
edge-preserving constraints in the regularized form of the inverse problem. The
use of the $\ell_q$-norm on the gradient of the image is a common such
constraint. For implementation purposes, the $\ell_q$-norm term is typically
replaced with a sequence of $\ell_2$-norm weighted gradient terms with the
weights determined from the current solution estimate. While (hybrid) Krylov
subspace methods can be employed on this sequence, it would require generating
a new Krylov subspace for every new two-norm regularized problem. The
majorization-minimization Krylov subspace method (MM-GKS) addresses this
disadvantage by combining norm reweighting with generalized Krylov subspaces
(GKS). After projecting the problem using a small dimensional subspace - one
that expands each iteration - the regularization parameter is selected. Basis
expansion repeats until a sufficiently accurate solution is found.
Unfortunately, for large-scale problems that require many expansion steps to
converge, storage and the cost of repeated orthogonalizations presents
overwhelming memory and computational requirements.
<br />In this paper we present a new method, recycled MM-GKS (RMM-GKS), that keeps
the memory requirements bounded through recycling the solution subspace.
Specifically, our method alternates between enlarging and compressing the GKS
subspace, recycling directions that are deemed most important via one of our
tailored compression routines. We further generalize the RMM-GKS approach to
handle experiments where the data is either not all available simultaneously,
or needs to be treated as such because of the extreme memory requirements.
Numerical examples from dynamic photoacoustic tomography and streaming X-ray
computerized tomography (CT) imaging are used to illustrate the effectiveness
of the described methods.
</p>
</div>
</dd>
<dt><a name="item252">[252]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15762" title="Abstract">arXiv:2309.15762</a> [<a href="/pdf/2309.15762" title="Download PDF">pdf</a>, <a href="/format/2309.15762" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Rapid Network Adaptation: Learning to Adapt Neural Networks Using  Test-Time Feedback
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yeo%2C+T">Teresa Yeo</a>, 
<a href="/search/cs?searchtype=author&query=Kar%2C+O+F">O&#x11f;uzhan Fatih Kar</a>, 
<a href="/search/cs?searchtype=author&query=Sodagar%2C+Z">Zahra Sodagar</a>, 
<a href="/search/cs?searchtype=author&query=Zamir%2C+A">Amir Zamir</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project website at <a href="https://rapid-network-adaptation.epfl.ch/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">We propose a method for adapting neural networks to distribution shifts at
test-time. In contrast to training-time robustness mechanisms that attempt to
anticipate and counter the shift, we create a closed-loop system and make use
of a test-time feedback signal to adapt a network on the fly. We show that this
loop can be effectively implemented using a learning-based function, which
realizes an amortized optimizer for the network. This leads to an adaptation
method, named Rapid Network Adaptation (RNA), that is notably more flexible and
orders of magnitude faster than the baselines. Through a broad set of
experiments using various adaptation signals and target tasks, we study the
efficiency and flexibility of this method. We perform the evaluations using
various datasets (Taskonomy, Replica, ScanNet, Hypersim, COCO, ImageNet), tasks
(depth, optical flow, semantic segmentation, classification), and distribution
shifts (Cross-datasets, 2D and 3D Common Corruptions) with promising results.
We end with a discussion on general formulations for handling distribution
shifts and our observations from comparing with similar approaches from other
domains.
</p>
</div>
</dd>
<dt><a name="item253">[253]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15763" title="Abstract">arXiv:2309.15763</a> [<a href="/pdf/2309.15763" title="Download PDF">pdf</a>, <a href="/ps/2309.15763" title="Download PostScript">ps</a>, <a href="/format/2309.15763" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Consistency and Permission in Deontic Justification Logic
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Faroldi%2C+F+L+G">Federico L. G. Faroldi</a>, 
<a href="/search/cs?searchtype=author&query=Ghari%2C+M">Meghdad Ghari</a>, 
<a href="/search/cs?searchtype=author&query=Lehmann%2C+E">Eveline Lehmann</a>, 
<a href="/search/cs?searchtype=author&query=Studer%2C+T">Thomas Studer</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>

</div>
<p class="mathjax">Different notions of the consistency of obligations collapse in standard
deontic logic. In justification logics, which feature explicit reasons for
obligations, the situation is different. Their strength depends on a constant
specification and on the available set of operations for combining different
reasons. We present different consistency principles in justification logic and
compare their logical strength. We propose a novel semantics for which
justification logics with the explicit version of axiom D, jd, are complete for
arbitrary constant specifications. Consistency is sometimes formulated in terms
of permission. We therefore study permission in the context of justification
logic, introducing a notion of free-choice permission for the first time. We
then discuss the philosophical implications with regard to some deontic
paradoxes.
</p>
</div>
</dd>
<dt><a name="item254">[254]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15768" title="Abstract">arXiv:2309.15768</a> [<a href="/pdf/2309.15768" title="Download PDF">pdf</a>, <a href="/ps/2309.15768" title="Download PostScript">ps</a>, <a href="/format/2309.15768" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AI in Software Engineering: Case Studies and Prospects
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+L">Lei Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Technical Report. The author conducted this work while enrolled as a master's student at UWA, specifically for the CITS5502 Software Processes unit in 2017
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Artificial intelligence (AI) and software engineering (SE) are two important
areas in computer science. In recent years, researchers are trying to apply AI
techniques in various stages of software development to improve the overall
quality of software products. Moreover, there are also some researchers focus
on the intersection between SE and AI. In fact, the relationship between SE and
AI is very weak; however, methods and techniques in one area have been adopted
in another area. More and more software products are capable of performing
intelligent behaviour like human beings. In this paper, two cases studies which
are IBM Watson and Google AlphaGo that use different AI techniques in solving
real world challenging problems have been analysed, evaluated and compared.
Based on the analysis of both case studies, using AI techniques such as deep
learning and machine learning in software systems contributes to intelligent
systems. Watson adopts 'decision making support' strategy to help human make
decisions; whereas AlphaGo uses 'self-decision making' to choose operations
that contribute to the best outcome. In addition, Watson learns from man-made
resources such as paper; AlphaGo, on the other hand, learns from massive online
resources such as photos. AlphaGo uses neural networks and reinforcement
learning to mimic human brain, which might be very useful in medical research
for diagnosis and treatment. However, there is still a long way to go if we
want to reproduce human brain in machine and view computers as thinkers,
because human brain and machines are intrinsically different. It would be more
promising to see whether computers and software systems will become more and
more intelligent to help with real world challenging problems that human beings
cannot do.
</p>
</div>
</dd>
<dt><a name="item255">[255]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15770" title="Abstract">arXiv:2309.15770</a> [<a href="/pdf/2309.15770" title="Download PDF">pdf</a>, <a href="/format/2309.15770" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Generating Transferable Adversarial Simulation Scenarios for  Self-Driving via Neural Rendering
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Abeysirigoonawardena%2C+Y">Yasasa Abeysirigoonawardena</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+K">Kevin Xie</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+C">Chuhan Chen</a>, 
<a href="/search/cs?searchtype=author&query=Hosseini%2C+S">Salar Hosseini</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+R">Ruiting Chen</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+R">Ruiqi Wang</a>, 
<a href="/search/cs?searchtype=author&query=Shkurti%2C+F">Florian Shkurti</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Conference paper submitted to CoRL 23
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Self-driving software pipelines include components that are learned from a
significant number of training examples, yet it remains challenging to evaluate
the overall system's safety and generalization performance. Together with
scaling up the real-world deployment of autonomous vehicles, it is of critical
importance to automatically find simulation scenarios where the driving
policies will fail. We propose a method that efficiently generates adversarial
simulation scenarios for autonomous driving by solving an optimal control
problem that aims to maximally perturb the policy from its nominal trajectory.
<br />Given an image-based driving policy, we show that we can inject new objects
in a neural rendering representation of the deployment scene, and optimize
their texture in order to generate adversarial sensor inputs to the policy. We
demonstrate that adversarial scenarios discovered purely in the neural renderer
(surrogate scene) can often be successfully transferred to the deployment
scene, without further optimization. We demonstrate this transfer occurs both
in simulated and real environments, provided the learned surrogate scene is
sufficiently close to the deployment scene.
</p>
</div>
</dd>
<dt><a name="item256">[256]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15771" title="Abstract">arXiv:2309.15771</a> [<a href="/pdf/2309.15771" title="Download PDF">pdf</a>, <a href="/format/2309.15771" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Importance-Weighted Offline Learning Done Right
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gabbianelli%2C+G">Germano Gabbianelli</a>, 
<a href="/search/cs?searchtype=author&query=Neu%2C+G">Gergely Neu</a>, 
<a href="/search/cs?searchtype=author&query=Papini%2C+M">Matteo Papini</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
<p class="mathjax">We study the problem of offline policy optimization in stochastic contextual
bandit problems, where the goal is to learn a near-optimal policy based on a
dataset of decision data collected by a suboptimal behavior policy. Rather than
making any structural assumptions on the reward function, we assume access to a
given policy class and aim to compete with the best comparator policy within
this class. In this setting, a standard approach is to compute
importance-weighted estimators of the value of each policy, and select a policy
that minimizes the estimated value up to a "pessimistic" adjustment subtracted
from the estimates to reduce their random fluctuations. In this paper, we show
that a simple alternative approach based on the "implicit exploration"
estimator of \citet{Neu2015} yields performance guarantees that are superior in
nearly all possible terms to all previous results. Most notably, we remove an
extremely restrictive "uniform coverage" assumption made in all previous works.
These improvements are made possible by the observation that the upper and
lower tails importance-weighted estimators behave very differently from each
other, and their careful control can massively improve on previous results that
were all based on symmetric two-sided concentration inequalities. We also
extend our results to infinite policy classes in a PAC-Bayesian fashion, and
showcase the robustness of our algorithm to the choice of hyper-parameters by
means of numerical simulations.
</p>
</div>
</dd>
<dt><a name="item257">[257]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15775" title="Abstract">arXiv:2309.15775</a> [<a href="/pdf/2309.15775" title="Download PDF">pdf</a>, <a href="/format/2309.15775" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning the Efficient Frontier
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chatigny%2C+P">Philippe Chatigny</a>, 
<a href="/search/cs?searchtype=author&query=Sergienko%2C+I">Ivan Sergienko</a>, 
<a href="/search/cs?searchtype=author&query=Ferguson%2C+R">Ryan Ferguson</a>, 
<a href="/search/cs?searchtype=author&query=Weir%2C+J">Jordan Weir</a>, 
<a href="/search/cs?searchtype=author&query=Bergeron%2C+M">Maxime Bergeron</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at the Thirty-seventh Conference on Neural Information Processing Systems (NeurIPS 2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computational Engineering, Finance, and Science (cs.CE)

</div>
<p class="mathjax">The efficient frontier (EF) is a fundamental resource allocation problem
where one has to find an optimal portfolio maximizing a reward at a given level
of risk. This optimal solution is traditionally found by solving a convex
optimization problem. In this paper, we introduce NeuralEF: a fast neural
approximation framework that robustly forecasts the result of the EF convex
optimization problem with respect to heterogeneous linear constraints and
variable number of optimization inputs. By reformulating an optimization
problem as a sequence to sequence problem, we show that NeuralEF is a viable
solution to accelerate large-scale simulation while handling discontinuous
behavior.
</p>
</div>
</dd>
<dt><a name="item258">[258]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15776" title="Abstract">arXiv:2309.15776</a> [<a href="/pdf/2309.15776" title="Download PDF">pdf</a>, <a href="/format/2309.15776" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Time-Domain Channel Measurements and Small-Scale Fading Characterization  for RIS-Assisted Wireless Communication Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ren%2C+Y">Yanqing Ren</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+M">Mingyong Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Teng%2C+X">Xiaokun Teng</a>, 
<a href="/search/cs?searchtype=author&query=Meng%2C+S">Shengguo Meng</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+W">Wankai Tang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xiao Li</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+S">Shi Jin</a>, 
<a href="/search/cs?searchtype=author&query=Matthaiou%2C+M">Michail Matthaiou</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>

</div>
<p class="mathjax">As a potentially revolutionary enabling technology for the sixth generation
(6G) mobile communication system, reconfigurable intelligent surfaces (RISs)
have attracted extensive attention from industry and academia. In RIS-assisted
wireless communication systems, practical channel measurements and modeling
serve as the foundation for system design, network optimization, and
performance evaluation. In this paper, a RIS time-domain channel measurement
system, based on a software defined radio (SDR) platform, is developed for the
first time to investigate the small-scale fading characteristics of
RIS-assisted channels. We present RIS channel measurements in corridor and
laboratory scenarios and compare the power delay profile (PDP) of the channel
without RIS, with RIS specular reflection, and with RIS intelligent reflection.
The multipath component parameters and cluster parameters based on the
Saleh-Valenzuela model are extracted. We find that the PDPs of the RIS-assisted
channel fit the power-law decay model and approximate the law of square decay.
Through intelligent reflection, the RIS can decrease the delay and concentrate
the energy of the virtual line-of-sight (VLOS) path, thereby reducing delay
spread and mitigating multipath fading. Furthermore, the cluster
characteristics of RIS-assisted channels are highly related to the measurement
environment. In the laboratory scenario, a single cluster dominated by the VLOS
path with smooth envelope is observed. On the other hand, in the corridor
scenario, some additional clusters introduced by the RIS reflection are
created.
</p>
</div>
</dd>
<dt><a name="item259">[259]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15779" title="Abstract">arXiv:2309.15779</a> [<a href="/pdf/2309.15779" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Question answering using deep learning in low resource Indian language  Marathi
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Amin%2C+D">Dhiraj Amin</a>, 
<a href="/search/cs?searchtype=author&query=Govilkar%2C+S">Sharvari Govilkar</a>, 
<a href="/search/cs?searchtype=author&query=Kulkarni%2C+S">Sagar Kulkarni</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Precise answers are extracted from a text for a given input question in a
question answering system. Marathi question answering system is created in
recent studies by using ontology, rule base and machine learning based
approaches. Recently transformer models and transfer learning approaches are
used to solve question answering challenges. In this paper we investigate
different transformer models for creating a reading comprehension-based Marathi
question answering system. We have experimented on different pretrained Marathi
language multilingual and monolingual models like Multilingual Representations
for Indian Languages (MuRIL), MahaBERT, Indic Bidirectional Encoder
Representations from Transformers (IndicBERT) and fine-tuned it on a Marathi
reading comprehension-based data set. We got the best accuracy in a MuRIL
multilingual model with an EM score of 0.64 and F1 score of 0.74 by fine tuning
the model on the Marathi dataset.
</p>
</div>
</dd>
<dt><a name="item260">[260]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15780" title="Abstract">arXiv:2309.15780</a> [<a href="/pdf/2309.15780" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AaP-ReID: Improved Attention-Aware Person Re-identification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gautam%2C+V">Vipin Gautam</a>, 
<a href="/search/cs?searchtype=author&query=Prasad%2C+S">Shitala Prasad</a>, 
<a href="/search/cs?searchtype=author&query=Sinha%2C+S">Sharad Sinha</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Person re-identification (ReID) is a well-known problem in the field of
computer vision. The primary objective is to identify a specific individual
within a gallery of images. However, this task is challenging due to various
factors, such as pose variations, illumination changes, obstructions, and the
presence ofconfusing backgrounds. Existing ReID methods often fail to capture
discriminative features (e.g., head, shoes, backpacks) and instead capture
irrelevant features when the target is occluded. Motivated by the success of
part-based and attention-based ReID methods, we improve AlignedReID++ and
present AaP-ReID, a more effective method for person ReID that incorporates
channel-wise attention into a ResNet-based architecture. Our method
incorporates the Channel-Wise Attention Bottleneck (CWAbottleneck) block and
can learn discriminating features by dynamically adjusting the importance
ofeach channel in the feature maps. We evaluated Aap-ReID on three benchmark
datasets: Market-1501, DukeMTMC-reID, and CUHK03. When compared with
state-of-the-art person ReID methods, we achieve competitive results with
rank-1 accuracies of 95.6% on Market-1501, 90.6% on DukeMTMC-reID, and 82.4% on
CUHK03.
</p>
</div>
</dd>
<dt><a name="item261">[261]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15782" title="Abstract">arXiv:2309.15782</a> [<a href="/pdf/2309.15782" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Joint-YODNet: A Light-weight Object Detector for UAVs to Achieve Above  100fps
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gautam%2C+V">Vipin Gautam</a>, 
<a href="/search/cs?searchtype=author&query=Prasad%2C+S">Shitala Prasad</a>, 
<a href="/search/cs?searchtype=author&query=Sinha%2C+S">Sharad Sinha</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Small object detection via UAV (Unmanned Aerial Vehicle) images captured from
drones and radar is a complex task with several formidable challenges. This
domain encompasses numerous complexities that impede the accurate detection and
localization of small objects. To address these challenges, we propose a novel
method called JointYODNet for UAVs to detect small objects, leveraging a joint
loss function specifically designed for this task. Our method revolves around
the development of a joint loss function tailored to enhance the detection
performance of small objects. Through extensive experimentation on a diverse
dataset of UAV images captured under varying environmental conditions, we
evaluated different variations of the loss function and determined the most
effective formulation. The results demonstrate that our proposed joint loss
function outperforms existing methods in accurately localizing small objects.
Specifically, our method achieves a recall of 0.971, and a F1Score of 0.975,
surpassing state-of-the-art techniques. Additionally, our method achieves a
mAP@.5(%) of 98.6, indicating its robustness in detecting small objects across
varying scales
</p>
</div>
</dd>
<dt><a name="item262">[262]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15784" title="Abstract">arXiv:2309.15784</a> [<a href="/pdf/2309.15784" title="Download PDF">pdf</a>, <a href="/format/2309.15784" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Gaussian Process-Enhanced, External and Internal Convertible (EIC)  Form-Based Control of Underactuated Balance Robots
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Han%2C+F">Feng Han</a>, 
<a href="/search/cs?searchtype=author&query=Yi%2C+J">Jingang Yi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Systems and Control (eess.SY)

</div>
<p class="mathjax">External and internal convertible (EIC) form-based motion control (i.e.,
EIC-based control) is one of the effective approaches for underactuated balance
robots. By sequentially controller design, trajectory tracking of the actuated
subsystem and balance of the unactuated subsystem can be achieved
simultaneously. However, with certain conditions, there exists uncontrolled
robot motion under the EIC-based control. We first identify these conditions
and then propose an enhanced EIC-based control with a Gaussian process
data-driven robot dynamic model. Under the new enhanced EIC-based control, the
stability and performance of the closed-loop system is guaranteed. We
demonstrate the GP-enhanced EIC-based control experimentally using two examples
of underactuated balance robots.
</p>
</div>
</dd>
<dt><a name="item263">[263]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15785" title="Abstract">arXiv:2309.15785</a> [<a href="/pdf/2309.15785" title="Download PDF">pdf</a>, <a href="/format/2309.15785" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> One For All: Video Conversation is Feasible Without Video Instruction  Tuning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+R">Ruyang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+C">Chen Li</a>, 
<a href="/search/cs?searchtype=author&query=Ge%2C+Y">Yixiao Ge</a>, 
<a href="/search/cs?searchtype=author&query=Shan%2C+Y">Ying Shan</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+T+H">Thomas H. Li</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+G">Ge Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">The recent progress in Large Language Models (LLM) has spurred various
advancements in image-language conversation agents, while how to build a
proficient video-based dialogue system is still under exploration. Considering
the extensive scale of LLM and visual backbone, minimal GPU memory is left for
facilitating effective temporal modeling, which is crucial for comprehending
and providing feedback on videos. To this end, we propose Branching Temporal
Adapter (BT-Adapter), a novel method for extending image-language pretrained
models into the video domain. Specifically, BT-Adapter serves as a plug-and-use
temporal modeling branch alongside the pretrained visual encoder, which is
tuned while keeping the backbone frozen. Just pretrained once, BT-Adapter can
be seamlessly integrated into all image conversation models using this version
of CLIP, enabling video conversations without the need for video instructions.
Besides, we develop a unique asymmetric token masking strategy inside the
branch with tailor-made training tasks for BT-Adapter, facilitating faster
convergence and better results. Thanks to BT-Adapter, we are able to empower
existing multimodal dialogue models with strong video understanding
capabilities without incurring excessive GPU costs. Without bells and whistles,
BT-Adapter achieves (1) state-of-the-art zero-shot results on various video
tasks using thousands of fewer GPU hours. (2) better performance than current
video chatbots without any video instruction tuning. (3) state-of-the-art
results of video chatting using video instruction tuning, outperforming
previous SOTAs by a large margin.
</p>
</div>
</dd>
<dt><a name="item264">[264]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15786" title="Abstract">arXiv:2309.15786</a> [<a href="/pdf/2309.15786" title="Download PDF">pdf</a>, <a href="/format/2309.15786" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Model-based design of temporal analysis for products (TAP) reactors: A  simulated case study in oxidative propane dehydrogenation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yonge%2C+A+C">Adam C. Yonge</a>, 
<a href="/search/cs?searchtype=author&query=Gusm%C3%A3o%2C+G+S">Gabriel S. Gusm&#xe3;o</a>, 
<a href="/search/cs?searchtype=author&query=Fushimi%2C+R">Rebecca Fushimi</a>, 
<a href="/search/cs?searchtype=author&query=Medford%2C+A+J">A.J. Medford</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Engineering, Finance, and Science (cs.CE)</span>

</div>
<p class="mathjax">Temporal analysis of products (TAP) reactors enable experiments that probe
numerous kinetic processes within a single set of experimental data through
variations in pulse intensity, delay, or temperature. Selecting additional TAP
experiments often involves arbitrary selection of reaction conditions or the
use of chemical intuition. To make experiment selection in TAP more robust, we
explore the efficacy of model-based design of experiments (MBDoE) for precision
in TAP reactor kinetic modeling. We successfully applied this approach to a
case study of synthetic oxidative propane dehydrogenation (OPDH) that involves
pulses of propane and oxygen. We found that experiments identified as optimal
through the MBDoE for precision generally reduce parameter uncertainties to a
higher degree than alternative experiments. The performance of MBDoE for model
divergence was also explored for OPDH, with the relevant active sites (catalyst
structure) being unknown. An experiment that maximized the divergence between
the three proposed mechanisms was identified and led to clear mechanism
discrimination. However, re-optimization of kinetic parameters eliminated the
ability to discriminate. The findings yield insight into the prospects and
limitations of MBDoE for TAP and transient kinetic experiments.
</p>
</div>
</dd>
<dt><a name="item265">[265]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15787" title="Abstract">arXiv:2309.15787</a> [<a href="/pdf/2309.15787" title="Download PDF">pdf</a>, <a href="/format/2309.15787" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Partial Transport for Point-Cloud Registration
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bai%2C+Y">Yikun Bai</a>, 
<a href="/search/cs?searchtype=author&query=Tran%2C+H">Huy Tran</a>, 
<a href="/search/cs?searchtype=author&query=Damelin%2C+S+B">Steven B. Damelin</a>, 
<a href="/search/cs?searchtype=author&query=Kolouri%2C+S">Soheil Kolouri</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Point cloud registration plays a crucial role in various fields, including
robotics, computer graphics, and medical imaging. This process involves
determining spatial relationships between different sets of points, typically
within a 3D space. In real-world scenarios, complexities arise from non-rigid
movements and partial visibility, such as occlusions or sensor noise, making
non-rigid registration a challenging problem. Classic non-rigid registration
methods are often computationally demanding, suffer from unstable performance,
and, importantly, have limited theoretical guarantees. The optimal transport
problem and its unbalanced variations (e.g., the optimal partial transport
problem) have emerged as powerful tools for point-cloud registration,
establishing a strong benchmark in this field. These methods view point clouds
as empirical measures and provide a mathematically rigorous way to quantify the
`correspondence' between (the transformed) source and target points. In this
paper, we approach the point-cloud registration problem through the lens of
optimal transport theory and first propose a comprehensive set of non-rigid
registration methods based on the optimal partial transportation problem.
Subsequently, leveraging the emerging work on efficient solutions to the
one-dimensional optimal partial transport problem, we extend our proposed
algorithms via slicing to gain significant computational efficiency, resulting
in fast and robust non-rigid registration algorithms. We demonstrate the
effectiveness of our proposed methods and compare them against baselines on
various 3D and 2D non-rigid registration problems where the source and target
point clouds are corrupted by random noise.
</p>
</div>
</dd>
<dt><a name="item266">[266]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15789" title="Abstract">arXiv:2309.15789</a> [<a href="/pdf/2309.15789" title="Download PDF">pdf</a>, <a href="/format/2309.15789" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Large Language Model Routing with Benchmark Datasets
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shnitzer%2C+T">Tal Shnitzer</a>, 
<a href="/search/cs?searchtype=author&query=Ou%2C+A">Anthony Ou</a>, 
<a href="/search/cs?searchtype=author&query=Silva%2C+M">M&#xed;rian Silva</a>, 
<a href="/search/cs?searchtype=author&query=Soule%2C+K">Kate Soule</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+Y">Yuekai Sun</a>, 
<a href="/search/cs?searchtype=author&query=Solomon%2C+J">Justin Solomon</a>, 
<a href="/search/cs?searchtype=author&query=Thompson%2C+N">Neil Thompson</a>, 
<a href="/search/cs?searchtype=author&query=Yurochkin%2C+M">Mikhail Yurochkin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 18 pages, 8 figures, 4 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">There is a rapidly growing number of open-source Large Language Models (LLMs)
and benchmark datasets to compare them. While some models dominate these
benchmarks, no single model typically achieves the best accuracy in all tasks
and use cases. In this work, we address the challenge of selecting the best LLM
out of a collection of models for new tasks. We propose a new formulation for
the problem, in which benchmark datasets are repurposed to learn a "router"
model for this LLM selection, and we show that this problem can be reduced to a
collection of binary classification tasks. We demonstrate the utility and
limitations of learning model routers from various benchmark datasets, where we
consistently improve performance upon using any single model for all tasks.
</p>
</div>
</dd>
<dt><a name="item267">[267]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15790" title="Abstract">arXiv:2309.15790</a> [<a href="/pdf/2309.15790" title="Download PDF">pdf</a>, <a href="/format/2309.15790" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Some Efficient and Optimal K-Norm Mechanisms
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Joseph%2C+M">Matthew Joseph</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+A">Alexander Yu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">A differentially private computation often begins with a bound on a
$d$-dimensional statistic's $\ell_p$ sensitivity. The $K$-norm mechanism can
yield more accurate additive noise by using a statistic-specific (and possibly
non-$\ell_p$) norm. However, sampling such mechanisms requires sampling from
the corresponding norm balls. These are $d$-dimensional convex polytopes, and
the fastest known general algorithm for approximately sampling such polytopes
takes time $\tilde O(d^{3+\omega})$, where $\omega \geq 2$ is the matrix
multiplication exponent. For the simple problems of sum and ranked vote, this
paper constructs samplers that run in time $\tilde O(d^2)$. More broadly, we
suggest that problem-specific $K$-norm mechanisms may be an overlooked
practical tool for private additive noise.
</p>
</div>
</dd>
<dt><a name="item268">[268]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15798" title="Abstract">arXiv:2309.15798</a> [<a href="/pdf/2309.15798" title="Download PDF">pdf</a>, <a href="/format/2309.15798" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Node-Aligned Graph-to-Graph Generation for Retrosynthesis Prediction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yao%2C+L">Lin Yao</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zhen Wang</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+W">Wentao Guo</a>, 
<a href="/search/cs?searchtype=author&query=Xiang%2C+S">Shang Xiang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+W">Wentan Liu</a>, 
<a href="/search/cs?searchtype=author&query=Ke%2C+G">Guolin Ke</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Chemical Physics (physics.chem-ph); Quantitative Methods (q-bio.QM)

</div>
<p class="mathjax">Single-step retrosynthesis is a crucial task in organic chemistry and drug
design, requiring the identification of required reactants to synthesize a
specific compound. with the advent of computer-aided synthesis planning, there
is growing interest in using machine-learning techniques to facilitate the
process. Existing template-free machine learning-based models typically utilize
transformer structures and represent molecules as ID sequences. However, these
methods often face challenges in fully leveraging the extensive topological
information of the molecule and aligning atoms between the production and
reactants, leading to results that are not as competitive as those of
semi-template models. Our proposed method, Node-Aligned Graph-to-Graph (NAG2G),
also serves as a transformer-based template-free model but utilizes 2D
molecular graphs and 3D conformation information. Furthermore, our approach
simplifies the incorporation of production-reactant atom mapping alignment by
leveraging node alignment to determine a specific order for node generation and
generating molecular graphs in an auto-regressive manner node-by-node. This
method ensures that the node generation order coincides with the node order in
the input graph, overcoming the difficulty of determining a specific node
generation order in an auto-regressive manner. Our extensive benchmarking
results demonstrate that the proposed NAG2G can outperform the previous
state-of-the-art baselines in various metrics.
</p>
</div>
</dd>
<dt><a name="item269">[269]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15800" title="Abstract">arXiv:2309.15800</a> [<a href="/pdf/2309.15800" title="Download PDF">pdf</a>, <a href="/format/2309.15800" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exploring Speech Recognition, Translation, and Understanding with  Discrete Speech Units: A Comparative Study
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chang%2C+X">Xuankai Chang</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+B">Brian Yan</a>, 
<a href="/search/cs?searchtype=author&query=Choi%2C+K">Kwanghee Choi</a>, 
<a href="/search/cs?searchtype=author&query=Jung%2C+J">Jeeweon Jung</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+Y">Yichen Lu</a>, 
<a href="/search/cs?searchtype=author&query=Maiti%2C+S">Soumi Maiti</a>, 
<a href="/search/cs?searchtype=author&query=Sharma%2C+R">Roshan Sharma</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+J">Jiatong Shi</a>, 
<a href="/search/cs?searchtype=author&query=Tian%2C+J">Jinchuan Tian</a>, 
<a href="/search/cs?searchtype=author&query=Watanabe%2C+S">Shinji Watanabe</a>, 
<a href="/search/cs?searchtype=author&query=Fujita%2C+Y">Yuya Fujita</a>, 
<a href="/search/cs?searchtype=author&query=Maekaku%2C+T">Takashi Maekaku</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+P">Pengcheng Guo</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+Y">Yao-Fei Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Denisov%2C+P">Pavel Denisov</a>, 
<a href="/search/cs?searchtype=author&query=Saijo%2C+K">Kohei Saijo</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Hsiu-Hsuan Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to IEEE ICASSP 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Sound (cs.SD); Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">Speech signals, typically sampled at rates in the tens of thousands per
second, contain redundancies, evoking inefficiencies in sequence modeling.
High-dimensional speech features such as spectrograms are often used as the
input for the subsequent model. However, they can still be redundant. Recent
investigations proposed the use of discrete speech units derived from
self-supervised learning representations, which significantly compresses the
size of speech data. Applying various methods, such as de-duplication and
subword modeling, can further compress the speech sequence length. Hence,
training time is significantly reduced while retaining notable performance. In
this study, we undertake a comprehensive and systematic exploration into the
application of discrete units within end-to-end speech processing models.
Experiments on 12 automatic speech recognition, 3 speech translation, and 1
spoken language understanding corpora demonstrate that discrete units achieve
reasonably good results in almost all the settings. We intend to release our
configurations and trained models to foster future research efforts.
</p>
</div>
</dd>
<dt><a name="item270">[270]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15803" title="Abstract">arXiv:2309.15803</a> [<a href="/pdf/2309.15803" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ANNCRIPS: Artificial Neural Networks for Cancer Research In Prediction &amp;  Survival
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mathapati%2C+A">Amit Mathapati</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, 25 figures, 2 tables. arXiv admin note: text overlap with <a href="/abs/cs/0405016">arXiv:cs/0405016</a> by other authors
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computational Engineering, Finance, and Science (cs.CE); Neural and Evolutionary Computing (cs.NE)

</div>
<p class="mathjax">Prostate cancer is a prevalent malignancy among men aged 50 and older.
Current diagnostic methods primarily rely on blood tests, PSA:Prostate-Specific
Antigen levels, and Digital Rectal Examinations (DRE). However, these methods
suffer from a significant rate of false positive results. This study focuses on
the development and validation of an intelligent mathematical model utilizing
Artificial Neural Networks (ANNs) to enhance the early detection of prostate
cancer. The primary objective of this research paper is to present a novel
mathematical model designed to aid in the early detection of prostate cancer,
facilitating prompt intervention by healthcare professionals. The model's
implementation demonstrates promising potential in reducing the incidence of
false positives, thereby improving patient outcomes. Furthermore, we envision
that, with further refinement, extensive testing, and validation, this model
can evolve into a robust, marketable solution for prostate cancer detection.
The long-term goal is to make this solution readily available for deployment in
various screening centers, hospitals, and research institutions, ultimately
contributing to more effective cancer screening and patient care.
</p>
</div>
</dd>
<dt><a name="item271">[271]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15805" title="Abstract">arXiv:2309.15805</a> [<a href="/pdf/2309.15805" title="Download PDF">pdf</a>, <a href="/ps/2309.15805" title="Download PostScript">ps</a>, <a href="/format/2309.15805" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Novel approach for solving multipoint boundary value problem for  integro-differential equation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Assanova%2C+A">Anar Assanova</a>, 
<a href="/search/math?searchtype=author&query=Bakirova%2C+E">Elmira Bakirova</a>, 
<a href="/search/math?searchtype=author&query=Uteshova%2C+R">Roza Uteshova</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Kazakh Mathematical Journal 20:1 (2020) 103-124
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">In the present paper, we study a multipoint boundary value problem for a
system of Fredholm integro-differenial equations by the method of
parameterization. The case of a degenerate kernel is studied separately, for
which we obtain well-posedness conditions and propose some algorithms to find
approximate and numerical solutions to the problem. Then we establish necessary
and sufficient conditions for the well-posedness of the multipoint problem for
the system of Fredholm integro-differential equations and develop some
algorithms for finding its approximate solutions. These algorithms are based on
the solutions of an approximating problem for the system of
integro-differential equations with degenerate kernel.
</p>
</div>
</dd>
<dt><a name="item272">[272]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15806" title="Abstract">arXiv:2309.15806</a> [<a href="/pdf/2309.15806" title="Download PDF">pdf</a>, <a href="/format/2309.15806" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Lyra: Orchestrating Dual Correction in Automated Theorem Proving
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zheng%2C+C">Chuanyang Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Haiming Wang</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+E">Enze Xie</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zhengying Liu</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+J">Jiankai Sun</a>, 
<a href="/search/cs?searchtype=author&query=Xin%2C+H">Huajian Xin</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+J">Jianhao Shen</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zhenguo Li</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yu Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Tech Report
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Large Language Models (LLMs) present an intriguing avenue for exploration in
the field of formal theorem proving. Nevertheless, their full potential,
particularly concerning the mitigation of hallucinations and refinement through
prover error messages, remains an area that has yet to be thoroughly
investigated. To enhance the effectiveness of LLMs in the field, we introduce
the Lyra, a new framework that employs two distinct correction mechanisms: Tool
Correction (TC) and Conjecture Correction (CC). To implement Tool Correction in
the post-processing of formal proofs, we leverage prior knowledge to utilize
predefined prover tools (e.g., Sledgehammer) for guiding the replacement of
incorrect tools. Tool Correction significantly contributes to mitigating
hallucinations, thereby improving the overall accuracy of the proof. In
addition, we introduce Conjecture Correction, an error feedback mechanism
designed to interact with prover to refine formal proof conjectures with prover
error messages. Compared to the previous refinement framework, the proposed
Conjecture Correction refines generation with instruction but does not collect
paired (generation, error &amp; refinement) prompts. Our method has achieved
state-of-the-art (SOTA) performance on both miniF2F validation (48.0% -&gt; 55.3%)
and test (45.5% -&gt; 51.2%). We also present 3 IMO problems solved by Lyra. We
believe Tool Correction (post-process for hallucination mitigation) and
Conjecture Correction (subgoal adjustment from interaction with environment)
could provide a promising avenue for future research in this field.
</p>
</div>
</dd>
<dt><a name="item273">[273]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15807" title="Abstract">arXiv:2309.15807</a> [<a href="/pdf/2309.15807" title="Download PDF">pdf</a>, <a href="/format/2309.15807" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Emu: Enhancing Image Generation Models Using Photogenic Needles in a  Haystack
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dai%2C+X">Xiaoliang Dai</a>, 
<a href="/search/cs?searchtype=author&query=Hou%2C+J">Ji Hou</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+C">Chih-Yao Ma</a>, 
<a href="/search/cs?searchtype=author&query=Tsai%2C+S">Sam Tsai</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jialiang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+R">Rui Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+P">Peizhao Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Vandenhende%2C+S">Simon Vandenhende</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xiaofang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Dubey%2C+A">Abhimanyu Dubey</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+M">Matthew Yu</a>, 
<a href="/search/cs?searchtype=author&query=Kadian%2C+A">Abhishek Kadian</a>, 
<a href="/search/cs?searchtype=author&query=Radenovic%2C+F">Filip Radenovic</a>, 
<a href="/search/cs?searchtype=author&query=Mahajan%2C+D">Dhruv Mahajan</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+K">Kunpeng Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Y">Yue Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Petrovic%2C+V">Vladan Petrovic</a>, 
<a href="/search/cs?searchtype=author&query=Singh%2C+M+K">Mitesh Kumar Singh</a>, 
<a href="/search/cs?searchtype=author&query=Motwani%2C+S">Simran Motwani</a>, 
<a href="/search/cs?searchtype=author&query=Wen%2C+Y">Yi Wen</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+Y">Yiwen Song</a>, 
<a href="/search/cs?searchtype=author&query=Sumbaly%2C+R">Roshan Sumbaly</a>, 
<a href="/search/cs?searchtype=author&query=Ramanathan%2C+V">Vignesh Ramanathan</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+Z">Zijian He</a>, 
<a href="/search/cs?searchtype=author&query=Vajda%2C+P">Peter Vajda</a>, 
<a href="/search/cs?searchtype=author&query=Parikh%2C+D">Devi Parikh</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Training text-to-image models with web scale image-text pairs enables the
generation of a wide range of visual concepts from text. However, these
pre-trained models often face challenges when it comes to generating highly
aesthetic images. This creates the need for aesthetic alignment post
pre-training. In this paper, we propose quality-tuning to effectively guide a
pre-trained model to exclusively generate highly visually appealing images,
while maintaining generality across visual concepts. Our key insight is that
supervised fine-tuning with a set of surprisingly small but extremely visually
appealing images can significantly improve the generation quality. We pre-train
a latent diffusion model on $1.1$ billion image-text pairs and fine-tune it
with only a few thousand carefully selected high-quality images. The resulting
model, Emu, achieves a win rate of $82.9\%$ compared with its pre-trained only
counterpart. Compared to the state-of-the-art SDXLv1.0, Emu is preferred
$68.4\%$ and $71.3\%$ of the time on visual appeal on the standard PartiPrompts
and our Open User Input benchmark based on the real-world usage of
text-to-image models. In addition, we show that quality-tuning is a generic
approach that is also effective for other architectures, including pixel
diffusion and masked generative transformer models.
</p>
</div>
</dd>
<dt><a name="item274">[274]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15809" title="Abstract">arXiv:2309.15809</a> [<a href="/pdf/2309.15809" title="Download PDF">pdf</a>, <a href="/format/2309.15809" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fair Canonical Correlation Analysis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Z">Zhuoping Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Tarzanagh%2C+D+A">Davoud Ataee Tarzanagh</a>, 
<a href="/search/cs?searchtype=author&query=Hou%2C+B">Bojian Hou</a>, 
<a href="/search/cs?searchtype=author&query=Tong%2C+B">Boning Tong</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+J">Jia Xu</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+Y">Yanbo Feng</a>, 
<a href="/search/cs?searchtype=author&query=Long%2C+Q">Qi Long</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+L">Li Shen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted for publication at NeurIPS 2023, 31 Pages, 14 Figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
<p class="mathjax">This paper investigates fairness and bias in Canonical Correlation Analysis
(CCA), a widely used statistical technique for examining the relationship
between two sets of variables. We present a framework that alleviates
unfairness by minimizing the correlation disparity error associated with
protected attributes. Our approach enables CCA to learn global projection
matrices from all data points while ensuring that these matrices yield
comparable correlation levels to group-specific projection matrices.
Experimental evaluation on both synthetic and real-world datasets demonstrates
the efficacy of our method in reducing correlation disparity error without
compromising CCA accuracy.
</p>
</div>
</dd>
<dt><a name="item275">[275]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15812" title="Abstract">arXiv:2309.15812</a> [<a href="/pdf/2309.15812" title="Download PDF">pdf</a>, <a href="/format/2309.15812" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Convolutional Networks with Oriented 1D Kernels
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kirchmeyer%2C+A">Alexandre Kirchmeyer</a>, 
<a href="/search/cs?searchtype=author&query=Deng%2C+J">Jia Deng</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">In computer vision, 2D convolution is arguably the most important operation
performed by a ConvNet. Unsurprisingly, it has been the focus of intense
software and hardware optimization and enjoys highly efficient implementations.
In this work, we ask an intriguing question: can we make a ConvNet work without
2D convolutions? Surprisingly, we find that the answer is yes -- we show that a
ConvNet consisting entirely of 1D convolutions can do just as well as 2D on
ImageNet classification. Specifically, we find that one key ingredient to a
high-performing 1D ConvNet is oriented 1D kernels: 1D kernels that are oriented
not just horizontally or vertically, but also at other angles. Our experiments
show that oriented 1D convolutions can not only replace 2D convolutions but
also augment existing architectures with large kernels, leading to improved
accuracy with minimal FLOPs increase. A key contribution of this work is a
highly-optimized custom CUDA implementation of oriented 1D kernels, specialized
to the depthwise convolution setting. Our benchmarks demonstrate that our
custom CUDA implementation almost perfectly realizes the theoretical advantage
of 1D convolution: it is faster than a native horizontal convolution for any
arbitrary angle. Code is available at
https://github.com/princeton-vl/Oriented1D.
</p>
</div>
</dd>
<dt><a name="item276">[276]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15817" title="Abstract">arXiv:2309.15817</a> [<a href="/pdf/2309.15817" title="Download PDF">pdf</a>, <a href="/format/2309.15817" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Identifying the Risks of LM Agents with an LM-Emulated Sandbox
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ruan%2C+Y">Yangjun Ruan</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+H">Honghua Dong</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+A">Andrew Wang</a>, 
<a href="/search/cs?searchtype=author&query=Pitis%2C+S">Silviu Pitis</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Y">Yongchao Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Ba%2C+J">Jimmy Ba</a>, 
<a href="/search/cs?searchtype=author&query=Dubois%2C+Y">Yann Dubois</a>, 
<a href="/search/cs?searchtype=author&query=Maddison%2C+C+J">Chris J. Maddison</a>, 
<a href="/search/cs?searchtype=author&query=Hashimoto%2C+T">Tatsunori Hashimoto</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computation and Language (cs.CL); Machine Learning (cs.LG)

</div>
<p class="mathjax">Recent advances in Language Model (LM) agents and tool use, exemplified by
applications like ChatGPT Plugins, enable a rich set of capabilities but also
amplify potential risks - such as leaking private data or causing financial
losses. Identifying these risks is labor-intensive, necessitating implementing
the tools, manually setting up the environment for each test scenario, and
finding risky cases. As tools and agents become more complex, the high cost of
testing these agents will make it increasingly difficult to find high-stakes,
long-tailed risks. To address these challenges, we introduce ToolEmu: a
framework that uses an LM to emulate tool execution and enables the testing of
LM agents against a diverse range of tools and scenarios, without manual
instantiation. Alongside the emulator, we develop an LM-based automatic safety
evaluator that examines agent failures and quantifies associated risks. We test
both the tool emulator and evaluator through human evaluation and find that
68.8% of failures identified with ToolEmu would be valid real-world agent
failures. Using our curated initial benchmark consisting of 36 high-stakes
tools and 144 test cases, we provide a quantitative risk analysis of current LM
agents and identify numerous failures with potentially severe outcomes.
Notably, even the safest LM agent exhibits such failures 23.9% of the time
according to our evaluator, underscoring the need to develop safer LM agents
for real-world deployment.
</p>
</div>
</dd>
<dt><a name="item277">[277]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15818" title="Abstract">arXiv:2309.15818</a> [<a href="/pdf/2309.15818" title="Download PDF">pdf</a>, <a href="/format/2309.15818" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Show-1: Marrying Pixel and Latent Diffusion Models for Text-to-Video  Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+D+J">David Junhao Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+J+Z">Jay Zhangjie Wu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jia-Wei Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+R">Rui Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Ran%2C+L">Lingmin Ran</a>, 
<a href="/search/cs?searchtype=author&query=Gu%2C+Y">Yuchao Gu</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+D">Difei Gao</a>, 
<a href="/search/cs?searchtype=author&query=Shou%2C+M+Z">Mike Zheng Shou</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> project page: <a href="https://showlab.github.io/Show-1">this https URL</a> ; code: <a href="https://github.com/showlab/Show-1">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Significant advancements have been achieved in the realm of large-scale
pre-trained text-to-video Diffusion Models (VDMs). However, previous methods
either rely solely on pixel-based VDMs, which come with high computational
costs, or on latent-based VDMs, which often struggle with precise text-video
alignment. In this paper, we are the first to propose a hybrid model, dubbed as
Show-1, which marries pixel-based and latent-based VDMs for text-to-video
generation. Our model first uses pixel-based VDMs to produce a low-resolution
video of strong text-video correlation. After that, we propose a novel expert
translation method that employs the latent-based VDMs to further upsample the
low-resolution video to high resolution. Compared to latent VDMs, Show-1 can
produce high-quality videos of precise text-video alignment; Compared to pixel
VDMs, Show-1 is much more efficient (GPU memory usage during inference is 15G
vs 72G). We also validate our model on standard video generation benchmarks.
Our code and model weights are publicly available at
\url{https://github.com/showlab/Show-1}.
</p>
</div>
</dd>
<dt><a name="item278">[278]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15821" title="Abstract">arXiv:2309.15821</a> [<a href="/pdf/2309.15821" title="Download PDF">pdf</a>, <a href="/format/2309.15821" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LGMCTS: Language-Guided Monte-Carlo Tree Search for Executable Semantic  Object Rearrangement
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chang%2C+H">Haonan Chang</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+K">Kai Gao</a>, 
<a href="/search/cs?searchtype=author&query=Boyalakuntla%2C+K">Kowndinya Boyalakuntla</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+A">Alex Lee</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+B">Baichuan Huang</a>, 
<a href="/search/cs?searchtype=author&query=Kumar%2C+H+U">Harish Udhaya Kumar</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+J">Jinjin Yu</a>, 
<a href="/search/cs?searchtype=author&query=Boularias%2C+A">Abdeslam Boularias</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Our code and supplementary materials are accessible at <a href="https://github.com/changhaonan/LG-MCTS">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">We introduce a novel approach to the executable semantic object rearrangement
problem. In this challenge, a robot seeks to create an actionable plan that
rearranges objects within a scene according to a pattern dictated by a natural
language description. Unlike existing methods such as StructFormer and
StructDiffusion, which tackle the issue in two steps by first generating poses
and then leveraging a task planner for action plan formulation, our method
concurrently addresses pose generation and action planning. We achieve this
integration using a Language-Guided Monte-Carlo Tree Search (LGMCTS).
Quantitative evaluations are provided on two simulation datasets, and
complemented by qualitative tests with a real robot.
</p>
</div>
</dd>
<dt><a name="item279">[279]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15826" title="Abstract">arXiv:2309.15826</a> [<a href="/pdf/2309.15826" title="Download PDF">pdf</a>, <a href="/format/2309.15826" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Cross-Modal Multi-Tasking for Speech-to-Text Translation via Hard  Parameter Sharing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yan%2C+B">Brian Yan</a>, 
<a href="/search/cs?searchtype=author&query=Chang%2C+X">Xuankai Chang</a>, 
<a href="/search/cs?searchtype=author&query=Anastasopoulos%2C+A">Antonios Anastasopoulos</a>, 
<a href="/search/cs?searchtype=author&query=Fujita%2C+Y">Yuya Fujita</a>, 
<a href="/search/cs?searchtype=author&query=Watanabe%2C+S">Shinji Watanabe</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Sound (cs.SD); Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">Recent works in end-to-end speech-to-text translation (ST) have proposed
multi-tasking methods with soft parameter sharing which leverage machine
translation (MT) data via secondary encoders that map text inputs to an
eventual cross-modal representation. In this work, we instead propose a ST/MT
multi-tasking framework with hard parameter sharing in which all model
parameters are shared cross-modally. Our method reduces the speech-text
modality gap via a pre-processing stage which converts speech and text inputs
into two discrete token sequences of similar length -- this allows models to
indiscriminately process both modalities simply using a joint vocabulary. With
experiments on MuST-C, we demonstrate that our multi-tasking framework improves
attentional encoder-decoder, Connectionist Temporal Classification (CTC),
transducer, and joint CTC/attention models by an average of +0.5 BLEU without
any external MT data. Further, we show that this framework incorporates
external MT data, yielding +0.8 BLEU, and also improves transfer learning from
pre-trained textual models, yielding +1.8 BLEU.
</p>
</div>
</dd>
<dt><a name="item280">[280]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15827" title="Abstract">arXiv:2309.15827</a> [<a href="/pdf/2309.15827" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> How We Define Harm Impacts Data Annotations: Explaining How Annotators  Distinguish Hateful, Offensive, and Toxic Comments
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sch%C3%B6pke-Gonzalez%2C+A">Angela Sch&#xf6;pke-Gonzalez</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+S">Siqi Wu</a>, 
<a href="/search/cs?searchtype=author&query=Kumar%2C+S">Sagar Kumar</a>, 
<a href="/search/cs?searchtype=author&query=Resnick%2C+P+J">Paul J. Resnick</a>, 
<a href="/search/cs?searchtype=author&query=Hemphill%2C+L">Libby Hemphill</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 29 pages, 1 figure, 9 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Computers and Society (cs.CY)

</div>
<p class="mathjax">Computational social science research has made advances in machine learning
and natural language processing that support content moderators in detecting
harmful content. These advances often rely on training datasets annotated by
crowdworkers for harmful content. In designing instructions for annotation
tasks to generate training data for these algorithms, researchers often treat
the harm concepts that we train algorithms to detect - 'hateful', 'offensive',
'toxic', 'racist', 'sexist', etc. - as interchangeable. In this work, we
studied whether the way that researchers define 'harm' affects annotation
outcomes. Using Venn diagrams, information gain comparisons, and content
analyses, we reveal that annotators do not use the concepts 'hateful',
'offensive', and 'toxic' interchangeably. We identify that features of harm
definitions and annotators' individual characteristics explain much of how
annotators use these terms differently. Our results offer empirical evidence
discouraging the common practice of using harm concepts interchangeably in
content moderation research. Instead, researchers should make specific choices
about which harm concepts to analyze based on their research goals. Recognizing
that researchers are often resource constrained, we also encourage researchers
to provide information to bound their findings when their concepts of interest
differ from concepts that off-the-shelf harmful content detection algorithms
identify. Finally, we encourage algorithm providers to ensure their instruments
can adapt to contextually-specific content detection goals (e.g., soliciting
instrument users' feedback).
</p>
</div>
</dd>
<dt><a name="item281">[281]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15830" title="Abstract">arXiv:2309.15830</a> [<a href="/pdf/2309.15830" title="Download PDF">pdf</a>, <a href="/format/2309.15830" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> OrthoPlanes: A Novel Representation for Better 3D-Awareness of GANs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=He%2C+H">Honglin He</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Z">Zhuoqian Yang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+S">Shikai Li</a>, 
<a href="/search/cs?searchtype=author&query=Dai%2C+B">Bo Dai</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+W">Wayne Wu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">We present a new method for generating realistic and view-consistent images
with fine geometry from 2D image collections. Our method proposes a hybrid
explicit-implicit representation called \textbf{OrthoPlanes}, which encodes
fine-grained 3D information in feature maps that can be efficiently generated
by modifying 2D StyleGANs. Compared to previous representations, our method has
better scalability and expressiveness with clear and explicit information. As a
result, our method can handle more challenging view-angles and synthesize
articulated objects with high spatial degree of freedom. Experiments
demonstrate that our method achieves state-of-the-art results on FFHQ and SHHQ
datasets, both quantitatively and qualitatively. Project page:
\url{https://orthoplanes.github.io/}.
</p>
</div>
</dd>
<dt><a name="item282">[282]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15838" title="Abstract">arXiv:2309.15838</a> [<a href="/pdf/2309.15838" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Automated Detection of Persistent Inflammatory Biomarkers in  Post-COVID-19 Patients Using Machine Learning Techniques
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fatima%2C+G">Ghizal Fatima</a>, 
<a href="/search/cs?searchtype=author&query=Al-Amran%2C+F+G">Fadhil G. Al-Amran</a>, 
<a href="/search/cs?searchtype=author&query=Yousif%2C+M+G">Maitham G. Yousif</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Biomolecules (q-bio.BM)

</div>
<p class="mathjax">The COVID-19 pandemic has left a lasting impact on individuals, with many
experiencing persistent symptoms, including inflammation, in the post-acute
phase of the disease. Detecting and monitoring these inflammatory biomarkers is
critical for timely intervention and improved patient outcomes. This study
employs machine learning techniques to automate the identification of
persistent inflammatory biomarkers in 290 post-COVID-19 patients, based on
medical data collected from hospitals in Iraq. The data encompassed a wide
array of clinical parameters, such as C-reactive protein and interleukin-6
levels, patient demographics, comorbidities, and treatment histories. Rigorous
data preprocessing and feature selection processes were implemented to optimize
the dataset for machine learning analysis. Various machine learning algorithms,
including logistic regression, random forests, support vector machines, and
gradient boosting, were deployed to construct predictive models. These models
exhibited promising results, showcasing high accuracy and precision in the
identification of patients with persistent inflammation. The findings of this
study underscore the potential of machine learning in automating the detection
of persistent inflammatory biomarkers in post-COVID-19 patients. These models
can serve as valuable tools for healthcare providers, facilitating early
diagnosis and personalized treatment strategies for individuals at risk of
persistent inflammation, ultimately contributing to improved post-acute
COVID-19 care and patient well-being. Keywords: COVID-19, post-COVID-19,
inflammation, biomarkers, machine learning, early detection.
</p>
</div>
</dd>
<dt><a name="item283">[283]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15839" title="Abstract">arXiv:2309.15839</a> [<a href="/pdf/2309.15839" title="Download PDF">pdf</a>, <a href="/format/2309.15839" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Examining the Values Reflected by Children during AI Problem Formulation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dwivedi%2C+U">Utkarsh Dwivedi</a>, 
<a href="/search/cs?searchtype=author&query=Elsayed-ali%2C+S">Salma Elsayed-ali</a>, 
<a href="/search/cs?searchtype=author&query=Bonsignore%2C+E">Elizabeth Bonsignore</a>, 
<a href="/search/cs?searchtype=author&query=Kacorri%2C+H">Hernisa Kacorri</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Understanding how children design and what they value in AI interfaces that
allow them to explicitly train their models such as teachable machines, could
help increase such activities' impact and guide the design of future
technologies. In a co-design session using a modified storyboard, a team of 5
children (aged 7-13 years) and adult co-designers, engaged in AI problem
formulation activities where they imagine their own teachable machines. Our
findings, leveraging an established psychological value framework (the Rokeach
Value Survey), illuminate how children conceptualize and embed their values in
AI systems that they themselves devise to support their everyday activities.
Specifically, we find that children's proposed ideas require advanced system
intelligence, e.g. emotion detection and understanding the social relationships
of a user. The underlying models could be trained under multiple modalities and
any errors would be fixed by adding more data or by anticipating negative
examples. Children's ideas showed they cared about family and expected machines
to understand their social context before making decisions.
</p>
</div>
</dd>
<dt><a name="item284">[284]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15840" title="Abstract">arXiv:2309.15840</a> [<a href="/pdf/2309.15840" title="Download PDF">pdf</a>, <a href="/format/2309.15840" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> How to Catch an AI Liar: Lie Detection in Black-Box LLMs by Asking  Unrelated Questions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pacchiardi%2C+L">Lorenzo Pacchiardi</a>, 
<a href="/search/cs?searchtype=author&query=Chan%2C+A+J">Alex J. Chan</a>, 
<a href="/search/cs?searchtype=author&query=Mindermann%2C+S">S&#xf6;ren Mindermann</a>, 
<a href="/search/cs?searchtype=author&query=Moscovitz%2C+I">Ilan Moscovitz</a>, 
<a href="/search/cs?searchtype=author&query=Pan%2C+A+Y">Alexa Y. Pan</a>, 
<a href="/search/cs?searchtype=author&query=Gal%2C+Y">Yarin Gal</a>, 
<a href="/search/cs?searchtype=author&query=Evans%2C+O">Owain Evans</a>, 
<a href="/search/cs?searchtype=author&query=Brauner%2C+J">Jan Brauner</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Large language models (LLMs) can "lie", which we define as outputting false
statements despite "knowing" the truth in a demonstrable sense. LLMs might
"lie", for example, when instructed to output misinformation. Here, we develop
a simple lie detector that requires neither access to the LLM's activations
(black-box) nor ground-truth knowledge of the fact in question. The detector
works by asking a predefined set of unrelated follow-up questions after a
suspected lie, and feeding the LLM's yes/no answers into a logistic regression
classifier. Despite its simplicity, this lie detector is highly accurate and
surprisingly general. When trained on examples from a single setting --
prompting GPT-3.5 to lie about factual questions -- the detector generalises
out-of-distribution to (1) other LLM architectures, (2) LLMs fine-tuned to lie,
(3) sycophantic lies, and (4) lies emerging in real-life scenarios such as
sales. These results indicate that LLMs have distinctive lie-related
behavioural patterns, consistent across architectures and contexts, which could
enable general-purpose lie detection.
</p>
</div>
</dd>
<dt><a name="item285">[285]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15842" title="Abstract">arXiv:2309.15842</a> [<a href="/pdf/2309.15842" title="Download PDF">pdf</a>, <a href="/format/2309.15842" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exploiting the Signal-Leak Bias in Diffusion Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Everaert%2C+M+N">Martin Nicolas Everaert</a>, 
<a href="/search/cs?searchtype=author&query=Fitsios%2C+A">Athanasios Fitsios</a>, 
<a href="/search/cs?searchtype=author&query=Bocchio%2C+M">Marco Bocchio</a>, 
<a href="/search/cs?searchtype=author&query=Arpa%2C+S">Sami Arpa</a>, 
<a href="/search/cs?searchtype=author&query=S%C3%BCsstrunk%2C+S">Sabine S&#xfc;sstrunk</a>, 
<a href="/search/cs?searchtype=author&query=Achanta%2C+R">Radhakrishna Achanta</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">There is a bias in the inference pipeline of most diffusion models. This bias
arises from a signal leak whose distribution deviates from the noise
distribution, creating a discrepancy between training and inference processes.
We demonstrate that this signal-leak bias is particularly significant when
models are tuned to a specific style, causing sub-optimal style matching.
Recent research tries to avoid the signal leakage during training. We instead
show how we can exploit this signal-leak bias in existing diffusion models to
allow more control over the generated images. This enables us to generate
images with more varied brightness, and images that better match a desired
style or color. By modeling the distribution of the signal leak in the spatial
frequency and pixel domains, and including a signal leak in the initial latent,
we generate images that better match expected results without any additional
training.
</p>
</div>
</dd>
<dt><a name="item286">[286]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15847" title="Abstract">arXiv:2309.15847</a> [<a href="/pdf/2309.15847" title="Download PDF">pdf</a>, <a href="/format/2309.15847" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Disinformation Detection: An Evolving Challenge in the Age of LLMs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jiang%2C+B">Bohan Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Tan%2C+Z">Zhen Tan</a>, 
<a href="/search/cs?searchtype=author&query=Nirmal%2C+A">Ayushi Nirmal</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+H">Huan Liu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Computers and Society (cs.CY)

</div>
<p class="mathjax">The advent of generative Large Language Models (LLMs) such as ChatGPT has
catalyzed transformative advancements across multiple domains. However,
alongside these advancements, they have also introduced potential threats. One
critical concern is the misuse of LLMs by disinformation spreaders, leveraging
these models to generate highly persuasive yet misleading content that
challenges the disinformation detection system. This work aims to address this
issue by answering three research questions: (1) To what extent can the current
disinformation detection technique reliably detect LLM-generated
disinformation? (2) If traditional techniques prove less effective, can LLMs
themself be exploited to serve as a robust defense against advanced
disinformation? and, (3) Should both these strategies falter, what novel
approaches can be proposed to counter this burgeoning threat effectively? A
holistic exploration for the formation and detection of disinformation is
conducted to foster this line of research.
</p>
</div>
</dd>
<dt><a name="item287">[287]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15848" title="Abstract">arXiv:2309.15848</a> [<a href="/pdf/2309.15848" title="Download PDF">pdf</a>, <a href="/format/2309.15848" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SHACIRA: Scalable HAsh-grid Compression for Implicit Neural  Representations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Girish%2C+S">Sharath Girish</a>, 
<a href="/search/cs?searchtype=author&query=Shrivastava%2C+A">Abhinav Shrivastava</a>, 
<a href="/search/cs?searchtype=author&query=Gupta%2C+K">Kamal Gupta</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Implicit Neural Representations (INR) or neural fields have emerged as a
popular framework to encode multimedia signals such as images and radiance
fields while retaining high-quality. Recently, learnable feature grids proposed
by Instant-NGP have allowed significant speed-up in the training as well as the
sampling of INRs by replacing a large neural network with a multi-resolution
look-up table of feature vectors and a much smaller neural network. However,
these feature grids come at the expense of large memory consumption which can
be a bottleneck for storage and streaming applications. In this work, we
propose SHACIRA, a simple yet effective task-agnostic framework for compressing
such feature grids with no additional post-hoc pruning/quantization stages. We
reparameterize feature grids with quantized latent weights and apply entropy
regularization in the latent space to achieve high levels of compression across
various domains. Quantitative and qualitative results on diverse datasets
consisting of images, videos, and radiance fields, show that our approach
outperforms existing INR approaches without the need for any large datasets or
domain-specific heuristics. Our project page is available at
<a href="http://shacira.github.io">this http URL</a> .
</p>
</div>
</dd>
</dl>
<h3>Cross-lists for Thu, 28 Sep 23</h3>
<dl>
<dt><a name="item288">[288]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.14506" title="Abstract">arXiv:2309.14506</a> (cross-list from math.OC) [<a href="/pdf/2309.14506" title="Download PDF">pdf</a>, <a href="/format/2309.14506" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Zeroth-order Riemannian Averaging Stochastic Approximation Algorithms
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Li%2C+J">Jiaxiang Li</a>, 
<a href="/search/math?searchtype=author&query=Balasubramanian%2C+K">Krishnakumar Balasubramanian</a>, 
<a href="/search/math?searchtype=author&query=Ma%2C+S">Shiqian Ma</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Machine Learning (cs.LG); Machine Learning (stat.ML)

</div>
<p class="mathjax">We present Zeroth-order Riemannian Averaging Stochastic Approximation
(\texttt{Zo-RASA}) algorithms for stochastic optimization on Riemannian
manifolds. We show that \texttt{Zo-RASA} achieves optimal sample complexities
for generating $\epsilon$-approximation first-order stationary solutions using
only one-sample or constant-order batches in each iteration. Our approach
employs Riemannian moving-average stochastic gradient estimators, and a novel
Riemannian-Lyapunov analysis technique for convergence analysis. We improve the
algorithm's practicality by using retractions and vector transport, instead of
exponential mappings and parallel transports, thereby reducing per-iteration
complexity. Additionally, we introduce a novel geometric condition, satisfied
by manifolds with bounded second fundamental form, which enables new error
bounds for approximating parallel transport with vector transport.
</p>
</div>
</dd>
<dt><a name="item289">[289]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15123" title="Abstract">arXiv:2309.15123</a> (cross-list from physics.chem-ph) [<a href="/pdf/2309.15123" title="Download PDF">pdf</a>, <a href="/format/2309.15123" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Uncovering Neural Scaling Laws in Molecular Representation Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Chen%2C+D">Dingshuo Chen</a>, 
<a href="/search/physics?searchtype=author&query=Zhu%2C+Y">Yanqiao Zhu</a>, 
<a href="/search/physics?searchtype=author&query=Zhang%2C+J">Jieyu Zhang</a>, 
<a href="/search/physics?searchtype=author&query=Du%2C+Y">Yuanqi Du</a>, 
<a href="/search/physics?searchtype=author&query=Li%2C+Z">Zhixun Li</a>, 
<a href="/search/physics?searchtype=author&query=Liu%2C+Q">Qiang Liu</a>, 
<a href="/search/physics?searchtype=author&query=Wu%2C+S">Shu Wu</a>, 
<a href="/search/physics?searchtype=author&query=Wang%2C+L">Liang Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 23 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Chemical Physics (physics.chem-ph)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Molecular Representation Learning (MRL) has emerged as a powerful tool for
drug and materials discovery in a variety of tasks such as virtual screening
and inverse design. While there has been a surge of interest in advancing
model-centric techniques, the influence of both data quantity and quality on
molecular representations is not yet clearly understood within this field. In
this paper, we delve into the neural scaling behaviors of MRL from a
data-centric viewpoint, examining four key dimensions: (1) data modalities, (2)
dataset splitting, (3) the role of pre-training, and (4) model capacity. Our
empirical studies confirm a consistent power-law relationship between data
volume and MRL performance across these dimensions. Additionally, through
detailed analysis, we identify potential avenues for improving learning
efficiency. To challenge these scaling laws, we adapt seven popular data
pruning strategies to molecular data and benchmark their performance. Our
findings underline the importance of data-centric MRL and highlight possible
directions for future research.
</p>
</div>
</dd>
<dt><a name="item290">[290]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15126" title="Abstract">arXiv:2309.15126</a> (cross-list from physics.chem-ph) [<a href="/pdf/2309.15126" title="Download PDF">pdf</a>, <a href="/format/2309.15126" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> From Peptides to Nanostructures: A Euclidean Transformer for Fast and  Stable Machine Learned Force Fields
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Frank%2C+J+T">J. Thorben Frank</a>, 
<a href="/search/physics?searchtype=author&query=Unke%2C+O+T">Oliver T. Unke</a>, 
<a href="/search/physics?searchtype=author&query=M%C3%BCller%2C+K">Klaus-Robert M&#xfc;ller</a>, 
<a href="/search/physics?searchtype=author&query=Chmiela%2C+S">Stefan Chmiela</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Chemical Physics (physics.chem-ph)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Recent years have seen vast progress in the development of machine learned
force fields (MLFFs) based on ab-initio reference calculations. Despite
achieving low test errors, the suitability of MLFFs in molecular dynamics (MD)
simulations is being increasingly scrutinized due to concerns about
instability. Our findings suggest a potential connection between MD simulation
stability and the presence of equivariant representations in MLFFs, but their
computational cost can limit practical advantages they would otherwise bring.
<br />To address this, we propose a transformer architecture called SO3krates that
combines sparse equivariant representations (Euclidean variables) with a
self-attention mechanism that can separate invariant and equivariant
information, eliminating the need for expensive tensor products. SO3krates
achieves a unique combination of accuracy, stability, and speed that enables
insightful analysis of quantum properties of matter on unprecedented time and
system size scales. To showcase this capability, we generate stable MD
trajectories for flexible peptides and supra-molecular structures with hundreds
of atoms. Furthermore, we investigate the PES topology for medium-sized
chainlike molecules (e.g., small peptides) by exploring thousands of minima.
Remarkably, SO3krates demonstrates the ability to strike a balance between the
conflicting demands of stability and the emergence of new minimum-energy
conformations beyond the training data, which is crucial for realistic
exploration tasks in the field of biochemistry.
</p>
</div>
</dd>
<dt><a name="item291">[291]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15127" title="Abstract">arXiv:2309.15127</a> (cross-list from physics.chem-ph) [<a href="/pdf/2309.15127" title="Download PDF">pdf</a>, <a href="/format/2309.15127" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Grad DFT: a software library for machine learning enhanced density  functional theory
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Casares%2C+P+A+M">Pablo A. M. Casares</a>, 
<a href="/search/physics?searchtype=author&query=Baker%2C+J+S">Jack S. Baker</a>, 
<a href="/search/physics?searchtype=author&query=Medvidovic%2C+M">Matija Medvidovic</a>, 
<a href="/search/physics?searchtype=author&query=Reis%2C+R+d">Roberto dos Reis</a>, 
<a href="/search/physics?searchtype=author&query=Arrazola%2C+J+M">Juan Miguel Arrazola</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 22 pages, 9 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Chemical Physics (physics.chem-ph)</span>; Materials Science (cond-mat.mtrl-sci); Machine Learning (cs.LG); Quantum Physics (quant-ph)

</div>
<p class="mathjax">Density functional theory (DFT) stands as a cornerstone method in
computational quantum chemistry and materials science due to its remarkable
versatility and scalability. Yet, it suffers from limitations in accuracy,
particularly when dealing with strongly correlated systems. To address these
shortcomings, recent work has begun to explore how machine learning can expand
the capabilities of DFT; an endeavor with many open questions and technical
challenges. In this work, we present Grad DFT: a fully differentiable JAX-based
DFT library, enabling quick prototyping and experimentation with machine
learning-enhanced exchange-correlation energy functionals. Grad DFT employs a
pioneering parametrization of exchange-correlation functionals constructed
using a weighted sum of energy densities, where the weights are determined
using neural networks. Moreover, Grad DFT encompasses a comprehensive suite of
auxiliary functions, notably featuring a just-in-time compilable and fully
differentiable self-consistent iterative procedure. To support training and
benchmarking efforts, we additionally compile a curated dataset of experimental
dissociation energies of dimers, half of which contain transition metal atoms
characterized by strong electronic correlations. The software library is tested
against experimental results to study the generalization capabilities of a
neural functional across potential energy surfaces and atomic species, as well
as the effect of training data noise on the resulting model accuracy.
</p>
</div>
</dd>
<dt><a name="item292">[292]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15130" title="Abstract">arXiv:2309.15130</a> (cross-list from physics.chem-ph) [<a href="/pdf/2309.15130" title="Download PDF">pdf</a>, <a href="/format/2309.15130" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Understanding the Structure of QM7b and QM9 Quantum Mechanical Datasets  Using Unsupervised Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Vald%C3%A9s%2C+J+J">Julio J. Vald&#xe9;s</a>, 
<a href="/search/physics?searchtype=author&query=Tchagang%2C+A+B">Alain B. Tchagang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 5 figures, 2 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Chemical Physics (physics.chem-ph)</span>; Materials Science (cond-mat.mtrl-sci); Machine Learning (cs.LG)

</div>
<p class="mathjax">This paper explores the internal structure of two quantum mechanics datasets
(QM7b, QM9), composed of several thousands of organic molecules and described
in terms of electronic properties. Understanding the structure and
characteristics of this kind of data is important when predicting the atomic
composition from the properties in inverse molecular designs. Intrinsic
dimension analysis, clustering, and outlier detection methods were used in the
study. They revealed that for both datasets the intrinsic dimensionality is
several times smaller than the descriptive dimensions. The QM7b data is
composed of well defined clusters related to atomic composition. The QM9 data
consists of an outer region predominantly composed of outliers, and an inner
core region that concentrates clustered, inliner objects. A significant
relationship exists between the number of atoms in the molecule and its
outlier/inner nature. Despite the structural differences, the predictability of
variables of interest for inverse molecular design is high. This is exemplified
with models estimating the number of atoms of the molecule from both the
original properties, and from lower dimensional embedding spaces.
</p>
</div>
</dd>
<dt><a name="item293">[293]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15132" title="Abstract">arXiv:2309.15132</a> (cross-list from q-bio.QM) [<a href="/pdf/2309.15132" title="Download PDF">pdf</a>, <a href="/format/2309.15132" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Genetic InfoMax: Exploring Mutual Information Maximization in  High-Dimensional Imaging Genetics Studies
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-bio?searchtype=author&query=Xie%2C+Y">Yaochen Xie</a>, 
<a href="/search/q-bio?searchtype=author&query=Xie%2C+Z">Ziqian Xie</a>, 
<a href="/search/q-bio?searchtype=author&query=Islam%2C+S+M+S">Sheikh Muhammad Saiful Islam</a>, 
<a href="/search/q-bio?searchtype=author&query=Zhi%2C+D">Degui Zhi</a>, 
<a href="/search/q-bio?searchtype=author&query=Ji%2C+S">Shuiwang Ji</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 17 pages, 7 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantitative Methods (q-bio.QM)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Genome-wide association studies (GWAS) are used to identify relationships
between genetic variations and specific traits. When applied to
high-dimensional medical imaging data, a key step is to extract
lower-dimensional, yet informative representations of the data as traits.
Representation learning for imaging genetics is largely under-explored due to
the unique challenges posed by GWAS in comparison to typical visual
representation learning. In this study, we tackle this problem from the mutual
information (MI) perspective by identifying key limitations of existing
methods. We introduce a trans-modal learning framework Genetic InfoMax (GIM),
including a regularized MI estimator and a novel genetics-informed transformer
to address the specific challenges of GWAS. We evaluate GIM on human brain 3D
MRI data and establish standardized evaluation protocols to compare it to
existing approaches. Our results demonstrate the effectiveness of GIM and a
significantly improved performance on GWAS.
</p>
</div>
</dd>
<dt><a name="item294">[294]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15136" title="Abstract">arXiv:2309.15136</a> (cross-list from eess.SP) [<a href="/pdf/2309.15136" title="Download PDF">pdf</a>, <a href="/format/2309.15136" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A multi-modal approach for identifying schizophrenia using cross-modal  attention
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Premananth%2C+G">Gowtham Premananth</a>, 
<a href="/search/eess?searchtype=author&query=Siriwardena%2C+Y+M">Yashish M.Siriwardena</a>, 
<a href="/search/eess?searchtype=author&query=Resnik%2C+P">Philip Resnik</a>, 
<a href="/search/eess?searchtype=author&query=Espy-Wilson%2C+C">Carol Espy-Wilson</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Multimedia (cs.MM); Sound (cs.SD); Audio and Speech Processing (eess.AS); Image and Video Processing (eess.IV)

</div>
<p class="mathjax">This study focuses on how different modalities of human communication can be
used to distinguish between healthy controls and subjects with schizophrenia
who exhibit strong positive symptoms. We developed a multi-modal schizophrenia
classification system using audio, video, and text. Facial action units and
vocal tract variables were extracted as low-level features from video and audio
respectively, which were then used to compute high-level coordination features
that served as the inputs to the audio and video modalities.
Context-independent text embeddings extracted from transcriptions of speech
were used as the input for the text modality. The multi-modal system is
developed by fusing a segment-to-session-level classifier for video and audio
modalities with a text model based on a Hierarchical Attention Network (HAN)
with cross-modal attention. The proposed multi-modal system outperforms the
previous state-of-the-art multi-modal system by 8.53% in the weighted average
F1 score.
</p>
</div>
</dd>
<dt><a name="item295">[295]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15186" title="Abstract">arXiv:2309.15186</a> (cross-list from eess.SP) [<a href="/pdf/2309.15186" title="Download PDF">pdf</a>, <a href="/format/2309.15186" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AsQM: Audio streaming Quality Metric based on Network Impairments and  User Preferences
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Santos%2C+M+R+d">Marcelo Rodrigo dos Santos</a>, 
<a href="/search/eess?searchtype=author&query=Batista%2C+A+P">Andreza Patr&#xed;cia Batista</a>, 
<a href="/search/eess?searchtype=author&query=Rosa%2C+R+L">Renata Lopes Rosa</a>, 
<a href="/search/eess?searchtype=author&query=Saadi%2C+M">Muhammad Saadi</a>, 
<a href="/search/eess?searchtype=author&query=Melgarejo%2C+D+C">Dick Carrillo Melgarejo</a>, 
<a href="/search/eess?searchtype=author&query=Rodr%C3%ADguez%2C+D+Z">Dem&#xf3;stenes Zegarra Rodr&#xed;guez</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> IEEE Transactions on Consumer Electronics, vol. 69, no. 3, pp.
  408-420, Aug. 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Networking and Internet Architecture (cs.NI)

</div>
<p class="mathjax">There are many users of audio streaming services because of the proliferation
of cloud-based audio streaming services for different content. The complex
networks that support these services do not always guarantee an acceptable
quality on the end-user side. In this paper, the impact of temporal
interruptions on the reproduction of audio streaming and the users preference
in relation to audio contents are studied. In order to determine the key
parameters in the audio streaming service, subjective tests were conducted, and
their results show that users Quality-of-Experience (QoE) is highly correlated
with the following application parameters, the number of temporal interruptions
or stalls, its frequency and length, and the temporal location in which they
occur. However, most important, experimental results demonstrated that users
preference for audio content plays an important role in users QoE. Thus, a
Preference Factor (PF) function is defined and considered in the formulation of
the proposed metric named Audio streaming Quality Metric (AsQM). Considering
that multimedia service providers are based on web servers, a framework to
obtain user information is proposed. Furthermore, results show that the AsQM
implemented in the audio player of an end users device presents a low impact on
energy, processing and memory consumption.
</p>
</div>
</dd>
<dt><a name="item296">[296]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15193" title="Abstract">arXiv:2309.15193</a> (cross-list from eess.SP) [<a href="/pdf/2309.15193" title="Download PDF">pdf</a>, <a href="/format/2309.15193" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Reliable Majority Vote Computation with Complementary Sequences for UAV  Waypoint Flight Control
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Sahin%2C+A">Alphan Sahin</a>, 
<a href="/search/eess?searchtype=author&query=Wang%2C+X">Xiaofeng Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, 6 figures. arXiv admin note: substantial text overlap with <a href="/abs/2308.06372">arXiv:2308.06372</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Information Theory (cs.IT)

</div>
<p class="mathjax">In this study, we propose a non-coherent over-the-air computation (OAC)
scheme to calculate the majority vote (MV) reliably in fading channels. The
proposed approach relies on modulating the amplitude of the elements of
complementary sequences (CSs) based on the sign of the parameters to be
aggregated. Since it does not use channel state information at the nodes, it is
compatible with time-varying channels. To demonstrate the efficacy of our
method, we employ it in a scenario where an unmanned aerial vehicle (UAV) is
guided by distributed sensors, relying on the MV computed using our proposed
scheme. We show that the proposed scheme reduces the computation error rate
notably with a longer sequence length in fading channels while maintaining the
peak-to-mean-envelope power ratio of the transmitted orthogonal frequency
division multiplexing signals to be less than or equal to 3 dB.
</p>
</div>
</dd>
<dt><a name="item297">[297]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15194" title="Abstract">arXiv:2309.15194</a> (cross-list from quant-ph) [<a href="/pdf/2309.15194" title="Download PDF">pdf</a>, <a href="/format/2309.15194" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Discrete-time quantum walks on Cayley graphs of Dihedral groups using  generalized Grover coins
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Sarkar%2C+R+S">Rohit Sarma Sarkar</a>, 
<a href="/search/quant-ph?searchtype=author&query=Adhikari%2C+B">Bibhas Adhikari</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Information Theory (cs.IT)

</div>
<p class="mathjax">In this paper we study discrete-time quantum walks on Cayley graphs
corresponding to Dihedral groups, which are graphs with both directed and
undirected edges. We consider the walks with coins that are one-parameter
continuous deformation of the Grover matrix and can be written as linear
combinations of certain permutation matrices. We show that the walks are
periodic only for coins that are permutation or negative of a permutation
matrix. Finally, we investigate the localization property of the walks through
numerical simulations and observe that the walks localize for a wide range of
coins for different sizes of the graphs.
</p>
</div>
</dd>
<dt><a name="item298">[298]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15198" title="Abstract">arXiv:2309.15198</a> (cross-list from eess.SP) [<a href="/pdf/2309.15198" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Application of reciprocity for facilitation of wave field visualization  and defect detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=K%C3%B6hler%2C+B">Bernd K&#xf6;hler</a>, 
<a href="/search/eess?searchtype=author&query=Takahashi%2C+K">Kanta Takahashi</a>, 
<a href="/search/eess?searchtype=author&query=Nakahata%2C+K">Kazuyuki Nakahata</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Systems and Control (eess.SY)

</div>
<p class="mathjax">The motion visualization in a structural component was studied for defect
detection. Elastic motions were excited by hammer impacts at multiple points
and received by an accelerometer at a fixed point. Reciprocity in
elastodynamics is only valid under certain conditions. Its validity under given
experimental conditions was derived from the elastodynamic reciprocity theorem.
Based on this, the dynamic motion of the structural component was obtained for
fixed-point excitation from measurements performed using multipoint
excitations. In the visualized eigenmodes, significant additional deformation
was observed at the wall thinning inserted as an artificial defect. To prevent
the dependence of defect detection on its position within the mode shape,
another approach was proposed based on the extraction of guided wave modes
immediately after impact excitation. It is shown that this maximum intensity
projection method works well in detecting defects.
</p>
</div>
</dd>
<dt><a name="item299">[299]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15224" title="Abstract">arXiv:2309.15224</a> (cross-list from eess.AS) [<a href="/pdf/2309.15224" title="Download PDF">pdf</a>, <a href="/format/2309.15224" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Collaborative Watermarking for Adversarial Speech Synthesis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Juvela%2C+L">Lauri Juvela</a> (Aalto University, Finland), 
<a href="/search/eess?searchtype=author&query=Wang%2C+X">Xin Wang</a> (National Institute of Informatics, Japan)
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to ICASSP 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Sound (cs.SD)

</div>
<p class="mathjax">Advances in neural speech synthesis have brought us technology that is not
only close to human naturalness, but is also capable of instant voice cloning
with little data, and is highly accessible with pre-trained models available.
Naturally, the potential flood of generated content raises the need for
synthetic speech detection and watermarking. Recently, considerable research
effort in synthetic speech detection has been related to the Automatic Speaker
Verification and Spoofing Countermeasure Challenge (ASVspoof), which focuses on
passive countermeasures. This paper takes a complementary view to generated
speech detection: a synthesis system should make an active effort to watermark
the generated speech in a way that aids detection by another machine, but
remains transparent to a human listener. We propose a collaborative training
scheme for synthetic speech watermarking and show that a HiFi-GAN neural
vocoder collaborating with the ASVspoof 2021 baseline countermeasure models
consistently improves detection performance over conventional classifier
training. Furthermore, we demonstrate how collaborative training can be paired
with augmentation strategies for added robustness against noise and
time-stretching. Finally, listening tests demonstrate that collaborative
training has little adverse effect on perceptual quality of vocoded speech.
</p>
</div>
</dd>
<dt><a name="item300">[300]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15243" title="Abstract">arXiv:2309.15243</a> (cross-list from eess.IV) [<a href="/pdf/2309.15243" title="Download PDF">pdf</a>, <a href="/format/2309.15243" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> APIS: A paired CT-MRI dataset for ischemic stroke segmentation challenge
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=G%C3%B3mez%2C+S">Santiago G&#xf3;mez</a>, 
<a href="/search/eess?searchtype=author&query=Mantilla%2C+D">Daniel Mantilla</a>, 
<a href="/search/eess?searchtype=author&query=Garz%C3%B3n%2C+G">Gustavo Garz&#xf3;n</a>, 
<a href="/search/eess?searchtype=author&query=Rangel%2C+E">Edgar Rangel</a>, 
<a href="/search/eess?searchtype=author&query=Ortiz%2C+A">Andr&#xe9;s Ortiz</a>, 
<a href="/search/eess?searchtype=author&query=Sierra-Jerez%2C+F">Franklin Sierra-Jerez</a>, 
<a href="/search/eess?searchtype=author&query=Mart%C3%ADnez%2C+F">Fabio Mart&#xed;nez</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV); Neurons and Cognition (q-bio.NC)

</div>
<p class="mathjax">Stroke is the second leading cause of mortality worldwide. Immediate
attention and diagnosis play a crucial role regarding patient prognosis. The
key to diagnosis consists in localizing and delineating brain lesions. Standard
stroke examination protocols include the initial evaluation from a non-contrast
CT scan to discriminate between hemorrhage and ischemia. However, non-contrast
CTs may lack sensitivity in detecting subtle ischemic changes in the acute
phase. As a result, complementary diffusion-weighted MRI studies are captured
to provide valuable insights, allowing to recover and quantify stroke lesions.
This work introduced APIS, the first paired public dataset with NCCT and ADC
studies of acute ischemic stroke patients. APIS was presented as a challenge at
the 20th IEEE International Symposium on Biomedical Imaging 2023, where
researchers were invited to propose new computational strategies that leverage
paired data and deal with lesion segmentation over CT sequences. Despite all
the teams employing specialized deep learning tools, the results suggest that
the ischemic stroke segmentation task from NCCT remains challenging. The
annotated dataset remains accessible to the public upon registration, inviting
the scientific community to deal with stroke characterization from NCCT but
guided with paired DWI information.
</p>
</div>
</dd>
<dt><a name="item301">[301]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15259" title="Abstract">arXiv:2309.15259</a> (cross-list from quant-ph) [<a href="/pdf/2309.15259" title="Download PDF">pdf</a>, <a href="/format/2309.15259" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SLIQ: Quantum Image Similarity Networks on Noisy Quantum Computers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Silver%2C+D">Daniel Silver</a>, 
<a href="/search/quant-ph?searchtype=author&query=Patel%2C+T">Tirthak Patel</a>, 
<a href="/search/quant-ph?searchtype=author&query=Ranjan%2C+A">Aditya Ranjan</a>, 
<a href="/search/quant-ph?searchtype=author&query=Gandhi%2C+H">Harshitta Gandhi</a>, 
<a href="/search/quant-ph?searchtype=author&query=Cutler%2C+W">William Cutler</a>, 
<a href="/search/quant-ph?searchtype=author&query=Tiwari%2C+D">Devesh Tiwari</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Vol. 37 No. 8: AAAI-2023 Technical Tracks 8
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Computer Vision and Pattern Recognition (cs.CV); Image and Video Processing (eess.IV)

</div>
<p class="mathjax">Exploration into quantum machine learning has grown tremendously in recent
years due to the ability of quantum computers to speed up classical programs.
However, these efforts have yet to solve unsupervised similarity detection
tasks due to the challenge of porting them to run on quantum computers. To
overcome this challenge, we propose SLIQ, the first open-sourced work for
resource-efficient quantum similarity detection networks, built with practical
and effective quantum learning and variance-reducing algorithms.
</p>
</div>
</dd>
<dt><a name="item302">[302]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15269" title="Abstract">arXiv:2309.15269</a> (cross-list from econ.TH) [<a href="/pdf/2309.15269" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Theoretical Foundations of Community Rating by a Private Monopolist  Insurer: Framework, Regulation, and Numerical Analysis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/econ?searchtype=author&query=Braouezec%2C+Y">Yann Braouezec</a>, 
<a href="/search/econ?searchtype=author&query=Cagnol%2C+J">John Cagnol</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Theoretical Economics (econ.TH)</span>; Numerical Analysis (math.NA); Optimization and Control (math.OC)

</div>
<p class="mathjax">Community rating is a policy that mandates uniform premium regardless of the
risk factors. In this paper, our focus narrows to the single contract
interpretation wherein we establish a theoretical framework for community
rating using Stiglitz's (1977) monopoly model in which there is a continuum of
agents. We exhibit profitability conditions and show that, under mild
regularity conditions, the optimal premium is unique and satisfies the inverse
elasticity rule. Our numerical analysis, using realistic parameter values,
reveals that under regulation, a 10% increase in indemnity is possible with
minimal impact on other variables.
</p>
</div>
</dd>
<dt><a name="item303">[303]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15294" title="Abstract">arXiv:2309.15294</a> (cross-list from physics.flu-dyn) [<a href="/pdf/2309.15294" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multiple Physics-Informed Neural Network for Biomedical Tube Flows
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Wong%2C+H+S">Hong Shen Wong</a>, 
<a href="/search/physics?searchtype=author&query=Chan%2C+W+X">Wei Xuan Chan</a>, 
<a href="/search/physics?searchtype=author&query=Li%2C+B+H">Bing Huan Li</a>, 
<a href="/search/physics?searchtype=author&query=Yap%2C+C+H">Choon Hwai Yap</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 24 pages, 8 figures, 5 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Fluid Dynamics (physics.flu-dyn)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Fluid dynamics computations for tube-like geometries are important for
biomedical evaluation of vascular and airway fluid dynamics. Physics-Informed
Neural Networks (PINNs) have recently emerged as a good alternative to
traditional computational fluid dynamics (CFD) methods. The vanilla PINN,
however, requires much longer training time than the traditional CFD methods
for each specific flow scenario and thus does not justify its mainstream use.
Here, we explore the use of the multi-case PINN approach for calculating
biomedical tube flows, where varied geometry cases are parameterized and
pre-trained on the PINN, such that results for unseen geometries can be
obtained in real time. Our objective is to identify network architecture,
tube-specific, and regularization strategies that can optimize this, via
experiments on a series of idealized 2D stenotic tube flows.
</p>
</div>
</dd>
<dt><a name="item304">[304]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15298" title="Abstract">arXiv:2309.15298</a> (cross-list from math.OC) [<a href="/pdf/2309.15298" title="Download PDF">pdf</a>, <a href="/format/2309.15298" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Beyond Log-Concavity: Theory and Algorithm for Sum-Log-Concave  Optimization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Achab%2C+M">Mastane Achab</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">This paper extends the classic theory of convex optimization to the
minimization of functions that are equal to the negated logarithm of what we
term as a sum-log-concave function, i.e., a sum of log-concave functions. In
particular, we show that such functions are in general not convex but still
satisfy generalized convexity inequalities. These inequalities unveil the key
importance of a certain vector that we call the cross-gradient and that is, in
general, distinct from the usual gradient. Thus, we propose the Cross Gradient
Descent (XGD) algorithm moving in the opposite direction of the cross-gradient
and derive a convergence analysis. As an application of our sum-log-concave
framework, we introduce the so-called checkered regression method relying on a
sum-log-concave function. This classifier extends (multiclass) logistic
regression to non-linearly separable problems since it is capable of
tessellating the feature space by using any given number of hyperplanes,
creating a checkerboard-like pattern of decision regions.
</p>
</div>
</dd>
<dt><a name="item305">[305]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15314" title="Abstract">arXiv:2309.15314</a> (cross-list from physics.med-ph) [<a href="/pdf/2309.15314" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Conversion of single-energy computed tomography to parametric maps of  dual-energy computed tomography using convolutional neural network
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Kim%2C+S">Sangwook Kim</a>, 
<a href="/search/physics?searchtype=author&query=Lee%2C+J">Jimin Lee</a>, 
<a href="/search/physics?searchtype=author&query=Kim%2C+J">Jungye Kim</a>, 
<a href="/search/physics?searchtype=author&query=Kim%2C+B">Bitbyeol Kim</a>, 
<a href="/search/physics?searchtype=author&query=Choi%2C+C+H">Chang Heon Choi</a>, 
<a href="/search/physics?searchtype=author&query=Jung%2C+S">Seongmoon Jung</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 29 pages, 17 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Medical Physics (physics.med-ph)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Objectives: We propose a deep learning (DL) multi-task learning framework
using convolutional neural network (CNN) for a direct conversion of
single-energy CT (SECT) to three different parametric maps of dual-energy CT
(DECT): Virtual-monochromatic image (VMI), effective atomic number (EAN), and
relative electron density (RED).
<br />Methods: We propose VMI-Net for conversion of SECT to 70, 120, and 200 keV
VMIs. In addition, EAN-Net and RED-Net were also developed to convert SECT to
EAN and RED. We trained and validated our model using 67 patients collected
between 2019 and 2020. SECT images with 120 kVp acquired by the DECT (IQon
spectral CT, Philips) were used as input, while the VMIs, EAN, and RED acquired
by the same device were used as target. The performance of the DL framework was
evaluated by absolute difference (AD) and relative difference (RD).
<br />Results: The VMI-Net converted 120 kVp SECT to the VMIs with AD of 9.02
Hounsfield Unit, and RD of 0.41% compared to the ground truth VMIs. The ADs of
the converted EAN and RED were 0.29 and 0.96, respectively, while the RDs were
1.99% and 0.50% for the converted EAN and RED, respectively.
<br />Conclusions: SECT images were directly converted to the three parametric maps
of DECT (i.e., VMIs, EAN, and RED). By using this model, one can generate the
parametric information from SECT images without DECT device. Our model can help
investigate the parametric information from SECT retrospectively.
<br />Advances in knowledge: Deep learning framework enables converting SECT to
various high-quality parametric maps of DECT.
</p>
</div>
</dd>
<dt><a name="item306">[306]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15366" title="Abstract">arXiv:2309.15366</a> (cross-list from q-bio.QM) [<a href="/pdf/2309.15366" title="Download PDF">pdf</a>, <a href="/format/2309.15366" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Density Estimation via Measure Transport: Outlook for Applications in  the Biological Sciences
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-bio?searchtype=author&query=Lopez-Marrero%2C+V">Vanessa Lopez-Marrero</a>, 
<a href="/search/q-bio?searchtype=author&query=Johnstone%2C+P+R">Patrick R. Johnstone</a>, 
<a href="/search/q-bio?searchtype=author&query=Park%2C+G">Gilchan Park</a>, 
<a href="/search/q-bio?searchtype=author&query=Luo%2C+X">Xihaier Luo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 23 pages; 12 figures; sha256 (main.tex): 6181e3b5969646ef2163539fc062bd94e929f3e4155e4f54ddcb3bad1f28ba34
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantitative Methods (q-bio.QM)</span>; Machine Learning (cs.LG); Biological Physics (physics.bio-ph)

</div>
<p class="mathjax">One among several advantages of measure transport methods is that they allow
for a unified framework for processing and analysis of data distributed
according to a wide class of probability measures. Within this context, we
present results from computational studies aimed at assessing the potential of
measure transport techniques, specifically, the use of triangular transport
maps, as part of a workflow intended to support research in the biological
sciences. Scarce data scenarios, which are common in domains such as radiation
biology, are of particular interest. We find that when data is scarce, sparse
transport maps are advantageous. In particular, statistics gathered from
computing series of (sparse) adaptive transport maps, trained on a series of
randomly chosen subsets of the set of available data samples, leads to
uncovering information hidden in the data. As a result, in the radiation
biology application considered here, this approach provides a tool for
generating hypotheses about gene relationships and their dynamics under
radiation exposure.
</p>
</div>
</dd>
<dt><a name="item307">[307]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15374" title="Abstract">arXiv:2309.15374</a> (cross-list from eess.IV) [<a href="/pdf/2309.15374" title="Download PDF">pdf</a>, <a href="/format/2309.15374" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DREAM-PCD: Deep Reconstruction and Enhancement of mmWave Radar  Pointcloud
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Geng%2C+R">Ruixu Geng</a>, 
<a href="/search/eess?searchtype=author&query=Li%2C+Y">Yadong Li</a>, 
<a href="/search/eess?searchtype=author&query=Zhang%2C+D">Dongheng Zhang</a>, 
<a href="/search/eess?searchtype=author&query=Wu%2C+J">Jincheng Wu</a>, 
<a href="/search/eess?searchtype=author&query=Gao%2C+Y">Yating Gao</a>, 
<a href="/search/eess?searchtype=author&query=Hu%2C+Y">Yang Hu</a>, 
<a href="/search/eess?searchtype=author&query=Chen%2C+Y">Yan Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, 9 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Robotics (cs.RO)

</div>
<p class="mathjax">Millimeter-wave (mmWave) radar pointcloud offers attractive potential for 3D
sensing, thanks to its robustness in challenging conditions such as smoke and
low illumination. However, existing methods failed to simultaneously address
the three main challenges in mmWave radar pointcloud reconstruction: specular
information lost, low angular resolution, and strong interference and noise. In
this paper, we propose DREAM-PCD, a novel framework that combines signal
processing and deep learning methods into three well-designed components to
tackle all three challenges: Non-Coherent Accumulation for dense points,
Synthetic Aperture Accumulation for improved angular resolution, and
Real-Denoise Multiframe network for noise and interference removal. Moreover,
the causal multiframe and "real-denoise" mechanisms in DREAM-PCD significantly
enhance the generalization performance. We also introduce RadarEyes, the
largest mmWave indoor dataset with over 1,000,000 frames, featuring a unique
design incorporating two orthogonal single-chip radars, lidar, and camera,
enriching dataset diversity and applications. Experimental results demonstrate
that DREAM-PCD surpasses existing methods in reconstruction quality, and
exhibits superior generalization and real-time capabilities, enabling
high-quality real-time reconstruction of radar pointcloud under various
parameters and scenarios. We believe that DREAM-PCD, along with the RadarEyes
dataset, will significantly advance mmWave radar perception in future
real-world applications.
</p>
</div>
</dd>
<dt><a name="item308">[308]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15400" title="Abstract">arXiv:2309.15400</a> (cross-list from physics.ao-ph) [<a href="/pdf/2309.15400" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Revolutionizing Terrain-Precipitation Understanding through AI-driven  Knowledge Discovery
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Xu%2C+H">Hao Xu</a>, 
<a href="/search/physics?searchtype=author&query=Chen%2C+Y">Yuntian Chen</a>, 
<a href="/search/physics?searchtype=author&query=Zeng%2C+Z">Zhenzhong Zeng</a>, 
<a href="/search/physics?searchtype=author&query=Li%2C+N">Nina Li</a>, 
<a href="/search/physics?searchtype=author&query=Li%2C+J">Jian Li</a>, 
<a href="/search/physics?searchtype=author&query=Zhang%2C+D">Dongxiao Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Atmospheric and Oceanic Physics (physics.ao-ph)</span>; Machine Learning (cs.LG); Geophysics (physics.geo-ph)

</div>
<p class="mathjax">Advancing our understanding of climate processes in regions characterized by
intricate terrain complexity is a paramount challenge in contemporary climate
science, particularly in the context of global climate change. Notably, the
scarcity of observational data in these regions has imposed substantial
limitations on understanding the nuanced climate dynamics therein. For the
first time, utilizing cutting-edge AI-driven knowledge discovery techniques, we
have uncovered explicit equations that elucidate the intricate relationship
between terrain features and precipitation patterns, illuminating the
previously concealed complexities governing these relationships. These
equations, thus far undisclosed, exhibit remarkable accuracy compared to
conventional empirical models when applied to precipitation data. Building on
this foundation, we reveal a phenomenon known as the '1995 turning point,'
indicating a significant shift in the terrain-precipitation relationship in
approximately 1995, related to the forces of climate change. These equations
have practical applications, particularly in achieving fine-scale downscaling
precipitation predictions from low-resolution future climate data. This
capability provides invaluable insights into the expected changes in
precipitation patterns across diverse terrains under future climate scenarios.
</p>
</div>
</dd>
<dt><a name="item309">[309]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15408" title="Abstract">arXiv:2309.15408</a> (cross-list from stat.ME) [<a href="/pdf/2309.15408" title="Download PDF">pdf</a>, <a href="/format/2309.15408" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Frequency and cardinality recovery from sketched data: a novel approach  bridging Bayesian and frequentist views
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Beraha%2C+M">Mario Beraha</a>, 
<a href="/search/stat?searchtype=author&query=Favaro%2C+S">Stefano Favaro</a>, 
<a href="/search/stat?searchtype=author&query=Sesia%2C+M">Matteo Sesia</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Methodology (stat.ME)</span>; Data Structures and Algorithms (cs.DS); Information Retrieval (cs.IR); Statistics Theory (math.ST)

</div>
<p class="mathjax">We study how to recover the frequency of a symbol in a large discrete data
set, using only a compressed representation, or sketch, of those data obtained
via random hashing. This is a classical problem in computer science, with
various algorithms available, such as the count-min sketch. However, these
algorithms often assume that the data are fixed, leading to overly conservative
and potentially inaccurate estimates when dealing with randomly sampled data.
In this paper, we consider the sketched data as a random sample from an unknown
distribution, and then we introduce novel estimators that improve upon existing
approaches. Our method combines Bayesian nonparametric and classical
(frequentist) perspectives, addressing their unique limitations to provide a
principled and practical solution. Additionally, we extend our method to
address the related but distinct problem of cardinality recovery, which
consists of estimating the total number of distinct objects in the data set. We
validate our method on synthetic and real data, comparing its performance to
state-of-the-art alternatives.
</p>
</div>
</dd>
<dt><a name="item310">[310]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15485" title="Abstract">arXiv:2309.15485</a> (cross-list from eess.IV) [<a href="/pdf/2309.15485" title="Download PDF">pdf</a>, <a href="/format/2309.15485" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Style Transfer and Self-Supervised Learning Powered Myocardium  Infarction Super-Resolution Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Wang%2C+L">Lichao Wang</a>, 
<a href="/search/eess?searchtype=author&query=Huang%2C+J">Jiahao Huang</a>, 
<a href="/search/eess?searchtype=author&query=Xing%2C+X">Xiaodan Xing</a>, 
<a href="/search/eess?searchtype=author&query=Wu%2C+Y">Yinzhe Wu</a>, 
<a href="/search/eess?searchtype=author&query=Rajakulasingam%2C+R">Ramyah Rajakulasingam</a>, 
<a href="/search/eess?searchtype=author&query=Scott%2C+A+D">Andrew D. Scott</a>, 
<a href="/search/eess?searchtype=author&query=Ferreira%2C+P+F">Pedro F Ferreira</a>, 
<a href="/search/eess?searchtype=author&query=De+Silva%2C+R">Ranil De Silva</a>, 
<a href="/search/eess?searchtype=author&query=Nielles-Vallespin%2C+S">Sonia Nielles-Vallespin</a>, 
<a href="/search/eess?searchtype=author&query=Yang%2C+G">Guang Yang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages, 8 figures, conference, accepted by SIPAIM2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">This study proposes a pipeline that incorporates a novel style transfer model
and a simultaneous super-resolution and segmentation model. The proposed
pipeline aims to enhance diffusion tensor imaging (DTI) images by translating
them into the late gadolinium enhancement (LGE) domain, which offers a larger
amount of data with high-resolution and distinct highlighting of myocardium
infarction (MI) areas. Subsequently, the segmentation task is performed on the
LGE style image. An end-to-end super-resolution segmentation model is
introduced to generate high-resolution mask from low-resolution LGE style DTI
image. Further, to enhance the performance of the model, a multi-task
self-supervised learning strategy is employed to pre-train the super-resolution
segmentation model, allowing it to acquire more representative knowledge and
improve its segmentation performance after fine-tuning. https:
github.com/wlc2424762917/Med_Img
</p>
</div>
</dd>
<dt><a name="item311">[311]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15496" title="Abstract">arXiv:2309.15496</a> (cross-list from eess.AS) [<a href="/pdf/2309.15496" title="Download PDF">pdf</a>, <a href="/format/2309.15496" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DualVC 2: Dynamic Masked Convolution for Unified Streaming and  Non-Streaming Voice Conversion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Ning%2C+Z">Ziqian Ning</a>, 
<a href="/search/eess?searchtype=author&query=Jiang%2C+Y">Yuepeng Jiang</a>, 
<a href="/search/eess?searchtype=author&query=Zhu%2C+P">Pengcheng Zhu</a>, 
<a href="/search/eess?searchtype=author&query=Wang%2C+S">Shuai Wang</a>, 
<a href="/search/eess?searchtype=author&query=Yao%2C+J">Jixun Yao</a>, 
<a href="/search/eess?searchtype=author&query=Xie%2C+L">Lei Xie</a>, 
<a href="/search/eess?searchtype=author&query=Bi%2C+M">Mengxiao Bi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Sound (cs.SD)

</div>
<p class="mathjax">Voice conversion is becoming increasingly popular, and a growing number of
application scenarios require models with streaming inference capabilities. The
recently proposed DualVC attempts to achieve this objective through streaming
model architecture design and intra-model knowledge distillation along with
hybrid predictive coding to compensate for the lack of future information.
However, DualVC encounters several problems that limit its performance. First,
the autoregressive decoder has error accumulation in its nature and limits the
inference speed as well. Second, the causal convolution enables streaming
capability but cannot sufficiently use future information within chunks. Third,
the model is unable to effectively address the noise in the unvoiced segments,
lowering the sound quality. In this paper, we propose DualVC 2 to address these
issues. Specifically, the model backbone is migrated to a Conformer-based
architecture, empowering parallel inference. Causal convolution is replaced by
non-causal convolution with dynamic chunk mask to make better use of
within-chunk future information. Also, quiet attention is introduced to enhance
the model's noise robustness. Experiments show that DualVC 2 outperforms DualVC
and other baseline systems in both subjective and objective metrics, with only
186.4 ms latency. Our audio samples are made publicly available.
</p>
</div>
</dd>
<dt><a name="item312">[312]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15498" title="Abstract">arXiv:2309.15498</a> (cross-list from math.OC) [<a href="/pdf/2309.15498" title="Download PDF">pdf</a>, <a href="/format/2309.15498" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Control Theoretical Approach to Online Constrained Optimization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Casti%2C+U">Umberto Casti</a>, 
<a href="/search/math?searchtype=author&query=Bastianello%2C+N">Nicola Bastianello</a>, 
<a href="/search/math?searchtype=author&query=Carli%2C+R">Ruggero Carli</a>, 
<a href="/search/math?searchtype=author&query=Zampieri%2C+S">Sandro Zampieri</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Systems and Control (eess.SY)

</div>
<p class="mathjax">In this paper we focus on the solution of online problems with time-varying,
linear equality and inequality constraints. Our approach is to design a novel
online algorithm by leveraging the tools of control theory. In particular, for
the case of equality constraints only, using robust control we design an online
algorithm with asymptotic convergence to the optimal trajectory, differently
from the alternatives that achieve non-zero tracking error. When also
inequality constraints are present, we show how to modify the proposed
algorithm to account for the wind-up induced by the nonnegativity constraints
on the dual variables. We report numerical results that corroborate the
theoretical analysis, and show how the proposed approach outperforms
state-of-the-art algorithms both with equality and inequality constraints.
</p>
</div>
</dd>
<dt><a name="item313">[313]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15529" title="Abstract">arXiv:2309.15529</a> (cross-list from eess.IV) [<a href="/pdf/2309.15529" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Missing-modality Enabled Multi-modal Fusion Architecture for Medical  Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Wang%2C+M">Muyu Wang</a>, 
<a href="/search/eess?searchtype=author&query=Fan%2C+S">Shiyu Fan</a>, 
<a href="/search/eess?searchtype=author&query=Li%2C+Y">Yichen Li</a>, 
<a href="/search/eess?searchtype=author&query=Chen%2C+H">Hui Chen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
<p class="mathjax">Fusing multi-modal data can improve the performance of deep learning models.
However, missing modalities are common for medical data due to patients'
specificity, which is detrimental to the performance of multi-modal models in
applications. Therefore, it is critical to adapt the models to missing
modalities. This study aimed to develop an efficient multi-modal fusion
architecture for medical data that was robust to missing modalities and further
improved the performance on disease diagnosis.X-ray chest radiographs for the
image modality, radiology reports for the text modality, and structured value
data for the tabular data modality were fused in this study. Each modality pair
was fused with a Transformer-based bi-modal fusion module, and the three
bi-modal fusion modules were then combined into a tri-modal fusion framework.
Additionally, multivariate loss functions were introduced into the training
process to improve model's robustness to missing modalities in the inference
process. Finally, we designed comparison and ablation experiments for
validating the effectiveness of the fusion, the robustness to missing
modalities and the enhancements from each key component. Experiments were
conducted on MIMIC-IV, MIMIC-CXR with the 14-label disease diagnosis task.
Areas under the receiver operating characteristic curve (AUROC), the area under
the precision-recall curve (AUPRC) were used to evaluate models' performance.
The experimental results demonstrated that our proposed multi-modal fusion
architecture effectively fused three modalities and showed strong robustness to
missing modalities. This method is hopeful to be scaled to more modalities to
enhance the clinical practicality of the model.
</p>
</div>
</dd>
<dt><a name="item314">[314]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15593" title="Abstract">arXiv:2309.15593</a> (cross-list from cond-mat.quant-gas) [<a href="/pdf/2309.15593" title="Download PDF">pdf</a>, <a href="/format/2309.15593" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exciton-Polariton Condensates: A Fourier Neural Operator Approach
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cond-mat?searchtype=author&query=Sathujoda%2C+S+T">Surya T. Sathujoda</a>, 
<a href="/search/cond-mat?searchtype=author&query=Wang%2C+Y">Yuan Wang</a>, 
<a href="/search/cond-mat?searchtype=author&query=Gandhi%2C+K">Kanishk Gandhi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 19 pages, 8 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Gases (cond-mat.quant-gas)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Advancements in semiconductor fabrication over the past decade have catalyzed
extensive research into all-optical devices driven by exciton-polariton
condensates. Preliminary validations of such devices, including transistors,
have shown encouraging results even under ambient conditions. A significant
challenge still remains for large scale application however: the lack of a
robust solver that can be used to simulate complex nonlinear systems which
require an extended period of time to stabilize. Addressing this need, we
propose the application of a machine-learning-based Fourier Neural Operator
approach to find the solution to the Gross-Pitaevskii equations coupled with
extra exciton rate equations. This work marks the first direct application of
Neural Operators to an exciton-polariton condensate system. Our findings show
that the proposed method can predict final-state solutions to a high degree of
accuracy almost 1000 times faster than CUDA-based GPU solvers. Moreover, this
paves the way for potential all-optical chip design workflows by integrating
experimental data.
</p>
</div>
</dd>
<dt><a name="item315">[315]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15608" title="Abstract">arXiv:2309.15608</a> (cross-list from eess.IV) [<a href="/pdf/2309.15608" title="Download PDF">pdf</a>, <a href="/format/2309.15608" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> NoSENSE: Learned unrolled cardiac MRI reconstruction without explicit  sensitivity maps
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Zimmermann%2C+F+F">Felix Frederik Zimmermann</a>, 
<a href="/search/eess?searchtype=author&query=Kofler%2C+A">Andreas Kofler</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at MICCAI STACOM 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG); Medical Physics (physics.med-ph)

</div>
<p class="mathjax">We present a novel learned image reconstruction method for accelerated
cardiac MRI with multiple receiver coils based on deep convolutional neural
networks (CNNs) and algorithm unrolling. In contrast to many existing learned
MR image reconstruction techniques that necessitate coil-sensitivity map (CSM)
estimation as a distinct network component, our proposed approach avoids
explicit CSM estimation. Instead, it implicitly captures and learns to exploit
the inter-coil relationships of the images. Our method consists of a series of
novel learned image and k-space blocks with shared latent information and
adaptation to the acquisition parameters by feature-wise modulation (FiLM), as
well as coil-wise data-consistency (DC) blocks.
<br />Our method achieved PSNR values of 34.89 and 35.56 and SSIM values of 0.920
and 0.942 in the cine track and mapping track validation leaderboard of the
MICCAI STACOM CMRxRecon Challenge, respectively, ranking 4th among different
teams at the time of writing.
<br />Code will be made available at https://github.com/fzimmermann89/CMRxRecon
</p>
</div>
</dd>
<dt><a name="item316">[316]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15610" title="Abstract">arXiv:2309.15610</a> (cross-list from physics.soc-ph) [<a href="/pdf/2309.15610" title="Download PDF">pdf</a>, <a href="/format/2309.15610" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Genius Cliques: Mapping out the Nobel Network
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Janosov%2C+M">Milan Janosov</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, 3 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Physics and Society (physics.soc-ph)</span>; Digital Libraries (cs.DL)

</div>
<p class="mathjax">In this short piece, I delved into the connections of Nobel laureates by
applying Network Science methods to and public data collected from Wikipedia. I
uncovered the existence of a central "giant component" in the Nobel laureate
network, highlighting the core-periphery structure and the disparity in
visibility among laureates. I explored the dominance of laureates in the fields
of science and humanities, revealing a polarization that contradicts the trend
of interdisciplinary research. Furthermore, it the finding sheds light on the
underrepresentation of female laureates in certain Nobel Prize categories.
</p>
</div>
</dd>
<dt><a name="item317">[317]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15638" title="Abstract">arXiv:2309.15638</a> (cross-list from eess.IV) [<a href="/pdf/2309.15638" title="Download PDF">pdf</a>, <a href="/format/2309.15638" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FRS-Nets: Fourier Parameterized Rotation and Scale Equivariant Networks  for Retinal Vessel Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Sun%2C+Z">Zihong Sun</a>, 
<a href="/search/eess?searchtype=author&query=Xie%2C+Q">Qi Xie</a>, 
<a href="/search/eess?searchtype=author&query=Meng%2C+D">Deyu Meng</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
<p class="mathjax">With translation equivariance, convolution neural networks (CNNs) have
achieved great success in retinal vessel segmentation. However, some other
symmetries of the vascular morphology are not characterized by CNNs, such as
rotation and scale symmetries. To embed more equivariance into CNNs and achieve
the accuracy requirement for retinal vessel segmentation, we construct a novel
convolution operator (FRS-Conv), which is Fourier parameterized and equivariant
to rotation and scaling. Specifically, we first adopt a new parameterization
scheme, which enables convolutional filters to arbitrarily perform
transformations with high accuracy. Secondly, we derive the formulations for
the rotation and scale equivariant convolution mapping. Finally, we construct
FRS-Conv following the proposed formulations and replace the traditional
convolution filters in U-Net and Iter-Net with FRS-Conv (FRS-Nets). We
faithfully reproduce all compared methods and conduct comprehensive experiments
on three public datasets under both in-dataset and cross-dataset settings. With
merely 13.9% parameters of corresponding baselines, FRS-Nets have achieved
state-of-the-art performance and significantly outperform all compared methods.
It demonstrates the remarkable accuracy, generalization, and clinical
application potential of FRS-Nets.
</p>
</div>
</dd>
<dt><a name="item318">[318]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15640" title="Abstract">arXiv:2309.15640</a> (cross-list from q-fin.PM) [<a href="/pdf/2309.15640" title="Download PDF">pdf</a>, <a href="/format/2309.15640" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Hedging Properties of Algorithmic Investment Strategies using Long  Short-Term Memory and Time Series models for Equity Indices
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-fin?searchtype=author&query=Micha%C5%84k%C3%B3w%2C+J">Jakub Micha&#x144;k&#xf3;w</a>, 
<a href="/search/q-fin?searchtype=author&query=Sakowski%2C+P">Pawe&#x142; Sakowski</a>, 
<a href="/search/q-fin?searchtype=author&query=%C5%9Alepaczuk%2C+R">Robert &#x15a;lepaczuk</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 19 pages, 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Portfolio Management (q-fin.PM)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Computational Finance (q-fin.CP); Trading and Market Microstructure (q-fin.TR)

</div>
<p class="mathjax">This paper proposes a novel approach to hedging portfolios of risky assets
when financial markets are affected by financial turmoils. We introduce a
completely novel approach to diversification activity not on the level of
single assets but on the level of ensemble algorithmic investment strategies
(AIS) built based on the prices of these assets. We employ four types of
diverse theoretical models (LSTM - Long Short-Term Memory, ARIMA-GARCH -
Autoregressive Integrated Moving Average - Generalized Autoregressive
Conditional Heteroskedasticity, momentum, and contrarian) to generate price
forecasts, which are then used to produce investment signals in single and
complex AIS. In such a way, we are able to verify the diversification potential
of different types of investment strategies consisting of various assets
(energy commodities, precious metals, cryptocurrencies, or soft commodities) in
hedging ensemble AIS built for equity indices (S&amp;P 500 index). Empirical data
used in this study cover the period between 2004 and 2022. Our main conclusion
is that LSTM-based strategies outperform the other models and that the best
diversifier for the AIS built for the S&amp;P 500 index is the AIS built for
Bitcoin. Finally, we test the LSTM model for a higher frequency of data (1
hour). We conclude that it outperforms the results obtained using daily data.
</p>
</div>
</dd>
<dt><a name="item319">[319]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15642" title="Abstract">arXiv:2309.15642</a> (cross-list from quant-ph) [<a href="/pdf/2309.15642" title="Download PDF">pdf</a>, <a href="/format/2309.15642" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Efficient tensor network simulation of IBM&#x27;s largest quantum processors
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Patra%2C+S">Siddhartha Patra</a>, 
<a href="/search/quant-ph?searchtype=author&query=Jahromi%2C+S+S">Saeed S. Jahromi</a>, 
<a href="/search/quant-ph?searchtype=author&query=Singh%2C+S">Sukhbinder Singh</a>, 
<a href="/search/quant-ph?searchtype=author&query=Orus%2C+R">Roman Orus</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages, 4 figures, plus Supplementary Material of 1 page with 1 table
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Strongly Correlated Electrons (cond-mat.str-el); Computational Engineering, Finance, and Science (cs.CE); Machine Learning (cs.LG)

</div>
<p class="mathjax">We show how quantum-inspired 2d tensor networks can be used to efficiently
and accurately simulate the largest quantum processors from IBM, namely Eagle
(127 qubits), Osprey (433 qubits) and Condor (1121 qubits). We simulate the
dynamics of a complex quantum many-body system -- specifically, the kicked
Ising experiment considered recently by IBM in Nature 618, p. 500-505 (2023) --
using graph-based Projected Entangled Pair States (gPEPS), which was proposed
by some of us in PRB 99, 195105 (2019). Our results show that simple tensor
updates are already sufficient to achieve very large unprecedented accuracy
with remarkably low computational resources for this model. Apart from
simulating the original experiment for 127 qubits, we also extend our results
to 433 and 1121 qubits, thus setting a benchmark for the newest IBM quantum
machines. We also report accurate simulations for infinitely-many qubits. Our
results show that gPEPS are a natural tool to efficiently simulate quantum
computers with an underlying lattice-based qubit connectivity, such as all
quantum processors based on superconducting qubits.
</p>
</div>
</dd>
<dt><a name="item320">[320]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15643" title="Abstract">arXiv:2309.15643</a> (cross-list from eess.AS) [<a href="/pdf/2309.15643" title="Download PDF">pdf</a>, <a href="/format/2309.15643" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Why do Angular Margin Losses work well for Semi-Supervised Anomalous  Sound Detection?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Wilkinghoff%2C+K">Kevin Wilkinghoff</a>, 
<a href="/search/eess?searchtype=author&query=Kurth%2C+F">Frank Kurth</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Machine Learning (cs.LG); Sound (cs.SD)

</div>
<p class="mathjax">State-of-the-art anomalous sound detection systems often utilize angular
margin losses to learn suitable representations of acoustic data using an
auxiliary task, which usually is a supervised or self-supervised classification
task. The underlying idea is that, in order to solve this auxiliary task,
specific information about normal data needs to be captured in the learned
representations and that this information is also sufficient to differentiate
between normal and anomalous samples. Especially in noisy conditions,
discriminative models based on angular margin losses tend to significantly
outperform systems based on generative or one-class models. The goal of this
work is to investigate why using angular margin losses with auxiliary tasks
works well for detecting anomalous sounds. To this end, it is shown, both
theoretically and experimentally, that minimizing angular margin losses also
minimizes compactness loss while inherently preventing learning trivial
solutions. Furthermore, multiple experiments are conducted to show that using a
related classification task as an auxiliary task teaches the model to learn
representations suitable for detecting anomalous sounds in noisy conditions.
Among these experiments are performance evaluations, visualizing the embedding
space with t-SNE and visualizing the input representations with respect to the
anomaly score using randomized input sampling for explanation.
</p>
</div>
</dd>
<dt><a name="item321">[321]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15654" title="Abstract">arXiv:2309.15654</a> (cross-list from math.LO) [<a href="/pdf/2309.15654" title="Download PDF">pdf</a>, <a href="/ps/2309.15654" title="Download PostScript">ps</a>, <a href="/format/2309.15654" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Complexity of Resilience Problems via Valued Constraint Satisfaction  Problems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Bodirsky%2C+M">Manuel Bodirsky</a>, 
<a href="/search/math?searchtype=author&query=Semani%C5%A1inov%C3%A1%2C+%C5%BD">&#x17d;aneta Semani&#x161;inov&#xe1;</a>, 
<a href="/search/math?searchtype=author&query=Lutz%2C+C">Carsten Lutz</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic (math.LO)</span>; Computational Complexity (cs.CC); Databases (cs.DB)

</div>
<p class="mathjax">Valued constraint satisfaction problems (VCSPs) are a large class of
computational optimisation problems. If the variables of a VCSP take values
from a finite domain, then recent results in constraint satisfaction imply that
the problem is in P or NP-complete, depending on the set of admitted cost
functions. Here we study the larger class of cost functions over countably
infinite domains that have an oligomorphic automorphism group. We present a
hardness condition based on a generalisation of pp-constructability as known
for (classical) CSPs. We also provide a universal-algebraic polynomial-time
tractability condition, based on the concept of fractional polymorphisms.
<br />We apply our general theory to study the computational complexity of
resilience problems in database theory (under bag semantics). We show how to
construct, for every fixed conjunctive query (and more generally for every
union of conjunctive queries), a set of cost functions with an oligomorphic
automorphism group such that the resulting VCSP is polynomial-time equivalent
to the resilience problem; we only require that the query is connected and show
that this assumption can be made without loss of generality. For the case where
the query is acylic, we obtain a complexity dichotomy of the resilience
problem, based on the dichotomy for finite-domain VCSPs. To illustrate the
utility of our methods, we exemplarily settle the complexity of a (non-acyclic)
conjunctive query whose computational complexity remained open in the
literature by verifying that it satisfies our tractability condition. We
conjecture that for resilience problems, our hardness and tractability
conditions match, which would establish a complexity dichotomy for resilience
problems for (unions of) conjunctive queries.
</p>
</div>
</dd>
<dt><a name="item322">[322]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15717" title="Abstract">arXiv:2309.15717</a> (cross-list from eess.AS) [<a href="/pdf/2309.15717" title="Download PDF">pdf</a>, <a href="/format/2309.15717" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Timbre-Trap: A Low-Resource Framework for Instrument-Agnostic Music  Transcription
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Cwitkowitz%2C+F">Frank Cwitkowitz</a>, 
<a href="/search/eess?searchtype=author&query=Cheuk%2C+K+W">Kin Wai Cheuk</a>, 
<a href="/search/eess?searchtype=author&query=Choi%2C+W">Woosung Choi</a>, 
<a href="/search/eess?searchtype=author&query=Mart%C3%ADnez-Ram%C3%ADrez%2C+M+A">Marco A. Mart&#xed;nez-Ram&#xed;rez</a>, 
<a href="/search/eess?searchtype=author&query=Toyama%2C+K">Keisuke Toyama</a>, 
<a href="/search/eess?searchtype=author&query=Liao%2C+W">Wei-Hsiang Liao</a>, 
<a href="/search/eess?searchtype=author&query=Mitsufuji%2C+Y">Yuki Mitsufuji</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to ICASSP 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Machine Learning (cs.LG); Sound (cs.SD)

</div>
<p class="mathjax">In recent years, research on music transcription has focused mainly on
architecture design and instrument-specific data acquisition. With the lack of
availability of diverse datasets, progress is often limited to solo-instrument
tasks such as piano transcription. Several works have explored multi-instrument
transcription as a means to bolster the performance of models on low-resource
tasks, but these methods face the same data availability issues. We propose
Timbre-Trap, a novel framework which unifies music transcription and audio
reconstruction by exploiting the strong separability between pitch and timbre.
We train a single U-Net to simultaneously estimate pitch salience and
reconstruct complex spectral coefficients, selecting between either output
during the decoding stage via a simple switch mechanism. In this way, the model
learns to produce coefficients corresponding to timbre-less audio, which can be
interpreted as pitch salience. We demonstrate that the framework leads to
performance comparable to state-of-the-art instrument-agnostic transcription
methods, while only requiring a small amount of annotated data.
</p>
</div>
</dd>
<dt><a name="item323">[323]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15747" title="Abstract">arXiv:2309.15747</a> (cross-list from eess.SP) [<a href="/pdf/2309.15747" title="Download PDF">pdf</a>, <a href="/format/2309.15747" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Differentiable Machine Learning-Based Modeling for Directly-Modulated  Lasers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Hernandez%2C+S">Sergio Hernandez</a>, 
<a href="/search/eess?searchtype=author&query=Jovanovic%2C+O">Ognjen Jovanovic</a>, 
<a href="/search/eess?searchtype=author&query=Peucheret%2C+C">Christophe Peucheret</a>, 
<a href="/search/eess?searchtype=author&query=Da+Ros%2C+F">Francesco Da Ros</a>, 
<a href="/search/eess?searchtype=author&query=Zibar%2C+D">Darko Zibar</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to IEEE Photonics Technology Letters on 27/09/2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Information Theory (cs.IT)

</div>
<p class="mathjax">End-to-end learning has become a popular method for joint transmitter and
receiver optimization in optical communication systems. Such approach may
require a differentiable channel model, thus hindering the optimization of
links based on directly modulated lasers (DMLs). This is due to the DML
behavior in the large-signal regime, for which no analytical solution is
available. In this paper, this problem is addressed by developing and comparing
differentiable machine learning-based surrogate models. The models are
quantitatively assessed in terms of root mean square error and training/testing
time. Once the models are trained, the surrogates are then tested in a
numerical equalization setup, resembling a practical end-to-end scenario. Based
on the numerical investigation conducted, the convolutional attention
transformer is shown to outperform the other models considered.
</p>
</div>
</dd>
<dt><a name="item324">[324]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15750" title="Abstract">arXiv:2309.15750</a> (cross-list from eess.IV) [<a href="/pdf/2309.15750" title="Download PDF">pdf</a>, <a href="/format/2309.15750" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Automated CT Lung Cancer Screening Workflow using 3D Camera
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Teixeira%2C+B">Brian Teixeira</a>, 
<a href="/search/eess?searchtype=author&query=Singh%2C+V">Vivek Singh</a>, 
<a href="/search/eess?searchtype=author&query=Tamersoy%2C+B">Birgi Tamersoy</a>, 
<a href="/search/eess?searchtype=author&query=Prokein%2C+A">Andreas Prokein</a>, 
<a href="/search/eess?searchtype=author&query=Kapoor%2C+A">Ankur Kapoor</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at MICCAI 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Despite recent developments in CT planning that enabled automation in patient
positioning, time-consuming scout scans are still needed to compute dose
profile and ensure the patient is properly positioned. In this paper, we
present a novel method which eliminates the need for scout scans in CT lung
cancer screening by estimating patient scan range, isocenter, and Water
Equivalent Diameter (WED) from 3D camera images. We achieve this task by
training an implicit generative model on over 60,000 CT scans and introduce a
novel approach for updating the prediction using real-time scan data. We
demonstrate the effectiveness of our method on a testing set of 110 pairs of
depth data and CT scan, resulting in an average error of 5mm in estimating the
isocenter, 13mm in determining the scan range, 10mm and 16mm in estimating the
AP and lateral WED respectively. The relative WED error of our method is 4%,
which is well within the International Electrotechnical Commission (IEC)
acceptance criteria of 10%.
</p>
</div>
</dd>
<dt><a name="item325">[325]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15769" title="Abstract">arXiv:2309.15769</a> (cross-list from math.ST) [<a href="/pdf/2309.15769" title="Download PDF">pdf</a>, <a href="/format/2309.15769" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Algebraic and Statistical Properties of the Ordinary Least Squares  Interpolator
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Shen%2C+D">Dennis Shen</a>, 
<a href="/search/math?searchtype=author&query=Song%2C+D">Dogyoon Song</a>, 
<a href="/search/math?searchtype=author&query=Ding%2C+P">Peng Ding</a>, 
<a href="/search/math?searchtype=author&query=Sekhon%2C+J+S">Jasjeet S. Sekhon</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 37 pages + supplementary materials (14 pages), 2 tables, 3 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Statistics Theory (math.ST)</span>; Machine Learning (cs.LG); Methodology (stat.ME)

</div>
<p class="mathjax">Deep learning research has uncovered the phenomenon of benign overfitting for
over-parameterized statistical models, which has drawn significant theoretical
interest in recent years. Given its simplicity and practicality, the ordinary
least squares (OLS) interpolator has become essential to gain foundational
insights into this phenomenon. While properties of OLS are well established in
classical settings, its behavior in high-dimensional settings is less explored
(unlike for ridge or lasso regression) though significant progress has been
made of late. We contribute to this growing literature by providing fundamental
algebraic and statistical results for the minimum $\ell_2$-norm OLS
interpolator. In particular, we provide high-dimensional algebraic equivalents
of (i) the leave-$k$-out residual formula, (ii) Cochran's formula, and (iii)
the Frisch-Waugh-Lovell theorem. These results aid in understanding the OLS
interpolator's ability to generalize and have substantive implications for
causal inference. Additionally, under the Gauss-Markov model, we present
statistical results such as a high-dimensional extension of the Gauss-Markov
theorem and an analysis of variance estimation under homoskedastic errors. To
substantiate our theoretical contributions, we conduct simulation studies that
further explore the stochastic properties of the OLS interpolator.
</p>
</div>
</dd>
<dt><a name="item326">[326]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15792" title="Abstract">arXiv:2309.15792</a> (cross-list from quant-ph) [<a href="/pdf/2309.15792" title="Download PDF">pdf</a>, <a href="/format/2309.15792" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Quantum-Classical Hybrid Block-Matching Algorithm in Noisy Environment  using Dissimilarity Measure
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Mart%C3%ADnez-Felipe%2C+M">M. Mart&#xed;nez-Felipe</a>, 
<a href="/search/quant-ph?searchtype=author&query=Montiel-P%C3%A9rez%2C+J">J. Montiel-P&#xe9;rez</a>, 
<a href="/search/quant-ph?searchtype=author&query=Onofre-Gonz%C3%A1lez%2C+V">V. Onofre-Gonz&#xe1;lez</a>, 
<a href="/search/quant-ph?searchtype=author&query=Maldonado-Romo%2C+A">A. Maldonado-Romo</a>, 
<a href="/search/quant-ph?searchtype=author&query=Young%2C+R">Ricky Young</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">A block-matching algorithm finds a group of similar image patches inside a
search area. Similarity/dissimilarity measures can help to solve this problem.
In different practical applications, finding groups of similar image blocks
within an ample search area is often necessary, such as video compression,
image clustering, vector quantization, and nonlocal noise reduction. In this
work, classical image processing is performed using Gaussian noise and image
size reduction with a fit of a Low-Pass Filter or Domain Transform. A
hierarchical search technique is implemented to encode the images by phase
operator. Using phase image coding with the quantum Fourier transform and the
Swap test, we propose a dissimilarity measure. Results were obtained with
perfect and noisy simulations and in the case of the Swap test with the IBM and
Ionq quantum devices.
</p>
</div>
</dd>
<dt><a name="item327">[327]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15793" title="Abstract">arXiv:2309.15793</a> (cross-list from stat.ME) [<a href="/pdf/2309.15793" title="Download PDF">pdf</a>, <a href="/format/2309.15793" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Targeting Relative Risk Heterogeneity with Causal Forests
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Shirvaikar%2C+V">Vik Shirvaikar</a>, 
<a href="/search/stat?searchtype=author&query=Holmes%2C+C">Chris Holmes</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 4 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Methodology (stat.ME)</span>; Machine Learning (cs.LG); Machine Learning (stat.ML)

</div>
<p class="mathjax">Treatment effect heterogeneity (TEH), or variability in treatment effect for
different subgroups within a population, is of significant interest in clinical
trial analysis. Causal forests (Wager and Athey, 2018) is a highly popular
method for this problem, but like many other methods for detecting TEH, its
criterion for separating subgroups focuses on differences in absolute risk.
This can dilute statistical power by masking nuance in the relative risk, which
is often a more appropriate quantity of clinical interest. In this work, we
propose and implement a methodology for modifying causal forests to target
relative risk using a novel node-splitting procedure based on generalized
linear model (GLM) comparison. We present results on simulated and real-world
data that suggest relative risk causal forests can capture otherwise unobserved
sources of heterogeneity.
</p>
</div>
</dd>
<dt><a name="item328">[328]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15796" title="Abstract">arXiv:2309.15796</a> (cross-list from eess.AS) [<a href="/pdf/2309.15796" title="Download PDF">pdf</a>, <a href="/format/2309.15796" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning from Flawed Data: Weakly Supervised Automatic Speech  Recognition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Gao%2C+D">Dongji Gao</a>, 
<a href="/search/eess?searchtype=author&query=Xu%2C+H">Hainan Xu</a>, 
<a href="/search/eess?searchtype=author&query=Raj%2C+D">Desh Raj</a>, 
<a href="/search/eess?searchtype=author&query=Perera%2C+L+P+G">Leibny Paola Garcia Perera</a>, 
<a href="/search/eess?searchtype=author&query=Povey%2C+D">Daniel Povey</a>, 
<a href="/search/eess?searchtype=author&query=Khudanpur%2C+S">Sanjeev Khudanpur</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Computation and Language (cs.CL); Machine Learning (cs.LG)

</div>
<p class="mathjax">Training automatic speech recognition (ASR) systems requires large amounts of
well-curated paired data. However, human annotators usually perform
"non-verbatim" transcription, which can result in poorly trained models. In
this paper, we propose Omni-temporal Classification (OTC), a novel training
criterion that explicitly incorporates label uncertainties originating from
such weak supervision. This allows the model to effectively learn speech-text
alignments while accommodating errors present in the training transcripts. OTC
extends the conventional CTC objective for imperfect transcripts by leveraging
weighted finite state transducers. Through experiments conducted on the
LibriSpeech and LibriVox datasets, we demonstrate that training ASR models with
OTC avoids performance degradation even with transcripts containing up to 70%
errors, a scenario where CTC models fail completely. Our implementation is
available at https://github.com/k2-fsa/icefall.
</p>
</div>
</dd>
<dt><a name="item329">[329]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15816" title="Abstract">arXiv:2309.15816</a> (cross-list from math.RT) [<a href="/pdf/2309.15816" title="Download PDF">pdf</a>, <a href="/ps/2309.15816" title="Download PostScript">ps</a>, <a href="/format/2309.15816" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Orbit closures, stabilizer limits and intermediate $G$-varieties
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Adsul%2C+B">Bharat Adsul</a>, 
<a href="/search/math?searchtype=author&query=Sohoni%2C+M">Milind Sohoni</a>, 
<a href="/search/math?searchtype=author&query=Subrahmanyam%2C+K+V">K V Subrahmanyam</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Representation Theory (math.RT)</span>; Computational Complexity (cs.CC)

</div>
<p class="mathjax">In this paper we study the orbit closure problem for a reductive group
$G\subseteq GL(X)$ acting on a finite dimensional vector space $V$ over
${\mathbb C}$. We assume that the center of $GL(X)$ lies within $G$ and acts on
$V$ through a fixed non-trivial character. We study points $y,z\in V$ where (i)
$z$ is obtained as the leading term of the action of a 1-parameter subgroup
$\lambda (t)\subseteq G$ on $y$, and (ii) $y$ and $z$ have large distinctive
stabilizers $K,H \subseteq G$. Let $O(z)$ (resp. $O(y)$) denote the $G$-orbits
of $z$ (resp. $y$), and $\overline{O(z)}$ (resp. $\overline{O(y)}$) their
closures, then (i) implies that $z\in \overline{O(y)}$. We address the
question: under what conditions can (i) and (ii) be simultaneously satisfied,
i.e, there exists a 1-PS $\lambda \subseteq G$ for which $z$ is observed as a
limit of $y$.
<br />Using $\lambda$, we develop a leading term analysis which applies to $V$ as
well as to ${\cal G}= Lie(G)$ the Lie algebra of $G$ and its subalgebras ${\cal
K}$ and ${\cal H}$, the Lie algebras of $K$ and $H$ respectively. Through this
we construct the Lie algebra $\hat{\cal K} \subseteq {\cal H}$ which connects
$y$ and $z$ through their Lie algebras. We develop the properties of $\hat{\cal
K}$ and relate it to the action of ${\cal H}$ on $\overline{N}=V/T_z O(z)$, the
normal slice to the orbit $O(z)$. Next, we examine the possibility of {\em
intermediate $G$-varieties} $W$ which lie between the orbit closures of $z$ and
$y$, i.e. $\overline{O(z)} \subsetneq W \subsetneq O(y)$. These intermediate
varieties are constructed using the grading obtained from $\lambda $ by its
action on $V$ and ${\cal G}$.
<br />The paper hopes to contribute to the Geometric Complexity Theory approach of
addressing problems in computational complexity in theoretical computer
science.
</p>
</div>
</dd>
<dt><a name="item330">[330]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15828" title="Abstract">arXiv:2309.15828</a> (cross-list from stat.ML) [<a href="/pdf/2309.15828" title="Download PDF">pdf</a>, <a href="/format/2309.15828" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multi-unit soft sensing permits few-shot learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Grimstad%2C+B">Bjarne Grimstad</a>, 
<a href="/search/stat?searchtype=author&query=L%C3%B8vland%2C+K">Kristian L&#xf8;vland</a>, 
<a href="/search/stat?searchtype=author&query=Imsland%2C+L+S">Lars S. Imsland</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 24 pages, 7 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Recent literature has explored various ways to improve soft sensors using
learning algorithms with transferability. Broadly put, the performance of a
soft sensor may be strengthened when it is learned by solving multiple tasks.
The usefulness of transferability depends on how strongly related the devised
learning tasks are. A particularly relevant case for transferability, is when a
soft sensor is to be developed for a process of which there are many
realizations, e.g. system or device with many implementations from which data
is available. Then, each realization presents a soft sensor learning task, and
it is reasonable to expect that the different tasks are strongly related.
Applying transferability in this setting leads to what we call multi-unit soft
sensing, where a soft sensor models a process by learning from data from all of
its realizations.
<br />This paper explores the learning abilities of a multi-unit soft sensor, which
is formulated as a hierarchical model and implemented using a deep neural
network. In particular, we investigate how well the soft sensor generalizes as
the number of units increase. Using a large industrial dataset, we demonstrate
that, when the soft sensor is learned from a sufficient number of tasks, it
permits few-shot learning on data from new units. Surprisingly, regarding the
difficulty of the task, few-shot learning on 1-3 data points often leads to a
high performance on new units.
</p>
</div>
</dd>
</dl>
<h3>Replacements for Thu, 28 Sep 23</h3>
<dl>
<dt><a name="item331">[331]</a>&nbsp;  <span class="list-identifier"><a href="/abs/1910.08222" title="Abstract">arXiv:1910.08222</a> (replaced) [<a href="/pdf/1910.08222" title="Download PDF">pdf</a>, <a href="/format/1910.08222" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Improving the convergence of SGD through adaptive batch sizes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sievert%2C+S">Scott Sievert</a>, 
<a href="/search/cs?searchtype=author&query=Shah%2C+S">Shrey Shah</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Optimization and Control (math.OC); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item332">[332]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2009.08267" title="Abstract">arXiv:2009.08267</a> (replaced) [<a href="/pdf/2009.08267" title="Download PDF">pdf</a>, <a href="/format/2009.08267" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Novel and flexible parameter estimation methods for data-consistent  inversion in mechanistic modeling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Rumbell%2C+T">Timothy Rumbell</a>, 
<a href="/search/stat?searchtype=author&query=Parikh%2C+J">Jaimit Parikh</a>, 
<a href="/search/stat?searchtype=author&query=Kozloski%2C+J">James Kozloski</a>, 
<a href="/search/stat?searchtype=author&query=Gurev%2C+V">Viatcheslav Gurev</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Additional methods, algorithms, and examples
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item333">[333]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2010.09278" title="Abstract">arXiv:2010.09278</a> (replaced) [<a href="/pdf/2010.09278" title="Download PDF">pdf</a>, <a href="/format/2010.09278" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MimicNorm: Weight Mean and Last BN Layer Mimic the Dynamic of Batch  Normalization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fei%2C+W">Wen Fei</a>, 
<a href="/search/cs?searchtype=author&query=Dai%2C+W">Wenrui Dai</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+C">Chenglin Li</a>, 
<a href="/search/cs?searchtype=author&query=Zou%2C+J">Junni Zou</a>, 
<a href="/search/cs?searchtype=author&query=Xiong%2C+H">Hongkai Xiong</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item334">[334]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2012.00738" title="Abstract">arXiv:2012.00738</a> (replaced) [<a href="/pdf/2012.00738" title="Download PDF">pdf</a>, <a href="/format/2012.00738" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Searching, Sorting, and Cake Cutting in Rounds
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Br%C3%A2nzei%2C+S">Simina Br&#xe2;nzei</a>, 
<a href="/search/cs?searchtype=author&query=Paparas%2C+D">Dimitris Paparas</a>, 
<a href="/search/cs?searchtype=author&query=Recker%2C+N">Nicholas Recker</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Major revision with several corrections
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>; Computer Science and Game Theory (cs.GT)

</div>
</div>
</dd>
<dt><a name="item335">[335]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2012.09274" title="Abstract">arXiv:2012.09274</a> (replaced) [<a href="/pdf/2012.09274" title="Download PDF">pdf</a>, <a href="/ps/2012.09274" title="Download PostScript">ps</a>, <a href="/format/2012.09274" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On Exploiting Hitting Sets for Model Reconciliation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Vasileiou%2C+S+L">Stylianos Loukas Vasileiou</a>, 
<a href="/search/cs?searchtype=author&query=Previti%2C+A">Alessandro Previti</a>, 
<a href="/search/cs?searchtype=author&query=Yeoh%2C+W">William Yeoh</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Logic in Computer Science (cs.LO)

</div>
</div>
</dd>
<dt><a name="item336">[336]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2102.12058" title="Abstract">arXiv:2102.12058</a> (replaced) [<a href="/pdf/2102.12058" title="Download PDF">pdf</a>, <a href="/format/2102.12058" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SoK: A Taxonomy for Critical Analysis of Consensus Mechanisms in  Consortium Blockchain
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yao%2C+W">Wei Yao</a>, 
<a href="/search/cs?searchtype=author&query=Deek%2C+F+P">Fadi P.Deek</a>, 
<a href="/search/cs?searchtype=author&query=Murimi%2C+R">Renita Murimi</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+G">Guiling Wang</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> IEEE Access, vol. 11, pp. 79572-79587, 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>; Distributed, Parallel, and Cluster Computing (cs.DC)

</div>
</div>
</dd>
<dt><a name="item337">[337]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2106.03824" title="Abstract">arXiv:2106.03824</a> (replaced) [<a href="/pdf/2106.03824" title="Download PDF">pdf</a>, <a href="/format/2106.03824" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Parallel Batch-Dynamic Algorithms for $k$-Core Decomposition and Related  Graph Problems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+Q+C">Quanquan C. Liu</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+J">Jessica Shi</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+S">Shangdi Yu</a>, 
<a href="/search/cs?searchtype=author&query=Dhulipala%2C+L">Laxman Dhulipala</a>, 
<a href="/search/cs?searchtype=author&query=Shun%2C+J">Julian Shun</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Abstract truncated per arXiv limits; add densest subgraph observation, fix Table 3 typos
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>; Distributed, Parallel, and Cluster Computing (cs.DC)

</div>
</div>
</dd>
<dt><a name="item338">[338]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2108.09483" title="Abstract">arXiv:2108.09483</a> (replaced) [<a href="/pdf/2108.09483" title="Download PDF">pdf</a>, <a href="/format/2108.09483" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> From Tutte to Floater and Gotsman: On the Resolution of Planar  Straight-line Drawings and Morphs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Di+Battista%2C+G">Giuseppe Di Battista</a>, 
<a href="/search/cs?searchtype=author&query=Frati%2C+F">Fabrizio Frati</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Appears in the Proceedings of the 29th International Symposium on Graph Drawing and Network Visualization (GD 2021)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Geometry (cs.CG)</span>; Discrete Mathematics (cs.DM); Data Structures and Algorithms (cs.DS)

</div>
</div>
</dd>
<dt><a name="item339">[339]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2109.10757" title="Abstract">arXiv:2109.10757</a> (replaced) [<a href="/pdf/2109.10757" title="Download PDF">pdf</a>, <a href="/format/2109.10757" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Unsupervised Movement Detection in Indoor Positioning Systems of  Production Halls
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Flossdorf%2C+J">Jonathan Flossdorf</a>, 
<a href="/search/cs?searchtype=author&query=Meyer%2C+A">Anne Meyer</a>, 
<a href="/search/cs?searchtype=author&query=Artjuch%2C+D">Dmitri Artjuch</a>, 
<a href="/search/cs?searchtype=author&query=Schneider%2C+J">Jaques Schneider</a>, 
<a href="/search/cs?searchtype=author&query=Jentsch%2C+C">Carsten Jentsch</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Applications (stat.AP)

</div>
</div>
</dd>
<dt><a name="item340">[340]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2109.11277" title="Abstract">arXiv:2109.11277</a> (replaced) [<a href="/pdf/2109.11277" title="Download PDF">pdf</a>, <a href="/format/2109.11277" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FormatFuzzer: Effective Fuzzing of Binary File Formats
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dutra%2C+R">Rafael Dutra</a>, 
<a href="/search/cs?searchtype=author&query=Gopinath%2C+R">Rahul Gopinath</a>, 
<a href="/search/cs?searchtype=author&query=Zeller%2C+A">Andreas Zeller</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ACM Transactions on Software Engineering and Methodology
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>; Cryptography and Security (cs.CR)

</div>
</div>
</dd>
<dt><a name="item341">[341]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2110.11697" title="Abstract">arXiv:2110.11697</a> (replaced) [<a href="/pdf/2110.11697" title="Download PDF">pdf</a>, <a href="/format/2110.11697" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An Efficient Branch-and-Bound Solver for Hitting Set
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bl%C3%A4sius%2C+T">Thomas Bl&#xe4;sius</a>, 
<a href="/search/cs?searchtype=author&query=Friedrich%2C+T">Tobias Friedrich</a>, 
<a href="/search/cs?searchtype=author&query=Stangl%2C+D">David Stangl</a>, 
<a href="/search/cs?searchtype=author&query=Weyand%2C+C">Christopher Weyand</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>

</div>
</div>
</dd>
<dt><a name="item342">[342]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2110.13774" title="Abstract">arXiv:2110.13774</a> (replaced) [<a href="/pdf/2110.13774" title="Download PDF">pdf</a>, <a href="/format/2110.13774" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Mont Blanc of Twitter: Identifying Hierarchies of Outstanding Peaks  in Social Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Stubbemann%2C+M">Maximilian Stubbemann</a>, 
<a href="/search/cs?searchtype=author&query=Stumme%2C+G">Gerd Stumme</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 15 pages, 3 figures, 2 tables. Accepted to ECML/PKDD 2023. Final version available at <a href="https://link.springer.com/chapter/10.1007/978-3-031-43418-1_11">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>

</div>
</div>
</dd>
<dt><a name="item343">[343]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2111.01919" title="Abstract">arXiv:2111.01919</a> (replaced) [<a href="/pdf/2111.01919" title="Download PDF">pdf</a>, <a href="/format/2111.01919" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Discovering and Exploiting Sparse Rewards in a Learned Behavior Space
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Paolo%2C+G">Giuseppe Paolo</a>, 
<a href="/search/cs?searchtype=author&query=Coninx%2C+M">Miranda Coninx</a>, 
<a href="/search/cs?searchtype=author&query=Laflaqui%C3%A8re%2C+A">Alban Laflaqui&#xe8;re</a>, 
<a href="/search/cs?searchtype=author&query=Doncieux%2C+S">Stephane Doncieux</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 25 pages. Published by the Evolutionary Computation Journal, MIT Press
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Neural and Evolutionary Computing (cs.NE); Robotics (cs.RO)

</div>
</div>
</dd>
<dt><a name="item344">[344]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2112.08626" title="Abstract">arXiv:2112.08626</a> (replaced) [<a href="/pdf/2112.08626" title="Download PDF">pdf</a>, <a href="/format/2112.08626" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Analysis and Evaluation of Kinect-based Action Recognition Algorithms
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+L">Lei Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Master's thesis, 34 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item345">[345]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2202.03356" title="Abstract">arXiv:2202.03356</a> (replaced) [<a href="/pdf/2202.03356" title="Download PDF">pdf</a>, <a href="/format/2202.03356" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Efficient Direct-Connect Topologies for Collective Communications
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhao%2C+L">Liangyu Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Pal%2C+S">Siddharth Pal</a>, 
<a href="/search/cs?searchtype=author&query=Chugh%2C+T">Tapan Chugh</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+W">Weiyang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Fantl%2C+J">Jason Fantl</a>, 
<a href="/search/cs?searchtype=author&query=Basu%2C+P">Prithwish Basu</a>, 
<a href="/search/cs?searchtype=author&query=Khoury%2C+J">Joud Khoury</a>, 
<a href="/search/cs?searchtype=author&query=Krishnamurthy%2C+A">Arvind Krishnamurthy</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>; Distributed, Parallel, and Cluster Computing (cs.DC); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item346">[346]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2203.00111" title="Abstract">arXiv:2203.00111</a> (replaced) [<a href="/pdf/2203.00111" title="Download PDF">pdf</a>, <a href="/format/2203.00111" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Pedagogical Demonstrations and Pragmatic Learning in Artificial  Tutor-Learner Interactions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Caselles-Dupr%C3%A9%2C+H">Hugo Caselles-Dupr&#xe9;</a>, 
<a href="/search/cs?searchtype=author&query=Chetouani%2C+M">Mohamed Chetouani</a>, 
<a href="/search/cs?searchtype=author&query=Sigaud%2C+O">Olivier Sigaud</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to HIRL workshop at HRI 2022
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Human-Computer Interaction (cs.HC)

</div>
</div>
</dd>
<dt><a name="item347">[347]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2203.11375" title="Abstract">arXiv:2203.11375</a> (replaced) [<a href="/pdf/2203.11375" title="Download PDF">pdf</a>, <a href="/format/2203.11375" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Robust Model Predictive Control with Polytopic Model Uncertainty through  System Level Synthesis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Chen%2C+S">Shaoru Chen</a>, 
<a href="/search/eess?searchtype=author&query=Preciado%2C+V+M">Victor M. Preciado</a>, 
<a href="/search/eess?searchtype=author&query=Morari%2C+M">Manfred Morari</a>, 
<a href="/search/eess?searchtype=author&query=Matni%2C+N">Nikolai Matni</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Expanded the conservatism comparison experiments. Under review of Automatica
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Optimization and Control (math.OC)

</div>
</div>
</dd>
<dt><a name="item348">[348]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2204.08570" title="Abstract">arXiv:2204.08570</a> (replaced) [<a href="/pdf/2204.08570" title="Download PDF">pdf</a>, <a href="/format/2204.08570" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Comprehensive Survey on Trustworthy Graph Neural Networks: Privacy,  Robustness, Fairness, and Explainability
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dai%2C+E">Enyan Dai</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+T">Tianxiang Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+H">Huaisheng Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+J">Junjie Xu</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+Z">Zhimeng Guo</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+H">Hui Liu</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+J">Jiliang Tang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Suhang Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Cryptography and Security (cs.CR)

</div>
</div>
</dd>
<dt><a name="item349">[349]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2205.00147" title="Abstract">arXiv:2205.00147</a> (replaced) [<a href="/pdf/2205.00147" title="Download PDF">pdf</a>, <a href="/format/2205.00147" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DIRA: A Framework for Dynamic Domain Incremental Regularised Adaptation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ghobrial%2C+A">Abanoub Ghobrial</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+X">Xuan Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Hond%2C+D">Darryl Hond</a>, 
<a href="/search/cs?searchtype=author&query=Asgari%2C+H">Hamid Asgari</a>, 
<a href="/search/cs?searchtype=author&query=Eder%2C+K">Kerstin Eder</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item350">[350]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2205.14756" title="Abstract">arXiv:2205.14756</a> (replaced) [<a href="/pdf/2205.14756" title="Download PDF">pdf</a>, <a href="/format/2205.14756" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> EfficientViT: Multi-Scale Linear Attention for High-Resolution Dense  Prediction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cai%2C+H">Han Cai</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Junyan Li</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+M">Muyan Hu</a>, 
<a href="/search/cs?searchtype=author&query=Gan%2C+C">Chuang Gan</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+S">Song Han</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ICCV 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item351">[351]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2206.04546" title="Abstract">arXiv:2206.04546</a> (replaced) [<a href="/pdf/2206.04546" title="Download PDF">pdf</a>, <a href="/format/2206.04546" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Pragmatically Learning from Pedagogical Demonstrations in Multi-Goal  Environments
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Caselles-Dupr%C3%A9%2C+H">Hugo Caselles-Dupr&#xe9;</a>, 
<a href="/search/cs?searchtype=author&query=Sigaud%2C+O">Olivier Sigaud</a>, 
<a href="/search/cs?searchtype=author&query=Chetouani%2C+M">Mohamed Chetouani</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> NeurIPS 2022
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item352">[352]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2206.06536" title="Abstract">arXiv:2206.06536</a> (replaced) [<a href="/pdf/2206.06536" title="Download PDF">pdf</a>, <a href="/format/2206.06536" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On Learning the Dynamical Response of Nonlinear Control Systems with  Deep Operator Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Lin%2C+G">Guang Lin</a>, 
<a href="/search/math?searchtype=author&query=Moya%2C+C">Christian Moya</a>, 
<a href="/search/math?searchtype=author&query=Zhang%2C+Z">Zecheng Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Dynamical Systems (math.DS)</span>; Numerical Analysis (math.NA)

</div>
</div>
</dd>
<dt><a name="item353">[353]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2206.11843" title="Abstract">arXiv:2206.11843</a> (replaced) [<a href="/pdf/2206.11843" title="Download PDF">pdf</a>, <a href="/format/2206.11843" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> More Than a Wife and a Mom: A Study of Mom Vlogging Practices in China
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhou%2C+K+Z">Kyrie Zhixuan Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+B">Bohui Shen</a>, 
<a href="/search/cs?searchtype=author&query=Zimmer%2C+F">Franziska Zimmer</a>, 
<a href="/search/cs?searchtype=author&query=Xia%2C+C">Chuanli Xia</a>, 
<a href="/search/cs?searchtype=author&query=Tong%2C+X">Xin Tong</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 26th ACM Conference On Computer-Supported Cooperative Work And Social Computing
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Computers and Society (cs.CY)

</div>
</div>
</dd>
<dt><a name="item354">[354]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2206.15051" title="Abstract">arXiv:2206.15051</a> (replaced) [<a href="/pdf/2206.15051" title="Download PDF">pdf</a>, <a href="/format/2206.15051" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Group-invariant tensor train networks for supervised learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sprangers%2C+B">Brent Sprangers</a>, 
<a href="/search/cs?searchtype=author&query=Vannieuwenhoven%2C+N">Nick Vannieuwenhoven</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 23 pages, 4 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Numerical Analysis (math.NA)

</div>
</div>
</dd>
<dt><a name="item355">[355]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2207.03652" title="Abstract">arXiv:2207.03652</a> (replaced) [<a href="/pdf/2207.03652" title="Download PDF">pdf</a>, <a href="/format/2207.03652" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Private independence testing across two parties
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Vepakomma%2C+P">Praneeth Vepakomma</a>, 
<a href="/search/math?searchtype=author&query=Amiri%2C+M+M">Mohammad Mohammadi Amiri</a>, 
<a href="/search/math?searchtype=author&query=Canonne%2C+C+L">Cl&#xe9;ment L. Canonne</a>, 
<a href="/search/math?searchtype=author&query=Raskar%2C+R">Ramesh Raskar</a>, 
<a href="/search/math?searchtype=author&query=Pentland%2C+A">Alex Pentland</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Statistics Theory (math.ST)</span>; Cryptography and Security (cs.CR); Machine Learning (cs.LG); Methodology (stat.ME)

</div>
</div>
</dd>
<dt><a name="item356">[356]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2207.04569" title="Abstract">arXiv:2207.04569</a> (replaced) [<a href="/pdf/2207.04569" title="Download PDF">pdf</a>, <a href="/format/2207.04569" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FedSS: Federated Learning with Smart Selection of clients
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tahir%2C+A">Ammar Tahir</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yongzhou Chen</a>, 
<a href="/search/cs?searchtype=author&query=Nilayam%2C+P">Prashanti Nilayam</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>; Machine Learning (cs.LG); Networking and Internet Architecture (cs.NI)

</div>
</div>
</dd>
<dt><a name="item357">[357]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2207.04726" title="Abstract">arXiv:2207.04726</a> (replaced) [<a href="/pdf/2207.04726" title="Download PDF">pdf</a>, <a href="/ps/2207.04726" title="Download PostScript">ps</a>, <a href="/format/2207.04726" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the Convergence of the Backward Reachable Sets of Robust Controlled  Invariant Sets For Discrete-time Linear Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Liu%2C+Z">Zexiang Liu</a>, 
<a href="/search/eess?searchtype=author&query=Ozay%2C+N">Necmiye Ozay</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages, presented at CDC 2022
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Optimization and Control (math.OC)

</div>
</div>
</dd>
<dt><a name="item358">[358]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2207.05225" title="Abstract">arXiv:2207.05225</a> (replaced) [<a href="/pdf/2207.05225" title="Download PDF">pdf</a>, <a href="/format/2207.05225" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Susceptibility of Continual Learning Against Adversarial Attacks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Khan%2C+H">Hikmat Khan</a>, 
<a href="/search/cs?searchtype=author&query=Shah%2C+P+M">Pir Masoom Shah</a>, 
<a href="/search/cs?searchtype=author&query=Zaidi%2C+S+F+A">Syed Farhan Alam Zaidi</a>, 
<a href="/search/cs?searchtype=author&query=Islam%2C+S+u">Saif ul Islam</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 18 pages, 13 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item359">[359]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2208.00480" title="Abstract">arXiv:2208.00480</a> (replaced) [<a href="/pdf/2208.00480" title="Download PDF">pdf</a>, <a href="/format/2208.00480" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Quantum networks with coherent routing of information through multiple  nodes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Kristj%C3%A1nsson%2C+H">Hl&#xe9;r Kristj&#xe1;nsson</a>, 
<a href="/search/quant-ph?searchtype=author&query=Zhong%2C+Y">Yan Zhong</a>, 
<a href="/search/quant-ph?searchtype=author&query=Munson%2C+A">Anthony Munson</a>, 
<a href="/search/quant-ph?searchtype=author&query=Chiribella%2C+G">Giulio Chiribella</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages, 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Information Theory (cs.IT)

</div>
</div>
</dd>
<dt><a name="item360">[360]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2208.10733" title="Abstract">arXiv:2208.10733</a> (replaced) [<a href="/pdf/2208.10733" title="Download PDF">pdf</a>, <a href="/format/2208.10733" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Recursively Feasible Probabilistic Safe Online Learning with Control  Barrier Functions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Casta%C3%B1eda%2C+F">Fernando Casta&#xf1;eda</a>, 
<a href="/search/eess?searchtype=author&query=Choi%2C+J+J">Jason J. Choi</a>, 
<a href="/search/eess?searchtype=author&query=Jung%2C+W">Wonsuhk Jung</a>, 
<a href="/search/eess?searchtype=author&query=Zhang%2C+B">Bike Zhang</a>, 
<a href="/search/eess?searchtype=author&query=Tomlin%2C+C+J">Claire J. Tomlin</a>, 
<a href="/search/eess?searchtype=author&query=Sreenath%2C+K">Koushil Sreenath</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Journal article. Includes the results of the 2021 CDC paper titled "Pointwise feasibility of gaussian process-based safety-critical control under model uncertainty" and proposes a recursively feasible safe online learning algorithm as new contribution
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Machine Learning (cs.LG); Optimization and Control (math.OC)

</div>
</div>
</dd>
<dt><a name="item361">[361]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2209.04048" title="Abstract">arXiv:2209.04048</a> (replaced) [<a href="/pdf/2209.04048" title="Download PDF">pdf</a>, <a href="/format/2209.04048" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Studying Drowsiness Detection Performance while Driving through Scalable  Machine Learning Models using Electroencephalography
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Rogel%2C+J+M+H">Jos&#xe9; Manuel Hidalgo Rogel</a>, 
<a href="/search/eess?searchtype=author&query=Beltr%C3%A1n%2C+E+T+M">Enrique Tom&#xe1;s Mart&#xed;nez Beltr&#xe1;n</a>, 
<a href="/search/eess?searchtype=author&query=P%C3%A9rez%2C+M+Q">Mario Quiles P&#xe9;rez</a>, 
<a href="/search/eess?searchtype=author&query=Bernal%2C+S+L">Sergio L&#xf3;pez Bernal</a>, 
<a href="/search/eess?searchtype=author&query=P%C3%A9rez%2C+G+M">Gregorio Mart&#xed;nez P&#xe9;rez</a>, 
<a href="/search/eess?searchtype=author&query=Celdr%C3%A1n%2C+A+H">Alberto Huertas Celdr&#xe1;n</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item362">[362]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2209.05324" title="Abstract">arXiv:2209.05324</a> (replaced) [<a href="/pdf/2209.05324" title="Download PDF">pdf</a>, <a href="/format/2209.05324" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Delving into the Devils of Bird&#x27;s-eye-view Perception: A Review,  Evaluation and Recipe
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Hongyang Li</a>, 
<a href="/search/cs?searchtype=author&query=Sima%2C+C">Chonghao Sima</a>, 
<a href="/search/cs?searchtype=author&query=Dai%2C+J">Jifeng Dai</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+W">Wenhai Wang</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+L">Lewei Lu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Huijie Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zeng%2C+J">Jia Zeng</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zhiqi Li</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+J">Jiazhi Yang</a>, 
<a href="/search/cs?searchtype=author&query=Deng%2C+H">Hanming Deng</a>, 
<a href="/search/cs?searchtype=author&query=Tian%2C+H">Hao Tian</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+E">Enze Xie</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+J">Jiangwei Xie</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+L">Li Chen</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+T">Tianyu Li</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yang Li</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+Y">Yulu Gao</a>, 
<a href="/search/cs?searchtype=author&query=Jia%2C+X">Xiaosong Jia</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+S">Si Liu</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+J">Jianping Shi</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+D">Dahua Lin</a>, 
<a href="/search/cs?searchtype=author&query=Qiao%2C+Y">Yu Qiao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> <a href="https://github.com/OpenDriveLab/Birds-eye-view-Perception">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG); Robotics (cs.RO)

</div>
</div>
</dd>
<dt><a name="item363">[363]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2209.08230" title="Abstract">arXiv:2209.08230</a> (replaced) [<a href="/pdf/2209.08230" title="Download PDF">pdf</a>, <a href="/format/2209.08230" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Robust and Constrained Multi-Agent Reinforcement Learning Electric  Vehicle Rebalancing Method in AMoD Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=He%2C+S">Sihong He</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yue Wang</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+S">Shuo Han</a>, 
<a href="/search/cs?searchtype=author&query=Zou%2C+S">Shaofeng Zou</a>, 
<a href="/search/cs?searchtype=author&query=Miao%2C+F">Fei Miao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, accepted to IROS2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Multiagent Systems (cs.MA)</span>; Machine Learning (cs.LG); Robotics (cs.RO); Systems and Control (eess.SY)

</div>
</div>
</dd>
<dt><a name="item364">[364]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2209.12758" title="Abstract">arXiv:2209.12758</a> (replaced) [<a href="/pdf/2209.12758" title="Download PDF">pdf</a>, <a href="/format/2209.12758" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Overcoming Referential Ambiguity in Language-Guided Goal-Conditioned  Reinforcement Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Caselles-Dupr%C3%A9%2C+H">Hugo Caselles-Dupr&#xe9;</a>, 
<a href="/search/cs?searchtype=author&query=Sigaud%2C+O">Olivier Sigaud</a>, 
<a href="/search/cs?searchtype=author&query=Chetouani%2C+M">Mohamed Chetouani</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> NeurIPS 2022 Workshop
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computation and Language (cs.CL)

</div>
</div>
</dd>
<dt><a name="item365">[365]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2209.14440" title="Abstract">arXiv:2209.14440</a> (replaced) [<a href="/pdf/2209.14440" title="Download PDF">pdf</a>, <a href="/format/2209.14440" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GeONet: a neural operator for learning the Wasserstein geodesic
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gracyk%2C+A">Andrew Gracyk</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+X">Xiaohui Chen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item366">[366]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2210.05129" title="Abstract">arXiv:2210.05129</a> (replaced) [<a href="/pdf/2210.05129" title="Download PDF">pdf</a>, <a href="/format/2210.05129" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multi-Object Navigation with dynamically learned neural implicit  representations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Marza%2C+P">Pierre Marza</a>, 
<a href="/search/cs?searchtype=author&query=Matignon%2C+L">Laetitia Matignon</a>, 
<a href="/search/cs?searchtype=author&query=Simonin%2C+O">Olivier Simonin</a>, 
<a href="/search/cs?searchtype=author&query=Wolf%2C+C">Christian Wolf</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG); Robotics (cs.RO)

</div>
</div>
</dd>
<dt><a name="item367">[367]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2210.05330" title="Abstract">arXiv:2210.05330</a> (replaced) [<a href="/pdf/2210.05330" title="Download PDF">pdf</a>, <a href="/format/2210.05330" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Label Noise-Robust Learning using a Confidence-Based Sieving Strategy
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Torkzadehmahani%2C+R">Reihaneh Torkzadehmahani</a>, 
<a href="/search/cs?searchtype=author&query=Nasirigerdeh%2C+R">Reza Nasirigerdeh</a>, 
<a href="/search/cs?searchtype=author&query=Rueckert%2C+D">Daniel Rueckert</a>, 
<a href="/search/cs?searchtype=author&query=Kaissis%2C+G">Georgios Kaissis</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> <a href="https://openreview.net/forum?id=3taIQG4C7H">this https URL</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Transactions on Machine Learning Research, 2835-8856, 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item368">[368]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2210.13905" title="Abstract">arXiv:2210.13905</a> (replaced) [<a href="/pdf/2210.13905" title="Download PDF">pdf</a>, <a href="/format/2210.13905" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Confidence-Calibrated Face and Kinship Verification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+M">Min Xu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Ximiao Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+X">Xiuzhuang Zhou</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages, 10 figures, and 9 tables
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> IEEE Transactions on Information Forensics and Security
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item369">[369]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2210.16060" title="Abstract">arXiv:2210.16060</a> (replaced) [<a href="/pdf/2210.16060" title="Download PDF">pdf</a>, <a href="/format/2210.16060" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deep network series for large-scale high-dynamic range imaging
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/astro-ph?searchtype=author&query=Aghabiglou%2C+A">Amir Aghabiglou</a>, 
<a href="/search/astro-ph?searchtype=author&query=Terris%2C+M">Matthieu Terris</a>, 
<a href="/search/astro-ph?searchtype=author&query=Jackson%2C+A">Adrian Jackson</a>, 
<a href="/search/astro-ph?searchtype=author&query=Wiaux%2C+Y">Yves Wiaux</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted for publication in IEEE Proc. ICASSP 2023
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> IEEE Proc. ICASSP 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Instrumentation and Methods for Astrophysics (astro-ph.IM)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item370">[370]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2211.01022" title="Abstract">arXiv:2211.01022</a> (replaced) [<a href="/pdf/2211.01022" title="Download PDF">pdf</a>, <a href="/ps/2211.01022" title="Download PostScript">ps</a>, <a href="/format/2211.01022" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Verifying And Interpreting Neural Networks using Finite Automata
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=S%C3%A4lzer%2C+M">Marco S&#xe4;lzer</a>, 
<a href="/search/cs?searchtype=author&query=Alsmann%2C+E">Eric Alsmann</a>, 
<a href="/search/cs?searchtype=author&query=Bruse%2C+F">Florian Bruse</a>, 
<a href="/search/cs?searchtype=author&query=Lange%2C+M">Martin Lange</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Formal Languages and Automata Theory (cs.FL)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item371">[371]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2211.01299" title="Abstract">arXiv:2211.01299</a> (replaced) [<a href="/pdf/2211.01299" title="Download PDF">pdf</a>, <a href="/format/2211.01299" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Late Audio-Visual Fusion for In-The-Wild Speaker Diarization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Pan%2C+Z">Zexu Pan</a>, 
<a href="/search/eess?searchtype=author&query=Wichern%2C+G">Gordon Wichern</a>, 
<a href="/search/eess?searchtype=author&query=Germain%2C+F+G">Fran&#xe7;ois G. Germain</a>, 
<a href="/search/eess?searchtype=author&query=Subramanian%2C+A">Aswin Subramanian</a>, 
<a href="/search/eess?searchtype=author&query=Roux%2C+J+L">Jonathan Le Roux</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Computation and Language (cs.CL); Sound (cs.SD)

</div>
</div>
</dd>
<dt><a name="item372">[372]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2211.04655" title="Abstract">arXiv:2211.04655</a> (replaced) [<a href="/pdf/2211.04655" title="Download PDF">pdf</a>, <a href="/ps/2211.04655" title="Download PostScript">ps</a>, <a href="/format/2211.04655" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Variants of SGD for Lipschitz Continuous Loss Functions in Low-Precision  Environments
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Metel%2C+M+R">Michael R. Metel</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item373">[373]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2211.09166" title="Abstract">arXiv:2211.09166</a> (replaced) [<a href="/pdf/2211.09166" title="Download PDF">pdf</a>, <a href="/format/2211.09166" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Two-Stage Deep Representation Learning-Based Speech Enhancement Method  Using Variational Autoencoder and Adversarial Training
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Xiang%2C+Y">Yang Xiang</a>, 
<a href="/search/eess?searchtype=author&query=H%C3%B8jvang%2C+J+L">Jesper Lisby H&#xf8;jvang</a>, 
<a href="/search/eess?searchtype=author&query=Rasmussen%2C+M+H">Morten H&#xf8;jfeldt Rasmussen</a>, 
<a href="/search/eess?searchtype=author&query=Christensen%2C+M+G">Mads Gr&#xe6;sb&#xf8;ll Christensen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by IEEE/ACM Transactions on Audio, Speech and Language Processing
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Sound (cs.SD)

</div>
</div>
</dd>
<dt><a name="item374">[374]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2211.12814" title="Abstract">arXiv:2211.12814</a> (replaced) [<a href="/pdf/2211.12814" title="Download PDF">pdf</a>, <a href="/format/2211.12814" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Vertical Federated Learning: Concepts, Advances and Challenges
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Kang%2C+Y">Yan Kang</a>, 
<a href="/search/cs?searchtype=author&query=Zou%2C+T">Tianyuan Zou</a>, 
<a href="/search/cs?searchtype=author&query=Pu%2C+Y">Yanhong Pu</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+Y">Yuanqin He</a>, 
<a href="/search/cs?searchtype=author&query=Ye%2C+X">Xiaozhou Ye</a>, 
<a href="/search/cs?searchtype=author&query=Ouyang%2C+Y">Ye Ouyang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Ya-Qin Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Q">Qiang Yang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> We added new works and revised the manuscript
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Cryptography and Security (cs.CR); Distributed, Parallel, and Cluster Computing (cs.DC)

</div>
</div>
</dd>
<dt><a name="item375">[375]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2211.12883" title="Abstract">arXiv:2211.12883</a> (replaced) [<a href="/pdf/2211.12883" title="Download PDF">pdf</a>, <a href="/format/2211.12883" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Mitigating and Evaluating Static Bias of Action Representations in the  Background and the Foreground
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Haoxin Li</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yuan Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Hanwang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+B">Boyang Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item376">[376]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2211.14045" title="Abstract">arXiv:2211.14045</a> (replaced) [<a href="/pdf/2211.14045" title="Download PDF">pdf</a>, <a href="/format/2211.14045" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Configurable Protocol for Quantum Entanglement Distribution to End  Nodes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bacciottini%2C+L">Leonardo Bacciottini</a>, 
<a href="/search/cs?searchtype=author&query=Lenzini%2C+L">Luciano Lenzini</a>, 
<a href="/search/cs?searchtype=author&query=Mingozzi%2C+E">Enzo Mingozzi</a>, 
<a href="/search/cs?searchtype=author&query=Anastasi%2C+G">Giuseppe Anastasi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages, 6 figures, accepted for publication at IEEE ICC 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>

</div>
</div>
</dd>
<dt><a name="item377">[377]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2211.15593" title="Abstract">arXiv:2211.15593</a> (replaced) [<a href="/pdf/2211.15593" title="Download PDF">pdf</a>, <a href="/format/2211.15593" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GPT-Neo for commonsense reasoning -- a theoretical and practical lens
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kashyap%2C+R">Rohan Kashyap</a>, 
<a href="/search/cs?searchtype=author&query=Kashyap%2C+V">Vivek Kashyap</a>, 
<a href="/search/cs?searchtype=author&query=P.%2C+N+C">Narendra C.P.</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item378">[378]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2211.15596" title="Abstract">arXiv:2211.15596</a> (replaced) [<a href="/pdf/2211.15596" title="Download PDF">pdf</a>, <a href="/format/2211.15596" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A survey of deep learning optimizers -- first and second order methods
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kashyap%2C+R">Rohan Kashyap</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV); Optimization and Control (math.OC)

</div>
</div>
</dd>
<dt><a name="item379">[379]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2212.01331" title="Abstract">arXiv:2212.01331</a> (replaced) [<a href="/pdf/2212.01331" title="Download PDF">pdf</a>, <a href="/format/2212.01331" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Surface Normal Clustering for Implicit Representation of Manhattan  Scenes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Popovic%2C+N">Nikola Popovic</a>, 
<a href="/search/cs?searchtype=author&query=Paudel%2C+D+P">Danda Pani Paudel</a>, 
<a href="/search/cs?searchtype=author&query=Van+Gool%2C+L">Luc Van Gool</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Paper accepted to ICCV23
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item380">[380]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2212.02469" title="Abstract">arXiv:2212.02469</a> (replaced) [<a href="/pdf/2212.02469" title="Download PDF">pdf</a>, <a href="/format/2212.02469" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> One-shot Implicit Animatable Avatars with Model-based Priors
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+Y">Yangyi Huang</a>, 
<a href="/search/cs?searchtype=author&query=Yi%2C+H">Hongwei Yi</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+W">Weiyang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Haofan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+B">Boxi Wu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+W">Wenxiao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+B">Binbin Lin</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+D">Debing Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Cai%2C+D">Deng Cai</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To appear at ICCV 2023. Project website: <a href="https://huangyangyi.github.io/ELICIT/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Graphics (cs.GR)

</div>
</div>
</dd>
<dt><a name="item381">[381]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2212.03068" title="Abstract">arXiv:2212.03068</a> (replaced) [<a href="/pdf/2212.03068" title="Download PDF">pdf</a>, <a href="/format/2212.03068" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Active Classification of Moving Targets with Learned Control Policies
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Serra-G%C3%B3mez%2C+%C3%81">&#xc1;lvaro Serra-G&#xf3;mez</a>, 
<a href="/search/cs?searchtype=author&query=Montijano%2C+E">Eduardo Montijano</a>, 
<a href="/search/cs?searchtype=author&query=B%C3%B6hmer%2C+W">Wendelin B&#xf6;hmer</a>, 
<a href="/search/cs?searchtype=author&query=Alonso-Mora%2C+J">Javier Alonso-Mora</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 6 figures, Accepted in IEEE RA-L
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item382">[382]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2212.09102" title="Abstract">arXiv:2212.09102</a> (replaced) [<a href="/pdf/2212.09102" title="Download PDF">pdf</a>, <a href="/format/2212.09102" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Face Generation and Editing with StyleGAN: A Survey
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Melnik%2C+A">Andrew Melnik</a>, 
<a href="/search/cs?searchtype=author&query=Miasayedzenkau%2C+M">Maksim Miasayedzenkau</a>, 
<a href="/search/cs?searchtype=author&query=Makarovets%2C+D">Dzianis Makarovets</a>, 
<a href="/search/cs?searchtype=author&query=Pirshtuk%2C+D">Dzianis Pirshtuk</a>, 
<a href="/search/cs?searchtype=author&query=Akbulut%2C+E">Eren Akbulut</a>, 
<a href="/search/cs?searchtype=author&query=Holzmann%2C+D">Dennis Holzmann</a>, 
<a href="/search/cs?searchtype=author&query=Renusch%2C+T">Tarek Renusch</a>, 
<a href="/search/cs?searchtype=author&query=Reichert%2C+G">Gustav Reichert</a>, 
<a href="/search/cs?searchtype=author&query=Ritter%2C+H">Helge Ritter</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item383">[383]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2212.10729" title="Abstract">arXiv:2212.10729</a> (replaced) [<a href="/pdf/2212.10729" title="Download PDF">pdf</a>, <a href="/format/2212.10729" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> UnICLAM:Contrastive Representation Learning with Adversarial Masking for  Unified and Interpretable Medical Vision Question Answering
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhan%2C+C">Chenlu Zhan</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+P">Peng Peng</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Hongsen Wang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+T">Tao Chen</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Hongwei Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item384">[384]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2212.12395" title="Abstract">arXiv:2212.12395</a> (replaced) [<a href="/pdf/2212.12395" title="Download PDF">pdf</a>, <a href="/format/2212.12395" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Detecting Objects with Context-Likelihood Graphs and Graph Refinement
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bhowmik%2C+A">Aritra Bhowmik</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yu Wang</a>, 
<a href="/search/cs?searchtype=author&query=Baka%2C+N">Nora Baka</a>, 
<a href="/search/cs?searchtype=author&query=Oswald%2C+M+R">Martin R. Oswald</a>, 
<a href="/search/cs?searchtype=author&query=Snoek%2C+C+G+M">Cees G. M. Snoek</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, 8 figures. In Proceedings of International Conference on Computer Vision (ICCV) 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item385">[385]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2212.13089" title="Abstract">arXiv:2212.13089</a> (replaced) [<a href="/pdf/2212.13089" title="Download PDF">pdf</a>, <a href="/format/2212.13089" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> New protocols for quantum key distribution with explicit upper and lower  bound on secret-key rate
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Dutta%2C+A">Arindam Dutta</a>, 
<a href="/search/quant-ph?searchtype=author&query=Pathak%2C+A">Anirban Pathak</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Two practical protocols for quantum key distribution (QKD) are proposed and rigorously analyzed for bounds on the key rates
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Cryptography and Security (cs.CR)

</div>
</div>
</dd>
<dt><a name="item386">[386]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2212.13563" title="Abstract">arXiv:2212.13563</a> (replaced) [<a href="/pdf/2212.13563" title="Download PDF">pdf</a>, <a href="/format/2212.13563" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Noise-aware Learning from Web-crawled Image-Text Data for Image  Captioning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kang%2C+W">Wooyoung Kang</a>, 
<a href="/search/cs?searchtype=author&query=Mun%2C+J">Jonghwan Mun</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+S">Sungjun Lee</a>, 
<a href="/search/cs?searchtype=author&query=Roh%2C+B">Byungseok Roh</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item387">[387]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.00957" title="Abstract">arXiv:2301.00957</a> (replaced) [<a href="/pdf/2301.00957" title="Download PDF">pdf</a>, <a href="/format/2301.00957" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Metalearning generalizable dynamics from trajectories
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+Q">Qiaofeng Li</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+T">Tianyi Wang</a>, 
<a href="/search/cs?searchtype=author&query=Roychowdhury%2C+V">Vwani Roychowdhury</a>, 
<a href="/search/cs?searchtype=author&query=Jawed%2C+M+K">M. Khalid Jawed</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computational Physics (physics.comp-ph)

</div>
</div>
</dd>
<dt><a name="item388">[388]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.02083" title="Abstract">arXiv:2301.02083</a> (replaced) [<a href="/pdf/2301.02083" title="Download PDF">pdf</a>, <a href="/format/2301.02083" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Self-Motivated Multi-Agent Exploration
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+S">Shaowei Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+J">Jiahan Cao</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+L">Lei Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+Y">Yang Yu</a>, 
<a href="/search/cs?searchtype=author&query=Zhan%2C+D">De-Chuan Zhan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Multiagent Systems (cs.MA)

</div>
</div>
</dd>
<dt><a name="item389">[389]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.10617" title="Abstract">arXiv:2301.10617</a> (replaced) [<a href="/pdf/2301.10617" title="Download PDF">pdf</a>, <a href="/ps/2301.10617" title="Download PostScript">ps</a>, <a href="/format/2301.10617" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Extended Nullstellensatz proof systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Krajicek%2C+J">Jan Krajicek</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Preliminary version January 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic (math.LO)</span>; Computational Complexity (cs.CC)

</div>
</div>
</dd>
<dt><a name="item390">[390]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.00533" title="Abstract">arXiv:2302.00533</a> (replaced) [<a href="/pdf/2302.00533" title="Download PDF">pdf</a>, <a href="/format/2302.00533" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Distillation Policy Optimization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ma%2C+J">Jianfei Ma</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item391">[391]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.01177" title="Abstract">arXiv:2302.01177</a> (replaced) [<a href="/pdf/2302.01177" title="Download PDF">pdf</a>, <a href="/format/2302.01177" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Order but Not Execute in Order
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gong%2C+T">Tiantian Gong</a>, 
<a href="/search/cs?searchtype=author&query=Kate%2C+A">Aniket Kate</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages, 31 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Computer Science and Game Theory (cs.GT)

</div>
</div>
</dd>
<dt><a name="item392">[392]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.02033" title="Abstract">arXiv:2302.02033</a> (replaced) [<a href="/pdf/2302.02033" title="Download PDF">pdf</a>, <a href="/format/2302.02033" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An Asymptotically Optimal Algorithm for the Convex Hull Membership  Problem
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Qiao%2C+G">Gang Qiao</a>, 
<a href="/search/stat?searchtype=author&query=Tewari%2C+A">Ambuj Tewari</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item393">[393]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.09880" title="Abstract">arXiv:2302.09880</a> (replaced) [<a href="/pdf/2302.09880" title="Download PDF">pdf</a>, <a href="/format/2302.09880" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Unbounded Machine Unlearning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kurmanji%2C+M">Meghdad Kurmanji</a>, 
<a href="/search/cs?searchtype=author&query=Triantafillou%2C+P">Peter Triantafillou</a>, 
<a href="/search/cs?searchtype=author&query=Hayes%2C+J">Jamie Hayes</a>, 
<a href="/search/cs?searchtype=author&query=Triantafillou%2C+E">Eleni Triantafillou</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Cryptography and Security (cs.CR)

</div>
</div>
</dd>
<dt><a name="item394">[394]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.10719" title="Abstract">arXiv:2302.10719</a> (replaced) [<a href="/pdf/2302.10719" title="Download PDF">pdf</a>, <a href="/format/2302.10719" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Memory-augmented Online Video Anomaly Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rossi%2C+L">Leonardo Rossi</a>, 
<a href="/search/cs?searchtype=author&query=Bernuzzi%2C+V">Vittorio Bernuzzi</a>, 
<a href="/search/cs?searchtype=author&query=Fontanini%2C+T">Tomaso Fontanini</a>, 
<a href="/search/cs?searchtype=author&query=Bertozzi%2C+M">Massimo Bertozzi</a>, 
<a href="/search/cs?searchtype=author&query=Prati%2C+A">Andrea Prati</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item395">[395]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.12867" title="Abstract">arXiv:2302.12867</a> (replaced) [<a href="/pdf/2302.12867" title="Download PDF">pdf</a>, <a href="/ps/2302.12867" title="Download PostScript">ps</a>, <a href="/format/2302.12867" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On homomorphic encryption using abelian groups: Classical security  analysis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Agathocleous%2C+E">Eleni Agathocleous</a>, 
<a href="/search/cs?searchtype=author&query=Anupindi%2C+V">Vishnupriya Anupindi</a>, 
<a href="/search/cs?searchtype=author&query=Bachmayr%2C+A">Annette Bachmayr</a>, 
<a href="/search/cs?searchtype=author&query=Martindale%2C+C">Chloe Martindale</a>, 
<a href="/search/cs?searchtype=author&query=Nchiwo%2C+R+Y+N">Rahinatou Yuh Njah Nchiwo</a>, 
<a href="/search/cs?searchtype=author&query=Stanojkovski%2C+M">Mima Stanojkovski</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 20 pages, changes in compliance with the referees' suggestions, to appear in the Springer AWM volume "Women in Numbers Europe 4 - Research Directions in Number Theory"
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
</div>
</dd>
<dt><a name="item396">[396]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.14160" title="Abstract">arXiv:2302.14160</a> (replaced) [<a href="/pdf/2302.14160" title="Download PDF">pdf</a>, <a href="/format/2302.14160" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Renaissance canons with asymmetric schemes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=O%27Dorney%2C+E+M">Evan M. O&#x27;Dorney</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 27 pages, including 17 figures and 3 tables. Revised and amplified to reflect comments made by the reviewers
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Number Theory (math.NT)</span>; Sound (cs.SD); Audio and Speech Processing (eess.AS); Combinatorics (math.CO)

</div>
</div>
</dd>
<dt><a name="item397">[397]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.14450" title="Abstract">arXiv:2302.14450</a> (replaced) [<a href="/pdf/2302.14450" title="Download PDF">pdf</a>, <a href="/format/2302.14450" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Swin Deformable Attention Hybrid U-Net for Medical Image Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Wang%2C+L">Lichao Wang</a>, 
<a href="/search/eess?searchtype=author&query=Huang%2C+J">Jiahao Huang</a>, 
<a href="/search/eess?searchtype=author&query=Xing%2C+X">Xiaodan Xing</a>, 
<a href="/search/eess?searchtype=author&query=Yang%2C+G">Guang Yang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 5 figures, accepted by SIPAIM2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item398">[398]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.00387" title="Abstract">arXiv:2303.00387</a> (replaced) [<a href="/pdf/2303.00387" title="Download PDF">pdf</a>, <a href="/format/2303.00387" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DOLOS: A Novel Architecture for Moving Target Defense
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pagnotta%2C+G">Giulio Pagnotta</a>, 
<a href="/search/cs?searchtype=author&query=De+Gaspari%2C+F">Fabio De Gaspari</a>, 
<a href="/search/cs?searchtype=author&query=Hitaj%2C+D">Dorjan Hitaj</a>, 
<a href="/search/cs?searchtype=author&query=Andreolini%2C+M">Mauro Andreolini</a>, 
<a href="/search/cs?searchtype=author&query=Colajanni%2C+M">Michele Colajanni</a>, 
<a href="/search/cs?searchtype=author&query=Mancini%2C+L+V">Luigi V. Mancini</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 pages
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> IEEE Transactions on Information Forensics and Security, 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Computers and Society (cs.CY)

</div>
</div>
</dd>
<dt><a name="item399">[399]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.01139" title="Abstract">arXiv:2303.01139</a> (replaced) [<a href="/pdf/2303.01139" title="Download PDF">pdf</a>, <a href="/format/2303.01139" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> RTIndeX: Exploiting Hardware-Accelerated GPU Raytracing for Database  Indexing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Henneberg%2C+J">Justus Henneberg</a>, 
<a href="/search/cs?searchtype=author&query=Schuhknecht%2C+F">Felix Schuhknecht</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Databases (cs.DB)</span>; Graphics (cs.GR)

</div>
</div>
</dd>
<dt><a name="item400">[400]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.03533" title="Abstract">arXiv:2303.03533</a> (replaced) [<a href="/pdf/2303.03533" title="Download PDF">pdf</a>, <a href="/format/2303.03533" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Dexterous In-hand Manipulation by Guiding Exploration with Simple  Sub-skill Controllers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Khandate%2C+G">Gagan Khandate</a>, 
<a href="/search/cs?searchtype=author&query=Mehlman%2C+C">Cameron Mehlman</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+X">Xingsheng Wei</a>, 
<a href="/search/cs?searchtype=author&query=Ciocarlie%2C+M">Matei Ciocarlie</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages, 7 figures, submitted to International Conference on Robotics and Automation 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI); Systems and Control (eess.SY)

</div>
</div>
</dd>
<dt><a name="item401">[401]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.05214" title="Abstract">arXiv:2303.05214</a> (replaced) [<a href="/pdf/2303.05214" title="Download PDF">pdf</a>, <a href="/format/2303.05214" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Taming Contrast Maximization for Learning Sequential, Low-latency,  Event-based Optical Flow
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Paredes-Vall%C3%A9s%2C+F">Federico Paredes-Vall&#xe9;s</a>, 
<a href="/search/cs?searchtype=author&query=Scheper%2C+K+Y+W">Kirk Y. W. Scheper</a>, 
<a href="/search/cs?searchtype=author&query=De+Wagter%2C+C">Christophe De Wagter</a>, 
<a href="/search/cs?searchtype=author&query=de+Croon%2C+G+C+H+E">Guido C. H. E. de Croon</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ICCV 2023. 15 pages, 12 figures, 7 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item402">[402]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.06389" title="Abstract">arXiv:2303.06389</a> (replaced) [<a href="/pdf/2303.06389" title="Download PDF">pdf</a>, <a href="/format/2303.06389" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Uncertainty-Aware Instance Reweighting for Off-Policy Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xiaoying Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Junpu Chen</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Hongning Wang</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+H">Hong Xie</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Lui%2C+J+C+S">John C.S. Lui</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Hang Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item403">[403]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.08690" title="Abstract">arXiv:2303.08690</a> (replaced) [<a href="/pdf/2303.08690" title="Download PDF">pdf</a>, <a href="/format/2303.08690" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Replay Buffer with Local Forgetting for Adapting to Local Environment  Changes in Deep Model-Based Reinforcement Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rahimi-Kalahroudi%2C+A">Ali Rahimi-Kalahroudi</a>, 
<a href="/search/cs?searchtype=author&query=Rajendran%2C+J">Janarthanan Rajendran</a>, 
<a href="/search/cs?searchtype=author&query=Momennejad%2C+I">Ida Momennejad</a>, 
<a href="/search/cs?searchtype=author&query=van+Seijen%2C+H">Harm van Seijen</a>, 
<a href="/search/cs?searchtype=author&query=Chandar%2C+S">Sarath Chandar</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item404">[404]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.08692" title="Abstract">arXiv:2303.08692</a> (replaced) [<a href="/pdf/2303.08692" title="Download PDF">pdf</a>, <a href="/format/2303.08692" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SpiderMesh: Spatial-aware Demand-guided Recursive Meshing for RGB-T  Semantic Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fan%2C+S">Siqi Fan</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zhe Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jingjing Liu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item405">[405]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.10510" title="Abstract">arXiv:2303.10510</a> (replaced) [<a href="/pdf/2303.10510" title="Download PDF">pdf</a>, <a href="/format/2303.10510" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Deep Learning System for Domain-specific Speech Recognition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jia%2C+Y">Yanan Jia</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 4th International Conference on Natural Language Processing and Computational Linguistics (NLPCL 2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Machine Learning (cs.LG); Sound (cs.SD); Audio and Speech Processing (eess.AS)

</div>
</div>
</dd>
<dt><a name="item406">[406]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.12057" title="Abstract">arXiv:2303.12057</a> (replaced) [<a href="/pdf/2303.12057" title="Download PDF">pdf</a>, <a href="/format/2303.12057" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Large Language Models Can Be Used to Estimate the Latent Positions of  Politicians
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+P+Y">Patrick Y. Wu</a>, 
<a href="/search/cs?searchtype=author&query=Nagler%2C+J">Jonathan Nagler</a>, 
<a href="/search/cs?searchtype=author&query=Tucker%2C+J+A">Joshua A. Tucker</a>, 
<a href="/search/cs?searchtype=author&query=Messing%2C+S">Solomon Messing</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 18 pages, 4 figures; V2: fixed graphical error on Figure 2; V3: reorganized sections, updated prose; V4: added additional scales and analysis
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>; Computation and Language (cs.CL)

</div>
</div>
</dd>
<dt><a name="item407">[407]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.12981" title="Abstract">arXiv:2303.12981</a> (replaced) [<a href="/pdf/2303.12981" title="Download PDF">pdf</a>, <a href="/format/2303.12981" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Connected Superlevel Set in (Deep) Reinforcement Learning and its  Application to Minimax Theorems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zeng%2C+S">Sihan Zeng</a>, 
<a href="/search/cs?searchtype=author&query=Doan%2C+T+T">Thinh T. Doan</a>, 
<a href="/search/cs?searchtype=author&query=Romberg%2C+J">Justin Romberg</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Optimization and Control (math.OC)

</div>
</div>
</dd>
<dt><a name="item408">[408]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.13873" title="Abstract">arXiv:2303.13873</a> (replaced) [<a href="/pdf/2303.13873" title="Download PDF">pdf</a>, <a href="/format/2303.13873" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fantasia3D: Disentangling Geometry and Appearance for High-quality  Text-to-3D Content Creation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+R">Rui Chen</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yongwei Chen</a>, 
<a href="/search/cs?searchtype=author&query=Jiao%2C+N">Ningxin Jiao</a>, 
<a href="/search/cs?searchtype=author&query=Jia%2C+K">Kui Jia</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by ICCV 2023. Project page: <a href="https://fantasia3d.github.io/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item409">[409]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.15119" title="Abstract">arXiv:2303.15119</a> (replaced) [<a href="/pdf/2303.15119" title="Download PDF">pdf</a>, <a href="/format/2303.15119" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PoPeC: PAoI-Centric Task Offloading with Priority over Unreliable  Channels
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Qiao%2C+N">Nan Qiao</a>, 
<a href="/search/cs?searchtype=author&query=Yue%2C+S">Sheng Yue</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yongmin Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Ren%2C+J">Ju Ren</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>

</div>
</div>
</dd>
<dt><a name="item410">[410]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.15343" title="Abstract">arXiv:2303.15343</a> (replaced) [<a href="/pdf/2303.15343" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Sigmoid Loss for Language Image Pre-Training
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhai%2C+X">Xiaohua Zhai</a>, 
<a href="/search/cs?searchtype=author&query=Mustafa%2C+B">Basil Mustafa</a>, 
<a href="/search/cs?searchtype=author&query=Kolesnikov%2C+A">Alexander Kolesnikov</a>, 
<a href="/search/cs?searchtype=author&query=Beyer%2C+L">Lucas Beyer</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ICCV'23 Oral. arXiv v2: fix typo in pseudocode; v3: clarify t vs t' init; v4: add SigLIP Base, Large, Shape-Optimized 400M results. Models released at: <a href="https://github.com/google-research/big_vision.">this https URL</a> Xiaohua and Lucas contributed equally
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item411">[411]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.15451" title="Abstract">arXiv:2303.15451</a> (replaced) [<a href="/pdf/2303.15451" title="Download PDF">pdf</a>, <a href="/format/2303.15451" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Automated tuning for the parameters of linear solvers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Petrushov%2C+A">Andrey Petrushov</a>, 
<a href="/search/math?searchtype=author&query=Krasnopolsky%2C+B">Boris Krasnopolsky</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Distributed, Parallel, and Cluster Computing (cs.DC)

</div>
</div>
</dd>
<dt><a name="item412">[412]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.15954" title="Abstract">arXiv:2303.15954</a> (replaced) [<a href="/pdf/2303.15954" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> TraffNet: Learning Causality of Traffic Generation for Road Network  Digital Twins
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+M">Ming Xu</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+Y">Yunyi Ma</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+R">Ruimin Li</a>, 
<a href="/search/cs?searchtype=author&query=Qi%2C+G">Geqi Qi</a>, 
<a href="/search/cs?searchtype=author&query=Meng%2C+X">Xiangfu Meng</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+H">Haibo Jin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item413">[413]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.00790" title="Abstract">arXiv:2304.00790</a> (replaced) [<a href="/pdf/2304.00790" title="Download PDF">pdf</a>, <a href="/format/2304.00790" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LQR-CBF-RRT*: Safe and Optimal Motion Planning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+G">Guang Yang</a>, 
<a href="/search/cs?searchtype=author&query=Cai%2C+M">Mingyu Cai</a>, 
<a href="/search/cs?searchtype=author&query=Ahmad%2C+A">Ahmad Ahmad</a>, 
<a href="/search/cs?searchtype=author&query=Prorok%2C+A">Amanda Prorok</a>, 
<a href="/search/cs?searchtype=author&query=Tron%2C+R">Roberto Tron</a>, 
<a href="/search/cs?searchtype=author&query=Belta%2C+C">Calin Belta</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Systems and Control (eess.SY)

</div>
</div>
</dd>
<dt><a name="item414">[414]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.02008" title="Abstract">arXiv:2304.02008</a> (replaced) [<a href="/pdf/2304.02008" title="Download PDF">pdf</a>, <a href="/format/2304.02008" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GlueStick: Robust Image Matching by Sticking Points and Lines Together
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pautrat%2C+R">R&#xe9;mi Pautrat</a>, 
<a href="/search/cs?searchtype=author&query=Su%C3%A1rez%2C+I">Iago Su&#xe1;rez</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+Y">Yifan Yu</a>, 
<a href="/search/cs?searchtype=author&query=Pollefeys%2C+M">Marc Pollefeys</a>, 
<a href="/search/cs?searchtype=author&query=Larsson%2C+V">Viktor Larsson</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at ICCV 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item415">[415]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.05874" title="Abstract">arXiv:2304.05874</a> (replaced) [<a href="/pdf/2304.05874" title="Download PDF">pdf</a>, <a href="/format/2304.05874" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Adaptive Gated Graph Convolutional Network for Explainable Diagnosis of  Alzheimer&#x27;s Disease using EEG Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-bio?searchtype=author&query=Klepl%2C+D">Dominik Klepl</a>, 
<a href="/search/q-bio?searchtype=author&query=He%2C+F">Fei He</a>, 
<a href="/search/q-bio?searchtype=author&query=Wu%2C+M">Min Wu</a>, 
<a href="/search/q-bio?searchtype=author&query=Blackburn%2C+D+J">Daniel J. Blackburn</a>, 
<a href="/search/q-bio?searchtype=author&query=Sarrigiannis%2C+P+G">Ptolemaios G. Sarrigiannis</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 pages, 16 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neurons and Cognition (q-bio.NC)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Neural and Evolutionary Computing (cs.NE); Signal Processing (eess.SP); Quantitative Methods (q-bio.QM)

</div>
</div>
</dd>
<dt><a name="item416">[416]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.05979" title="Abstract">arXiv:2304.05979</a> (replaced) [<a href="/pdf/2304.05979" title="Download PDF">pdf</a>, <a href="/format/2304.05979" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> NaviSTAR: Socially Aware Robot Navigation with Hybrid Spatio-Temporal  Graph Transformer and Preference Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+W">Weizheng Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+R">Ruiqi Wang</a>, 
<a href="/search/cs?searchtype=author&query=Mao%2C+L">Le Mao</a>, 
<a href="/search/cs?searchtype=author&query=Min%2C+B">Byung-Cheol Min</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To appear in IROS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
</div>
</dd>
<dt><a name="item417">[417]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.08332" title="Abstract">arXiv:2304.08332</a> (replaced) [<a href="/pdf/2304.08332" title="Download PDF">pdf</a>, <a href="/format/2304.08332" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multiscale hierarchical decomposition methods for ill-posed problems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Kindermann%2C+S">Stefan Kindermann</a>, 
<a href="/search/math?searchtype=author&query=Resmerita%2C+E">Elena Resmerita</a>, 
<a href="/search/math?searchtype=author&query=Wolf%2C+T">Tobias Wolf</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
</div>
</dd>
<dt><a name="item418">[418]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.08429" title="Abstract">arXiv:2304.08429</a> (replaced) [<a href="/e-print/2304.08429" title="Download source">src</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Security and Privacy Issues for Urban Smart Traffic Infrastructure
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Baksi%2C+A">Anubhab Baksi</a>, 
<a href="/search/cs?searchtype=author&query=Khalil%2C+A+I+S">Ahmed Ibrahim Samir Khalil</a>, 
<a href="/search/cs?searchtype=author&query=Chattopadhyay%2C+A">Anupam Chattopadhyay</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> The study is partly outdated
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
</div>
</dd>
<dt><a name="item419">[419]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.09123" title="Abstract">arXiv:2304.09123</a> (replaced) [<a href="/pdf/2304.09123" title="Download PDF">pdf</a>, <a href="/format/2304.09123" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Finite-Sample Bounds for Adaptive Inverse Reinforcement Learning using  Passive Langevin Dynamics
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Snow%2C+L">Luke Snow</a>, 
<a href="/search/cs?searchtype=author&query=Krishnamurthy%2C+V">Vikram Krishnamurthy</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item420">[420]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.09734" title="Abstract">arXiv:2304.09734</a> (replaced) [<a href="/pdf/2304.09734" title="Download PDF">pdf</a>, <a href="/format/2304.09734" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Differentiable Task Assignment and Motion Planning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Envall%2C+J">Jimmy Envall</a>, 
<a href="/search/cs?searchtype=author&query=Poranne%2C+R">Roi Poranne</a>, 
<a href="/search/cs?searchtype=author&query=Coros%2C+S">Stelian Coros</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to the 2023 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
</div>
</dd>
<dt><a name="item421">[421]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.10630" title="Abstract">arXiv:2304.10630</a> (replaced) [<a href="/pdf/2304.10630" title="Download PDF">pdf</a>, <a href="/format/2304.10630" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Ellipsoid fitting with the Cayley transform
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Melikechi%2C+O">Omar Melikechi</a>, 
<a href="/search/stat?searchtype=author&query=Dunson%2C+D+B">David B. Dunson</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG); Applications (stat.AP)

</div>
</div>
</dd>
<dt><a name="item422">[422]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.11477" title="Abstract">arXiv:2304.11477</a> (replaced) [<a href="/pdf/2304.11477" title="Download PDF">pdf</a>, <a href="/format/2304.11477" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LLM+P: Empowering Large Language Models with Optimal Planning  Proficiency
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+B">Bo Liu</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+Y">Yuqian Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xiaohan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Q">Qiang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+S">Shiqi Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Biswas%2C+J">Joydeep Biswas</a>, 
<a href="/search/cs?searchtype=author&query=Stone%2C+P">Peter Stone</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Robotics (cs.RO)

</div>
</div>
</dd>
<dt><a name="item423">[423]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.11625" title="Abstract">arXiv:2304.11625</a> (replaced) [<a href="/pdf/2304.11625" title="Download PDF">pdf</a>, <a href="/ps/2304.11625" title="Download PostScript">ps</a>, <a href="/format/2304.11625" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Meaningful Causal Aggregation and Paradoxical Confounding
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhu%2C+Y">Yuchen Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Budhathoki%2C+K">Kailash Budhathoki</a>, 
<a href="/search/cs?searchtype=author&query=Kuebler%2C+J">Jonas Kuebler</a>, 
<a href="/search/cs?searchtype=author&query=Janzing%2C+D">Dominik Janzing</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item424">[424]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.12534" title="Abstract">arXiv:2304.12534</a> (replaced) [<a href="/pdf/2304.12534" title="Download PDF">pdf</a>, <a href="/format/2304.12534" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Mobilizing Personalized Federated Learning in Infrastructure-Less and  Heterogeneous Environments via Random Walk Stochastic ADMM
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Parsons%2C+Z">Ziba Parsons</a>, 
<a href="/search/cs?searchtype=author&query=Dou%2C+F">Fei Dou</a>, 
<a href="/search/cs?searchtype=author&query=Du%2C+H">Houyi Du</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+Z">Zheng Song</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+J">Jin Lu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 28 pages, 7 figures, 3 tables, 1 algorithm. Proof details are provided in the main body of the paper
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Distributed, Parallel, and Cluster Computing (cs.DC); Optimization and Control (math.OC)

</div>
</div>
</dd>
<dt><a name="item425">[425]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.13615" title="Abstract">arXiv:2304.13615</a> (replaced) [<a href="/pdf/2304.13615" title="Download PDF">pdf</a>, <a href="/format/2304.13615" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Domain Adaptive and Generalizable Network Architectures and Training  Strategies for Semantic Image Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hoyer%2C+L">Lukas Hoyer</a>, 
<a href="/search/cs?searchtype=author&query=Dai%2C+D">Dengxin Dai</a>, 
<a href="/search/cs?searchtype=author&query=Van+Gool%2C+L">Luc Van Gool</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> TPAMI 2023. arXiv admin note: text overlap with <a href="/abs/2111.14887">arXiv:2111.14887</a>, <a href="/abs/2204.13132">arXiv:2204.13132</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item426">[426]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.14880" title="Abstract">arXiv:2304.14880</a> (replaced) [<a href="/pdf/2304.14880" title="Download PDF">pdf</a>, <a href="/format/2304.14880" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SGAligner : 3D Scene Alignment with Scene Graphs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sarkar%2C+S+D">Sayan Deb Sarkar</a>, 
<a href="/search/cs?searchtype=author&query=Miksik%2C+O">Ondrej Miksik</a>, 
<a href="/search/cs?searchtype=author&query=Pollefeys%2C+M">Marc Pollefeys</a>, 
<a href="/search/cs?searchtype=author&query=Barath%2C+D">Daniel Barath</a>, 
<a href="/search/cs?searchtype=author&query=Armeni%2C+I">Iro Armeni</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at ICCV 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item427">[427]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.14884" title="Abstract">arXiv:2304.14884</a> (replaced) [<a href="/pdf/2304.14884" title="Download PDF">pdf</a>, <a href="/format/2304.14884" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A registration method for reduced basis problems using linear optimal  transport
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Blickhan%2C+T">Tobias Blickhan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to the SIAM Journal on Scientific Computing
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
</div>
</dd>
<dt><a name="item428">[428]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.00485" title="Abstract">arXiv:2305.00485</a> (replaced) [<a href="/pdf/2305.00485" title="Download PDF">pdf</a>, <a href="/format/2305.00485" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Representing the Special Linear Group with Block Unitriangular Matrices
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Urschel%2C+J">John Urschel</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
</div>
</dd>
<dt><a name="item429">[429]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.00584" title="Abstract">arXiv:2305.00584</a> (replaced) [<a href="/pdf/2305.00584" title="Download PDF">pdf</a>, <a href="/format/2305.00584" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MAMBO-V: Dynamic Side-Channel Leakage Analysis on RISC-V
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wichelmann%2C+J">Jan Wichelmann</a>, 
<a href="/search/cs?searchtype=author&query=Peredy%2C+C">Christopher Peredy</a>, 
<a href="/search/cs?searchtype=author&query=Sieck%2C+F">Florian Sieck</a>, 
<a href="/search/cs?searchtype=author&query=P%C3%A4tschke%2C+A">Anna P&#xe4;tschke</a>, 
<a href="/search/cs?searchtype=author&query=Eisenbarth%2C+T">Thomas Eisenbarth</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 20 pages
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Detection of Intrusions and Malware, and Vulnerability Assessment-
  20th International Conference, DIMVA 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
</div>
</dd>
<dt><a name="item430">[430]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.02263" title="Abstract">arXiv:2305.02263</a> (replaced) [<a href="/pdf/2305.02263" title="Download PDF">pdf</a>, <a href="/format/2305.02263" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Triangle Counting with Local Edge Differential Privacy
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Eden%2C+T">Talya Eden</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Q+C">Quanquan C. Liu</a>, 
<a href="/search/cs?searchtype=author&query=Raskhodnikova%2C+S">Sofya Raskhodnikova</a>, 
<a href="/search/cs?searchtype=author&query=Smith%2C+A">Adam Smith</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ICALP 2023; update reference
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>; Cryptography and Security (cs.CR)

</div>
</div>
</dd>
<dt><a name="item431">[431]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.08074" title="Abstract">arXiv:2305.08074</a> (replaced) [<a href="/pdf/2305.08074" title="Download PDF">pdf</a>, <a href="/format/2305.08074" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Orthogonal polynomial approximation and Extended Dynamic Mode  Decomposition in chaos
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Wormell%2C+C+L">Caroline L. Wormell</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Classical Analysis and ODEs (math.CA); Dynamical Systems (math.DS); Chaotic Dynamics (nlin.CD); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item432">[432]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.10223" title="Abstract">arXiv:2305.10223</a> (replaced) [<a href="/pdf/2305.10223" title="Download PDF">pdf</a>, <a href="/format/2305.10223" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> NAI$_2$: Learning Noise-Aware Illuminance-Interpolator for Unsupervised  Low-Light Image Enhancement
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xiaofeng Liu</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+J">Jiaxin Gao</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+R">Risheng Liu</a>, 
<a href="/search/cs?searchtype=author&query=Fan%2C+X">Xin Fan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Low-light, iuminance learning, noise removal, low-level vision
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Multimedia (cs.MM)

</div>
</div>
</dd>
<dt><a name="item433">[433]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.10924" title="Abstract">arXiv:2305.10924</a> (replaced) [<a href="/pdf/2305.10924" title="Download PDF">pdf</a>, <a href="/format/2305.10924" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Structural Pruning for Diffusion Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fang%2C+G">Gongfan Fang</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+X">Xinyin Ma</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xinchao Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Preprint version
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item434">[434]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.12333" title="Abstract">arXiv:2305.12333</a> (replaced) [<a href="/pdf/2305.12333" title="Download PDF">pdf</a>, <a href="/format/2305.12333" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GRACE++: Loss-Resilient Real-Time Video through Neural Codecs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cheng%2C+Y">Yihua Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Ziyi Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Hanchen Li</a>, 
<a href="/search/cs?searchtype=author&query=Arapin%2C+A">Anton Arapin</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yue Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Q">Qizheng Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yuhan Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xu Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+F">Francis Yan</a>, 
<a href="/search/cs?searchtype=author&query=Mazumdar%2C+A">Amrita Mazumdar</a>, 
<a href="/search/cs?searchtype=author&query=Feamster%2C+N">Nick Feamster</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+J">Junchen Jiang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Multimedia (cs.MM)</span>; Artificial Intelligence (cs.AI); Networking and Internet Architecture (cs.NI)

</div>
</div>
</dd>
<dt><a name="item435">[435]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.13901" title="Abstract">arXiv:2305.13901</a> (replaced) [<a href="/pdf/2305.13901" title="Download PDF">pdf</a>, <a href="/format/2305.13901" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> WinDB: HMD-free and Distortion-free Panoptic Video Fixation Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+G">Guotao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+C">Chenglizhao Chen</a>, 
<a href="/search/cs?searchtype=author&query=Hao%2C+A">Aimin Hao</a>, 
<a href="/search/cs?searchtype=author&query=Qin%2C+H">Hong Qin</a>, 
<a href="/search/cs?searchtype=author&query=Fan%2C+D">Deng-Ping Fan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item436">[436]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.14683" title="Abstract">arXiv:2305.14683</a> (replaced) [<a href="/pdf/2305.14683" title="Download PDF">pdf</a>, <a href="/format/2305.14683" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On progressive sharpening, flat minima and generalisation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=MacDonald%2C+L+E">Lachlan Ewen MacDonald</a>, 
<a href="/search/cs?searchtype=author&query=Valmadre%2C+J">Jack Valmadre</a>, 
<a href="/search/cs?searchtype=author&query=Lucey%2C+S">Simon Lucey</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item437">[437]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.15240" title="Abstract">arXiv:2305.15240</a> (replaced) [<a href="/pdf/2305.15240" title="Download PDF">pdf</a>, <a href="/format/2305.15240" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Localizing Multiple Radiation Sources Actively with a Particle Filter
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lazna%2C+T">Tomas Lazna</a>, 
<a href="/search/cs?searchtype=author&query=Zalud%2C+L">Ludek Zalud</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 2 tables, 3 figures; submitted to Nuclear Engineering and Technology
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
</div>
</dd>
<dt><a name="item438">[438]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.15261" title="Abstract">arXiv:2305.15261</a> (replaced) [<a href="/pdf/2305.15261" title="Download PDF">pdf</a>, <a href="/ps/2305.15261" title="Download PostScript">ps</a>, <a href="/format/2305.15261" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Random periodic sampling patterns for shift-invariant spaces
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Antezana%2C+J">Jorge Antezana</a>, 
<a href="/search/math?searchtype=author&query=Carbajal%2C+D">Diana Carbajal</a>, 
<a href="/search/math?searchtype=author&query=Romero%2C+J+L">Jos&#xe9; Luis Romero</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Functional Analysis (math.FA)</span>; Information Theory (cs.IT); Classical Analysis and ODEs (math.CA)

</div>
</div>
</dd>
<dt><a name="item439">[439]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.16460" title="Abstract">arXiv:2305.16460</a> (replaced) [<a href="/pdf/2305.16460" title="Download PDF">pdf</a>, <a href="/format/2305.16460" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Optimized Custom Dataset for Efficient Detection of Underwater Trash
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Walia%2C+J+S">Jaskaran Singh Walia</a>, 
<a href="/search/cs?searchtype=author&query=Seemakurthy%2C+K">Karthik Seemakurthy</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Presented the paper in University of Cambridge under TAROS 2023
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> In Towards Autonomous Robotic Systems(2023) Springer Nature
  Switzerland; pages=292--303
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Robotics (cs.RO)

</div>
</div>
</dd>
<dt><a name="item440">[440]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.18370" title="Abstract">arXiv:2305.18370</a> (replaced) [<a href="/pdf/2305.18370" title="Download PDF">pdf</a>, <a href="/format/2305.18370" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Explainable Brain Age Prediction using coVariance Neural Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-bio?searchtype=author&query=Sihag%2C+S">Saurabh Sihag</a>, 
<a href="/search/q-bio?searchtype=author&query=Mateos%2C+G">Gonzalo Mateos</a>, 
<a href="/search/q-bio?searchtype=author&query=McMillan%2C+C+T">Corey T. McMillan</a>, 
<a href="/search/q-bio?searchtype=author&query=Ribeiro%2C+A">Alejandro Ribeiro</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Paper accepted at NeurIPS 2023. arXiv admin note: substantial text overlap with <a href="/abs/2305.01807">arXiv:2305.01807</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantitative Methods (q-bio.QM)</span>; Machine Learning (cs.LG); Applications (stat.AP)

</div>
</div>
</dd>
<dt><a name="item441">[441]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.18974" title="Abstract">arXiv:2305.18974</a> (replaced) [<a href="/pdf/2305.18974" title="Download PDF">pdf</a>, <a href="/format/2305.18974" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Asymptotic Characterisation of Robust Empirical Risk Minimisation  Performance in the Presence of Outliers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Vilucchio%2C+M">Matteo Vilucchio</a>, 
<a href="/search/stat?searchtype=author&query=Troiani%2C+E">Emanuele Troiani</a>, 
<a href="/search/stat?searchtype=author&query=Erba%2C+V">Vittorio Erba</a>, 
<a href="/search/stat?searchtype=author&query=Krzakala%2C+F">Florent Krzakala</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item442">[442]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.00851" title="Abstract">arXiv:2306.00851</a> (replaced) [<a href="/pdf/2306.00851" title="Download PDF">pdf</a>, <a href="/format/2306.00851" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning Sampling Dictionaries for Efficient and Generalizable Robot  Motion Planning with Transformers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Johnson%2C+J+J">Jacob J Johnson</a>, 
<a href="/search/cs?searchtype=author&query=Qureshi%2C+A+H">Ahmed H Qureshi</a>, 
<a href="/search/cs?searchtype=author&query=Yip%2C+M">Michael Yip</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item443">[443]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.03253" title="Abstract">arXiv:2306.03253</a> (replaced) [<a href="/pdf/2306.03253" title="Download PDF">pdf</a>, <a href="/format/2306.03253" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Zero-Shot 3D Shape Correspondence
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Abdelreheem%2C+A">Ahmed Abdelreheem</a>, 
<a href="/search/cs?searchtype=author&query=Eldesokey%2C+A">Abdelrahman Eldesokey</a>, 
<a href="/search/cs?searchtype=author&query=Ovsjanikov%2C+M">Maks Ovsjanikov</a>, 
<a href="/search/cs?searchtype=author&query=Wonka%2C+P">Peter Wonka</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project webpage: <a href="https://samir55.github.io/3dshapematch/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item444">[444]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.03572" title="Abstract">arXiv:2306.03572</a> (replaced) [<a href="/pdf/2306.03572" title="Download PDF">pdf</a>, <a href="/format/2306.03572" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Range-Restricted Interpolation through Clausal Tableaux
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wernhard%2C+C">Christoph Wernhard</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Extended version of the TABLEAUX 2023 contribution; minor corrections
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>; Artificial Intelligence (cs.AI); Databases (cs.DB)

</div>
</div>
</dd>
<dt><a name="item445">[445]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.05288" title="Abstract">arXiv:2306.05288</a> (replaced) [<a href="/pdf/2306.05288" title="Download PDF">pdf</a>, <a href="/format/2306.05288" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Design and analysis of an exactly divergence-free hybridized  discontinuous Galerkin method for incompressible flows on meshes with  quadrilateral cells
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Dean%2C+J+P">Joseph P. Dean</a>, 
<a href="/search/math?searchtype=author&query=Rhebergen%2C+S">Sander Rhebergen</a>, 
<a href="/search/math?searchtype=author&query=Wells%2C+G+N">Garth N. Wells</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Computational Engineering, Finance, and Science (cs.CE)

</div>
</div>
</dd>
<dt><a name="item446">[446]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.06531" title="Abstract">arXiv:2306.06531</a> (replaced) [<a href="/pdf/2306.06531" title="Download PDF">pdf</a>, <a href="/format/2306.06531" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AutoTAMP: Autoregressive Task and Motion Planning with LLMs as  Translators and Checkers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yongchao Chen</a>, 
<a href="/search/cs?searchtype=author&query=Arkin%2C+J">Jacob Arkin</a>, 
<a href="/search/cs?searchtype=author&query=Dawson%2C+C">Charles Dawson</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Roy%2C+N">Nicholas Roy</a>, 
<a href="/search/cs?searchtype=author&query=Fan%2C+C">Chuchu Fan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 4 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Computation and Language (cs.CL); Human-Computer Interaction (cs.HC)

</div>
</div>
</dd>
<dt><a name="item447">[447]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.08480" title="Abstract">arXiv:2306.08480</a> (replaced) [<a href="/pdf/2306.08480" title="Download PDF">pdf</a>, <a href="/format/2306.08480" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Combining piano performance dimensions for score difficulty  classification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ramoneda%2C+P">Pedro Ramoneda</a>, 
<a href="/search/cs?searchtype=author&query=Jeong%2C+D">Dasaem Jeong</a>, 
<a href="/search/cs?searchtype=author&query=Eremenko%2C+V">Vsevolod Eremenko</a>, 
<a href="/search/cs?searchtype=author&query=Tamer%2C+N+C">Nazif Can Tamer</a>, 
<a href="/search/cs?searchtype=author&query=Miron%2C+M">Marius Miron</a>, 
<a href="/search/cs?searchtype=author&query=Serra%2C+X">Xavier Serra</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 36 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Audio and Speech Processing (eess.AS)

</div>
</div>
</dd>
<dt><a name="item448">[448]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.09610" title="Abstract">arXiv:2306.09610</a> (replaced) [<a href="/pdf/2306.09610" title="Download PDF">pdf</a>, <a href="/format/2306.09610" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CHORUS: Foundation Models for Unified Data Discovery and Exploration
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kayali%2C+M">Moe Kayali</a>, 
<a href="/search/cs?searchtype=author&query=Lykov%2C+A">Anton Lykov</a>, 
<a href="/search/cs?searchtype=author&query=Fountalis%2C+I">Ilias Fountalis</a>, 
<a href="/search/cs?searchtype=author&query=Vasiloglou%2C+N">Nikolaos Vasiloglou</a>, 
<a href="/search/cs?searchtype=author&query=Olteanu%2C+D">Dan Olteanu</a>, 
<a href="/search/cs?searchtype=author&query=Suciu%2C+D">Dan Suciu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Databases (cs.DB)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item449">[449]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.10376" title="Abstract">arXiv:2306.10376</a> (replaced) [<a href="/pdf/2306.10376" title="Download PDF">pdf</a>, <a href="/format/2306.10376" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CLARA: Classifying and Disambiguating User Commands for Reliable  Interactive Robotic Agents
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Park%2C+J">Jeongeun Park</a>, 
<a href="/search/cs?searchtype=author&query=Lim%2C+S">Seungwon Lim</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+J">Joonhyung Lee</a>, 
<a href="/search/cs?searchtype=author&query=Park%2C+S">Sangbeom Park</a>, 
<a href="/search/cs?searchtype=author&query=Chang%2C+M">Minsuk Chang</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+Y">Youngjae Yu</a>, 
<a href="/search/cs?searchtype=author&query=Choi%2C+S">Sungjoon Choi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project Page: <a href="https://clararobot.github.io/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item450">[450]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.11112" title="Abstract">arXiv:2306.11112</a> (replaced) [<a href="/pdf/2306.11112" title="Download PDF">pdf</a>, <a href="/ps/2306.11112" title="Download PostScript">ps</a>, <a href="/format/2306.11112" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Correcting Underrepresentation and Intersectional Bias for Fair  Classification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tolbert%2C+A+W">Alexander Williams Tolbert</a>, 
<a href="/search/cs?searchtype=author&query=Diana%2C+E">Emily Diana</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computers and Society (cs.CY); Data Structures and Algorithms (cs.DS); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item451">[451]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.13840" title="Abstract">arXiv:2306.13840</a> (replaced) [<a href="/pdf/2306.13840" title="Download PDF">pdf</a>, <a href="/format/2306.13840" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Beyond Scale: the Diversity Coefficient as a Data Quality Metric  Demonstrates LLMs are Pre-trained on Formally Diverse Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lee%2C+A">Alycia Lee</a>, 
<a href="/search/cs?searchtype=author&query=Miranda%2C+B">Brando Miranda</a>, 
<a href="/search/cs?searchtype=author&query=Sundar%2C+S">Sudharsan Sundar</a>, 
<a href="/search/cs?searchtype=author&query=Koyejo%2C+S">Sanmi Koyejo</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Proceedings of the 40th International Conference on Machine
  Learning DMLR 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Neural and Evolutionary Computing (cs.NE)

</div>
</div>
</dd>
<dt><a name="item452">[452]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.15620" title="Abstract">arXiv:2306.15620</a> (replaced) [<a href="/pdf/2306.15620" title="Download PDF">pdf</a>, <a href="/format/2306.15620" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SCENEREPLICA: Benchmarking Real-World Robot Manipulation by Creating  Replicable Scenes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Khargonkar%2C+N">Ninad Khargonkar</a>, 
<a href="/search/cs?searchtype=author&query=Allu%2C+S+H">Sai Haneesh Allu</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+Y">Yangxiao Lu</a>, 
<a href="/search/cs?searchtype=author&query=P%2C+J+J">Jishnu Jaykumar P</a>, 
<a href="/search/cs?searchtype=author&query=Prabhakaran%2C+B">Balakrishnan Prabhakaran</a>, 
<a href="/search/cs?searchtype=author&query=Xiang%2C+Y">Yu Xiang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project page is available at <a href="https://irvlutd.github.io/SceneReplica">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item453">[453]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.00071" title="Abstract">arXiv:2307.00071</a> (replaced) [<a href="/pdf/2307.00071" title="Download PDF">pdf</a>, <a href="/format/2307.00071" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GIRA: Gaussian Mixture Models for Inference and Robot Autonomy
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Goel%2C+K">Kshitij Goel</a>, 
<a href="/search/cs?searchtype=author&query=Tabib%2C+W">Wennie Tabib</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, 7 figures, under review for 2023 IEEE International Conference on Robotics and Automation (ICRA)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
</div>
</dd>
<dt><a name="item454">[454]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.00481" title="Abstract">arXiv:2307.00481</a> (replaced) [<a href="/pdf/2307.00481" title="Download PDF">pdf</a>, <a href="/format/2307.00481" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Seeing is not Believing: An Identity Hider for Human Vision Privacy  Protection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+T">Tao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yushu Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Z">Zixuan Yang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Hua Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Hua%2C+Z">Zhongyun Hua</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item455">[455]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.00972" title="Abstract">arXiv:2307.00972</a> (replaced) [<a href="/pdf/2307.00972" title="Download PDF">pdf</a>, <a href="/format/2307.00972" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MoVie: Visual Model-Based Policy Adaptation for View Generalization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+S">Sizhe Yang</a>, 
<a href="/search/cs?searchtype=author&query=Ze%2C+Y">Yanjie Ze</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+H">Huazhe Xu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted in NeurIPS 2023. The first two authors contribute equally
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV); Robotics (cs.RO)

</div>
</div>
</dd>
<dt><a name="item456">[456]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.02623" title="Abstract">arXiv:2307.02623</a> (replaced) [<a href="/pdf/2307.02623" title="Download PDF">pdf</a>, <a href="/format/2307.02623" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FLuID: Mitigating Stragglers in Federated Learning using Invariant  Dropout
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+I">Irene Wang</a>, 
<a href="/search/cs?searchtype=author&query=Nair%2C+P+J">Prashant J. Nair</a>, 
<a href="/search/cs?searchtype=author&query=Mahajan%2C+D">Divya Mahajan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at the 37th Conference on Neural Information Processing Systems (NeurIPS), 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Distributed, Parallel, and Cluster Computing (cs.DC)

</div>
</div>
</dd>
<dt><a name="item457">[457]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.03167" title="Abstract">arXiv:2307.03167</a> (replaced) [<a href="/pdf/2307.03167" title="Download PDF">pdf</a>, <a href="/format/2307.03167" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Risk-Averse Trajectory Optimization via Sample Average Approximation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lew%2C+T">Thomas Lew</a>, 
<a href="/search/cs?searchtype=author&query=Bonalli%2C+R">Riccardo Bonalli</a>, 
<a href="/search/cs?searchtype=author&query=Pavone%2C+M">Marco Pavone</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Added numerical comparisons
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Systems and Control (eess.SY); Optimization and Control (math.OC)

</div>
</div>
</dd>
<dt><a name="item458">[458]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.07683" title="Abstract">arXiv:2307.07683</a> (replaced) [<a href="/pdf/2307.07683" title="Download PDF">pdf</a>, <a href="/format/2307.07683" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Single and Multi-Speaker Cloned Voice Detection: From Perceptual to  Learned Features
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Barrington%2C+S">Sarah Barrington</a>, 
<a href="/search/cs?searchtype=author&query=Barua%2C+R">Romit Barua</a>, 
<a href="/search/cs?searchtype=author&query=Koorma%2C+G">Gautham Koorma</a>, 
<a href="/search/cs?searchtype=author&query=Farid%2C+H">Hany Farid</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> S. Barrington, R. Barua, G. Koorma, and Hany Farid. Single and Multi-Speaker Cloned Voice Detection: From Perceptual to Learned Features. Workshop on Image Forensics and Security, Nuremberg, Germany, 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Computation and Language (cs.CL); Audio and Speech Processing (eess.AS)

</div>
</div>
</dd>
<dt><a name="item459">[459]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.07935" title="Abstract">arXiv:2307.07935</a> (replaced) [<a href="/pdf/2307.07935" title="Download PDF">pdf</a>, <a href="/format/2307.07935" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> S2R-ViT for Multi-Agent Cooperative Perception: Bridging the Gap from  Simulation to Reality
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jinlong Li</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+R">Runsheng Xu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xinyu Liu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+B">Baolu Li</a>, 
<a href="/search/cs?searchtype=author&query=Zou%2C+Q">Qin Zou</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+J">Jiaqi Ma</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+H">Hongkai Yu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> submit the latest one
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item460">[460]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.09283" title="Abstract">arXiv:2307.09283</a> (replaced) [<a href="/pdf/2307.09283" title="Download PDF">pdf</a>, <a href="/format/2307.09283" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> RepViT: Revisiting Mobile CNN From ViT Perspective
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+A">Ao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+H">Hui Chen</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+Z">Zijia Lin</a>, 
<a href="/search/cs?searchtype=author&query=Pu%2C+H">Hengjun Pu</a>, 
<a href="/search/cs?searchtype=author&query=Ding%2C+G">Guiguang Ding</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages, 7 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item461">[461]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.09330" title="Abstract">arXiv:2307.09330</a> (replaced) [<a href="/pdf/2307.09330" title="Download PDF">pdf</a>, <a href="/format/2307.09330" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Visual Validation versus Visual Estimation: A Study on the Average Value  in Scatterplots
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Braun%2C+D">Daniel Braun</a>, 
<a href="/search/cs?searchtype=author&query=Suh%2C+A">Ashley Suh</a>, 
<a href="/search/cs?searchtype=author&query=Chang%2C+R">Remco Chang</a>, 
<a href="/search/cs?searchtype=author&query=Gleicher%2C+M">Michael Gleicher</a>, 
<a href="/search/cs?searchtype=author&query=von+Landesberger%2C+T">Tatiana von Landesberger</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Preprint and Author Version of a Short Paper, accepted to the 2023 IEEE Visualization Conference (VIS)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Graphics (cs.GR)

</div>
</div>
</dd>
<dt><a name="item462">[462]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.09497" title="Abstract">arXiv:2307.09497</a> (replaced) [<a href="/pdf/2307.09497" title="Download PDF">pdf</a>, <a href="/format/2307.09497" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards a geometry for syntax
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sterling%2C+J">Jonathan Sterling</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Minor revisions, fixing typographical errors; added more historical discussion of Zermelo's, Grothendieck's, and Martin-L\"of's universes
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>; Category Theory (math.CT)

</div>
</div>
</dd>
<dt><a name="item463">[463]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.09662" title="Abstract">arXiv:2307.09662</a> (replaced) [<a href="/pdf/2307.09662" title="Download PDF">pdf</a>, <a href="/format/2307.09662" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Object-aware Gaze Target Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tonini%2C+F">Francesco Tonini</a>, 
<a href="/search/cs?searchtype=author&query=Dall%27Asen%2C+N">Nicola Dall&#x27;Asen</a>, 
<a href="/search/cs?searchtype=author&query=Beyan%2C+C">Cigdem Beyan</a>, 
<a href="/search/cs?searchtype=author&query=Ricci%2C+E">Elisa Ricci</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to ICCV 2023. Code is available at <a href="https://github.com/francescotonini/object-aware-gaze-target-detection">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item464">[464]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.10947" title="Abstract">arXiv:2307.10947</a> (replaced) [<a href="/pdf/2307.10947" title="Download PDF">pdf</a>, <a href="/format/2307.10947" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Improving Online Lane Graph Extraction by Object-Lane Clustering
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Can%2C+Y+B">Yigit Baran Can</a>, 
<a href="/search/cs?searchtype=author&query=Liniger%2C+A">Alexander Liniger</a>, 
<a href="/search/cs?searchtype=author&query=Paudel%2C+D+P">Danda Pani Paudel</a>, 
<a href="/search/cs?searchtype=author&query=Van+Gool%2C+L">Luc Van Gool</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ICCV 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item465">[465]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.12577" title="Abstract">arXiv:2307.12577</a> (replaced) [<a href="/pdf/2307.12577" title="Download PDF">pdf</a>, <a href="/format/2307.12577" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PRIOR: Prototype Representation Joint Learning from Medical Images and  Reports
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cheng%2C+P">Pujin Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+L">Li Lin</a>, 
<a href="/search/cs?searchtype=author&query=Lyu%2C+J">Junyan Lyu</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+Y">Yijin Huang</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+W">Wenhan Luo</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+X">Xiaoying Tang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by ICCV 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item466">[466]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.13929" title="Abstract">arXiv:2307.13929</a> (replaced) [<a href="/pdf/2307.13929" title="Download PDF">pdf</a>, <a href="/format/2307.13929" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Spatio-Temporal Domain Awareness for Multi-Agent Collaborative  Perception
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+K">Kun Yang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+D">Dingkang Yang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jingyu Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+M">Mingcheng Li</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jing Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Hanqi Wang</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+P">Peng Sun</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+L">Liang Song</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by ICCV 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item467">[467]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.15285" title="Abstract">arXiv:2307.15285</a> (replaced) [<a href="/pdf/2307.15285" title="Download PDF">pdf</a>, <a href="/format/2307.15285" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Optimal Approximation of Zonoids and Uniform Approximation by Shallow  Neural Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Siegel%2C+J+W">Jonathan W. Siegel</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG); Numerical Analysis (math.NA)

</div>
</div>
</dd>
<dt><a name="item468">[468]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.15593" title="Abstract">arXiv:2307.15593</a> (replaced) [<a href="/pdf/2307.15593" title="Download PDF">pdf</a>, <a href="/format/2307.15593" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Robust Distortion-free Watermarks for Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kuditipudi%2C+R">Rohith Kuditipudi</a>, 
<a href="/search/cs?searchtype=author&query=Thickstun%2C+J">John Thickstun</a>, 
<a href="/search/cs?searchtype=author&query=Hashimoto%2C+T">Tatsunori Hashimoto</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+P">Percy Liang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computation and Language (cs.CL); Cryptography and Security (cs.CR)

</div>
</div>
</dd>
<dt><a name="item469">[469]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.00221" title="Abstract">arXiv:2308.00221</a> (replaced) [<a href="/pdf/2308.00221" title="Download PDF">pdf</a>, <a href="/format/2308.00221" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Advancing Beyond Identification: Multi-bit Watermark for Large Language  Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yoo%2C+K">KiYoon Yoo</a>, 
<a href="/search/cs?searchtype=author&query=Ahn%2C+W">Wonhyuk Ahn</a>, 
<a href="/search/cs?searchtype=author&query=Kwak%2C+N">Nojun Kwak</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Under review. 9 pages and appendix
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Cryptography and Security (cs.CR)

</div>
</div>
</dd>
<dt><a name="item470">[470]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.01804" title="Abstract">arXiv:2308.01804</a> (replaced) [<a href="/pdf/2308.01804" title="Download PDF">pdf</a>, <a href="/format/2308.01804" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> QUEST: Query Stream for Practical Cooperative Perception
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fan%2C+S">Siqi Fan</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+H">Haibao Yu</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+W">Wenxian Yang</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+J">Jirui Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Nie%2C+Z">Zaiqing Nie</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item471">[471]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.02104" title="Abstract">arXiv:2308.02104</a> (replaced) [<a href="/pdf/2308.02104" title="Download PDF">pdf</a>, <a href="/format/2308.02104" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Mechanistic Modeling and Analysis of Thermal Radiation in Conventional,  Microwave-assisted, and Hybrid Freeze Drying for Biopharmaceutical  Manufacturing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Srisuma%2C+P">Prakitr Srisuma</a>, 
<a href="/search/cs?searchtype=author&query=Barbastathis%2C+G">George Barbastathis</a>, 
<a href="/search/cs?searchtype=author&query=Braatz%2C+R+D">Richard D. Braatz</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Engineering, Finance, and Science (cs.CE)</span>

</div>
</div>
</dd>
<dt><a name="item472">[472]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.02711" title="Abstract">arXiv:2308.02711</a> (replaced) [<a href="/e-print/2308.02711" title="Download source">src</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Resilient and Privacy-Preserving Threshold Vehicular Public Key  Infrastructure (VPKI)
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ajibuwa%2C+O+E">Opeyemi Emmanuel Ajibuwa</a>, 
<a href="/search/cs?searchtype=author&query=Fabiyi%2C+S+D">Samson Damilola Fabiyi</a>, 
<a href="/search/cs?searchtype=author&query=Dada%2C+G+E">Gbenga Emmanuel Dada</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This research has been withdrawn due to the omission of proper attribution to some individuals who made contributions to the research. We recognize the importance of giving credit where it is due and have chosen to withdraw the paper in order to address these attribution concerns appropriately
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
</div>
</dd>
<dt><a name="item473">[473]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.03666" title="Abstract">arXiv:2308.03666</a> (replaced) [<a href="/pdf/2308.03666" title="Download PDF">pdf</a>, <a href="/format/2308.03666" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Bridging Trustworthiness and Open-World Learning: An Exploratory Neural  Approach for Enhancing Interpretability, Generalization, and Robustness
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Du%2C+S">Shide Du</a>, 
<a href="/search/stat?searchtype=author&query=Fang%2C+Z">Zihan Fang</a>, 
<a href="/search/stat?searchtype=author&query=Lan%2C+S">Shiyang Lan</a>, 
<a href="/search/stat?searchtype=author&query=Tan%2C+Y">Yanchao Tan</a>, 
<a href="/search/stat?searchtype=author&query=G%C3%BCnther%2C+M">Manuel G&#xfc;nther</a>, 
<a href="/search/stat?searchtype=author&query=Wang%2C+S">Shiping Wang</a>, 
<a href="/search/stat?searchtype=author&query=Guo%2C+W">Wenzhong Guo</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item474">[474]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.07796" title="Abstract">arXiv:2308.07796</a> (replaced) [<a href="/pdf/2308.07796" title="Download PDF">pdf</a>, <a href="/format/2308.07796" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Research Software Engineering in 2030
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Katz%2C+D+S">Daniel S. Katz</a>, 
<a href="/search/cs?searchtype=author&query=Hettrick%2C+S">Simon Hettrick</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Invited paper for 2023 IEEE Conference on eScience
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
</div>
</dd>
<dt><a name="item475">[475]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.07895" title="Abstract">arXiv:2308.07895</a> (replaced) [<a href="/pdf/2308.07895" title="Download PDF">pdf</a>, <a href="/format/2308.07895" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Roses Have Thorns: Understanding the Downside of Oncological Care  Delivery Through Visual Analytics and Sequential Rule Mining
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Floricel%2C+C">Carla Floricel</a>, 
<a href="/search/cs?searchtype=author&query=Wentzel%2C+A">Andrew Wentzel</a>, 
<a href="/search/cs?searchtype=author&query=Mohamed%2C+A">Abdallah Mohamed</a>, 
<a href="/search/cs?searchtype=author&query=Fuller%2C+C+D">C.David Fuller</a>, 
<a href="/search/cs?searchtype=author&query=Canahuate%2C+G">Guadalupe Canahuate</a>, 
<a href="/search/cs?searchtype=author&query=Marai%2C+G+E">G. Elisabeta Marai</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
</div>
</dd>
<dt><a name="item476">[476]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.08417" title="Abstract">arXiv:2308.08417</a> (replaced) [<a href="/pdf/2308.08417" title="Download PDF">pdf</a>, <a href="/format/2308.08417" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Porting Batched Iterative Solvers onto Intel GPUs with SYCL
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+P">Phuong Nguyen</a>, 
<a href="/search/cs?searchtype=author&query=Nayak%2C+P">Pratik Nayak</a>, 
<a href="/search/cs?searchtype=author&query=Anzt%2C+H">Hartwig Anzt</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages, 8 figures
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> In Workshops of The International Conference on High Performance
  Computing, Network, Storage, and Analysis (SC-W 2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>

</div>
</div>
</dd>
<dt><a name="item477">[477]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.08873" title="Abstract">arXiv:2308.08873</a> (replaced) [<a href="/pdf/2308.08873" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Accelerating Training Time with Feature Enforcing- Physics Informed  Neural Network (FE-PINN): Utilizing Boundary Conditions as Prior Knowledge  for Faster Convergence
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jahaninasab%2C+M">Mahyar Jahaninasab</a>, 
<a href="/search/cs?searchtype=author&query=Bijarchi%2C+M+A">Mohamad Ali Bijarchi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 26 pages, 9 figures, 4 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item478">[478]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.09683" title="Abstract">arXiv:2308.09683</a> (replaced) [<a href="/pdf/2308.09683" title="Download PDF">pdf</a>, <a href="/ps/2308.09683" title="Download PostScript">ps</a>, <a href="/format/2308.09683" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Near-linear time samplers for matroid independent sets with applications
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+X">Xiaoyu Chen</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+H">Heng Guo</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xinyuan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zou%2C+Z">Zongrui Zou</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>; Probability (math.PR)

</div>
</div>
</dd>
<dt><a name="item479">[479]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10842" title="Abstract">arXiv:2308.10842</a> (replaced) [<a href="/pdf/2308.10842" title="Download PDF">pdf</a>, <a href="/format/2308.10842" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Enhancing Agent Communication and Learning through Action and Language
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Caselles-Dupr%C3%A9%2C+H">Hugo Caselles-Dupr&#xe9;</a>, 
<a href="/search/cs?searchtype=author&query=Sigaud%2C+O">Olivier Sigaud</a>, 
<a href="/search/cs?searchtype=author&query=Chetouani%2C+M">Mohamed Chetouani</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> IMOL workshop, Paris 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item480">[480]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.11073" title="Abstract">arXiv:2308.11073</a> (replaced) [<a href="/pdf/2308.11073" title="Download PDF">pdf</a>, <a href="/format/2308.11073" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Audio-Visual Class-Incremental Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pian%2C+W">Weiguo Pian</a>, 
<a href="/search/cs?searchtype=author&query=Mo%2C+S">Shentong Mo</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+Y">Yunhui Guo</a>, 
<a href="/search/cs?searchtype=author&query=Tian%2C+Y">Yapeng Tian</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at ICCV 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item481">[481]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.11677" title="Abstract">arXiv:2308.11677</a> (replaced) [<a href="/pdf/2308.11677" title="Download PDF">pdf</a>, <a href="/format/2308.11677" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An Analysis of Initial Training Strategies for Exemplar-Free  Class-Incremental Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Petit%2C+G">Gr&#xe9;goire Petit</a>, 
<a href="/search/cs?searchtype=author&query=Soumm%2C+M">Michael Soumm</a>, 
<a href="/search/cs?searchtype=author&query=Feillet%2C+E">Eva Feillet</a>, 
<a href="/search/cs?searchtype=author&query=Popescu%2C+A">Adrian Popescu</a>, 
<a href="/search/cs?searchtype=author&query=Delezoide%2C+B">Bertrand Delezoide</a>, 
<a href="/search/cs?searchtype=author&query=Picard%2C+D">David Picard</a>, 
<a href="/search/cs?searchtype=author&query=Hudelot%2C+C">C&#xe9;line Hudelot</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item482">[482]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.12013" title="Abstract">arXiv:2308.12013</a> (replaced) [<a href="/pdf/2308.12013" title="Download PDF">pdf</a>, <a href="/format/2308.12013" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Quantum-Noise-driven Generative Diffusion Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Parigi%2C+M">Marco Parigi</a>, 
<a href="/search/quant-ph?searchtype=author&query=Martina%2C+S">Stefano Martina</a>, 
<a href="/search/quant-ph?searchtype=author&query=Caruso%2C+F">Filippo Caruso</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages, 3 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Disordered Systems and Neural Networks (cond-mat.dis-nn); Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item483">[483]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.12259" title="Abstract">arXiv:2308.12259</a> (replaced) [<a href="/pdf/2308.12259" title="Download PDF">pdf</a>, <a href="/format/2308.12259" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Data-driven Identification of Parametric Governing Equations of  Dynamical Systems Using the Signed Cumulative Distribution Transform
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Rubaiyat%2C+A+H+M">Abu Hasnat Mohammad Rubaiyat</a>, 
<a href="/search/eess?searchtype=author&query=Thai%2C+D+H">Duy H. Thai</a>, 
<a href="/search/eess?searchtype=author&query=Nichols%2C+J+M">Jonathan M. Nichols</a>, 
<a href="/search/eess?searchtype=author&query=Hutchinson%2C+M+N">Meredith N. Hutchinson</a>, 
<a href="/search/eess?searchtype=author&query=Wallen%2C+S+P">Samuel P. Wallen</a>, 
<a href="/search/eess?searchtype=author&query=Naify%2C+C+J">Christina J. Naify</a>, 
<a href="/search/eess?searchtype=author&query=Geib%2C+N">Nathan Geib</a>, 
<a href="/search/eess?searchtype=author&query=Haberman%2C+M+R">Michael R. Haberman</a>, 
<a href="/search/eess?searchtype=author&query=Rohde%2C+G+K">Gustavo K. Rohde</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Systems and Control (eess.SY)

</div>
</div>
</dd>
<dt><a name="item484">[484]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.12388" title="Abstract">arXiv:2308.12388</a> (replaced) [<a href="/pdf/2308.12388" title="Download PDF">pdf</a>, <a href="/format/2308.12388" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FOSA: Full Information Maximum Likelihood (FIML) Optimized  Self-Attention Imputation for Missing Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Deng%2C+O">Ou Deng</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+Q">Qun Jin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> The source code for the experiments is publicly available at: <a href="https://github.com/oudeng/FOSA/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item485">[485]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.12877" title="Abstract">arXiv:2308.12877</a> (replaced) [<a href="/pdf/2308.12877" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DS4DH at #SMM4H 2023: Zero-Shot Adverse Drug Events Normalization using  Sentence Transformers and Reciprocal-Rank Fusion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yazdani%2C+A">Anthony Yazdani</a>, 
<a href="/search/cs?searchtype=author&query=Rouhizadeh%2C+H">Hossein Rouhizadeh</a>, 
<a href="/search/cs?searchtype=author&query=Alvarez%2C+D+V">David Vicente Alvarez</a>, 
<a href="/search/cs?searchtype=author&query=Teodoro%2C+D">Douglas Teodoro</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item486">[486]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.12885" title="Abstract">arXiv:2308.12885</a> (replaced) [<a href="/pdf/2308.12885" title="Download PDF">pdf</a>, <a href="/format/2308.12885" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Collect, Measure, Repeat: Reliability Factors for Responsible AI Data  Collection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Inel%2C+O">Oana Inel</a>, 
<a href="/search/cs?searchtype=author&query=Draws%2C+T">Tim Draws</a>, 
<a href="/search/cs?searchtype=author&query=Aroyo%2C+L">Lora Aroyo</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> HCOMP 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Human-Computer Interaction (cs.HC)

</div>
</div>
</dd>
<dt><a name="item487">[487]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.13150" title="Abstract">arXiv:2308.13150</a> (replaced) [<a href="/pdf/2308.13150" title="Download PDF">pdf</a>, <a href="/format/2308.13150" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Enhancing Breast Cancer Classification Using Transfer ResNet with  Lightweight Attention Mechanism
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Liu%2C+S">Suxing Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages, 8 figures,6 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item488">[488]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.13670" title="Abstract">arXiv:2308.13670</a> (replaced) [<a href="/pdf/2308.13670" title="Download PDF">pdf</a>, <a href="/format/2308.13670" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Linear Oscillation: A Novel Activation Function for Vision Transformer
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yun%2C+J">Juyoung Yun</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV); Neural and Evolutionary Computing (cs.NE)

</div>
</div>
</dd>
<dt><a name="item489">[489]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.16018" title="Abstract">arXiv:2308.16018</a> (replaced) [<a href="/pdf/2308.16018" title="Download PDF">pdf</a>, <a href="/format/2308.16018" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SiT-MLP: A Simple MLP with Point-wise Topology Feature Learning for  Skeleton-based Action Recognition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+S">Shaojie Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Yin%2C+J">Jianqin Yin</a>, 
<a href="/search/cs?searchtype=author&query=Dang%2C+Y">Yonghao Dang</a>, 
<a href="/search/cs?searchtype=author&query=Fu%2C+J">Jiajun Fu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 10 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item490">[490]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.00424" title="Abstract">arXiv:2309.00424</a> (replaced) [<a href="/pdf/2309.00424" title="Download PDF">pdf</a>, <a href="/format/2309.00424" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning Speech Representation From Contrastive Token-Acoustic  Pretraining
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Qiang%2C+C">Chunyu Qiang</a>, 
<a href="/search/eess?searchtype=author&query=Li%2C+H">Hao Li</a>, 
<a href="/search/eess?searchtype=author&query=Tian%2C+Y">Yixin Tian</a>, 
<a href="/search/eess?searchtype=author&query=Fu%2C+R">Ruibo Fu</a>, 
<a href="/search/eess?searchtype=author&query=Wang%2C+T">Tao Wang</a>, 
<a href="/search/eess?searchtype=author&query=Wang%2C+L">Longbiao Wang</a>, 
<a href="/search/eess?searchtype=author&query=Dang%2C+J">Jianwu Dang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Sound (cs.SD)

</div>
</div>
</dd>
<dt><a name="item491">[491]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.02211" title="Abstract">arXiv:2309.02211</a> (replaced) [<a href="/pdf/2309.02211" title="Download PDF">pdf</a>, <a href="/format/2309.02211" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Distributionally Robust Machine Learning with Multi-source Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Wang%2C+Z">Zhenyu Wang</a>, 
<a href="/search/stat?searchtype=author&query=B%C3%BChlmann%2C+P">Peter B&#xfc;hlmann</a>, 
<a href="/search/stat?searchtype=author&query=Guo%2C+Z">Zijian Guo</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG); Methodology (stat.ME)

</div>
</div>
</dd>
<dt><a name="item492">[492]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.02427" title="Abstract">arXiv:2309.02427</a> (replaced) [<a href="/pdf/2309.02427" title="Download PDF">pdf</a>, <a href="/format/2309.02427" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Cognitive Architectures for Language Agents
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sumers%2C+T+R">Theodore R. Sumers</a>, 
<a href="/search/cs?searchtype=author&query=Yao%2C+S">Shunyu Yao</a>, 
<a href="/search/cs?searchtype=author&query=Narasimhan%2C+K">Karthik Narasimhan</a>, 
<a href="/search/cs?searchtype=author&query=Griffiths%2C+T+L">Thomas L. Griffiths</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> v2 enriched actionable insights and discussions, and polished abstract and introduction. 18 pages of main content, 12 pages of references, 5 figures. The first two authors contributed equally, order decided by coin flip. A CoALA-based repo of recent work on language agents: <a href="https://github.com/ysymyth/awesome-language-agents">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computation and Language (cs.CL); Machine Learning (cs.LG); Symbolic Computation (cs.SC)

</div>
</div>
</dd>
<dt><a name="item493">[493]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.03071" title="Abstract">arXiv:2309.03071</a> (replaced) [<a href="/pdf/2309.03071" title="Download PDF">pdf</a>, <a href="/format/2309.03071" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Disarming Steganography Attacks Inside Neural Network Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dubin%2C+R">Ran Dubin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Multimedia (cs.MM)

</div>
</div>
</dd>
<dt><a name="item494">[494]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.05169" title="Abstract">arXiv:2309.05169</a> (replaced) [<a href="/pdf/2309.05169" title="Download PDF">pdf</a>, <a href="/format/2309.05169" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SYSPART: Automated Temporal System Call Filtering for Binaries
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rajagopalan%2C+V+L">Vidya Lakshmi Rajagopalan</a> (1), 
<a href="/search/cs?searchtype=author&query=Kleftogiorgos%2C+K">Konstantinos Kleftogiorgos</a> (1), 
<a href="/search/cs?searchtype=author&query=G%C3%B6kta%C5%9F%2C+E">Enes G&#xf6;kta&#x15f;</a> (1), 
<a href="/search/cs?searchtype=author&query=Xu%2C+J">Jun Xu</a> (2), 
<a href="/search/cs?searchtype=author&query=Portokalidis%2C+G">Georgios Portokalidis</a> (1 and 3) ((1) Stevens Institute of Technology, (2) University of Utah, (3) IMDEA Software Institute)
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 17 pages, 3 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
</div>
</dd>
<dt><a name="item495">[495]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.05854" title="Abstract">arXiv:2309.05854</a> (replaced) [<a href="/pdf/2309.05854" title="Download PDF">pdf</a>, <a href="/format/2309.05854" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Modeling Information Acquisition and Social Learning Dynamics: A  Rational Inattention Perspective
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lin%2C+Y">Yiqing Lin</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Z">Zhanjiang Chen</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Huisheng Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+H+V">H.Vicky Zhao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 4 figures, submitted to ICASSP 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>

</div>
</div>
</dd>
<dt><a name="item496">[496]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.06268" title="Abstract">arXiv:2309.06268</a> (replaced) [<a href="/pdf/2309.06268" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ssVERDICT: Self-Supervised VERDICT-MRI for Enhanced Prostate Tumour  Characterisation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Sen%2C+S">Snigdha Sen</a>, 
<a href="/search/eess?searchtype=author&query=Singh%2C+S">Saurabh Singh</a>, 
<a href="/search/eess?searchtype=author&query=Pye%2C+H">Hayley Pye</a>, 
<a href="/search/eess?searchtype=author&query=Moore%2C+C+M">Caroline M. Moore</a>, 
<a href="/search/eess?searchtype=author&query=Whitaker%2C+H">Hayley Whitaker</a>, 
<a href="/search/eess?searchtype=author&query=Punwani%2C+S">Shonit Punwani</a>, 
<a href="/search/eess?searchtype=author&query=Atkinson%2C+D">David Atkinson</a>, 
<a href="/search/eess?searchtype=author&query=Panagiotaki%2C+E">Eleftheria Panagiotaki</a>, 
<a href="/search/eess?searchtype=author&query=Slator%2C+P+J">Paddy J. Slator</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 5 figures. Submitted to Magnetic Resonance in Medicine
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item497">[497]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.06626" title="Abstract">arXiv:2309.06626</a> (replaced) [<a href="/pdf/2309.06626" title="Download PDF">pdf</a>, <a href="/format/2309.06626" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Accelerating Deep Neural Networks via Semi-Structured Activation  Sparsity
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Grimaldi%2C+M">Matteo Grimaldi</a>, 
<a href="/search/cs?searchtype=author&query=Ganji%2C+D+C">Darshan C. Ganji</a>, 
<a href="/search/cs?searchtype=author&query=Lazarevich%2C+I">Ivan Lazarevich</a>, 
<a href="/search/cs?searchtype=author&query=Sah%2C+S">Sudhakar Sah</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Code is available at <a href="http://github.com/Deeplite/activ-sparse">this http URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item498">[498]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.07261" title="Abstract">arXiv:2309.07261</a> (replaced) [<a href="/pdf/2309.07261" title="Download PDF">pdf</a>, <a href="/format/2309.07261" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Simultaneous inference for generalized linear models with unmeasured  confounders
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Du%2C+J">Jin-Hong Du</a>, 
<a href="/search/stat?searchtype=author&query=Wasserman%2C+L">Larry Wasserman</a>, 
<a href="/search/stat?searchtype=author&query=Roeder%2C+K">Kathryn Roeder</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 67 pages, 10 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Methodology (stat.ME)</span>; Machine Learning (cs.LG); Genomics (q-bio.GN); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item499">[499]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.07311" title="Abstract">arXiv:2309.07311</a> (replaced) [<a href="/pdf/2309.07311" title="Download PDF">pdf</a>, <a href="/format/2309.07311" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Sudden Drops in the Loss: Syntax Acquisition, Phase Transitions, and  Simplicity Bias in MLMs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+A">Angelica Chen</a>, 
<a href="/search/cs?searchtype=author&query=Shwartz-Ziv%2C+R">Ravid Shwartz-Ziv</a>, 
<a href="/search/cs?searchtype=author&query=Cho%2C+K">Kyunghyun Cho</a>, 
<a href="/search/cs?searchtype=author&query=Leavitt%2C+M+L">Matthew L. Leavitt</a>, 
<a href="/search/cs?searchtype=author&query=Saphra%2C+N">Naomi Saphra</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item500">[500]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08247" title="Abstract">arXiv:2309.08247</a> (replaced) [<a href="/pdf/2309.08247" title="Download PDF">pdf</a>, <a href="/format/2309.08247" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Geometric Perspective on Autoencoders
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lee%2C+Y">Yonghyeon Lee</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 13 figures, a summary of the contents presented in publications from NeurIPS 2021, ICLR 2022, and TAG-ML at ICML 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computational Geometry (cs.CG)

</div>
</div>
</dd>
<dt><a name="item501">[501]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08811" title="Abstract">arXiv:2309.08811</a> (replaced) [<a href="/pdf/2309.08811" title="Download PDF">pdf</a>, <a href="/format/2309.08811" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Subgroup and Coset Intersection in abelian-by-cyclic groups
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Dong%2C+R">Ruiwen Dong</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 25 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Group Theory (math.GR)</span>; Discrete Mathematics (cs.DM)

</div>
</div>
</dd>
<dt><a name="item502">[502]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.09404" title="Abstract">arXiv:2309.09404</a> (replaced) [<a href="/pdf/2309.09404" title="Download PDF">pdf</a>, <a href="/format/2309.09404" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Promoting Research Collaboration with Open Data Driven Team  Recommendation in Response to Call for Proposals
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Valluru%2C+S+L">Siva Likitha Valluru</a>, 
<a href="/search/cs?searchtype=author&query=Srivastava%2C+B">Biplav Srivastava</a>, 
<a href="/search/cs?searchtype=author&query=Paladi%2C+S+T">Sai Teja Paladi</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+S">Siwen Yan</a>, 
<a href="/search/cs?searchtype=author&query=Natarajan%2C+S">Sriraam Natarajan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages, 2 figures, 3 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
</div>
</dd>
<dt><a name="item503">[503]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.09514" title="Abstract">arXiv:2309.09514</a> (replaced) [<a href="/pdf/2309.09514" title="Download PDF">pdf</a>, <a href="/format/2309.09514" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PanoMixSwap Panorama Mixing via Structural Swapping for Indoor Scene  Understanding
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hsieh%2C+Y">Yu-Cheng Hsieh</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+C">Cheng Sun</a>, 
<a href="/search/cs?searchtype=author&query=Dengale%2C+S">Suraj Dengale</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+M">Min Sun</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> BMVC'23; project page:<a href="https://yuchenghsieh.github.io/PanoMixSwap">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item504">[504]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.09880" title="Abstract">arXiv:2309.09880</a> (replaced) [<a href="/pdf/2309.09880" title="Download PDF">pdf</a>, <a href="/ps/2309.09880" title="Download PostScript">ps</a>, <a href="/format/2309.09880" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Error Reduction from Stacked Regressions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Chen%2C+X">Xin Chen</a>, 
<a href="/search/stat?searchtype=author&query=Klusowski%2C+J+M">Jason M. Klusowski</a>, 
<a href="/search/stat?searchtype=author&query=Tan%2C+Y+S">Yan Shuo Tan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item505">[505]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.10288" title="Abstract">arXiv:2309.10288</a> (replaced) [<a href="/pdf/2309.10288" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AstroPortal: An ontology repository concept for astronomy, astronautics  and other space topics
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/astro-ph?searchtype=author&query=Rovetto%2C+R+J">Robert J. Rovetto</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> See also <a href="https://github.com/rrovetto/astroportal">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Instrumentation and Methods for Astrophysics (astro-ph.IM)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item506">[506]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.10677" title="Abstract">arXiv:2309.10677</a> (replaced) [<a href="/pdf/2309.10677" title="Download PDF">pdf</a>, <a href="/format/2309.10677" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Estimating Contamination via Perplexity: Quantifying Memorisation in  Language Model Evaluation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yucheng Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item507">[507]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.10966" title="Abstract">arXiv:2309.10966</a> (replaced) [<a href="/pdf/2309.10966" title="Download PDF">pdf</a>, <a href="/format/2309.10966" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MBR and QE Finetuning: Training-time Distillation of the Best and Most  Expensive Decoding Methods
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Finkelstein%2C+M">Mara Finkelstein</a>, 
<a href="/search/cs?searchtype=author&query=Freitag%2C+M">Markus Freitag</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item508">[508]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.11166" title="Abstract">arXiv:2309.11166</a> (replaced) [<a href="/pdf/2309.11166" title="Download PDF">pdf</a>, <a href="/format/2309.11166" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Are Large Language Models Really Robust to Word-Level Perturbations?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Haoyu Wang</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+G">Guozheng Ma</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+C">Cong Yu</a>, 
<a href="/search/cs?searchtype=author&query=Gui%2C+N">Ning Gui</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+L">Linrui Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+Z">Zhiqi Huang</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+S">Suwei Ma</a>, 
<a href="/search/cs?searchtype=author&query=Chang%2C+Y">Yongzhe Chang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+S">Sen Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+L">Li Shen</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xueqian Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+P">Peilin Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Tao%2C+D">Dacheng Tao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item509">[509]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.11730" title="Abstract">arXiv:2309.11730</a> (replaced) [<a href="/pdf/2309.11730" title="Download PDF">pdf</a>, <a href="/format/2309.11730" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Leveraging In-the-Wild Data for Effective Self-Supervised Pretraining in  Speaker Recognition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Wang%2C+S">Shuai Wang</a>, 
<a href="/search/eess?searchtype=author&query=Bai%2C+Q">Qibing Bai</a>, 
<a href="/search/eess?searchtype=author&query=Liu%2C+Q">Qi Liu</a>, 
<a href="/search/eess?searchtype=author&query=Yu%2C+J">Jianwei Yu</a>, 
<a href="/search/eess?searchtype=author&query=Chen%2C+Z">Zhengyang Chen</a>, 
<a href="/search/eess?searchtype=author&query=Han%2C+B">Bing Han</a>, 
<a href="/search/eess?searchtype=author&query=Qian%2C+Y">Yanmin Qian</a>, 
<a href="/search/eess?searchtype=author&query=Li%2C+H">Haizhou Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> submitted to ICASSP 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Sound (cs.SD)

</div>
</div>
</dd>
<dt><a name="item510">[510]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.11791" title="Abstract">arXiv:2309.11791</a> (replaced) [<a href="/pdf/2309.11791" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SLHCat: Mapping Wikipedia Categories and Lists to DBpedia by Leveraging  Semantic, Lexical, and Hierarchical Features
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zhaoyi Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zhenyang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Qin%2C+J">Jiaxin Qin</a>, 
<a href="/search/cs?searchtype=author&query=Iwaihara%2C+M">Mizuho Iwaihara</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ICADL23
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Digital Libraries (cs.DL)</span>; Computation and Language (cs.CL)

</div>
</div>
</dd>
<dt><a name="item511">[511]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.12463" title="Abstract">arXiv:2309.12463</a> (replaced) [<a href="/pdf/2309.12463" title="Download PDF">pdf</a>, <a href="/format/2309.12463" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Impact of architecture on robustness and interpretability of  multispectral deep neural networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Godfrey%2C+C">Charles Godfrey</a>, 
<a href="/search/cs?searchtype=author&query=Bishoff%2C+E">Elise Bishoff</a>, 
<a href="/search/cs?searchtype=author&query=McKay%2C+M">Myles McKay</a>, 
<a href="/search/cs?searchtype=author&query=Byler%2C+E">Eleanor Byler</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Comments welcome! V2: minor changes (author contact info updated, a few formatting issues fixed)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item512">[512]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.12592" title="Abstract">arXiv:2309.12592</a> (replaced) [<a href="/pdf/2309.12592" title="Download PDF">pdf</a>, <a href="/format/2309.12592" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ChainsFormer: A Chain Latency-aware Resource Provisioning Approach for  Microservices Cluster
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Song%2C+C">Chenghao Song</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+M">Minxian Xu</a>, 
<a href="/search/cs?searchtype=author&query=Ye%2C+K">Kejiang Ye</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+H">Huaming Wu</a>, 
<a href="/search/cs?searchtype=author&query=Gill%2C+S+S">Sukhpal Singh Gill</a>, 
<a href="/search/cs?searchtype=author&query=Buyya%2C+R">Rajkumar Buyya</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+C">Chengzhong Xu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 15 pages
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> In the Proceedings of International Conference on Service Oriented
  Computing (ICSOC 2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>

</div>
</div>
</dd>
<dt><a name="item513">[513]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.12627" title="Abstract">arXiv:2309.12627</a> (replaced) [<a href="/pdf/2309.12627" title="Download PDF">pdf</a>, <a href="/format/2309.12627" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Quantum Computing-based System for Portfolio Optimization using Future  Asset Values and Automatic Reduction of the Investment Universe
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Osaba%2C+E">Eneko Osaba</a>, 
<a href="/search/cs?searchtype=author&query=Gelabert%2C+G">Guillaume Gelabert</a>, 
<a href="/search/cs?searchtype=author&query=Villar-Rodriguez%2C+E">Esther Villar-Rodriguez</a>, 
<a href="/search/cs?searchtype=author&query=Asla%2C+A">Ant&#xf3;n Asla</a>, 
<a href="/search/cs?searchtype=author&query=Oregi%2C+I">Izaskun Oregi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 3 figures, paper accepted for being presented in the upcoming 9th International Congress on Information and Communication Technology (ICICT 2024)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Emerging Technologies (cs.ET)

</div>
</div>
</dd>
<dt><a name="item514">[514]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13057" title="Abstract">arXiv:2309.13057</a> (replaced) [<a href="/pdf/2309.13057" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Return on Investment in AI Ethics: A Holistic Framework
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bevilacqua%2C+M">Marialena Bevilacqua</a>, 
<a href="/search/cs?searchtype=author&query=Berente%2C+N">Nicholas Berente</a>, 
<a href="/search/cs?searchtype=author&query=Domin%2C+H">Heather Domin</a>, 
<a href="/search/cs?searchtype=author&query=Goehring%2C+B">Brian Goehring</a>, 
<a href="/search/cs?searchtype=author&query=Rossi%2C+F">Francesca Rossi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> A subsequent version of this paper will be published in the Hawaii International Conference on System Sciences (HICSS) 2024 Proceedings
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>

</div>
</div>
</dd>
<dt><a name="item515">[515]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13404" title="Abstract">arXiv:2309.13404</a> (replaced) [<a href="/pdf/2309.13404" title="Download PDF">pdf</a>, <a href="/format/2309.13404" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> WS-YOLO: Weakly Supervised Yolo Network for Surgical Tool Localization  in Endoscopic Videos
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Wei%2C+R">Rongfeng Wei</a>, 
<a href="/search/eess?searchtype=author&query=Wu%2C+J">Jinlin Wu</a>, 
<a href="/search/eess?searchtype=author&query=Pang%2C+Y">You Pang</a>, 
<a href="/search/eess?searchtype=author&query=Chen%2C+Z">Zhen Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Surgical Tool Localization in Endoscopic Videos Challenge of MICCAI2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item516">[516]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13494" title="Abstract">arXiv:2309.13494</a> (replaced) [<a href="/pdf/2309.13494" title="Download PDF">pdf</a>, <a href="/format/2309.13494" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Communication-Constrained Multi-Robot Exploration with Intermittent  Rendezvous
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=da+Silva%2C+A+R">Alysson Ribeiro da Silva</a>, 
<a href="/search/cs?searchtype=author&query=Chaimowicz%2C+L">Luiz Chaimowicz</a>, 
<a href="/search/cs?searchtype=author&query=Kumar%2C+V">Vijay Kumar</a>, 
<a href="/search/cs?searchtype=author&query=Silva%2C+T+C">Thales Costa Silva</a>, 
<a href="/search/cs?searchtype=author&query=Hsieh%2C+A">Ani Hsieh</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, 12 figures, 1 table, video: <a href="https://youtu.be/EuVbCoyjuIY">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Multiagent Systems (cs.MA)

</div>
</div>
</dd>
<dt><a name="item517">[517]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13505" title="Abstract">arXiv:2309.13505</a> (replaced) [<a href="/pdf/2309.13505" title="Download PDF">pdf</a>, <a href="/format/2309.13505" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Bridging Semantic Gaps for Language-Supervised Semantic Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xing%2C+Y">Yun Xing</a>, 
<a href="/search/cs?searchtype=author&query=Kang%2C+J">Jian Kang</a>, 
<a href="/search/cs?searchtype=author&query=Xiao%2C+A">Aoran Xiao</a>, 
<a href="/search/cs?searchtype=author&query=Nie%2C+J">Jiahao Nie</a>, 
<a href="/search/cs?searchtype=author&query=Ling%2C+S">Shao Ling</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+S">Shijian Lu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> NeurIPS 2023 poster. Code will be available at <a href="https://github.com/xing0047/CoCu">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item518">[518]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13550" title="Abstract">arXiv:2309.13550</a> (replaced) [<a href="/pdf/2309.13550" title="Download PDF">pdf</a>, <a href="/format/2309.13550" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Decoding Radiologists Intense Focus for Accurate CXR Diagnoses: A  Controllable and Interpretable AI System
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pham%2C+T+T">Trong Thang Pham</a>, 
<a href="/search/cs?searchtype=author&query=Brecheisen%2C+J">Jacob Brecheisen</a>, 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+A">Anh Nguyen</a>, 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+H">Hien Nguyen</a>, 
<a href="/search/cs?searchtype=author&query=Le%2C+N">Ngan Le</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item519">[519]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13701" title="Abstract">arXiv:2309.13701</a> (replaced) [<a href="/pdf/2309.13701" title="Download PDF">pdf</a>, <a href="/format/2309.13701" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ALLURE: Auditing and Improving LLM-based Evaluation of Text using  Iterative In-Context-Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hasanbeig%2C+H">Hosein Hasanbeig</a>, 
<a href="/search/cs?searchtype=author&query=Sharma%2C+H">Hiteshi Sharma</a>, 
<a href="/search/cs?searchtype=author&query=Betthauser%2C+L">Leo Betthauser</a>, 
<a href="/search/cs?searchtype=author&query=Frujeri%2C+F+V">Felipe Vieira Frujeri</a>, 
<a href="/search/cs?searchtype=author&query=Momennejad%2C+I">Ida Momennejad</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Human-Computer Interaction (cs.HC)

</div>
</div>
</dd>
<dt><a name="item520">[520]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13775" title="Abstract">arXiv:2309.13775</a> (replaced) [<a href="/pdf/2309.13775" title="Download PDF">pdf</a>, <a href="/format/2309.13775" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Rashomon Importance Distribution: Getting RID of Unstable, Single  Model-based Variable Importance
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Donnelly%2C+J">Jon Donnelly</a>, 
<a href="/search/cs?searchtype=author&query=Katta%2C+S">Srikar Katta</a>, 
<a href="/search/cs?searchtype=author&query=Rudin%2C+C">Cynthia Rudin</a>, 
<a href="/search/cs?searchtype=author&query=Browne%2C+E+P">Edward P. Browne</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To appear in NeurIPS 2023 as a spotlight paper
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Genomics (q-bio.GN); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item521">[521]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13781" title="Abstract">arXiv:2309.13781</a> (replaced) [<a href="/pdf/2309.13781" title="Download PDF">pdf</a>, <a href="/format/2309.13781" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Explainable Machine Learning for ICU Readmission Prediction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=de+S%C3%A1%2C+A+G+C">Alex G. C. de S&#xe1;</a>, 
<a href="/search/cs?searchtype=author&query=Gould%2C+D">Daniel Gould</a>, 
<a href="/search/cs?searchtype=author&query=Fedyukova%2C+A">Anna Fedyukova</a>, 
<a href="/search/cs?searchtype=author&query=Nicholas%2C+M">Mitchell Nicholas</a>, 
<a href="/search/cs?searchtype=author&query=Dockrell%2C+L">Lucy Dockrell</a>, 
<a href="/search/cs?searchtype=author&query=Fletcher%2C+C">Calvin Fletcher</a>, 
<a href="/search/cs?searchtype=author&query=Pilcher%2C+D">David Pilcher</a>, 
<a href="/search/cs?searchtype=author&query=Capurro%2C+D">Daniel Capurro</a>, 
<a href="/search/cs?searchtype=author&query=Ascher%2C+D+B">David B. Ascher</a>, 
<a href="/search/cs?searchtype=author&query=El-Khawas%2C+K">Khaled El-Khawas</a>, 
<a href="/search/cs?searchtype=author&query=Pires%2C+D+E+V">Douglas E. V. Pires</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item522">[522]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.14243" title="Abstract">arXiv:2309.14243</a> (replaced) [<a href="/pdf/2309.14243" title="Download PDF">pdf</a>, <a href="/format/2309.14243" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Enhancing data efficiency in reinforcement learning: a novel imagination  mechanism based on mesh information propagation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zihang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+M">Maowei Jiang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages. arXiv admin note: text overlap with <a href="/abs/2007.05929">arXiv:2007.05929</a> by other authors
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item523">[523]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.14290" title="Abstract">arXiv:2309.14290</a> (replaced) [<a href="/pdf/2309.14290" title="Download PDF">pdf</a>, <a href="/format/2309.14290" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Automated Market Makers for Cross-chain DeFi and Sharded Blockchains
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pourpouneh%2C+M">Mohsen Pourpouneh</a>, 
<a href="/search/cs?searchtype=author&query=Nielsen%2C+K">Kurt Nielsen</a>, 
<a href="/search/cs?searchtype=author&query=Gravgaard%2C+J+B">Jesper Balman Gravgaard</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>

</div>
</div>
</dd>
<dt><a name="item524">[524]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.14298" title="Abstract">arXiv:2309.14298</a> (replaced) [<a href="/pdf/2309.14298" title="Download PDF">pdf</a>, <a href="/format/2309.14298" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Improved Algorithms for Stochastic Linear Bandits Using Tail Bounds for  Martingale Mixtures
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Flynn%2C+H">Hamish Flynn</a>, 
<a href="/search/stat?searchtype=author&query=Reeb%2C+D">David Reeb</a>, 
<a href="/search/stat?searchtype=author&query=Kandemir%2C+M">Melih Kandemir</a>, 
<a href="/search/stat?searchtype=author&query=Peters%2C+J">Jan Peters</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at NeurIPS 2023. 35 pages, 6 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item525">[525]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.14303" title="Abstract">arXiv:2309.14303</a> (replaced) [<a href="/pdf/2309.14303" title="Download PDF">pdf</a>, <a href="/format/2309.14303" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Dataset Diffusion: Diffusion-based Synthetic Dataset Generation for  Pixel-Level Semantic Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+Q">Quang Nguyen</a>, 
<a href="/search/cs?searchtype=author&query=Vu%2C+T">Truong Vu</a>, 
<a href="/search/cs?searchtype=author&query=Tran%2C+A">Anh Tran</a>, 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+K">Khoi Nguyen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item526">[526]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.14398" title="Abstract">arXiv:2309.14398</a> (replaced) [<a href="/pdf/2309.14398" title="Download PDF">pdf</a>, <a href="/format/2309.14398" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Seeing and hearing what has not been said; A multimodal client behavior  classifier in Motivational Interviewing with interpretable fusion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Galland%2C+L">Lucie Galland</a>, 
<a href="/search/cs?searchtype=author&query=Pelachaud%2C+C">Catherine Pelachaud</a>, 
<a href="/search/cs?searchtype=author&query=Pecune%2C+F">Florian Pecune</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages, 7 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Audio and Speech Processing (eess.AS)

</div>
</div>
</dd>
<dt><a name="item527">[527]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.14425" title="Abstract">arXiv:2309.14425</a> (replaced) [<a href="/pdf/2309.14425" title="Download PDF">pdf</a>, <a href="/format/2309.14425" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Self-Recovery Prompting: Promptable General Purpose Service Robot System  with Foundation Models and Self-Recovery
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shirasaka%2C+M">Mimo Shirasaka</a>, 
<a href="/search/cs?searchtype=author&query=Matsushima%2C+T">Tatsuya Matsushima</a>, 
<a href="/search/cs?searchtype=author&query=Tsunashima%2C+S">Soshi Tsunashima</a>, 
<a href="/search/cs?searchtype=author&query=Ikeda%2C+Y">Yuya Ikeda</a>, 
<a href="/search/cs?searchtype=author&query=Horo%2C+A">Aoi Horo</a>, 
<a href="/search/cs?searchtype=author&query=Ikoma%2C+S">So Ikoma</a>, 
<a href="/search/cs?searchtype=author&query=Tsuji%2C+C">Chikaha Tsuji</a>, 
<a href="/search/cs?searchtype=author&query=Wada%2C+H">Hikaru Wada</a>, 
<a href="/search/cs?searchtype=author&query=Omija%2C+T">Tsunekazu Omija</a>, 
<a href="/search/cs?searchtype=author&query=Komukai%2C+D">Dai Komukai</a>, 
<a href="/search/cs?searchtype=author&query=Iwasawa%2C+Y+M+Y">Yutaka Matsuo Yusuke Iwasawa</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Website: <a href="https://sites.google.com/view/srgpsr">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG); Systems and Control (eess.SY)

</div>
</div>
</dd>
<dt><a name="item528">[528]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.14496" title="Abstract">arXiv:2309.14496</a> (replaced) [<a href="/pdf/2309.14496" title="Download PDF">pdf</a>, <a href="/format/2309.14496" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Era Splitting -- Invariant Learning for Decision Trees
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=DeLise%2C+T">Timothy DeLise</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 20 pages, 8 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computational Engineering, Finance, and Science (cs.CE)

</div>
</div>
</dd>
<dt><a name="item529">[529]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.14555" title="Abstract">arXiv:2309.14555</a> (replaced) [<a href="/pdf/2309.14555" title="Download PDF">pdf</a>, <a href="/ps/2309.14555" title="Download PostScript">ps</a>, <a href="/format/2309.14555" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Optimal Stopping with Multi-Dimensional Comparative Loss Aversion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cai%2C+L">Linda Cai</a>, 
<a href="/search/cs?searchtype=author&query=Gardner%2C+J">Joshua Gardner</a>, 
<a href="/search/cs?searchtype=author&query=Weinberg%2C+S+M">S. Matthew Weinberg</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to WINE 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>; Theoretical Economics (econ.TH)

</div>
</div>
</dd>
<dt><a name="item530">[530]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.14616" title="Abstract">arXiv:2309.14616</a> (replaced) [<a href="/pdf/2309.14616" title="Download PDF">pdf</a>, <a href="/format/2309.14616" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> NDC-Scene: Boost Monocular 3D Semantic Scene Completion in Normalized  Device Coordinates Space
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yao%2C+J">Jiawei Yao</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+C">Chuming Li</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+K">Keqiang Sun</a>, 
<a href="/search/cs?searchtype=author&query=Cai%2C+Y">Yingjie Cai</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Hao Li</a>, 
<a href="/search/cs?searchtype=author&query=Ouyang%2C+W">Wanli Ouyang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Hongsheng Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at ICCV 2023. Project page: <a href="https://jiawei-yao0812.github.io/NDC-Scene/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item531">[531]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.14623" title="Abstract">arXiv:2309.14623</a> (replaced) [<a href="/pdf/2309.14623" title="Download PDF">pdf</a>, <a href="/format/2309.14623" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Text-to-Image Generation for Abstract Concepts
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liao%2C+J">Jiayi Liao</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+X">Xu Chen</a>, 
<a href="/search/cs?searchtype=author&query=Fu%2C+Q">Qiang Fu</a>, 
<a href="/search/cs?searchtype=author&query=Du%2C+L">Lun Du</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+X">Xiangnan He</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xiang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+S">Shi Han</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+D">Dongmei Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item532">[532]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.14764" title="Abstract">arXiv:2309.14764</a> (replaced) [<a href="/pdf/2309.14764" title="Download PDF">pdf</a>, <a href="/format/2309.14764" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> InvKA: Gait Recognition via Invertible Koopman Autoencoder
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+F">Fan Li</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+D">Dong Liang</a>, 
<a href="/search/cs?searchtype=author&query=Lian%2C+J">Jing Lian</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Q">Qidong Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+H">Hegui Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jizhao Liu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item533">[533]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.14872" title="Abstract">arXiv:2309.14872</a> (replaced) [<a href="/pdf/2309.14872" title="Download PDF">pdf</a>, <a href="/format/2309.14872" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ITEM3D: Illumination-Aware Directional Texture Editing for 3D Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+S">Shengqi Liu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Z">Zhuo Chen</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+J">Jingnan Gao</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+Y">Yichao Yan</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+W">Wenhan Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xiaobo Li</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+K">Ke Gao</a>, 
<a href="/search/cs?searchtype=author&query=Lyu%2C+J">Jiangjing Lyu</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+X">Xiaokang Yang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item534">[534]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.14877" title="Abstract">arXiv:2309.14877</a> (replaced) [<a href="/pdf/2309.14877" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Explainable Sustainability for AI in the Arts
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=J%C3%A4%C3%A4skel%C3%A4inen%2C+P">Petra J&#xe4;&#xe4;skel&#xe4;inen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item535">[535]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.14900" title="Abstract">arXiv:2309.14900</a> (replaced) [<a href="/pdf/2309.14900" title="Download PDF">pdf</a>, <a href="/format/2309.14900" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Pre-training-free Image Manipulation Localization through Non-Mutually  Exclusive Contrastive Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhou%2C+J">Jizhe Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+X">Xiaochen Ma</a>, 
<a href="/search/cs?searchtype=author&query=Du%2C+X">Xia Du</a>, 
<a href="/search/cs?searchtype=author&query=Alhammadi%2C+A+Y">Ahmed Y.Alhammadi</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+W">Wentao Feng</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Tech report. ICCV2023 paper
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item536">[536]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.14976" title="Abstract">arXiv:2309.14976</a> (replaced) [<a href="/pdf/2309.14976" title="Download PDF">pdf</a>, <a href="/format/2309.14976" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MoCaE: Mixture of Calibrated Experts Significantly Improves Object  Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Oksuz%2C+K">Kemal Oksuz</a>, 
<a href="/search/cs?searchtype=author&query=Kuzucu%2C+S">Selim Kuzucu</a>, 
<a href="/search/cs?searchtype=author&query=Joy%2C+T">Tom Joy</a>, 
<a href="/search/cs?searchtype=author&query=Dokania%2C+P+K">Puneet K. Dokania</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item537">[537]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15030" title="Abstract">arXiv:2309.15030</a> (replaced) [<a href="/pdf/2309.15030" title="Download PDF">pdf</a>, <a href="/format/2309.15030" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Quadratic Detection in Noncoherent Massive SIMO Systems over Correlated  Channels
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Vil%C3%A0-Insa%2C+M">Marc Vil&#xe0;-Insa</a>, 
<a href="/search/cs?searchtype=author&query=Mart%C3%AD%2C+A">Aniol Mart&#xed;</a>, 
<a href="/search/cs?searchtype=author&query=Riba%2C+J">Jaume Riba</a>, 
<a href="/search/cs?searchtype=author&query=Lamarca%2C+M">Meritxell Lamarca</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This work has been submitted to the IEEE for possible publication
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
</div>
</dd>
<dt><a name="item538">[538]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15103" title="Abstract">arXiv:2309.15103</a> (replaced) [<a href="/pdf/2309.15103" title="Download PDF">pdf</a>, <a href="/format/2309.15103" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LAVIE: High-Quality Video Generation with Cascaded Latent Diffusion  Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yaohui Wang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+X">Xinyuan Chen</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+X">Xin Ma</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+S">Shangchen Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+Z">Ziqi Huang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yi Wang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+C">Ceyuan Yang</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+Y">Yinan He</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+J">Jiashuo Yu</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+P">Peiqing Yang</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+Y">Yuwei Guo</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+T">Tianxing Wu</a>, 
<a href="/search/cs?searchtype=author&query=Si%2C+C">Chenyang Si</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+Y">Yuming Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+C">Cunjian Chen</a>, 
<a href="/search/cs?searchtype=author&query=Loy%2C+C+C">Chen Change Loy</a>, 
<a href="/search/cs?searchtype=author&query=Dai%2C+B">Bo Dai</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+D">Dahua Lin</a>, 
<a href="/search/cs?searchtype=author&query=Qiao%2C+Y">Yu Qiao</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Ziwei Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project webpage: <a href="https://vchitect.github.io/LaVie-project/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item539">[539]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15112" title="Abstract">arXiv:2309.15112</a> (replaced) [<a href="/pdf/2309.15112" title="Download PDF">pdf</a>, <a href="/format/2309.15112" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> InternLM-XComposer: A Vision-Language Large Model for Advanced  Text-image Comprehension and Composition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+P">Pan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+X">Xiaoyi Dong</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+B">Bin Wang</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+Y">Yuhang Cao</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+C">Chao Xu</a>, 
<a href="/search/cs?searchtype=author&query=Ouyang%2C+L">Linke Ouyang</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Z">Zhiyuan Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Ding%2C+S">Shuangrui Ding</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+S">Songyang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Duan%2C+H">Haodong Duan</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+H">Hang Yan</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xinyue Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+W">Wei Li</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jingwen Li</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+K">Kai Chen</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+C">Conghui He</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xingcheng Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Qiao%2C+Y">Yu Qiao</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+D">Dahua Lin</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jiaqi Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Code is available at <a href="https://github.com/InternLM/InternLM-XComposer">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
</dl>
<ul>
<li><a href="/list/cs/new?skip=0&amp;show=2000">New submissions</a></li>
<li><a href="#item288">Cross-lists</a></li>
<li><a href="#item331">Replacements</a></li>
</ul>
<small>[ total of 539 entries:  <b>1-539</b>  ]</small><br />
<small>[ showing up to 2000 entries per page:  <a href="/list/cs/new?skip=0&amp;show=1000">fewer</a> |  <font color="#999999">more</font> ]</small><br />
</div>
<br/><small><a id="mathjax_toggle" href="javascript:setMathjaxCookie()">Disable MathJax</a> (<a href="/help/mathjax">What is MathJax?</a>)</small><script type="text/javascript" language="javascript">mathjaxToggle();</script>

<hr />
<p>Links to:
<a href="/" accesskey="a">arXiv</a>,
<a href="/form/cs">form interface</a>,
<a href="/find/cs">find</a>,
<a href="/archive/cs">cs</a>, <a href="/list/cs/recent">recent</a>, <a href="/list/cs/2309">2309</a>,
<a href="/help/contact">contact</a>,
<a href="/help/" accesskey="h"><span class="accesskey">h</span>elp</a>&nbsp;
<small>(<a href="/help/accesskeys">Access key</a> information)</small>
</p>
<hr />
</div>
</div>
 <footer style="clear: both;">
      <div class="columns is-desktop" role="navigation" aria-label="Secondary" style="margin: -0.75em -0.75em 0.75em -0.75em">
        <!-- Macro-Column 1 -->
        <div class="column" style="padding: 0;">
          <div class="columns">
            <div class="column">
              <ul style="list-style: none; line-height: 2;">
                <li><a href="https://arxiv.org/about">About</a></li>
                <li><a href="https://arxiv.org/help">Help</a></li>
              </ul>
            </div>
            <div class="column">
              <ul style="list-style: none; line-height: 2;">
                <li>
                  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon filter-black" role="presentation"><title>contact arXiv</title><desc>Click here to contact arXiv</desc><path d="M502.3 190.8c3.9-3.1 9.7-.2 9.7 4.7V400c0 26.5-21.5 48-48 48H48c-26.5 0-48-21.5-48-48V195.6c0-5 5.7-7.8 9.7-4.7 22.4 17.4 52.1 39.5 154.1 113.6 21.1 15.4 56.7 47.8 92.2 47.6 35.7.3 72-32.8 92.3-47.6 102-74.1 131.6-96.3 154-113.7zM256 320c23.2.4 56.6-29.2 73.4-41.4 132.7-96.3 142.8-104.7 173.4-128.7 5.8-4.5 9.2-11.5 9.2-18.9v-19c0-26.5-21.5-48-48-48H48C21.5 64 0 85.5 0 112v19c0 7.4 3.4 14.3 9.2 18.9 30.6 23.9 40.7 32.4 173.4 128.7 16.8 12.2 50.2 41.8 73.4 41.4z"/></svg>
                  <a href="https://arxiv.org/help/contact"> Contact</a>
                </li>
                <li>
                  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon filter-black" role="presentation"><title>subscribe to arXiv mailings</title><desc>Click here to subscribe</desc><path d="M476 3.2L12.5 270.6c-18.1 10.4-15.8 35.6 2.2 43.2L121 358.4l287.3-253.2c5.5-4.9 13.3 2.6 8.6 8.3L176 407v80.5c0 23.6 28.5 32.9 42.5 15.8L282 426l124.6 52.2c14.2 6 30.4-2.9 33-18.2l72-432C515 7.8 493.3-6.8 476 3.2z"/></svg>
                  <a href="https://arxiv.org/help/subscribe"> Subscribe</a>
                </li>
              </ul>
            </div>
          </div>
        </div>
        <!-- End Macro-Column 1 -->
        <!-- Macro-Column 2 -->
        <div class="column" style="padding: 0;">
          <div class="columns">
            <div class="column">
              <ul style="list-style: none; line-height: 2;">
                <li><a href="https://arxiv.org/help/license">Copyright</a></li>
                <li><a href="https://arxiv.org/help/policies/privacy_policy">Privacy Policy</a></li>
              </ul>
            </div>
            <div class="column sorry-app-links">
              <ul style="list-style: none; line-height: 2;">
                <li><a href="https://arxiv.org/help/web_accessibility">Web Accessibility Assistance</a></li>
                <li>
                  <p class="help">
                    <a class="a11y-main-link" href="https://status.arxiv.org" target="_blank">arXiv Operational Status <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 256 512" class="icon filter-dark_grey" role="presentation"><path d="M224.3 273l-136 136c-9.4 9.4-24.6 9.4-33.9 0l-22.6-22.6c-9.4-9.4-9.4-24.6 0-33.9l96.4-96.4-96.4-96.4c-9.4-9.4-9.4-24.6 0-33.9L54.3 103c9.4-9.4 24.6-9.4 33.9 0l136 136c9.5 9.4 9.5 24.6.1 34z"/></svg></a><br>
                    Get status notifications via
                    <a class="is-link" href="https://subscribe.sorryapp.com/24846f03/email/new" target="_blank"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon filter-black" role="presentation"><path d="M502.3 190.8c3.9-3.1 9.7-.2 9.7 4.7V400c0 26.5-21.5 48-48 48H48c-26.5 0-48-21.5-48-48V195.6c0-5 5.7-7.8 9.7-4.7 22.4 17.4 52.1 39.5 154.1 113.6 21.1 15.4 56.7 47.8 92.2 47.6 35.7.3 72-32.8 92.3-47.6 102-74.1 131.6-96.3 154-113.7zM256 320c23.2.4 56.6-29.2 73.4-41.4 132.7-96.3 142.8-104.7 173.4-128.7 5.8-4.5 9.2-11.5 9.2-18.9v-19c0-26.5-21.5-48-48-48H48C21.5 64 0 85.5 0 112v19c0 7.4 3.4 14.3 9.2 18.9 30.6 23.9 40.7 32.4 173.4 128.7 16.8 12.2 50.2 41.8 73.4 41.4z"/></svg>email</a>
                    or <a class="is-link" href="https://subscribe.sorryapp.com/24846f03/slack/new" target="_blank"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512" class="icon filter-black" role="presentation"><path d="M94.12 315.1c0 25.9-21.16 47.06-47.06 47.06S0 341 0 315.1c0-25.9 21.16-47.06 47.06-47.06h47.06v47.06zm23.72 0c0-25.9 21.16-47.06 47.06-47.06s47.06 21.16 47.06 47.06v117.84c0 25.9-21.16 47.06-47.06 47.06s-47.06-21.16-47.06-47.06V315.1zm47.06-188.98c-25.9 0-47.06-21.16-47.06-47.06S139 32 164.9 32s47.06 21.16 47.06 47.06v47.06H164.9zm0 23.72c25.9 0 47.06 21.16 47.06 47.06s-21.16 47.06-47.06 47.06H47.06C21.16 243.96 0 222.8 0 196.9s21.16-47.06 47.06-47.06H164.9zm188.98 47.06c0-25.9 21.16-47.06 47.06-47.06 25.9 0 47.06 21.16 47.06 47.06s-21.16 47.06-47.06 47.06h-47.06V196.9zm-23.72 0c0 25.9-21.16 47.06-47.06 47.06-25.9 0-47.06-21.16-47.06-47.06V79.06c0-25.9 21.16-47.06 47.06-47.06 25.9 0 47.06 21.16 47.06 47.06V196.9zM283.1 385.88c25.9 0 47.06 21.16 47.06 47.06 0 25.9-21.16 47.06-47.06 47.06-25.9 0-47.06-21.16-47.06-47.06v-47.06h47.06zm0-23.72c-25.9 0-47.06-21.16-47.06-47.06 0-25.9 21.16-47.06 47.06-47.06h117.84c25.9 0 47.06 21.16 47.06 47.06 0 25.9-21.16 47.06-47.06 47.06H283.1z"/></svg>slack</a>
                  </p>
                </li>
              </ul>
            </div>
          </div>
        </div> <!-- end MetaColumn 2 -->
        <!-- End Macro-Column 2 -->
      </div>
    </footer>
</body>
</html>
