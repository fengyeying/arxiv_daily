<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en">
<head>
<title>Computer Science  authors/titles &quot;new&quot;</title>
<link rel="shortcut icon" href="/favicon.ico" type="image/x-icon" />
<link rel="stylesheet" type="text/css" media="screen" href="//static.arxiv.org/static/browse/0.3.2.8/css/arXiv.css?v=20220215" />
<link rel="stylesheet" type="text/css" media="screen" href="/bibex/bibex.css?20181009">
<link rel="stylesheet" type="text/css" media="screen" href="https://static.arxiv.org/static/browse/0.3.8/css/browse_search.css" />
<link rel="alternate" type="application/rss+xml" title="Computer Science " href="http://arxiv.org/rss/cs"/>
<script src="/js/mathjaxToggle.min.js" type="text/javascript"></script>


</head>
<body class="with-cu-identity">

<div id="cu-identity">
<div id="cu-logo">
<a href="https://www.cornell.edu/"><img src="//static.arxiv.org/icons/cu/cornell-reduced-white-SMALL.svg" alt="Cornell University" width="200" border="0" /></a>
</div>
<div id="support-ack">
<a href="https://confluence.cornell.edu/x/ALlRF">We gratefully acknowledge support from<br /> the Simons Foundation and member institutions.</a>
</div>
</div>
<div id="header">
<h1 class="header-breadcrumbs"><a href="/"><img src="//static.arxiv.org/images/arxiv-logo-one-color-white.svg" aria-label="logo" alt="arxiv logo" width="85" style="width:85px;margin-right:8px;"></a> <span>&gt;</span> <a href="/list/cs/recent">cs</a></h1>
<div class="search-block level-right">
<form class="level-item mini-search" method="GET" action="https://arxiv.org/search" _lpchecked="1">
<div class="field has-addons">
<div class="control">
<input class="input is-small" type="text" name="query" placeholder="Search..." aria-label="Search term or terms" data-com.agilebits.onepassword.user-edited="yes">
<p class="help"><a href="https://arxiv.org/help">Help</a> | <a href="https://arxiv.org/search/advanced">Advanced Search</a></p>
</div>
<div class="control">
<div class="select is-small">
<select name="searchtype" aria-label="Field to search">
<option value="all" selected="selected">All fields</option>
<option value="title">Title</option>
<option value="author">Author</option>
<option value="abstract">Abstract</option>
<option value="comments">Comments</option>
<option value="journal_ref">Journal reference</option>
<option value="acm_class">ACM classification</option>
<option value="msc_class">MSC classification</option>
<option value="report_num">Report number</option>
<option value="paper_id">arXiv identifier</option>
<option value="doi">DOI</option>
<option value="orcid">ORCID</option>
<option value="author_id">arXiv author ID</option>
<option value="help">Help pages</option>
<option value="full_text">Full text</option>
</select>
</div>
</div>
<button class="button is-small is-cul-darker">Search</button>
</div>
</form>
</div>
</div>
<div id="content">
<div id="dlpage">
<h1>Computer Science </h1>
<h2>New submissions</h2>
<div class="list-dateline">Submissions received from  Thu  9 Nov 23  to  Fri 10 Nov 23, announced Mon, 13 Nov 23</div>
<ul>
<li><a href="/list/cs/new?skip=0&amp;show=2000">New submissions</a></li>
<li><a href="#item249">Cross-lists</a></li>
<li><a href="#item287">Replacements</a></li>
</ul>
<small>[ total of 457 entries:  <b>1-457</b>  ]</small><br />
<small>[ showing up to 2000 entries per page:  <a href="/list/cs/new?skip=0&amp;show=1000">fewer</a> |  <font color="#999999">more</font> ]</small><br />
<h3>New submissions for Mon, 13 Nov 23</h3>
<dl>
<dt><a name="item1">[1]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05624" title="Abstract">arXiv:2311.05624</a> [<a href="/pdf/2311.05624" title="Download PDF">pdf</a>, <a href="/ps/2311.05624" title="Download PostScript">ps</a>, <a href="/format/2311.05624" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> NP-hard problems are not in BQP
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Czerwinski%2C+R">Reiner Czerwinski</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Complexity (cs.CC)</span>

</div>
<p class="mathjax">Grover's algorithm can solve NP-complete problems on quantum computers faster
than all the known algorithms on classical computers. However, Grover's
algorithm still needs exponential time. Due to the BBBV theorem, Grover's
algorithm is optimal for searches in the domain of a function, when the
function is used as a black box.
<br />We analyze the NP-complete set \[\{ (\langle M \rangle, 1^n, 1^t ) \mid
\text{ TM }M\text{ accepts an }x\in\{0,1\}^n\text{ within }t\text{ steps}\}.\]
If $t$ is large enough, then M accepts each word in $L(M)$ with length $n$
within $t$ steps. So, one can use methods from computability theory to show
that black box searching is the fastest way to find a solution. Therefore,
Grover's algorithm is optimal for NP-complete problems.
</p>
</div>
</dd>
<dt><a name="item2">[2]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05626" title="Abstract">arXiv:2311.05626</a> [<a href="/pdf/2311.05626" title="Download PDF">pdf</a>, <a href="/ps/2311.05626" title="Download PostScript">ps</a>, <a href="/format/2311.05626" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> L&#x27;origine de l&#x27;objectif est-elle importante? Effets motivationnels  d&#x27;objectifs autod{&#xe9;}finis en production
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Passalacqua%2C+M">Mario Passalacqua</a> (MAGI), 
<a href="/search/cs?searchtype=author&query=Pellerin%2C+R">Robert Pellerin</a> (MAGI), 
<a href="/search/cs?searchtype=author&query=Magnani%2C+F">Florian Magnani</a> (CERGAM), 
<a href="/search/cs?searchtype=author&query=Joblot%2C+L">Laurent Joblot</a> (LISPEN), 
<a href="/search/cs?searchtype=author&query=Yahia%2C+E">Esma Yahia</a> (LISPEN), 
<a href="/search/cs?searchtype=author&query=Rosin%2C+F">Fr&#xe9;d&#xe9;ric Rosin</a> (LAMIH), 
<a href="/search/cs?searchtype=author&query=L%C3%A9ger%2C+P">Pierre-Majorique L&#xe9;ger</a> (HEC Montr&#xe9;al)
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> in French language, CIGI QUALITA MOSIM 2023, Jun 2023, Trois Rivi{\`e}res, Canada
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>

</div>
<p class="mathjax">Only 21% of employees consider themselves engaged at work. Moreover,
disengagement has been shown to be even more problematic when work is
repetitive in nature. Lack of engagement has been linked to variety of negative
outcomes for employees and companies (e.g., turnover, absenteeism, well-being,
safety incidents, productivity). Gamification, i.e., integrating game elements
into work systems, has been successfully used to increase engagement and
motivation, even when work tasks were mundane and repetitive. In the current
study, we focused on a commonly used game element, goal setting, through the
lens of self-determination theory and goal-setting theory. We argue that goals
given by an external source (e.g., company, experimenter) produce extrinsic
motivation, which improves engagement and performance only in the short term.
We posit that self-set goals lead to more autonomous motivation, and therefore
long-term engagement and performance. One hundred two participants completed a
repetitive material-handling task in one of three conditions (assigned goal,
self-set goal, no goal). Results showed that perceived autonomy (autonomous
motivation) and performance were best when goals were self-set. Engagement,
however, was equal between self-set and assigned goals. The results indicate
that self-set goals have the greatest potential to generate long-term positive
outcomes both for employees and companies.
</p>
</div>
</dd>
<dt><a name="item3">[3]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05627" title="Abstract">arXiv:2311.05627</a> [<a href="/pdf/2311.05627" title="Download PDF">pdf</a>, <a href="/ps/2311.05627" title="Download PostScript">ps</a>, <a href="/format/2311.05627" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Understanding the Difference between Office Presence and Co-presence in  Team Member Interactions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Moe%2C+N+B">Nils Brede Moe</a>, 
<a href="/search/cs?searchtype=author&query=Ulsaker%2C+S">Simen Ulsaker</a>, 
<a href="/search/cs?searchtype=author&query=Smite%2C+D">Darja Smite</a>, 
<a href="/search/cs?searchtype=author&query=Hildrum%2C+J+M">Jarle Moss Hildrum</a>, 
<a href="/search/cs?searchtype=author&query=Ay%2C+F+C">Fehime Ceren Ay</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> the 57th Hawaii International Conference on System Sciences (Hicss 2024)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>

</div>
<p class="mathjax">Although the public health emergency related to the coronavirus disease 2019
(COVID-19) pandemic has officially ended, many software developers still work
partly from home. Agile teams that coordinate their office time foster a sense
of unity, collaboration, and cohesion among team members. In contrast, teams
with limited co-presence may experience challenges in establishing
psychological safety and developing a cohesive and inclusive team culture,
potentially hindering effective communication, knowledge sharing, and trust
building. Therefore, the effect of agile team members not being co-located
daily must be investigated. We explore the co-presence patterns of 17 agile
teams in a large agile telecommunications company whose employees work partly
from home. Based on office access card data, we found significant variation in
co-presence practices. Some teams exhibited a coordinated approach, ensuring
team members are simultaneously present at the office. However, other teams
demonstrated fragmented co-presence, with only small subgroups of members
meeting in person and the remainder rarely interacting with their team members
face-to-face. Thus, high average office presence in the team does not
necessarily imply that team members meet often in person at the office. In
contrast, non-coordinated teams may have both high average office presence and
low frequency of in-person interactions among the members. Our results suggest
that the promotion of mere office presence without coordinated co-presence is
based on a false assumption that good average attendance levels guarantee
frequent personal interactions. These findings carry important implications for
research on long-term team dynamics and practice.
</p>
</div>
</dd>
<dt><a name="item4">[4]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05628" title="Abstract">arXiv:2311.05628</a> [<a href="/pdf/2311.05628" title="Download PDF">pdf</a>, <a href="/ps/2311.05628" title="Download PostScript">ps</a>, <a href="/format/2311.05628" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Design and Development of Rubrics System for Android Applications
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kundu%2C+K">Kaustubh Kundu</a>, 
<a href="/search/cs?searchtype=author&query=Yadav%2C+S">Sushant Yadav</a>, 
<a href="/search/cs?searchtype=author&query=Sayyad%2C+T">Tayyabbali Sayyad</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> American Journal of Engineering Research (AJER)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>; Software Engineering (cs.SE)

</div>
<p class="mathjax">Online grading systems have become extremely prevalent as majority of
academic materials are in the process of being digitized, if not already done.
In this paper, we present the concept of design and implementation of a mobile
application for "Student Evaluation System", envisaged with the purpose of
making the task of evaluation of students performance by faculty and graders
facile. This application aims to provide an user-friendly interface for viewing
the students performance and has several functions which extends the Rubrics
with graphical analysis of students assignments. Rubrics evaluation system is
the widespread practice in both the software industry and the educational
institutes. Our application promises to make the grading system easier and to
enhance the effectiveness in terms of time and resources. This application also
allows the user/grader to keep track of submissions and the evaluated data in a
form that can be easily accessed and statistically analysed in a consistent
manner.
</p>
</div>
</dd>
<dt><a name="item5">[5]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05629" title="Abstract">arXiv:2311.05629</a> [<a href="/pdf/2311.05629" title="Download PDF">pdf</a>, <a href="/ps/2311.05629" title="Download PostScript">ps</a>, <a href="/format/2311.05629" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Experimental Evidence on Negative Impact of Generative AI on Scientific  Learning Outcomes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ju%2C+Q">Qirui Ju</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Pilot Working Paper
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL)

</div>
<p class="mathjax">In this study, I explored the impact of Generative AI on learning efficacy in
academic reading materials using experimental methods. College-educated
participants engaged in three cycles of reading and writing tasks. After each
cycle, they responded to comprehension questions related to the material. After
adjusting for background knowledge and demographic factors, complete reliance
on AI for writing tasks led to a 25.1% reduction in accuracy. In contrast,
AI-assisted reading resulted in a 12% decline. Interestingly, using AI for
summarization significantly improved both quality and output. Accuracy
exhibited notable variance in the AI-assisted section. Further analysis
revealed that individuals with a robust background in the reading topic and
superior reading/writing skills benefitted the most. I conclude the research by
discussing educational policy implications, emphasizing the need for educators
to warn students about the dangers of over-dependence on AI and provide
guidance on its optimal use in educational settings.
</p>
</div>
</dd>
<dt><a name="item6">[6]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05632" title="Abstract">arXiv:2311.05632</a> [<a href="/pdf/2311.05632" title="Download PDF">pdf</a>, <a href="/ps/2311.05632" title="Download PostScript">ps</a>, <a href="/format/2311.05632" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Impact of Performance Expectancy, Workload, Risk, and Satisfaction  on Trust in ChatGPT: Cross-sectional Survey Analysis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shamszare%2C+H">Hamid Shamszare</a>, 
<a href="/search/cs?searchtype=author&query=Choudhury%2C+A">Avishek Choudhury</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>; Artificial Intelligence (cs.AI); Human-Computer Interaction (cs.HC)

</div>
<p class="mathjax">This study investigated how perceived workload, satisfaction, performance
expectancy, and risk-benefit perception influenced users' trust in Chat
Generative Pre-Trained Transformer (ChatGPT). We aimed to understand the
nuances of user engagement and provide insights to improve future design and
adoption strategies for similar technologies. A semi-structured, web-based
survey was conducted among adults in the United States who actively use ChatGPT
at least once a month. The survey was conducted from 22nd February 2023 through
24th March 2023. We used structural equation modeling to understand the
relationships among the constructs of perceived workload, satisfaction,
performance expectancy, risk-benefit, and trust. The analysis of 607 survey
responses revealed a significant negative relationship between perceived
workload and user satisfaction, a negative but insignificant relationship
between perceived workload and trust, and a positive relationship between user
satisfaction and trust. Trust was also found to increase with performance
expectancy. In contrast, the relationship between the benefit-to-risk ratio of
using ChatGPT and trust was insignificant. The findings underscore the
importance of ensuring user-friendly design and functionality in AI-based
applications to reduce workload and enhance user satisfaction, thereby
increasing user trust. Future research should further explore the relationship
between the benefit-to-risk ratio and trust in the context of AI chatbots.
</p>
</div>
</dd>
<dt><a name="item7">[7]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05640" title="Abstract">arXiv:2311.05640</a> [<a href="/pdf/2311.05640" title="Download PDF">pdf</a>, <a href="/format/2311.05640" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FinGPT: Large Generative Models for a Small Language
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Luukkonen%2C+R">Risto Luukkonen</a>, 
<a href="/search/cs?searchtype=author&query=Komulainen%2C+V">Ville Komulainen</a>, 
<a href="/search/cs?searchtype=author&query=Luoma%2C+J">Jouni Luoma</a>, 
<a href="/search/cs?searchtype=author&query=Eskelinen%2C+A">Anni Eskelinen</a>, 
<a href="/search/cs?searchtype=author&query=Kanerva%2C+J">Jenna Kanerva</a>, 
<a href="/search/cs?searchtype=author&query=Kupari%2C+H">Hanna-Mari Kupari</a>, 
<a href="/search/cs?searchtype=author&query=Ginter%2C+F">Filip Ginter</a>, 
<a href="/search/cs?searchtype=author&query=Laippala%2C+V">Veronika Laippala</a>, 
<a href="/search/cs?searchtype=author&query=Muennighoff%2C+N">Niklas Muennighoff</a>, 
<a href="/search/cs?searchtype=author&query=Piktus%2C+A">Aleksandra Piktus</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+T">Thomas Wang</a>, 
<a href="/search/cs?searchtype=author&query=Tazi%2C+N">Nouamane Tazi</a>, 
<a href="/search/cs?searchtype=author&query=Scao%2C+T+L">Teven Le Scao</a>, 
<a href="/search/cs?searchtype=author&query=Wolf%2C+T">Thomas Wolf</a>, 
<a href="/search/cs?searchtype=author&query=Suominen%2C+O">Osma Suominen</a>, 
<a href="/search/cs?searchtype=author&query=Sairanen%2C+S">Samuli Sairanen</a>, 
<a href="/search/cs?searchtype=author&query=Merioksa%2C+M">Mikko Merioksa</a>, 
<a href="/search/cs?searchtype=author&query=Heinonen%2C+J">Jyrki Heinonen</a>, 
<a href="/search/cs?searchtype=author&query=Vahtola%2C+A">Aija Vahtola</a>, 
<a href="/search/cs?searchtype=author&query=Antao%2C+S">Samuel Antao</a>, 
<a href="/search/cs?searchtype=author&query=Pyysalo%2C+S">Sampo Pyysalo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 17 pages (10 main), 7 figures, 5 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Large language models (LLMs) excel in many tasks in NLP and beyond, but most
open models have very limited coverage of smaller languages and LLM work tends
to focus on languages where nearly unlimited data is available for pretraining.
In this work, we study the challenges of creating LLMs for Finnish, a language
spoken by less than 0.1% of the world population. We compile an extensive
dataset of Finnish combining web crawls, news, social media and eBooks. We
pursue two approaches to pretrain models: 1) we train seven monolingual models
from scratch (186M to 13B parameters) dubbed FinGPT, 2) we continue the
pretraining of the multilingual BLOOM model on a mix of its original training
data and Finnish, resulting in a 176 billion parameter model we call BLUUMI.
For model evaluation, we introduce FIN-bench, a version of BIG-bench with
Finnish tasks. We also assess other model qualities such as toxicity and bias.
Our models and tools are openly available at https://turkunlp.org/gpt3-finnish.
</p>
</div>
</dd>
<dt><a name="item8">[8]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05642" title="Abstract">arXiv:2311.05642</a> [<a href="/pdf/2311.05642" title="Download PDF">pdf</a>, <a href="/ps/2311.05642" title="Download PostScript">ps</a>, <a href="/format/2311.05642" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A protein network refinement method based on module discovery and  biological information
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pan%2C+L">Li Pan</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Haoyue Wang</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+J">Jing Sun</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+B">Bin Li</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+B">Bo Yang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+W">Wenbin Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Engineering, Finance, and Science (cs.CE)</span>

</div>
<p class="mathjax">The identification of essential proteins can help in understanding the
minimum requirements for cell survival and development. Network-based
centrality approaches are commonly used to identify essential proteins from
protein-protein interaction networks (PINs). Unfortunately, these approaches
are limited by the poor quality of the underlying PIN data. To overcome this
problem, researchers have focused on the prediction of essential proteins by
combining PINs with other biological data. In this paper, we proposed a network
refinement method based on module discovery and biological information to
obtain a higher quality PIN. First, to extract the maximal connected subgraph
in the PIN and to divide it into different modules by using Fast-unfolding
algorithm; then, to detect critical modules based on the homology information,
subcellular localization information and topology information within each
module, and to construct a more refined network (CM-PIN). To evaluate the
effectiveness of the proposed method, we used 10 typical network-based
centrality methods (LAC, DC, DMNC, NC, TP, LID, CC, BC, PR, LR) to compare the
overall performance of the CM-PIN with those the refined dynamic protein
network (RD-PIN). The experimental results showed that the CM-PIN was optimal
in terms of precision-recall curve, jackknife curve and other criteria, and can
help to identify essential proteins more accurately.
</p>
</div>
</dd>
<dt><a name="item9">[9]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05643" title="Abstract">arXiv:2311.05643</a> [<a href="/pdf/2311.05643" title="Download PDF">pdf</a>, <a href="/format/2311.05643" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fundamentally New Coupled Approach to Contact Mechanics via the  Dirichlet-Neumann Schwarz Alternating Method
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mota%2C+A">A. Mota</a>, 
<a href="/search/cs?searchtype=author&query=Koliesnikova%2C+D">D. Koliesnikova</a>, 
<a href="/search/cs?searchtype=author&query=Tezaur%2C+I">I. Tezaur</a>, 
<a href="/search/cs?searchtype=author&query=Hoy%2C+J">J. Hoy</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Engineering, Finance, and Science (cs.CE)</span>; Analysis of PDEs (math.AP); Numerical Analysis (math.NA)

</div>
<p class="mathjax">Contact phenomena are essential in understanding the behavior of mechanical
systems. Existing computational approaches for simulating mechanical contact
often encounter numerical issues, such as inaccurate physical predictions,
energy conservation errors, and unwanted oscillations. We introduce an
alternative technique, rooted in the non-overlapping Schwarz alternating
method, originally developed for domain decomposition. In multi-body contact
scenarios, this method treats each body as a separate, non-overlapping domain
and prevents interpenetration using an alternating Dirichlet-Neumann iterative
process. This approach has a strong theoretical foundation, eliminates the need
for contact constraints, and offers flexibility, making it well-suited for
multiscale and multi-physics applications.
<br />We conducted a numerical comparison between the Schwarz method and
traditional methods like Lagrange multiplier and penalty methods, focusing on a
benchmark impact problem. Our results indicate that the Schwarz alternating
method surpasses traditional methods in several key areas: it provides more
accurate predictions for various measurable quantities and demonstrates
exceptional energy conservation capabilities. To address the issue of unwanted
oscillations in contact velocities and forces, we explored various algorithms
and stabilization techniques, ultimately opting for the naive-stabilized
Newmark scheme for its simplicity and effectiveness. Furthermore, we validated
the efficiency of the Schwarz method in a three-dimensional impact problem,
highlighting its innate capacity to accommodate different mesh topologies, time
integration schemes, and time steps for each interacting body.
</p>
</div>
</dd>
<dt><a name="item10">[10]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05646" title="Abstract">arXiv:2311.05646</a> [<a href="/pdf/2311.05646" title="Download PDF">pdf</a>, <a href="/format/2311.05646" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Automatic differentiation accelerated shape optimization approaches to  photonic inverse design on rectilinear simulation grids
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hooten%2C+S">Sean Hooten</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+P">Peng Sun</a>, 
<a href="/search/cs?searchtype=author&query=Gantz%2C+L">Liron Gantz</a>, 
<a href="/search/cs?searchtype=author&query=Fiorentino%2C+M">Marco Fiorentino</a>, 
<a href="/search/cs?searchtype=author&query=Beausoleil%2C+R+G">Raymond G. Beausoleil</a>, 
<a href="/search/cs?searchtype=author&query=Van+Vaerenbergh%2C+T">Thomas Van Vaerenbergh</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 29 pages, 15 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Engineering, Finance, and Science (cs.CE)</span>; Optics (physics.optics)

</div>
<p class="mathjax">Shape optimization approaches to inverse design offer low-dimensional,
physically-guided parameterizations of structures by representing them as
combinations of shape primitives. However, on discretized rectilinear
simulation grids, computing the gradient of a user objective via the adjoint
variables method requires a sum reduction of the forward/adjoint field
solutions and the Jacobian of the simulation material distribution with respect
to the structural shape parameters. These shape parameters often perturb large
or global parts of the simulation grid resulting in many non-zero Jacobian
entries, which are typically computed by finite-difference in practice.
Consequently, the gradient calculation can be non-trivial. In this work we
propose to accelerate the gradient calculation by invoking automatic
differentiation (AutoDiff) in instantiations of structural material
distributions. In doing so, we develop extensible differentiable mappings from
shape parameters to shape primitives and differentiable effective logic
operations (denoted AutoDiffGeo). These AutoDiffGeo definitions may introduce
some additional discretization error into the field solutions because they
relax notions of sub-pixel smoothing along shape boundaries. However, we show
that some mappings (e.g. simple cuboids) can achieve zero error with respect to
volumetric averaging strategies. We demonstrate AutoDiff enhanced shape
optimization using three integrated photonic examples: a multi-etch blazed
grating coupler, a non-adiabatic waveguide transition taper, and a
polarization-splitting grating coupler. We find accelerations of the gradient
calculation by AutoDiff relative to finite-difference often exceed 50x,
resulting in total wall time accelerations of 4x or more on the same hardware
with little or no compromise to final device performance. Our code is available
open source at https://github.com/smhooten/emopt
</p>
</div>
</dd>
<dt><a name="item11">[11]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05647" title="Abstract">arXiv:2311.05647</a> [<a href="/pdf/2311.05647" title="Download PDF">pdf</a>, <a href="/ps/2311.05647" title="Download PostScript">ps</a>, <a href="/format/2311.05647" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the density of primes of the form $X^2+c$
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wolf%2C+M">Marc Wolf</a>, 
<a href="/search/cs?searchtype=author&query=Wolf%2C+F">Fran&#xe7;ois Wolf</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 25 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>

</div>
<p class="mathjax">We present a method for finding large fixed-size primes of the form $X^2+c$.
We study the density of primes on the sets $E_c = \{N(X,c)=X^2+c,\ X \in
(2\mathbb{Z}+(c-1))\}$, $c \in \mathbb{N}^*$. We describe an algorithm for
generating values of $c$ such that a given prime $p$ is the minimum of the
union of prime divisors of all elements in $E_c$. We also present quadratic
forms generating divisors of Ec and study the prime divisors of its terms. This
paper uses the results of Dirichlet's arithmetic progression theorem [1] and
the article [6] to rewrite a conjecture of Shanks [2] on the density of primes
in $E_c$. Finally, based on these results, we discuss the heuristics of large
primes occurrences in the research set of our algorithm.
</p>
</div>
</dd>
<dt><a name="item12">[12]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05648" title="Abstract">arXiv:2311.05648</a> [<a href="/pdf/2311.05648" title="Download PDF">pdf</a>, <a href="/ps/2311.05648" title="Download PostScript">ps</a>, <a href="/format/2311.05648" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Risk Management of Unmanned Aerial Vehicles
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Naji%2C+H+R">Hamid Reza Naji</a>, 
<a href="/search/eess?searchtype=author&query=Ayari%2C+A">Aref Ayari</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Cryptography and Security (cs.CR)

</div>
<p class="mathjax">This paper presents an efficient risk management model for unmanned aerial
vehicles or UAVs. Our proposed risk management establishes a cyclic model with
a continuous and iterative structure that is very adaptable to agile methods
and all IT-related resources. This model can be used in many applications, but
as a case study, we have discussed it for UAVs. The increasing use of UAVs or
drones in many fields and the existence of different threats is the main reason
to have an efficient risk management method for them. In this paper, we cover
risks based on IT-driven assets to decrease the chance of losing any data,
failing the equipment or the system, and missing the reputation or credit based
on cyclic and iterative flow. Our current risk management model for UAVs or
drones is based on qualitative measures and can cover most of IT-based risks.
</p>
</div>
</dd>
<dt><a name="item13">[13]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05651" title="Abstract">arXiv:2311.05651</a> [<a href="/pdf/2311.05651" title="Download PDF">pdf</a>, <a href="/format/2311.05651" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On Mergable Coresets for Polytope Distance
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shi%2C+B">Benwei Shi</a>, 
<a href="/search/cs?searchtype=author&query=Bhaskara%2C+A">Aditya Bhaskara</a>, 
<a href="/search/cs?searchtype=author&query=Tai%2C+W+M">Wai Ming Tai</a>, 
<a href="/search/cs?searchtype=author&query=Phillips%2C+J+M">Jeff M. Phillips</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Presented in SoCG'19 Young Researchers Forum (CG:YRF)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Geometry (cs.CG)</span>; Data Structures and Algorithms (cs.DS); Machine Learning (cs.LG)

</div>
<p class="mathjax">We show that a constant-size constant-error coreset for polytope distance is
simple to maintain under merges of coresets. However, increasing the size
cannot improve the error bound significantly beyond that constant.
</p>
</div>
</dd>
<dt><a name="item14">[14]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05653" title="Abstract">arXiv:2311.05653</a> [<a href="/pdf/2311.05653" title="Download PDF">pdf</a>, <a href="/ps/2311.05653" title="Download PostScript">ps</a>, <a href="/format/2311.05653" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Minimal Input Structural Modifications for Strongly Structural  Controllability
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Joseph%2C+G">Geethu Joseph</a>, 
<a href="/search/eess?searchtype=author&query=Moothedath%2C+S">Shana Moothedath</a>, 
<a href="/search/eess?searchtype=author&query=Lin%2C+J">Jiabin Lin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">This paper studies the problem of modifying the input matrix of a structured
system to make the system strongly structurally controllable. We focus on the
generalized structured systems that rely on zero/nonzero/arbitrary structure,
i.e., some entries of system matrices are zeros, some are nonzero, and the
remaining entries can be zero or nonzero (arbitrary). Our first approach to
finding minimal changes is a greedy heuristic, which is simple to implement and
fast. However, we also show that the greedy algorithm can give arbitrarily poor
solutions for some special systems. The second approach is a randomized Markov
chain Monte Carlo-based algorithm. Unlike the greedy algorithm, this algorithm
is always guaranteed to converge to an optimal solution. Finally, we
numerically evaluate the algorithms' performances on random graphs to show that
the algorithms perform well.
</p>
</div>
</dd>
<dt><a name="item15">[15]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05655" title="Abstract">arXiv:2311.05655</a> [<a href="/pdf/2311.05655" title="Download PDF">pdf</a>, <a href="/format/2311.05655" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fuzzy Ensembles of Reinforcement Learning Policies for Robotic Systems  with Varied Parameters
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Haddad%2C+A+G">Abdel Gafoor Haddad</a>, 
<a href="/search/cs?searchtype=author&query=Mohiuddin%2C+M+B">Mohammed B. Mohiuddin</a>, 
<a href="/search/cs?searchtype=author&query=Boiko%2C+I">Igor Boiko</a>, 
<a href="/search/cs?searchtype=author&query=Zweiri%2C+Y">Yahya Zweiri</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: text overlap with <a href="/abs/2311.05013">arXiv:2311.05013</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Systems and Control (eess.SY)

</div>
<p class="mathjax">Reinforcement Learning (RL) is an emerging approach to control many dynamical
systems for which classical control approaches are not applicable or
insufficient. However, the resultant policies may not generalize to variations
in the parameters that the system may exhibit. This paper presents a powerful
yet simple algorithm in which collaboration is facilitated between RL agents
that are trained independently to perform the same task but with different
system parameters. The independency among agents allows the exploitation of
multi-core processing to perform parallel training. Two examples are provided
to demonstrate the effectiveness of the proposed technique. The main
demonstration is performed on a quadrotor with slung load tracking problem in a
real-time experimental setup. It is shown that integrating the developed
algorithm outperforms individual policies by reducing the RMSE tracking error.
The robustness of the ensemble is also verified against wind disturbance.
</p>
</div>
</dd>
<dt><a name="item16">[16]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05656" title="Abstract">arXiv:2311.05656</a> [<a href="/pdf/2311.05656" title="Download PDF">pdf</a>, <a href="/format/2311.05656" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Combating Misinformation in the Age of LLMs: Opportunities and  Challenges
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+C">Canyu Chen</a>, 
<a href="/search/cs?searchtype=author&query=Shu%2C+K">Kai Shu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages for the main paper, 35 pages including 656 references, more resources on "LLMs Meet Misinformation" are on the website: <a href="https://llm-misinformation.github.io/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>

</div>
<p class="mathjax">Misinformation such as fake news and rumors is a serious threat on
information ecosystems and public trust. The emergence of Large Language Models
(LLMs) has great potential to reshape the landscape of combating
misinformation. Generally, LLMs can be a double-edged sword in the fight. On
the one hand, LLMs bring promising opportunities for combating misinformation
due to their profound world knowledge and strong reasoning abilities. Thus, one
emergent question is: how to utilize LLMs to combat misinformation? On the
other hand, the critical challenge is that LLMs can be easily leveraged to
generate deceptive misinformation at scale. Then, another important question
is: how to combat LLM-generated misinformation? In this paper, we first
systematically review the history of combating misinformation before the advent
of LLMs. Then we illustrate the current efforts and present an outlook for
these two fundamental questions respectively. The goal of this survey paper is
to facilitate the progress of utilizing LLMs for fighting misinformation and
call for interdisciplinary efforts from different stakeholders for combating
LLM-generated misinformation.
</p>
</div>
</dd>
<dt><a name="item17">[17]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05657" title="Abstract">arXiv:2311.05657</a> [<a href="/pdf/2311.05657" title="Download PDF">pdf</a>, <a href="/format/2311.05657" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Lumos: Learning Agents with Unified Data, Modular Design, and  Open-Source LLMs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yin%2C+D">Da Yin</a>, 
<a href="/search/cs?searchtype=author&query=Brahman%2C+F">Faeze Brahman</a>, 
<a href="/search/cs?searchtype=author&query=Ravichander%2C+A">Abhilasha Ravichander</a>, 
<a href="/search/cs?searchtype=author&query=Chandu%2C+K">Khyathi Chandu</a>, 
<a href="/search/cs?searchtype=author&query=Chang%2C+K">Kai-Wei Chang</a>, 
<a href="/search/cs?searchtype=author&query=Choi%2C+Y">Yejin Choi</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+B+Y">Bill Yuchen Lin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project website: <a href="https://allenai.github.io/lumos/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computation and Language (cs.CL); Machine Learning (cs.LG)

</div>
<p class="mathjax">We introduce Lumos, a novel framework for training language agents that
employs a unified data format and a modular architecture based on open-source
large language models (LLMs). Lumos consists of three distinct modules:
planning, grounding, and execution. The planning module breaks down a task into
a series of high-level, tool-agnostic subgoals, which are then made specific by
the grounding module through a set of low-level actions. These actions are
subsequently executed by the execution module, utilizing a range of
off-the-shelf tools and APIs. In order to train these modules effectively,
high-quality annotations of subgoals and actions were collected and are made
available for fine-tuning open-source LLMs for various tasks such as complex
question answering, web tasks, and math problems. Leveraging this unified data
and modular design, Lumos not only achieves comparable or superior performance
to current, state-of-the-art agents, but also exhibits several key advantages:
(1) Lumos surpasses GPT-4/3.5-based agents in complex question answering and
web tasks, while equalling the performance of significantly larger LLM agents
on math tasks; (2) Lumos outperforms open-source agents created through
conventional training methods and those using chain-of-thoughts training; and
(3) Lumos is capable of effectively generalizing to unseen interactive tasks,
outperforming larger LLM-based agents and even exceeding performance of
specialized agents.
</p>
</div>
</dd>
<dt><a name="item18">[18]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05658" title="Abstract">arXiv:2311.05658</a> [<a href="/pdf/2311.05658" title="Download PDF">pdf</a>, <a href="/ps/2311.05658" title="Download PostScript">ps</a>, <a href="/format/2311.05658" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Three non-cubical applications of extension types
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+T">Tesla Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Programming Languages (cs.PL)</span>

</div>
<p class="mathjax">The development of cubical type theory inspired the idea of "extension types"
which has been found to have applications in other type theories that are
unrelated to homotopy type theory or cubical type theory.
<br />This article describes these applications, including on records,
metaprogramming, controlling unfolding, and some more exotic ones.
</p>
</div>
</dd>
<dt><a name="item19">[19]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05659" title="Abstract">arXiv:2311.05659</a> [<a href="/pdf/2311.05659" title="Download PDF">pdf</a>, <a href="/format/2311.05659" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Enhancing Instance-Level Image Classification with Set-Level Labels
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+R">Renyu Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Khan%2C+A+A">Aly A. Khan</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yuxin Chen</a>, 
<a href="/search/cs?searchtype=author&query=Grossman%2C+R+L">Robert L. Grossman</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Instance-level image classification tasks have traditionally relied on
single-instance labels to train models, e.g., few-shot learning and transfer
learning. However, set-level coarse-grained labels that capture relationships
among instances can provide richer information in real-world scenarios. In this
paper, we present a novel approach to enhance instance-level image
classification by leveraging set-level labels. We provide a theoretical
analysis of the proposed method, including recognition conditions for fast
excess risk rate, shedding light on the theoretical foundations of our
approach. We conducted experiments on two distinct categories of datasets:
natural image datasets and histopathology image datasets. Our experimental
results demonstrate the effectiveness of our approach, showcasing improved
classification performance compared to traditional single-instance label-based
methods. Notably, our algorithm achieves 13% improvement in classification
accuracy compared to the strongest baseline on the histopathology image
classification benchmarks. Importantly, our experimental findings align with
the theoretical analysis, reinforcing the robustness and reliability of our
proposed method. This work bridges the gap between instance-level and set-level
image classification, offering a promising avenue for advancing the
capabilities of image classification models with set-level coarse-grained
labels.
</p>
</div>
</dd>
<dt><a name="item20">[20]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05661" title="Abstract">arXiv:2311.05661</a> [<a href="/pdf/2311.05661" title="Download PDF">pdf</a>, <a href="/format/2311.05661" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Prompt Engineering a Prompt Engineer
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ye%2C+Q">Qinyuan Ye</a>, 
<a href="/search/cs?searchtype=author&query=Axmed%2C+M">Maxamed Axmed</a>, 
<a href="/search/cs?searchtype=author&query=Pryzant%2C+R">Reid Pryzant</a>, 
<a href="/search/cs?searchtype=author&query=Khani%2C+F">Fereshte Khani</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Prompt engineering is a challenging yet crucial task for optimizing the
performance of large language models (LLMs). It requires complex reasoning to
examine the model's errors, hypothesize what is missing or misleading in the
current prompt, and communicate the task with clarity. While recent works
indicate that LLMs can be meta-prompted to perform automatic prompt
engineering, their potentials may not be fully untapped due to the lack of
sufficient guidance to elicit complex reasoning capabilities in LLMs in the
meta-prompt. In this work, we investigate the problem of "prompt engineering a
prompt engineer" -- constructing a meta-prompt that more effectively guides
LLMs to perform automatic prompt engineering. We introduce and analyze key
components, such as a step-by-step reasoning template and context
specification, which lead to improved performance. In addition, inspired by
common optimization concepts such as batch size, step size and momentum, we
introduce their verbalized counterparts to the meta-prompt and investigate
their effects. Our final method, named PE2, finds a prompt that outperforms
"let's think step by step" by 6.3% on the MultiArith dataset and 3.1% on the
GSM8K dataset. To demonstrate its versatility, we apply PE2 to the Instruction
Induction benchmark, a suite of counterfactual tasks, and a lengthy, real-world
industrial prompt. In these settings, PE2 achieves strong performance and
outperforms prior automatic prompt engineering baselines. Further, we show that
PE2 makes meaningful and targeted prompt edits, amends erroneous or incomplete
prompts, and presents non-trivial counterfactual reasoning abilities.
</p>
</div>
</dd>
<dt><a name="item21">[21]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05662" title="Abstract">arXiv:2311.05662</a> [<a href="/pdf/2311.05662" title="Download PDF">pdf</a>, <a href="/format/2311.05662" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An Experiment in Retrofitting Competency Questions for Existing  Ontologies
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Alharbi%2C+R">Reham Alharbi</a>, 
<a href="/search/cs?searchtype=author&query=Tamma%2C+V">Valentina Tamma</a>, 
<a href="/search/cs?searchtype=author&query=Grasso%2C+F">Floriana Grasso</a>, 
<a href="/search/cs?searchtype=author&query=Payne%2C+T">Terry Payne</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
<p class="mathjax">Competency Questions (CQs) are a form of ontology functional requirements
expressed as natural language questions. Inspecting CQs together with the
axioms in an ontology provides critical insights into the intended scope and
applicability of the ontology. CQs also underpin a number of tasks in the
development of ontologies e.g. ontology reuse, ontology testing, requirement
specification, and the definition of patterns that implement such requirements.
Although CQs are integral to the majority of ontology engineering
methodologies, the practice of publishing CQs alongside the ontological
artefacts is not widely observed by the community. In this context, we present
an experiment in retrofitting CQs from existing ontologies. We propose
RETROFIT-CQs, a method to extract candidate CQs directly from ontologies using
Generative AI. In the paper we present the pipeline that facilitates the
extraction of CQs by leveraging Large Language Models (LLMs) and we discuss its
application to a number of existing ontologies.
</p>
</div>
</dd>
<dt><a name="item22">[22]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05665" title="Abstract">arXiv:2311.05665</a> [<a href="/pdf/2311.05665" title="Download PDF">pdf</a>, <a href="/ps/2311.05665" title="Download PostScript">ps</a>, <a href="/format/2311.05665" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Explainable artificial intelligence for Healthcare applications using  Random Forest Classifier with LIME and SHAP
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Panda%2C+M">Mrutyunjaya Panda</a>, 
<a href="/search/cs?searchtype=author&query=Mahanta%2C+S+R">Soumya Ranjan Mahanta</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Chapter-6: Accepted Book Chapter in: Transparent, Interpretable and Explainable AI Systems, BK Tripathy &amp; Hari Seetha (Editors), CRC Press, May 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computers and Society (cs.CY)

</div>
<p class="mathjax">With the advances in computationally efficient artificial Intelligence (AI)
techniques and their numerous applications in our everyday life, there is a
pressing need to understand the computational details hidden in black box AI
techniques such as most popular machine learning and deep learning techniques;
through more detailed explanations. The origin of explainable AI (xAI) is
coined from these challenges and recently gained more attention by the
researchers by adding explainability comprehensively in traditional AI systems.
This leads to develop an appropriate framework for successful applications of
xAI in real life scenarios with respect to innovations, risk mitigation,
ethical issues and logical values to the users. In this book chapter, an
in-depth analysis of several xAI frameworks and methods including LIME (Local
Interpretable Model-agnostic Explanations) and SHAP (SHapley Additive
exPlanations) are provided. Random Forest Classifier as black box AI is used on
a publicly available Diabetes symptoms dataset with LIME and SHAP for better
interpretations. The results obtained are interesting in terms of transparency,
valid and trustworthiness in diabetes disease prediction.
</p>
</div>
</dd>
<dt><a name="item23">[23]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05667" title="Abstract">arXiv:2311.05667</a> [<a href="/pdf/2311.05667" title="Download PDF">pdf</a>, <a href="/format/2311.05667" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A theory for the sparsity emerged in the Forward Forward algorithm
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yukun Yang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">This report explores the theory that explains the high sparsity phenomenon
\citep{tosato2023emergent} observed in the forward-forward algorithm
\citep{hinton2022forward}. The two theorems proposed predict the sparsity
changes of a single data point's activation in two cases: Theorem
\ref{theorem:1}: Decrease the goodness of the whole batch. Theorem
\ref{theorem:2}: Apply the complete forward forward algorithm to decrease the
goodness for negative data and increase the goodness for positive data. The
theory aligns well with the experiments tested on the MNIST dataset.
</p>
</div>
</dd>
<dt><a name="item24">[24]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05669" title="Abstract">arXiv:2311.05669</a> [<a href="/pdf/2311.05669" title="Download PDF">pdf</a>, <a href="/format/2311.05669" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multi-Modal Gaze Following in Conversational Scenarios
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hou%2C+Y">Yuqi Hou</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zhongqun Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Horanyi%2C+N">Nora Horanyi</a>, 
<a href="/search/cs?searchtype=author&query=Moon%2C+J">Jaewon Moon</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+Y">Yihua Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Chang%2C+H+J">Hyung Jin Chang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Gaze following estimates gaze targets of in-scene person by understanding
human behavior and scene information. Existing methods usually analyze scene
images for gaze following. However, compared with visual images, audio also
provides crucial cues for determining human behavior.This suggests that we can
further improve gaze following considering audio cues. In this paper, we
explore gaze following tasks in conversational scenarios. We propose a novel
multi-modal gaze following framework based on our observation ``audiences tend
to focus on the speaker''. We first leverage the correlation between audio and
lips, and classify speakers and listeners in a scene. We then use the identity
information to enhance scene images and propose a gaze candidate estimation
network. The network estimates gaze candidates from enhanced scene images and
we use MLP to match subjects with candidates as classification tasks. Existing
gaze following datasets focus on visual images while ignore audios.To evaluate
our method, we collect a conversational dataset, VideoGazeSpeech (VGS), which
is the first gaze following dataset including images and audio. Our method
significantly outperforms existing methods in VGS datasets. The visualization
result also prove the advantage of audio cues in gaze following tasks. Our work
will inspire more researches in multi-modal gaze following estimation.
</p>
</div>
</dd>
<dt><a name="item25">[25]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05698" title="Abstract">arXiv:2311.05698</a> [<a href="/pdf/2311.05698" title="Download PDF">pdf</a>, <a href="/format/2311.05698" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Mirasol3B: A Multimodal Autoregressive model for time-aligned and  contextual modalities
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Piergiovanni%2C+A">AJ Piergiovanni</a>, 
<a href="/search/cs?searchtype=author&query=Nobel%2C+I">Isaac Nobel</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+D">Dahun Kim</a>, 
<a href="/search/cs?searchtype=author&query=Ryoo%2C+M+S">Michael S. Ryoo</a>, 
<a href="/search/cs?searchtype=author&query=Gomes%2C+V">Victor Gomes</a>, 
<a href="/search/cs?searchtype=author&query=Angelova%2C+A">Anelia Angelova</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">One of the main challenges of multimodal learning is the need to combine
heterogeneous modalities (e.g., video, audio, text). For example, video and
audio are obtained at much higher rates than text and are roughly aligned in
time. They are often not synchronized with text, which comes as a global
context, e.g., a title, or a description. Furthermore, video and audio inputs
are of much larger volumes, and grow as the video length increases, which
naturally requires more compute dedicated to these modalities and makes
modeling of long-range dependencies harder.
<br />We here decouple the multimodal modeling, dividing it into separate, focused
autoregressive models, processing the inputs according to the characteristics
of the modalities. We propose a multimodal model, called Mirasol3B, consisting
of an autoregressive component for the time-synchronized modalities (audio and
video), and an autoregressive component for the context modalities which are
not necessarily aligned in time but are still sequential. To address the
long-sequences of the video-audio inputs, we propose to further partition the
video and audio sequences in consecutive snippets and autoregressively process
their representations. To that end, we propose a Combiner mechanism, which
models the audio-video information jointly within a timeframe. The Combiner
learns to extract audio and video features from raw spatio-temporal signals,
and then learns to fuse these features producing compact but expressive
representations per snippet.
<br />Our approach achieves the state-of-the-art on well established multimodal
benchmarks, outperforming much larger models. It effectively addresses the high
computational demand of media inputs by both learning compact representations,
controlling the sequence length of the audio-video feature representations, and
modeling their dependencies in time.
</p>
</div>
</dd>
<dt><a name="item26">[26]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05705" title="Abstract">arXiv:2311.05705</a> [<a href="/pdf/2311.05705" title="Download PDF">pdf</a>, <a href="/format/2311.05705" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Achieving Maximum Utilization in Optimal Time for Learning or  Convergence in the Kolkata Paise Restaurant Problem
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Biswas%2C+A">Aniruddha Biswas</a>, 
<a href="/search/cs?searchtype=author&query=Sinha%2C+A">Antika Sinha</a>, 
<a href="/search/cs?searchtype=author&query=Chakrabarti%2C+B+K">Bikas K. Chakrabarti</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 6 figures included in manuscript; submitted to Indian Journal of Physics
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>; Physics and Society (physics.soc-ph)

</div>
<p class="mathjax">In the original version of the Kolkata Paise Restaurant (KPR) problem, where
each of the $N$ agents (or players) choose independently every day (updating
their strategy based on past experience of failures) among the $N$ restaurants,
where he/she will be alone or lucky enough to be picked up randomly from the
crowd who arrived at that restaurant that day, to get the only food plate
served there. The objective of the agents are to learn themselves in the
minimum (learning) time to have maximum success or utilization probability
($f$). A dictator can easily solve the problem with $f = 1$ in no time, by
asking every one to form a queue and go to the respective restaurant, resulting
in no fluctuation and full utilization from the first day (convergence time
$\tau = 0$). It has already been shown that if each agent chooses randomly the
restaurants, $f = 1 - e^{-1} \simeq 0.63$ and $\tau = 0$, while the crowd
avoiding (CA) strategy (determined by yesterday's crowd size at the chosen
restaurant) gives ($f \simeq 0.80$) in finite (of order ten) convergence time
($\tau$). Many numerical studies of modified learning strategies, actually
indicated increased value of $f = 1 - \alpha$ for $\alpha \to 0$, with $\tau
\sim 1/\alpha$. We show here using Monte Carlo technique, a modified Greedy
Crowd Avoiding (GCA) Strategy can assure full utilization ($f = 1$) in
convergence time $\tau = e N$, where $e$ denotes the Euler number. This
observation perhaps suggests that using non-dictated strategies for KPR, full
utilization can never be collectively learned or achieved in finite convergence
time, when $N$, the number of customers or of restaurants goes to infinity.
</p>
</div>
</dd>
<dt><a name="item27">[27]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05707" title="Abstract">arXiv:2311.05707</a> [<a href="/pdf/2311.05707" title="Download PDF">pdf</a>, <a href="/format/2311.05707" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FMViT: A multiple-frequency mixing Vision Transformer
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tan%2C+W">Wei Tan</a>, 
<a href="/search/cs?searchtype=author&query=Geng%2C+Y">Yifeng Geng</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+X">Xuansong Xie</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">The transformer model has gained widespread adoption in computer vision tasks
in recent times. However, due to the quadratic time and memory complexity of
self-attention, which is proportional to the number of input tokens, most
existing Vision Transformers (ViTs) encounter challenges in achieving efficient
performance in practical industrial deployment scenarios, such as TensorRT and
CoreML, where traditional CNNs excel. Although some recent attempts have been
made to design CNN-Transformer hybrid architectures to tackle this problem,
their overall performance has not met expectations. To tackle these challenges,
we propose an efficient hybrid ViT architecture named FMViT. This approach
enhances the model's expressive power by blending high-frequency features and
low-frequency features with varying frequencies, enabling it to capture both
local and global information effectively. Additionally, we introduce
deploy-friendly mechanisms such as Convolutional Multigroup Reparameterization
(gMLP), Lightweight Multi-head Self-Attention (RLMHSA), and Convolutional
Fusion Block (CFB) to further improve the model's performance and reduce
computational overhead. Our experiments demonstrate that FMViT surpasses
existing CNNs, ViTs, and CNNTransformer hybrid architectures in terms of
latency/accuracy trade-offs for various vision tasks. On the TensorRT platform,
FMViT outperforms Resnet101 by 2.5% (83.3% vs. 80.8%) in top-1 accuracy on the
ImageNet dataset while maintaining similar inference latency. Moreover, FMViT
achieves comparable performance with EfficientNet-B5, but with a 43%
improvement in inference speed. On CoreML, FMViT outperforms MobileOne by 2.6%
in top-1 accuracy on the ImageNet dataset, with inference latency comparable to
MobileOne (78.5% vs. 75.9%). Our code can be found at
https://github.com/tany0699/FMViT.
</p>
</div>
</dd>
<dt><a name="item28">[28]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05708" title="Abstract">arXiv:2311.05708</a> [<a href="/pdf/2311.05708" title="Download PDF">pdf</a>, <a href="/format/2311.05708" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Intelligent Cervical Spine Fracture Detection Using Deep Learning  Methods
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nejad%2C+R+B">Reza Behbahani Nejad</a>, 
<a href="/search/cs?searchtype=author&query=Komijani%2C+A+H">Amir Hossein Komijani</a>, 
<a href="/search/cs?searchtype=author&query=Najafi%2C+E">Esmaeil Najafi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Cervical spine fractures constitute a critical medical emergency, with the
potential for lifelong paralysis or even fatality if left untreated or
undetected. Over time, these fractures can deteriorate without intervention. To
address the lack of research on the practical application of deep learning
techniques for the detection of spine fractures, this study leverages a dataset
containing both cervical spine fractures and non-fractured computed tomography
images. This paper introduces a two-stage pipeline designed to identify the
presence of cervical vertebrae in each image slice and pinpoint the location of
fractures. In the first stage, a multi-input network, incorporating image and
image metadata, is trained. This network is based on the Global Context Vision
Transformer, and its performance is benchmarked against popular deep learning
image classification model. In the second stage, a YOLOv8 model is trained to
detect fractures within the images, and its effectiveness is compared to
YOLOv5. The obtained results indicate that the proposed algorithm significantly
reduces the workload of radiologists and enhances the accuracy of fracture
detection.
</p>
</div>
</dd>
<dt><a name="item29">[29]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05709" title="Abstract">arXiv:2311.05709</a> [<a href="/pdf/2311.05709" title="Download PDF">pdf</a>, <a href="/ps/2311.05709" title="Download PostScript">ps</a>, <a href="/format/2311.05709" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> OmniVec: Learning robust representations with cross modal sharing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Srivastava%2C+S">Siddharth Srivastava</a>, 
<a href="/search/cs?searchtype=author&query=Sharma%2C+G">Gaurav Sharma</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to WACV 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Majority of research in learning based methods has been towards designing and
training networks for specific tasks. However, many of the learning based
tasks, across modalities, share commonalities and could be potentially tackled
in a joint framework. We present an approach in such direction, to learn
multiple tasks, in multiple modalities, with a unified architecture. The
proposed network is composed of task specific encoders, a common trunk in the
middle, followed by task specific prediction heads. We first pre-train it by
self-supervised masked training, followed by sequential training for the
different tasks. We train the network on all major modalities, e.g.\ visual,
audio, text and 3D, and report results on $22$ diverse and challenging public
benchmarks. We demonstrate empirically that, using a joint network to train
across modalities leads to meaningful information sharing and this allows us to
achieve state-of-the-art results on most of the benchmarks. We also show
generalization of the trained network on cross-modal tasks as well as unseen
datasets and tasks.
</p>
</div>
</dd>
<dt><a name="item30">[30]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05716" title="Abstract">arXiv:2311.05716</a> [<a href="/pdf/2311.05716" title="Download PDF">pdf</a>, <a href="/format/2311.05716" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ML-based Real-Time Control at the Edge: An Approach Using hls4ml
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shi%2C+R">R. Shi</a>, 
<a href="/search/cs?searchtype=author&query=Ogrenci%2C+S">S. Ogrenci</a>, 
<a href="/search/cs?searchtype=author&query=Arnold%2C+J+M">J.M. Arnold</a>, 
<a href="/search/cs?searchtype=author&query=Berlioz%2C+J+R">J.R. Berlioz</a>, 
<a href="/search/cs?searchtype=author&query=Hanlet%2C+P">P. Hanlet</a>, 
<a href="/search/cs?searchtype=author&query=Hazelwood%2C+K+J">K.J. Hazelwood</a>, 
<a href="/search/cs?searchtype=author&query=Ibrahim%2C+M+A">M.A. Ibrahim</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+H">H. Liu</a>, 
<a href="/search/cs?searchtype=author&query=Nagaslaev%2C+V+P">V.P. Nagaslaev</a>, 
<a href="/search/cs?searchtype=author&query=1%2C+A+N">A. Narayanan 1</a>, 
<a href="/search/cs?searchtype=author&query=Nicklaus%2C+D+J">D.J. Nicklaus</a>, 
<a href="/search/cs?searchtype=author&query=Mitrevski%2C+J">J. Mitrevski</a>, 
<a href="/search/cs?searchtype=author&query=Pradhan%2C+G">G. Pradhan</a>, 
<a href="/search/cs?searchtype=author&query=Saewert%2C+A+L">A.L. Saewert</a>, 
<a href="/search/cs?searchtype=author&query=Schupbach%2C+B+A">B.A. Schupbach</a>, 
<a href="/search/cs?searchtype=author&query=Seiya%2C+K">K. Seiya</a>, 
<a href="/search/cs?searchtype=author&query=Thieme%2C+M">M. Thieme</a>, 
<a href="/search/cs?searchtype=author&query=Thurman-Keup%2C+R+M">R.M. Thurman-Keup</a>, 
<a href="/search/cs?searchtype=author&query=Tran%2C+N+V">N.V. Tran</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Hardware Architecture (cs.AR)</span>

</div>
<p class="mathjax">This study focuses on implementing a real-time control system for a particle
accelerator facility that performs high energy physics experiments. A critical
operating parameter in this facility is beam loss, which is the fraction of
particles deviating from the accelerated proton beam into a cascade of
secondary particles. Accelerators employ a large number of sensors to monitor
beam loss. The data from these sensors is monitored by human operators who
predict the relative contribution of different sub-systems to the beam loss.
Using this information, they engage control interventions. In this paper, we
present a controller to track this phenomenon in real-time using edge-Machine
Learning (ML) and support control with low latency and high accuracy. We
implemented this system on an Intel Arria 10 SoC. Optimizations at the
algorithm, high-level synthesis, and interface levels to improve latency and
resource usage are presented. Our design implements a neural network, which can
predict the main source of beam loss (between two possible causes) at speeds up
to 575 frames per second (fps) (average latency of 1.74 ms). The practical
deployed system is required to operate at 320 fps, with a 3ms latency
requirement, which has been met by our design successfully.
</p>
</div>
</dd>
<dt><a name="item31">[31]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05717" title="Abstract">arXiv:2311.05717</a> [<a href="/pdf/2311.05717" title="Download PDF">pdf</a>, <a href="/format/2311.05717" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PL-CVIO: Point-Line Cooperative Visual-Inertial Odometry
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yanyu Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+P">Pengxiang Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Ren%2C+W">Wei Ren</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Low-feature environments are one of the main Achilles' heels of geometric
computer vision (CV) algorithms. In most human-built scenes often with low
features, lines can be considered complements to points. In this paper, we
present a multi-robot cooperative visual-inertial navigation system (VINS)
using both point and line features. By utilizing the covariance intersection
(CI) update within the multi-state constraint Kalman filter (MSCKF) framework,
each robot exploits not only its own point and line measurements, but also
constraints of common point and common line features observed by its neighbors.
The line features are parameterized and updated by utilizing the Closest Point
representation. The proposed algorithm is validated extensively in both
Monte-Carlo simulations and a real-world dataset. The results show that the
point-line cooperative visual-inertial odometry (PL-CVIO) outperforms the
independent MSCKF and our previous work CVIO in both low-feature and
rich-feature environments.
</p>
</div>
</dd>
<dt><a name="item32">[32]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05720" title="Abstract">arXiv:2311.05720</a> [<a href="/pdf/2311.05720" title="Download PDF">pdf</a>, <a href="/format/2311.05720" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Long-Horizon Dialogue Understanding for Role Identification in the Game  of Avalon with Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Stepputtis%2C+S">Simon Stepputtis</a>, 
<a href="/search/cs?searchtype=author&query=Campbell%2C+J">Joseph Campbell</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+Y">Yaqi Xie</a>, 
<a href="/search/cs?searchtype=author&query=Qi%2C+Z">Zhengyang Qi</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+W+S">Wenxin Sharon Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+R">Ruiyi Wang</a>, 
<a href="/search/cs?searchtype=author&query=Rangreji%2C+S">Sanketh Rangreji</a>, 
<a href="/search/cs?searchtype=author&query=Lewis%2C+M">Michael Lewis</a>, 
<a href="/search/cs?searchtype=author&query=Sycara%2C+K">Katia Sycara</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to the 2023 Conference on Empirical Methods in Natural Language Processing (EMNLP, Findings of the Association for Computational Linguistics)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Deception and persuasion play a critical role in long-horizon dialogues
between multiple parties, especially when the interests, goals, and motivations
of the participants are not aligned. Such complex tasks pose challenges for
current Large Language Models (LLM) as deception and persuasion can easily
mislead them, especially in long-horizon multi-party dialogues. To this end, we
explore the game of Avalon: The Resistance, a social deduction game in which
players must determine each other's hidden identities to complete their team's
objective. We introduce an online testbed and a dataset containing 20 carefully
collected and labeled games among human players that exhibit long-horizon
deception in a cooperative-competitive setting. We discuss the capabilities of
LLMs to utilize deceptive long-horizon conversations between six human players
to determine each player's goal and motivation. Particularly, we discuss the
multimodal integration of the chat between the players and the game's state
that grounds the conversation, providing further insights into the true player
identities. We find that even current state-of-the-art LLMs do not reach human
performance, making our dataset a compelling benchmark to investigate the
decision-making and language-processing capabilities of LLMs. Our dataset and
online testbed can be found at our project website:
https://sstepput.github.io/Avalon-NLU/
</p>
</div>
</dd>
<dt><a name="item33">[33]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05722" title="Abstract">arXiv:2311.05722</a> [<a href="/pdf/2311.05722" title="Download PDF">pdf</a>, <a href="/format/2311.05722" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Verilog-to-PyG -- A Framework for Graph Learning and Augmentation on RTL  Designs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yingjie Li</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+M">Mingju Liu</a>, 
<a href="/search/cs?searchtype=author&query=Mishchenko%2C+A">Alan Mishchenko</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+C">Cunxi Yu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, International Conference on Computer-Aided Design (ICCAD'23)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Hardware Architecture (cs.AR); Logic in Computer Science (cs.LO)

</div>
<p class="mathjax">The complexity of modern hardware designs necessitates advanced methodologies
for optimizing and analyzing modern digital systems. In recent times, machine
learning (ML) methodologies have emerged as potent instruments for assessing
design quality-of-results at the Register-Transfer Level (RTL) or Boolean
level, aiming to expedite design exploration of advanced RTL configurations. In
this presentation, we introduce an innovative open-source framework that
translates RTL designs into graph representation foundations, which can be
seamlessly integrated with the PyTorch Geometric graph learning platform.
Furthermore, the Verilog-to-PyG (V2PYG) framework is compatible with the
open-source Electronic Design Automation (EDA) toolchain OpenROAD, facilitating
the collection of labeled datasets in an utterly open-source manner.
Additionally, we will present novel RTL data augmentation methods (incorporated
in our framework) that enable functional equivalent design augmentation for the
construction of an extensive graph-based RTL design database. Lastly, we will
showcase several using cases of V2PYG with detailed scripting examples. V2PYG
can be found at \url{https://yu-maryland.github.io/Verilog-to-PyG/}.
</p>
</div>
</dd>
<dt><a name="item34">[34]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05723" title="Abstract">arXiv:2311.05723</a> [<a href="/pdf/2311.05723" title="Download PDF">pdf</a>, <a href="/ps/2311.05723" title="Download PostScript">ps</a>, <a href="/format/2311.05723" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Active Admission Control in a P2P Distributed Environment for Capacity  Efficient Livestreaming in Mobile Wireless Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Negulescu%2C+A">Andrei Negulescu</a>, 
<a href="/search/cs?searchtype=author&query=Shang%2C+W">Weijia Shang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 6 figures, 3 tables, Conference Submission
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>; Distributed, Parallel, and Cluster Computing (cs.DC); Performance (cs.PF); Systems and Control (eess.SY)

</div>
<p class="mathjax">In this study, the Active Control in an Intelligent and Distributed
Environment (ACIDE) media distribution model solution and algorithms are
proposed for livestreaming in capacity efficient mobile wireless networks. The
elements of the ACIDE model are a base station and a cluster formed by a number
of peers able to establish peer to peer communications. The cluster peers are
selected from a group of users interested in livestreaming the same media. The
ACIDE model solution minimizes the bandwidth allocated to a cluster of n peers
such that an uninterrupted media play for all peers is guaranteed. The
livestream media is sent to the peers in packages and every media package is
divided into n blocks. The blocks are distributed to the n peers of a cluster
in two phases, such that the base station bandwidth is utilized during first
phase only. The allocated bandwidth, the amount of bandwidth the base station
has to allocate to a cluster, is minimized and its lower bound is equal to the
bandwidth required for multicasting. In this study, the ACIDE model is used to
address the problem of how to find the maximum number of peers n, chosen from a
group of N users, that can be admitted to a cluster knowing the given allocated
bandwidth, the amount of bandwidth that a base station allocates to a cluster
in advance, prior to admitting users. When users become peers of an ACIDE
cluster, the network capacity, the total number of users who are able to access
live media, increases meaning that network resources are used more efficiently.
The problem of finding the maximum number of peers n is addressed as an
optimization problem, with the objective of having the entire given allocated
bandwidth used by the peers admitted to the cluster. This problem is
NP-complete and a non-optimal solution is proposed for peers selection such
that all admitted peers play media continuously.
</p>
</div>
</dd>
<dt><a name="item35">[35]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05724" title="Abstract">arXiv:2311.05724</a> [<a href="/pdf/2311.05724" title="Download PDF">pdf</a>, <a href="/format/2311.05724" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Susceptibility to Unreliable Information Sources: Swift Adoption with  Minimal Exposure
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ye%2C+J">Jinyi Ye</a>, 
<a href="/search/cs?searchtype=author&query=Luceri%2C+L">Luca Luceri</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+J">Julie Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Ferrara%2C+E">Emilio Ferrara</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>; Computers and Society (cs.CY)

</div>
<p class="mathjax">Misinformation proliferation on social media platforms is a pervasive threat
to the integrity of online public discourse. Genuine users, susceptible to
others' influence, often unknowingly engage with, endorse, and re-share
questionable pieces of information, collectively amplifying the spread of
misinformation. In this study, we introduce an empirical framework to
investigate users' susceptibility to influence when exposed to unreliable and
reliable information sources. Leveraging two datasets on political and public
health discussions on Twitter, we analyze the impact of exposure on the
adoption of information sources, examining how the reliability of the source
modulates this relationship. Our findings provide evidence that increased
exposure augments the likelihood of adoption. Users tend to adopt
low-credibility sources with fewer exposures than high-credibility sources, a
trend that persists even among non-partisan users. Furthermore, the number of
exposures needed for adoption varies based on the source credibility, with
extreme ends of the spectrum (very high or low credibility) requiring fewer
exposures for adoption. Additionally, we reveal that the adoption of
information sources often mirrors users' prior exposure to sources with
comparable credibility levels. Our research offers critical insights for
mitigating the endorsement of misinformation by vulnerable users, offering a
framework to study the dynamics of content exposure and adoption on social
media platforms.
</p>
</div>
</dd>
<dt><a name="item36">[36]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05725" title="Abstract">arXiv:2311.05725</a> [<a href="/pdf/2311.05725" title="Download PDF">pdf</a>, <a href="/format/2311.05725" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Whole-body Detection, Recognition and Identification at Altitude and  Range
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+S">Siyuan Huang</a>, 
<a href="/search/cs?searchtype=author&query=Kathirvel%2C+R+P">Ram Prabhakar Kathirvel</a>, 
<a href="/search/cs?searchtype=author&query=Lau%2C+C+P">Chun Pong Lau</a>, 
<a href="/search/cs?searchtype=author&query=Chellappa%2C+R">Rama Chellappa</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">In this paper, we address the challenging task of whole-body biometric
detection, recognition, and identification at distances of up to 500m and large
pitch angles of up to 50 degree. We propose an end-to-end system evaluated on
diverse datasets, including the challenging Biometric Recognition and
Identification at Range (BRIAR) dataset. Our approach involves pre-training the
detector on common image datasets and fine-tuning it on BRIAR's complex videos
and images. After detection, we extract body images and employ a feature
extractor for recognition. We conduct thorough evaluations under various
conditions, such as different ranges and angles in indoor, outdoor, and aerial
scenarios. Our method achieves an average F1 score of 98.29% at IoU = 0.7 and
demonstrates strong performance in recognition accuracy and true acceptance
rate at low false acceptance rates compared to existing models. On a test set
of 100 subjects with 444 distractors, our model achieves a rank-20 recognition
accuracy of 75.13% and a TAR@1%FAR of 54.09%.
</p>
</div>
</dd>
<dt><a name="item37">[37]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05729" title="Abstract">arXiv:2311.05729</a> [<a href="/pdf/2311.05729" title="Download PDF">pdf</a>, <a href="/format/2311.05729" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GIPCOL: Graph-Injected Soft Prompting for Compositional Zero-Shot  Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+G">Guangyue Xu</a>, 
<a href="/search/cs?searchtype=author&query=Chai%2C+J">Joyce Chai</a>, 
<a href="/search/cs?searchtype=author&query=Kordjamshidi%2C+P">Parisa Kordjamshidi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> WACV24
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Pre-trained vision-language models (VLMs) have achieved promising success in
many fields, especially with prompt learning paradigm. In this work, we propose
GIP-COL (Graph-Injected Soft Prompting for COmpositional Learning) to better
explore the compositional zero-shot learning (CZSL) ability of VLMs within the
prompt-based learning framework. The soft prompt in GIPCOL is structured and
consists of the prefix learnable vectors, attribute label and object label. In
addition, the attribute and object labels in the soft prompt are designated as
nodes in a compositional graph. The compositional graph is constructed based on
the compositional structure of the objects and attributes extracted from the
training data and consequently feeds the updated concept representation into
the soft prompt to capture this compositional structure for a better prompting
for CZSL. With the new prompting strategy, GIPCOL achieves state-of-the-art AUC
results on all three CZSL benchmarks, including MIT-States, UT-Zappos, and
C-GQA datasets in both closed and open settings compared to previous non-CLIP
as well as CLIP-based methods. We analyze when and why GIPCOL operates well
given the CLIP backbone and its training data limitations, and our findings
shed light on designing more effective prompts for CZSL
</p>
</div>
</dd>
<dt><a name="item38">[38]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05733" title="Abstract">arXiv:2311.05733</a> [<a href="/pdf/2311.05733" title="Download PDF">pdf</a>, <a href="/format/2311.05733" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LogShield: A Transformer-based APT Detection System Leveraging  Self-Attention
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Afnan%2C+S">Sihat Afnan</a>, 
<a href="/search/cs?searchtype=author&query=Sadia%2C+M">Mushtari Sadia</a>, 
<a href="/search/cs?searchtype=author&query=Iqbal%2C+S">Shahrear Iqbal</a>, 
<a href="/search/cs?searchtype=author&query=Iqbal%2C+A">Anindya Iqbal</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Cyber attacks are often identified using system and network logs. There have
been significant prior works that utilize provenance graphs and ML techniques
to detect attacks, specifically advanced persistent threats, which are very
difficult to detect. Lately, there have been studies where transformer-based
language models are being used to detect various types of attacks from system
logs. However, no such attempts have been made in the case of APTs. In
addition, existing state-of-the-art techniques that use system provenance
graphs, lack a data processing framework generalized across datasets for
optimal performance. For mitigating this limitation as well as exploring the
effectiveness of transformer-based language models, this paper proposes
LogShield, a framework designed to detect APT attack patterns leveraging the
power of self-attention in transformers. We incorporate customized embedding
layers to effectively capture the context of event sequences derived from
provenance graphs. While acknowledging the computational overhead associated
with training transformer networks, our framework surpasses existing LSTM and
Language models regarding APT detection. We integrated the model parameters and
training procedure from the RoBERTa model and conducted extensive experiments
on well-known APT datasets (DARPA OpTC and DARPA TC E3). Our framework achieved
superior F1 scores of 98% and 95% on the two datasets respectively, surpassing
the F1 scores of 96% and 94% obtained by LSTM models. Our findings suggest that
LogShield's performance benefits from larger datasets and demonstrates its
potential for generalization across diverse domains. These findings contribute
to the advancement of APT attack detection methods and underscore the
significance of transformer-based architectures in addressing security
challenges in computer systems.
</p>
</div>
</dd>
<dt><a name="item39">[39]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05734" title="Abstract">arXiv:2311.05734</a> [<a href="/pdf/2311.05734" title="Download PDF">pdf</a>, <a href="/format/2311.05734" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Cut-set and Stability Constrained Optimal Power Flow for Resilient  Operation During Wildfires
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Sahoo%2C+S">Satyaprajna Sahoo</a>, 
<a href="/search/eess?searchtype=author&query=Pal%2C+A">Anamitra Pal</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">Resilient operation of the power system during ongoing wildfires is
challenging because of the uncertain ways in which the fires impact the
electric power infrastructure (multiple arc-faults, complete melt-down). To
address this challenge, we propose a novel cut-set and stability-constrained
optimal power flow (OPF) that quickly mitigates both static and dynamic
insecurities as wildfires progress through a region. First, a Feasibility Test
(FT) algorithm that quickly desaturates overloaded cut-sets to prevent
cascading line outages is integrated with the OPF problem. Then, the resulting
formulation is combined with a data-driven transient stability analyzer that
predicts the correction factors for eliminating dynamic insecurities. The
proposed model considers the possibility of generation rescheduling as well as
load shed. The results obtained using the IEEE 118-bus system indicate that the
proposed approach alleviates vulnerability of the system to wildfires while
minimizing operational cost.
</p>
</div>
</dd>
<dt><a name="item40">[40]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05735" title="Abstract">arXiv:2311.05735</a> [<a href="/pdf/2311.05735" title="Download PDF">pdf</a>, <a href="/format/2311.05735" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A high order accurate space-time trajectory reconstruction technique for  quantitative particle trafficking analysis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Corradi%2C+E">Eloina Corradi</a>, 
<a href="/search/math?searchtype=author&query=Tavelli%2C+M">Maurizio Tavelli</a>, 
<a href="/search/math?searchtype=author&query=Baudet%2C+M">Marie-Laure Baudet</a>, 
<a href="/search/math?searchtype=author&query=Boscheri%2C+W">Walter Boscheri</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">The study of moving particles (e.g. molecules, virus, vesicles, organelles,
or whole cells) is crucial to decipher a plethora of cellular mechanisms within
physiological and pathological conditions. Powerful live-imaging approaches
enable life scientists to capture particle movements at different scale from
cells to single molecules, that are collected in a series of frames. However,
although these events can be captured, an accurate quantitative analysis of
live-imaging experiments still remains a challenge. Two main approaches are
currently used to study particle kinematics: kymographs, which are graphical
representation of spatial motion over time, and single particle tracking (SPT)
followed by linear linking. Both kymograph and SPT apply a space-time
approximation in quantifying particle kinematics, considering the velocity
constant either over several frames or between consecutive frames,
respectively. Thus, both approaches intrinsically limit the analysis of complex
motions with rapid changes in velocity. Therefore, we design, implement and
validate a novel reconstruction algorithm aiming at supporting tracking
particle trafficking analysis with mathematical foundations. Our method is
based on polynomial reconstruction of 4D (3D+time) particle trajectories,
enabling to assess particle instantaneous velocity and acceleration, at any
time, over the entire trajectory. Here, the new algorithm is compared to
state-of-the-art SPT followed by linear linking, demonstrating an increased
accuracy in quantifying particle kinematics. Our approach is directly derived
from the governing equations of motion, thus it arises from physical principles
and, as such, it is a versatile and reliable numerical method for accurate
particle kinematics analysis which can be applied to any live-imaging
experiment where the space-time coordinates can be retrieved.
</p>
</div>
</dd>
<dt><a name="item41">[41]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05736" title="Abstract">arXiv:2311.05736</a> [<a href="/pdf/2311.05736" title="Download PDF">pdf</a>, <a href="/ps/2311.05736" title="Download PostScript">ps</a>, <a href="/format/2311.05736" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An algorithm for scaling vectors by the reciprocal of a complex number
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=da+Silva+Pereira%2C+W">Weslley da Silva Pereira</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, no figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">This document describes an algorithm to scale a complex vector by the
reciprocal of a complex value. The algorithm computes the reciprocal of the
complex value and then scales the vector by the reciprocal. Some scaling may be
necessary due to this 2-step strategy, and the proposed algorithm takes scaling
into account. This algorithm is supposed to be faster than the naive approach
of dividing each entry of the vector by the complex value, without losing much
accuracy. It also serves as a single strategy for scaling vectors by the
reciprocal of a complex value, which improves the software maintainability.
</p>
</div>
</dd>
<dt><a name="item42">[42]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05739" title="Abstract">arXiv:2311.05739</a> [<a href="/pdf/2311.05739" title="Download PDF">pdf</a>, <a href="/format/2311.05739" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deep Learning Architecture for Network-Efficiency at the Edge
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mudvari%2C+A">Akrit Mudvari</a>, 
<a href="/search/cs?searchtype=author&query=Vainio%2C+A">Antero Vainio</a>, 
<a href="/search/cs?searchtype=author&query=Ofeidis%2C+I">Iason Ofeidis</a>, 
<a href="/search/cs?searchtype=author&query=Tarkoma%2C+S">Sasu Tarkoma</a>, 
<a href="/search/cs?searchtype=author&query=Tassiulas%2C+L">Leandros Tassiulas</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">The growing number of AI-driven applications in the mobile devices has led to
solutions that integrate deep learning models with the available edge-cloud
resources; due to multiple benefits such as reduction in on-device energy
consumption, improved latency, improved network usage, and certain privacy
improvements, split learning, where deep learning models are split away from
the mobile device and computed in a distributed manner, has become an
extensively explored topic. Combined with compression-aware methods where
learning adapts to compression of communicated data, the benefits of this
approach have further improved and could serve as an alternative to established
approaches like federated learning methods. In this work, we develop an
adaptive compression-aware split learning method ('deprune') to improve and
train deep learning models so that they are much more network-efficient (use
less network resources and are faster), which would make them ideal to deploy
in weaker devices with the help of edge-cloud resources. This method is also
extended ('prune') to very quickly train deep learning models, through a
transfer learning approach, that trades off little accuracy for much more
network-efficient inference abilities. We show that the 'deprune' method can
reduce network usage by 4x when compared with a split-learning approach (that
does not use our method) without loss of accuracy, while also improving
accuracy over compression-aware split-learning by 4 percent. Lastly, we show
that the 'prune' method can reduce the training time for certain models by up
to 6x without affecting the accuracy when compared against a compression-aware
split-learning approach.
</p>
</div>
</dd>
<dt><a name="item43">[43]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05740" title="Abstract">arXiv:2311.05740</a> [<a href="/pdf/2311.05740" title="Download PDF">pdf</a>, <a href="/format/2311.05740" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Generating Pragmatic Examples to Train Neural Program Synthesizers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Vaduguru%2C+S">Saujas Vaduguru</a>, 
<a href="/search/cs?searchtype=author&query=Fried%2C+D">Daniel Fried</a>, 
<a href="/search/cs?searchtype=author&query=Pu%2C+Y">Yewen Pu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Programming Languages (cs.PL)

</div>
<p class="mathjax">Programming-by-example is the task of synthesizing a program that is
consistent with a set of user-provided input-output examples. As examples are
often an under-specification of one's intent, a good synthesizer must choose
the intended program from the many that are consistent with the given set of
examples. Prior work frames program synthesis as a cooperative game between a
listener (that synthesizes programs) and a speaker (a user choosing examples),
and shows that models of computational pragmatic inference are effective in
choosing the user intended programs. However, these models require
counterfactual reasoning over a large set of programs and examples, which is
infeasible in realistic program spaces. In this paper, we propose a novel way
to amortize this search with neural networks. We sample pairs of programs and
examples via self-play between listener and speaker models, and use pragmatic
inference to choose informative training examples from this sample.We then use
the informative dataset to train models to improve the synthesizer's ability to
disambiguate user-provided examples without human supervision. We validate our
method on the challenging task of synthesizing regular expressions from example
strings, and find that our method (1) outperforms models trained without
choosing pragmatic examples by 23% (a 51% relative increase) (2) matches the
performance of supervised learning on a dataset of pragmatic examples provided
by humans, despite using no human data in training.
</p>
</div>
</dd>
<dt><a name="item44">[44]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05741" title="Abstract">arXiv:2311.05741</a> [<a href="/pdf/2311.05741" title="Download PDF">pdf</a>, <a href="/ps/2311.05741" title="Download PostScript">ps</a>, <a href="/format/2311.05741" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Efficiently Adapting Pretrained Language Models To New Languages
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Csaki%2C+Z">Zoltan Csaki</a>, 
<a href="/search/cs?searchtype=author&query=Pawakapan%2C+P">Pian Pawakapan</a>, 
<a href="/search/cs?searchtype=author&query=Thakker%2C+U">Urmish Thakker</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+Q">Qiantong Xu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to "The third Neurips Workshop on Efficient Natural Language and Speech Processing 2023" (ENLSP-III)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Recent large language models (LLM) exhibit sub-optimal performance on
low-resource languages, as the training data of these models is usually
dominated by English and other high-resource languages. Furthermore, it is
challenging to train models for low-resource languages, especially from
scratch, due to a lack of high quality training data. Adapting pretrained LLMs
reduces the need for data in the new language while also providing cross
lingual transfer capabilities. However, naively adapting to new languages leads
to catastrophic forgetting and poor tokenizer efficiency. In this work, we
study how to efficiently adapt any existing pretrained LLM to a new language
without running into these issues. In particular, we improve the encoding
efficiency of the tokenizer by adding new tokens from the target language and
study the data mixing recipe to mitigate forgetting. Our experiments on
adapting an English LLM to Hungarian and Thai show that our recipe can reach
better performance than open source models on the target language, with minimal
regressions on English.
</p>
</div>
</dd>
<dt><a name="item45">[45]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05744" title="Abstract">arXiv:2311.05744</a> [<a href="/pdf/2311.05744" title="Download PDF">pdf</a>, <a href="/format/2311.05744" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Flexibility of Integrated Power and Gas Systems: Modeling and Solution  Choices Matter
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Raheli%2C+E">Enrica Raheli</a>, 
<a href="/search/eess?searchtype=author&query=Werner%2C+Y">Yannick Werner</a>, 
<a href="/search/eess?searchtype=author&query=Kazempour%2C+J">Jalal Kazempour</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Optimization and Control (math.OC)

</div>
<p class="mathjax">Due to their slow gas flow dynamics, natural gas pipelines function as
short-term storage, the so-called \textit{linepack}. By efficiently utilizing
linepack, the natural gas system can provide flexibility to the power system
through the flexible operation of gas-fired power plants. This requires
accurately representing the gas flow physics governed by partial differential
equations. Although several modeling and solution choices have been proposed in
the literature, their impact on the flexibility provision of gas networks to
power systems has not been thoroughly analyzed and compared. This paper bridges
this gap by first developing a unified framework. We harmonize existing
approaches and demonstrate their derivation from and application to the partial
differential equations. Secondly, based on the proposed framework, we
numerically analyze the implications of various modeling and solution choices
on the flexibility provision from gas networks to power systems. One key
conclusion is that relaxation-based approaches allow charging and discharging
the linepack at physically infeasible high rates, ultimately overestimating the
flexibility.
</p>
</div>
</dd>
<dt><a name="item46">[46]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05746" title="Abstract">arXiv:2311.05746</a> [<a href="/pdf/2311.05746" title="Download PDF">pdf</a>, <a href="/format/2311.05746" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Bridging the Digital Divide: Performance Variation across Socio-Economic  Factors in Vision-Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nwatu%2C+J">Joan Nwatu</a>, 
<a href="/search/cs?searchtype=author&query=Ignat%2C+O">Oana Ignat</a>, 
<a href="/search/cs?searchtype=author&query=Mihalcea%2C+R">Rada Mihalcea</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> EMNLP 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Despite the impressive performance of current AI models reported across
various tasks, performance reports often do not include evaluations of how
these models perform on the specific groups that will be impacted by these
technologies. Among the minority groups under-represented in AI, data from
low-income households are often overlooked in data collection and model
evaluation. We evaluate the performance of a state-of-the-art vision-language
model (CLIP) on a geo-diverse dataset containing household images associated
with different income values (Dollar Street) and show that performance
inequality exists among households of different income levels. Our results
indicate that performance for the poorer groups is consistently lower than the
wealthier groups across various topics and countries. We highlight insights
that can help mitigate these issues and propose actionable steps for
economic-level inclusive AI development. Code is available at
https://github.com/MichiganNLP/Bridging_the_Digital_Divide.
</p>
</div>
</dd>
<dt><a name="item47">[47]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05748" title="Abstract">arXiv:2311.05748</a> [<a href="/pdf/2311.05748" title="Download PDF">pdf</a>, <a href="/format/2311.05748" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Enabling Automated Integration Testing of Smart Farming Applications via  Digital Twin Prototypes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Barbie%2C+A">Alexander Barbie</a>, 
<a href="/search/cs?searchtype=author&query=Hasselbring%2C+W">Wilhelm Hasselbring</a>, 
<a href="/search/cs?searchtype=author&query=Hansen%2C+M">Malte Hansen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 6 figures, 1 table, conference, In the Proceedings Of The 2023 IEEE International Conference on Digital Twin (Digital Twin 2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
<p class="mathjax">Industry 4.0 represents a major technological shift that has the potential to
transform the manufacturing industry, making it more efficient, productive, and
sustainable. Smart farming is a concept that involves the use of advanced
technologies to improve the efficiency and sustainability of agricultural
practices. Industry 4.0 and smart farming are closely related, as many of the
technologies used in smart farming are also used in Industry 4.0. Digital twins
have the potential for cost-effective software development of such
applications. With our Digital Twin Prototype approach, all sensor interfaces
are integrated into the development process, and their inputs and outputs of
the emulated hardware match those of the real hardware. The emulators respond
to the same commands and return identically formatted data packages as their
real counterparts, making the Digital Twin Prototype a valid source of a
digital shadow, i.e. the Digital Twin Prototype is a prototype of the physical
twin and can replace it for automated testing of the digital twin software. In
this paper, we present a case study for employing our Digital Twin Prototype
approach to automated testing of software for improving the making of silage
with a smart farming application. Besides automated testing with continuous
integration, we also discuss continuous deployment of modular Docker containers
in this context.
</p>
</div>
</dd>
<dt><a name="item48">[48]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05754" title="Abstract">arXiv:2311.05754</a> [<a href="/pdf/2311.05754" title="Download PDF">pdf</a>, <a href="/format/2311.05754" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deep Natural Language Feature Learning for Interpretable Prediction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Urrutia%2C+F">Felipe Urrutia</a>, 
<a href="/search/cs?searchtype=author&query=Buc%2C+C">Cristian Buc</a>, 
<a href="/search/cs?searchtype=author&query=Barriere%2C+V">Valentin Barriere</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">We propose a general method to break down a main complex task into a set of
intermediary easier sub-tasks, which are formulated in natural language as
binary questions related to the final target task. Our method allows for
representing each example by a vector consisting of the answers to these
questions. We call this representation Natural Language Learned Features
(NLLF). NLLF is generated by a small transformer language model (e.g., BERT)
that has been trained in a Natural Language Inference (NLI) fashion, using weak
labels automatically obtained from a Large Language Model (LLM). We show that
the LLM normally struggles for the main task using in-context learning, but can
handle these easiest subtasks and produce useful weak labels to train a BERT.
The NLI-like training of the BERT allows for tackling zero-shot inference with
any binary question, and not necessarily the ones seen during the training. We
show that this NLLF vector not only helps to reach better performances by
enhancing any classifier, but that it can be used as input of an
easy-to-interpret machine learning model like a decision tree. This decision
tree is interpretable but also reaches high performances, surpassing those of a
pre-trained transformer in some cases.We have successfully applied this method
to two completely different tasks: detecting incoherence in students' answers
to open-ended mathematics exam questions, and screening abstracts for a
systematic literature review of scientific papers on climate change and
agroecology.
</p>
</div>
</dd>
<dt><a name="item49">[49]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05760" title="Abstract">arXiv:2311.05760</a> [<a href="/pdf/2311.05760" title="Download PDF">pdf</a>, <a href="/ps/2311.05760" title="Download PostScript">ps</a>, <a href="/format/2311.05760" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MALCOM-PSGD: Inexact Proximal Stochastic Gradient Descent for  Communication-Efficient Decentralized Machine Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Campbell%2C+A">Andrew Campbell</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+H">Hang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Woldemariam%2C+L">Leah Woldemariam</a>, 
<a href="/search/cs?searchtype=author&query=Scaglione%2C+A">Anna Scaglione</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Distributed, Parallel, and Cluster Computing (cs.DC); Data Structures and Algorithms (cs.DS); Multiagent Systems (cs.MA); Optimization and Control (math.OC)

</div>
<p class="mathjax">Recent research indicates that frequent model communication stands as a major
bottleneck to the efficiency of decentralized machine learning (ML),
particularly for large-scale and over-parameterized neural networks (NNs). In
this paper, we introduce MALCOM-PSGD, a new decentralized ML algorithm that
strategically integrates gradient compression techniques with model
sparsification. MALCOM-PSGD leverages proximal stochastic gradient descent to
handle the non-smoothness resulting from the $\ell_1$ regularization in model
sparsification. Furthermore, we adapt vector source coding and dithering-based
quantization for compressed gradient communication of sparsified models. Our
analysis shows that decentralized proximal stochastic gradient descent with
compressed communication has a convergence rate of
$\mathcal{O}\left(\ln(t)/\sqrt{t}\right)$ assuming a diminishing learning rate
and where $t$ denotes the number of iterations. Numerical results verify our
theoretical findings and demonstrate that our method reduces communication
costs by approximately $75\%$ when compared to the state-of-the-art method.
</p>
</div>
</dd>
<dt><a name="item50">[50]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05764" title="Abstract">arXiv:2311.05764</a> [<a href="/pdf/2311.05764" title="Download PDF">pdf</a>, <a href="/format/2311.05764" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Generative Explanations for Graph Neural Network: Methods and  Evaluations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Jialin Chen</a>, 
<a href="/search/cs?searchtype=author&query=Amara%2C+K">Kenza Amara</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+J">Junchi Yu</a>, 
<a href="/search/cs?searchtype=author&query=Ying%2C+R">Rex Ying</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Graph Neural Networks (GNNs) achieve state-of-the-art performance in various
graph-related tasks. However, the black-box nature often limits their
interpretability and trustworthiness. Numerous explainability methods have been
proposed to uncover the decision-making logic of GNNs, by generating underlying
explanatory substructures. In this paper, we conduct a comprehensive review of
the existing explanation methods for GNNs from the perspective of graph
generation. Specifically, we propose a unified optimization objective for
generative explanation methods, comprising two sub-objectives: Attribution and
Information constraints. We further demonstrate their specific manifestations
in various generative model architectures and different explanation scenarios.
With the unified objective of the explanation problem, we reveal the shared
characteristics and distinctions among current methods, laying the foundation
for future methodological advancements. Empirical results demonstrate the
advantages and limitations of different explainability approaches in terms of
explanation performance, efficiency, and generalizability.
</p>
</div>
</dd>
<dt><a name="item51">[51]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05767" title="Abstract">arXiv:2311.05767</a> [<a href="/pdf/2311.05767" title="Download PDF">pdf</a>, <a href="/format/2311.05767" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Dirichlet Energy Enhancement of Graph Neural Networks by Framelet  Augmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Jialin Chen</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yuelin Wang</a>, 
<a href="/search/cs?searchtype=author&query=Bodnar%2C+C">Cristian Bodnar</a>, 
<a href="/search/cs?searchtype=author&query=Ying%2C+R">Rex Ying</a>, 
<a href="/search/cs?searchtype=author&query=Lio%2C+P">Pietro Lio</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y+G">Yu Guang Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Graph convolutions have been a pivotal element in learning graph
representations. However, recursively aggregating neighboring information with
graph convolutions leads to indistinguishable node features in deep layers,
which is known as the over-smoothing issue. The performance of graph neural
networks decays fast as the number of stacked layers increases, and the
Dirichlet energy associated with the graph decreases to zero as well. In this
work, we introduce a framelet system into the analysis of Dirichlet energy and
take a multi-scale perspective to leverage the Dirichlet energy and alleviate
the over-smoothing issue. Specifically, we develop a Framelet Augmentation
strategy by adjusting the update rules with positive and negative increments
for low-pass and high-passes respectively. Based on that, we design the Energy
Enhanced Convolution (EEConv), which is an effective and practical operation
that is proved to strictly enhance Dirichlet energy. From a message-passing
perspective, EEConv inherits multi-hop aggregation property from the framelet
transform and takes into account all hops in the multi-scale representation,
which benefits the node classification tasks over heterophilous graphs.
Experiments show that deep GNNs with EEConv achieve state-of-the-art
performance over various node classification datasets, especially for
heterophilous graphs, while also lifting the Dirichlet energy as the network
goes deeper.
</p>
</div>
</dd>
<dt><a name="item52">[52]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05769" title="Abstract">arXiv:2311.05769</a> [<a href="/pdf/2311.05769" title="Download PDF">pdf</a>, <a href="/format/2311.05769" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Chatbots Are Not Reliable Text Annotators
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kristensen-McLachlan%2C+R+D">Ross Deans Kristensen-McLachlan</a>, 
<a href="/search/cs?searchtype=author&query=Canavan%2C+M">Miceal Canavan</a>, 
<a href="/search/cs?searchtype=author&query=Kardos%2C+M">M&#xe1;rton Kardos</a>, 
<a href="/search/cs?searchtype=author&query=Jacobsen%2C+M">Mia Jacobsen</a>, 
<a href="/search/cs?searchtype=author&query=Aar%C3%B8e%2C+L">Lene Aar&#xf8;e</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Recent research highlights the significant potential of ChatGPT for text
annotation in social science research. However, ChatGPT is a closed-source
product which has major drawbacks with regards to transparency,
reproducibility, cost, and data protection. Recent advances in open-source (OS)
large language models (LLMs) offer alternatives which remedy these challenges.
This means that it is important to evaluate the performance of OS LLMs relative
to ChatGPT and standard approaches to supervised machine learning
classification. We conduct a systematic comparative evaluation of the
performance of a range of OS LLM models alongside ChatGPT, using both zero- and
few-shot learning as well as generic and custom prompts, with results compared
to more traditional supervised classification models. Using a new dataset of
Tweets from US news media, and focusing on simple binary text annotation tasks
for standard social science concepts, we find significant variation in the
performance of ChatGPT and OS models across the tasks, and that supervised
classifiers consistently outperform both. Given the unreliable performance of
ChatGPT and the significant challenges it poses to Open Science we advise
against using ChatGPT for substantive text annotation tasks in social science
research.
</p>
</div>
</dd>
<dt><a name="item53">[53]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05770" title="Abstract">arXiv:2311.05770</a> [<a href="/pdf/2311.05770" title="Download PDF">pdf</a>, <a href="/format/2311.05770" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PolyMaX: General Dense Prediction with Mask Transformer
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+X">Xuan Yang</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+L">Liangzhe Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Wilber%2C+K">Kimberly Wilber</a>, 
<a href="/search/cs?searchtype=author&query=Sharma%2C+A">Astuti Sharma</a>, 
<a href="/search/cs?searchtype=author&query=Gu%2C+X">Xiuye Gu</a>, 
<a href="/search/cs?searchtype=author&query=Qiao%2C+S">Siyuan Qiao</a>, 
<a href="/search/cs?searchtype=author&query=Debats%2C+S">Stephanie Debats</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Huisheng Wang</a>, 
<a href="/search/cs?searchtype=author&query=Adam%2C+H">Hartwig Adam</a>, 
<a href="/search/cs?searchtype=author&query=Sirotenko%2C+M">Mikhail Sirotenko</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+L">Liang-Chieh Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> WACV 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Dense prediction tasks, such as semantic segmentation, depth estimation, and
surface normal prediction, can be easily formulated as per-pixel classification
(discrete outputs) or regression (continuous outputs). This per-pixel
prediction paradigm has remained popular due to the prevalence of fully
convolutional networks. However, on the recent frontier of segmentation task,
the community has been witnessing a shift of paradigm from per-pixel prediction
to cluster-prediction with the emergence of transformer architectures,
particularly the mask transformers, which directly predicts a label for a mask
instead of a pixel. Despite this shift, methods based on the per-pixel
prediction paradigm still dominate the benchmarks on the other dense prediction
tasks that require continuous outputs, such as depth estimation and surface
normal prediction. Motivated by the success of DORN and AdaBins in depth
estimation, achieved by discretizing the continuous output space, we propose to
generalize the cluster-prediction based method to general dense prediction
tasks. This allows us to unify dense prediction tasks with the mask transformer
framework. Remarkably, the resulting model PolyMaX demonstrates
state-of-the-art performance on three benchmarks of NYUD-v2 dataset. We hope
our simple yet effective design can inspire more research on exploiting mask
transformers for more dense prediction tasks. Code and model will be made
available.
</p>
</div>
</dd>
<dt><a name="item54">[54]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05772" title="Abstract">arXiv:2311.05772</a> [<a href="/pdf/2311.05772" title="Download PDF">pdf</a>, <a href="/format/2311.05772" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ADaPT: As-Needed Decomposition and Planning with Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Prasad%2C+A">Archiki Prasad</a>, 
<a href="/search/cs?searchtype=author&query=Koller%2C+A">Alexander Koller</a>, 
<a href="/search/cs?searchtype=author&query=Hartmann%2C+M">Mareike Hartmann</a>, 
<a href="/search/cs?searchtype=author&query=Clark%2C+P">Peter Clark</a>, 
<a href="/search/cs?searchtype=author&query=Sabharwal%2C+A">Ashish Sabharwal</a>, 
<a href="/search/cs?searchtype=author&query=Bansal%2C+M">Mohit Bansal</a>, 
<a href="/search/cs?searchtype=author&query=Khot%2C+T">Tushar Khot</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project Page: <a href="https://allenai.github.io/adaptllm">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computation and Language (cs.CL); Machine Learning (cs.LG)

</div>
<p class="mathjax">Large Language Models (LLMs) are increasingly being used for interactive
decision-making tasks requiring planning and adapting to the environment.
Recent works employ LLMs-as-agents in broadly two ways: iteratively determining
the next action (iterative executors) or generating plans and executing
sub-tasks using LLMs (plan-and-execute). However, these methods struggle with
task complexity, as the inability to execute any sub-task may lead to task
failure. To address these shortcomings, we introduce As-Needed Decomposition
and Planning for complex Tasks (ADaPT), an approach that explicitly plans and
decomposes complex sub-tasks as-needed, i.e., when the LLM is unable to execute
them. ADaPT recursively decomposes sub-tasks to adapt to both task complexity
and LLM capability. Our results demonstrate that ADaPT substantially
outperforms established strong baselines, achieving success rates up to 28.3%
higher in ALFWorld, 27% in WebShop, and 33% in TextCraft -- a novel
compositional dataset that we introduce. Through extensive analysis, we
illustrate the importance of multilevel decomposition and establish that ADaPT
dynamically adjusts to the capabilities of the executor LLM as well as to task
complexity.
</p>
</div>
</dd>
<dt><a name="item55">[55]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05773" title="Abstract">arXiv:2311.05773</a> [<a href="/pdf/2311.05773" title="Download PDF">pdf</a>, <a href="/format/2311.05773" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An Algorithm for Bichromatic Sorting with Polylog Competitive Ratio
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Goswami%2C+M">Mayank Goswami</a>, 
<a href="/search/cs?searchtype=author&query=Jacob%2C+R">Riko Jacob</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 18 pages, accepted to ITCS 2024. arXiv admin note: text overlap with <a href="/abs/2211.04601">arXiv:2211.04601</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>

</div>
<p class="mathjax">The problem of sorting with priced information was introduced by [Charikar,
Fagin, Guruswami, Kleinberg, Raghavan, Sahai (CFGKRS), STOC 2000]. In this
setting, different comparisons have different (potentially infinite) costs. The
goal is to find a sorting algorithm with small competitive ratio, defined as
the (worst-case) ratio of the algorithm's cost to the cost of the cheapest
proof of the sorted order.
<br />The simple case of bichromatic sorting posed by [CFGKRS] remains open: We are
given two sets $A$ and $B$ of total size $N$, and the cost of an $A-A$
comparison or a $B-B$ comparison is higher than an $A-B$ comparison. The goal
is to sort $A \cup B$. An $\Omega(\log N)$ lower bound on competitive ratio
follows from unit-cost sorting. Note that this is a generalization of the
famous nuts and bolts problem, where $A-A$ and $B-B$ comparisons have infinite
cost, and elements of $A$ and $B$ are guaranteed to alternate in the final
sorted order.
<br />In this paper we give a randomized algorithm InversionSort with an
almost-optimal w.h.p. competitive ratio of $O(\log^{3} N)$. This is the first
algorithm for bichromatic sorting with a $o(N)$ competitive ratio.
</p>
</div>
</dd>
<dt><a name="item56">[56]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05778" title="Abstract">arXiv:2311.05778</a> [<a href="/pdf/2311.05778" title="Download PDF">pdf</a>, <a href="/format/2311.05778" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DONUT-hole: DONUT Sparsification by Harnessing Knowledge and Optimizing  Learning Efficiency
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shaikh%2C+A">Azhar Shaikh</a>, 
<a href="/search/cs?searchtype=author&query=Cochez%2C+M">Michael Cochez</a>, 
<a href="/search/cs?searchtype=author&query=Diachkov%2C+D">Denis Diachkov</a>, 
<a href="/search/cs?searchtype=author&query=de+Rijcke%2C+M">Michiel de Rijcke</a>, 
<a href="/search/cs?searchtype=author&query=Yousefi%2C+S">Sahar Yousefi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">This paper introduces DONUT-hole, a sparse OCR-free visual document
understanding (VDU) model that addresses the limitations of its predecessor
model, dubbed DONUT. The DONUT model, leveraging a transformer architecture,
overcoming the challenges of separate optical character recognition (OCR) and
visual semantic understanding (VSU) components. However, its deployment in
production environments and edge devices is hindered by high memory and
computational demands, particularly in large-scale request services. To
overcome these challenges, we propose an optimization strategy based on
knowledge distillation and model pruning. Our paradigm to produce DONUT-hole,
reduces the model denisty by 54\% while preserving performance. We also achieve
a global representational similarity index between DONUT and DONUT-hole based
on centered kernel alignment (CKA) metric of 0.79. Moreover, we evaluate the
effectiveness of DONUT-hole in the document image key information extraction
(KIE) task, highlighting its potential for developing more efficient VDU
systems for logistic companies.
</p>
</div>
</dd>
<dt><a name="item57">[57]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05779" title="Abstract">arXiv:2311.05779</a> [<a href="/pdf/2311.05779" title="Download PDF">pdf</a>, <a href="/format/2311.05779" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Language-guided Robot Grasping: CLIP-based Referring Grasp Synthesis in  Clutter
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tziafas%2C+G">Georgios Tziafas</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+Y">Yucheng Xu</a>, 
<a href="/search/cs?searchtype=author&query=Goel%2C+A">Arushi Goel</a>, 
<a href="/search/cs?searchtype=author&query=Kasaei%2C+M">Mohammadreza Kasaei</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zhibin Li</a>, 
<a href="/search/cs?searchtype=author&query=Kasaei%2C+H">Hamidreza Kasaei</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Poster CoRL 2023. Dataset and code available here: <a href="https://github.com/gtziafas/OCID-VLG">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Robots operating in human-centric environments require the integration of
visual grounding and grasping capabilities to effectively manipulate objects
based on user instructions. This work focuses on the task of referring grasp
synthesis, which predicts a grasp pose for an object referred through natural
language in cluttered scenes. Existing approaches often employ multi-stage
pipelines that first segment the referred object and then propose a suitable
grasp, and are evaluated in private datasets or simulators that do not capture
the complexity of natural indoor scenes. To address these limitations, we
develop a challenging benchmark based on cluttered indoor scenes from OCID
dataset, for which we generate referring expressions and connect them with
4-DoF grasp poses. Further, we propose a novel end-to-end model (CROG) that
leverages the visual grounding capabilities of CLIP to learn grasp synthesis
directly from image-text pairs. Our results show that vanilla integration of
CLIP with pretrained models transfers poorly in our challenging benchmark,
while CROG achieves significant improvements both in terms of grounding and
grasping. Extensive robot experiments in both simulation and hardware
demonstrate the effectiveness of our approach in challenging interactive object
grasping scenarios that include clutter.
</p>
</div>
</dd>
<dt><a name="item58">[58]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05780" title="Abstract">arXiv:2311.05780</a> [<a href="/pdf/2311.05780" title="Download PDF">pdf</a>, <a href="/format/2311.05780" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Real-time Control of Electric Autonomous Mobility-on-Demand Systems via  Graph Reinforcement Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Singhal%2C+A">Aaryan Singhal</a>, 
<a href="/search/eess?searchtype=author&query=Gammelli%2C+D">Daniele Gammelli</a>, 
<a href="/search/eess?searchtype=author&query=Luke%2C+J">Justin Luke</a>, 
<a href="/search/eess?searchtype=author&query=Gopalakrishnan%2C+K">Karthik Gopalakrishnan</a>, 
<a href="/search/eess?searchtype=author&query=Helmreich%2C+D">Dominik Helmreich</a>, 
<a href="/search/eess?searchtype=author&query=Pavone%2C+M">Marco Pavone</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Machine Learning (cs.LG); Robotics (cs.RO)

</div>
<p class="mathjax">Operators of Electric Autonomous Mobility-on-Demand (E-AMoD) fleets need to
make several real-time decisions such as matching available cars to ride
requests, rebalancing idle cars to areas of high demand, and charging vehicles
to ensure sufficient range. While this problem can be posed as a linear program
that optimizes flows over a space-charge-time graph, the size of the resulting
optimization problem does not allow for real-time implementation in realistic
settings. In this work, we present the E-AMoD control problem through the lens
of reinforcement learning and propose a graph network-based framework to
achieve drastically improved scalability and superior performance over
heuristics. Specifically, we adopt a bi-level formulation where we (1) leverage
a graph network-based RL agent to specify a desired next state in the
space-charge graph, and (2) solve more tractable linear programs to best
achieve the desired state while ensuring feasibility. Experiments using
real-world data from San Francisco and New York City show that our approach
achieves up to 89% of the profits of the theoretically-optimal solution while
achieving more than a 100x speedup in computational time. Furthermore, our
approach outperforms the best domain-specific heuristics with comparable
runtimes, with an increase in profits by up to 3x. Finally, we highlight
promising zero-shot transfer capabilities of our learned policy on tasks such
as inter-city generalization and service area expansion, thus showing the
utility, scalability, and flexibility of our framework.
</p>
</div>
</dd>
<dt><a name="item59">[59]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05782" title="Abstract">arXiv:2311.05782</a> [<a href="/pdf/2311.05782" title="Download PDF">pdf</a>, <a href="/format/2311.05782" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MPGemmFI: A Fault Injection Technique for Mixed Precision GEMM in ML  Applications
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fang%2C+B">Bo Fang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xinyi Li</a>, 
<a href="/search/cs?searchtype=author&query=Dam%2C+H">Harvey Dam</a>, 
<a href="/search/cs?searchtype=author&query=Tan%2C+C">Cheng Tan</a>, 
<a href="/search/cs?searchtype=author&query=Hari%2C+S+K+S">Siva Kumar Sastry Hari</a>, 
<a href="/search/cs?searchtype=author&query=Tsai%2C+T">Timothy Tsai</a>, 
<a href="/search/cs?searchtype=author&query=Laguna%2C+I">Ignacio Laguna</a>, 
<a href="/search/cs?searchtype=author&query=Tao%2C+D">Dingwen Tao</a>, 
<a href="/search/cs?searchtype=author&query=Gopalakrishnan%2C+G">Ganesh Gopalakrishnan</a>, 
<a href="/search/cs?searchtype=author&query=Nair%2C+P">Prashant Nair</a>, 
<a href="/search/cs?searchtype=author&query=Barker%2C+K">Kevin Barker</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+A">Ang Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>

</div>
<p class="mathjax">Emerging deep learning workloads urgently need fast general matrix
multiplication (GEMM). To meet such demand, one of the critical features of
machine-learning-specific accelerators such as NVIDIA Tensor Cores, AMD Matrix
Cores, and Google TPUs is the support of mixed-precision enabled GEMM. For DNN
models, lower-precision FP data formats and computation offer acceptable
correctness but significant performance, area, and memory footprint
improvement. While promising, the mixed-precision computation on error
resilience remains unexplored. To this end, we develop a fault injection
framework that systematically injects fault into the mixed-precision
computation results. We investigate how the faults affect the accuracy of
machine learning applications. Based on the error resilience characteristics,
we offer lightweight error detection and correction solutions that
significantly improve the overall model accuracy if the models experience
hardware faults. The solutions can be efficiently integrated into the
accelerator's pipelines.
</p>
</div>
</dd>
<dt><a name="item60">[60]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05784" title="Abstract">arXiv:2311.05784</a> [<a href="/pdf/2311.05784" title="Download PDF">pdf</a>, <a href="/format/2311.05784" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Are &quot;Hierarchical&quot; Visual Representations Hierarchical?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shen%2C+E">Ethan Shen</a>, 
<a href="/search/cs?searchtype=author&query=Farhadi%2C+A">Ali Farhadi</a>, 
<a href="/search/cs?searchtype=author&query=Kusupati%2C+A">Aditya Kusupati</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Learned visual representations often capture large amounts of semantic
information for accurate downstream applications. Human understanding of the
world is fundamentally grounded in hierarchy. To mimic this and further improve
representation capabilities, the community has explored "hierarchical" visual
representations that aim at modeling the underlying hierarchy of the visual
world. In this work, we set out to investigate if hierarchical visual
representations truly capture the human perceived hierarchy better than
standard learned representations. To this end, we create HierNet, a suite of 12
datasets spanning 3 kinds of hierarchy from the BREEDs subset of ImageNet.
After extensive evaluation of Hyperbolic and Matryoshka Representations across
training setups, we conclude that they do not capture hierarchy any better than
the standard representations but can assist in other aspects like search
efficiency and interpretability. Our benchmark and the datasets are
open-sourced at https://github.com/ethanlshen/HierNet.
</p>
</div>
</dd>
<dt><a name="item61">[61]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05787" title="Abstract">arXiv:2311.05787</a> [<a href="/pdf/2311.05787" title="Download PDF">pdf</a>, <a href="/format/2311.05787" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards stable real-world equation discovery with assessing  differentiating quality influence
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Masliaev%2C+M">Mikhail Masliaev</a>, 
<a href="/search/cs?searchtype=author&query=Markov%2C+I">Ilya Markov</a>, 
<a href="/search/cs?searchtype=author&query=Hvatov%2C+A">Alexander Hvatov</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">This paper explores the critical role of differentiation approaches for
data-driven differential equation discovery. Accurate derivatives of the input
data are essential for reliable algorithmic operation, particularly in
real-world scenarios where measurement quality is inevitably compromised. We
propose alternatives to the commonly used finite differences-based method,
notorious for its instability in the presence of noise, which can exacerbate
random errors in the data. Our analysis covers four distinct methods:
Savitzky-Golay filtering, spectral differentiation, smoothing based on
artificial neural networks, and the regularization of derivative variation. We
evaluate these methods in terms of applicability to problems, similar to the
real ones, and their ability to ensure the convergence of equation discovery
algorithms, providing valuable insights for robust modeling of real-world
processes.
</p>
</div>
</dd>
<dt><a name="item62">[62]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05788" title="Abstract">arXiv:2311.05788</a> [<a href="/pdf/2311.05788" title="Download PDF">pdf</a>, <a href="/format/2311.05788" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Structured Transforms Across Spaces with Cost-Regularized Optimal  Transport
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sebbouh%2C+O">Othmane Sebbouh</a>, 
<a href="/search/cs?searchtype=author&query=Cuturi%2C+M">Marco Cuturi</a>, 
<a href="/search/cs?searchtype=author&query=Peyr%C3%A9%2C+G">Gabriel Peyr&#xe9;</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Optimization and Control (math.OC); Machine Learning (stat.ML)

</div>
<p class="mathjax">Matching a source to a target probability measure is often solved by
instantiating a linear optimal transport (OT) problem, parameterized by a
ground cost function that quantifies discrepancy between points. When these
measures live in the same metric space, the ground cost often defaults to its
distance. When instantiated across two different spaces, however, choosing that
cost in the absence of aligned data is a conundrum. As a result, practitioners
often resort to solving instead a quadratic Gromow-Wasserstein (GW) problem. We
exploit in this work a parallel between GW and cost-regularized OT, the
regularized minimization of a linear OT objective parameterized by a ground
cost. We use this cost-regularized formulation to match measures across two
different Euclidean spaces, where the cost is evaluated between transformed
source points and target points. We show that several quadratic OT problems
fall in this category, and consider enforcing structure in linear transform
(e.g. sparsity), by introducing structure-inducing regularizers. We provide a
proximal algorithm to extract such transforms from unaligned data, and
demonstrate its applicability to single-cell spatial transcriptomics/multiomics
matching tasks.
</p>
</div>
</dd>
<dt><a name="item63">[63]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05790" title="Abstract">arXiv:2311.05790</a> [<a href="/pdf/2311.05790" title="Download PDF">pdf</a>, <a href="/format/2311.05790" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Paradox of Noise: An Empirical Study of Noise-Infusion Mechanisms to  Improve Generalization, Stability, and Privacy in Federated Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jafarigol%2C+E">Elaheh Jafarigol</a>, 
<a href="/search/cs?searchtype=author&query=Trafalis%2C+T">Theodore Trafalis</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">In a data-centric era, concerns regarding privacy and ethical data handling
grow as machine learning relies more on personal information. This empirical
study investigates the privacy, generalization, and stability of deep learning
models in the presence of additive noise in federated learning frameworks. Our
main objective is to provide strategies to measure the generalization,
stability, and privacy-preserving capabilities of these models and further
improve them. To this end, five noise infusion mechanisms at varying noise
levels within centralized and federated learning settings are explored. As
model complexity is a key component of the generalization and stability of deep
learning models during training and evaluation, a comparative analysis of three
Convolutional Neural Network (CNN) architectures is provided. The paper
introduces Signal-to-Noise Ratio (SNR) as a quantitative measure of the
trade-off between privacy and training accuracy of noise-infused models, aiming
to find the noise level that yields optimal privacy and accuracy. Moreover, the
Price of Stability and Price of Anarchy are defined in the context of
privacy-preserving deep learning, contributing to the systematic investigation
of the noise infusion strategies to enhance privacy without compromising
performance. Our research sheds light on the delicate balance between these
critical factors, fostering a deeper understanding of the implications of
noise-based regularization in machine learning. By leveraging noise as a tool
for regularization and privacy enhancement, we aim to contribute to the
development of robust, privacy-aware algorithms, ensuring that AI-driven
solutions prioritize both utility and privacy.
</p>
</div>
</dd>
<dt><a name="item64">[64]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05791" title="Abstract">arXiv:2311.05791</a> [<a href="/pdf/2311.05791" title="Download PDF">pdf</a>, <a href="/ps/2311.05791" title="Download PostScript">ps</a>, <a href="/format/2311.05791" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Detecting Suspicious Commenter Mob Behaviors on YouTube Using Graph2Vec
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shajari%2C+S">Shadi Shajari</a>, 
<a href="/search/cs?searchtype=author&query=Alassad%2C+M">Mustafa Alassad</a>, 
<a href="/search/cs?searchtype=author&query=Agarwal%2C+N">Nitin Agarwal</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">YouTube, a widely popular online platform, has transformed the dynamics of
con-tent consumption and interaction for users worldwide. With its extensive
range of content crea-tors and viewers, YouTube serves as a hub for video
sharing, entertainment, and information dissemination. However, the exponential
growth of users and their active engagement on the platform has raised concerns
regarding suspicious commenter behaviors, particularly in the com-ment section.
This paper presents a social network analysis-based methodology for detecting
suspicious commenter mob-like behaviors among YouTube channels and the
similarities therein. The method aims to characterize channels based on the
level of such behavior and identify com-mon patterns across them. To evaluate
the effectiveness of the proposed model, we conducted an analysis of 20 YouTube
channels, consisting of 7,782 videos, 294,199 commenters, and 596,982 comments.
These channels were specifically selected for propagating false views about the
U.S. Military. The analysis revealed significant similarities among the
channels, shedding light on the prevalence of suspicious commenter behavior. By
understanding these similarities, we contribute to a better understanding of
the dynamics of suspicious behavior on YouTube channels, which can inform
strategies for addressing and mitigating such behavior.
</p>
</div>
</dd>
<dt><a name="item65">[65]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05792" title="Abstract">arXiv:2311.05792</a> [<a href="/pdf/2311.05792" title="Download PDF">pdf</a>, <a href="/format/2311.05792" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Is a Seat at the Table Enough? Engaging Teachers and Students in Dataset  Specification for ML in Education
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tan%2C+M">Mei Tan</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+H">Hansol Lee</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+D">Dakuo Wang</a>, 
<a href="/search/cs?searchtype=author&query=Subramonyam%2C+H">Hariharan Subramonyam</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>; Artificial Intelligence (cs.AI); Human-Computer Interaction (cs.HC); Machine Learning (cs.LG)

</div>
<p class="mathjax">Despite the promises of ML in education, its adoption in the classroom has
surfaced numerous issues regarding fairness, accountability, and transparency,
as well as concerns about data privacy and student consent. A root cause of
these issues is the lack of understanding of the complex dynamics of education,
including teacher-student interactions, collaborative learning, and classroom
environment. To overcome these challenges and fully utilize the potential of ML
in education, software practitioners need to work closely with educators and
students to fully understand the context of the data (the backbone of ML
applications) and collaboratively define the ML data specifications. To gain a
deeper understanding of such a collaborative process, we conduct ten co-design
sessions with ML software practitioners, educators, and students. In the
sessions, teachers and students work with ML engineers, UX designers, and legal
practitioners to define dataset characteristics for a given ML application. We
find that stakeholders contextualize data based on their domain and procedural
knowledge, proactively design data requirements to mitigate downstream harms
and data reliability concerns, and exhibit role-based collaborative strategies
and contribution patterns. Further, we find that beyond a seat at the table,
meaningful stakeholder participation in ML requires structured supports:
defined processes for continuous iteration and co-evaluation, shared contextual
data quality standards, and information scaffolds for both technical and
non-technical stakeholders to traverse expertise boundaries.
</p>
</div>
</dd>
<dt><a name="item66">[66]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05795" title="Abstract">arXiv:2311.05795</a> [<a href="/pdf/2311.05795" title="Download PDF">pdf</a>, <a href="/format/2311.05795" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Improvements on Uncertainty Quantification for Node Classification via  Distance-Based Regularization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hart%2C+R+A">Russell Alan Hart</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+L">Linlin Yu</a>, 
<a href="/search/cs?searchtype=author&query=Lou%2C+Y">Yifei Lou</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+F">Feng Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Neurips 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
<p class="mathjax">Deep neural networks have achieved significant success in the last decades,
but they are not well-calibrated and often produce unreliable predictions. A
large number of literature relies on uncertainty quantification to evaluate the
reliability of a learning model, which is particularly important for
applications of out-of-distribution (OOD) detection and misclassification
detection. We are interested in uncertainty quantification for interdependent
node-level classification. We start our analysis based on graph posterior
networks (GPNs) that optimize the uncertainty cross-entropy (UCE)-based loss
function. We describe the theoretical limitations of the widely-used UCE loss.
To alleviate the identified drawbacks, we propose a distance-based
regularization that encourages clustered OOD nodes to remain clustered in the
latent space. We conduct extensive comparison experiments on eight standard
datasets and demonstrate that the proposed regularization outperforms the
state-of-the-art in both OOD detection and misclassification detection.
</p>
</div>
</dd>
<dt><a name="item67">[67]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05800" title="Abstract">arXiv:2311.05800</a> [<a href="/pdf/2311.05800" title="Download PDF">pdf</a>, <a href="/format/2311.05800" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Leveraging LLMs for Synthesizing Training Data Across Many Languages in  Multilingual Dense Retrieval
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Thakur%2C+N">Nandan Thakur</a>, 
<a href="/search/cs?searchtype=author&query=Ni%2C+J">Jianmo Ni</a>, 
<a href="/search/cs?searchtype=author&query=%C3%81brego%2C+G+H">Gustavo Hern&#xe1;ndez &#xc1;brego</a>, 
<a href="/search/cs?searchtype=author&query=Wieting%2C+J">John Wieting</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+J">Jimmy Lin</a>, 
<a href="/search/cs?searchtype=author&query=Cer%2C+D">Daniel Cer</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Data released at <a href="https://github.com/google-research-datasets/swim-ir">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL)

</div>
<p class="mathjax">Dense retrieval models have predominantly been studied for English, where
models have shown great success, due to the availability of human-labeled
training pairs. However, there has been limited success for multilingual
retrieval so far, as training data is uneven or scarcely available across
multiple languages. Synthetic training data generation is promising (e.g.,
InPars or Promptagator), but has been investigated only for English. Therefore,
to study model capabilities across both cross-lingual and monolingual retrieval
tasks, we develop SWIM-IR, a synthetic retrieval training dataset containing 33
(high to very-low resource) languages for training multilingual dense retrieval
models without requiring any human supervision. To construct SWIM-IR, we
propose SAP (summarize-then-ask prompting), where the large language model
(LLM) generates a textual summary prior to the query generation step. SAP
assists the LLM in generating informative queries in the target language. Using
SWIM-IR, we explore synthetic fine-tuning of multilingual dense retrieval
models and evaluate them robustly on three retrieval benchmarks: XOR-Retrieve
(cross-lingual), XTREME-UP (cross-lingual) and MIRACL (monolingual). Our
models, called SWIM-X, are competitive with human-supervised dense retrieval
models, e.g., mContriever, finding that SWIM-IR can cheaply substitute for
expensive human-labeled retrieval training data.
</p>
</div>
</dd>
<dt><a name="item68">[68]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05802" title="Abstract">arXiv:2311.05802</a> [<a href="/pdf/2311.05802" title="Download PDF">pdf</a>, <a href="/format/2311.05802" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Generative Modeling of Residuals for Real-Time Risk-Sensitive Safety  with Discrete-Time Control Barrier Functions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Cosner%2C+R+K">Ryan K. Cosner</a>, 
<a href="/search/eess?searchtype=author&query=Sadalski%2C+I">Igor Sadalski</a>, 
<a href="/search/eess?searchtype=author&query=Woo%2C+J+K">Jana K. Woo</a>, 
<a href="/search/eess?searchtype=author&query=Culbertson%2C+P">Preston Culbertson</a>, 
<a href="/search/eess?searchtype=author&query=Ames%2C+A+D">Aaron D. Ames</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages, 6 figures, submitted to the 2024 IEEE International Conference on Robotics and Automation (ICRA 2024)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">A key source of brittleness for robotic systems is the presence of model
uncertainty and external disturbances. Most existing approaches to robust
control either seek to bound the worst-case disturbance (which results in
conservative behavior), or to learn a deterministic dynamics model (which is
unable to capture uncertain dynamics or disturbances). This work proposes a
different approach: training a state-conditioned generative model to represent
the distribution of error residuals between the nominal dynamics and the actual
system. In particular we introduce the Online Risk-Informed Optimization
controller (ORIO), which uses Discrete-Time Control Barrier Functions, combined
with a learned, generative disturbance model, to ensure the safety of the
system up to some level of risk. We demonstrate our approach in both
simulations and hardware, and show our method can learn a disturbance model
that is accurate enough to enable risk-sensitive control of a quadrotor flying
aggressively with an unmodelled slung load. We use a conditional variational
autoencoder (CVAE) to learn a state-conditioned dynamics residual distribution,
and find that the resulting probabilistic safety controller, which can be run
at 100Hz on an embedded computer, exhibits less conservative behavior while
retaining theoretical safety properties.
</p>
</div>
</dd>
<dt><a name="item69">[69]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05804" title="Abstract">arXiv:2311.05804</a> [<a href="/pdf/2311.05804" title="Download PDF">pdf</a>, <a href="/format/2311.05804" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Model-as-a-Service (MaaS): A Survey
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gan%2C+W">Wensheng Gan</a>, 
<a href="/search/cs?searchtype=author&query=Wan%2C+S">Shicheng Wan</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+P+S">Philip S. Yu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Preprint. 3 figures, 1 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
<p class="mathjax">Due to the increased number of parameters and data in the pre-trained model
exceeding a certain level, a foundation model (e.g., a large language model)
can significantly improve downstream task performance and emerge with some
novel special abilities (e.g., deep learning, complex reasoning, and human
alignment) that were not present before. Foundation models are a form of
generative artificial intelligence (GenAI), and Model-as-a-Service (MaaS) has
emerged as a groundbreaking paradigm that revolutionizes the deployment and
utilization of GenAI models. MaaS represents a paradigm shift in how we use AI
technologies and provides a scalable and accessible solution for developers and
users to leverage pre-trained AI models without the need for extensive
infrastructure or expertise in model training. In this paper, the introduction
aims to provide a comprehensive overview of MaaS, its significance, and its
implications for various industries. We provide a brief review of the
development history of "X-as-a-Service" based on cloud computing and present
the key technologies involved in MaaS. The development of GenAI models will
become more democratized and flourish. We also review recent application
studies of MaaS. Finally, we highlight several challenges and future issues in
this promising area. MaaS is a new deployment and service paradigm for
different AI-based models. We hope this review will inspire future research in
the field of MaaS.
</p>
</div>
</dd>
<dt><a name="item70">[70]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05808" title="Abstract">arXiv:2311.05808</a> [<a href="/pdf/2311.05808" title="Download PDF">pdf</a>, <a href="/format/2311.05808" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Scale-MIA: A Scalable Model Inversion Attack against Secure Federated  Learning via Latent Space Reconstruction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shi%2C+S">Shanghao Shi</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+N">Ning Wang</a>, 
<a href="/search/cs?searchtype=author&query=Xiao%2C+Y">Yang Xiao</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+C">Chaoyu Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+Y">Yi Shi</a>, 
<a href="/search/cs?searchtype=author&query=Hou%2C+Y+T">Y.Thomas Hou</a>, 
<a href="/search/cs?searchtype=author&query=Lou%2C+W">Wenjing Lou</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Federated learning is known for its capability to safeguard participants'
data privacy. However, recently emerged model inversion attacks (MIAs) have
shown that a malicious parameter server can reconstruct individual users' local
data samples through model updates. The state-of-the-art attacks either rely on
computation-intensive search-based optimization processes to recover each input
batch, making scaling difficult, or they involve the malicious parameter server
adding extra modules before the global model architecture, rendering the
attacks too conspicuous and easily detectable.
<br />To overcome these limitations, we propose Scale-MIA, a novel MIA capable of
efficiently and accurately recovering training samples of clients from the
aggregated updates, even when the system is under the protection of a robust
secure aggregation protocol. Unlike existing approaches treating models as
black boxes, Scale-MIA recognizes the importance of the intricate architecture
and inner workings of machine learning models. It identifies the latent space
as the critical layer for breaching privacy and decomposes the complex recovery
task into an innovative two-step process to reduce computation complexity. The
first step involves reconstructing the latent space representations (LSRs) from
the aggregated model updates using a closed-form inversion mechanism,
leveraging specially crafted adversarial linear layers. In the second step, the
whole input batches are recovered from the LSRs by feeding them into a
fine-tuned generative decoder.
<br />We implemented Scale-MIA on multiple commonly used machine learning models
and conducted comprehensive experiments across various settings. The results
demonstrate that Scale-MIA achieves excellent recovery performance on different
datasets, exhibiting high reconstruction rates, accuracy, and attack efficiency
on a larger scale compared to state-of-the-art MIAs.
</p>
</div>
</dd>
<dt><a name="item71">[71]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05810" title="Abstract">arXiv:2311.05810</a> [<a href="/pdf/2311.05810" title="Download PDF">pdf</a>, <a href="/ps/2311.05810" title="Download PostScript">ps</a>, <a href="/format/2311.05810" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Interactive Motion Planning for Autonomous Vehicles via Adaptive  Interactive MPC
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Bhattacharyya%2C+V">Viranjan Bhattacharyya</a>, 
<a href="/search/eess?searchtype=author&query=Vahidi%2C+A">Ardalan Vahidi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">This article presents a new optimal control-based interactive motion planning
algorithm for an autonomous vehicle interacting with a human-driven vehicle.
The ego vehicle solves a joint optimization problem for its motion planning
involving costs and coupled constraints of both vehicles and applies its own
actions. The non-convex feasible region and lane discipline are handled by
introducing integer decision variables and the resulting optimization problem
is a mixed-integer quadratic program (MIQP) which is implemented via model
predictive control (MPC). Furthermore, the ego vehicle imputes the cost of
human-driven neighboring vehicle (NV) using an inverse optimal control method
based on Karush-Kuhn-Tucker (KKT) conditions and adapts the joint optimization
cost accordingly. We call the algorithm adaptive interactive mixed-integer MPC
(aiMPC). Its interaction with human subjects driving the NV in a mandatory lane
change scenario is tested in a developed software-and-human-in-the-loop
simulator. Results show the effectiveness of the presented algorithm in terms
of enhanced mobility of both the vehicles compared to baseline methods.
</p>
</div>
</dd>
<dt><a name="item72">[72]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05812" title="Abstract">arXiv:2311.05812</a> [<a href="/pdf/2311.05812" title="Download PDF">pdf</a>, <a href="/format/2311.05812" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CFBenchmark: Chinese Financial Assistant Benchmark for Large Language  Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lei%2C+Y">Yang Lei</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jiangtong Li</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+M">Ming Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+J">Junjie Hu</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+D">Dawei Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Ding%2C+Z">Zhijun Ding</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+C">Changjun Jiang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 4 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Large language models (LLMs) have demonstrated great potential in the
financial domain. Thus, it becomes important to assess the performance of LLMs
in the financial tasks. In this work, we introduce CFBenchmark, to evaluate the
performance of LLMs for Chinese financial assistant. The basic version of
CFBenchmark is designed to evaluate the basic ability in Chinese financial text
processing from three aspects~(\emph{i.e.} recognition, classification, and
generation) including eight tasks, and includes financial texts ranging in
length from 50 to over 1,800 characters. We conduct experiments on several LLMs
available in the literature with CFBenchmark-Basic, and the experimental
results indicate that while some LLMs show outstanding performance in specific
tasks, overall, there is still significant room for improvement in basic tasks
of financial text processing with existing models. In the future, we plan to
explore the advanced version of CFBenchmark, aiming to further explore the
extensive capabilities of language models in more profound dimensions as a
financial assistant in Chinese. Our codes are released at
https://github.com/TongjiFinLab/CFBenchmark.
</p>
</div>
</dd>
<dt><a name="item73">[73]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05818" title="Abstract">arXiv:2311.05818</a> [<a href="/pdf/2311.05818" title="Download PDF">pdf</a>, <a href="/format/2311.05818" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning Agile Bipedal Motions on a Quadrupedal Robot
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yunfei Li</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jinhan Li</a>, 
<a href="/search/cs?searchtype=author&query=Fu%2C+W">Wei Fu</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Y">Yi Wu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Can a quadrupedal robot perform bipedal motions like humans? Although
developing human-like behaviors is more often studied on costly bipedal robot
platforms, we present a solution over a lightweight quadrupedal robot that
unlocks the agility of the quadruped in an upright standing pose and is capable
of a variety of human-like motions. Our framework is with a bi-level structure.
At the low level is a motion-conditioned control policy that allows the
quadrupedal robot to track desired base and front limb movements while
balancing on two hind feet. The policy is commanded by a high-level motion
generator that gives trajectories of parameterized human-like motions to the
robot from multiple modalities of human input. We for the first time
demonstrate various bipedal motions on a quadrupedal robot, and showcase
interesting human-robot interaction modes including mimicking human videos,
following natural language instructions, and physical interaction.
</p>
</div>
</dd>
<dt><a name="item74">[74]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05820" title="Abstract">arXiv:2311.05820</a> [<a href="/pdf/2311.05820" title="Download PDF">pdf</a>, <a href="/format/2311.05820" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Machine Learning-powered Compact Modeling of Stochastic Electronic  Devices using Mixture Density Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hutchins%2C+J">Jack Hutchins</a>, 
<a href="/search/cs?searchtype=author&query=Alam%2C+S">Shamiul Alam</a>, 
<a href="/search/cs?searchtype=author&query=Rampini%2C+D+S">Dana S. Rampini</a>, 
<a href="/search/cs?searchtype=author&query=Oripov%2C+B+G">Bakhrom G. Oripov</a>, 
<a href="/search/cs?searchtype=author&query=McCaughan%2C+A+N">Adam N. McCaughan</a>, 
<a href="/search/cs?searchtype=author&query=Aziz%2C+A">Ahmedullah Aziz</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">The relentless pursuit of miniaturization and performance enhancement in
electronic devices has led to a fundamental challenge in the field of circuit
design and simulation: how to accurately account for the inherent stochastic
nature of certain devices. While conventional deterministic models have served
as indispensable tools for circuit designers, they fall short when it comes to
capture the subtle yet critical variability exhibited by many electronic
components. In this paper, we present an innovative approach that transcends
the limitations of traditional modeling techniques by harnessing the power of
machine learning, specifically Mixture Density Networks (MDNs), to faithfully
represent and simulate the stochastic behavior of electronic devices. We
demonstrate our approach to model heater cryotrons, where the model is able to
capture the stochastic switching dynamics observed in the experiment. Our model
shows 0.82% mean absolute error for switching probability. This paper marks a
significant step forward in the quest for accurate and versatile compact
models, poised to drive innovation in the realm of electronic circuits.
</p>
</div>
</dd>
<dt><a name="item75">[75]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05821" title="Abstract">arXiv:2311.05821</a> [<a href="/pdf/2311.05821" title="Download PDF">pdf</a>, <a href="/format/2311.05821" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Let&#x27;s Reinforce Step by Step
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pan%2C+S">Sarah Pan</a>, 
<a href="/search/cs?searchtype=author&query=Lialin%2C+V">Vladislav Lialin</a>, 
<a href="/search/cs?searchtype=author&query=Muckatira%2C+S">Sherin Muckatira</a>, 
<a href="/search/cs?searchtype=author&query=Rumshisky%2C+A">Anna Rumshisky</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> NeurIPS 2023 Workshop on Instruction Tuning and Instruction Following
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">While recent advances have boosted LM proficiency in linguistic benchmarks,
LMs consistently struggle to reason correctly on complex tasks like
mathematics. We turn to Reinforcement Learning from Human Feedback (RLHF) as a
method with which to shape model reasoning processes. In particular, we explore
two reward schemes, outcome-supervised reward models (ORMs) and
process-supervised reward models (PRMs), to optimize for logical reasoning. Our
results show that the fine-grained reward provided by PRM-based methods
enhances accuracy on simple mathematical reasoning (GSM8K) while, unexpectedly,
reducing performance in complex tasks (MATH). Furthermore, we show the critical
role reward aggregation functions play in model performance. Providing
promising avenues for future research, our study underscores the need for
further exploration into fine-grained reward modeling for more reliable
language models.
</p>
</div>
</dd>
<dt><a name="item76">[76]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05826" title="Abstract">arXiv:2311.05826</a> [<a href="/pdf/2311.05826" title="Download PDF">pdf</a>, <a href="/format/2311.05826" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Honest Score Client Selection Scheme: Preventing Federated Learning  Label Flipping Attacks in Non-IID Scenarios
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yanli Li</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+H">Huaming Chen</a>, 
<a href="/search/cs?searchtype=author&query=Bao%2C+W">Wei Bao</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+Z">Zhengmeng Xu</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+D">Dong Yuan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">Federated Learning (FL) is a promising technology that enables multiple
actors to build a joint model without sharing their raw data. The distributed
nature makes FL vulnerable to various poisoning attacks, including model
poisoning attacks and data poisoning attacks. Today, many byzantine-resilient
FL methods have been introduced to mitigate the model poisoning attack, while
the effectiveness when defending against data poisoning attacks still remains
unclear. In this paper, we focus on the most representative data poisoning
attack - "label flipping attack" and monitor its effectiveness when attacking
the existing FL methods. The results show that the existing FL methods perform
similarly in Independent and identically distributed (IID) settings but fail to
maintain the model robustness in Non-IID settings. To mitigate the weaknesses
of existing FL methods in Non-IID scenarios, we introduce the Honest Score
Client Selection (HSCS) scheme and the corresponding HSCSFL framework. In the
HSCSFL, The server collects a clean dataset for evaluation. Under each
iteration, the server collects the gradients from clients and then perform HSCS
to select aggregation candidates. The server first evaluates the performance of
each class of the global model and generates the corresponding risk vector to
indicate which class could be potentially attacked. Similarly, the server
evaluates the client's model and records the performance of each class as the
accuracy vector. The dot product of each client's accuracy vector and global
risk vector is generated as the client's host score; only the top p\% host
score clients are included in the following aggregation. Finally, server
aggregates the gradients and uses the outcome to update the global model. The
comprehensive experimental results show our HSCSFL effectively enhances the FL
robustness and defends against the "label flipping attack."
</p>
</div>
</dd>
<dt><a name="item77">[77]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05827" title="Abstract">arXiv:2311.05827</a> [<a href="/pdf/2311.05827" title="Download PDF">pdf</a>, <a href="/format/2311.05827" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AccEPT: An Acceleration Scheme for Speeding Up Edge Pipeline-parallel  Training
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yuhao Chen</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+Y">Yuxuan Yan</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Q">Qianqian Yang</a>, 
<a href="/search/cs?searchtype=author&query=Shu%2C+Y">Yuanchao Shu</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+S">Shibo He</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+Z">Zhiguo Shi</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Jiming Chen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">It is usually infeasible to fit and train an entire large deep neural network
(DNN) model using a single edge device due to the limited resources. To
facilitate intelligent applications across edge devices, researchers have
proposed partitioning a large model into several sub-models, and deploying each
of them to a different edge device to collaboratively train a DNN model.
However, the communication overhead caused by the large amount of data
transmitted from one device to another during training, as well as the
sub-optimal partition point due to the inaccurate latency prediction of
computation at each edge device can significantly slow down training. In this
paper, we propose AccEPT, an acceleration scheme for accelerating the edge
collaborative pipeline-parallel training. In particular, we propose a
light-weight adaptive latency predictor to accurately estimate the computation
latency of each layer at different devices, which also adapts to unseen devices
through continuous learning. Therefore, the proposed latency predictor leads to
better model partitioning which balances the computation loads across
participating devices. Moreover, we propose a bit-level computation-efficient
data compression scheme to compress the data to be transmitted between devices
during training. Our numerical results demonstrate that our proposed
acceleration approach is able to significantly speed up edge pipeline parallel
training up to 3 times faster in the considered experimental settings.
</p>
</div>
</dd>
<dt><a name="item78">[78]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05828" title="Abstract">arXiv:2311.05828</a> [<a href="/pdf/2311.05828" title="Download PDF">pdf</a>, <a href="/format/2311.05828" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Diffusion Shape Prior for Wrinkle-Accurate Cloth Registration
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Guo%2C+J">Jingfan Guo</a>, 
<a href="/search/cs?searchtype=author&query=Prada%2C+F">Fabian Prada</a>, 
<a href="/search/cs?searchtype=author&query=Xiang%2C+D">Donglai Xiang</a>, 
<a href="/search/cs?searchtype=author&query=Romero%2C+J">Javier Romero</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+C">Chenglei Wu</a>, 
<a href="/search/cs?searchtype=author&query=Park%2C+H+S">Hyun Soo Park</a>, 
<a href="/search/cs?searchtype=author&query=Shiratori%2C+T">Takaaki Shiratori</a>, 
<a href="/search/cs?searchtype=author&query=Saito%2C+S">Shunsuke Saito</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project page: <a href="https://www-users.cse.umn.edu/~guo00109/projects/3dv2024/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Registering clothes from 4D scans with vertex-accurate correspondence is
challenging, yet important for dynamic appearance modeling and physics
parameter estimation from real-world data. However, previous methods either
rely on texture information, which is not always reliable, or achieve only
coarse-level alignment. In this work, we present a novel approach to enabling
accurate surface registration of texture-less clothes with large deformation.
Our key idea is to effectively leverage a shape prior learned from pre-captured
clothing using diffusion models. We also propose a multi-stage guidance scheme
based on learned functional maps, which stabilizes registration for large-scale
deformation even when they vary significantly from training data. Using
high-fidelity real captured clothes, our experiments show that the proposed
approach based on diffusion models generalizes better than surface registration
with VAE or PCA-based priors, outperforming both optimization-based and
learning-based non-rigid registration methods for both interpolation and
extrapolation tests.
</p>
</div>
</dd>
<dt><a name="item79">[79]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05830" title="Abstract">arXiv:2311.05830</a> [<a href="/pdf/2311.05830" title="Download PDF">pdf</a>, <a href="/ps/2311.05830" title="Download PostScript">ps</a>, <a href="/format/2311.05830" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Are quasi-Monte Carlo sequences quasi-uniform?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Goda%2C+T">Takashi Goda</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">While this question remains widely open, in this short note, we prove that
the two-dimensional Sobol' sequence is not quasi-uniform. This result partially
answers an unsolved problem of Sobol' and Shukhman (2007) in a negative manner.
</p>
</div>
</dd>
<dt><a name="item80">[80]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05831" title="Abstract">arXiv:2311.05831</a> [<a href="/pdf/2311.05831" title="Download PDF">pdf</a>, <a href="/format/2311.05831" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Robust Constant-Time Cryptography
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kolosick%2C+M">Matthew Kolosick</a>, 
<a href="/search/cs?searchtype=author&query=Shivakumar%2C+B+A">Basavesh Ammanaghatta Shivakumar</a>, 
<a href="/search/cs?searchtype=author&query=Cauligi%2C+S">Sunjay Cauligi</a>, 
<a href="/search/cs?searchtype=author&query=Patrignani%2C+M">Marco Patrignani</a>, 
<a href="/search/cs?searchtype=author&query=Vassena%2C+M">Marco Vassena</a>, 
<a href="/search/cs?searchtype=author&query=Jhala%2C+R">Ranjit Jhala</a>, 
<a href="/search/cs?searchtype=author&query=Stefan%2C+D">Deian Stefan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">The constant-time property is considered the security standard for
cryptographic code. Code following the constant-time discipline is free from
secret-dependent branches and memory accesses, and thus avoids leaking secrets
through cache and timing side-channels. The constant-time property makes a
number of implicit assumptions that are fundamentally at odds with the reality
of cryptographic code. Constant-time is not robust. The first issue with
constant-time is that it is a whole-program property: It relies on the entirety
of the code base being constant-time. But, cryptographic developers do not
generally write whole programs; rather, they provide libraries and specific
algorithms for other application developers to use. As such, developers of
security libraries must maintain their security guarantees even when their code
is operating within (potentially untrusted) application contexts. Constant-time
requires memory safety. The whole-program nature of constant-time also leads to
a second issue: constant-time requires memory safety of all the running code.
Any memory safety bugs, whether in the library or the application, will wend
their way back to side-channel leaks of secrets if not direct disclosure. And
although cryptographic libraries should (and are) written to be memory-safe, it
is unfortunately unrealistic to expect the same from every application that
uses each library. We formalize robust constant-time and build a RobustIsoCrypt
compiler that transforms the library code and protects the secrets even when
they are linked with untrusted code. Our evaluation with SUPERCOP benchmarking
framework shows that the performance overhead is less than five percent on
average.
</p>
</div>
</dd>
<dt><a name="item81">[81]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05838" title="Abstract">arXiv:2311.05838</a> [<a href="/pdf/2311.05838" title="Download PDF">pdf</a>, <a href="/format/2311.05838" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Interpretable Motion-level Skill Assessment in Robotic Surgery
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hutchinson%2C+K">Kay Hutchinson</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+K">Katherina Chen</a>, 
<a href="/search/cs?searchtype=author&query=Alemzadeh%2C+H">Homa Alemzadeh</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 pages, 5 figures, 7 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Purpose: We study the relationship between surgical gestures and motion
primitives in dry-lab surgical exercises towards a deeper understanding of
surgical activity at fine-grained levels and interpretable feedback in skill
assessment.
<br />Methods: We analyze the motion primitive sequences of gestures in the JIGSAWS
dataset and identify inverse motion primitives in those sequences. Inverse
motion primitives are defined as sequential actions on the same object by the
same tool that effectively negate each other. We also examine the correlation
between surgical skills (measured by GRS scores) and the number and total
durations of inverse motion primitives in the dry-lab trials of Suturing,
Needle Passing, and Knot Tying tasks.
<br />Results: We find that the sequence of motion primitives used to perform
gestures can help detect labeling errors in surgical gestures. Inverse motion
primitives are often used as recovery actions to correct the position or
orientation of objects or may be indicative of other issues such as with depth
perception. The number and total durations of inverse motion primitives in
trials are also strongly correlated with lower GRS scores in the Suturing and
Knot Tying tasks.
<br />Conclusion: The sequence and pattern of motion primitives could be used to
provide interpretable feedback in surgical skill assessment. Combined with an
action recognition model, the explainability of automated skill assessment can
be improved by showing video clips of the inverse motion primitives of
inefficient or problematic movements.
</p>
</div>
</dd>
<dt><a name="item82">[82]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05842" title="Abstract">arXiv:2311.05842</a> [<a href="/pdf/2311.05842" title="Download PDF">pdf</a>, <a href="/format/2311.05842" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AI-native Interconnect Framework for Integration of Large Language Model  Technologies in 6G Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tarkoma%2C+S">Sasu Tarkoma</a>, 
<a href="/search/cs?searchtype=author&query=Morabito%2C+R">Roberto Morabito</a>, 
<a href="/search/cs?searchtype=author&query=Sauvola%2C+J">Jaakko Sauvola</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">The evolution towards 6G architecture promises a transformative shift in
communication networks, with artificial intelligence (AI) playing a pivotal
role. This paper delves deep into the seamless integration of Large Language
Models (LLMs) and Generalized Pretrained Transformers (GPT) within 6G systems.
Their ability to grasp intent, strategize, and execute intricate commands will
be pivotal in redefining network functionalities and interactions. Central to
this is the AI Interconnect framework, intricately woven to facilitate
AI-centric operations within the network. Building on the continuously evolving
current state-of-the-art, we present a new architectural perspective for the
upcoming generation of mobile networks. Here, LLMs and GPTs will
collaboratively take center stage alongside traditional pre-generative AI and
machine learning (ML) algorithms. This union promises a novel confluence of the
old and new, melding tried-and-tested methods with transformative AI
technologies. Along with providing a conceptual overview of this evolution, we
delve into the nuances of practical applications arising from such an
integration. Through this paper, we envisage a symbiotic integration where AI
becomes the cornerstone of the next-generation communication paradigm, offering
insights into the structural and functional facets of an AI-native 6G network.
</p>
</div>
</dd>
<dt><a name="item83">[83]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05843" title="Abstract">arXiv:2311.05843</a> [<a href="/pdf/2311.05843" title="Download PDF">pdf</a>, <a href="/format/2311.05843" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> TacIPC: Intersection- and Inversion-free FEM-based Elastomer Simulation  For Optical Tactile Sensors
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Du%2C+W">Wenxin Du</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+W">Wenqiang Xu</a>, 
<a href="/search/cs?searchtype=author&query=Ren%2C+J">Jieji Ren</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+Z">Zhenjun Yu</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+C">Cewu Lu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Tactile perception stands as a critical sensory modality for human
interaction with the environment. Among various tactile sensor techniques,
optical sensor-based approaches have gained traction, notably for producing
high-resolution tactile images. This work explores gel elastomer deformation
simulation through a physics-based approach. While previous works in this
direction usually adopt the explicit material point method (MPM), which has
certain limitations in force simulation and rendering, we adopt the finite
element method (FEM) and address the challenges in penetration and mesh
distortion with incremental potential contact (IPC) method. As a result, we
present a simulator named TacIPC, which can ensure numerically stable
simulations while accommodating direct rendering and friction modeling. To
evaluate TacIPC, we conduct three tasks: pseudo-image quality assessment,
deformed geometry estimation, and marker displacement prediction. These tasks
show its superior efficacy in reducing the sim-to-real gap. Our method can also
seamlessly integrate with existing simulators. More experiments and videos can
be found in the supplementary materials and on the website:
https://sites.google.com/view/tac-ipc.
</p>
</div>
</dd>
<dt><a name="item84">[84]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05844" title="Abstract">arXiv:2311.05844</a> [<a href="/pdf/2311.05844" title="Download PDF">pdf</a>, <a href="/format/2311.05844" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Face-StyleSpeech: Improved Face-to-Voice latent mapping for Natural  Zero-shot Speech Synthesis from a Face Image
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kang%2C+M">Minki Kang</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+W">Wooseok Han</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+E">Eunho Yang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to ICASSP 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Multimedia (cs.MM); Sound (cs.SD); Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">Generating a voice from a face image is crucial for developing virtual humans
capable of interacting using their unique voices, without relying on
pre-recorded human speech. In this paper, we propose Face-StyleSpeech, a
zero-shot Text-To-Speech (TTS) synthesis model that generates natural speech
conditioned on a face image rather than reference speech. We hypothesize that
learning both speaker identity and prosody from a face image poses a
significant challenge. To address the issue, our TTS model incorporates both a
face encoder and a prosody encoder. The prosody encoder is specifically
designed to model prosodic features that are not captured only with a face
image, allowing the face encoder to focus solely on capturing the speaker
identity from the face image. Experimental results demonstrate that
Face-StyleSpeech effectively generates more natural speech from a face image
than baselines, even for the face images the model has not trained. Samples are
at our demo page https://face-stylespeech.github.io.
</p>
</div>
</dd>
<dt><a name="item85">[85]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05845" title="Abstract">arXiv:2311.05845</a> [<a href="/pdf/2311.05845" title="Download PDF">pdf</a>, <a href="/format/2311.05845" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Tamil-Llama: A New Tamil Language Model Based on Llama 2
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Balachandran%2C+A">Abhinand Balachandran</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 19 pages, 10 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Language modeling has witnessed remarkable advancements in recent years, with
Large Language Models (LLMs) like ChatGPT setting unparalleled benchmarks in
human-like text generation. However, a prevailing limitation is the
underrepresentation of languages like Tamil in these cutting-edge models,
leading to suboptimal performance in diverse linguistic contexts. This paper
addresses this lacuna, enhancing the open-source LLaMA model with an addition
of 16,000 Tamil tokens, aiming to achieve superior text generation and
comprehension in the Tamil language. We strategically employ the LoRA
methodology for efficient model training on a comprehensive Tamil corpus,
ensuring computational feasibility and model robustness. Moreover, we introduce
a Tamil-translated version of the Alpaca dataset and a subset of the OpenOrca
dataset tailored for instruction fine-tuning. Our results showcase significant
performance improvements in Tamil text generation, with potential implications
for the broader landscape of LLMs in Indian languages. We further underscore
our commitment to open research by making our models, datasets, and code
publicly accessible, fostering further innovations in language modeling.
</p>
</div>
</dd>
<dt><a name="item86">[86]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05846" title="Abstract">arXiv:2311.05846</a> [<a href="/pdf/2311.05846" title="Download PDF">pdf</a>, <a href="/format/2311.05846" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Clipped-Objective Policy Gradients for Pessimistic Policy Optimization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Markowitz%2C+J">Jared Markowitz</a>, 
<a href="/search/cs?searchtype=author&query=Staley%2C+E+W">Edward W. Staley</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 8 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">To facilitate efficient learning, policy gradient approaches to deep
reinforcement learning (RL) are typically paired with variance reduction
measures and strategies for making large but safe policy changes based on a
batch of experiences. Natural policy gradient methods, including Trust Region
Policy Optimization (TRPO), seek to produce monotonic improvement through
bounded changes in policy outputs. Proximal Policy Optimization (PPO) is a
commonly used, first-order algorithm that instead uses loss clipping to take
multiple safe optimization steps per batch of data, replacing the bound on the
single step of TRPO with regularization on multiple steps. In this work, we
find that the performance of PPO, when applied to continuous action spaces, may
be consistently improved through a simple change in objective. Instead of the
importance sampling objective of PPO, we instead recommend a basic policy
gradient, clipped in an equivalent fashion. While both objectives produce
biased gradient estimates with respect to the RL objective, they also both
display significantly reduced variance compared to the unbiased off-policy
policy gradient. Additionally, we show that (1) the clipped-objective policy
gradient (COPG) objective is on average "pessimistic" compared to both the PPO
objective and (2) this pessimism promotes enhanced exploration. As a result, we
empirically observe that COPG produces improved learning compared to PPO in
single-task, constrained, and multi-task learning, without adding significant
computational cost or complexity. Compared to TRPO, the COPG approach is seen
to offer comparable or superior performance, while retaining the simplicity of
a first-order method.
</p>
</div>
</dd>
<dt><a name="item87">[87]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05850" title="Abstract">arXiv:2311.05850</a> [<a href="/pdf/2311.05850" title="Download PDF">pdf</a>, <a href="/format/2311.05850" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exploring Fine-tuning ChatGPT for News Recommendation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xinyi Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yongfeng Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Malthouse%2C+E+C">Edward C Malthouse</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>

</div>
<p class="mathjax">News recommendation systems (RS) play a pivotal role in the current digital
age, shaping how individuals access and engage with information. The fusion of
natural language processing (NLP) and RS, spurred by the rise of large language
models such as the GPT and T5 series, blurs the boundaries between these
domains, making a tendency to treat RS as a language task. ChatGPT, renowned
for its user-friendly interface and increasing popularity, has become a
prominent choice for a wide range of NLP tasks. While previous studies have
explored ChatGPT on recommendation tasks, this study breaks new ground by
investigating its fine-tuning capability, particularly within the news domain.
In this study, we design two distinct prompts: one designed to treat news RS as
the ranking task and another tailored for the rating task. We evaluate
ChatGPT's performance in news recommendation by eliciting direct responses
through the formulation of these two tasks. More importantly, we unravel the
pivotal role of fine-tuning data quality in enhancing ChatGPT's personalized
recommendation capabilities, and illustrates its potential in addressing the
longstanding challenge of the "cold item" problem in RS. Our experiments,
conducted using the Microsoft News dataset (MIND), reveal significant
improvements achieved by ChatGPT after fine-tuning, especially in scenarios
where a user's topic interests remain consistent, treating news RS as a ranking
task. This study illuminates the transformative potential of fine-tuning
ChatGPT as a means to advance news RS, offering more effective news consumption
experiences.
</p>
</div>
</dd>
<dt><a name="item88">[88]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05851" title="Abstract">arXiv:2311.05851</a> [<a href="/pdf/2311.05851" title="Download PDF">pdf</a>, <a href="/format/2311.05851" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Cognitive Architecture Toward Common Ground Sharing Among Humans and  Generative AIs: Trial on Model-Model Interactions in Tangram Naming Task
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Morita%2C+J">Junya Morita</a>, 
<a href="/search/cs?searchtype=author&query=Yui%2C+T">Tatsuya Yui</a>, 
<a href="/search/cs?searchtype=author&query=Amaya%2C+T">Takeru Amaya</a>, 
<a href="/search/cs?searchtype=author&query=Higashinaka%2C+R">Ryuichiro Higashinaka</a>, 
<a href="/search/cs?searchtype=author&query=Takeuchi%2C+Y">Yugo Takeuchi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Proceedings of the 2023 AAAI Fall Symposium on Integrating Cognitive Architectures and Generative Models
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
<p class="mathjax">For generative AIs to be trustworthy, establishing transparent common
grounding with humans is essential. As a preparation toward human-model common
grounding, this study examines the process of model-model common grounding. In
this context, common ground is defined as a cognitive framework shared among
agents in communication, enabling the connection of symbols exchanged between
agents to the meanings inherent in each agent. This connection is facilitated
by a shared cognitive framework among the agents involved. In this research, we
focus on the tangram naming task (TNT) as a testbed to examine the
common-ground-building process. Unlike previous models designed for this task,
our approach employs generative AIs to visualize the internal processes of the
model. In this task, the sender constructs a metaphorical image of an abstract
figure within the model and generates a detailed description based on this
image. The receiver interprets the generated description from the partner by
constructing another image and reconstructing the original abstract figure.
Preliminary results from the study show an improvement in task performance
beyond the chance level, indicating the effect of the common cognitive
framework implemented in the models. Additionally, we observed that incremental
backpropagations leveraging successful communication cases for a component of
the model led to a statistically significant increase in performance. These
results provide valuable insights into the mechanisms of common grounding made
by generative AIs, improving human communication with the evolving intelligent
machines in our future society.
</p>
</div>
</dd>
<dt><a name="item89">[89]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05853" title="Abstract">arXiv:2311.05853</a> [<a href="/pdf/2311.05853" title="Download PDF">pdf</a>, <a href="/format/2311.05853" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Reframing Audience Expansion through the Lens of Probability Density  Estimation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Carvalhaes%2C+C">Claudio Carvalhaes</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
<p class="mathjax">Audience expansion has become an important element of prospective marketing,
helping marketers create target audiences based on a mere representative sample
of their current customer base. Within the realm of machine learning, a favored
algorithm for scaling this sample into a broader audience hinges on a binary
classification task, with class probability estimates playing a crucial role.
In this paper, we review this technique and introduce a key change in how we
choose training examples to ensure the quality of the generated audience. We
present a simulation study based on the widely used MNIST dataset, where
consistent high precision and recall values demonstrate our approach's ability
to identify the most relevant users for an expanded audience. Our results are
easily reproducible and a Python implementation is openly available on GitHub:
\url{https://github.com/carvalhaes-ai/audience-expansion}
</p>
</div>
</dd>
<dt><a name="item90">[90]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05857" title="Abstract">arXiv:2311.05857</a> [<a href="/pdf/2311.05857" title="Download PDF">pdf</a>, <a href="/format/2311.05857" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the Design and Analysis of Parallel and Distributed Algorithms
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Purohit%2C+R">Rajendra Purohit</a>, 
<a href="/search/cs?searchtype=author&query=Chowdhary%2C+K+R">K R Chowdhary</a>, 
<a href="/search/cs?searchtype=author&query=Purohit%2C+S+D">S D Purohit</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>

</div>
<p class="mathjax">Arrival of multicore systems has enforced a new scenario in computing, the
parallel and distributed algorithms are fast replacing the older sequential
algorithms, with many challenges of these techniques. The distributed
algorithms provide distributed processing using distributed file systems and
processing units, while network is modeled as minimum cost spanning tree. On
the other hand, the parallel processing chooses different language platforms,
data parallel vs. parallel programming, and GPUs. Processing units, memory
elements and storage are connected through dynamic distributed networks in the
form of spanning trees. The article presents foundational algorithms, analysis,
and efficiency considerations.
</p>
</div>
</dd>
<dt><a name="item91">[91]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05858" title="Abstract">arXiv:2311.05858</a> [<a href="/pdf/2311.05858" title="Download PDF">pdf</a>, <a href="/format/2311.05858" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Layer-wise Auto-Weighting for Non-Stationary Test-Time Adaptation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Park%2C+J">Junyoung Park</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+J">Jin Kim</a>, 
<a href="/search/cs?searchtype=author&query=Kwon%2C+H">Hyeongjun Kwon</a>, 
<a href="/search/cs?searchtype=author&query=Yoon%2C+I">Ilhoon Yoon</a>, 
<a href="/search/cs?searchtype=author&query=Sohn%2C+K">Kwanghoon Sohn</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to WACV 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Given the inevitability of domain shifts during inference in real-world
applications, test-time adaptation (TTA) is essential for model adaptation
after deployment. However, the real-world scenario of continuously changing
target distributions presents challenges including catastrophic forgetting and
error accumulation. Existing TTA methods for non-stationary domain shifts,
while effective, incur excessive computational load, making them impractical
for on-device settings. In this paper, we introduce a layer-wise auto-weighting
algorithm for continual and gradual TTA that autonomously identifies layers for
preservation or concentrated adaptation. By leveraging the Fisher Information
Matrix (FIM), we first design the learning weight to selectively focus on
layers associated with log-likelihood changes while preserving unrelated ones.
Then, we further propose an exponential min-max scaler to make certain layers
nearly frozen while mitigating outliers. This minimizes forgetting and error
accumulation, leading to efficient adaptation to non-stationary target
distribution. Experiments on CIFAR-10C, CIFAR-100C, and ImageNet-C show our
method outperforms conventional continual and gradual TTA approaches while
significantly reducing computational load, highlighting the importance of
FIM-based learning weight in adapting to continuously or gradually shifting
target domains.
</p>
</div>
</dd>
<dt><a name="item92">[92]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05861" title="Abstract">arXiv:2311.05861</a> [<a href="/pdf/2311.05861" title="Download PDF">pdf</a>, <a href="/format/2311.05861" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Domain Generalization by Learning from Privileged Medical Imaging  Information
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Korevaar%2C+S">Steven Korevaar</a>, 
<a href="/search/cs?searchtype=author&query=Tennakoon%2C+R">Ruwan Tennakoon</a>, 
<a href="/search/cs?searchtype=author&query=O%27Brien%2C+R">Ricky O&#x27;Brien</a>, 
<a href="/search/cs?searchtype=author&query=Mahapatra%2C+D">Dwarikanath Mahapatra</a>, 
<a href="/search/cs?searchtype=author&query=Bab-Hadiasha%2C+A">Alireza Bab-Hadiasha</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Learning the ability to generalize knowledge between similar contexts is
particularly important in medical imaging as data distributions can shift
substantially from one hospital to another, or even from one machine to
another. To strengthen generalization, most state-of-the-art techniques inject
knowledge of the data distribution shifts by enforcing constraints on learned
features or regularizing parameters. We offer an alternative approach: Learning
from Privileged Medical Imaging Information (LPMII). We show that using some
privileged information such as tumor shape or location leads to stronger domain
generalization ability than current state-of-the-art techniques. This paper
demonstrates that by using privileged information to predict the severity of
intra-layer retinal fluid in optical coherence tomography scans, the
classification accuracy of a deep learning model operating on
out-of-distribution data improves from $0.911$ to $0.934$. This paper provides
a strong starting point for using privileged information in other medical
problems requiring generalization.
</p>
</div>
</dd>
<dt><a name="item93">[93]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05863" title="Abstract">arXiv:2311.05863</a> [<a href="/pdf/2311.05863" title="Download PDF">pdf</a>, <a href="/format/2311.05863" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Watermarking Vision-Language Pre-trained Models for Multi-modal  Embedding as a Service
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tang%2C+Y">Yuanmin Tang</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+J">Jing Yu</a>, 
<a href="/search/cs?searchtype=author&query=Gai%2C+K">Keke Gai</a>, 
<a href="/search/cs?searchtype=author&query=Qu%2C+X">Xiangyan Qu</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+Y">Yue Hu</a>, 
<a href="/search/cs?searchtype=author&query=Xiong%2C+G">Gang Xiong</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Q">Qi Wu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Recent advances in vision-language pre-trained models (VLPs) have
significantly increased visual understanding and cross-modal analysis
capabilities. Companies have emerged to provide multi-modal Embedding as a
Service (EaaS) based on VLPs (e.g., CLIP-based VLPs), which cost a large amount
of training data and resources for high-performance service. However, existing
studies indicate that EaaS is vulnerable to model extraction attacks that
induce great loss for the owners of VLPs. Protecting the intellectual property
and commercial ownership of VLPs is increasingly crucial yet challenging. A
major solution of watermarking model for EaaS implants a backdoor in the model
by inserting verifiable trigger embeddings into texts, but it is only
applicable for large language models and is unrealistic due to data and model
privacy. In this paper, we propose a safe and robust backdoor-based embedding
watermarking method for VLPs called VLPMarker. VLPMarker utilizes embedding
orthogonal transformation to effectively inject triggers into the VLPs without
interfering with the model parameters, which achieves high-quality copyright
verification and minimal impact on model performance. To enhance the watermark
robustness, we further propose a collaborative copyright verification strategy
based on both backdoor trigger and embedding distribution, enhancing resilience
against various attacks. We increase the watermark practicality via an
out-of-distribution trigger selection approach, removing access to the model
training data and thus making it possible for many real-world scenarios. Our
extensive experiments on various datasets indicate that the proposed
watermarking approach is effective and safe for verifying the copyright of VLPs
for multi-modal EaaS and robust against model extraction attacks. Our code is
available at https://github.com/Pter61/vlpmarker.
</p>
</div>
</dd>
<dt><a name="item94">[94]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05864" title="Abstract">arXiv:2311.05864</a> [<a href="/pdf/2311.05864" title="Download PDF">pdf</a>, <a href="/format/2311.05864" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DPR: An Algorithm Mitigate Bias Accumulation in Recommendation feedback  loops
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+H">Hangtong Xu</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+Y">Yuanbo Xu</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yongjian Yang</a>, 
<a href="/search/cs?searchtype=author&query=Zhuang%2C+F">Fuzhen Zhuang</a>, 
<a href="/search/cs?searchtype=author&query=Xiong%2C+H">Hui Xiong</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Recommendation models trained on the user feedback collected from deployed
recommendation systems are commonly biased. User feedback is considerably
affected by the exposure mechanism, as users only provide feedback on the items
exposed to them and passively ignore the unexposed items, thus producing
numerous false negative samples. Inevitably, biases caused by such user
feedback are inherited by new models and amplified via feedback loops.
Moreover, the presence of false negative samples makes negative sampling
difficult and introduces spurious information in the user preference modeling
process of the model. Recent work has investigated the negative impact of
feedback loops and unknown exposure mechanisms on recommendation quality and
user experience, essentially treating them as independent factors and ignoring
their cross-effects. To address these issues, we deeply analyze the data
exposure mechanism from the perspective of data iteration and feedback loops
with the Missing Not At Random (\textbf{MNAR}) assumption, theoretically
demonstrating the existence of an available stabilization factor in the
transformation of the exposure mechanism under the feedback loops. We further
propose Dynamic Personalized Ranking (\textbf{DPR}), an unbiased algorithm that
uses dynamic re-weighting to mitigate the cross-effects of exposure mechanisms
and feedback loops without additional information. Furthermore, we design a
plugin named Universal Anti-False Negative (\textbf{UFN}) to mitigate the
negative impact of the false negative problem. We demonstrate theoretically
that our approach mitigates the negative effects of feedback loops and unknown
exposure mechanisms. Experimental results on real-world datasets demonstrate
that models using DPR can better handle bias accumulation and the universality
of UFN in mainstream loss methods.
</p>
</div>
</dd>
<dt><a name="item95">[95]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05867" title="Abstract">arXiv:2311.05867</a> [<a href="/pdf/2311.05867" title="Download PDF">pdf</a>, <a href="/format/2311.05867" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PodReels: Human-AI Co-Creation of Video Podcast Teasers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Sitong Wang</a>, 
<a href="/search/cs?searchtype=author&query=Ning%2C+Z">Zheng Ning</a>, 
<a href="/search/cs?searchtype=author&query=Truong%2C+A">Anh Truong</a>, 
<a href="/search/cs?searchtype=author&query=Dontcheva%2C+M">Mira Dontcheva</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+D">Dingzeyu Li</a>, 
<a href="/search/cs?searchtype=author&query=Chilton%2C+L+B">Lydia B. Chilton</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">Video podcast teasers are short videos that can be shared on social media
platforms to capture interest in the full episodes of a video podcast. These
teasers enable long-form podcasters to reach new audiences and gain new
followers. However, creating a compelling teaser from an hour-long episode is
challenging. Selecting interesting clips requires significant mental effort;
editing the chosen clips into a cohesive, well-produced teaser is
time-consuming. To support the creation of video podcast teasers, we first
investigate what makes a good teaser. We combine insights from both audience
comments and creator interviews to determine a set of essential ingredients. We
also identify a common workflow shared by creators during the process. Based on
these findings, we introduce a human-AI co-creative tool called PodReels to
assist video podcasters in creating teasers. Our user study shows that PodReels
significantly reduces creators' mental demand and improves their efficiency in
producing video podcast teasers.
</p>
</div>
</dd>
<dt><a name="item96">[96]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05869" title="Abstract">arXiv:2311.05869</a> [<a href="/pdf/2311.05869" title="Download PDF">pdf</a>, <a href="/ps/2311.05869" title="Download PostScript">ps</a>, <a href="/format/2311.05869" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> One-shot data-driven design of fractional-order PID controller  considering closed-loop stability: fictitious reference signal approach
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Yonezawa%2C+A">Ansei Yonezawa</a>, 
<a href="/search/eess?searchtype=author&query=Yonezawa%2C+H">Heisei Yonezawa</a>, 
<a href="/search/eess?searchtype=author&query=Yahagi%2C+S">Shuichi Yahagi</a>, 
<a href="/search/eess?searchtype=author&query=Kajiwara%2C+I">Itsuro Kajiwara</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">A one-shot data-driven tuning method for a fractional-order
proportional-integral-derivative (FOPID) controller is proposed. The proposed
method tunes the FOPID controller in the model-reference control formulation. A
loss function is defined to evaluate the match between a given reference model
and the closed-loop response while explicitly considering the closed-loop
stability. A loss function value is based on the fictitious reference signal
computed using the input/output data. Model matching is achieved via loss
function minimization. The proposed method is simple and practical: it needs
only one-shot input/output data of a plant (no plant model required), considers
the bounded-input bounded-output stability of the closed-loop system, and
automatically determines the appropriate parameter value via optimization.
Numerical simulations show that the proposed approach facilitates good control
performance, and destabilization can be avoided even if perfect model matching
is unachievable.
</p>
</div>
</dd>
<dt><a name="item97">[97]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05870" title="Abstract">arXiv:2311.05870</a> [<a href="/pdf/2311.05870" title="Download PDF">pdf</a>, <a href="/ps/2311.05870" title="Download PostScript">ps</a>, <a href="/format/2311.05870" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Automated Heterogeneous Low-Bit Quantization of Multi-Model Deep  Learning Inference Pipeline
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mondal%2C+J">Jayeeta Mondal</a>, 
<a href="/search/cs?searchtype=author&query=Dey%2C+S">Swarnava Dey</a>, 
<a href="/search/cs?searchtype=author&query=Mukherjee%2C+A">Arijit Mukherjee</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> LBQNN@ICCV2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Optimization and Control (math.OC)

</div>
<p class="mathjax">Multiple Deep Neural Networks (DNNs) integrated into single Deep Learning
(DL) inference pipelines e.g. Multi-Task Learning (MTL) or Ensemble Learning
(EL), etc., albeit very accurate, pose challenges for edge deployment. In these
systems, models vary in their quantization tolerance and resource demands,
requiring meticulous tuning for accuracy-latency balance. This paper introduces
an automated heterogeneous quantization approach for DL inference pipelines
with multiple DNNs.
</p>
</div>
</dd>
<dt><a name="item98">[98]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05874" title="Abstract">arXiv:2311.05874</a> [<a href="/pdf/2311.05874" title="Download PDF">pdf</a>, <a href="/ps/2311.05874" title="Download PostScript">ps</a>, <a href="/format/2311.05874" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Testing Dependency of Unlabeled Databases
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Paslev%2C+V">Vered Paslev</a>, 
<a href="/search/cs?searchtype=author&query=Huleihel%2C+W">Wasim Huleihel</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 39 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Information Theory (cs.IT); Statistics Theory (math.ST)

</div>
<p class="mathjax">In this paper, we investigate the problem of deciding whether two random
databases $\mathsf{X}\in\mathcal{X}^{n\times d}$ and
$\mathsf{Y}\in\mathcal{Y}^{n\times d}$ are statistically dependent or not. This
is formulated as a hypothesis testing problem, where under the null hypothesis,
these two databases are statistically independent, while under the alternative,
there exists an unknown row permutation $\sigma$, such that $\mathsf{X}$ and
$\mathsf{Y}^\sigma$, a permuted version of $\mathsf{Y}$, are statistically
dependent with some known joint distribution, but have the same marginal
distributions as the null. We characterize the thresholds at which optimal
testing is information-theoretically impossible and possible, as a function of
$n$, $d$, and some spectral properties of the generative distributions of the
datasets. For example, we prove that if a certain function of the eigenvalues
of the likelihood function and $d$, is below a certain threshold, as
$d\to\infty$, then weak detection (performing slightly better than random
guessing) is statistically impossible, no matter what the value of $n$ is. This
mimics the performance of an efficient test that thresholds a centered version
of the log-likelihood function of the observed matrices. We also analyze the
case where $d$ is fixed, for which we derive strong (vanishing error) and weak
detection lower and upper bounds.
</p>
</div>
</dd>
<dt><a name="item99">[99]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05876" title="Abstract">arXiv:2311.05876</a> [<a href="/pdf/2311.05876" title="Download PDF">pdf</a>, <a href="/format/2311.05876" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Trends in Integration of Knowledge and Large Language Models: A Survey  and Taxonomy of Methods, Benchmarks, and Applications
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Feng%2C+Z">Zhangyin Feng</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+W">Weitao Ma</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+W">Weijiang Yu</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+L">Lei Huang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Haotian Wang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Q">Qianglong Chen</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+W">Weihua Peng</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+X">Xiaocheng Feng</a>, 
<a href="/search/cs?searchtype=author&query=Qin%2C+B">Bing Qin</a>, 
<a href="/search/cs?searchtype=author&query=liu%2C+T">Ting liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Work in progress; 22 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Large language models (LLMs) exhibit superior performance on various natural
language tasks, but they are susceptible to issues stemming from outdated data
and domain-specific limitations. In order to address these challenges,
researchers have pursued two primary strategies, knowledge editing and
retrieval augmentation, to enhance LLMs by incorporating external information
from different aspects. Nevertheless, there is still a notable absence of a
comprehensive survey. In this paper, we propose a review to discuss the trends
in integration of knowledge and large language models, including taxonomy of
methods, benchmarks, and applications. In addition, we conduct an in-depth
analysis of different methods and point out potential research directions in
the future. We hope this survey offers the community quick access and a
comprehensive overview of this research area, with the intention of inspiring
future research endeavors.
</p>
</div>
</dd>
<dt><a name="item100">[100]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05877" title="Abstract">arXiv:2311.05877</a> [<a href="/pdf/2311.05877" title="Download PDF">pdf</a>, <a href="/format/2311.05877" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Performance-Driven Benchmark for Feature Selection in Tabular Deep  Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cherepanova%2C+V">Valeriia Cherepanova</a>, 
<a href="/search/cs?searchtype=author&query=Levin%2C+R">Roman Levin</a>, 
<a href="/search/cs?searchtype=author&query=Somepalli%2C+G">Gowthami Somepalli</a>, 
<a href="/search/cs?searchtype=author&query=Geiping%2C+J">Jonas Geiping</a>, 
<a href="/search/cs?searchtype=author&query=Bruss%2C+C+B">C. Bayan Bruss</a>, 
<a href="/search/cs?searchtype=author&query=Wilson%2C+A+G">Andrew Gordon Wilson</a>, 
<a href="/search/cs?searchtype=author&query=Goldstein%2C+T">Tom Goldstein</a>, 
<a href="/search/cs?searchtype=author&query=Goldblum%2C+M">Micah Goldblum</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Conference on Neural Information Processing Systems 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Academic tabular benchmarks often contain small sets of curated features. In
contrast, data scientists typically collect as many features as possible into
their datasets, and even engineer new features from existing ones. To prevent
overfitting in subsequent downstream modeling, practitioners commonly use
automated feature selection methods that identify a reduced subset of
informative features. Existing benchmarks for tabular feature selection
consider classical downstream models, toy synthetic datasets, or do not
evaluate feature selectors on the basis of downstream performance. Motivated by
the increasing popularity of tabular deep learning, we construct a challenging
feature selection benchmark evaluated on downstream neural networks including
transformers, using real datasets and multiple methods for generating
extraneous features. We also propose an input-gradient-based analogue of Lasso
for neural networks that outperforms classical feature selection methods on
challenging problems such as selecting from corrupted or second-order features.
</p>
</div>
</dd>
<dt><a name="item101">[101]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05878" title="Abstract">arXiv:2311.05878</a> [<a href="/pdf/2311.05878" title="Download PDF">pdf</a>, <a href="/ps/2311.05878" title="Download PostScript">ps</a>, <a href="/format/2311.05878" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Central Angle Optimization for 360-degree Holographic 3D Content
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kim%2C+H">Hakdong Kim</a>, 
<a href="/search/cs?searchtype=author&query=Yoon%2C+M">Minsung Yoon</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+C">Cheongwon Kim</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Image and Video Processing (eess.IV)

</div>
<p class="mathjax">In this study, we propose a method to find an optimal central angle in deep
learning-based depth map estimation used to produce realistic holographic
content. The acquisition of RGB-depth map images as detailed as possible must
be performed to generate holograms of high quality, despite the high
computational cost. Therefore, we introduce a novel pipeline designed to
analyze various values of central angles between adjacent camera viewpoints
equidistant from the origin of an object-centered environment. Then we propose
the optimal central angle to generate high-quality holographic content. The
proposed pipeline comprises key steps such as comparing estimated depth maps
and comparing reconstructed CGHs (Computer-Generated Holograms) from RGB images
and estimated depth maps. We experimentally demonstrate and discuss the
relationship between the central angle and the quality of digital holographic
content.
</p>
</div>
</dd>
<dt><a name="item102">[102]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05880" title="Abstract">arXiv:2311.05880</a> [<a href="/pdf/2311.05880" title="Download PDF">pdf</a>, <a href="/format/2311.05880" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> High-order bounds-satisfying approximation of partial differential  equations via finite element variational inequalities
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Kirby%2C+R+C">Robert C. Kirby</a>, 
<a href="/search/math?searchtype=author&query=Shapero%2C+D">Daniel Shapero</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">Solutions to many important partial differential equations satisfy bounds
constraints, but approximations computed by finite element or finite difference
methods typically fail to respect the same conditions. Chang and Nakshatrala
enforce such bounds in finite element methods through the solution of
variational inequalities rather than linear variational problems. Here, we
provide a theoretical justification for this method, including higher-order
discretizations. We prove an abstract best approximation result for the linear
variational inequality and estimates showing that bounds-constrained
polynomials provide comparable approximation power to standard spaces. For any
unconstrained approximation to a function, there exists a constrained
approximation which is comparable in the $W^{1,p}$ norm. In practice, one
cannot efficiently represent and manipulate the entire family of
bounds-constrained polynomials, but applying bounds constraints to the
coefficients of a polynomial in the Bernstein basis guarantees those
constraints on the polynomial. Although our theoretical results do not
guaruntee high accuracy for this subset of bounds-constrained polynomials,
numerical results indicate optimal orders of accuracy for smooth solutions and
sharp resolution of features in convection-diffusion problems, all subject to
bounds constraints.
</p>
</div>
</dd>
<dt><a name="item103">[103]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05884" title="Abstract">arXiv:2311.05884</a> [<a href="/pdf/2311.05884" title="Download PDF">pdf</a>, <a href="/format/2311.05884" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Hiformer: Heterogeneous Feature Interactions Learning with Transformers  for Recommender Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gui%2C+H">Huan Gui</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+R">Ruoxi Wang</a>, 
<a href="/search/cs?searchtype=author&query=Yin%2C+K">Ke Yin</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+L">Long Jin</a>, 
<a href="/search/cs?searchtype=author&query=Kula%2C+M">Maciej Kula</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+T">Taibai Xu</a>, 
<a href="/search/cs?searchtype=author&query=Hong%2C+L">Lichan Hong</a>, 
<a href="/search/cs?searchtype=author&query=Chi%2C+E+H">Ed H. Chi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Learning feature interaction is the critical backbone to building recommender
systems. In web-scale applications, learning feature interaction is extremely
challenging due to the sparse and large input feature space; meanwhile,
manually crafting effective feature interactions is infeasible because of the
exponential solution space. We propose to leverage a Transformer-based
architecture with attention layers to automatically capture feature
interactions. Transformer architectures have witnessed great success in many
domains, such as natural language processing and computer vision. However,
there has not been much adoption of Transformer architecture for feature
interaction modeling in industry. We aim at closing the gap. We identify two
key challenges for applying the vanilla Transformer architecture to web-scale
recommender systems: (1) Transformer architecture fails to capture the
heterogeneous feature interactions in the self-attention layer; (2) The serving
latency of Transformer architecture might be too high to be deployed in
web-scale recommender systems. We first propose a heterogeneous self-attention
layer, which is a simple yet effective modification to the self-attention layer
in Transformer, to take into account the heterogeneity of feature interactions.
We then introduce \textsc{Hiformer} (\textbf{H}eterogeneous
\textbf{I}nteraction Trans\textbf{former}) to further improve the model
expressiveness. With low-rank approximation and model pruning, \hiformer enjoys
fast inference for online deployment. Extensive offline experiment results
corroborates the effectiveness and efficiency of the \textsc{Hiformer} model.
We have successfully deployed the \textsc{Hiformer} model to a real world large
scale App ranking model at Google Play, with significant improvement in key
engagement metrics (up to +2.66\%).
</p>
</div>
</dd>
<dt><a name="item104">[104]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05887" title="Abstract">arXiv:2311.05887</a> [<a href="/pdf/2311.05887" title="Download PDF">pdf</a>, <a href="/format/2311.05887" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Practical Guide to Implementing Off-Axis Stereo Projection Using  Existing Ray Tracing Libraries
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zellmann%2C+S">Stefan Zellmann</a>, 
<a href="/search/cs?searchtype=author&query=Amstutz%2C+J">Jeff Amstutz</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Graphics (cs.GR)</span>

</div>
<p class="mathjax">Virtual reality (VR) renderers driving CAVEs and similar immersive
environments use the off-axis stereo camera model so that a tracked user can
move freely in front of the projection plane. Geometrically, off-axis
projection results in asymmetric viewing frusta and generalizes the ubiquitous
perspective camera model to support positioning off the center of the
projection plane. VR renderers often integrate with larger visualization
systems that rely on libraries for position tracking and pose estimates, for
ray tracing-based rendering, and for user interaction. We demonstrate different
strategies to implement off-axis stereo projection within the constraints of
given VR applications and ray tracing libraries. We aim for minimal to no
adjustments required to the internal camera representation of such libraries.
We include host and shader code with the article that can be directly
integrated in custom applications.
</p>
</div>
</dd>
<dt><a name="item105">[105]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05888" title="Abstract">arXiv:2311.05888</a> [<a href="/pdf/2311.05888" title="Download PDF">pdf</a>, <a href="/format/2311.05888" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Low-Multi-Rank High-Order Bayesian Robust Tensor Factorization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jianan Liu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+C">Chunguang Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">The recently proposed tensor robust principal component analysis (TRPCA)
methods based on tensor singular value decomposition (t-SVD) have achieved
numerous successes in many fields. However, most of these methods are only
applicable to third-order tensors, whereas the data obtained in practice are
often of higher order, such as fourth-order color videos, fourth-order
hyperspectral videos, and fifth-order light-field images. Additionally, in the
t-SVD framework, the multi-rank of a tensor can describe more fine-grained
low-rank structure in the tensor compared with the tubal rank. However,
determining the multi-rank of a tensor is a much more difficult problem than
determining the tubal rank. Moreover, most of the existing TRPCA methods do not
explicitly model the noises except the sparse noise, which may compromise the
accuracy of estimating the low-rank tensor. In this work, we propose a novel
high-order TRPCA method, named as Low-Multi-rank High-order Bayesian Robust
Tensor Factorization (LMH-BRTF), within the Bayesian framework. Specifically,
we decompose the observed corrupted tensor into three parts, i.e., the low-rank
component, the sparse component, and the noise component. By constructing a
low-rank model for the low-rank component based on the order-$d$ t-SVD and
introducing a proper prior for the model, LMH-BRTF can automatically determine
the tensor multi-rank. Meanwhile, benefiting from the explicit modeling of both
the sparse and noise components, the proposed method can leverage information
from the noises more effectivly, leading to an improved performance of TRPCA.
Then, an efficient variational inference algorithm is established for
parameters estimation. Empirical studies on synthetic and real-world datasets
demonstrate the effectiveness of the proposed method in terms of both
qualitative and quantitative results.
</p>
</div>
</dd>
<dt><a name="item106">[106]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05890" title="Abstract">arXiv:2311.05890</a> [<a href="/pdf/2311.05890" title="Download PDF">pdf</a>, <a href="/ps/2311.05890" title="Download PostScript">ps</a>, <a href="/format/2311.05890" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Improved bounds on the Product Rank of the Permanent
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+R">Rongyu Xu</a>, 
<a href="/search/cs?searchtype=author&query=Gnang%2C+E">Edinah Gnang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Complexity (cs.CC)</span>

</div>
<p class="mathjax">We unify Ryser's and Glynn's formulas for computing the permanent into a
single framework. We then show via an orbital bound argument that the product
rank of the permanent is asymptotically upper bounded by $
\frac{\exp\left(\pi\sqrt{\frac{2n}{3}}\right)}{4\sqrt{3}n} $.
</p>
</div>
</dd>
<dt><a name="item107">[107]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05892" title="Abstract">arXiv:2311.05892</a> [<a href="/pdf/2311.05892" title="Download PDF">pdf</a>, <a href="/format/2311.05892" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Structural Parameterizations of Vertex Integrity
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gima%2C+T">Tatsuya Gima</a>, 
<a href="/search/cs?searchtype=author&query=Hanaka%2C+T">Tesshu Hanaka</a>, 
<a href="/search/cs?searchtype=author&query=Kobayashi%2C+Y">Yasuaki Kobayashi</a>, 
<a href="/search/cs?searchtype=author&query=Murai%2C+R">Ryota Murai</a>, 
<a href="/search/cs?searchtype=author&query=Ono%2C+H">Hirotaka Ono</a>, 
<a href="/search/cs?searchtype=author&query=Otachi%2C+Y">Yota Otachi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 21 pages, 6 figures, WALCOM 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>

</div>
<p class="mathjax">The graph parameter vertex integrity measures how vulnerable a graph is to a
removal of a small number of vertices. More precisely, a graph with small
vertex integrity admits a small number of vertex removals to make the remaining
connected components small. In this paper, we initiate a systematic study of
structural parameterizations of the problem of computing the
unweighted/weighted vertex integrity. As structural graph parameters, we
consider well-known parameters such as clique-width, treewidth, pathwidth,
treedepth, modular-width, neighborhood diversity, twin cover number, and
cluster vertex deletion number. We show several positive and negative results
and present sharp complexity contrasts.
</p>
</div>
</dd>
<dt><a name="item108">[108]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05896" title="Abstract">arXiv:2311.05896</a> [<a href="/pdf/2311.05896" title="Download PDF">pdf</a>, <a href="/format/2311.05896" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Optimal Privacy-Aware Dynamic Estimation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Weng%2C+C">Chuanghong Weng</a>, 
<a href="/search/eess?searchtype=author&query=Nekouei%2C+E">Ehsan Nekouei</a>, 
<a href="/search/eess?searchtype=author&query=Johansson%2C+K+H">Karl H. Johansson</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">In this paper, we develop an information-theoretic framework for the optimal
privacy-aware estimation of the states of a (linear or nonlinear) system. In
our setup, a private process, modeled as a first-order Markov chain, derives
the states of the system, and the state estimates are shared with an untrusted
party who might attempt to infer the private process based on the state
estimates. As the privacy metric, we use the mutual information between the
private process and the state estimates. We first show that the privacy-aware
estimation is a closed-loop control problem wherein the estimator controls the
belief of the adversary about the private process. We also derive the Bellman
optimality principle for the optimal privacy-aware estimation problem, which is
used to study the structural properties of the optimal estimator. We next
develop a policy gradient algorithm, for computing an optimal estimation
policy, based on a novel variational formulation of the mutual information. We
finally study the performance of the optimal estimator in a building automation
application.
</p>
</div>
</dd>
<dt><a name="item109">[109]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05897" title="Abstract">arXiv:2311.05897</a> [<a href="/pdf/2311.05897" title="Download PDF">pdf</a>, <a href="/ps/2311.05897" title="Download PostScript">ps</a>, <a href="/format/2311.05897" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Stability Problems on D-finite Functions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+S">Shaoshi Chen</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+R">Ruyong Feng</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+Z">Zewang Guo</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+W">Wei Lu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Proceedings of ISSAC'23,2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Symbolic Computation (cs.SC)</span>; Classical Analysis and ODEs (math.CA); Dynamical Systems (math.DS)

</div>
<p class="mathjax">This paper continues the studies of symbolic integration by focusing on the
stability problems on D-finite functions. We introduce the notion of stability
index in order to investigate the order growth of the differential operators
satisfied by iterated integrals of D-finite functions and determine bounds and
exact formula for stability indices of several special classes of differential
operators. With the basic properties of stability index, we completely solve
the stability problem on general hyperexponential functions.
</p>
</div>
</dd>
<dt><a name="item110">[110]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05902" title="Abstract">arXiv:2311.05902</a> [<a href="/pdf/2311.05902" title="Download PDF">pdf</a>, <a href="/ps/2311.05902" title="Download PostScript">ps</a>, <a href="/format/2311.05902" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Citation Recommendation on Scholarly Legal Articles
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Arslan%2C+D">Do&#x11f;ukan Arslan</a>, 
<a href="/search/cs?searchtype=author&query=Erdo%C4%9Fan%2C+S+S">Saadet Sena Erdo&#x11f;an</a>, 
<a href="/search/cs?searchtype=author&query=Eryi%C4%9Fit%2C+G">G&#xfc;l&#x15f;en Eryi&#x11f;it</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Seventeenth International Workshop on Juris-informatics (JURISIN 2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Computation and Language (cs.CL)

</div>
<p class="mathjax">Citation recommendation is the task of finding appropriate citations based on
a given piece of text. The proposed datasets for this task consist mainly of
several scientific fields, lacking some core ones, such as law. Furthermore,
citation recommendation is used within the legal domain to identify supporting
arguments, utilizing non-scholarly legal articles. In order to alleviate the
limitations of existing studies, we gather the first scholarly legal dataset
for the task of citation recommendation. Also, we conduct experiments with
state-of-the-art models and compare their performance on this dataset. The
study suggests that, while BM25 is a strong benchmark for the legal citation
recommendation task, the most effective method involves implementing a two-step
process that entails pre-fetching with BM25+, followed by re-ranking with
SciNCL, which enhances the performance of the baseline from 0.26 to 0.30
MAP@10. Moreover, fine-tuning leads to considerable performance increases in
pre-trained models, which shows the importance of including legal articles in
the training data of these models.
</p>
</div>
</dd>
<dt><a name="item111">[111]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05903" title="Abstract">arXiv:2311.05903</a> [<a href="/pdf/2311.05903" title="Download PDF">pdf</a>, <a href="/format/2311.05903" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Establishing Performance Baselines in Fine-Tuning, Retrieval-Augmented  Generation and Soft-Prompting for Non-Specialist LLM Users
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dodgson%2C+J">Jennifer Dodgson</a>, 
<a href="/search/cs?searchtype=author&query=Nanzheng%2C+L">Lin Nanzheng</a>, 
<a href="/search/cs?searchtype=author&query=Peh%2C+J">Julian Peh</a>, 
<a href="/search/cs?searchtype=author&query=Pattirane%2C+A+R+J">Akira Rafhael Janson Pattirane</a>, 
<a href="/search/cs?searchtype=author&query=Alhajir%2C+A+D">Alfath Daryl Alhajir</a>, 
<a href="/search/cs?searchtype=author&query=Dinarto%2C+E+R">Eko Ridho Dinarto</a>, 
<a href="/search/cs?searchtype=author&query=Lim%2C+J">Joseph Lim</a>, 
<a href="/search/cs?searchtype=author&query=Ahmad%2C+S+D">Syed Danyal Ahmad</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Research into methods for improving the performance of large language models
(LLMs) through fine-tuning, retrieval-augmented generation (RAG) and
soft-prompting has tended to focus on the use of highly technical or high-cost
techniques, making many of the newly discovered approaches comparatively
inaccessible to non-technical users. In this paper we tested an unmodified
version of GPT 3.5, a fine-tuned version, and the same unmodified model when
given access to a vectorised RAG database, both in isolation and in combination
with a basic, non-algorithmic soft prompt. In each case we tested the model's
ability to answer a set of 100 questions relating primarily to events that
occurred after September 2021 (the point at which GPT 3.5's training data set
ends). We found that if commercial platforms are used and default settings are
applied with no iteration in order to establish a baseline set of outputs, a
fine-tuned model outperforms GPT 3.5 Turbo, while the RAG approach
out-performed both. The application of a soft prompt significantly improved the
performance of each approach.
</p>
</div>
</dd>
<dt><a name="item112">[112]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05907" title="Abstract">arXiv:2311.05907</a> [<a href="/pdf/2311.05907" title="Download PDF">pdf</a>, <a href="/format/2311.05907" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Sensing-Assisted Sparse Channel Recovery for Massive Antenna Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ren%2C+Z">Zixiang Ren</a>, 
<a href="/search/cs?searchtype=author&query=Qiu%2C+L">Ling Qiu</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+J">Jie Xu</a>, 
<a href="/search/cs?searchtype=author&query=Ng%2C+D+W+K">Derrick Wing Kwan Ng</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages, 4 figs
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">This correspondence presents a novel sensing-assisted sparse channel recovery
approach for massive antenna wireless communication systems. We focus on a
fundamental configuration with one massive-antenna base station (BS) and one
single-antenna communication user (CU). The wireless channel exhibits sparsity
and consists of multiple paths associated with scatterers detectable via radar
sensing. Under this setup, the BS first sends downlink pilots to the CU and
concurrently receives the echo pilot signals for sensing the surrounding
scatterers. Subsequently, the CU sends feedback information on its received
pilot signal to the BS. Accordingly, the BS determines the sparse basis based
on the sensed scatterers and proceeds to recover the wireless channel,
exploiting the feedback information based on advanced compressive sensing (CS)
algorithms. Numerical results show that the proposed sensing-assisted approach
significantly increases the overall achievable rate than the conventional
design relying on a discrete Fourier transform (DFT)-based sparse basis without
sensing, thanks to the reduced training overhead and enhanced recovery accuracy
with limited feedback.
</p>
</div>
</dd>
<dt><a name="item113">[113]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05908" title="Abstract">arXiv:2311.05908</a> [<a href="/pdf/2311.05908" title="Download PDF">pdf</a>, <a href="/format/2311.05908" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FlashFFTConv: Efficient Convolutions for Long Sequences with Tensor  Cores
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fu%2C+D+Y">Daniel Y. Fu</a>, 
<a href="/search/cs?searchtype=author&query=Kumbong%2C+H">Hermann Kumbong</a>, 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+E">Eric Nguyen</a>, 
<a href="/search/cs?searchtype=author&query=R%C3%A9%2C+C">Christopher R&#xe9;</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Convolution models with long filters have demonstrated state-of-the-art
reasoning abilities in many long-sequence tasks but lag behind the most
optimized Transformers in wall-clock time. A major bottleneck is the Fast
Fourier Transform (FFT)--which allows long convolutions to run in $O(N logN)$
time in sequence length $N$ but has poor hardware utilization. In this paper,
we study how to optimize the FFT convolution. We find two key bottlenecks: the
FFT does not effectively use specialized matrix multiply units, and it incurs
expensive I/O between layers of the memory hierarchy. In response, we propose
FlashFFTConv. FlashFFTConv uses a matrix decomposition that computes the FFT
using matrix multiply units and enables kernel fusion for long sequences,
reducing I/O. We also present two sparse convolution algorithms--1) partial
convolutions and 2) frequency-sparse convolutions--which can be implemented
simply by skipping blocks in the matrix decomposition, enabling further
opportunities for memory and compute savings. FlashFFTConv speeds up exact FFT
convolutions by up to 7.93$\times$ over PyTorch and achieves up to 4.4$\times$
speedup end-to-end. Given the same compute budget, FlashFFTConv allows
Hyena-GPT-s to achieve 2.3 points better perplexity on the PILE and
M2-BERT-base to achieve 3.3 points higher GLUE score--matching models with
twice the parameter count. FlashFFTConv also achieves 96.1% accuracy on
Path-512, a high-resolution vision task where no model had previously achieved
better than 50%. Furthermore, partial convolutions enable longer-sequence
models--yielding the first DNA model that can process the longest human genes
(2.3M base pairs)--and frequency-sparse convolutions speed up pretrained models
while maintaining or improving model quality.
</p>
</div>
</dd>
<dt><a name="item114">[114]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05909" title="Abstract">arXiv:2311.05909</a> [<a href="/pdf/2311.05909" title="Download PDF">pdf</a>, <a href="/ps/2311.05909" title="Download PostScript">ps</a>, <a href="/format/2311.05909" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> How Embeddedness Affects the Evolution of Collaboration: The Role of  Knowledge Stock and Social Interactions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+H">Hongshu Chen</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+Q">Qianqian Jin</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xuefeng Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 2 pages, 1 figure. Conference presentation
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>

</div>
<p class="mathjax">Science and technology are becoming increasingly collaborative. This paper
aims to explore the factors and mechanisms that impact the dynamic changes of
collaborative innovation networks. We consider both collaborative interactions
of organizations and their knowledge element exchanges to reveal how social and
knowledge network embeddedness affects the collaboration dynamics. Knowledge
elements are extracted to present the core concepts of scientific and technical
information, overcoming the limitations of using predefined categorizations
such as IPC when representing the content. Based on multiple collaboration and
knowledge networks, we then conduct a longitudinal analysis and apply a
stochastic actor-oriented model (SAOM) to model network dynamics over different
periods. The influence of network features and structures, individual node
characteristics, and various dimensions of proximity on collaboration dynamics
is tested and analyzed.
</p>
</div>
</dd>
<dt><a name="item115">[115]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05911" title="Abstract">arXiv:2311.05911</a> [<a href="/pdf/2311.05911" title="Download PDF">pdf</a>, <a href="/ps/2311.05911" title="Download PostScript">ps</a>, <a href="/format/2311.05911" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An alternative for one-hot encoding in neural network models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zlati%C4%87%2C+L">Lazar Zlati&#x107;</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">This paper proposes an algorithm that implements binary encoding of the
categorical features of neural network model input data, while also
implementing changes in the forward and backpropagation procedures in order to
achieve the property of having model weight changes, that result from the
neural network learning process for certain data instances of some feature
category, only affect the forward pass calculations for input data instances of
that same feature category, as it is in the case of utilising one-hot encoding
for categorical features.
</p>
</div>
</dd>
<dt><a name="item116">[116]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05912" title="Abstract">arXiv:2311.05912</a> [<a href="/pdf/2311.05912" title="Download PDF">pdf</a>, <a href="/format/2311.05912" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> BPCoach: Exploring Hero Drafting in Professional MOBA Tournaments via  Visual Analytics
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+S">Shiyi Liu</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+R">Ruofei Ma</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+C">Chuyi Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zhenbang Li</a>, 
<a href="/search/cs?searchtype=author&query=Xiao%2C+J">Jianpeng Xiao</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Q">Quan Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by The 2024 ACM SIGCHI Conference on Computer-Supported Cooperative Work &amp; Social Computing (CSCW) (Proc. CSCW 2024)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">Hero drafting for multiplayer online arena (MOBA) games is crucial because
drafting directly affects the outcome of a match. Both sides take turns to
"ban"/"pick" a hero from a roster of approximately 100 heroes to assemble their
drafting. In professional tournaments, the process becomes more complex as
teams are not allowed to pick heroes used in the previous rounds with the
"best-of-N" rule. Additionally, human factors including the team's familiarity
with drafting and play styles are overlooked by previous studies. Meanwhile,
the huge impact of patch iteration on drafting strengths in the professional
tournament is of concern. To this end, we propose a visual analytics system,
BPCoach, to facilitate hero drafting planning by comparing various drafting
through recommendations and predictions and distilling relevant human and
in-game factors. Two case studies, expert feedback, and a user study suggest
that BPCoach helps determine hero drafting in a rounded and efficient manner.
</p>
</div>
</dd>
<dt><a name="item117">[117]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05913" title="Abstract">arXiv:2311.05913</a> [<a href="/pdf/2311.05913" title="Download PDF">pdf</a>, <a href="/ps/2311.05913" title="Download PostScript">ps</a>, <a href="/format/2311.05913" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Conditional lower bounds for sparse parameterized 2-CSP: A streamlined  proof
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=S.%2C+K+C">Karthik C. S.</a>, 
<a href="/search/cs?searchtype=author&query=Marx%2C+D">D&#xe1;niel Marx</a>, 
<a href="/search/cs?searchtype=author&query=Pilipczuk%2C+M">Marcin Pilipczuk</a>, 
<a href="/search/cs?searchtype=author&query=Souza%2C+U">U&#xe9;verton Souza</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Complexity (cs.CC)</span>; Data Structures and Algorithms (cs.DS)

</div>
<p class="mathjax">Assuming the Exponential Time Hypothesis (ETH), a result of Marx (ToC'10)
implies that there is no $f(k)\cdot n^{o(k/\log k)}$ time algorithm that can
solve 2-CSPs with $k$ constraints (over a domain of arbitrary large size $n$)
for any computable function $f$. This lower bound is widely used to show that
certain parameterized problems cannot be solved in time $f(k)\cdot n^{o(k/\log
k)}$ time (assuming the ETH). The purpose of this note is to give a streamlined
proof of this result.
</p>
</div>
</dd>
<dt><a name="item118">[118]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05915" title="Abstract">arXiv:2311.05915</a> [<a href="/pdf/2311.05915" title="Download PDF">pdf</a>, <a href="/format/2311.05915" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fake Alignment: Are LLMs Really Aligned Well?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yixu Wang</a>, 
<a href="/search/cs?searchtype=author&query=Teng%2C+Y">Yan Teng</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+K">Kexin Huang</a>, 
<a href="/search/cs?searchtype=author&query=Lyu%2C+C">Chengqi Lyu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+S">Songyang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+W">Wenwei Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+X">Xingjun Ma</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yingchun Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">The growing awareness of safety concerns in large language models (LLMs) has
sparked considerable interest in the evaluation of safety within current
research endeavors. This study investigates an interesting issue pertaining to
the evaluation of LLMs, namely the substantial discrepancy in performance
between multiple-choice questions and open-ended questions. Inspired by
research on jailbreak attack patterns, we argue this is caused by mismatched
generalization. That is, the LLM does not have a comprehensive understanding of
the complex concept of safety. Instead, it only remembers what to answer for
open-ended safety questions, which makes it unable to solve other forms of
safety tests. We refer to this phenomenon as fake alignment and construct a
comparative benchmark to empirically verify its existence in LLMs. Such fake
alignment renders previous evaluation protocols unreliable. To address this, we
introduce the FAEF framework and two novel metrics\textemdash Consistency Score
(CS) and Consistent Safety Score (CSS), which jointly assess two complementary
forms of evaluation to quantify fake alignment and obtain corrected performance
estimates. Applying FAEF to 14 widely-used LLMs reveals several models with
purported safety are poorly aligned in practice. Our work highlights potential
limitations in prevailing alignment methodologies.
</p>
</div>
</dd>
<dt><a name="item119">[119]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05918" title="Abstract">arXiv:2311.05918</a> [<a href="/pdf/2311.05918" title="Download PDF">pdf</a>, <a href="/format/2311.05918" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Reliable Broadcast despite Mobile Byzantine Faults
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bonomi%2C+S">Silvia Bonomi</a> (DIAG UNIROMA), 
<a href="/search/cs?searchtype=author&query=Farina%2C+G">Giovanni Farina</a> (DIAG UNIROMA), 
<a href="/search/cs?searchtype=author&query=Tixeuil%2C+S">S&#xe9;bastien Tixeuil</a> (NPA)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>

</div>
<p class="mathjax">We investigate the solvability of the Byzantine Reliable Broadcast and
Byzantine Broadcast Channel problems in distributed systems affected by Mobile
Byzantine Faults. We show that both problems are not solvable even in one of
the most constrained system models for mobile Byzantine faults defined so far.
By endowing processes with an additional local failure oracle, we provide a
solution to the Byzantine Broadcast Channel problem.
</p>
</div>
</dd>
<dt><a name="item120">[120]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05919" title="Abstract">arXiv:2311.05919</a> [<a href="/pdf/2311.05919" title="Download PDF">pdf</a>, <a href="/format/2311.05919" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Inter-object Discriminative Graph Modeling for Indoor Scene Recognition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Song%2C+C">Chuanxin Song</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+H">Hanbo Wu</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+X">Xin Ma</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yibin Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Variable scene layouts and coexisting objects across scenes make indoor scene
recognition still a challenging task. Leveraging object information within
scenes to enhance the distinguishability of feature representations has emerged
as a key approach in this domain. Currently, most object-assisted methods use a
separate branch to process object information, combining object and scene
features heuristically. However, few of them pay attention to interpretably
handle the hidden discriminative knowledge within object information. In this
paper, we propose to leverage discriminative object knowledge to enhance scene
feature representations. Initially, we capture the object-scene discriminative
relationships from a probabilistic perspective, which are transformed into an
Inter-Object Discriminative Prototype (IODP). Given the abundant prior
knowledge from IODP, we subsequently construct a Discriminative Graph Network
(DGN), in which pixel-level scene features are defined as nodes and the
discriminative relationships between node features are encoded as edges. DGN
aims to incorporate inter-object discriminative knowledge into the image
representation through graph convolution. With the proposed IODP and DGN, we
obtain state-of-the-art results on several widely used scene datasets,
demonstrating the effectiveness of the proposed approach.
</p>
</div>
</dd>
<dt><a name="item121">[121]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05920" title="Abstract">arXiv:2311.05920</a> [<a href="/pdf/2311.05920" title="Download PDF">pdf</a>, <a href="/format/2311.05920" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Understanding How People with Binge Eating Disorder and Bulimia Interact  with Digital Food Content
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Choi%2C+R">Ryuhaerang Choi</a>, 
<a href="/search/cs?searchtype=author&query=Park%2C+S">Subin Park</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+S">Sujin Han</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+S">Sung-Ju Lee</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 21 pages, 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Computers and Society (cs.CY); Multimedia (cs.MM)

</div>
<p class="mathjax">A large body of research has focused on understanding how online content and
disordered eating behaviors are associated. However, there is a lack of
comprehensive studies investigating digital food content's influence on
individuals with eating disorders. We conducted two rounds of studies (N=23 and
22, respectively) with individuals with eating disorders to understand their
motivations and practices of consuming digital food content. Our study reveals
that individuals with eating disorders anticipate positive effects from digital
food media to overcome their condition, but in practice, it often exacerbates
their disorder. We also discovered that many individuals have experienced a
cycle of quitting and returning to digital food content consumption. Based on
these findings, we articulate design implications for digital food content and
multimedia platforms to support individuals vulnerable in everyday online
platform interactions.
</p>
</div>
</dd>
<dt><a name="item122">[122]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05921" title="Abstract">arXiv:2311.05921</a> [<a href="/pdf/2311.05921" title="Download PDF">pdf</a>, <a href="/format/2311.05921" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Wi-Fi Signal-Based Human Activity Recognition Using High-Dimensional  Factor Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Liu%2C+J">Junshuo Liu</a>, 
<a href="/search/eess?searchtype=author&query=Wang%2C+F">Fuhai Wang</a>, 
<a href="/search/eess?searchtype=author&query=Li%2C+Z">Zhe Li</a>, 
<a href="/search/eess?searchtype=author&query=Xiong%2C+R">Rujing Xiong</a>, 
<a href="/search/eess?searchtype=author&query=Mi%2C+T">Tiebin Mi</a>, 
<a href="/search/eess?searchtype=author&query=Qiu%2C+R+C">Robert Caiming Qiu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">Passive sensing techniques based on Wi-Fi signals have emerged as a promising
technology in advanced wireless communication systems due to their widespread
application and cost-effectiveness. However, the proliferation of low-cost
Internet of Things (IoT) devices has led to dense network deployments,
resulting in increased levels of noise and interference in Wi-Fi environments.
This, in turn, leads to noisy and redundant Channel State Information (CSI)
data. As a consequence, the accuracy of human activity recognition based on
Wi-Fi signals is compromised. To address this issue, we propose a novel CSI
data signal extraction method. We established a human activity recognition
system based on the Intel 5300 network interface cards (NICs) and collected a
dataset containing six categories of human activities. Using our approach,
signals extracted from the CSI data serve as inputs to machine learning (ML)
classification algorithms to evaluate classification performance. In comparison
to ML methods based on Principal Component Analysis (PCA), our proposed
High-Dimensional Factor Model (HDFM) method improves recognition accuracy by
6.8%.
</p>
</div>
</dd>
<dt><a name="item123">[123]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05922" title="Abstract">arXiv:2311.05922</a> [<a href="/pdf/2311.05922" title="Download PDF">pdf</a>, <a href="/format/2311.05922" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Chain of Thought with Explicit Evidence Reasoning for Few-shot Relation  Extraction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ma%2C+X">Xilai Ma</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jing Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+M">Min Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Findings of EMNLP 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Few-shot relation extraction involves identifying the type of relationship
between two specific entities within a text, using a limited number of
annotated samples. A variety of solutions to this problem have emerged by
applying meta-learning and neural graph techniques which typically necessitate
a training process for adaptation. Recently, the strategy of in-context
learning has been demonstrating notable results without the need of training.
Few studies have already utilized in-context learning for zero-shot information
extraction. Unfortunately, the evidence for inference is either not considered
or implicitly modeled during the construction of chain-of-thought prompts. In
this paper, we propose a novel approach for few-shot relation extraction using
large language models, named CoT-ER, chain-of-thought with explicit evidence
reasoning. In particular, CoT-ER first induces large language models to
generate evidences using task-specific and concept-level knowledge. Then these
evidences are explicitly incorporated into chain-of-thought prompting for
relation extraction. Experimental results demonstrate that our CoT-ER approach
(with 0% training data) achieves competitive performance compared to the
fully-supervised (with 100% training data) state-of-the-art approach on the
FewRel1.0 and FewRel2.0 datasets.
</p>
</div>
</dd>
<dt><a name="item124">[124]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05924" title="Abstract">arXiv:2311.05924</a> [<a href="/pdf/2311.05924" title="Download PDF">pdf</a>, <a href="/format/2311.05924" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Federated Learning with Manifold Regularization and Normalized Update  Reaggregation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=An%2C+X">Xuming An</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+L">Li Shen</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+H">Han Hu</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+Y">Yong Luo</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Federated Learning (FL) is an emerging collaborative machine learning
framework where multiple clients train the global model without sharing their
own datasets. In FL, the model inconsistency caused by the local data
heterogeneity across clients results in the near-orthogonality of client
updates, which leads to the global update norm reduction and slows down the
convergence. Most previous works focus on eliminating the difference of
parameters (or gradients) between the local and global models, which may fail
to reflect the model inconsistency due to the complex structure of the machine
learning model and the Euclidean space's limitation in meaningful geometric
representations. In this paper, we propose FedMRUR by adopting the manifold
model fusion scheme and a new global optimizer to alleviate the negative
impacts. Concretely, FedMRUR adopts a hyperbolic graph manifold regularizer
enforcing the representations of the data in the local and global models are
close to each other in a low-dimensional subspace. Because the machine learning
model has the graph structure, the distance in hyperbolic space can reflect the
model bias better than the Euclidean distance. In this way, FedMRUR exploits
the manifold structures of the representations to significantly reduce the
model inconsistency. FedMRUR also aggregates the client updates norms as the
global update norm, which can appropriately enlarge each client's contribution
to the global update, thereby mitigating the norm reduction introduced by the
near-orthogonality of client updates. Furthermore, we theoretically prove that
our algorithm can achieve a linear speedup property for non-convex setting
under partial client participation.Experiments demonstrate that FedMRUR can
achieve a new state-of-the-art (SOTA) accuracy with less communication.
</p>
</div>
</dd>
<dt><a name="item125">[125]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05927" title="Abstract">arXiv:2311.05927</a> [<a href="/pdf/2311.05927" title="Download PDF">pdf</a>, <a href="/format/2311.05927" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Automated Sperm Assessment Framework and Neural Network Specialized for  Sperm Video Recognition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fujii%2C+T">Takuro Fujii</a>, 
<a href="/search/cs?searchtype=author&query=Nakagawa%2C+H">Hayato Nakagawa</a>, 
<a href="/search/cs?searchtype=author&query=Takeshima%2C+T">Teppei Takeshima</a>, 
<a href="/search/cs?searchtype=author&query=Yumura%2C+Y">Yasushi Yumura</a>, 
<a href="/search/cs?searchtype=author&query=Hamagami%2C+T">Tomoki Hamagami</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at Winter Conference on Applications of Computer Vision (WACV) 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Infertility is a global health problem, and an increasing number of couples
are seeking medical assistance to achieve reproduction, at least half of which
are caused by men. The success rate of assisted reproductive technologies
depends on sperm assessment, in which experts determine whether sperm can be
used for reproduction based on morphology and motility of sperm. Previous sperm
assessment studies with deep learning have used datasets comprising images that
include only sperm heads, which cannot consider motility and other morphologies
of sperm. Furthermore, the labels of the dataset are one-hot, which provides
insufficient support for experts, because assessment results are inconsistent
between experts, and they have no absolute answer. Therefore, we constructed
the video dataset for sperm assessment whose videos include sperm head as well
as neck and tail, and its labels were annotated with soft-label. Furthermore,
we proposed the sperm assessment framework and the neural network, RoSTFine,
for sperm video recognition. Experimental results showed that RoSTFine could
improve the sperm assessment performances compared to existing video
recognition models and focus strongly on important sperm parts (i.e., head and
neck).
</p>
</div>
</dd>
<dt><a name="item126">[126]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05928" title="Abstract">arXiv:2311.05928</a> [<a href="/pdf/2311.05928" title="Download PDF">pdf</a>, <a href="/format/2311.05928" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Shape of Learning: Anisotropy and Intrinsic Dimensions in  Transformer-Based Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Razzhigaev%2C+A">Anton Razzhigaev</a>, 
<a href="/search/cs?searchtype=author&query=Mikhalchuk%2C+M">Matvey Mikhalchuk</a>, 
<a href="/search/cs?searchtype=author&query=Goncharova%2C+E">Elizaveta Goncharova</a>, 
<a href="/search/cs?searchtype=author&query=Oseledets%2C+I">Ivan Oseledets</a>, 
<a href="/search/cs?searchtype=author&query=Dimitrov%2C+D">Denis Dimitrov</a>, 
<a href="/search/cs?searchtype=author&query=Kuznetsov%2C+A">Andrey Kuznetsov</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to EACL-2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Information Theory (cs.IT); Machine Learning (cs.LG); General Topology (math.GN)

</div>
<p class="mathjax">In this study, we present an investigation into the anisotropy dynamics and
intrinsic dimension of embeddings in transformer architectures, focusing on the
dichotomy between encoders and decoders. Our findings reveal that the
anisotropy profile in transformer decoders exhibits a distinct bell-shaped
curve, with the highest anisotropy concentrations in the middle layers. This
pattern diverges from the more uniformly distributed anisotropy observed in
encoders. In addition, we found that the intrinsic dimension of embeddings
increases in the initial phases of training, indicating an expansion into
higher-dimensional space. Which is then followed by a compression phase towards
the end of training with dimensionality decrease, suggesting a refinement into
more compact representations. Our results provide fresh insights to the
understanding of encoders and decoders embedding properties.
</p>
</div>
</dd>
<dt><a name="item127">[127]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05929" title="Abstract">arXiv:2311.05929</a> [<a href="/pdf/2311.05929" title="Download PDF">pdf</a>, <a href="/format/2311.05929" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Efficient Segmentation with Texture in Ore Images Based on  Box-supervised Approach
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sun%2C+G">Guodong Sun</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+D">Delong Huang</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+Y">Yuting Peng</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+L">Le Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+B">Bo Wu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yang Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages, 8 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Image and Video Processing (eess.IV)

</div>
<p class="mathjax">Image segmentation methods have been utilized to determine the particle size
distribution of crushed ores. Due to the complex working environment,
high-powered computing equipment is difficult to deploy. At the same time, the
ore distribution is stacked, and it is difficult to identify the complete
features. To address this issue, an effective box-supervised technique with
texture features is provided for ore image segmentation that can identify
complete and independent ores. Firstly, a ghost feature pyramid network
(Ghost-FPN) is proposed to process the features obtained from the backbone to
reduce redundant semantic information and computation generated by complex
networks. Then, an optimized detection head is proposed to obtain the feature
to maintain accuracy. Finally, Lab color space (Lab) and local binary patterns
(LBP) texture features are combined to form a fusion feature similarity-based
loss function to improve accuracy while incurring no loss. Experiments on MS
COCO have shown that the proposed fusion features are also worth studying on
other types of datasets. Extensive experimental results demonstrate the
effectiveness of the proposed method, which achieves over 50 frames per second
with a small model size of 21.6 MB. Meanwhile, the method maintains a high
level of accuracy compared with the state-of-the-art approaches on ore image
dataset. The source code is available at
\url{https://github.com/MVME-HBUT/OREINST}.
</p>
</div>
</dd>
<dt><a name="item128">[128]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05931" title="Abstract">arXiv:2311.05931</a> [<a href="/pdf/2311.05931" title="Download PDF">pdf</a>, <a href="/format/2311.05931" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Anytime-Valid Confidence Sequences for Consistent Uncertainty Estimation  in Early-Exit Neural Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jazbec%2C+M">Metod Jazbec</a>, 
<a href="/search/cs?searchtype=author&query=Forr%C3%A9%2C+P">Patrick Forr&#xe9;</a>, 
<a href="/search/cs?searchtype=author&query=Mandt%2C+S">Stephan Mandt</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+D">Dan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Nalisnick%2C+E">Eric Nalisnick</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Machine Learning (stat.ML)

</div>
<p class="mathjax">Early-exit neural networks (EENNs) facilitate adaptive inference by producing
predictions at multiple stages of the forward pass. In safety-critical
applications, these predictions are only meaningful when complemented with
reliable uncertainty estimates. Yet, due to their sequential structure, an
EENN's uncertainty estimates should also be consistent: labels that are deemed
improbable at one exit should not reappear within the confidence interval / set
of later exits. We show that standard uncertainty quantification techniques,
like Bayesian methods or conformal prediction, can lead to inconsistency across
exits. We address this problem by applying anytime-valid confidence sequences
(AVCSs) to the exits of EENNs. By design, AVCSs maintain consistency across
exits. We examine the theoretical and practical challenges of applying AVCSs to
EENNs and empirically validate our approach on both regression and
classification tasks.
</p>
</div>
</dd>
<dt><a name="item129">[129]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05934" title="Abstract">arXiv:2311.05934</a> [<a href="/pdf/2311.05934" title="Download PDF">pdf</a>, <a href="/format/2311.05934" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A TBLMI Framework for Harmonic Robust Control
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Vernerey%2C+F">Flora Vernerey</a> (CRAN), 
<a href="/search/eess?searchtype=author&query=Riedinger%2C+P">Pierre Riedinger</a> (CRAN), 
<a href="/search/eess?searchtype=author&query=Daafouz%2C+J">Jamal Daafouz</a> (CRAN)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">The primary objective of this paper is to demonstrate that problems related
to stability and robust control in the harmonic context can be effectively
addressed by formulating them as semidefinite optimization problems, invoking
the concept of infinite-dimensional Toeplitz Block LMIs (TBLMIs). One of the
central challenges tackled in this study pertains to the efficient resolution
of these infinite-dimensional TBLMIs. Exploiting the structured nature of such
problems, we introduce a consistent truncation method that effectively reduces
the problem to a finite-dimensional convex optimization problem. By consistent
we mean that the solution to this finite-dimensional problem allows to closely
approximate the infinite-dimensional solution with arbitrary precision.
Furthermore, we establish a link between the harmonic framework and the time
domain setting, emphasizing the advantages over Periodic Differential LMIs
(PDLMIs). We illustrate that our proposed framework is not only theoretically
sound but also practically applicable to solving H 2 and H$\infty$ harmonic
control design problems. To enable this, we extend the definitions of H 2 and
H$\infty$ norms into the harmonic space, leveraging the concepts of the
harmonic transfer function and the average trace operator for Toeplitz Block
operators. Throughout this paper, we support our theoretical contributions with
a range of illustrative examples that demonstrate the effectiveness of our
approach.
</p>
</div>
</dd>
<dt><a name="item130">[130]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05935" title="Abstract">arXiv:2311.05935</a> [<a href="/pdf/2311.05935" title="Download PDF">pdf</a>, <a href="/format/2311.05935" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Resilient and constrained consensus against adversarial attacks: A  distributed MPC framework
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Wei%2C+H">Henglai Wei</a>, 
<a href="/search/eess?searchtype=author&query=Zhang%2C+K">Kunwu Zhang</a>, 
<a href="/search/eess?searchtype=author&query=Zhang%2C+H">Hui Zhang</a>, 
<a href="/search/eess?searchtype=author&query=Shi%2C+Y">Yang Shi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">There has been a growing interest in realizing the resilient consensus of the
multi-agent system (MAS) under cyber-attacks, which aims to achieve the
consensus of normal agents (i.e., agents without attacks) in a network,
depending on the neighboring information. The literature has developed
mean-subsequence-reduced (MSR) algorithms for the MAS with F adversarial
attacks and has shown that the consensus is achieved for the normal agents when
the communication network is at least (2F+1)-robust. However, such a stringent
requirement on the communication network needs to be relaxed to enable more
practical applications. Our objective is, for the first time, to achieve less
stringent conditions on the network, while ensuring the resilient consensus for
the general linear MAS subject to control input constraints. In this work, we
propose a distributed resilient consensus framework, consisting of a
pre-designed consensus protocol and distributed model predictive control (DMPC)
optimization, which can help significantly reduce the requirement on the
network robustness and effectively handle the general linear constrained MAS
under adversarial attacks. By employing a novel distributed adversarial attack
detection mechanism based on the history information broadcast by neighbors and
a convex set (i.e., resilience set), we can evaluate the reliability of
communication links. Moreover, we show that the recursive feasibility of the
associated DMPC optimization problem can be guaranteed. The proposed consensus
protocol features the following properties: 1) by minimizing a group of control
variables, the consensus performance is optimized; 2) the resilient consensus
of the general linear constrained MAS subject to F-locally adversarial attacks
is achieved when the communication network is (F+1)-robust. Finally, numerical
simulation results are presented to verify the theoretical results.
</p>
</div>
</dd>
<dt><a name="item131">[131]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05936" title="Abstract">arXiv:2311.05936</a> [<a href="/pdf/2311.05936" title="Download PDF">pdf</a>, <a href="/ps/2311.05936" title="Download PostScript">ps</a>, <a href="/format/2311.05936" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Aggregation Weighting of Federated Learning via Generalization Bound  Estimation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+M">Mingwei Xu</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+X">Xiaofeng Cao</a>, 
<a href="/search/cs?searchtype=author&query=Tsang%2C+I+W">Ivor W.Tsang</a>, 
<a href="/search/cs?searchtype=author&query=Kwok%2C+J+T">James T.Kwok</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Federated Learning (FL) typically aggregates client model parameters using a
weighting approach determined by sample proportions. However, this naive
weighting method may lead to unfairness and degradation in model performance
due to statistical heterogeneity and the inclusion of noisy data among clients.
Theoretically, distributional robustness analysis has shown that the
generalization performance of a learning model with respect to any shifted
distribution is bounded. This motivates us to reconsider the weighting approach
in federated learning. In this paper, we replace the aforementioned weighting
method with a new strategy that considers the generalization bounds of each
local model. Specifically, we estimate the upper and lower bounds of the
second-order origin moment of the shifted distribution for the current local
model, and then use these bounds disagreements as the aggregation proportions
for weightings in each communication round. Experiments demonstrate that the
proposed weighting strategy significantly improves the performance of several
representative FL algorithms on benchmark datasets.
</p>
</div>
</dd>
<dt><a name="item132">[132]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05937" title="Abstract">arXiv:2311.05937</a> [<a href="/pdf/2311.05937" title="Download PDF">pdf</a>, <a href="/ps/2311.05937" title="Download PostScript">ps</a>, <a href="/format/2311.05937" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Genetic Algorithm enhanced by Deep Reinforcement Learning in parent  selection mechanism and mutation : Minimizing makespan in permutation flow  shop scheduling problems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Irmouli%2C+M">Maissa Irmouli</a>, 
<a href="/search/cs?searchtype=author&query=Benazzoug%2C+N">Nourelhouda Benazzoug</a>, 
<a href="/search/cs?searchtype=author&query=Adimi%2C+A+D">Alaa Dania Adimi</a>, 
<a href="/search/cs?searchtype=author&query=Rezkellah%2C+F+Z">Fatma Zohra Rezkellah</a>, 
<a href="/search/cs?searchtype=author&query=Hamzaoui%2C+I">Imane Hamzaoui</a>, 
<a href="/search/cs?searchtype=author&query=Hamitouche%2C+T">Thanina Hamitouche</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neural and Evolutionary Computing (cs.NE)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">This paper introduces a reinforcement learning (RL) approach to address the
challenges associated with configuring and optimizing genetic algorithms (GAs)
for solving difficult combinatorial or non-linear problems. The proposed RL+GA
method was specifically tested on the flow shop scheduling problem (FSP). The
hybrid algorithm incorporates neural networks (NN) and uses the off-policy
method Q-learning or the on-policy method Sarsa(0) to control two key genetic
algorithm (GA) operators: parent selection mechanism and mutation. At each
generation, the RL agent's action is determining the selection method, the
probability of the parent selection and the probability of the offspring
mutation. This allows the RL agent to dynamically adjust the selection and
mutation based on its learned policy. The results of the study highlight the
effectiveness of the RL+GA approach in improving the performance of the
primitive GA. They also demonstrate its ability to learn and adapt from
population diversity and solution improvements over time. This adaptability
leads to improved scheduling solutions compared to static parameter
configurations while maintaining population diversity throughout the
evolutionary process.
</p>
</div>
</dd>
<dt><a name="item133">[133]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05938" title="Abstract">arXiv:2311.05938</a> [<a href="/pdf/2311.05938" title="Download PDF">pdf</a>, <a href="/format/2311.05938" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Efficient Learning of Fast Inverse Kinematics with Collision Avoidance
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tenhumberg%2C+J">Johannes Tenhumberg</a>, 
<a href="/search/cs?searchtype=author&query=Mielke%2C+A">Arman Mielke</a>, 
<a href="/search/cs?searchtype=author&query=B%C3%A4uml%2C+B">Berthold B&#xe4;uml</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Presented at the 2023 IEEE-RAS International Conference on Humanoid Robots
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Fast inverse kinematics (IK) is a central component in robotic motion
planning. For complex robots, IK methods are often based on root search and
non-linear optimization algorithms. These algorithms can be massively sped up
using a neural network to predict a good initial guess, which can then be
refined in a few numerical iterations. Besides previous work on learning-based
IK, we present a learning approach for the fundamentally more complex problem
of IK with collision avoidance. We do this in diverse and previously unseen
environments. From a detailed analysis of the IK learning problem, we derive a
network and unsupervised learning architecture that removes the need for a
sample data generation step. Using the trained network's prediction as an
initial guess for a two-stage Jacobian-based solver allows for fast and
accurate computation of the collision-free IK. For the humanoid robot, Agile
Justin (19 DoF), the collision-free IK is solved in less than 10 milliseconds
(on a single CPU core) and with an accuracy of 10^-4 m and 10^-3 rad based on a
high-resolution world model generated from the robot's integrated 3D sensor.
Our method massively outperforms a random multi-start baseline in a benchmark
with the 19 DoF humanoid and challenging 3D environments. It requires ten times
less training time than a supervised training method while achieving comparable
results.
</p>
</div>
</dd>
<dt><a name="item134">[134]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05941" title="Abstract">arXiv:2311.05941</a> [<a href="/pdf/2311.05941" title="Download PDF">pdf</a>, <a href="/format/2311.05941" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning-Augmented Scheduling for Solar-Powered Electric Vehicle  Charging
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Li%2C+T">Tongxin Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">We tackle the complex challenge of scheduling the charging of electric
vehicles (EVs) equipped with solar panels and batteries, particularly under
out-of-distribution (OOD) conditions. Traditional scheduling approaches, such
as reinforcement learning (RL) and model predictive control (MPC), often fail
to provide satisfactory results when faced with OOD data, struggling to balance
robustness (worst-case performance) and consistency (near-optimal average
performance). To address this gap, we introduce a novel learning-augmented
policy. This policy employs a dynamic robustness budget, which is adapted in
real-time based on the reinforcement learning policy's performance.
Specifically, it leverages the temporal difference (TD) error, a measure of the
learning policy's prediction accuracy, to assess the trustworthiness of the
machine-learned policy. This method allows for a more effective balance between
consistency and robustness in EV charging schedules, significantly enhancing
adaptability and efficiency in real-world, unpredictable environments. Our
results demonstrate that this approach markedly improves scheduling
effectiveness and reliability, particularly in OOD contexts, paving the way for
more resilient and adaptive EV charging systems.
</p>
</div>
</dd>
<dt><a name="item135">[135]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05943" title="Abstract">arXiv:2311.05943</a> [<a href="/pdf/2311.05943" title="Download PDF">pdf</a>, <a href="/format/2311.05943" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Prompt Problems: A New Programming Exercise for the Generative AI Era
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Denny%2C+P">Paul Denny</a>, 
<a href="/search/cs?searchtype=author&query=Leinonen%2C+J">Juho Leinonen</a>, 
<a href="/search/cs?searchtype=author&query=Prather%2C+J">James Prather</a>, 
<a href="/search/cs?searchtype=author&query=Luxton-Reilly%2C+A">Andrew Luxton-Reilly</a>, 
<a href="/search/cs?searchtype=author&query=Amarouche%2C+T">Thezyrie Amarouche</a>, 
<a href="/search/cs?searchtype=author&query=Becker%2C+B+A">Brett A. Becker</a>, 
<a href="/search/cs?searchtype=author&query=Reeves%2C+B+N">Brent N. Reeves</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to SIGCSE'24. arXiv admin note: substantial text overlap with <a href="/abs/2307.16364">arXiv:2307.16364</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">Large Language Models (LLMs) are revolutionizing the field of computing
education with their powerful code-generating capabilities. Traditional
pedagogical practices have focused on code writing tasks, but there is now a
shift in importance towards code reading, comprehension and evaluation of
LLM-generated code. Alongside this shift, an important new skill is emerging --
the ability to solve programming tasks by constructing good prompts for
code-generating models. In this work we introduce a new type of programming
exercise to hone this nascent skill: 'Prompt Problems'. Prompt Problems are
designed to help students learn how to write effective prompts for AI code
generators. A student solves a Prompt Problem by crafting a natural language
prompt which, when provided as input to an LLM, outputs code that successfully
solves a specified programming task. We also present a new web-based tool
called Promptly which hosts a repository of Prompt Problems and supports the
automated evaluation of prompt-generated code. We deploy Promptly for the first
time in one CS1 and one CS2 course and describe our experiences, which include
student perceptions of this new type of activity and their interactions with
the tool. We find that students are enthusiastic about Prompt Problems, and
appreciate how the problems engage their computational thinking skills and
expose them to new programming constructs. We discuss ideas for the future
development of new variations of Prompt Problems, and the need to carefully
study their integration into classroom practice.
</p>
</div>
</dd>
<dt><a name="item136">[136]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05945" title="Abstract">arXiv:2311.05945</a> [<a href="/pdf/2311.05945" title="Download PDF">pdf</a>, <a href="/format/2311.05945" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Intersection-free Robot Manipulation with Soft-Rigid Coupled Incremental  Potential Contact
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Du%2C+W">Wenxin Du</a>, 
<a href="/search/cs?searchtype=author&query=Yao%2C+S">Siqiong Yao</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xinlei Wang</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+Y">Yuhang Xu</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+W">Wenqiang Xu</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+C">Cewu Lu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">This paper presents a novel simulation platform, ZeMa, designed for robotic
manipulation tasks concerning soft objects. Such simulation ideally requires
three properties: two-way soft-rigid coupling, intersection-free guarantees,
and frictional contact modeling, with acceptable runtime suitable for deep and
reinforcement learning tasks. Current simulators often satisfy only a subset of
these needs, primarily focusing on distinct rigid-rigid or soft-soft
interactions. The proposed ZeMa prioritizes physical accuracy and integrates
the incremental potential contact method, offering unified dynamics simulation
for both soft and rigid objects. It efficiently manages soft-rigid contact,
operating 75x faster than baseline tools with similar methodologies like
IPC-GraspSim. To demonstrate its applicability, we employ it for parallel grasp
generation, penetrated grasp repair, and reinforcement learning for grasping,
successfully transferring the trained RL policy to real-world scenarios.
</p>
</div>
</dd>
<dt><a name="item137">[137]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05947" title="Abstract">arXiv:2311.05947</a> [<a href="/pdf/2311.05947" title="Download PDF">pdf</a>, <a href="/ps/2311.05947" title="Download PostScript">ps</a>, <a href="/format/2311.05947" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multiplying matrices using n arithmetic operations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Macedo%2C+H+D">Hugo Daniel Macedo</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>

</div>
<p class="mathjax">It is widely known that the lower bound for the algorithmic complexity of
square matrix multiplication resorts to at least $n^2$ arithmetic operations.
The justification builds upon the following reasoning: given that there are $2
n^2$ numbers in the input matrices, any algorithm necessarily must operate on
each at least once. In this paper, we show that this is not necessarily the
case for certain instances of the problem, for instance matrices with natural
number entries. We present an algorithm performing a single multiplication and
$(n - 1)$ sums, therefore using n arithmetic operations. The ingenuity of the
approach relies on encoding the original $2n^2$ elements as two numbers of much
greater magnitude. Thus, though processing each of the inputs at least once, it
relies on a lower count of arithmetic operations. In the computational model
used to analyze this problem, such encoding operation is not available, thus it
is not clear this work affects the currently accepted complexity results for
matrix multiplication, but the new algorithm complexity (when taking into
account the encodings) is $3n^2 + 2n - 1$ operations. In addition, given the
exponential increase in multiplication operands magnitude, its practical usage
is constrained to certain instances of the problem. Nonetheless, this work
presents a novel mathematically inspired algorithm while pointing towards an
alternative research path, which opens the possibility of novel algorithms and
a taxonomy of matrix multiplications and associated complexities.
</p>
</div>
</dd>
<dt><a name="item138">[138]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05956" title="Abstract">arXiv:2311.05956</a> [<a href="/pdf/2311.05956" title="Download PDF">pdf</a>, <a href="/format/2311.05956" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ID Embedding as Subtle Features of Content and Structure for Multimodal  Recommendation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yuting Liu</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+E">Enneng Yang</a>, 
<a href="/search/cs?searchtype=author&query=Dang%2C+Y">Yizhou Dang</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+G">Guibing Guo</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Q">Qiang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+Y">Yuliang Liang</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+L">Linying Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xingwei Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Multimodal recommendation aims to model user and item representations
comprehensively with the involvement of multimedia content for effective
recommendations. Existing research has shown that it is beneficial for
recommendation performance to combine (user- and item-) ID embeddings with
multimodal salient features, indicating the value of IDs. However, there is a
lack of a thorough analysis of the ID embeddings in terms of feature semantics
in the literature. In this paper, we revisit the value of ID embeddings for
multimodal recommendation and conduct a thorough study regarding its semantics,
which we recognize as subtle features of content and structures. Then, we
propose a novel recommendation model by incorporating ID embeddings to enhance
the semantic features of both content and structures. Specifically, we put
forward a hierarchical attention mechanism to incorporate ID embeddings in
modality fusing, coupled with contrastive learning, to enhance content
representations. Meanwhile, we propose a lightweight graph convolutional
network for each modality to amalgamate neighborhood and ID embeddings for
improving structural representations. Finally, the content and structure
representations are combined to form the ultimate item embedding for
recommendation. Extensive experiments on three real-world datasets (Baby,
Sports, and Clothing) demonstrate the superiority of our method over
state-of-the-art multimodal recommendation methods and the effectiveness of
fine-grained ID embeddings.
</p>
</div>
</dd>
<dt><a name="item139">[139]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05958" title="Abstract">arXiv:2311.05958</a> [<a href="/pdf/2311.05958" title="Download PDF">pdf</a>, <a href="/format/2311.05958" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Neural Height-Map Approach for the Binocular Photometric Stereo  Problem
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Logothetis%2C+F">Fotios Logothetis</a>, 
<a href="/search/cs?searchtype=author&query=Budvytis%2C+I">Ignas Budvytis</a>, 
<a href="/search/cs?searchtype=author&query=Cipolla%2C+R">Roberto Cipolla</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> WACV 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">In this work we propose a novel, highly practical, binocular photometric
stereo (PS) framework, which has same acquisition speed as single view PS,
however significantly improves the quality of the estimated geometry.
<br />As in recent neural multi-view shape estimation frameworks such as NeRF,
SIREN and inverse graphics approaches to multi-view photometric stereo (e.g.
PS-NeRF) we formulate shape estimation task as learning of a differentiable
surface and texture representation by minimising surface normal discrepancy for
normals estimated from multiple varying light images for two views as well as
discrepancy between rendered surface intensity and observed images. Our method
differs from typical multi-view shape estimation approaches in two key ways.
First, our surface is represented not as a volume but as a neural heightmap
where heights of points on a surface are computed by a deep neural network.
Second, instead of predicting an average intensity as PS-NeRF or introducing
lambertian material assumptions as Guo et al., we use a learnt BRDF and perform
near-field per point intensity rendering.
<br />Our method achieves the state-of-the-art performance on the DiLiGenT-MV
dataset adapted to binocular stereo setup as well as a new binocular
photometric stereo dataset - LUCES-ST.
</p>
</div>
</dd>
<dt><a name="item140">[140]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05964" title="Abstract">arXiv:2311.05964</a> [<a href="/pdf/2311.05964" title="Download PDF">pdf</a>, <a href="/format/2311.05964" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multiscale Neural Operators for Solving Time-Independent PDEs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ripken%2C+W">Winfried Ripken</a>, 
<a href="/search/cs?searchtype=author&query=Coiffard%2C+L">Lisa Coiffard</a>, 
<a href="/search/cs?searchtype=author&query=Pieper%2C+F">Felix Pieper</a>, 
<a href="/search/cs?searchtype=author&query=Dziadzio%2C+S">Sebastian Dziadzio</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> The Symbiosis of Deep Learning and Differential Equations III @ NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Time-independent Partial Differential Equations (PDEs) on large meshes pose
significant challenges for data-driven neural PDE solvers. We introduce a novel
graph rewiring technique to tackle some of these challenges, such as
aggregating information across scales and on irregular meshes. Our proposed
approach bridges distant nodes, enhancing the global interaction capabilities
of GNNs. Our experiments on three datasets reveal that GNN-based methods set
new performance standards for time-independent PDEs on irregular meshes.
Finally, we show that our graph rewiring strategy boosts the performance of
baseline methods, achieving state-of-the-art results in one of the tasks.
</p>
</div>
</dd>
<dt><a name="item141">[141]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05965" title="Abstract">arXiv:2311.05965</a> [<a href="/pdf/2311.05965" title="Download PDF">pdf</a>, <a href="/format/2311.05965" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Large Language Models are Zero Shot Hypothesis Proposers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Qi%2C+B">Biqing Qi</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+K">Kaiyan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Haoxiang Li</a>, 
<a href="/search/cs?searchtype=author&query=Tian%2C+K">Kai Tian</a>, 
<a href="/search/cs?searchtype=author&query=Zeng%2C+S">Sihang Zeng</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Z">Zhang-Ren Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+B">Bowen Zhou</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Instruction Workshop @ NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Significant scientific discoveries have driven the progress of human
civilisation. The explosion of scientific literature and data has created
information barriers across disciplines that have slowed the pace of scientific
discovery. Large Language Models (LLMs) hold a wealth of global and
interdisciplinary knowledge that promises to break down these information
barriers and foster a new wave of scientific discovery. However, the potential
of LLMs for scientific discovery has not been formally explored. In this paper,
we start from investigating whether LLMs can propose scientific hypotheses. To
this end, we construct a dataset consist of background knowledge and hypothesis
pairs from biomedical literature. The dataset is divided into training, seen,
and unseen test sets based on the publication date to control visibility. We
subsequently evaluate the hypothesis generation capabilities of various
top-tier instructed models in zero-shot, few-shot, and fine-tuning settings,
including both closed and open-source LLMs. Additionally, we introduce an
LLM-based multi-agent cooperative framework with different role designs and
external tools to enhance the capabilities related to generating hypotheses. We
also design four metrics through a comprehensive review to evaluate the
generated hypotheses for both ChatGPT-based and human evaluations. Through
experiments and analyses, we arrive at the following findings: 1) LLMs
surprisingly generate untrained yet validated hypotheses from testing
literature. 2) Increasing uncertainty facilitates candidate generation,
potentially enhancing zero-shot hypothesis generation capabilities. These
findings strongly support the potential of LLMs as catalysts for new scientific
discoveries and guide further exploration.
</p>
</div>
</dd>
<dt><a name="item142">[142]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05966" title="Abstract">arXiv:2311.05966</a> [<a href="/pdf/2311.05966" title="Download PDF">pdf</a>, <a href="/ps/2311.05966" title="Download PostScript">ps</a>, <a href="/format/2311.05966" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Proposal for a Lean and Functional Delivery versus Payment across two  Blockchains
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fries%2C+C+P">Christian P. Fries</a>, 
<a href="/search/cs?searchtype=author&query=Kohl-Landgraf%2C+P">Peter Kohl-Landgraf</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">We propose a lean and functional transaction scheme to establish a secure
delivery-versus-payment across two blockchains, where a) no intermediary is
required and b) the operator of the payment chain/payment system has a small
overhead and does not need to store state. The main idea comes with two
requirements: First, the payment chain operator hosts a stateless decryption
service that allows the decrypt of messages with his secret key. Second a
"Payment Contract" is deployed on the payment chain that implements a function
transferAndDecrypt(uint id, address from, address to, string
keyEncryptedSuccess, string keyEncryptedFail) that processes the
(trigger-based) payment and emits the decrypted key depending on success or
failure of the transaction. The respective key can then trigger an associated
transaction, e.g. claiming delivery by the buyer or re-claiming the locked
asset by the seller.
</p>
</div>
</dd>
<dt><a name="item143">[143]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05970" title="Abstract">arXiv:2311.05970</a> [<a href="/pdf/2311.05970" title="Download PDF">pdf</a>, <a href="/format/2311.05970" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Quantized Distillation: Optimizing Driver Activity Recognition Models  for Resource-Constrained Environments
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tanama%2C+C">Calvin Tanama</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+K">Kunyu Peng</a>, 
<a href="/search/cs?searchtype=author&query=Marinov%2C+Z">Zdravko Marinov</a>, 
<a href="/search/cs?searchtype=author&query=Stiefelhagen%2C+R">Rainer Stiefelhagen</a>, 
<a href="/search/cs?searchtype=author&query=Roitberg%2C+A">Alina Roitberg</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at IROS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Robotics (cs.RO)

</div>
<p class="mathjax">Deep learning-based models are at the forefront of most driver observation
benchmarks due to their remarkable accuracies but are also associated with high
computational costs. This is challenging, as resources are often limited in
real-world driving scenarios. This paper introduces a lightweight framework for
resource-efficient driver activity recognition. The framework enhances 3D
MobileNet, a neural architecture optimized for speed in video classification,
by incorporating knowledge distillation and model quantization to balance model
accuracy and computational efficiency. Knowledge distillation helps maintain
accuracy while reducing the model size by leveraging soft labels from a larger
teacher model (I3D), instead of relying solely on original ground truth data.
Model quantization significantly lowers memory and computation demands by using
lower precision integers for model weights and activations. Extensive testing
on a public dataset for in-vehicle monitoring during autonomous driving
demonstrates that this new framework achieves a threefold reduction in model
size and a 1.4-fold improvement in inference time, compared to an already
optimized architecture. The code for this study is available at
https://github.com/calvintanama/qd-driver-activity-reco.
</p>
</div>
</dd>
<dt><a name="item144">[144]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05975" title="Abstract">arXiv:2311.05975</a> [<a href="/pdf/2311.05975" title="Download PDF">pdf</a>, <a href="/format/2311.05975" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Sum-max Submodular Bandits
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pasteris%2C+S">Stephen Pasteris</a>, 
<a href="/search/cs?searchtype=author&query=Rumi%2C+A">Alberto Rumi</a>, 
<a href="/search/cs?searchtype=author&query=Vitale%2C+F">Fabio Vitale</a>, 
<a href="/search/cs?searchtype=author&query=Cesa-Bianchi%2C+N">Nicol&#xf2; Cesa-Bianchi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Many online decision-making problems correspond to maximizing a sequence of
submodular functions. In this work, we introduce sum-max functions, a subclass
of monotone submodular functions capturing several interesting problems,
including best-of-$K$-bandits, combinatorial bandits, and the bandit versions
on facility location, $M$-medians, and hitting sets. We show that all functions
in this class satisfy a key property that we call pseudo-concavity. This allows
us to prove $\big(1 - \frac{1}{e}\big)$-regret bounds for bandit feedback in
the nonstochastic setting of the order of $\sqrt{MKT}$ (ignoring log factors),
where $T$ is the time horizon and $M$ is a cardinality constraint. This bound,
attained by a simple and efficient algorithm, significantly improves on the
$\widetilde{O}\big(T^{2/3}\big)$ regret bound for online monotone submodular
maximization with bandit feedback.
</p>
</div>
</dd>
<dt><a name="item145">[145]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05981" title="Abstract">arXiv:2311.05981</a> [<a href="/pdf/2311.05981" title="Download PDF">pdf</a>, <a href="/format/2311.05981" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Comparing Male Nyala and Male Kudu Classification using Transfer  Learning with ResNet-50 and VGG-16
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lemani%2C+T+T">T.T Lemani</a>, 
<a href="/search/cs?searchtype=author&query=van+Zyl%2C+T+L">T.L. van Zyl</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Computers and Society (cs.CY)

</div>
<p class="mathjax">Reliable and efficient monitoring of wild animals is crucial to inform
management and conservation decisions. The process of manually identifying
species of animals is time-consuming, monotonous, and expensive. Leveraging on
advances in deep learning and computer vision, we investigate in this paper the
efficiency of pre-trained models, specifically the VGG-16 and ResNet-50 model,
in identifying a male Kudu and a male Nyala in their natural habitats. These
pre-trained models have proven to be efficient in animal identification in
general. Still, there is little research on animals like the Kudu and Nyala,
who are usually well camouflaged and have similar features. The method of
transfer learning used in this paper is the fine-tuning method. The models are
evaluated before and after fine-tuning. The experimental results achieved an
accuracy of 93.2\% and 97.7\% for the VGG-16 and ResNet-50 models,
respectively, before fine-tuning and 97.7\% for both models after fine-tuning.
Although these results are impressive, it should be noted that they were taken
over a small sample size of 550 images split in half between the two classes;
therefore, this might not cater to enough scenarios to get a full conclusion of
the efficiency of the models. Therefore, there is room for more work in getting
a more extensive dataset and testing and extending to the female counterparts
of these species and the whole antelope species.
</p>
</div>
</dd>
<dt><a name="item146">[146]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05982" title="Abstract">arXiv:2311.05982</a> [<a href="/pdf/2311.05982" title="Download PDF">pdf</a>, <a href="/format/2311.05982" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> KRATT: QBF-Assisted Removal and Structural Analysis Attack Against Logic  Locking
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Aksoy%2C+L">Levent Aksoy</a>, 
<a href="/search/cs?searchtype=author&query=Yasin%2C+M">Muhammad Yasin</a>, 
<a href="/search/cs?searchtype=author&query=Pagliarini%2C+S">Samuel Pagliarini</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">This paper introduces KRATT, a removal and structural analysis attack against
state-of-the-art logic locking techniques, such as single and double flip
locking techniques (SFLTs and DFLTs). KRATT utilizes powerful quantified
Boolean formulas (QBFs), which have not found widespread use in hardware
security, to find the secret key of SFLTs for the first time. It can handle
locked circuits under both oracle-less (OL) and oracle-guided (OG) threat
models. It modifies the locked circuit and uses a prominent OL attack to make a
strong guess under the OL threat model. It uses a structural analysis technique
to identify promising protected input patterns and explores them using the
oracle under the OG model. Experimental results on ISCAS'85, ITC'99, and HeLLO:
CTF'22 benchmarks show that KRATT can break SFLTs using a QBF formulation in
less than a minute, can decipher a large number of key inputs of SFLTs and
DFLTs with high accuracy under the OL threat model, and can easily find the
secret key of DFLTs under the OG threat model. It is shown that KRATT
outperforms publicly available OL and OG attacks in terms of solution quality
and run-time.
</p>
</div>
</dd>
<dt><a name="item147">[147]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05986" title="Abstract">arXiv:2311.05986</a> [<a href="/pdf/2311.05986" title="Download PDF">pdf</a>, <a href="/format/2311.05986" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Signature-Based Community Detection for Time Series
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gregnanin%2C+M">Marco Gregnanin</a>, 
<a href="/search/cs?searchtype=author&query=De+Smedt%2C+J">Johannes De Smedt</a>, 
<a href="/search/cs?searchtype=author&query=Gnecco%2C+G">Giorgio Gnecco</a>, 
<a href="/search/cs?searchtype=author&query=Parton%2C+M">Maurizio Parton</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>; Data Analysis, Statistics and Probability (physics.data-an)

</div>
<p class="mathjax">Community detection for time series without prior knowledge poses an open
challenge within complex networks theory. Traditional approaches begin by
assessing time series correlations and maximizing modularity under diverse null
models. These methods suffer from assuming temporal stationarity and are
influenced by the granularity of observation intervals. In this study, we
propose an approach based on the signature matrix, a concept from path theory
for studying stochastic processes. By employing a signature-derived similarity
measure, our method overcomes drawbacks of traditional correlation-based
techniques. Through a series of numerical experiments, we demonstrate that our
method consistently yields higher modularity compared to baseline models, when
tested on the Standard and Poor's 500 dataset. Moreover, our approach showcases
enhanced stability in modularity when the length of the underlying time series
is manipulated. This research contributes to the field of community detection
by introducing a signature-based similarity measure, offering an alternative to
conventional correlation matrices.
</p>
</div>
</dd>
<dt><a name="item148">[148]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05988" title="Abstract">arXiv:2311.05988</a> [<a href="/pdf/2311.05988" title="Download PDF">pdf</a>, <a href="/format/2311.05988" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Vision Big Bird: Random Sparsification for Full Attention
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zhemin Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Gong%2C+X">Xun Gong</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: substantial text overlap with <a href="/abs/2304.06250">arXiv:2304.06250</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Recently, Transformers have shown promising performance in various vision
tasks. However, the high costs of global self-attention remain challenging for
Transformers, especially for high-resolution vision tasks. Inspired by one of
the most successful transformers-based models for NLP: Big Bird, we propose a
novel sparse attention mechanism for Vision Transformers (ViT). Specifically,
we separate the heads into three groups, the first group used convolutional
neural network (CNN) to extract local features and provide positional
information for the model, the second group used Random Sampling Windows
(RS-Win) for sparse self-attention calculation, and the third group reduces the
resolution of the keys and values by average pooling for global attention.
Based on these components, ViT maintains the sparsity of self-attention while
maintaining the merits of Big Bird (i.e., the model is a universal approximator
of sequence functions and is Turing complete). Moreover, our results show that
the positional encoding, a crucial component in ViTs, can be safely removed in
our model. Experiments show that Vision Big Bird demonstrates competitive
performance on common vision tasks.
</p>
</div>
</dd>
<dt><a name="item149">[149]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05992" title="Abstract">arXiv:2311.05992</a> [<a href="/pdf/2311.05992" title="Download PDF">pdf</a>, <a href="/format/2311.05992" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Robust Adversarial Attacks Detection for Deep Learning based Relative  Pose Estimation for Space Rendezvous
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Ziwei Wang</a>, 
<a href="/search/cs?searchtype=author&query=Aouf%2C+N">Nabil Aouf</a>, 
<a href="/search/cs?searchtype=author&query=Pizarro%2C+J">Jose Pizarro</a>, 
<a href="/search/cs?searchtype=author&query=Honvault%2C+C">Christophe Honvault</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Cryptography and Security (cs.CR); Machine Learning (cs.LG); Robotics (cs.RO)

</div>
<p class="mathjax">Research on developing deep learning techniques for autonomous spacecraft
relative navigation challenges is continuously growing in recent years.
Adopting those techniques offers enhanced performance. However, such approaches
also introduce heightened apprehensions regarding the trustability and security
of such deep learning methods through their susceptibility to adversarial
attacks. In this work, we propose a novel approach for adversarial attack
detection for deep neural network-based relative pose estimation schemes based
on the explainability concept. We develop for an orbital rendezvous scenario an
innovative relative pose estimation technique adopting our proposed
Convolutional Neural Network (CNN), which takes an image from the chaser's
onboard camera and outputs accurately the target's relative position and
rotation. We perturb seamlessly the input images using adversarial attacks that
are generated by the Fast Gradient Sign Method (FGSM). The adversarial attack
detector is then built based on a Long Short Term Memory (LSTM) network which
takes the explainability measure namely SHapley Value from the CNN-based pose
estimator and flags the detection of adversarial attacks when acting.
Simulation results show that the proposed adversarial attack detector achieves
a detection accuracy of 99.21%. Both the deep relative pose estimator and
adversarial attack detector are then tested on real data captured from our
laboratory-designed setup. The experimental results from our
laboratory-designed setup demonstrate that the proposed adversarial attack
detector achieves an average detection accuracy of 96.29%.
</p>
</div>
</dd>
<dt><a name="item150">[150]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05997" title="Abstract">arXiv:2311.05997</a> [<a href="/pdf/2311.05997" title="Download PDF">pdf</a>, <a href="/format/2311.05997" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> JARVIS-1: Open-World Multi-task Agents with Memory-Augmented Multimodal  Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zihao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Cai%2C+S">Shaofei Cai</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+A">Anji Liu</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+Y">Yonggang Jin</a>, 
<a href="/search/cs?searchtype=author&query=Hou%2C+J">Jinbing Hou</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+B">Bowei Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+H">Haowei Lin</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+Z">Zhaofeng He</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+Z">Zilong Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yaodong Yang</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+X">Xiaojian Ma</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+Y">Yitao Liang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
<p class="mathjax">Achieving human-like planning and control with multimodal observations in an
open world is a key milestone for more functional generalist agents. Existing
approaches can handle certain long-horizon tasks in an open world. However,
they still struggle when the number of open-world tasks could potentially be
infinite and lack the capability to progressively enhance task completion as
game time progresses. We introduce JARVIS-1, an open-world agent that can
perceive multimodal input (visual observations and human instructions),
generate sophisticated plans, and perform embodied control, all within the
popular yet challenging open-world Minecraft universe. Specifically, we develop
JARVIS-1 on top of pre-trained multimodal language models, which map visual
observations and textual instructions to plans. The plans will be ultimately
dispatched to the goal-conditioned controllers. We outfit JARVIS-1 with a
multimodal memory, which facilitates planning using both pre-trained knowledge
and its actual game survival experiences. In our experiments, JARVIS-1 exhibits
nearly perfect performances across over 200 varying tasks from the Minecraft
Universe Benchmark, ranging from entry to intermediate levels. JARVIS-1 has
achieved a completion rate of 12.5% in the long-horizon diamond pickaxe task.
This represents a significant increase up to 5 times compared to previous
records. Furthermore, we show that JARVIS-1 is able to $\textit{self-improve}$
following a life-long learning paradigm thanks to multimodal memory, sparking a
more general intelligence and improved autonomy. The project page is available
at https://craftjarvis-jarvis1.github.io.
</p>
</div>
</dd>
<dt><a name="item151">[151]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06000" title="Abstract">arXiv:2311.06000</a> [<a href="/pdf/2311.06000" title="Download PDF">pdf</a>, <a href="/format/2311.06000" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Keystroke Verification Challenge (KVC): Biometric and Fairness Benchmark  Evaluation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Stragapede%2C+G">Giuseppe Stragapede</a>, 
<a href="/search/cs?searchtype=author&query=Vera-Rodriguez%2C+R">Ruben Vera-Rodriguez</a>, 
<a href="/search/cs?searchtype=author&query=Tolosana%2C+R">Ruben Tolosana</a>, 
<a href="/search/cs?searchtype=author&query=Morales%2C+A">Aythami Morales</a>, 
<a href="/search/cs?searchtype=author&query=Damer%2C+N">Naser Damer</a>, 
<a href="/search/cs?searchtype=author&query=Fierrez%2C+J">Julian Fierrez</a>, 
<a href="/search/cs?searchtype=author&query=Ortega-Garcia%2C+J">Javier Ortega-Garcia</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, 4 figure, 5 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Analyzing keystroke dynamics (KD) for biometric verification has several
advantages: it is among the most discriminative behavioral traits; keyboards
are among the most common human-computer interfaces, being the primary means
for users to enter textual data; its acquisition does not require additional
hardware, and its processing is relatively lightweight; and it allows for
transparently recognizing subjects. However, the heterogeneity of experimental
protocols and metrics, and the limited size of the databases adopted in the
literature impede direct comparisons between different systems, thus
representing an obstacle in the advancement of keystroke biometrics. To
alleviate this aspect, we present a new experimental framework to benchmark
KD-based biometric verification performance and fairness based on tweet-long
sequences of variable transcript text from over 185,000 subjects, acquired
through desktop and mobile keyboards, extracted from the Aalto Keystroke
Databases. The framework runs on CodaLab in the form of the Keystroke
Verification Challenge (KVC). Moreover, we also introduce a novel fairness
metric, the Skewed Impostor Ratio (SIR), to capture inter- and
intra-demographic group bias patterns in the verification scores. We
demonstrate the usefulness of the proposed framework by employing two
state-of-the-art keystroke verification systems, TypeNet and TypeFormer, to
compare different sets of input features, achieving a less privacy-invasive
system, by discarding the analysis of text content (ASCII codes of the keys
pressed) in favor of extended features in the time domain. Our experiments show
that this approach allows to maintain satisfactory performance.
</p>
</div>
</dd>
<dt><a name="item152">[152]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06008" title="Abstract">arXiv:2311.06008</a> [<a href="/pdf/2311.06008" title="Download PDF">pdf</a>, <a href="/format/2311.06008" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Network Resource Management For Cyber-Physical Production Systems Based  On Quality of Experience
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Vid%C3%A1cs%2C+A">Attila Vid&#xe1;cs</a>, 
<a href="/search/cs?searchtype=author&query=Trombit%C3%A1s%2C+Z">Zal&#xe1;n Trombit&#xe1;s</a>, 
<a href="/search/cs?searchtype=author&query=Szab%C3%B3%2C+G">G&#xe9;za Szab&#xf3;</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> In Proc., 37th European Simulation and Modelling Conference 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>

</div>
<p class="mathjax">In today's industrial challenges, it can be observed that the trends point in
the direction of agile, wireless connected robots where elements of
intelligence and control are implemented in the edge cloud. This paper outlines
the roles of three key participants in the value chain of an industrial
process: the network provider, the robot operator, and the customer. It
proposes a scheme where the Quality of Service (QoS) parameters of the robot
are fed into the network to inform network resource management. A sanding
process use case is simulated to demonstrate the relationship between QoS and
Quality of Experience (QoE) for each participant, quantitatively.
</p>
</div>
</dd>
<dt><a name="item153">[153]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06012" title="Abstract">arXiv:2311.06012</a> [<a href="/pdf/2311.06012" title="Download PDF">pdf</a>, <a href="/format/2311.06012" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Doubly Robust Structure Identification from Temporal Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Angelis%2C+E">Emmanouil Angelis</a>, 
<a href="/search/cs?searchtype=author&query=Quinzan%2C+F">Francesco Quinzan</a>, 
<a href="/search/cs?searchtype=author&query=Soleymani%2C+A">Ashkan Soleymani</a>, 
<a href="/search/cs?searchtype=author&query=Jaillet%2C+P">Patrick Jaillet</a>, 
<a href="/search/cs?searchtype=author&query=Bauer%2C+S">Stefan Bauer</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Learning the causes of time-series data is a fundamental task in many
applications, spanning from finance to earth sciences or bio-medical
applications. Common approaches for this task are based on vector
auto-regression, and they do not take into account unknown confounding between
potential causes. However, in settings with many potential causes and noisy
data, these approaches may be substantially biased. Furthermore, potential
causes may be correlated in practical applications. Moreover, existing
algorithms often do not work with cyclic data. To address these challenges, we
propose a new doubly robust method for Structure Identification from Temporal
Data ( SITD ). We provide theoretical guarantees, showing that our method
asymptotically recovers the true underlying causal structure. Our analysis
extends to cases where the potential causes have cycles and they may be
confounded. We further perform extensive experiments to showcase the superior
performance of our method.
</p>
</div>
</dd>
<dt><a name="item154">[154]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06013" title="Abstract">arXiv:2311.06013</a> [<a href="/pdf/2311.06013" title="Download PDF">pdf</a>, <a href="/format/2311.06013" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Spanners under the Hausdorff and Fr&#xe9;chet Distances
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Farhana%2C+T">Tsuri Farhana</a>, 
<a href="/search/cs?searchtype=author&query=Katz%2C+M+J">Matthew J. Katz</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Geometry (cs.CG)</span>

</div>
<p class="mathjax">We initiate the study of spanners under the Hausdorff and Fr\'echet
distances. We show that any $t$-spanner of a planar point-set $S$ is a
$\frac{\sqrt{t^2-1}}{2}$-Hausdorff-spanner and a
$\min\{\frac{t}{2},\frac{\sqrt{t^2-t}}{\sqrt{2}}\}$-Fr\'echet spanner. We also
prove that for any $t &gt; 1$, there exist a set of points $S$ and an
$\varepsilon_1$-Hausdorff-spanner of $S$ and an
$\varepsilon_2$-Fr\'echet-spanner of $S$, where $\varepsilon_1$ and
$\varepsilon_2$ are constants, such that neither of them is a $t$-spanner.
</p>
</div>
</dd>
<dt><a name="item155">[155]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06015" title="Abstract">arXiv:2311.06015</a> [<a href="/pdf/2311.06015" title="Download PDF">pdf</a>, <a href="/ps/2311.06015" title="Download PostScript">ps</a>, <a href="/format/2311.06015" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> RSG: Fast Learning Adaptive Skills for Quadruped Robots by Skill Graph
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Hongyin Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+D">Diyuan Shi</a>, 
<a href="/search/cs?searchtype=author&query=Zhuang%2C+Z">Zifeng Zhuang</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+H">Han Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+Z">Zhenyu Wei</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+F">Feng Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Gai%2C+S">Sibo Gai</a>, 
<a href="/search/cs?searchtype=author&query=Lyu%2C+S">Shangke Lyu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+D">Donglin Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Developing robotic intelligent systems that can adapt quickly to unseen wild
situations is one of the critical challenges in pursuing autonomous robotics.
Although some impressive progress has been made in walking stability and skill
learning in the field of legged robots, their ability to fast adaptation is
still inferior to that of animals in nature. Animals are born with massive
skills needed to survive, and can quickly acquire new ones, by composing
fundamental skills with limited experience. Inspired by this, we propose a
novel framework, named Robot Skill Graph (RSG) for organizing massive
fundamental skills of robots and dexterously reusing them for fast adaptation.
Bearing a structure similar to the Knowledge Graph (KG), RSG is composed of
massive dynamic behavioral skills instead of static knowledge in KG and enables
discovering implicit relations that exist in be-tween of learning context and
acquired skills of robots, serving as a starting point for understanding subtle
patterns existing in robots' skill learning. Extensive experimental results
demonstrate that RSG can provide rational skill inference upon new tasks and
environments and enable quadruped robots to adapt to new scenarios and learn
new skills rapidly.
</p>
</div>
</dd>
<dt><a name="item156">[156]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06018" title="Abstract">arXiv:2311.06018</a> [<a href="/pdf/2311.06018" title="Download PDF">pdf</a>, <a href="/format/2311.06018" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> U3DS$^3$: Unsupervised 3D Semantic Scene Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jiaxu Liu</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+Z">Zhengdi Yu</a>, 
<a href="/search/cs?searchtype=author&query=Breckon%2C+T+P">Toby P. Breckon</a>, 
<a href="/search/cs?searchtype=author&query=Shum%2C+H+P+H">Hubert P.H. Shum</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 Pages, 4 figures, accepted to IEEE/CVF Winter Conference on Applications of Computer Vision (WACV) 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Contemporary point cloud segmentation approaches largely rely on richly
annotated 3D training data. However, it is both time-consuming and challenging
to obtain consistently accurate annotations for such 3D scene data. Moreover,
there is still a lack of investigation into fully unsupervised scene
segmentation for point clouds, especially for holistic 3D scenes. This paper
presents U3DS$^3$, as a step towards completely unsupervised point cloud
segmentation for any holistic 3D scenes. To achieve this, U3DS$^3$ leverages a
generalized unsupervised segmentation method for both object and background
across both indoor and outdoor static 3D point clouds with no requirement for
model pre-training, by leveraging only the inherent information of the point
cloud to achieve full 3D scene segmentation. The initial step of our proposed
approach involves generating superpoints based on the geometric characteristics
of each scene. Subsequently, it undergoes a learning process through a spatial
clustering-based methodology, followed by iterative training using
pseudo-labels generated in accordance with the cluster centroids. Moreover, by
leveraging the invariance and equivariance of the volumetric representations,
we apply the geometric transformation on voxelized features to provide two sets
of descriptors for robust representation learning. Finally, our evaluation
provides state-of-the-art results on the ScanNet and SemanticKITTI, and
competitive results on the S3DIS, benchmark datasets.
</p>
</div>
</dd>
<dt><a name="item157">[157]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06025" title="Abstract">arXiv:2311.06025</a> [<a href="/pdf/2311.06025" title="Download PDF">pdf</a>, <a href="/format/2311.06025" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ChiMed-GPT: A Chinese Medical Large Language Model with Full Training  Regime and Better Alignment to Human Preferences
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tian%2C+Y">Yuanhe Tian</a>, 
<a href="/search/cs?searchtype=author&query=Gan%2C+R">Ruyi Gan</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+Y">Yan Song</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jiaxing Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yongdong Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 17 pages, 3 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Recently, the increasing demand for superior medical services has highlighted
the discrepancies in the medical infrastructure. With big data, especially
texts, forming the foundation of medical services, there is an exigent need for
effective natural language processing (NLP) solutions tailored to the
healthcare domain. Conventional approaches leveraging pre-trained models
present promising results in this domain and current large language models
(LLMs) offer advanced foundation for medical text processing. However, most
medical LLMs are trained only with supervised fine-tuning (SFT), even though it
efficiently empowers LLMs to understand and respond to medical instructions but
is ineffective in learning domain knowledge and aligning with human preference.
Another engineering barrier that prevents current medical LLM from better text
processing ability is their restricted context length (e.g., 2,048 tokens),
making it hard for the LLMs to process long context, which is frequently
required in the medical domain. In this work, we propose ChiMed-GPT, a new
benchmark LLM designed explicitly for Chinese medical domain, with enlarged
context length to 4,096 tokens and undergoes a comprehensive training regime
with pre-training, SFT, and RLHF. Evaluations on real-world tasks including
information extraction, question answering, and dialogue generation demonstrate
ChiMed-GPT's superior performance over general domain LLMs. Furthermore, we
analyze possible biases through prompting ChiMed-GPT to perform attitude scales
regarding discrimination of patients, so as to contribute to further
responsible development of LLMs in the medical domain. The code and model are
released at https://github.com/synlp/ChiMed-GPT.
</p>
</div>
</dd>
<dt><a name="item158">[158]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06028" title="Abstract">arXiv:2311.06028</a> [<a href="/pdf/2311.06028" title="Download PDF">pdf</a>, <a href="/format/2311.06028" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Symbolic Regression as Feature Engineering Method for Machine and Deep  Learning Regression Tasks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shmuel%2C+A">Assaf Shmuel</a>, 
<a href="/search/cs?searchtype=author&query=Glickman%2C+O">Oren Glickman</a>, 
<a href="/search/cs?searchtype=author&query=Lazebnik%2C+T">Teddy Lazebnik</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">In the realm of machine and deep learning regression tasks, the role of
effective feature engineering (FE) is pivotal in enhancing model performance.
Traditional approaches of FE often rely on domain expertise to manually design
features for machine learning models. In the context of deep learning models,
the FE is embedded in the neural network's architecture, making it hard for
interpretation. In this study, we propose to integrate symbolic regression (SR)
as an FE process before a machine learning model to improve its performance. We
show, through extensive experimentation on synthetic and real-world
physics-related datasets, that the incorporation of SR-derived features
significantly enhances the predictive capabilities of both machine and deep
learning regression models with 34-86% root mean square error (RMSE)
improvement in synthetic datasets and 4-11.5% improvement in real-world
datasets. In addition, as a realistic use-case, we show the proposed method
improves the machine learning performance in predicting superconducting
critical temperatures based on Eliashberg theory by more than 20% in terms of
RMSE. These results outline the potential of SR as an FE component in
data-driven models.
</p>
</div>
</dd>
<dt><a name="item159">[159]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06031" title="Abstract">arXiv:2311.06031</a> [<a href="/pdf/2311.06031" title="Download PDF">pdf</a>, <a href="/format/2311.06031" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Diagonal Hierarchical Consistency Learning for Semi-supervised Medical  Image Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Koo%2C+H">Heejoon Koo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages, 2 figures, and 2 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Medical image segmentation, which is essential for many clinical
applications, has achieved almost human-level performance via data-driven deep
learning techniques. Nevertheless, its performance is predicated on the costly
process of manually annotating a large amount of medical images. To this end,
we propose a novel framework for robust semi-supervised medical image
segmentation using diagonal hierarchical consistency (DiHC-Net). First, it is
composed of multiple sub-models with identical multi-scale architecture but
with distinct sub-layers, such as up-sampling and normalisation layers. Second,
a novel diagonal hierarchical consistency is enforced between one model's
intermediate and final prediction and other models' soft pseudo labels in a
diagonal hierarchical fashion. Experimental results verify the efficacy of our
simple framework, outperforming all previous approaches on public Left Atrium
(LA) dataset.
</p>
</div>
</dd>
<dt><a name="item160">[160]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06035" title="Abstract">arXiv:2311.06035</a> [<a href="/pdf/2311.06035" title="Download PDF">pdf</a>, <a href="/format/2311.06035" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Time-invariant Network Flow Model for Ride-pooling in  Mobility-on-Demand Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Paparella%2C+F">Fabio Paparella</a>, 
<a href="/search/eess?searchtype=author&query=Pedroso%2C+L">Leonardo Pedroso</a>, 
<a href="/search/eess?searchtype=author&query=Hofman%2C+T">Theo Hofman</a>, 
<a href="/search/eess?searchtype=author&query=Salazar%2C+M">Mauro Salazar</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: substantial text overlap with <a href="/abs/2303.15051">arXiv:2303.15051</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Optimization and Control (math.OC)

</div>
<p class="mathjax">This paper presents a framework to incorporate ride-pooling from a mesoscopic
point of view, within time-invariant network flow models of Mobility-on-Demand
systems. The resulting problem structure remains identical to a standard
network flow model, a linear problem, which can be solved in polynomial time
for a given ride-pooling request assignment. In order to compute such a
ride-pooling assignment, we devise a polynomial-time knapsack-like algorithm
that is optimal w.r.t. the minimum user travel time instance of the original
problem. Finally, we conduct two case studies of Sioux Falls and Manhattan,
where we validate our models against state-of-the-art time-varying results, and
we quantitatively highlight the effects that maximum waiting time and maximum
delay thresholds have on the vehicle hours traveled, overall pooled rides and
actual delay experienced. We show that for a sufficient number of requests,
with a maximum waiting time and delay of 5 minutes, it is possible to ride-pool
more than 80% of the requests for both case studies. Last, allowing for four
people ride-pooling can significantly boost the performance of the system.
</p>
</div>
</dd>
<dt><a name="item161">[161]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06038" title="Abstract">arXiv:2311.06038</a> [<a href="/pdf/2311.06038" title="Download PDF">pdf</a>, <a href="/format/2311.06038" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> 2D Image head pose estimation via latent space regression under  occlusion settings
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Celestino%2C+J">Jos&#xe9; Celestino</a>, 
<a href="/search/cs?searchtype=author&query=Marques%2C+M">Manuel Marques</a>, 
<a href="/search/cs?searchtype=author&query=Nascimento%2C+J+C">Jacinto C. Nascimento</a>, 
<a href="/search/cs?searchtype=author&query=Costeira%2C+J+P">Jo&#xe3;o Paulo Costeira</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Pattern Recognition, Volume 137, May 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Head orientation is a challenging Computer Vision problem that has been
extensively researched having a wide variety of applications. However, current
state-of-the-art systems still underperform in the presence of occlusions and
are unreliable for many task applications in such scenarios. This work proposes
a novel deep learning approach for the problem of head pose estimation under
occlusions. The strategy is based on latent space regression as a fundamental
key to better structure the problem for occluded scenarios. Our model surpasses
several state-of-the-art methodologies for occluded HPE, and achieves similar
accuracy for non-occluded scenarios. We demonstrate the usefulness of the
proposed approach with: (i) two synthetically occluded versions of the BIWI and
AFLW2000 datasets, (ii) real-life occlusions of the Pandora dataset, and (iii)
a real-life application to human-robot interaction scenarios where face
occlusions often occur. Specifically, the autonomous feeding from a robotic
arm.
</p>
</div>
</dd>
<dt><a name="item162">[162]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06043" title="Abstract">arXiv:2311.06043</a> [<a href="/pdf/2311.06043" title="Download PDF">pdf</a>, <a href="/format/2311.06043" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deep learning for 3D Object Detection and Tracking in Autonomous  Driving: A Brief Survey
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Peng%2C+Y">Yang Peng</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 8 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Object detection and tracking are vital and fundamental tasks for autonomous
driving, aiming at identifying and locating objects from those predefined
categories in a scene. 3D point cloud learning has been attracting more and
more attention among all other forms of self-driving data. Currently, there are
many deep learning methods for 3D object detection. However, the tasks of
object detection and tracking for point clouds still need intensive study due
to the unique characteristics of point cloud data. To help get a good grasp of
the present situation of this research, this paper shows recent advances in
deep learning methods for 3D object detection and tracking.
</p>
</div>
</dd>
<dt><a name="item163">[163]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06049" title="Abstract">arXiv:2311.06049</a> [<a href="/pdf/2311.06049" title="Download PDF">pdf</a>, <a href="/format/2311.06049" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Privacy-Preserving Individual-Level COVID-19 Infection Prediction via  Federated Graph Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fu%2C+W">Wenjie Fu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Huandong Wang</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+C">Chen Gao</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+G">Guanghua Liu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yong Li</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+T">Tao Jiang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> accepted by TOIS
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>; Computers and Society (cs.CY)

</div>
<p class="mathjax">Accurately predicting individual-level infection state is of great value
since its essential role in reducing the damage of the epidemic. However, there
exists an inescapable risk of privacy leakage in the fine-grained user mobility
trajectories required by individual-level infection prediction. In this paper,
we focus on developing a framework of privacy-preserving individual-level
infection prediction based on federated learning (FL) and graph neural networks
(GNN). We propose Falcon, a Federated grAph Learning method for
privacy-preserving individual-level infeCtion predictiON. It utilizes a novel
hypergraph structure with spatio-temporal hyperedges to describe the complex
interactions between individuals and locations in the contagion process. By
organically combining the FL framework with hypergraph neural networks, the
information propagation process of the graph machine learning is able to be
divided into two stages distributed on the server and the clients,
respectively, so as to effectively protect user privacy while transmitting
high-level information. Furthermore, it elaborately designs a differential
privacy perturbation mechanism as well as a plausible pseudo location
generation approach to preserve user privacy in the graph structure. Besides,
it introduces a cooperative coupling mechanism between the individual-level
prediction model and an additional region-level model to mitigate the
detrimental impacts caused by the injected obfuscation mechanisms. Extensive
experimental results show that our methodology outperforms state-of-the-art
algorithms and is able to protect user privacy against actual privacy attacks.
Our code and datasets are available at the link:
https://github.com/wjfu99/FL-epidemic.
</p>
</div>
</dd>
<dt><a name="item164">[164]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06054" title="Abstract">arXiv:2311.06054</a> [<a href="/pdf/2311.06054" title="Download PDF">pdf</a>, <a href="/ps/2311.06054" title="Download PostScript">ps</a>, <a href="/format/2311.06054" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Refining the ONCE Benchmark with Hyperparameter Tuning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Golyadkin%2C+M">Maksim Golyadkin</a>, 
<a href="/search/cs?searchtype=author&query=Gambashidze%2C+A">Alexander Gambashidze</a>, 
<a href="/search/cs?searchtype=author&query=Nurgaliev%2C+I">Ildar Nurgaliev</a>, 
<a href="/search/cs?searchtype=author&query=Makarov%2C+I">Ilya Makarov</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">In response to the growing demand for 3D object detection in applications
such as autonomous driving, robotics, and augmented reality, this work focuses
on the evaluation of semi-supervised learning approaches for point cloud data.
The point cloud representation provides reliable and consistent observations
regardless of lighting conditions, thanks to advances in LiDAR sensors. Data
annotation is of paramount importance in the context of LiDAR applications, and
automating 3D data annotation with semi-supervised methods is a pivotal
challenge that promises to reduce the associated workload and facilitate the
emergence of cost-effective LiDAR solutions. Nevertheless, the task of
semi-supervised learning in the context of unordered point cloud data remains
formidable due to the inherent sparsity and incomplete shapes that hinder the
generation of accurate pseudo-labels. In this study, we consider these
challenges by posing the question: "To what extent does unlabelled data
contribute to the enhancement of model performance?" We show that improvements
from previous semi-supervised methods may not be as profound as previously
thought. Our results suggest that simple grid search hyperparameter tuning
applied to a supervised model can lead to state-of-the-art performance on the
ONCE dataset, while the contribution of unlabelled data appears to be
comparatively less exceptional.
</p>
</div>
</dd>
<dt><a name="item165">[165]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06056" title="Abstract">arXiv:2311.06056</a> [<a href="/pdf/2311.06056" title="Download PDF">pdf</a>, <a href="/format/2311.06056" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning Contrastive Self-Distillation for Ultra-Fine-Grained Visual  Categorization Targeting Limited Samples
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fang%2C+Z">Ziye Fang</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+X">Xin Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+H">Hao Tang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zechao Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> The first two authors contributed equally to this work
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Multimedia (cs.MM)

</div>
<p class="mathjax">In the field of intelligent multimedia analysis, ultra-fine-grained visual
categorization (Ultra-FGVC) plays a vital role in distinguishing intricate
subcategories within broader categories. However, this task is inherently
challenging due to the complex granularity of category subdivisions and the
limited availability of data for each category. To address these challenges,
this work proposes CSDNet, a pioneering framework that effectively explores
contrastive learning and self-distillation to learn discriminative
representations specifically designed for Ultra-FGVC tasks. CSDNet comprises
three main modules: Subcategory-Specific Discrepancy Parsing (SSDP), Dynamic
Discrepancy Learning (DDL), and Subcategory-Specific Discrepancy Transfer
(SSDT), which collectively enhance the generalization of deep models across
instance, feature, and logit prediction levels. To increase the diversity of
training samples, the SSDP module introduces augmented samples from different
viewpoints to spotlight subcategory-specific discrepancies. Simultaneously, the
proposed DDL module stores historical intermediate features by a dynamic memory
queue, which optimizes the feature learning space through iterative contrastive
learning. Furthermore, the SSDT module is developed by a novel
self-distillation paradigm at the logit prediction level of raw and augmented
samples, which effectively distills more subcategory-specific discrepancies
knowledge from the inherent structure of limited training data without
requiring additional annotations. Experimental results demonstrate that CSDNet
outperforms current state-of-the-art Ultra-FGVC methods, emphasizing its
powerful efficacy and adaptability in addressing Ultra-FGVC tasks.
</p>
</div>
</dd>
<dt><a name="item166">[166]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06059" title="Abstract">arXiv:2311.06059</a> [<a href="/pdf/2311.06059" title="Download PDF">pdf</a>, <a href="/format/2311.06059" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Improved Positional Encoding for Implicit Neural Representation based  Compact Data Representation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Damodaran%2C+B+B">Bharath Bhushan Damodaran</a>, 
<a href="/search/cs?searchtype=author&query=Schnitzler%2C+F">Francois Schnitzler</a>, 
<a href="/search/cs?searchtype=author&query=Lambert%2C+A">Anne Lambert</a>, 
<a href="/search/cs?searchtype=author&query=Hellier%2C+P">Pierre Hellier</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Published at ICCV 2023 Workshop on Neural Fields for Autonomous Driving and Robotics
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG); Image and Video Processing (eess.IV)

</div>
<p class="mathjax">Positional encodings are employed to capture the high frequency information
of the encoded signals in implicit neural representation (INR). In this paper,
we propose a novel positional encoding method which improves the reconstruction
quality of the INR. The proposed embedding method is more advantageous for the
compact data representation because it has a greater number of frequency basis
than the existing methods. Our experiments shows that the proposed method
achieves significant gain in the rate-distortion performance without
introducing any additional complexity in the compression task and higher
reconstruction quality in novel view synthesis.
</p>
</div>
</dd>
<dt><a name="item167">[167]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06060" title="Abstract">arXiv:2311.06060</a> [<a href="/pdf/2311.06060" title="Download PDF">pdf</a>, <a href="/ps/2311.06060" title="Download PostScript">ps</a>, <a href="/format/2311.06060" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Equivalence for flag codes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Navarro-P%C3%A9rez%2C+M+%C3%81">Miguel &#xc1;ngel Navarro-P&#xe9;rez</a>, 
<a href="/search/cs?searchtype=author&query=Soler-Escriv%C3%A0%2C+X">Xaro Soler-Escriv&#xe0;</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>

</div>
<p class="mathjax">Given a finite field F_q and a positive integer n, a flag is a sequence of
nested F_q-subspaces of a vector space F_q^n and a flag code is a nonempty
collection of flags. The projected codes of a flag code are the constant
dimension codes containing all the subspaces of prescribed dimensions that form
the flags in the flag code.
<br />In this paper we address the notion of equivalence for flag codes and explore
in which situations such an equivalence can be reduced to the equivalence of
the corresponding projected codes. In addition, this study leads to new results
concerning the automorphism group of certain families of flag codes, some of
them also introduced in this paper.
</p>
</div>
</dd>
<dt><a name="item168">[168]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06062" title="Abstract">arXiv:2311.06062</a> [<a href="/pdf/2311.06062" title="Download PDF">pdf</a>, <a href="/format/2311.06062" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Practical Membership Inference Attacks against Fine-tuned Large Language  Models via Self-prompt Calibration
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fu%2C+W">Wenjie Fu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Huandong Wang</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+C">Chen Gao</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+G">Guanghua Liu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yong Li</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+T">Tao Jiang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Cryptography and Security (cs.CR); Machine Learning (cs.LG)

</div>
<p class="mathjax">Membership Inference Attacks (MIA) aim to infer whether a target data record
has been utilized for model training or not. Prior attempts have quantified the
privacy risks of language models (LMs) via MIAs, but there is still no
consensus on whether existing MIA algorithms can cause remarkable privacy
leakage on practical Large Language Models (LLMs). Existing MIAs designed for
LMs can be classified into two categories: reference-free and reference-based
attacks. They are both based on the hypothesis that training records
consistently strike a higher probability of being sampled. Nevertheless, this
hypothesis heavily relies on the overfitting of target models, which will be
mitigated by multiple regularization methods and the generalization of LLMs.
The reference-based attack seems to achieve promising effectiveness in LLMs,
which measures a more reliable membership signal by comparing the probability
discrepancy between the target model and the reference model. However, the
performance of reference-based attack is highly dependent on a reference
dataset that closely resembles the training dataset, which is usually
inaccessible in the practical scenario. Overall, existing MIAs are unable to
effectively unveil privacy leakage over practical fine-tuned LLMs that are
overfitting-free and private. We propose a Membership Inference Attack based on
Self-calibrated Probabilistic Variation (SPV-MIA). Specifically, since
memorization in LLMs is inevitable during the training process and occurs
before overfitting, we introduce a more reliable membership signal,
probabilistic variation, which is based on memorization rather than
overfitting. Furthermore, we introduce a self-prompt approach, which constructs
the dataset to fine-tune the reference model by prompting the target LLM
itself. In this manner, the adversary can collect a dataset with a similar
distribution from public APIs.
</p>
</div>
</dd>
<dt><a name="item169">[169]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06063" title="Abstract">arXiv:2311.06063</a> [<a href="/pdf/2311.06063" title="Download PDF">pdf</a>, <a href="/format/2311.06063" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> RIGA: A Regret-Based Interactive Genetic Algorithm
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Benabbou%2C+N">Nawal Benabbou</a>, 
<a href="/search/cs?searchtype=author&query=Leroy%2C+C">Cassandre Leroy</a>, 
<a href="/search/cs?searchtype=author&query=Lust%2C+T">Thibaut Lust</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Discrete Mathematics (cs.DM)

</div>
<p class="mathjax">In this paper, we propose an interactive genetic algorithm for solving
multi-objective combinatorial optimization problems under preference
imprecision. More precisely, we consider problems where the decision maker's
preferences over solutions can be represented by a parameterized aggregation
function (e.g., a weighted sum, an OWA operator, a Choquet integral), and we
assume that the parameters are initially not known by the recommendation
system. In order to quickly make a good recommendation, we combine elicitation
and search in the following way: 1) we use regret-based elicitation techniques
to reduce the parameter space in a efficient way, 2) genetic operators are
applied on parameter instances (instead of solutions) to better explore the
parameter space, and 3) we generate promising solutions (population) using
existing solving methods designed for the problem with known preferences. Our
algorithm, called RIGA, can be applied to any multi-objective combinatorial
optimization problem provided that the aggregation function is linear in its
parameters and that a (near-)optimal solution can be efficiently determined for
the problem with known preferences. We also study its theoretical performances:
RIGA can be implemented in such way that it runs in polynomial time while
asking no more than a polynomial number of queries. The method is tested on the
multi-objective knapsack and traveling salesman problems. For several
performance indicators (computation times, gap to optimality and number of
queries), RIGA obtains better results than state-of-the-art algorithms.
</p>
</div>
</dd>
<dt><a name="item170">[170]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06065" title="Abstract">arXiv:2311.06065</a> [<a href="/pdf/2311.06065" title="Download PDF">pdf</a>, <a href="/format/2311.06065" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the Existence of Telescopers for P-recursive Sequences
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Du%2C+L">Lixin Du</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 18 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Symbolic Computation (cs.SC)</span>

</div>
<p class="mathjax">We extend the criterion on the existence of telescopers for hypergeometric
terms to the case of P-recursive sequences. This criterion is based on the
concept of integral bases and the generalized Abramov-Petkovsek reduction for
P-recursive sequences.
</p>
</div>
</dd>
<dt><a name="item171">[171]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06066" title="Abstract">arXiv:2311.06066</a> [<a href="/pdf/2311.06066" title="Download PDF">pdf</a>, <a href="/format/2311.06066" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Lidar-based Norwegian tree species detection using deep learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Vermeer%2C+M">Martijn Vermeer</a>, 
<a href="/search/cs?searchtype=author&query=Hay%2C+J+A">Jacob Alexander Hay</a>, 
<a href="/search/cs?searchtype=author&query=V%C3%B6lgyes%2C+D">David V&#xf6;lgyes</a>, 
<a href="/search/cs?searchtype=author&query=Koma%2C+Z">Zs&#xf3;fia Koma</a>, 
<a href="/search/cs?searchtype=author&query=Breidenbach%2C+J">Johannes Breidenbach</a>, 
<a href="/search/cs?searchtype=author&query=Fantin%2C+D+S+M">Daniele Stefano Maria Fantin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Image and Video Processing (eess.IV)

</div>
<p class="mathjax">Background: The mapping of tree species within Norwegian forests is a
time-consuming process, involving forest associations relying on manual
labeling by experts. The process can involve both aerial imagery, personal
familiarity, or on-scene references, and remote sensing data. The
state-of-the-art methods usually use high resolution aerial imagery with
semantic segmentation methods. Methods: We present a deep learning based tree
species classification model utilizing only lidar (Light Detection And Ranging)
data. The lidar images are segmented into four classes (Norway Spruce, Scots
Pine, Birch, background) with a U-Net based network. The model is trained with
focal loss over partial weak labels. A major benefit of the approach is that
both the lidar imagery and the base map for the labels have free and open
access. Results: Our tree species classification model achieves a
macro-averaged F1 score of 0.70 on an independent validation with National
Forest Inventory (NFI) in-situ sample plots. That is close to, but below the
performance of aerial, or aerial and lidar combined models.
</p>
</div>
</dd>
<dt><a name="item172">[172]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06067" title="Abstract">arXiv:2311.06067</a> [<a href="/pdf/2311.06067" title="Download PDF">pdf</a>, <a href="/format/2311.06067" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Attributes Grouping and Mining Hashing for Fine-Grained Image Retrieval
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lu%2C+X">Xin Lu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+S">Shikun Chen</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+Y">Yichao Cao</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+X">Xin Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+X">Xiaobo Lu</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Proceedings of the 31st ACM International Conference on on
  Multimedia (MM '23), 2023, 6558-6566
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">In recent years, hashing methods have been popular in the large-scale media
search for low storage and strong representation capabilities. To describe
objects with similar overall appearance but subtle differences, more and more
studies focus on hashing-based fine-grained image retrieval. Existing hashing
networks usually generate both local and global features through attention
guidance on the same deep activation tensor, which limits the diversity of
feature representations. To handle this limitation, we substitute convolutional
descriptors for attention-guided features and propose an Attributes Grouping
and Mining Hashing (AGMH), which groups and embeds the category-specific visual
attributes in multiple descriptors to generate a comprehensive feature
representation for efficient fine-grained image retrieval. Specifically, an
Attention Dispersion Loss (ADL) is designed to force the descriptors to attend
to various local regions and capture diverse subtle details. Moreover, we
propose a Stepwise Interactive External Attention (SIEA) to mine critical
attributes in each descriptor and construct correlations between fine-grained
attributes and objects. The attention mechanism is dedicated to learning
discrete attributes, which will not cost additional computations in hash codes
generation. Finally, the compact binary codes are learned by preserving
pairwise similarities. Experimental results demonstrate that AGMH consistently
yields the best performance against state-of-the-art methods on fine-grained
benchmark datasets.
</p>
</div>
</dd>
<dt><a name="item173">[173]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06069" title="Abstract">arXiv:2311.06069</a> [<a href="/pdf/2311.06069" title="Download PDF">pdf</a>, <a href="/format/2311.06069" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A filtered multilevel Monte Carlo method for estimating the expectation  of discretized random fields
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Briant%2C+J">J&#xe9;r&#xe9;my Briant</a> (1 and 2), 
<a href="/search/math?searchtype=author&query=Mycek%2C+P">Paul Mycek</a> (2), 
<a href="/search/math?searchtype=author&query=Destouches%2C+M">Mayeul Destouches</a> (3), 
<a href="/search/math?searchtype=author&query=Goux%2C+O">Olivier Goux</a> (2), 
<a href="/search/math?searchtype=author&query=Gratton%2C+S">Serge Gratton</a> (1 and 4), 
<a href="/search/math?searchtype=author&query=G%C3%BCrol%2C+S">Selime G&#xfc;rol</a> (2), 
<a href="/search/math?searchtype=author&query=Simon%2C+E">Ehouarn Simon</a> (1), 
<a href="/search/math?searchtype=author&query=Weaver%2C+A+T">Anthony T. Weaver</a> (2) ((1) Irit CNRS-INP, (2) CECI CNRS-Cerfacs, (3) Met Office, (4) ANITI)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">We investigate the use of multilevel Monte Carlo (MLMC) methods for
estimating the expectation of discretized random fields. Specifically, we
consider a setting in which the input and output vectors of the numerical
simulators have inconsistent dimensions across the multilevel hierarchy. This
requires the introduction of grid transfer operators borrowed from multigrid
methods. Starting from a simple 1D illustration, we demonstrate numerically
that the resulting MLMC estimator deteriorates the estimation of high-frequency
components of the discretized expectation field compared to a Monte Carlo (MC)
estimator. By adapting mathematical tools initially developed for multigrid
methods, we perform a theoretical spectral analysis of the MLMC estimator of
the expectation of discretized random fields, in the specific case of linear,
symmetric and circulant simulators. This analysis provides a spectral
decomposition of the variance into contributions associated with each scale
component of the discretized field. We then propose improved MLMC estimators
using a filtering mechanism similar to the smoothing process of multigrid
methods. The filtering operators improve the estimation of both the small- and
large-scale components of the variance, resulting in a reduction of the total
variance of the estimator. These improvements are quantified for the specific
class of simulators considered in our spectral analysis. The resulting filtered
MLMC (F-MLMC) estimator is applied to the problem of estimating the discretized
variance field of a diffusion-based covariance operator, which amounts to
estimating the expectation of a discretized random field. The numerical
experiments support the conclusions of the theoretical analysis even with
non-linear simulators, and demonstrate the improvements brought by the proposed
F-MLMC estimator compared to both a crude MC and an unfiltered MLMC estimator.
</p>
</div>
</dd>
<dt><a name="item174">[174]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06070" title="Abstract">arXiv:2311.06070</a> [<a href="/pdf/2311.06070" title="Download PDF">pdf</a>, <a href="/format/2311.06070" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning-Based Biharmonic Augmentation for Point Cloud Classification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wei%2C+J">Jiacheng Wei</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+G">Guosheng Lin</a>, 
<a href="/search/cs?searchtype=author&query=Ding%2C+H">Henghui Ding</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+J">Jie Hu</a>, 
<a href="/search/cs?searchtype=author&query=Yap%2C+K">Kim-Hui Yap</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Point cloud datasets often suffer from inadequate sample sizes in comparison
to image datasets, making data augmentation challenging. While traditional
methods, like rigid transformations and scaling, have limited potential in
increasing dataset diversity due to their constraints on altering individual
sample shapes, we introduce the Biharmonic Augmentation (BA) method. BA is a
novel and efficient data augmentation technique that diversifies point cloud
data by imposing smooth non-rigid deformations on existing 3D structures. This
approach calculates biharmonic coordinates for the deformation function and
learns diverse deformation prototypes. Utilizing a CoefNet, our method predicts
coefficients to amalgamate these prototypes, ensuring comprehensive
deformation. Moreover, we present AdvTune, an advanced online augmentation
system that integrates adversarial training. This system synergistically
refines the CoefNet and the classification network, facilitating the automated
creation of adaptive shape deformations contingent on the learner status.
Comprehensive experimental analysis validates the superiority of Biharmonic
Augmentation, showcasing notable performance improvements over prevailing point
cloud augmentation techniques across varied network designs.
</p>
</div>
</dd>
<dt><a name="item175">[175]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06073" title="Abstract">arXiv:2311.06073</a> [<a href="/pdf/2311.06073" title="Download PDF">pdf</a>, <a href="/format/2311.06073" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Collaborative Inference in DNN-based Satellite Systems with Dynamic Task  Streams
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Guan%2C+J">Jinglong Guan</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Q">Qiyang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Murturi%2C+I">Ilir Murturi</a>, 
<a href="/search/cs?searchtype=author&query=Donta%2C+P+K">Praveen Kumar Donta</a>, 
<a href="/search/cs?searchtype=author&query=Dustdar%2C+S">Schahram Dustdar</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Shangguang Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>

</div>
<p class="mathjax">As a driving force in the advancement of intelligent in-orbit applications,
DNN models have been gradually integrated into satellites, producing daily
latency-constraint and computation-intensive tasks. However, the substantial
computation capability of DNN models, coupled with the instability of the
satellite-ground link, pose significant challenges, hindering timely completion
of tasks. It becomes necessary to adapt to task stream changes when dealing
with tasks requiring latency guarantees, such as dynamic observation tasks on
the satellites. To this end, we consider a system model for a collaborative
inference system with latency constraints, leveraging the multi-exit and model
partition technology. To address this, we propose an algorithm, which is
tailored to effectively address the trade-off between task completion and
maintaining satisfactory task accuracy by dynamically choosing early-exit and
partition points. Simulation evaluations show that our proposed algorithm
significantly outperforms baseline algorithms across the task stream with
strict latency constraints.
</p>
</div>
</dd>
<dt><a name="item176">[176]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06078" title="Abstract">arXiv:2311.06078</a> [<a href="/pdf/2311.06078" title="Download PDF">pdf</a>, <a href="/format/2311.06078" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The First Verification Test of Space-Ground Collaborative Intelligence  via Cloud-Native Satellites
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Shangguang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Q">Qiyang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Xing%2C+R">Ruolin Xing</a>, 
<a href="/search/cs?searchtype=author&query=Qi%2C+F">Fei Qi</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+M">Mengwei Xu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by China Communications
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>

</div>
<p class="mathjax">Recent advancements in satellite technologies and the declining cost of
access to space have led to the emergence of large satellite constellations in
Low Earth Orbit. However, these constellations often rely on bent-pipe
architecture, resulting in high communication costs. Existing onboard inference
architectures suffer from limitations in terms of low accuracy and
inflexibility in the deployment and management of in-orbit applications. To
address these challenges, we propose a cloud-native-based satellite design
specifically tailored for Earth Observation tasks, enabling diverse computing
paradigms. In this work, we present a case study of a satellite-ground
collaborative inference system deployed in the Tiansuan constellation,
demonstrating a remarkable 50\% accuracy improvement and a substantial 90\%
data reduction. Our work sheds light on in-orbit energy, where in-orbit
computing accounts for 17\% of the total onboard energy consumption. Our
approach represents a significant advancement of cloud-native satellite, aiming
to enhance the accuracy of in-orbit computing while simultaneously reducing
communication cost.
</p>
</div>
</dd>
<dt><a name="item177">[177]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06079" title="Abstract">arXiv:2311.06079</a> [<a href="/pdf/2311.06079" title="Download PDF">pdf</a>, <a href="/ps/2311.06079" title="Download PostScript">ps</a>, <a href="/format/2311.06079" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Enhancing Rock Image Segmentation in Digital Rock Physics: A Fusion of  Generative AI and State-of-the-Art Neural Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ma%2C+Z">Zhaoyang Ma</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+X">Xupeng He</a>, 
<a href="/search/cs?searchtype=author&query=Kwak%2C+H">Hyung Kwak</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+J">Jun Gao</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+S">Shuyu Sun</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+B">Bicheng Yan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Image and Video Processing (eess.IV)

</div>
<p class="mathjax">In digital rock physics, analysing microstructures from CT and SEM scans is
crucial for estimating properties like porosity and pore connectivity.
Traditional segmentation methods like thresholding and CNNs often fall short in
accurately detailing rock microstructures and are prone to noise. U-Net
improved segmentation accuracy but required many expert-annotated samples, a
laborious and error-prone process due to complex pore shapes. Our study
employed an advanced generative AI model, the diffusion model, to overcome
these limitations. This model generated a vast dataset of CT/SEM and binary
segmentation pairs from a small initial dataset. We assessed the efficacy of
three neural networks: U-Net, Attention-U-net, and TransUNet, for segmenting
these enhanced images. The diffusion model proved to be an effective data
augmentation technique, improving the generalization and robustness of deep
learning models. TransU-Net, incorporating Transformer structures, demonstrated
superior segmentation accuracy and IoU metrics, outperforming both U-Net and
Attention-U-net. Our research advances rock image segmentation by combining the
diffusion model with cutting-edge neural networks, reducing dependency on
extensive expert data and boosting segmentation accuracy and robustness.
TransU-Net sets a new standard in digital rock physics, paving the way for
future geoscience and engineering breakthroughs.
</p>
</div>
</dd>
<dt><a name="item178">[178]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06081" title="Abstract">arXiv:2311.06081</a> [<a href="/pdf/2311.06081" title="Download PDF">pdf</a>, <a href="/format/2311.06081" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> RapidChiplet: A Toolchain for Rapid Design Space Exploration of Chiplet  Architectures
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Iff%2C+P">Patrick Iff</a>, 
<a href="/search/cs?searchtype=author&query=Bruggmann%2C+B">Benigna Bruggmann</a>, 
<a href="/search/cs?searchtype=author&query=Besta%2C+M">Maciej Besta</a>, 
<a href="/search/cs?searchtype=author&query=Benini%2C+L">Luca Benini</a>, 
<a href="/search/cs?searchtype=author&query=Hoefler%2C+T">Torsten Hoefler</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Hardware Architecture (cs.AR)</span>

</div>
<p class="mathjax">Chiplet architectures are a promising paradigm to overcome the scaling
challenges of monolithic chips. Chiplets offer heterogeneity, modularity, and
cost-effectiveness. The design space of chiplet architectures is huge as there
are many degrees of freedom such as the number, size and placement of chiplets,
the topology of the inter-chiplet interconnect and many more. Existing tools
for cost and performance prediction are often too slow to explore this design
space. We present RapidChiplet, a fast, open-source toolchain to predict
latency and throughput of the inter-chiplet interconnect, as well as a chip's
manufacturing cost and thermal stability.
</p>
</div>
</dd>
<dt><a name="item179">[179]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06082" title="Abstract">arXiv:2311.06082</a> [<a href="/pdf/2311.06082" title="Download PDF">pdf</a>, <a href="/ps/2311.06082" title="Download PostScript">ps</a>, <a href="/format/2311.06082" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A high throughput Intrusion Detection System (IDS) to enhance the  security of data transmission among research centers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Grossi%2C+M">Marco Grossi</a>, 
<a href="/search/cs?searchtype=author&query=Alfonsi%2C+F">Fabrizio Alfonsi</a>, 
<a href="/search/cs?searchtype=author&query=Prandini%2C+M">Marco Prandini</a>, 
<a href="/search/cs?searchtype=author&query=Gabrielli%2C+A">Alessandro Gabrielli</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 10 figures, 16th Topical Seminar on Innovative Particle and Radiation Detectors (IPRD23), 25-29 September 2023, Siena, Italy
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Systems and Control (eess.SY)

</div>
<p class="mathjax">Data breaches and cyberattacks represent a severe problem in higher education
institutions and universities that can result in illegal access to sensitive
information and data loss. To enhance the security of data transmission,
Intrusion Prevention Systems (IPS, i.e., firewalls) and Intrusion Detection
Systems (IDS, i.e., packet sniffers) are used to detect potential threats in
the exchanged data. IPSs and IDSs are usually designed as software programs
running on a server machine. However, when the speed of exchanged data is too
high, this solution can become unreliable. In this case, IPSs and IDSs designed
on a real hardware platform, such as ASICs and FPGAs, represent a more reliable
solution. This paper presents a packet sniffer that was designed using a
commercial FPGA development board. The system can support a data throughput of
10 Gbit/s with preliminary results showing that the speed of data transmission
can be reliably extended to 100 Gbit/s. The designed system is highly
configurable by the user and can enhance the data protection of information
transmitted using the Ethernet protocol. It is particularly suited for the
security of universities and research centers, where point-to-point network
connections are dominant and large amount of sensitive data are shared among
different hosts.
</p>
</div>
</dd>
<dt><a name="item180">[180]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06084" title="Abstract">arXiv:2311.06084</a> [<a href="/pdf/2311.06084" title="Download PDF">pdf</a>, <a href="/format/2311.06084" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Perceptual impact of the loss function on deep-learning image coding  performance
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mohammadi%2C+S">Shima Mohammadi</a>, 
<a href="/search/cs?searchtype=author&query=Ascenso%2C+J">Joao Ascenso</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages, 4 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Multimedia (cs.MM)</span>; Image and Video Processing (eess.IV)

</div>
<p class="mathjax">Nowadays, deep-learning image coding solutions have shown similar or better
compression efficiency than conventional solutions based on hand-crafted
transforms and spatial prediction techniques. These deep-learning codecs
require a large training set of images and a training methodology to obtain a
suitable model (set of parameters) for efficient compression. The training is
performed with an optimization algorithm which provides a way to minimize the
loss function. Therefore, the loss function plays a key role in the overall
performance and includes a differentiable quality metric that attempts to mimic
human perception. The main objective of this paper is to study the perceptual
impact of several image quality metrics that can be used in the loss function
of the training process, through a crowdsourcing subjective image quality
assessment study. From this study, it is possible to conclude that the choice
of the quality metric is critical for the perceptual performance of the
deep-learning codec and that can vary depending on the image content.
</p>
</div>
</dd>
<dt><a name="item181">[181]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06093" title="Abstract">arXiv:2311.06093</a> [<a href="/pdf/2311.06093" title="Download PDF">pdf</a>, <a href="/format/2311.06093" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Evaluation of Sampling Algorithms for a Pairwise Subjective Assessment  Methodology
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mohammadi%2C+S">Shima Mohammadi</a>, 
<a href="/search/cs?searchtype=author&query=Ascenso%2C+J">Joao Ascenso</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages, 4 Figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Multimedia (cs.MM)</span>

</div>
<p class="mathjax">Subjective assessment tests are often employed to evaluate image processing
systems, notably image and video compression, super-resolution among others and
have been used as an indisputable way to provide evidence of the performance of
an algorithm or system. While several methodologies can be used in a subjective
quality assessment test, pairwise comparison tests are nowadays attracting a
lot of attention due to their accuracy and simplicity. However, the number of
comparisons in a pairwise comparison test increases quadratically with the
number of stimuli and thus often leads to very long tests, which is impractical
for many cases. However, not all the pairs contribute equally to the final
score and thus, it is possible to reduce the number of comparisons without
degrading the final accuracy. To do so, pairwise sampling methods are often
used to select the pairs which provide more information about the quality of
each stimuli. In this paper, a reliable and much-needed evaluation procedure is
proposed and used for already available methods in the literature, especially
considering the case of subjective evaluation of image and video codecs. The
results indicate that an appropriate selection of the pairs allows to achieve
very reliable scores while requiring the comparison of a much lower number of
pairs.
</p>
</div>
</dd>
<dt><a name="item182">[182]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06095" title="Abstract">arXiv:2311.06095</a> [<a href="/pdf/2311.06095" title="Download PDF">pdf</a>, <a href="/format/2311.06095" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Dual input stream transformer for eye-tracking line assignment
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mercier%2C+T+M">Thomas M. Mercier</a>, 
<a href="/search/cs?searchtype=author&query=Budka%2C+M">Marcin Budka</a>, 
<a href="/search/cs?searchtype=author&query=Vasilev%2C+M+R">Martin R. Vasilev</a>, 
<a href="/search/cs?searchtype=author&query=Kirkby%2C+J+A">Julie A. Kirkby</a>, 
<a href="/search/cs?searchtype=author&query=Angele%2C+B">Bernhard Angele</a>, 
<a href="/search/cs?searchtype=author&query=Slattery%2C+T+J">Timothy J. Slattery</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This work has been submitted to the IEEE Transactions on pattern analysis and machine intelligence for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible. Code will be published after publication
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">We introduce a novel Dual Input Stream Transformer (DIST) for the challenging
problem of assigning fixation points from eye-tracking data collected during
passage reading to the line of text that the reader was actually focused on.
This post-processing step is crucial for analysis of the reading data due to
the presence of noise in the form of vertical drift. We evaluate DIST against
nine classical approaches on a comprehensive suite of nine diverse datasets,
and demonstrate DIST's superiority. By combining multiple instances of the DIST
model in an ensemble we achieve an average accuracy of 98.5\% across all
datasets. Our approach presents a significant step towards addressing the
bottleneck of manual line assignment in reading research. Through extensive
model analysis and ablation studies, we identify key factors that contribute to
DIST's success, including the incorporation of line overlap features and the
use of a second input stream. Through evaluation on a set of diverse datasets
we demonstrate that DIST is robust to various experimental setups, making it a
safe first choice for practitioners in the field.
</p>
</div>
</dd>
<dt><a name="item183">[183]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06098" title="Abstract">arXiv:2311.06098</a> [<a href="/pdf/2311.06098" title="Download PDF">pdf</a>, <a href="/format/2311.06098" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Gradient-robust hybrid DG discretizations for the compressible Stokes  equations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Lederer%2C+P+L">Philip L. Lederer</a>, 
<a href="/search/math?searchtype=author&query=Merdon%2C+C">Christian Merdon</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">This paper studies two hybrid discontinuous Galerkin (HDG) discretizations
for the velocity-density formulation of the compressible Stokes equations with
respect to several desired structural properties, namely provable convergence,
the preservation of non-negativity and mass constraints for the density, and
gradient-robustness. The later property dramatically enhances the accuracy in
well-balanced situations, such as the hydrostatic balance where the pressure
gradient balances the gravity force. One of the studied schemes employs an
H(div)-conforming velocity ansatz space which ensures all mentioned properties,
while a fully discontinuous method is shown to satisfy all properties but the
gradient-robustness. Also higher-order schemes for both variants are presented
and compared in three numerical benchmark problems. The final example shows the
importance also for non-hydrostatic well-balanced states for the compressible
Navier-Stokes equations.
</p>
</div>
</dd>
<dt><a name="item184">[184]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06101" title="Abstract">arXiv:2311.06101</a> [<a href="/pdf/2311.06101" title="Download PDF">pdf</a>, <a href="/format/2311.06101" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> In-Context Learning for MIMO Equalization Using Transformer-Based  Sequence Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zecchin%2C+M">Matteo Zecchin</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+K">Kai Yu</a>, 
<a href="/search/cs?searchtype=author&query=Simeone%2C+O">Osvaldo Simeone</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Large pre-trained sequence models, such as transformer-based architectures,
have been recently shown to have the capacity to carry out in-context learning
(ICL). In ICL, a decision on a new input is made via a direct mapping of the
input and of a few examples from the given task, serving as the task's context,
to the output variable. No explicit updates of model parameters are needed to
tailor the decision to a new task. Pre-training, which amounts to a form of
meta-learning, is based on the observation of examples from several related
tasks. Prior work has shown ICL capabilities for linear regression. In this
study, we leverage ICL to address the inverse problem of multiple-input and
multiple-output (MIMO) equalization based on a context given by pilot symbols.
A task is defined by the unknown fading channel and by the signal-to-noise
ratio (SNR) level, which may be known. To highlight the practical potential of
the approach, we allow for the presence of quantization of the received
signals. We demonstrate via numerical results that transformer-based ICL has a
threshold behavior, whereby, as the number of pre-training tasks grows, the
performance switches from that of a minimum mean squared error (MMSE) equalizer
with a prior determined by the pre-trained tasks to that of an MMSE equalizer
with the true data-generating prior.
</p>
</div>
</dd>
<dt><a name="item185">[185]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06102" title="Abstract">arXiv:2311.06102</a> [<a href="/pdf/2311.06102" title="Download PDF">pdf</a>, <a href="/format/2311.06102" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Making LLMs Worth Every Penny: Resource-Limited Text Classification in  Banking
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Loukas%2C+L">Lefteris Loukas</a>, 
<a href="/search/cs?searchtype=author&query=Stogiannidis%2C+I">Ilias Stogiannidis</a>, 
<a href="/search/cs?searchtype=author&query=Diamantopoulos%2C+O">Odysseas Diamantopoulos</a>, 
<a href="/search/cs?searchtype=author&query=Malakasiotis%2C+P">Prodromos Malakasiotis</a>, 
<a href="/search/cs?searchtype=author&query=Vassos%2C+S">Stavros Vassos</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Long paper accepted to ACM ICAIF-23
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Standard Full-Data classifiers in NLP demand thousands of labeled examples,
which is impractical in data-limited domains. Few-shot methods offer an
alternative, utilizing contrastive learning techniques that can be effective
with as little as 20 examples per class. Similarly, Large Language Models
(LLMs) like GPT-4 can perform effectively with just 1-5 examples per class.
However, the performance-cost trade-offs of these methods remain underexplored,
a critical concern for budget-limited organizations. Our work addresses this
gap by studying the aforementioned approaches over the Banking77 financial
intent detection dataset, including the evaluation of cutting-edge LLMs by
OpenAI, Cohere, and Anthropic in a comprehensive set of few-shot scenarios. We
complete the picture with two additional methods: first, a cost-effective
querying method for LLMs based on retrieval-augmented generation (RAG), able to
reduce operational costs multiple times compared to classic few-shot
approaches, and second, a data augmentation method using GPT-4, able to improve
performance in data-limited scenarios. Finally, to inspire future research, we
provide a human expert's curated subset of Banking77, along with extensive
error analysis.
</p>
</div>
</dd>
<dt><a name="item186">[186]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06103" title="Abstract">arXiv:2311.06103</a> [<a href="/pdf/2311.06103" title="Download PDF">pdf</a>, <a href="/format/2311.06103" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> 1-Lipschitz Neural Networks are more expressive with N-Activations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Prach%2C+B">Bernd Prach</a>, 
<a href="/search/cs?searchtype=author&query=Lampert%2C+C+H">Christoph H. Lampert</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">A crucial property for achieving secure, trustworthy and interpretable deep
learning systems is their robustness: small changes to a system's inputs should
not result in large changes to its outputs. Mathematically, this means one
strives for networks with a small Lipschitz constant. Several recent works have
focused on how to construct such Lipschitz networks, typically by imposing
constraints on the weight matrices. In this work, we study an orthogonal
aspect, namely the role of the activation function. We show that commonly used
activation functions, such as MaxMin, as well as all piece-wise linear ones
with two segments unnecessarily restrict the class of representable functions,
even in the simplest one-dimensional setting. We furthermore introduce the new
N-activation function that is provably more expressive than currently popular
activation functions. We provide code at
https://github.com/berndprach/NActivation.
</p>
</div>
</dd>
<dt><a name="item187">[187]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06104" title="Abstract">arXiv:2311.06104</a> [<a href="/pdf/2311.06104" title="Download PDF">pdf</a>, <a href="/format/2311.06104" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Hamiltonian reduction using a convolutional auto-encoder coupled to an  Hamiltonian neural network
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=C%C3%B4te%2C+R">Rapha&#xeb;l C&#xf4;te</a>, 
<a href="/search/math?searchtype=author&query=Franck%2C+E">Emmanuel Franck</a>, 
<a href="/search/math?searchtype=author&query=Navoret%2C+L">Laurent Navoret</a>, 
<a href="/search/math?searchtype=author&query=Steimer%2C+G">Guillaume Steimer</a>, 
<a href="/search/math?searchtype=author&query=Vigon%2C+V">Vincent Vigon</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 29 pages, 15 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">The reduction of Hamiltonian systems aims to build smaller reduced models,
valid over a certain range of time and parameters, in order to reduce computing
time. By maintaining the Hamiltonian structure in the reduced model, certain
long-term stability properties can be preserved. In this paper, we propose a
non-linear reduction method for models coming from the spatial discretization
of partial differential equations: it is based on convolutional auto-encoders
and Hamiltonian neural networks. Their training is coupled in order to
simultaneously learn the encoder-decoder operators and the reduced dynamics.
Several test cases on non-linear wave dynamics show that the method has better
reduction properties than standard linear Hamiltonian reduction methods.
</p>
</div>
</dd>
<dt><a name="item188">[188]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06110" title="Abstract">arXiv:2311.06110</a> [<a href="/pdf/2311.06110" title="Download PDF">pdf</a>, <a href="/ps/2311.06110" title="Download PostScript">ps</a>, <a href="/format/2311.06110" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An Interpretable Machine Learning Framework to Understand Bikeshare  Demand before and during the COVID-19 Pandemic in New York City
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Uddin%2C+M">Majbah Uddin</a>, 
<a href="/search/cs?searchtype=author&query=Hwang%2C+H">Ho-Ling Hwang</a>, 
<a href="/search/cs?searchtype=author&query=Hasnine%2C+M+S">Md Sami Hasnine</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">In recent years, bikesharing systems have become increasingly popular as
affordable and sustainable micromobility solutions. Advanced mathematical
models such as machine learning are required to generate good forecasts for
bikeshare demand. To this end, this study proposes a machine learning modeling
framework to estimate hourly demand in a large-scale bikesharing system. Two
Extreme Gradient Boosting models were developed: one using data from before the
COVID-19 pandemic (March 2019 to February 2020) and the other using data from
during the pandemic (March 2020 to February 2021). Furthermore, a model
interpretation framework based on SHapley Additive exPlanations was
implemented. Based on the relative importance of the explanatory variables
considered in this study, share of female users and hour of day were the two
most important explanatory variables in both models. However, the month
variable had higher importance in the pandemic model than in the pre-pandemic
model.
</p>
</div>
</dd>
<dt><a name="item189">[189]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06111" title="Abstract">arXiv:2311.06111</a> [<a href="/pdf/2311.06111" title="Download PDF">pdf</a>, <a href="/ps/2311.06111" title="Download PostScript">ps</a>, <a href="/format/2311.06111" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A $(3+&#x3b5;)$-approximation algorithm for the minimum sum of radii  problem with outliers and extensions for generalized lower bounds
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Buchem%2C+M">Moritz Buchem</a>, 
<a href="/search/cs?searchtype=author&query=Ettmayr%2C+K">Katja Ettmayr</a>, 
<a href="/search/cs?searchtype=author&query=Rosado%2C+H+K+K">Hugo Kooki Kasuya Rosado</a>, 
<a href="/search/cs?searchtype=author&query=Wiese%2C+A">Andreas Wiese</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>; Computational Geometry (cs.CG)

</div>
<p class="mathjax">For a given set of points in a metric space and an integer $k$, we seek to
partition the given points into $k$ clusters. For each computed cluster, one
typically defines one point as the center of the cluster. A natural objective
is to minimize the sum of the cluster center's radii, where we assign the
smallest radius $r$ to each center such that each point in the cluster is at a
distance of at most $r$ from the center. The best-known polynomial time
approximation ratio for this problem is $3.389$. In the setting with outliers,
i.e., we are given an integer $m$ and allow up to $m$ points that are not in
any cluster, the best-known approximation factor is $12.365$.
<br />In this paper, we improve both approximation ratios to $3+\epsilon$. Our
algorithms are primal-dual algorithms that use fundamentally new ideas to
compute solutions and to guarantee the claimed approximation ratios. For
example, we replace the classical binary search to find the best value of a
Lagrangian multiplier $\lambda$ by a primal-dual routine in which $\lambda$ is
a variable that is raised. Also, we show that for each connected component due
to almost tight dual constraints, we can find one single cluster that covers
all its points and we bound its cost via a new primal-dual analysis. We remark
that our approximation factor of $3+\epsilon$ is a natural limit for the known
approaches in the literature.
<br />Then, we extend our results to the setting of lower bounds. There are
algorithms known for the case that for each point $i$ there is a lower bound
$L_{i}$, stating that we need to assign at least $L_{i}$ clients to $i$ if $i$
is a cluster center. For this setting, there is a $ 3.83$ approximation if
outliers are not allowed and a ${12.365}$-approximation with outliers. We
improve both ratios to $3.5 + \epsilon$ and, at the same time, generalize the
type of allowed lower bounds.
</p>
</div>
</dd>
<dt><a name="item190">[190]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06115" title="Abstract">arXiv:2311.06115</a> [<a href="/pdf/2311.06115" title="Download PDF">pdf</a>, <a href="/format/2311.06115" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Efficient and Scalable Kernel Matrix Approximations using Hierarchical  Decomposition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Gaddameedi%2C+K">Keerthi Gaddameedi</a>, 
<a href="/search/math?searchtype=author&query=Reiz%2C+S">Severin Reiz</a>, 
<a href="/search/math?searchtype=author&query=Neckel%2C+T">Tobias Neckel</a>, 
<a href="/search/math?searchtype=author&query=Bungartz%2C+H">Hans-Joachim Bungartz</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">With the emergence of Artificial Intelligence, numerical algorithms are
moving towards more approximate approaches. For methods such as PCA or
diffusion maps, it is necessary to compute eigenvalues of a large matrix, which
may also be dense depending on the kernel. A global method, i.e. a method that
requires all data points simultaneously, scales with the data dimension N and
not with the intrinsic dimension d; the complexity for an exact dense
eigendecomposition leads to $\mathcal{O}(N^{3})$. We have combined the two
frameworks, $\mathsf{datafold}$ and $\mathsf{GOFMM}$. The first framework
computes diffusion maps, where the computational bottleneck is the
eigendecomposition while with the second framework we compute the
eigendecomposition approximately within the iterative Lanczos method. A
hierarchical approximation approach scales roughly with a runtime complexity of
$\mathcal{O}(Nlog(N))$ vs. $\mathcal{O}(N^{3})$ for a classic approach. We
evaluate the approach on two benchmark datasets -- scurve and MNIST -- with
strong and weak scaling using OpenMP and MPI on dense matrices with maximum
size of $100k\times100k$.
</p>
</div>
</dd>
<dt><a name="item191">[191]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06116" title="Abstract">arXiv:2311.06116</a> [<a href="/pdf/2311.06116" title="Download PDF">pdf</a>, <a href="/format/2311.06116" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Quantum Bisimilarity via Barbs and Contexts: Curbing the Power of  Non-Deterministic Observers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ceragioli%2C+L">Lorenzo Ceragioli</a>, 
<a href="/search/cs?searchtype=author&query=Gadducci%2C+F">Fabio Gadducci</a>, 
<a href="/search/cs?searchtype=author&query=Lomurno%2C+G">Giuseppe Lomurno</a>, 
<a href="/search/cs?searchtype=author&query=Tedeschi%2C+G">Gabriele Tedeschi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This is the extended version of the POPL2024 paper "Quantum Bisimilarity via Barbs and Contexts: Curbing the Power of Non-Deterministic Observers"
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>

</div>
<p class="mathjax">Past years have seen the development of a few proposals for quantum
extensions of process calculi. The rationale is clear: with the development of
quantum communication protocols, there is a need to abstract and focus on the
basic features of quantum concurrent systems, like CCS has done for its
classical counterpart. So far, though, no accepted standard has emerged,
neither for the syntax nor for the behavioural semantics. Indeed, the various
proposals do not agree on what should be the observational properties of
quantum values, and as a matter of fact, the soundness of such properties has
never been validated against the prescriptions of quantum theory.
<br />To this aim, we introduce a new calculus, Linear Quantum CCS, and investigate
the features of behavioural equivalences based on barbs and contexts. Our
calculus can be thought of as an asynchronous, linear version of qCCS (based on
value-passing CCS). Linearity ensures that each qubit is sent exactly once,
precisely specifying which qubits of a process interact with the context.
<br />We exploit contexts to examine how bisimilarities relate to quantum theory.
We show that the observational power of general contexts is incompatible with
quantum theory: roughly, they can perform non-deterministic moves depending on
quantum values without measuring (hence perturbing) them.
<br />Therefore, we refine the operational semantics in order to prevent contexts
from performing unfeasible non-deterministic choices. This induces a coarser
bisimilarity that better fits the quantum setting: (i) it lifts the
indistinguishability of quantum states to the distributions of processes and,
despite the additional constraints, (ii) it preserves the expressivity of
non-deterministic choices based on classical information. To the best of our
knowledge, our semantics is the first one that satisfies the two properties
above.
</p>
</div>
</dd>
<dt><a name="item192">[192]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06117" title="Abstract">arXiv:2311.06117</a> [<a href="/pdf/2311.06117" title="Download PDF">pdf</a>, <a href="/format/2311.06117" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Distributionally Robust Skeleton Learning of Discrete Bayesian Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yeshu Li</a>, 
<a href="/search/cs?searchtype=author&query=Ziebart%2C+B+D">Brian D. Ziebart</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> NeurIPS 2O23 Spotlight. More empirical results added
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
<p class="mathjax">We consider the problem of learning the exact skeleton of general discrete
Bayesian networks from potentially corrupted data. Building on distributionally
robust optimization and a regression approach, we propose to optimize the most
adverse risk over a family of distributions within bounded Wasserstein distance
or KL divergence to the empirical distribution. The worst-case risk accounts
for the effect of outliers. The proposed approach applies for general
categorical random variables without assuming faithfulness, an ordinal
relationship or a specific form of conditional distribution. We present
efficient algorithms and show the proposed methods are closely related to the
standard regularized regression approach. Under mild assumptions, we derive
non-asymptotic guarantees for successful structure learning with logarithmic
sample complexities for bounded-degree graphs. Numerical study on synthetic and
real datasets validates the effectiveness of our method. Code is available at
https://github.com/DanielLeee/drslbn.
</p>
</div>
</dd>
<dt><a name="item193">[193]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06119" title="Abstract">arXiv:2311.06119</a> [<a href="/pdf/2311.06119" title="Download PDF">pdf</a>, <a href="/format/2311.06119" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Augmenting Ad-Hoc IR Dataset for Interactive Conversational Search
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Erbacher%2C+P">Pierre Erbacher</a>, 
<a href="/search/cs?searchtype=author&query=Nie%2C+J">Jian-Yun Nie</a>, 
<a href="/search/cs?searchtype=author&query=Preux%2C+P">Philippe Preux</a>, 
<a href="/search/cs?searchtype=author&query=Soulier%2C+L">Laure Soulier</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>

</div>
<p class="mathjax">A peculiarity of conversational search systems is that they involve
mixed-initiatives such as system-generated query clarifying questions.
Evaluating those systems at a large scale on the end task of IR is very
challenging, requiring adequate datasets containing such interactions. However,
current datasets only focus on either traditional ad-hoc IR tasks or query
clarification tasks, the latter being usually seen as a reformulation task from
the initial query. The only two datasets known to us that contain both document
relevance judgments and the associated clarification interactions are Qulac and
ClariQ. Both are based on the TREC Web Track 2009-12 collection, but cover a
very limited number of topics (237 topics), far from being enough for training
and testing conversational IR models. To fill the gap, we propose a methodology
to automatically build large-scale conversational IR datasets from ad-hoc IR
datasets in order to facilitate explorations on conversational IR. Our
methodology is based on two processes: 1) generating query clarification
interactions through query clarification and answer generators, and 2)
augmenting ad-hoc IR datasets with simulated interactions. In this paper, we
focus on MsMarco and augment it with query clarification and answer
simulations. We perform a thorough evaluation showing the quality and the
relevance of the generated interactions for each initial query. This paper
shows the feasibility and utility of augmenting ad-hoc IR datasets for
conversational IR.
</p>
</div>
</dd>
<dt><a name="item194">[194]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06121" title="Abstract">arXiv:2311.06121</a> [<a href="/pdf/2311.06121" title="Download PDF">pdf</a>, <a href="/format/2311.06121" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Is it indeed bigger better? The comprehensive study of claim detection  LMs applied for disinformation tackling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hyben%2C+M">Martin Hyben</a>, 
<a href="/search/cs?searchtype=author&query=Kula%2C+S">Sebastian Kula</a>, 
<a href="/search/cs?searchtype=author&query=Srba%2C+I">Ivan Srba</a>, 
<a href="/search/cs?searchtype=author&query=Moro%2C+R">Robert Moro</a>, 
<a href="/search/cs?searchtype=author&query=Simko%2C+J">Jakub Simko</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 27 pages, 10 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">This study compares the performance of (1) fine-tuned models and (2)
extremely large language models on the task of check-worthy claim detection.
For the purpose of the comparison we composed a multilingual and multi-topical
dataset comprising texts of various sources and styles. Building on this, we
performed a benchmark analysis to determine the most general multilingual and
multi-topical claim detector.
<br />We chose three state-of-the-art models in the check-worthy claim detection
task and fine-tuned them. Furthermore, we selected three state-of-the-art
extremely large language models without any fine-tuning. We made modifications
to the models to adapt them for multilingual settings and through extensive
experimentation and evaluation. We assessed the performance of all the models
in terms of accuracy, recall, and F1-score in in-domain and cross-domain
scenarios. Our results demonstrate that despite the technological progress in
the area of natural language processing, the models fine-tuned for the task of
check-worthy claim detection still outperform the zero-shot approaches in a
cross-domain settings.
</p>
</div>
</dd>
<dt><a name="item195">[195]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06122" title="Abstract">arXiv:2311.06122</a> [<a href="/pdf/2311.06122" title="Download PDF">pdf</a>, <a href="/format/2311.06122" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fight Fire with Fire: Combating Adversarial Patch Attacks using  Pattern-randomized Defensive Patches
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Feng%2C+J">Jianan Feng</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jiachun Li</a>, 
<a href="/search/cs?searchtype=author&query=Miao%2C+C">Changqing Miao</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+J">Jianjun Huang</a>, 
<a href="/search/cs?searchtype=author&query=You%2C+W">Wei You</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+W">Wenchang Shi</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+B">Bin Liang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Object detection has found extensive applications in various tasks, but it is
also susceptible to adversarial patch attacks. Existing defense methods often
necessitate modifications to the target model or result in unacceptable time
overhead. In this paper, we adopt a counterattack approach, following the
principle of "fight fire with fire," and propose a novel and general
methodology for defending adversarial attacks. We utilize an active defense
strategy by injecting two types of defensive patches, canary and woodpecker,
into the input to proactively probe or weaken potential adversarial patches
without altering the target model. Moreover, inspired by randomization
techniques employed in software security, we employ randomized canary and
woodpecker injection patterns to defend against defense-aware attacks. The
effectiveness and practicality of the proposed method are demonstrated through
comprehensive experiments. The results illustrate that canary and woodpecker
achieve high performance, even when confronted with unknown attack methods,
while incurring limited time overhead. Furthermore, our method also exhibits
sufficient robustness against defense-aware attacks, as evidenced by adaptive
attack experiments.
</p>
</div>
</dd>
<dt><a name="item196">[196]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06132" title="Abstract">arXiv:2311.06132</a> [<a href="/pdf/2311.06132" title="Download PDF">pdf</a>, <a href="/ps/2311.06132" title="Download PostScript">ps</a>, <a href="/format/2311.06132" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The core of an approval-based PB instance can be empty for nearly all  cost-based satisfaction functions and for the share
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Maly%2C+J">Jan Maly</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>

</div>
<p class="mathjax">The core is a strong fairness notion in multiwinner voting and participatory
budgeting (PB). It is known that the core can be empty if we consider cardinal
utilities, but it is not known whether it is always satisfiable with
approval-ballots. In this short note, I show that in approval-based PB the core
can be empty for nearly all satisfaction functions that are based on the cost
of a project. In particular, I show that the core can be empty for the cost
satisfaction function, satisfaction functions based on diminishing marginal
returns and the share. However, it remains open whether the core can be empty
for the cardinality satisfaction function.
</p>
</div>
</dd>
<dt><a name="item197">[197]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06137" title="Abstract">arXiv:2311.06137</a> [<a href="/pdf/2311.06137" title="Download PDF">pdf</a>, <a href="/format/2311.06137" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MonoProb: Self-Supervised Monocular Depth Estimation with Interpretable  Uncertainty
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chabot%2C+R+M+F">Remi Marsal Florian Chabot</a>, 
<a href="/search/cs?searchtype=author&query=Loesch%2C+A">Angelique Loesch</a>, 
<a href="/search/cs?searchtype=author&query=Grolleau%2C+W">William Grolleau</a>, 
<a href="/search/cs?searchtype=author&query=Sahbi%2C+H">Hichem Sahbi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at WACV 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Self-supervised monocular depth estimation methods aim to be used in critical
applications such as autonomous vehicles for environment analysis. To
circumvent the potential imperfections of these approaches, a quantification of
the prediction confidence is crucial to guide decision-making systems that rely
on depth estimation. In this paper, we propose MonoProb, a new unsupervised
monocular depth estimation method that returns an interpretable uncertainty,
which means that the uncertainty reflects the expected error of the network in
its depth predictions. We rethink the stereo or the structure-from-motion
paradigms used to train unsupervised monocular depth models as a probabilistic
problem. Within a single forward pass inference, this model provides a depth
prediction and a measure of its confidence, without increasing the inference
time. We then improve the performance on depth and uncertainty with a novel
self-distillation loss for which a student is supervised by a pseudo ground
truth that is a probability distribution on depth output by a teacher. To
quantify the performance of our models we design new metrics that, unlike
traditional ones, measure the absolute performance of uncertainty predictions.
Our experiments highlight enhancements achieved by our method on standard depth
and uncertainty metrics as well as on our tailored metrics.
https://github.com/CEA-LIST/MonoProb
</p>
</div>
</dd>
<dt><a name="item198">[198]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06141" title="Abstract">arXiv:2311.06141</a> [<a href="/pdf/2311.06141" title="Download PDF">pdf</a>, <a href="/format/2311.06141" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Federated Learning Across Decentralized and Unshared Archives for Remote  Sensing Image Classification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=B%C3%BCy%C3%BCkta%C5%9F%2C+B">Bar&#x131;&#x15f; B&#xfc;y&#xfc;kta&#x15f;</a>, 
<a href="/search/cs?searchtype=author&query=Sumbul%2C+G">Gencer Sumbul</a>, 
<a href="/search/cs?searchtype=author&query=Demir%2C+B">Beg&#xfc;m Demir</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to the IEEE Geoscience and Remote Sensing Magazine
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Federated learning (FL) enables the collaboration of multiple deep learning
models to learn from decentralized data archives (i.e., clients) without
accessing data on clients. Although FL offers ample opportunities in knowledge
discovery from distributed image archives, it is seldom considered in remote
sensing (RS). In this paper, as a first time in RS, we present a comparative
study of state-of-the-art FL algorithms. To this end, we initially provide a
systematic review of the FL algorithms presented in the computer vision
community for image classification problems, and select several
state-of-the-art FL algorithms based on their effectiveness with respect to
training data heterogeneity across clients (known as non-IID data). After
presenting an extensive overview of the selected algorithms, a theoretical
comparison of the algorithms is conducted based on their: 1) local training
complexity; 2) aggregation complexity; 3) learning efficiency; 4) communication
cost; and 5) scalability in terms of number of clients. As the classification
task, we consider multi-label classification (MLC) problem since RS images
typically consist of multiple classes, and thus can simultaneously be
associated with multi-labels. After the theoretical comparison, experimental
analyses are presented to compare them under different decentralization
scenarios in terms of MLC performance. Based on our comprehensive analyses, we
finally derive a guideline for selecting suitable FL algorithms in RS. The code
of this work will be publicly available at https://git.tu-berlin.de/rsim/FL-RS.
</p>
</div>
</dd>
<dt><a name="item199">[199]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06142" title="Abstract">arXiv:2311.06142</a> [<a href="/pdf/2311.06142" title="Download PDF">pdf</a>, <a href="/format/2311.06142" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Compiler from Array Programs to Vectorized Homomorphic Encryption
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Recto%2C+R">Rolph Recto</a>, 
<a href="/search/cs?searchtype=author&query=Myers%2C+A+C">Andrew C. Myers</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Programming Languages (cs.PL)</span>; Cryptography and Security (cs.CR)

</div>
<p class="mathjax">Homomorphic encryption (HE) is a practical approach to secure computation
over encrypted data. However, writing programs with efficient HE
implementations remains the purview of experts. A difficult barrier for
programmability is that efficiency requires operations to be vectorized in
inobvious ways, forcing efficient HE programs to manipulate ciphertexts with
complex data layouts and to interleave computations with data movement
primitives.
<br />We present Viaduct-HE, a compiler generates efficient vectorized HE programs.
Viaduct-HE can generate both the operations and complex data layouts required
for efficient HE programs. The source language of Viaduct-HE is array-oriented,
enabling the compiler to have a simple representation of possible vectorization
schedules. With such a representation, the compiler searches the space of
possible vectorization schedules and finds those with efficient data layouts.
After finding a vectorization schedule, Viaduct-HE further optimizes HE
programs through term rewriting. The compiler has extension points to customize
the exploration of vectorization schedules, to customize the cost model for HE
programs, and to add back ends for new HE libraries.
<br />Our evaluation of the prototype Viaduct-HE compiler shows that it produces
efficient vectorized HE programs with sophisticated data layouts and
optimizations comparable to those designed by experts.
</p>
</div>
</dd>
<dt><a name="item200">[200]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06144" title="Abstract">arXiv:2311.06144</a> [<a href="/pdf/2311.06144" title="Download PDF">pdf</a>, <a href="/format/2311.06144" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multi-Agent Reinforcement Learning for the Low-Level Control of a  Quadrotor UAV
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yu%2C+B">Beomyeol Yu</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+T">Taeyoung Lee</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 6 figures, 3 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Systems and Control (eess.SY)

</div>
<p class="mathjax">This paper presents multi-agent reinforcement learning frameworks for the
low-level control of a quadrotor UAV. While single-agent reinforcement learning
has been successfully applied to quadrotors, training a single monolithic
network is often data-intensive and time-consuming. To address this, we
decompose the quadrotor dynamics into the translational dynamics and the yawing
dynamics, and assign a reinforcement learning agent to each part for efficient
training and performance improvements. The proposed multi-agent framework for
quadrotor low-level control that leverages the underlying structures of the
quadrotor dynamics is a unique contribution. Further, we introduce
regularization terms to mitigate steady-state errors and to avoid aggressive
control inputs. Through benchmark studies with sim-to-sim transfer, it is
illustrated that the proposed multi-agent reinforcement learning substantially
improves the convergence rate of the training and the stability of the
controlled dynamics.
</p>
</div>
</dd>
<dt><a name="item201">[201]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06145" title="Abstract">arXiv:2311.06145</a> [<a href="/pdf/2311.06145" title="Download PDF">pdf</a>, <a href="/format/2311.06145" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An Evaluation of Forensic Facial Recognition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Norman%2C+J">Justin Norman</a>, 
<a href="/search/cs?searchtype=author&query=Agarwal%2C+S">Shruti Agarwal</a>, 
<a href="/search/cs?searchtype=author&query=Farid%2C+H">Hany Farid</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Computers and Society (cs.CY)

</div>
<p class="mathjax">Recent advances in machine learning and computer vision have led to reported
facial recognition accuracies surpassing human performance. We question if
these systems will translate to real-world forensic scenarios in which a
potentially low-resolution, low-quality, partially-occluded image is compared
against a standard facial database. We describe the construction of a
large-scale synthetic facial dataset along with a controlled facial forensic
lineup, the combination of which allows for a controlled evaluation of facial
recognition under a range of real-world conditions. Using this synthetic
dataset, and a popular dataset of real faces, we evaluate the accuracy of two
popular neural-based recognition systems. We find that previously reported face
recognition accuracies of more than 95% drop to as low as 65% in this more
challenging forensic scenario.
</p>
</div>
</dd>
<dt><a name="item202">[202]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06147" title="Abstract">arXiv:2311.06147</a> [<a href="/pdf/2311.06147" title="Download PDF">pdf</a>, <a href="/ps/2311.06147" title="Download PostScript">ps</a>, <a href="/format/2311.06147" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Incorporating sufficient physical information into artificial neural  networks: a guaranteed improvement via physics-based Rao-Blackwellization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Geuken%2C+G">Gian-Luca Geuken</a>, 
<a href="/search/cs?searchtype=author&query=Mosler%2C+J">J&#xf6;rn Mosler</a>, 
<a href="/search/cs?searchtype=author&query=Kurzeja%2C+P">Patrick Kurzeja</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Engineering, Finance, and Science (cs.CE)</span>; Artificial Intelligence (cs.AI); Statistics Theory (math.ST)

</div>
<p class="mathjax">The concept of Rao-Blackwellization is employed to improve predictions of
artificial neural networks by physical information. The error norm and the
proof of improvement are transferred from the original statistical concept to a
deterministic one, using sufficient information on physics-based conditions.
The proposed strategy is applied to material modeling and illustrated by
examples of the identification of a yield function, elasto-plastic steel
simulations, the identification of driving forces for quasi-brittle damage and
rubber experiments. Sufficient physical information is employed, e.g., in the
form of invariants, parameters of a minimization problem, dimensional analysis,
isotropy and differentiability. It is proven how intuitive accretion of
information can yield improvement if it is physically sufficient, but also how
insufficient or superfluous information can cause impairment. Opportunities for
the improvement of artificial neural networks are explored in terms of the
training data set, the networks' structure and output filters. Even crude
initial predictions are remarkably improved by reducing noise, overfitting and
data requirements.
</p>
</div>
</dd>
<dt><a name="item203">[203]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06149" title="Abstract">arXiv:2311.06149</a> [<a href="/pdf/2311.06149" title="Download PDF">pdf</a>, <a href="/ps/2311.06149" title="Download PostScript">ps</a>, <a href="/format/2311.06149" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Dense Visual Odometry Using Genetic Algorithm
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Djema%2C+S">Slimane Djema</a>, 
<a href="/search/cs?searchtype=author&query=Benselama%2C+Z+A">Zoubir Abdeslem Benselama</a>, 
<a href="/search/cs?searchtype=author&query=Hedjar%2C+R">Ramdane Hedjar</a>, 
<a href="/search/cs?searchtype=author&query=Abdallah%2C+K">Krabi Abdallah</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages, 9 figures
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> International Journal of Intelligent Systems and Applications in
  Engineering, Volume 11, issue 3, Pages 611-619, published date 2023/7/16
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Our work aims to estimate the camera motion mounted on the head of a mobile
robot or a moving object from RGB-D images in a static scene. The problem of
motion estimation is transformed into a nonlinear least squares function.
Methods for solving such problems are iterative. Various classic methods gave
an iterative solution by linearizing this function. We can also use the
metaheuristic optimization method to solve this problem and improve results. In
this paper, a new algorithm is developed for visual odometry using a sequence
of RGB-D images. This algorithm is based on a genetic algorithm. The proposed
iterative genetic algorithm searches using particles to estimate the optimal
motion and then compares it to the traditional methods. To evaluate our method,
we use the root mean square error to compare it with the based energy method
and another metaheuristic method. We prove the efficiency of our innovative
algorithm on a large set of images.
</p>
</div>
</dd>
<dt><a name="item204">[204]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06152" title="Abstract">arXiv:2311.06152</a> [<a href="/pdf/2311.06152" title="Download PDF">pdf</a>, <a href="/format/2311.06152" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Going beyond persistent homology using persistent homology
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Immonen%2C+J">Johanna Immonen</a>, 
<a href="/search/cs?searchtype=author&query=Souza%2C+A+H">Amauri H. Souza</a>, 
<a href="/search/cs?searchtype=author&query=Garg%2C+V">Vikas Garg</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Representational limits of message-passing graph neural networks (MP-GNNs),
e.g., in terms of the Weisfeiler-Leman (WL) test for isomorphism, are well
understood. Augmenting these graph models with topological features via
persistent homology (PH) has gained prominence, but identifying the class of
attributed graphs that PH can recognize remains open. We introduce a novel
concept of color-separating sets to provide a complete resolution to this
important problem. Specifically, we establish the necessary and sufficient
conditions for distinguishing graphs based on the persistence of their
connected components, obtained from filter functions on vertex and edge colors.
Our constructions expose the limits of vertex- and edge-level PH, proving that
neither category subsumes the other. Leveraging these theoretical insights, we
propose RePHINE for learning topological features on graphs. RePHINE
efficiently combines vertex- and edge-level PH, achieving a scheme that is
provably more powerful than both. Integrating RePHINE into MP-GNNs boosts their
expressive power, resulting in gains over standard PH on several benchmarks for
graph classification.
</p>
</div>
</dd>
<dt><a name="item205">[205]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06153" title="Abstract">arXiv:2311.06153</a> [<a href="/pdf/2311.06153" title="Download PDF">pdf</a>, <a href="/format/2311.06153" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Interpretable Graph Anomaly Detection using Gradient Attention Maps
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yifei Yang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+P">Peng Wang</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+X">Xiaofan He</a>, 
<a href="/search/cs?searchtype=author&query=Zou%2C+D">Dongmian Zou</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Detecting unusual patterns in graph data is a crucial task in data mining.
However, existing methods often face challenges in consistently achieving
satisfactory performance and lack interpretability, which hinders our
understanding of anomaly detection decisions. In this paper, we propose a novel
approach to graph anomaly detection that leverages the power of
interpretability to enhance performance. Specifically, our method extracts an
attention map derived from gradients of graph neural networks, which serves as
a basis for scoring anomalies. In addition, we conduct theoretical analysis
using synthetic data to validate our method and gain insights into its
decision-making process. To demonstrate the effectiveness of our method, we
extensively evaluate our approach against state-of-the-art graph anomaly
detection techniques. The results consistently demonstrate the superior
performance of our method compared to the baselines.
</p>
</div>
</dd>
<dt><a name="item206">[206]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06154" title="Abstract">arXiv:2311.06154</a> [<a href="/pdf/2311.06154" title="Download PDF">pdf</a>, <a href="/format/2311.06154" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Last-Level Defense for Application Integrity and Confidentiality
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fernandez%2C+G+P">Gabriel P. Fernandez</a>, 
<a href="/search/cs?searchtype=author&query=Brito%2C+A">Andrey Brito</a>, 
<a href="/search/cs?searchtype=author&query=Hartono%2C+A+P+P">Ardhi Putra Pratama Hartono</a>, 
<a href="/search/cs?searchtype=author&query=Sardar%2C+M+U">Muhammad Usama Sardar</a>, 
<a href="/search/cs?searchtype=author&query=Fetzer%2C+C">Christof Fetzer</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Distributed, Parallel, and Cluster Computing (cs.DC)

</div>
<p class="mathjax">Our objective is to protect the integrity and confidentiality of applications
operating in untrusted environments. Trusted Execution Environments (TEEs) are
not a panacea. Hardware TEEs fail to protect applications against Sybil, Fork
and Rollback Attacks and, consequently, fail to preserve the consistency and
integrity of applications. We introduce a novel system, LLD, that enforces the
integrity and consistency of applications in a transparent and scalable
fashion. Our solution augments TEEs with instantiation control and rollback
protection. Instantiation control, enforced with TEE-supported leases,
mitigates Sybil/Fork Attacks without incurring the high costs of solving
crypto-puzzles. Our rollback detection mechanism does not need excessive
replication, nor does it sacrifice durability. We show that implementing these
functionalities in the LLD runtime automatically protects applications and
services such as a popular DBMS.
</p>
</div>
</dd>
<dt><a name="item207">[207]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06156" title="Abstract">arXiv:2311.06156</a> [<a href="/pdf/2311.06156" title="Download PDF">pdf</a>, <a href="/format/2311.06156" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Triad: Trusted Timestamps in Untrusted Environments
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fernandez%2C+G+P">Gabriel P. Fernandez</a>, 
<a href="/search/cs?searchtype=author&query=Brito%2C+A">Andrey Brito</a>, 
<a href="/search/cs?searchtype=author&query=Fetzer%2C+C">Christof Fetzer</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Distributed, Parallel, and Cluster Computing (cs.DC)

</div>
<p class="mathjax">We aim to provide trusted time measurement mechanisms to applications and
cloud infrastructure deployed in environments that could harbor potential
adversaries, including the hardware infrastructure provider. Despite Trusted
Execution Environments (TEEs) providing multiple security functionalities,
timestamps from the Operating System are not covered. Nevertheless, some
services require time for validating permissions or ordering events. To address
that need, we introduce Triad, a trusted timestamp dispatcher of time readings.
The solution provides trusted timestamps enforced by mutually supportive
enclave-based clock servers that create a continuous trusted timeline. We
leverage enclave properties such as forced exits and CPU-based counters to
mitigate attacks on the server's timestamp counters. Triad produces trusted,
confidential, monotonically-increasing timestamps with bounded error and
desirable, non-trivial properties. Our implementation relies on Intel SGX and
SCONE, allowing transparent usage. We evaluate Triad's error and behavior in
multiple dimensions.
</p>
</div>
</dd>
<dt><a name="item208">[208]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06157" title="Abstract">arXiv:2311.06157</a> [<a href="/pdf/2311.06157" title="Download PDF">pdf</a>, <a href="/ps/2311.06157" title="Download PostScript">ps</a>, <a href="/format/2311.06157" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Registry of Scientometric Data Sources
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fraumann%2C+G">Grischa Fraumann</a>, 
<a href="/search/cs?searchtype=author&query=Lilienthal%2C+S">Svantje Lilienthal</a>, 
<a href="/search/cs?searchtype=author&query=Hauschke%2C+C">Christian Hauschke</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 20 pages, 4 figures, 1 table
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Digital Libraries (cs.DL)</span>

</div>
<p class="mathjax">In this article, we describe the Registry of Scientometric Data Sources
(RSDS) and several scientometric data sources recorded in this open registry
that could be of interest for scientometricians, institutional researchers,
librarians, practitioners, policy makers, students and other stakeholders with
an interest in scientometrics. This registry was created after carrying out a
literature review and a technical evaluation of several data sources. Each data
source is recorded with descriptive metadata fields and URLs to further
information. This article describes the motivation behind the development of
the registry, explains the features that are available on its public website
(https://labs.tib.eu/rosi), and closes with a call for participation.
</p>
</div>
</dd>
<dt><a name="item209">[209]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06158" title="Abstract">arXiv:2311.06158</a> [<a href="/pdf/2311.06158" title="Download PDF">pdf</a>, <a href="/format/2311.06158" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Language Models can be Logical Solvers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Feng%2C+J">Jiazhan Feng</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+R">Ruochen Xu</a>, 
<a href="/search/cs?searchtype=author&query=Hao%2C+J">Junheng Hao</a>, 
<a href="/search/cs?searchtype=author&query=Sharma%2C+H">Hiteshi Sharma</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+Y">Yelong Shen</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+D">Dongyan Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+W">Weizhu Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Preprint
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Logical reasoning is a fundamental aspect of human intelligence and a key
component of tasks like problem-solving and decision-making. Recent
advancements have enabled Large Language Models (LLMs) to potentially exhibit
reasoning capabilities, but complex logical reasoning remains a challenge. The
state-of-the-art, solver-augmented language models, use LLMs to parse natural
language logical questions into symbolic representations first and then adopt
external logical solvers to take in the symbolic representations and output the
answers. Despite their impressive performance, any parsing errors will
inevitably result in the failure of the execution of the external logical
solver and no answer to the logical questions. In this paper, we introduce
LoGiPT, a novel language model that directly emulates the reasoning processes
of logical solvers and bypasses the parsing errors by learning to strict
adherence to solver syntax and grammar. LoGiPT is fine-tuned on a newly
constructed instruction-tuning dataset derived from revealing and refining the
invisible reasoning process of deductive solvers. Experimental results on two
public deductive reasoning datasets demonstrate that LoGiPT outperforms
state-of-the-art solver-augmented LMs and few-shot prompting methods on
competitive LLMs like ChatGPT or GPT-4.
</p>
</div>
</dd>
<dt><a name="item210">[210]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06162" title="Abstract">arXiv:2311.06162</a> [<a href="/pdf/2311.06162" title="Download PDF">pdf</a>, <a href="/format/2311.06162" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Challenges in Developing Great Quasi-Monte Carlo Software
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Choi%2C+S+T">Sou-Cheng T. Choi</a>, 
<a href="/search/math?searchtype=author&query=Ding%2C+Y">Yuhan Ding</a>, 
<a href="/search/math?searchtype=author&query=Hickernell%2C+F+J">Fred J. Hickernell</a>, 
<a href="/search/math?searchtype=author&query=Rathinavel%2C+J">Jagadeeswaran Rathinavel</a>, 
<a href="/search/math?searchtype=author&query=Sorokin%2C+A+G">Aleksei G. Sorokin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Computation (stat.CO)

</div>
<p class="mathjax">Quasi-Monte Carlo (QMC) methods have developed over several decades. With the
explosion in computational science, there is a need for great software that
implements QMC algorithms. We summarize the QMC software that has been
developed to date, propose some criteria for developing great QMC software, and
suggest some steps toward achieving great software. We illustrate these
criteria and steps with the Quasi-Monte Carlo Python library (QMCPy), an
open-source community software framework, extensible by design with common
programming interfaces to an increasing number of existing or emerging QMC
libraries developed by the greater community of QMC researchers.
</p>
</div>
</dd>
<dt><a name="item211">[211]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06164" title="Abstract">arXiv:2311.06164</a> [<a href="/pdf/2311.06164" title="Download PDF">pdf</a>, <a href="/format/2311.06164" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fast and Reliable Reduced-Order Models for Cardiac Electrophysiology
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Chellappa%2C+S">Sridhar Chellappa</a>, 
<a href="/search/math?searchtype=author&query=Cans%C4%B1z%2C+B">Bar&#x131;&#x15f; Cans&#x131;z</a>, 
<a href="/search/math?searchtype=author&query=Feng%2C+L">Lihong Feng</a>, 
<a href="/search/math?searchtype=author&query=Benner%2C+P">Peter Benner</a>, 
<a href="/search/math?searchtype=author&query=Kaliske%2C+M">Michael Kaliske</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 28 pages, 17 figures, 1 table
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">Mathematical models of the human heart are increasingly playing a vital role
in understanding the working mechanisms of the heart, both under healthy
functioning and during disease. The aim is to aid medical practitioners
diagnose and treat the many ailments affecting the heart. Towards this,
modelling cardiac electrophysiology is crucial as the heart's electrical
activity underlies the contraction mechanism and the resulting pumping action.
The governing equations and the constitutive laws describing the electrical
activity in the heart are coupled, nonlinear, and involve a fast moving wave
front, which is generally solved by the finite element method. The simulation
of this complex system as part of a virtual heart model is challenging due to
the necessity of fine spatial and temporal resolution of the domain. Therefore,
efficient surrogate models are needed to predict the dynamics under varying
parameters and inputs. In this work, we develop an adaptive, projection-based
surrogate model for cardiac electrophysiology. We introduce an a posteriori
error estimator that can accurately and efficiently quantify the accuracy of
the surrogate model. Using the error estimator, we systematically update our
surrogate model through a greedy search of the parameter space. Furthermore,
using the error estimator, the parameter search space is dynamically updated
such that the most relevant samples get chosen at every iteration. The proposed
adaptive surrogate modelling technique is tested on three benchmark models to
illustrate its efficiency, accuracy, and ability of generalization.
</p>
</div>
</dd>
<dt><a name="item212">[212]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06166" title="Abstract">arXiv:2311.06166</a> [<a href="/pdf/2311.06166" title="Download PDF">pdf</a>, <a href="/format/2311.06166" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Random Access Protocols for Cell-Free Wireless Network Exploiting  Statistical Behavior of THz Signal Propagation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bhardwaj%2C+P">Pranay Bhardwaj</a>, 
<a href="/search/cs?searchtype=author&query=Zafaruddin%2C+S+M">S.M. Zafaruddin</a>, 
<a href="/search/cs?searchtype=author&query=Leshem%2C+A">Amir Leshem</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This work has been submitted to IEEE for possible publcation. arXiv admin note: substantial text overlap with <a href="/abs/2310.18616">arXiv:2310.18616</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">The current body of research on terahertz (THz) wireless communications
predominantly focuses on its application for single-user backhaul/fronthaul
connectivity at sub-THz frequencies. First, we develop a generalized
statistical model for signal propagation at THz frequencies encompassing
physical layer impairments, including random path-loss with Gamma distribution
for the molecular absorption coefficient, short-term fading characterized by
the $\alpha$-$\eta$-$\kappa$-$\mu$ distribution, antenna misalignment errors,
and transceiver hardware impairments. Next, we propose random access protocols
for a cell-free wireless network, ensuring successful transmission for multiple
users with limited delay and energy loss, exploiting the combined effect of
random atmospheric absorption, non-linearity of fading, hardware impairments,
and antenna misalignment errors. We consider two schemes: a fixed transmission
probability (FTP) scheme where the transmission probability (TP) of each user
is updated at the beginning of the data transmission and an adaptive
transmission probability (ATP) scheme where the TP is updated with each
successful reception of the data. We analyze the performance of both protocols
using delay, energy consumption, and outage probability with scaling laws for
the transmission of a data frame consisting of a single packet from users at a
predefined quality of service (QoS).
</p>
</div>
</dd>
<dt><a name="item213">[213]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06169" title="Abstract">arXiv:2311.06169</a> [<a href="/pdf/2311.06169" title="Download PDF">pdf</a>, <a href="/format/2311.06169" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deep Fast Vision: A Python Library for Accelerated Deep Transfer  Learning Vision Prototyping
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Prezja%2C+F">Fabi Prezja</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, 1 figure
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG); Image and Video Processing (eess.IV)

</div>
<p class="mathjax">Deep learning-based vision is characterized by intricate frameworks that
often necessitate a profound understanding, presenting a barrier to newcomers
and limiting broad adoption. With many researchers grappling with the
constraints of smaller datasets, there's a pronounced reliance on pre-trained
neural networks, especially for tasks such as image classification. This
reliance is further intensified in niche imaging areas where obtaining vast
datasets is challenging. Despite the widespread use of transfer learning as a
remedy to the small dataset dilemma, a conspicuous absence of tailored auto-ML
solutions persists. Addressing these challenges is "Deep Fast Vision", a python
library that streamlines the deep learning process. This tool offers a
user-friendly experience, enabling results through a simple nested dictionary
definition, helping to democratize deep learning for non-experts. Designed for
simplicity and scalability, Deep Fast Vision appears as a bridge, connecting
the complexities of existing deep learning frameworks with the needs of a
diverse user base.
</p>
</div>
</dd>
<dt><a name="item214">[214]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06170" title="Abstract">arXiv:2311.06170</a> [<a href="/pdf/2311.06170" title="Download PDF">pdf</a>, <a href="/format/2311.06170" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Time Scale Network: A Shallow Neural Network For Time Series Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Meyer%2C+T">Trevor Meyer</a>, 
<a href="/search/cs?searchtype=author&query=Shultz%2C+C">Camden Shultz</a>, 
<a href="/search/cs?searchtype=author&query=Dehak%2C+N">Najim Dehak</a>, 
<a href="/search/cs?searchtype=author&query=Moro-Velazquez%2C+L">Laureano Moro-Velazquez</a>, 
<a href="/search/cs?searchtype=author&query=Irazoqui%2C+P">Pedro Irazoqui</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 5 figures, preprint
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Time series data is often composed of information at multiple time scales,
particularly in biomedical data. While numerous deep learning strategies exist
to capture this information, many make networks larger, require more data, are
more demanding to compute, and are difficult to interpret. This limits their
usefulness in real-world applications facing even modest computational or data
constraints and can further complicate their translation into practice. We
present a minimal, computationally efficient Time Scale Network combining the
translation and dilation sequence used in discrete wavelet transforms with
traditional convolutional neural networks and back-propagation. The network
simultaneously learns features at many time scales for sequence classification
with significantly reduced parameters and operations. We demonstrate advantages
in Atrial Dysfunction detection including: superior accuracy-per-parameter and
accuracy-per-operation, fast training and inference speeds, and visualization
and interpretation of learned patterns in atrial dysfunction detection on ECG
signals. We also demonstrate impressive performance in seizure prediction using
EEG signals. Our network isolated a few time scales that could be strategically
selected to achieve 90.9% accuracy using only 1,133 active parameters and
consistently converged on pulsatile waveform shapes. This method does not rest
on any constraints or assumptions regarding signal content and could be
leveraged in any area of time series analysis dealing with signals containing
features at many time scales.
</p>
</div>
</dd>
<dt><a name="item215">[215]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06175" title="Abstract">arXiv:2311.06175</a> [<a href="/pdf/2311.06175" title="Download PDF">pdf</a>, <a href="/ps/2311.06175" title="Download PostScript">ps</a>, <a href="/format/2311.06175" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Search-Based Fairness Testing: An Overview
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mamman%2C+H">Hussaini Mamman</a>, 
<a href="/search/cs?searchtype=author&query=Basri%2C+S">Shuib Basri</a>, 
<a href="/search/cs?searchtype=author&query=Balogun%2C+A+O">Abdullateef Oluwaqbemiga Balogun</a>, 
<a href="/search/cs?searchtype=author&query=Imam%2C+A+A">Abdullahi Abubakar Imam</a>, 
<a href="/search/cs?searchtype=author&query=Kumar%2C+G">Ganesh Kumar</a>, 
<a href="/search/cs?searchtype=author&query=Capretz%2C+L+F">Luiz Fernando Capretz</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> IEEE International Conference on Computing (ICOCO 2023), Langkawi Island, Malaysia, pp. 89-94, October 2023
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> IEEE International Conference on Computing (ICOCO 2023), Langkawi
  Island, Malaysia, pp. 89-94, October 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
<p class="mathjax">Artificial Intelligence (AI) has demonstrated remarkable capabilities in
domains such as recruitment, finance, healthcare, and the judiciary. However,
biases in AI systems raise ethical and societal concerns, emphasizing the need
for effective fairness testing methods. This paper reviews current research on
fairness testing, particularly its application through search-based testing.
Our analysis highlights progress and identifies areas of improvement in
addressing AI systems biases. Future research should focus on leveraging
established search-based testing methodologies for fairness testing.
</p>
</div>
</dd>
<dt><a name="item216">[216]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06176" title="Abstract">arXiv:2311.06176</a> [<a href="/pdf/2311.06176" title="Download PDF">pdf</a>, <a href="/format/2311.06176" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Automatic Report Generation for Histopathology images using pre-trained  Vision Transformers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sengupta%2C+S">Saurav Sengupta</a>, 
<a href="/search/cs?searchtype=author&query=Brown%2C+D+E">Donald E. Brown</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Deep learning for histopathology has been successfully used for disease
classification, image segmentation and more. However, combining image and text
modalities using current state-of-the-art methods has been a challenge due to
the high resolution of histopathology images. Automatic report generation for
histopathology images is one such challenge. In this work, we show that using
an existing pre-trained Vision Transformer in a two-step process of first using
it to encode 4096x4096 sized patches of the Whole Slide Image (WSI) and then
using it as the encoder and an LSTM decoder for report generation, we can build
a fairly performant and portable report generation mechanism that takes into
account the whole of the high resolution image, instead of just the patches. We
are also able to use representations from an existing powerful pre-trained
hierarchical vision transformer and show its usefulness in not just zero shot
classification but also for report generation.
</p>
</div>
</dd>
<dt><a name="item217">[217]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06183" title="Abstract">arXiv:2311.06183</a> [<a href="/pdf/2311.06183" title="Download PDF">pdf</a>, <a href="/ps/2311.06183" title="Download PostScript">ps</a>, <a href="/format/2311.06183" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Novel Multidimensional Reference Model For Heterogeneous Textual  Datasets Using Context, Semantic And Syntactic Clues
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kumar%2C+G">Ganesh Kumar</a>, 
<a href="/search/cs?searchtype=author&query=Basri%2C+S">Shuib Basri</a>, 
<a href="/search/cs?searchtype=author&query=Imam%2C+A+A">Abdullahi Abubakar Imam</a>, 
<a href="/search/cs?searchtype=author&query=Balogun%2C+A+O">Abdullateef Oluwaqbemiga Balogun</a>, 
<a href="/search/cs?searchtype=author&query=Mamman%2C+H">Hussaini Mamman</a>, 
<a href="/search/cs?searchtype=author&query=Capretz%2C+L+F">Luiz Fernando Capretz</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> International Journal of Advanced Science and Applications, Volume 14, Issue 10, pp. 754-763, 2023
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> International Journal of Advanced Science and Applications, Volume
  14, Issue 10, pp. 754-763, 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
<p class="mathjax">With the advent of technology and use of latest devices, they produces
voluminous data. Out of it, 80% of the data are unstructured and remaining 20%
are structured and semi-structured. The produced data are in heterogeneous
format and without following any standards. Among heterogeneous (structured,
semi-structured and unstructured) data, textual data are nowadays used by
industries for prediction and visualization of future challenges. Extracting
useful information from it is really challenging for stakeholders due to
lexical and semantic matching. Few studies have been solving this issue by
using ontologies and semantic tools, but the main limitations of proposed work
were the less coverage of multidimensional terms. To solve this problem, this
study aims to produce a novel multidimensional reference model using
linguistics categories for heterogeneous textual datasets. The categories such
context, semantic and syntactic clues are focused along with their score. The
main contribution of MRM is that it checks each tokens with each term based on
indexing of linguistic categories such as synonym, antonym, formal, lexical
word order and co-occurrence. The experiments show that the percentage of MRM
is better than the state-of-the-art single dimension reference model in terms
of more coverage, linguistics categories and heterogeneous datasets.
</p>
</div>
</dd>
<dt><a name="item218">[218]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06184" title="Abstract">arXiv:2311.06184</a> [<a href="/pdf/2311.06184" title="Download PDF">pdf</a>, <a href="/format/2311.06184" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Frequency-domain MLPs are More Effective Learners in Time Series  Forecasting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yi%2C+K">Kun Yi</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Q">Qi Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Fan%2C+W">Wei Fan</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Shoujin Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+P">Pengyang Wang</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+H">Hui He</a>, 
<a href="/search/cs?searchtype=author&query=Lian%2C+D">Defu Lian</a>, 
<a href="/search/cs?searchtype=author&query=An%2C+N">Ning An</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+L">Longbing Cao</a>, 
<a href="/search/cs?searchtype=author&query=Niu%2C+Z">Zhendong Niu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Time series forecasting has played the key role in different industrial,
including finance, traffic, energy, and healthcare domains. While existing
literatures have designed many sophisticated architectures based on RNNs, GNNs,
or Transformers, another kind of approaches based on multi-layer perceptrons
(MLPs) are proposed with simple structure, low complexity, and {superior
performance}. However, most MLP-based forecasting methods suffer from the
point-wise mappings and information bottleneck, which largely hinders the
forecasting performance. To overcome this problem, we explore a novel direction
of applying MLPs in the frequency domain for time series forecasting. We
investigate the learned patterns of frequency-domain MLPs and discover their
two inherent characteristic benefiting forecasting, (i) global view: frequency
spectrum makes MLPs own a complete view for signals and learn global
dependencies more easily, and (ii) energy compaction: frequency-domain MLPs
concentrate on smaller key part of frequency components with compact signal
energy. Then, we propose FreTS, a simple yet effective architecture built upon
Frequency-domain MLPs for Time Series forecasting. FreTS mainly involves two
stages, (i) Domain Conversion, that transforms time-domain signals into complex
numbers of frequency domain; (ii) Frequency Learning, that performs our
redesigned MLPs for the learning of real and imaginary part of frequency
components. The above stages operated on both inter-series and intra-series
scales further contribute to channel-wise and time-wise dependency learning.
Extensive experiments on 13 real-world benchmarks (including 7 benchmarks for
short-term forecasting and 6 benchmarks for long-term forecasting) demonstrate
our consistent superiority over state-of-the-art methods.
</p>
</div>
</dd>
<dt><a name="item219">[219]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06187" title="Abstract">arXiv:2311.06187</a> [<a href="/pdf/2311.06187" title="Download PDF">pdf</a>, <a href="/ps/2311.06187" title="Download PostScript">ps</a>, <a href="/format/2311.06187" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Note on Tesla&#x27;s Revised Safety Report Crash Rates
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Goodall%2C+N">Noah Goodall</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>

</div>
<p class="mathjax">Between June 2018 and December 2022, Tesla released quarterly safety reports
citing average miles between crashes for Tesla vehicles. Prior to March 2021,
crash rates were categorized as 1) with their SAE Level 2 automated driving
system Autopilot engaged, 2) without Autopilot but with active safety features
such as automatic emergency braking, and 3) without Autopilot and without
active safety features. In January 2022, Tesla revised past reports to reflect
their new categories of with and without Autopilot engaged, in addition to
making small adjustments based on recently discovered double counting of
reports and excluding previously recorded crashes that did not meet their
thresholds of airbag or active safety restraint activation. The revisions are
heavily biased towards no-active-safety-features$\unicode{x2014}$a surprising
result given prior research showing that drivers predominantly keep most active
safety features enabled. As Tesla's safety reports represent the only national
source of Level 2 advanced driver assistance system crash rates, clarification
of their methods is essential for researchers and regulators. This note
describes the changes and considers possible explanations for the
discrepancies.
</p>
</div>
</dd>
<dt><a name="item220">[220]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06188" title="Abstract">arXiv:2311.06188</a> [<a href="/pdf/2311.06188" title="Download PDF">pdf</a>, <a href="/format/2311.06188" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Formalization of Martingales in Isabelle/HOL
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Keskin%2C+A">Ata Keskin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 61 pages, Bachelor's Thesis in Informatics and Mathematics at the Technical University of Munich
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>; Probability (math.PR)

</div>
<p class="mathjax">This thesis presents a formalization of martingales in arbitrary Banach
spaces using Isabelle/HOL. We begin by examining formalizations in prominent
proof repositories and extend the definition of the conditional expectation
operator from the real numbers to general Banach spaces. The current
formalization of conditional expectation in the Isabelle library is limited to
real-valued functions. To overcome this limitation, we use measure theoretic
arguments to construct the conditional expectation in Banach spaces using
suitable limits of simple functions. Subsequently, we define stochastic
processes and introduce the concepts of adapted, progressively measurable and
predictable processes using suitable locale definitions. We show the relation
$$\text{adapted} \supseteq \text{progressive} \supseteq \text{predictable}$$
Furthermore, we show that progressive measurability and adaptedness are
equivalent when the indexing set is discrete. We pay special attention to
predictable processes in discrete-time, showing that $(X_n)_{n \in \mathbb{N}}$
is predictable if and only if $(X_{n + 1})_{n \in \mathbb{N}}$ is adapted.
<br />We rigorously define martingales, submartingales, and supermartingales,
presenting their first consequences and corollaries. Discrete-time martingales
are given special attention in the formalization. In every step of our
formalization, we make extensive use of the powerful locale system of Isabelle.
<br />The formalization further contributes by generalizing concepts in Bochner
integration by extending their application from the real numbers to arbitrary
Banach spaces equipped with a second-countable topology. Induction schemes for
integrable simple functions on Banach spaces are introduced. Additionally, we
formalize a powerful result called the "Averaging Theorem" which allows us to
show that densities are unique in Banach spaces.
</p>
</div>
</dd>
<dt><a name="item221">[221]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06189" title="Abstract">arXiv:2311.06189</a> [<a href="/pdf/2311.06189" title="Download PDF">pdf</a>, <a href="/format/2311.06189" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Syntax-semantics interface: an algebraic model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Marcolli%2C+M">Matilde Marcolli</a>, 
<a href="/search/cs?searchtype=author&query=Berwick%2C+R+C">Robert C. Berwick</a>, 
<a href="/search/cs?searchtype=author&query=Chomsky%2C+N">Noam Chomsky</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> LaTeX, 75 pages, 19 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Logic (math.LO); Quantum Algebra (math.QA); Rings and Algebras (math.RA)

</div>
<p class="mathjax">We extend our formulation of Merge and Minimalism in terms of Hopf algebras
to an algebraic model of a syntactic-semantic interface. We show that methods
adopted in the formulation of renormalization (extraction of meaningful
physical values) in theoretical physics are relevant to describe the extraction
of meaning from syntactic expressions. We show how this formulation relates to
computational models of semantics and we answer some recent controversies about
implications for generative linguistics of the current functioning of large
language models.
</p>
</div>
</dd>
<dt><a name="item222">[222]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06190" title="Abstract">arXiv:2311.06190</a> [<a href="/pdf/2311.06190" title="Download PDF">pdf</a>, <a href="/format/2311.06190" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FourierGNN: Rethinking Multivariate Time Series Forecasting from a Pure  Graph Perspective
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yi%2C+K">Kun Yi</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Q">Qi Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Fan%2C+W">Wei Fan</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+H">Hui He</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+L">Liang Hu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+P">Pengyang Wang</a>, 
<a href="/search/cs?searchtype=author&query=An%2C+N">Ning An</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+L">Longbing Cao</a>, 
<a href="/search/cs?searchtype=author&query=Niu%2C+Z">Zhendong Niu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: substantial text overlap with <a href="/abs/2210.03093">arXiv:2210.03093</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Multivariate time series (MTS) forecasting has shown great importance in
numerous industries. Current state-of-the-art graph neural network (GNN)-based
forecasting methods usually require both graph networks (e.g., GCN) and
temporal networks (e.g., LSTM) to capture inter-series (spatial) dynamics and
intra-series (temporal) dependencies, respectively. However, the uncertain
compatibility of the two networks puts an extra burden on handcrafted model
designs. Moreover, the separate spatial and temporal modeling naturally
violates the unified spatiotemporal inter-dependencies in real world, which
largely hinders the forecasting performance. To overcome these problems, we
explore an interesting direction of directly applying graph networks and
rethink MTS forecasting from a pure graph perspective. We first define a novel
data structure, hypervariate graph, which regards each series value (regardless
of variates or timestamps) as a graph node, and represents sliding windows as
space-time fully-connected graphs. This perspective considers spatiotemporal
dynamics unitedly and reformulates classic MTS forecasting into the predictions
on hypervariate graphs. Then, we propose a novel architecture Fourier Graph
Neural Network (FourierGNN) by stacking our proposed Fourier Graph Operator
(FGO) to perform matrix multiplications in Fourier space. FourierGNN
accommodates adequate expressiveness and achieves much lower complexity, which
can effectively and efficiently accomplish the forecasting. Besides, our
theoretical analysis reveals FGO's equivalence to graph convolutions in the
time domain, which further verifies the validity of FourierGNN. Extensive
experiments on seven datasets have demonstrated our superior performance with
higher efficiency and fewer parameters compared with state-of-the-art methods.
</p>
</div>
</dd>
<dt><a name="item223">[223]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06192" title="Abstract">arXiv:2311.06192</a> [<a href="/pdf/2311.06192" title="Download PDF">pdf</a>, <a href="/format/2311.06192" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Greedy PIG: Adaptive Integrated Gradients
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Axiotis%2C+K">Kyriakos Axiotis</a>, 
<a href="/search/cs?searchtype=author&query=Abu-al-haija%2C+S">Sami Abu-al-haija</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+L">Lin Chen</a>, 
<a href="/search/cs?searchtype=author&query=Fahrbach%2C+M">Matthew Fahrbach</a>, 
<a href="/search/cs?searchtype=author&query=Fu%2C+G">Gang Fu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Machine Learning (stat.ML)

</div>
<p class="mathjax">Deep learning has become the standard approach for most machine learning
tasks. While its impact is undeniable, interpreting the predictions of deep
learning models from a human perspective remains a challenge. In contrast to
model training, model interpretability is harder to quantify and pose as an
explicit optimization problem. Inspired by the AUC softmax information curve
(AUC SIC) metric for evaluating feature attribution methods, we propose a
unified discrete optimization framework for feature attribution and feature
selection based on subset selection. This leads to a natural adaptive
generalization of the path integrated gradients (PIG) method for feature
attribution, which we call Greedy PIG. We demonstrate the success of Greedy PIG
on a wide variety of tasks, including image feature attribution, graph
compression/explanation, and post-hoc feature selection on tabular data. Our
results show that introducing adaptivity is a powerful and versatile method for
making attribution methods more powerful.
</p>
</div>
</dd>
<dt><a name="item224">[224]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06201" title="Abstract">arXiv:2311.06201</a> [<a href="/pdf/2311.06201" title="Download PDF">pdf</a>, <a href="/ps/2311.06201" title="Download PostScript">ps</a>, <a href="/format/2311.06201" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Myths and Facts about a Career in Software Testing: A Comparison between  Students&#x27; Beliefs and Professionals&#x27; Experience
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=de+Souza+Santos%2C+R">Ronnie de Souza Santos</a>, 
<a href="/search/cs?searchtype=author&query=Capretz%2C+L+F">Luiz Fernando Capretz</a>, 
<a href="/search/cs?searchtype=author&query=Magalhaes%2C+C">Cleyton Magalhaes</a>, 
<a href="/search/cs?searchtype=author&query=Souza%2C+R">Rodrigo Souza</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> IEEE Software, Volume 40, Issue 5, pp. 76-84, September/October 2023
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> IEEE Software, Volume 40, Issue 5, pp. 76-84. September/October
  2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
<p class="mathjax">Testing is an indispensable part of software development. However, a career
in software testing is reported to be unpopular among students in computer
science and related areas. This can potentially create a shortage of testers in
the software industry in the future. The question is, whether the perception
that undergraduate students have about software testing is accurate and whether
it differs from the experience reported by those who work in testing activities
in the software development industry. This investigation demonstrates that a
career in software testing is more exciting and rewarding, as reported by
professionals working in the field, than students may believe. Therefore, in
order to guarantee a workforce focused on software quality, the academy and the
software industry need to work together to better inform students about
software testing and its essential role in software development.
</p>
</div>
</dd>
<dt><a name="item225">[225]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06204" title="Abstract">arXiv:2311.06204</a> [<a href="/pdf/2311.06204" title="Download PDF">pdf</a>, <a href="/format/2311.06204" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> BanglaBait: Semi-Supervised Adversarial Approach for Clickbait Detection  on Bangla Clickbait Dataset
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mahtab%2C+M+M">Md. Motahar Mahtab</a>, 
<a href="/search/cs?searchtype=author&query=Haque%2C+M">Monirul Haque</a>, 
<a href="/search/cs?searchtype=author&query=Hasan%2C+M">Mehedi Hasan</a>, 
<a href="/search/cs?searchtype=author&query=Sadeque%2C+F">Farig Sadeque</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 3 figures, 5 tables, published in Recent Advances in Natural Language Processing 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Intentionally luring readers to click on a particular content by exploiting
their curiosity defines a title as clickbait. Although several studies focused
on detecting clickbait titles in English articles, low resource language like
Bangla has not been given adequate attention. To tackle clickbait titles in
Bangla, we have constructed the first Bangla clickbait detection dataset
containing 15,056 labeled news articles and 65,406 unlabelled news articles
extracted from clickbait dense news sites. Each article has been labeled by
three expert linguists and includes an article's title, body, and other
metadata. By incorporating labeled and unlabelled data, we finetune a
pretrained Bangla transformer model in an adversarial fashion using Semi
Supervised Generative Adversarial Networks (SS GANs). The proposed model acts
as a good baseline for this dataset, outperforming traditional neural network
models (LSTM, GRU, CNN) and linguistic feature based models. We expect that
this dataset and the detailed analysis and comparison of these clickbait
detection models will provide a fundamental basis for future research into
detecting clickbait titles in Bengali articles. We have released the
corresponding code and dataset.
</p>
</div>
</dd>
<dt><a name="item226">[226]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06206" title="Abstract">arXiv:2311.06206</a> [<a href="/pdf/2311.06206" title="Download PDF">pdf</a>, <a href="/ps/2311.06206" title="Download PostScript">ps</a>, <a href="/format/2311.06206" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Parallel Algorithms for Equilevel Predicates
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Garg%2C+V+K">Vijay K. Garg</a>, 
<a href="/search/cs?searchtype=author&query=Streit%2C+R+P">Robert P. Streit</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To appear in ICDCN 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>; Data Structures and Algorithms (cs.DS)

</div>
<p class="mathjax">We define a new class of predicates called equilevel predicates on a
distributive lattice which eases the analysis of parallel algorithms. Many
combinatorial problems such as the vertex cover problem, the bipartite matching
problem, and the minimum spanning tree problem can be modeled as detecting an
equilevel predicate. The problem of detecting an equilevel problem is
NP-complete, but equilevel predicates with the helpful property can be detected
in polynomial time in an online manner. An equilevel predicate has the helpful
property with a polynomial time algorithm if the algorithm can return a
nonempty set of indices such that advancing on any of them can be used to
detect the predicate. Furthermore, the refined independently helpful property
allows online parallel detection of such predicates in NC. When the
independently helpful property holds, advancing on all the specified indices in
parallel can be used to detect the predicate in polylogarithmic time.
<br />We also define a special class of equilevel predicates called solitary
predicates. Unless NP = RP, this class of predicate also does not admit
efficient algorithms. Earlier work has shown that solitary predicates with the
efficient advancement can be detected in polynomial time. We introduce two
properties called the antimonotone advancement and the efficient rejection
which yield the detection of solitary predicates in NC. Finally, we identify
the minimum spanning tree, the shortest path, and the conjunctive predicate
detection as problems satisfying such properties, giving alternative
certifications of their NC memberships as a result.
</p>
</div>
</dd>
<dt><a name="item227">[227]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06207" title="Abstract">arXiv:2311.06207</a> [<a href="/pdf/2311.06207" title="Download PDF">pdf</a>, <a href="/ps/2311.06207" title="Download PostScript">ps</a>, <a href="/format/2311.06207" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Vox Populi, Vox ChatGPT: Large Language Models, Education and Democracy
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zuber%2C+N">Niina Zuber</a>, 
<a href="/search/cs?searchtype=author&query=Gogoll%2C+J">Jan Gogoll</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>

</div>
<p class="mathjax">In the era of generative AI and specifically large language models (LLMs),
exemplified by ChatGPT, the intersection of artificial intelligence and human
reasoning has become a focal point of global attention. Unlike conventional
search engines, LLMs go beyond mere information retrieval, entering into the
realm of discourse culture. Its outputs mimic well-considered, independent
opinions or statements of facts, presenting a pretense of wisdom. This paper
explores the potential transformative impact of LLMs on democratic societies.
It delves into the concerns regarding the difficulty in distinguishing
ChatGPT-generated texts from human output. The discussion emphasizes the
essence of authorship, rooted in the unique human capacity for reason - a
quality indispensable for democratic discourse and successful collaboration
within free societies. Highlighting the potential threats to democracy, this
paper presents three arguments: the Substitution argument, the Authenticity
argument, and the Facts argument. These arguments highlight the potential risks
that are associated with an overreliance on LLMs. The central thesis posits
that widespread deployment of LLMs may adversely affect the fabric of a
democracy if not comprehended and addressed proactively and properly. In
proposing a solution, we advocate for an emphasis on education as a means to
mitigate risks. We suggest cultivating thinking skills in children, fostering
coherent thought formulation, and distinguishing between machine-generated
output and genuine, i.e. human, reasoning. The focus should be on responsible
development and usage of LLMs, with the goal of augmenting human capacities in
thinking, deliberating and decision-making rather than substituting them.
</p>
</div>
</dd>
<dt><a name="item228">[228]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06210" title="Abstract">arXiv:2311.06210</a> [<a href="/pdf/2311.06210" title="Download PDF">pdf</a>, <a href="/format/2311.06210" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Optimal Cooperative Multiplayer Learning Bandits with Noisy Rewards and  No Communication
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chang%2C+W">William Chang</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+Y">Yuanhao Lu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Multiagent Systems (cs.MA); Machine Learning (stat.ML)

</div>
<p class="mathjax">We consider a cooperative multiplayer bandit learning problem where the
players are only allowed to agree on a strategy beforehand, but cannot
communicate during the learning process. In this problem, each player
simultaneously selects an action. Based on the actions selected by all players,
the team of players receives a reward. The actions of all the players are
commonly observed. However, each player receives a noisy version of the reward
which cannot be shared with other players. Since players receive potentially
different rewards, there is an asymmetry in the information used to select
their actions. In this paper, we provide an algorithm based on upper and lower
confidence bounds that the players can use to select their optimal actions
despite the asymmetry in the reward information. We show that this algorithm
can achieve logarithmic $O(\frac{\log T}{\Delta_{\bm{a}}})$ (gap-dependent)
regret as well as $O(\sqrt{T\log T})$ (gap-independent) regret. This is
asymptotically optimal in $T$. We also show that it performs empirically better
than the current state of the art algorithm for this environment.
</p>
</div>
</dd>
<dt><a name="item229">[229]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06211" title="Abstract">arXiv:2311.06211</a> [<a href="/pdf/2311.06211" title="Download PDF">pdf</a>, <a href="/format/2311.06211" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ASSIST: Interactive Scene Nodes for Scalable and Realistic Indoor  Simulation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhong%2C+Z">Zhide Zhong</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+J">Jiakai Cao</a>, 
<a href="/search/cs?searchtype=author&query=Gu%2C+S">Songen Gu</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+S">Sirui Xie</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+W">Weibo Gao</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+L">Liyi Luo</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+Z">Zike Yan</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+H">Hao Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+G">Guyue Zhou</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Robotics (cs.RO)

</div>
<p class="mathjax">We present ASSIST, an object-wise neural radiance field as a panoptic
representation for compositional and realistic simulation. Central to our
approach is a novel scene node data structure that stores the information of
each object in a unified fashion, allowing online interaction in both intra-
and cross-scene settings. By incorporating a differentiable neural network
along with the associated bounding box and semantic features, the proposed
structure guarantees user-friendly interaction on independent objects to scale
up novel view simulation. Objects in the scene can be queried, added,
duplicated, deleted, transformed, or swapped simply through mouse/keyboard
controls or language instructions. Experiments demonstrate the efficacy of the
proposed method, where scaled realistic simulation can be achieved through
interactive editing and compositional rendering, with color images, depth
images, and panoptic segmentation masks generated in a 3D consistent manner.
</p>
</div>
</dd>
<dt><a name="item230">[230]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06214" title="Abstract">arXiv:2311.06214</a> [<a href="/pdf/2311.06214" title="Download PDF">pdf</a>, <a href="/format/2311.06214" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Instant3D: Fast Text-to-3D with Sparse-View Generation and Large  Reconstruction Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jiahao Li</a>, 
<a href="/search/cs?searchtype=author&query=Tan%2C+H">Hao Tan</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+K">Kai Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+Z">Zexiang Xu</a>, 
<a href="/search/cs?searchtype=author&query=Luan%2C+F">Fujun Luan</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+Y">Yinghao Xu</a>, 
<a href="/search/cs?searchtype=author&query=Hong%2C+Y">Yicong Hong</a>, 
<a href="/search/cs?searchtype=author&query=Sunkavalli%2C+K">Kalyan Sunkavalli</a>, 
<a href="/search/cs?searchtype=author&query=Shakhnarovich%2C+G">Greg Shakhnarovich</a>, 
<a href="/search/cs?searchtype=author&query=Bi%2C+S">Sai Bi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project webpage: <a href="https://jiahao.ai/instant3d/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Text-to-3D with diffusion models have achieved remarkable progress in recent
years. However, existing methods either rely on score distillation-based
optimization which suffer from slow inference, low diversity and Janus
problems, or are feed-forward methods that generate low quality results due to
the scarcity of 3D training data. In this paper, we propose Instant3D, a novel
method that generates high-quality and diverse 3D assets from text prompts in a
feed-forward manner. We adopt a two-stage paradigm, which first generates a
sparse set of four structured and consistent views from text in one shot with a
fine-tuned 2D text-to-image diffusion model, and then directly regresses the
NeRF from the generated images with a novel transformer-based sparse-view
reconstructor. Through extensive experiments, we demonstrate that our method
can generate high-quality, diverse and Janus-free 3D assets within 20 seconds,
which is two order of magnitude faster than previous optimization-based methods
that can take 1 to 10 hours. Our project webpage: https://jiahao.ai/instant3d/.
</p>
</div>
</dd>
<dt><a name="item231">[231]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06217" title="Abstract">arXiv:2311.06217</a> [<a href="/pdf/2311.06217" title="Download PDF">pdf</a>, <a href="/format/2311.06217" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MultiIoT: Towards Large-scale Multisensory Learning for the Internet of  Things
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mo%2C+S">Shentong Mo</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+P+P">Paul Pu Liang</a>, 
<a href="/search/cs?searchtype=author&query=Salakhutdinov%2C+R">Russ Salakhutdinov</a>, 
<a href="/search/cs?searchtype=author&query=Morency%2C+L">Louis-Philippe Morency</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Computer Vision and Pattern Recognition (cs.CV); Multimedia (cs.MM)

</div>
<p class="mathjax">The Internet of Things (IoT), the network integrating billions of smart
physical devices embedded with sensors, software, and communication
technologies for the purpose of connecting and exchanging data with other
devices and systems, is a critical and rapidly expanding component of our
modern world. The IoT ecosystem provides a rich source of real-world modalities
such as motion, thermal, geolocation, imaging, depth, sensors, video, and audio
for prediction tasks involving the pose, gaze, activities, and gestures of
humans as well as the touch, contact, pose, 3D of physical objects. Machine
learning presents a rich opportunity to automatically process IoT data at
scale, enabling efficient inference for impact in understanding human
wellbeing, controlling physical devices, and interconnecting smart cities. To
develop machine learning technologies for IoT, this paper proposes MultiIoT,
the most expansive IoT benchmark to date, encompassing over 1.15 million
samples from 12 modalities and 8 tasks. MultiIoT introduces unique challenges
involving (1) learning from many sensory modalities, (2) fine-grained
interactions across long temporal ranges, and (3) extreme heterogeneity due to
unique structure and noise topologies in real-world sensors. We also release a
set of strong modeling baselines, spanning modality and task-specific methods
to multisensory and multitask models to encourage future research in
multisensory representation learning for IoT.
</p>
</div>
</dd>
<dt><a name="item232">[232]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06218" title="Abstract">arXiv:2311.06218</a> [<a href="/pdf/2311.06218" title="Download PDF">pdf</a>, <a href="/format/2311.06218" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Semantic-aware Video Representation for Few-shot Action Recognition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tang%2C+Y">Yutao Tang</a>, 
<a href="/search/cs?searchtype=author&query=Bejar%2C+B">Benjamin Bejar</a>, 
<a href="/search/cs?searchtype=author&query=Vidal%2C+R">Rene Vidal</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> WACV2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Recent work on action recognition leverages 3D features and textual
information to achieve state-of-the-art performance. However, most of the
current few-shot action recognition methods still rely on 2D frame-level
representations, often require additional components to model temporal
relations, and employ complex distance functions to achieve accurate alignment
of these representations. In addition, existing methods struggle to effectively
integrate textual semantics, some resorting to concatenation or addition of
textual and visual features, and some using text merely as an additional
supervision without truly achieving feature fusion and information transfer
from different modalities. In this work, we propose a simple yet effective
Semantic-Aware Few-Shot Action Recognition (SAFSAR) model to address these
issues. We show that directly leveraging a 3D feature extractor combined with
an effective feature-fusion scheme, and a simple cosine similarity for
classification can yield better performance without the need of extra
components for temporal modeling or complex distance functions. We introduce an
innovative scheme to encode the textual semantics into the video representation
which adaptively fuses features from text and video, and encourages the visual
encoder to extract more semantically consistent features. In this scheme,
SAFSAR achieves alignment and fusion in a compact way. Experiments on five
challenging few-shot action recognition benchmarks under various settings
demonstrate that the proposed SAFSAR model significantly improves the
state-of-the-art performance.
</p>
</div>
</dd>
<dt><a name="item233">[233]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06221" title="Abstract">arXiv:2311.06221</a> [<a href="/pdf/2311.06221" title="Download PDF">pdf</a>, <a href="/format/2311.06221" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Comparison of Lexicon-Based and ML-Based Sentiment Analysis: Are There  Outlier Words?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mahajani%2C+S+J">Siddhant Jaydeep Mahajani</a>, 
<a href="/search/cs?searchtype=author&query=Srivastava%2C+S">Shashank Srivastava</a>, 
<a href="/search/cs?searchtype=author&query=Smeaton%2C+A+F">Alan F. Smeaton</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 4 pages, to appear in Proceedings of the 31st Irish Conference on Artificial Intelligence and Cognitive Science. December 7th-8th, 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Lexicon-based approaches to sentiment analysis of text are based on each word
or lexical entry having a pre-defined weight indicating its sentiment polarity.
These are usually manually assigned but the accuracy of these when compared
against machine leaning based approaches to computing sentiment, are not known.
It may be that there are lexical entries whose sentiment values cause a
lexicon-based approach to give results which are very different to a machine
learning approach. In this paper we compute sentiment for more than 150,000
English language texts drawn from 4 domains using the Hedonometer, a
lexicon-based technique and Azure, a contemporary machine-learning based
approach which is part of the Azure Cognitive Services family of APIs which is
easy to use. We model differences in sentiment scores between approaches for
documents in each domain using a regression and analyse the independent
variables (Hedonometer lexical entries) as indicators of each word's importance
and contribution to the score differences. Our findings are that the importance
of a word depends on the domain and there are no standout lexical entries which
systematically cause differences in sentiment scores.
</p>
</div>
</dd>
<dt><a name="item234">[234]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06222" title="Abstract">arXiv:2311.06222</a> [<a href="/pdf/2311.06222" title="Download PDF">pdf</a>, <a href="/format/2311.06222" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Diffusion Models for Earth Observation Use-cases: from cloud removal to  urban change detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sanguigni%2C+F">Fulvio Sanguigni</a>, 
<a href="/search/cs?searchtype=author&query=Czerkawski%2C+M">Mikolaj Czerkawski</a>, 
<a href="/search/cs?searchtype=author&query=Papa%2C+L">Lorenzo Papa</a>, 
<a href="/search/cs?searchtype=author&query=Amerini%2C+I">Irene Amerini</a>, 
<a href="/search/cs?searchtype=author&query=Saux%2C+B+L">Bertrand Le Saux</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Presented at Big Data from Space 2023 (BiDS)
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Proceedings of the 2023 conference on Big Data from Space, Soille,
  P., Lumnitz, S. and Albani, S. editor(s), Publications Office of the European
  Union, Luxembourg, 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">The advancements in the state of the art of generative Artificial
Intelligence (AI) brought by diffusion models can be highly beneficial in novel
contexts involving Earth observation data. After introducing this new family of
generative models, this work proposes and analyses three use cases which
demonstrate the potential of diffusion-based approaches for satellite image
data. Namely, we tackle cloud removal and inpainting, dataset generation for
change-detection tasks, and urban replanning.
</p>
</div>
</dd>
<dt><a name="item235">[235]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06224" title="Abstract">arXiv:2311.06224</a> [<a href="/pdf/2311.06224" title="Download PDF">pdf</a>, <a href="/format/2311.06224" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Harnessing Synthetic Datasets: The Role of Shape Bias in Deep Neural  Network Generalization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Benarous%2C+E">Elior Benarous</a>, 
<a href="/search/cs?searchtype=author&query=Anagnostidis%2C+S">Sotiris Anagnostidis</a>, 
<a href="/search/cs?searchtype=author&query=Biggio%2C+L">Luca Biggio</a>, 
<a href="/search/cs?searchtype=author&query=Hofmann%2C+T">Thomas Hofmann</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Recent advancements in deep learning have been primarily driven by the use of
large models trained on increasingly vast datasets. While neural scaling laws
have emerged to predict network performance given a specific level of
computational resources, the growing demand for expansive datasets raises
concerns. To address this, a new research direction has emerged, focusing on
the creation of synthetic data as a substitute. In this study, we investigate
how neural networks exhibit shape bias during training on synthetic datasets,
serving as an indicator of the synthetic data quality. Specifically, our
findings indicate three key points: (1) Shape bias varies across network
architectures and types of supervision, casting doubt on its reliability as a
predictor for generalization and its ability to explain differences in model
recognition compared to human capabilities. (2) Relying solely on shape bias to
estimate generalization is unreliable, as it is entangled with diversity and
naturalism. (3) We propose a novel interpretation of shape bias as a tool for
estimating the diversity of samples within a dataset. Our research aims to
clarify the implications of using synthetic data and its associated shape bias
in deep learning, addressing concerns regarding generalization and dataset
quality.
</p>
</div>
</dd>
<dt><a name="item236">[236]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06226" title="Abstract">arXiv:2311.06226</a> [<a href="/pdf/2311.06226" title="Download PDF">pdf</a>, <a href="/format/2311.06226" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MaDEVIoT: Cyberattacks on EV Charging Can Disrupt Power Grid Operation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Acharya%2C+S">Samrat Acharya</a>, 
<a href="/search/eess?searchtype=author&query=Khan%2C+H+A+U">Hafiz Anwar Ullah Khan</a>, 
<a href="/search/eess?searchtype=author&query=Karri%2C+R">Ramesh Karri</a>, 
<a href="/search/eess?searchtype=author&query=Dvorkin%2C+Y">Yury Dvorkin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This paper is accepted for publication in the proceeding of IEEE ISGT NA 2024 in Washington DC, USA
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">This paper examines the feasibility of demand-side cyberattacks on power
grids launched via internet-connected high-power EV Charging Stations (EVCSs).
By distorting power grid frequency and voltage, these attacks can trigger
system-wide outages. Our case study focuses on Manhattan, New York, and reveals
that such attacks will become feasible by 2030 with increased EV adoption. With
a single EVCS company dominating Manhattan, compromising a single EVCS server
raises serious power grid security concerns. These attacks can overload power
lines and trip over-frequency (OF) protection relays, resulting in a power grid
blackout. This study serves as a crucial resource for planning authorities and
power grid operators involved in the EV charging infrastructure roll-out,
highlighting potential cyberthreats to power grids stemming from high-power
EVCSs.
</p>
</div>
</dd>
<dt><a name="item237">[237]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06227" title="Abstract">arXiv:2311.06227</a> [<a href="/pdf/2311.06227" title="Download PDF">pdf</a>, <a href="/format/2311.06227" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Does Differential Privacy Prevent Backdoor Attacks in Practice?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Razmi%2C+F">Fereshteh Razmi</a>, 
<a href="/search/cs?searchtype=author&query=Lou%2C+J">Jian Lou</a>, 
<a href="/search/cs?searchtype=author&query=Xiong%2C+L">Li Xiong</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Differential Privacy (DP) was originally developed to protect privacy.
However, it has recently been utilized to secure machine learning (ML) models
from poisoning attacks, with DP-SGD receiving substantial attention.
Nevertheless, a thorough investigation is required to assess the effectiveness
of different DP techniques in preventing backdoor attacks in practice. In this
paper, we investigate the effectiveness of DP-SGD and, for the first time in
literature, examine PATE in the context of backdoor attacks. We also explore
the role of different components of DP algorithms in defending against backdoor
attacks and will show that PATE is effective against these attacks due to the
bagging structure of the teacher models it employs. Our experiments reveal that
hyperparameters and the number of backdoors in the training dataset impact the
success of DP algorithms. Additionally, we propose Label-DP as a faster and
more accurate alternative to DP-SGD and PATE. We conclude that while Label-DP
algorithms generally offer weaker privacy protection, accurate hyper-parameter
tuning can make them more effective than DP methods in defending against
backdoor attacks while maintaining model accuracy.
</p>
</div>
</dd>
<dt><a name="item238">[238]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06228" title="Abstract">arXiv:2311.06228</a> [<a href="/pdf/2311.06228" title="Download PDF">pdf</a>, <a href="/ps/2311.06228" title="Download PostScript">ps</a>, <a href="/format/2311.06228" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning material synthesis-structure-property relationship by data  fusion: Bayesian Co-regionalization N-Dimensional Piecewise Function Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kusne%2C+A+G">A. Gilad Kusne</a>, 
<a href="/search/cs?searchtype=author&query=McDannald%2C+A">Austin McDannald</a>, 
<a href="/search/cs?searchtype=author&query=DeCost%2C+B">Brian DeCost</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Materials Science (cond-mat.mtrl-sci)

</div>
<p class="mathjax">Advanced materials are needed to further next-generation technologies such as
quantum computing, carbon capture, and low-cost medical imaging. However,
advanced materials discovery is confounded by two fundamental challenges: the
challenge of a high-dimensional, complex materials search space and the
challenge of combining knowledge, i.e., data fusion across instruments and
labs. To overcome the first challenge, researchers employ knowledge of the
underlying material synthesis-structure-property relationship, as a material's
structure is often predictive of its functional property and vice versa. For
example, optimal materials often occur along composition-phase boundaries or
within specific phase regions. Additionally, knowledge of the
synthesis-structure-property relationship is fundamental to understanding
underlying physical mechanisms. However, quantifying the
synthesis-structure-property relationship requires overcoming the second
challenge. Researchers must merge knowledge gathered across instruments,
measurement modalities, and even laboratories. We present the
Synthesis-structure-property relAtionship coreGionalized lEarner (SAGE)
algorithm. A fully Bayesian algorithm that uses multimodal coregionalization to
merge knowledge across data sources to learn synthesis-structure-property
relationships.
</p>
</div>
</dd>
<dt><a name="item239">[239]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06231" title="Abstract">arXiv:2311.06231</a> [<a href="/pdf/2311.06231" title="Download PDF">pdf</a>, <a href="/format/2311.06231" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning Human Action Recognition Representations Without Real Humans
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhong%2C+H">Howard Zhong</a>, 
<a href="/search/cs?searchtype=author&query=Mishra%2C+S">Samarth Mishra</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+D">Donghyun Kim</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+S">SouYoung Jin</a>, 
<a href="/search/cs?searchtype=author&query=Panda%2C+R">Rameswar Panda</a>, 
<a href="/search/cs?searchtype=author&query=Kuehne%2C+H">Hilde Kuehne</a>, 
<a href="/search/cs?searchtype=author&query=Karlinsky%2C+L">Leonid Karlinsky</a>, 
<a href="/search/cs?searchtype=author&query=Saligrama%2C+V">Venkatesh Saligrama</a>, 
<a href="/search/cs?searchtype=author&query=Oliva%2C+A">Aude Oliva</a>, 
<a href="/search/cs?searchtype=author&query=Feris%2C+R">Rogerio Feris</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 19 pages, 7 figures, 2023 NeurIPS Datasets and Benchmarks Track
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Pre-training on massive video datasets has become essential to achieve high
action recognition performance on smaller downstream datasets. However, most
large-scale video datasets contain images of people and hence are accompanied
with issues related to privacy, ethics, and data protection, often preventing
them from being publicly shared for reproducible research. Existing work has
attempted to alleviate these problems by blurring faces, downsampling videos,
or training on synthetic data. On the other hand, analysis on the
transferability of privacy-preserving pre-trained models to downstream tasks
has been limited. In this work, we study this problem by first asking the
question: can we pre-train models for human action recognition with data that
does not include real humans? To this end, we present, for the first time, a
benchmark that leverages real-world videos with humans removed and synthetic
data containing virtual humans to pre-train a model. We then evaluate the
transferability of the representation learned on this data to a diverse set of
downstream action recognition benchmarks. Furthermore, we propose a novel
pre-training strategy, called Privacy-Preserving MAE-Align, to effectively
combine synthetic data and human-removed real data. Our approach outperforms
previous baselines by up to 5% and closes the performance gap between human and
no-human action recognition representations on downstream tasks, for both
linear probing and fine-tuning. Our benchmark, code, and models are available
at https://github.com/howardzh01/PPMA .
</p>
</div>
</dd>
<dt><a name="item240">[240]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06232" title="Abstract">arXiv:2311.06232</a> [<a href="/pdf/2311.06232" title="Download PDF">pdf</a>, <a href="/ps/2311.06232" title="Download PostScript">ps</a>, <a href="/format/2311.06232" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Better Sparsifiers for Directed Eulerian Graphs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sachdeva%2C+S">Sushant Sachdeva</a>, 
<a href="/search/cs?searchtype=author&query=Thudi%2C+A">Anvith Thudi</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Y">Yibin Zhao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>

</div>
<p class="mathjax">Spectral sparsification for directed Eulerian graphs is a key component in
the design of fast algorithms for solving directed Laplacian linear systems.
Directed Laplacian linear system solvers are crucial algorithmic primitives to
fast computation of fundamental problems on random walks, such as computing
stationary distribution, hitting and commute time, and personalized PageRank
vectors. While spectral sparsification is well understood for undirected graphs
and it is known that for every graph $G,$ $(1+\varepsilon)$-sparsifiers with
$O(n\varepsilon^{-2})$ edges exist [Batson-Spielman-Srivastava, STOC '09]
(which is optimal), the best known constructions of Eulerian sparsifiers
require $\Omega(n\varepsilon^{-2}\log^4 n)$ edges and are based on short-cycle
decompositions [Chu et al., FOCS '18].
<br />In this paper, we give improved constructions of Eulerian sparsifiers,
specifically:
<br />1. We show that for every directed Eulerian graph $\vec{G},$ there exist an
Eulerian sparsifier with $O(n\varepsilon^{-2} \log^2 n \log^2\log n +
n\varepsilon^{-4/3}\log^{8/3} n)$ edges. This result is based on combining
short-cycle decompositions [Chu-Gao-Peng-Sachdeva-Sawlani-Wang, FOCS '18,
SICOMP] and [Parter-Yogev, ICALP '19], with recent progress on the matrix
Spencer conjecture [Bansal-Meka-Jiang, STOC '23].
<br />2. We give an improved analysis of the constructions based on short-cycle
decompositions, giving an $m^{1+\delta}$-time algorithm for any constant
$\delta &gt; 0$ for constructing Eulerian sparsifiers with
$O(n\varepsilon^{-2}\log^3 n)$ edges.
</p>
</div>
</dd>
<dt><a name="item241">[241]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06233" title="Abstract">arXiv:2311.06233</a> [<a href="/pdf/2311.06233" title="Download PDF">pdf</a>, <a href="/format/2311.06233" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Data Contamination Quiz: A Tool to Detect and Estimate Contamination in  Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Golchin%2C+S">Shahriar Golchin</a>, 
<a href="/search/cs?searchtype=author&query=Surdeanu%2C+M">Mihai Surdeanu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> v1 preprint
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">We propose the Data Contamination Quiz, a simple and effective approach to
detect data contamination in large language models (LLMs) and estimate the
amount of it. Specifically, we frame data contamination detection as a series
of multiple-choice questions. We devise a quiz format wherein three perturbed
versions of each dataset instance are created. These changes only include
word-level perturbations, replacing words with their contextual synonyms,
ensuring both the semantic and sentence structure remain exactly the same as
the original instance. Together with the original instance, these perturbed
versions constitute the choices in the quiz. Given that the only distinguishing
signal among these choices is the exact wording, an LLM, when tasked with
identifying the original instance from the choices, opts for the original if it
has memorized it in its pre-training phase--a trait intrinsic to LLMs. A
dataset partition is then marked as contaminated if the LLM's performance on
the quiz surpasses what random chance suggests. Our evaluation spans seven
datasets and their respective splits (train and test/validation) on two
state-of-the-art LLMs: GPT-4 and GPT-3.5. While lacking access to the
pre-training data, our results suggest that our approach not only enhances the
detection of data contamination but also provides an accurate estimation of its
extent, even when the contamination signal is weak.
</p>
</div>
</dd>
<dt><a name="item242">[242]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06234" title="Abstract">arXiv:2311.06234</a> [<a href="/pdf/2311.06234" title="Download PDF">pdf</a>, <a href="/format/2311.06234" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> EVORA: Deep Evidential Traversability Learning for Risk-Aware Off-Road  Autonomy
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cai%2C+X">Xiaoyi Cai</a>, 
<a href="/search/cs?searchtype=author&query=Ancha%2C+S">Siddharth Ancha</a>, 
<a href="/search/cs?searchtype=author&query=Sharma%2C+L">Lakshay Sharma</a>, 
<a href="/search/cs?searchtype=author&query=Osteen%2C+P+R">Philip R. Osteen</a>, 
<a href="/search/cs?searchtype=author&query=Bucher%2C+B">Bernadette Bucher</a>, 
<a href="/search/cs?searchtype=author&query=Phillips%2C+S">Stephen Phillips</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jiuguang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Everett%2C+M">Michael Everett</a>, 
<a href="/search/cs?searchtype=author&query=Roy%2C+N">Nicholas Roy</a>, 
<a href="/search/cs?searchtype=author&query=How%2C+J+P">Jonathan P. How</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Under review. Journal extension for <a href="/abs/2210.00153">arXiv:2210.00153</a>. Project website: <a href="https://xiaoyi-cai.github.io/evora/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Machine Learning (cs.LG); Systems and Control (eess.SY)

</div>
<p class="mathjax">Traversing terrain with good traction is crucial for achieving fast off-road
navigation. Instead of manually designing costs based on terrain features,
existing methods learn terrain properties directly from data via
self-supervision, but challenges remain to properly quantify and mitigate risks
due to uncertainties in learned models. This work efficiently quantifies both
aleatoric and epistemic uncertainties by learning discrete traction
distributions and probability densities of the traction predictor's latent
features. Leveraging evidential deep learning, we parameterize Dirichlet
distributions with the network outputs and propose a novel uncertainty-aware
squared Earth Mover's distance loss with a closed-form expression that improves
learning accuracy and navigation performance. The proposed risk-aware planner
simulates state trajectories with the worst-case expected traction to handle
aleatoric uncertainty, and penalizes trajectories moving through terrain with
high epistemic uncertainty. Our approach is extensively validated in simulation
and on wheeled and quadruped robots, showing improved navigation performance
compared to methods that assume no slip, assume the expected traction, or
optimize for the worst-case expected cost.
</p>
</div>
</dd>
<dt><a name="item243">[243]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06236" title="Abstract">arXiv:2311.06236</a> [<a href="/pdf/2311.06236" title="Download PDF">pdf</a>, <a href="/ps/2311.06236" title="Download PostScript">ps</a>, <a href="/format/2311.06236" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deep Learning meets Blockchain for Automated and Secure Access Control
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Akbarfam%2C+A+J">Asma Jodeiri Akbarfam</a>, 
<a href="/search/cs?searchtype=author&query=Barazandeh%2C+S">Sina Barazandeh</a>, 
<a href="/search/cs?searchtype=author&query=Gupta%2C+D">Deepti Gupta</a>, 
<a href="/search/cs?searchtype=author&query=Maleki%2C+H">Hoda Maleki</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: text overlap with <a href="/abs/2303.14758">arXiv:2303.14758</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> International Journal of Security, Privacy and Trust Management
  (IJSPTM) Vol 12, No 3/4, November 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">Access control is a critical component of computer security, governing access
to system resources. However, designing policies and roles in traditional
access control can be challenging and difficult to maintain in dynamic and
complex systems, which is particularly problematic for organizations with
numerous resources. Furthermore, traditional methods suffer from issues such as
third-party involvement, inefficiency, and privacy gaps, making transparent and
dynamic access control an ongoing research problem. Moreover detecting
malicious activities and identifying users who are not behaving appropriately
can present notable difficulties. To address these challenges, we propose
DLACB, a Deep Learning Based Access Control Using Blockchain, as a solution to
decentralized access control. DLACB uses blockchain to provide transparency,
traceability, and reliability in various domains such as medicine, finance, and
government while taking advantage of deep learning to not rely on predefined
policies and eventually automate access control. With the integration of
blockchain and deep learning for access control, DLACB can provide a general
framework applicable to various domains, enabling transparent and reliable
logging of all transactions. As all data is recorded on the blockchain, we have
the capability to identify malicious activities. We store a list of malicious
activities in the storage system and employ a verification algorithm to
cross-reference it with the blockchain. We conduct measurements and comparisons
of the smart contract processing time for the deployed access control system in
contrast to traditional access control methods, determining the time overhead
involved. The processing time of DLBAC demonstrates remarkable stability when
exposed to increased request volumes.
</p>
</div>
</dd>
<dt><a name="item244">[244]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06237" title="Abstract">arXiv:2311.06237</a> [<a href="/pdf/2311.06237" title="Download PDF">pdf</a>, <a href="/format/2311.06237" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Summon a Demon and Bind it: A Grounded Theory of LLM Red Teaming in the  Wild
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Inie%2C+N">Nanna Inie</a>, 
<a href="/search/cs?searchtype=author&query=Stray%2C+J">Jonathan Stray</a>, 
<a href="/search/cs?searchtype=author&query=Derczynski%2C+L">Leon Derczynski</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Cryptography and Security (cs.CR); Human-Computer Interaction (cs.HC)

</div>
<p class="mathjax">Engaging in the deliberate generation of abnormal outputs from large language
models (LLMs) by attacking them is a novel human activity. This paper presents
a thorough exposition of how and why people perform such attacks. Using a
formal qualitative methodology, we interviewed dozens of practitioners from a
broad range of backgrounds, all contributors to this novel work of attempting
to cause LLMs to fail. We relate and connect this activity between its
practitioners' motivations and goals; the strategies and techniques they
deploy; and the crucial role the community plays. As a result, this paper
presents a grounded theory of how and why people attack large language models:
LLM red teaming in the wild.
</p>
</div>
</dd>
<dt><a name="item245">[245]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06239" title="Abstract">arXiv:2311.06239</a> [<a href="/pdf/2311.06239" title="Download PDF">pdf</a>, <a href="/format/2311.06239" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Argumentation Element Annotation Modeling using XLNet
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ormerod%2C+C">Christopher Ormerod</a>, 
<a href="/search/cs?searchtype=author&query=Burkhardt%2C+A">Amy Burkhardt</a>, 
<a href="/search/cs?searchtype=author&query=Young%2C+M">Mackenzie Young</a>, 
<a href="/search/cs?searchtype=author&query=Lottridge%2C+S">Sue Lottridge</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 28 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">This study demonstrates the effectiveness of XLNet, a transformer-based
language model, for annotating argumentative elements in persuasive essays.
XLNet's architecture incorporates a recurrent mechanism that allows it to model
long-term dependencies in lengthy texts. Fine-tuned XLNet models were applied
to three datasets annotated with different schemes - a proprietary dataset
using the Annotations for Revisions and Reflections on Writing (ARROW) scheme,
the PERSUADE corpus, and the Argument Annotated Essays (AAE) dataset. The XLNet
models achieved strong performance across all datasets, even surpassing human
agreement levels in some cases. This shows XLNet capably handles diverse
annotation schemes and lengthy essays. Comparisons between the model outputs on
different datasets also revealed insights into the relationships between the
annotation tags. Overall, XLNet's strong performance on modeling argumentative
structures across diverse datasets highlights its suitability for providing
automated feedback on essay organization.
</p>
</div>
</dd>
<dt><a name="item246">[246]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06241" title="Abstract">arXiv:2311.06241</a> [<a href="/pdf/2311.06241" title="Download PDF">pdf</a>, <a href="/format/2311.06241" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Nonnegativity Problems for Matrix Semigroups
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=D%27Costa%2C+J">Julian D&#x27;Costa</a>, 
<a href="/search/cs?searchtype=author&query=Ouaknine%2C+J">Joel Ouaknine</a>, 
<a href="/search/cs?searchtype=author&query=Worrell%2C+J">James Worrell</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>

</div>
<p class="mathjax">The matrix semigroup membership problem asks, given square matrices
$M,M_1,\ldots,M_k$ of the same dimension, whether $M$ lies in the semigroup
generated by $M_1,\ldots,M_k$. It is classical that this problem is undecidable
in general but decidable in case $M_1,\ldots,M_k$ commute. In this paper we
consider the problem of whether, given $M_1,\ldots,M_k$, the semigroup
generated by $M_1,\ldots,M_k$ contains a non-negative matrix. We show that in
case $M_1,\ldots,M_k$ commute, this problem is decidable subject to Schanuel's
Conjecture. We show also that the problem is undecidable if the commutativity
assumption is dropped. A key lemma in our decidability result is a procedure to
determine, given a matrix $M$, whether the sequence of matrices $(M^n)_{n\geq
0}$ is ultimately nonnegative. This answers a problem posed by S. Akshay
(<a href="/abs/2205.09190">arXiv:2205.09190</a>). The latter result is in stark contrast to the notorious
fact that it is not known how to determine effectively whether for any specific
matrix index $(i,j)$ the sequence $(M^n)_{i,j}$ is ultimately nonnegative
(which is a formulation of the Ultimate Positivity Problem for linear
recurrence sequences).
</p>
</div>
</dd>
<dt><a name="item247">[247]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06242" title="Abstract">arXiv:2311.06242</a> [<a href="/pdf/2311.06242" title="Download PDF">pdf</a>, <a href="/format/2311.06242" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Florence-2: Advancing a Unified Representation for a Variety of Vision  Tasks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xiao%2C+B">Bin Xiao</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+H">Haiping Wu</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+W">Weijian Xu</a>, 
<a href="/search/cs?searchtype=author&query=Dai%2C+X">Xiyang Dai</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+H">Houdong Hu</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+Y">Yumao Lu</a>, 
<a href="/search/cs?searchtype=author&query=Zeng%2C+M">Michael Zeng</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+C">Ce Liu</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+L">Lu Yuan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">We introduce Florence-2, a novel vision foundation model with a unified,
prompt-based representation for a variety of computer vision and
vision-language tasks. While existing large vision models excel in transfer
learning, they struggle to perform a diversity of tasks with simple
instructions, a capability that implies handling the complexity of various
spatial hierarchy and semantic granularity. Florence-2 was designed to take
text-prompt as task instructions and generate desirable results in text forms,
whether it be captioning, object detection, grounding or segmentation. This
multi-task learning setup demands large-scale, high-quality annotated data. To
this end, we co-developed FLD-5B that consists of 5.4 billion comprehensive
visual annotations on 126 million images, using an iterative strategy of
automated image annotation and model refinement. We adopted a
sequence-to-sequence structure to train Florence-2 to perform versatile and
comprehensive vision tasks. Extensive evaluations on numerous tasks
demonstrated Florence-2 to be a strong vision foundation model contender with
unprecedented zero-shot and fine-tuning capabilities.
</p>
</div>
</dd>
<dt><a name="item248">[248]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06243" title="Abstract">arXiv:2311.06243</a> [<a href="/pdf/2311.06243" title="Download PDF">pdf</a>, <a href="/format/2311.06243" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Parameter-Efficient Orthogonal Finetuning via Butterfly Factorization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+W">Weiyang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Qiu%2C+Z">Zeju Qiu</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+Y">Yao Feng</a>, 
<a href="/search/cs?searchtype=author&query=Xiu%2C+Y">Yuliang Xiu</a>, 
<a href="/search/cs?searchtype=author&query=Xue%2C+Y">Yuxuan Xue</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+L">Longhui Yu</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+H">Haiwen Feng</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zhen Liu</a>, 
<a href="/search/cs?searchtype=author&query=Heo%2C+J">Juyeon Heo</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+S">Songyou Peng</a>, 
<a href="/search/cs?searchtype=author&query=Wen%2C+Y">Yandong Wen</a>, 
<a href="/search/cs?searchtype=author&query=Black%2C+M+J">Michael J. Black</a>, 
<a href="/search/cs?searchtype=author&query=Weller%2C+A">Adrian Weller</a>, 
<a href="/search/cs?searchtype=author&query=Sch%C3%B6lkopf%2C+B">Bernhard Sch&#xf6;lkopf</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Technical Report (33 pages, 18 figures)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Large foundation models are becoming ubiquitous, but training them from
scratch is prohibitively expensive. Thus, efficiently adapting these powerful
models to downstream tasks is increasingly important. In this paper, we study a
principled finetuning paradigm -- Orthogonal Finetuning (OFT) -- for downstream
task adaptation. Despite demonstrating good generalizability, OFT still uses a
fairly large number of trainable parameters due to the high dimensionality of
orthogonal matrices. To address this, we start by examining OFT from an
information transmission perspective, and then identify a few key desiderata
that enable better parameter-efficiency. Inspired by how the Cooley-Tukey fast
Fourier transform algorithm enables efficient information transmission, we
propose an efficient orthogonal parameterization using butterfly structures. We
apply this parameterization to OFT, creating a novel parameter-efficient
finetuning method, called Orthogonal Butterfly (BOFT). By subsuming OFT as a
special case, BOFT introduces a generalized orthogonal finetuning framework.
Finally, we conduct an extensive empirical study of adapting large vision
transformers, large language models, and text-to-image diffusion models to
various downstream tasks in vision and language.
</p>
</div>
</dd>
</dl>
<h3>Cross-lists for Mon, 13 Nov 23</h3>
<dl>
<dt><a name="item249">[249]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05638" title="Abstract">arXiv:2311.05638</a> (cross-list from stat.ML) [<a href="/pdf/2311.05638" title="Download PDF">pdf</a>, <a href="/ps/2311.05638" title="Download PostScript">ps</a>, <a href="/format/2311.05638" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Instance-Optimality in Online PAC Reinforcement Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Al-Marjani%2C+A">Aymen Al-Marjani</a>, 
<a href="/search/stat?searchtype=author&query=Tirinzoni%2C+A">Andrea Tirinzoni</a>, 
<a href="/search/stat?searchtype=author&query=Kaufmann%2C+E">Emilie Kaufmann</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Several recent works have proposed instance-dependent upper bounds on the
number of episodes needed to identify, with probability $1-\delta$, an
$\varepsilon$-optimal policy in finite-horizon tabular Markov Decision
Processes (MDPs). These upper bounds feature various complexity measures for
the MDP, which are defined based on different notions of sub-optimality gaps.
However, as of now, no lower bound has been established to assess the
optimality of any of these complexity measures, except for the special case of
MDPs with deterministic transitions. In this paper, we propose the first
instance-dependent lower bound on the sample complexity required for the PAC
identification of a near-optimal policy in any tabular episodic MDP.
Additionally, we demonstrate that the sample complexity of the PEDEL algorithm
of \cite{Wagenmaker22linearMDP} closely approaches this lower bound.
Considering the intractability of PEDEL, we formulate an open question
regarding the possibility of achieving our lower bound using a
computationally-efficient algorithm.
</p>
</div>
</dd>
<dt><a name="item250">[250]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05641" title="Abstract">arXiv:2311.05641</a> (cross-list from stat.AP) [<a href="/pdf/2311.05641" title="Download PDF">pdf</a>, <a href="/format/2311.05641" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Mobile Internet Quality Estimation using Self-Tuning Kernel Regression
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Jiang%2C+H">Hanyang Jiang</a>, 
<a href="/search/stat?searchtype=author&query=Yuchi%2C+H+S">Henry Shaowu Yuchi</a>, 
<a href="/search/stat?searchtype=author&query=Belding%2C+E">Elizabeth Belding</a>, 
<a href="/search/stat?searchtype=author&query=Zegura%2C+E">Ellen Zegura</a>, 
<a href="/search/stat?searchtype=author&query=Xie%2C+Y">Yao Xie</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Applications (stat.AP)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Modeling and estimation for spatial data are ubiquitous in real life,
frequently appearing in weather forecasting, pollution detection, and
agriculture. Spatial data analysis often involves processing datasets of
enormous scale. In this work, we focus on large-scale internet-quality open
datasets from Ookla. We look into estimating mobile (cellular) internet quality
at the scale of a state in the United States. In particular, we aim to conduct
estimation based on highly {\it imbalanced} data: Most of the samples are
concentrated in limited areas, while very few are available in the rest, posing
significant challenges to modeling efforts. We propose a new adaptive kernel
regression approach that employs self-tuning kernels to alleviate the adverse
effects of data imbalance in this problem. Through comparative experimentation
on two distinct mobile network measurement datasets, we demonstrate that the
proposed self-tuning kernel regression method produces more accurate
predictions, with the potential to be applied in other applications.
</p>
</div>
</dd>
<dt><a name="item251">[251]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05644" title="Abstract">arXiv:2311.05644</a> (cross-list from math.OC) [<a href="/pdf/2311.05644" title="Download PDF">pdf</a>, <a href="/format/2311.05644" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the tractability of Nash equilibrium
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Avramopoulos%2C+I">Ioannis Avramopoulos</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Computer Science and Game Theory (cs.GT)

</div>
<p class="mathjax">In this paper, we propose a method for solving a PPAD-complete problem
[Papadimitriou, 1994]. Given is the payoff matrix $C$ of a symmetric bimatrix
game $(C, C^T)$ and our goal is to compute a Nash equilibrium of $(C, C^T)$. In
this paper, we devise a nonlinear replicator dynamic (whose right-hand-side can
be obtained by solving a pair of convex optimization problems) with the
following property: Under any invertible $0 \leq C \leq 1$, every orbit of our
dynamic starting at an interior strategy of the standard simplex approaches a
set of strategies of $(C, C^T)$ such that, for each strategy in this set, a
symmetric Nash equilibrium strategy can be computed by solving the
aforementioned convex mathematical programs. We prove convergence using
previous results in analysis (the analytic implicit function theorem),
nonlinear optimization theory (duality theory, Berge's maximum principle, and a
theorem of Robinson [1980] on the Lipschitz continuity of parametric nonlinear
programs), and dynamical systems theory (a theorem of Losert and Akin [1983]
related to the LaSalle invariance principle that is stronger under a stronger
assumption).
</p>
</div>
</dd>
<dt><a name="item252">[252]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05645" title="Abstract">arXiv:2311.05645</a> (cross-list from math.OC) [<a href="/pdf/2311.05645" title="Download PDF">pdf</a>, <a href="/format/2311.05645" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> EControl: Fast Distributed Optimization with Compression and Error  Control
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Gao%2C+Y">Yuan Gao</a>, 
<a href="/search/math?searchtype=author&query=Islamov%2C+R">Rustem Islamov</a>, 
<a href="/search/math?searchtype=author&query=Stich%2C+S">Sebastian Stich</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Machine Learning (cs.LG); Machine Learning (stat.ML)

</div>
<p class="mathjax">Modern distributed training relies heavily on communication compression to
reduce the communication overhead. In this work, we study algorithms employing
a popular class of contractive compressors in order to reduce communication
overhead. However, the naive implementation often leads to unstable convergence
or even exponential divergence due to the compression bias. Error Compensation
(EC) is an extremely popular mechanism to mitigate the aforementioned issues
during the training of models enhanced by contractive compression operators.
Compared to the effectiveness of EC in the data homogeneous regime, the
understanding of the practicality and theoretical foundations of EC in the data
heterogeneous regime is limited. Existing convergence analyses typically rely
on strong assumptions such as bounded gradients, bounded data heterogeneity, or
large batch accesses, which are often infeasible in modern machine learning
applications. We resolve the majority of current issues by proposing EControl,
a novel mechanism that can regulate error compensation by controlling the
strength of the feedback signal. We prove fast convergence for EControl in
standard strongly convex, general convex, and nonconvex settings without any
additional assumptions on the problem or data heterogeneity. We conduct
extensive numerical evaluations to illustrate the efficacy of our method and
support our theoretical findings.
</p>
</div>
</dd>
<dt><a name="item253">[253]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05650" title="Abstract">arXiv:2311.05650</a> (cross-list from math.OC) [<a href="/pdf/2311.05650" title="Download PDF">pdf</a>, <a href="/format/2311.05650" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning to Configure Separators in Branch-and-Cut
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Li%2C+S">Sirui Li</a>, 
<a href="/search/math?searchtype=author&query=Ouyang%2C+W">Wenbin Ouyang</a>, 
<a href="/search/math?searchtype=author&query=Paulus%2C+M+B">Max B. Paulus</a>, 
<a href="/search/math?searchtype=author&query=Wu%2C+C">Cathy Wu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Cutting planes are crucial in solving mixed integer linear programs (MILP) as
they facilitate bound improvements on the optimal solution. Modern MILP solvers
rely on a variety of separators to generate a diverse set of cutting planes by
invoking the separators frequently during the solving process. This work
identifies that MILP solvers can be drastically accelerated by appropriately
selecting separators to activate. As the combinatorial separator selection
space imposes challenges for machine learning, we learn to separate by
proposing a novel data-driven strategy to restrict the selection space and a
learning-guided algorithm on the restricted space. Our method predicts
instance-aware separator configurations which can dynamically adapt during the
solve, effectively accelerating the open source MILP solver SCIP by improving
the relative solve time up to 72% and 37% on synthetic and real-world MILP
benchmarks. Our work complements recent work on learning to select cutting
planes and highlights the importance of separator management.
</p>
</div>
</dd>
<dt><a name="item254">[254]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05668" title="Abstract">arXiv:2311.05668</a> (cross-list from q-bio.OT) [<a href="/pdf/2311.05668" title="Download PDF">pdf</a>, <a href="/ps/2311.05668" title="Download PostScript">ps</a>, <a href="/format/2311.05668" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Biological Data Sustainability Paradox
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-bio?searchtype=author&query=Johnson%2C+T+R">Terence R. Johnson</a>, 
<a href="/search/q-bio?searchtype=author&query=Bourne%2C+P+E">Philip E. Bourne</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages 5852 words 1 figure
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Other Quantitative Biology (q-bio.OT)</span>; Databases (cs.DB)

</div>
<p class="mathjax">Biological data in digital form has become a, if not the, driving force
behind innovations in biology, medicine, and the environment. No study and no
model would be complete without access to digital data (including text)
collected by others and available in public repositories. With this ascent in
the fundamental importance of data for reproducible scientific progress has
come a troubling paradox.
</p>
</div>
</dd>
<dt><a name="item255">[255]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05697" title="Abstract">arXiv:2311.05697</a> (cross-list from eess.IV) [<a href="/pdf/2311.05697" title="Download PDF">pdf</a>, <a href="/format/2311.05697" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> 3DGAUnet: 3D generative adversarial networks with a 3D U-Net based  generator to achieve the accurate and effective synthesis of clinical tumor  image data for pancreatic cancer
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Shi%2C+Y">Yu Shi</a>, 
<a href="/search/eess?searchtype=author&query=Tang%2C+H">Hannah Tang</a>, 
<a href="/search/eess?searchtype=author&query=Baine%2C+M">Michael Baine</a>, 
<a href="/search/eess?searchtype=author&query=Hollingsworth%2C+M+A">Michael A. Hollingsworth</a>, 
<a href="/search/eess?searchtype=author&query=Du%2C+H">Huijing Du</a>, 
<a href="/search/eess?searchtype=author&query=Zheng%2C+D">Dandan Zheng</a>, 
<a href="/search/eess?searchtype=author&query=Zhang%2C+C">Chi Zhang</a>, 
<a href="/search/eess?searchtype=author&query=Yu%2C+H">Hongfeng Yu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Pancreatic ductal adenocarcinoma (PDAC) presents a critical global health
challenge, and early detection is crucial for improving the 5-year survival
rate. Recent medical imaging and computational algorithm advances offer
potential solutions for early diagnosis. Deep learning, particularly in the
form of convolutional neural networks (CNNs), has demonstrated success in
medical image analysis tasks, including classification and segmentation.
However, the limited availability of clinical data for training purposes
continues to provide a significant obstacle. Data augmentation, generative
adversarial networks (GANs), and cross-validation are potential techniques to
address this limitation and improve model performance, but effective solutions
are still rare for 3D PDAC, where contrast is especially poor owing to the high
heterogeneity in both tumor and background tissues. In this study, we developed
a new GAN-based model, named 3DGAUnet, for generating realistic 3D CT images of
PDAC tumors and pancreatic tissue, which can generate the interslice connection
data that the existing 2D CT image synthesis models lack. Our innovation is to
develop a 3D U-Net architecture for the generator to improve shape and texture
learning for PDAC tumors and pancreatic tissue. Our approach offers a promising
path to tackle the urgent requirement for creative and synergistic methods to
combat PDAC. The development of this GAN-based model has the potential to
alleviate data scarcity issues, elevate the quality of synthesized data, and
thereby facilitate the progression of deep learning models to enhance the
accuracy and early detection of PDAC tumors, which could profoundly impact
patient outcomes. Furthermore, this model has the potential to be adapted to
other types of solid tumors, hence making significant contributions to the
field of medical imaging in terms of image processing models.
</p>
</div>
</dd>
<dt><a name="item256">[256]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05726" title="Abstract">arXiv:2311.05726</a> (cross-list from physics.ins-det) [<a href="/pdf/2311.05726" title="Download PDF">pdf</a>, <a href="/format/2311.05726" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Neural Network Methods for Radiation Detectors and Imaging
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Lin%2C+S">S. Lin</a>, 
<a href="/search/physics?searchtype=author&query=Ning%2C+S">S. Ning</a>, 
<a href="/search/physics?searchtype=author&query=Zhu%2C+H">H. Zhu</a>, 
<a href="/search/physics?searchtype=author&query=Zhou%2C+T">T. Zhou</a>, 
<a href="/search/physics?searchtype=author&query=Morris%2C+C+L">C. L. Morris</a>, 
<a href="/search/physics?searchtype=author&query=Clayton%2C+S">S. Clayton</a>, 
<a href="/search/physics?searchtype=author&query=Cherukara%2C+M">M. Cherukara</a>, 
<a href="/search/physics?searchtype=author&query=Chen%2C+R+T">R. T. Chen</a>, 
<a href="/search/physics?searchtype=author&query=Wang%2C+Z">Z. Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Instrumentation and Detectors (physics.ins-det)</span>; Machine Learning (cs.LG); Data Analysis, Statistics and Probability (physics.data-an)

</div>
<p class="mathjax">Recent advances in image data processing through machine learning and
especially deep neural networks (DNNs) allow for new optimization and
performance-enhancement schemes for radiation detectors and imaging hardware
through data-endowed artificial intelligence. We give an overview of data
generation at photon sources, deep learning-based methods for image processing
tasks, and hardware solutions for deep learning acceleration. Most existing
deep learning approaches are trained offline, typically using large amounts of
computational resources. However, once trained, DNNs can achieve fast inference
speeds and can be deployed to edge devices. A new trend is edge computing with
less energy consumption (hundreds of watts or less) and real-time analysis
potential. While popularly used for edge computing, electronic-based hardware
accelerators ranging from general purpose processors such as central processing
units (CPUs) to application-specific integrated circuits (ASICs) are constantly
reaching performance limits in latency, energy consumption, and other physical
constraints. These limits give rise to next-generation analog neuromorhpic
hardware platforms, such as optical neural networks (ONNs), for high parallel,
low latency, and low energy computing to boost deep learning acceleration.
</p>
</div>
</dd>
<dt><a name="item257">[257]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05742" title="Abstract">arXiv:2311.05742</a> (cross-list from stat.ML) [<a href="/pdf/2311.05742" title="Download PDF">pdf</a>, <a href="/format/2311.05742" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Optimal simulation-based Bayesian decisions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Alsing%2C+J">Justin Alsing</a>, 
<a href="/search/stat?searchtype=author&query=Edwards%2C+T+D+P">Thomas D. P. Edwards</a>, 
<a href="/search/stat?searchtype=author&query=Wandelt%2C+B">Benjamin Wandelt</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 4 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Instrumentation and Methods for Astrophysics (astro-ph.IM); Artificial Intelligence (cs.AI); Computer Science and Game Theory (cs.GT); Machine Learning (cs.LG)

</div>
<p class="mathjax">We present a framework for the efficient computation of optimal Bayesian
decisions under intractable likelihoods, by learning a surrogate model for the
expected utility (or its distribution) as a function of the action and data
spaces. We leverage recent advances in simulation-based inference and Bayesian
optimization to develop active learning schemes to choose where in parameter
and action spaces to simulate. This allows us to learn the optimal action in as
few simulations as possible. The resulting framework is extremely simulation
efficient, typically requiring fewer model calls than the associated posterior
inference task alone, and a factor of $100-1000$ more efficient than
Monte-Carlo based methods. Our framework opens up new capabilities for
performing Bayesian decision making, particularly in the previously challenging
regime where likelihoods are intractable, and simulations expensive.
</p>
</div>
</dd>
<dt><a name="item258">[258]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05776" title="Abstract">arXiv:2311.05776</a> (cross-list from eess.SP) [<a href="/pdf/2311.05776" title="Download PDF">pdf</a>, <a href="/format/2311.05776" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multi-fidelity Bayesian Optimisation of Syngas Fermentation Simulators
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Eskandari%2C+M">Mahdi Eskandari</a>, 
<a href="/search/eess?searchtype=author&query=Puiman%2C+L">Lars Puiman</a>, 
<a href="/search/eess?searchtype=author&query=Zeitler%2C+J">Jakob Zeitler</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Systems and Control (eess.SY)

</div>
<p class="mathjax">A Bayesian optimization approach for maximizing the gas conversion rate in an
industrial-scale bioreactor for syngas fermentation is presented. We have
access to a high-fidelity, computational fluid dynamic (CFD) reactor model and
a low-fidelity ideal-mixing-based reactor model. The goal is to maximize the
gas conversion rate, with respect to the input variables (e.g., pressure,
biomass concentration, gas flow rate). Due to the high cost of the CFD reactor
model, a multi-fidelity Bayesian optimization algorithm is adopted to solve the
optimization problem using both high and low fidelities. We first describe the
problem in the context of syngas fermentation followed by our approach to
solving simulator optimization using multiple fidelities. We discuss concerns
regarding significant differences in fidelity cost and their impact on fidelity
sampling and conclude with a discussion on the integration of real-world
fermentation data.
</p>
</div>
</dd>
<dt><a name="item259">[259]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05794" title="Abstract">arXiv:2311.05794</a> (cross-list from stat.ME) [<a href="/pdf/2311.05794" title="Download PDF">pdf</a>, <a href="/format/2311.05794" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An Experimental Design for Anytime-Valid Causal Inference on Multi-Armed  Bandits
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Liang%2C+B">Biyonka Liang</a>, 
<a href="/search/stat?searchtype=author&query=Bojinov%2C+I">Iavor Bojinov</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Methodology (stat.ME)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Typically, multi-armed bandit (MAB) experiments are analyzed at the end of
the study and thus require the analyst to specify a fixed sample size in
advance. However, in many online learning applications, it is advantageous to
continuously produce inference on the average treatment effect (ATE) between
arms as new data arrive and determine a data-driven stopping time for the
experiment. Existing work on continuous inference for adaptive experiments
assumes that the treatment assignment probabilities are bounded away from zero
and one, thus excluding nearly all standard bandit algorithms. In this work, we
develop the Mixture Adaptive Design (MAD), a new experimental design for
multi-armed bandits that enables continuous inference on the ATE with
guarantees on statistical validity and power for nearly any bandit algorithm.
On a high level, the MAD "mixes" a bandit algorithm of the user's choice with a
Bernoulli design through a tuning parameter $\delta_t$, where $\delta_t$ is a
deterministic sequence that controls the priority placed on the Bernoulli
design as the sample size grows. We show that for $\delta_t =
o\left(1/t^{1/4}\right)$, the MAD produces a confidence sequence that is
asymptotically valid and guaranteed to shrink around the true ATE. We
empirically show that the MAD improves the coverage and power of ATE inference
in MAB experiments without significant losses in finite-sample reward.
</p>
</div>
</dd>
<dt><a name="item260">[260]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05798" title="Abstract">arXiv:2311.05798</a> (cross-list from eess.IV) [<a href="/pdf/2311.05798" title="Download PDF">pdf</a>, <a href="/format/2311.05798" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Synthesizing Bidirectional Temporal States of Knee Osteoarthritis  Radiographs with Cycle-Consistent Generative Adversarial Neural Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Prezja%2C+F">Fabi Prezja</a>, 
<a href="/search/eess?searchtype=author&query=Annala%2C+L">Leevi Annala</a>, 
<a href="/search/eess?searchtype=author&query=Kiiskinen%2C+S">Sampsa Kiiskinen</a>, 
<a href="/search/eess?searchtype=author&query=Lahtinen%2C+S">Suvi Lahtinen</a>, 
<a href="/search/eess?searchtype=author&query=Ojala%2C+T">Timo Ojala</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 29 pages, 10 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
<p class="mathjax">Knee Osteoarthritis (KOA), a leading cause of disability worldwide, is
challenging to detect early due to subtle radiographic indicators. Diverse,
extensive datasets are needed but are challenging to compile because of
privacy, data collection limitations, and the progressive nature of KOA.
However, a model capable of projecting genuine radiographs into different OA
stages could augment data pools, enhance algorithm training, and offer
pre-emptive prognostic insights. In this study, we trained a CycleGAN model to
synthesize past and future stages of KOA on any genuine radiograph. The model
was validated using a Convolutional Neural Network that was deceived into
misclassifying disease stages in transformed images, demonstrating the
CycleGAN's ability to effectively transform disease characteristics forward or
backward in time. The model was particularly effective in synthesizing future
disease states and showed an exceptional ability to retroactively transition
late-stage radiographs to earlier stages by eliminating osteophytes and
expanding knee joint space, signature characteristics of None or Doubtful KOA.
The model's results signify a promising potential for enhancing diagnostic
models, data augmentation, and educational and prognostic usage in healthcare.
Nevertheless, further refinement, validation, and a broader evaluation process
encompassing both CNN-based assessments and expert medical feedback are
emphasized for future research and development.
</p>
</div>
</dd>
<dt><a name="item261">[261]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05799" title="Abstract">arXiv:2311.05799</a> (cross-list from eess.IV) [<a href="/pdf/2311.05799" title="Download PDF">pdf</a>, <a href="/format/2311.05799" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Adaptive Variance Thresholding: A Novel Approach to Improve Existing  Deep Transfer Vision Models and Advance Automatic Knee-Joint Osteoarthritis  Classification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Prezja%2C+F">Fabi Prezja</a>, 
<a href="/search/eess?searchtype=author&query=Annala%2C+L">Leevi Annala</a>, 
<a href="/search/eess?searchtype=author&query=Kiiskinen%2C+S">Sampsa Kiiskinen</a>, 
<a href="/search/eess?searchtype=author&query=Lahtinen%2C+S">Suvi Lahtinen</a>, 
<a href="/search/eess?searchtype=author&query=Ojala%2C+T">Timo Ojala</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 26 pages, 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
<p class="mathjax">Knee-Joint Osteoarthritis (KOA) is a prevalent cause of global disability and
is inherently complex to diagnose due to its subtle radiographic markers and
individualized progression. One promising classification avenue involves
applying deep learning methods; however, these techniques demand extensive,
diversified datasets, which pose substantial challenges due to medical data
collection restrictions. Existing practices typically resort to smaller
datasets and transfer learning. However, this approach often inherits
unnecessary pre-learned features that can clutter the classifier's vector
space, potentially hampering performance. This study proposes a novel paradigm
for improving post-training specialized classifiers by introducing adaptive
variance thresholding (AVT) followed by Neural Architecture Search (NAS). This
approach led to two key outcomes: an increase in the initial accuracy of the
pre-trained KOA models and a 60-fold reduction in the NAS input vector space,
thus facilitating faster inference speed and a more efficient hyperparameter
search. We also applied this approach to an external model trained for KOA
classification. Despite its initial performance, the application of our
methodology improved its average accuracy, making it one of the top three KOA
classification models.
</p>
</div>
</dd>
<dt><a name="item262">[262]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05813" title="Abstract">arXiv:2311.05813</a> (cross-list from math.OC) [<a href="/pdf/2311.05813" title="Download PDF">pdf</a>, <a href="/format/2311.05813" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Feasibility Analysis and Regularity Characterization of Distributionally  Robust Safe Stabilizing Controllers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Mestres%2C+P">Pol Mestres</a>, 
<a href="/search/math?searchtype=author&query=Long%2C+K">Kehan Long</a>, 
<a href="/search/math?searchtype=author&query=Atanasov%2C+N">Nikolay Atanasov</a>, 
<a href="/search/math?searchtype=author&query=Cort%C3%A9s%2C+J">Jorge Cort&#xe9;s</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Systems and Control (eess.SY)

</div>
<p class="mathjax">This paper studies the well-posedness and regularity of safe stabilizing
optimization-based controllers for control-affine systems in the presence of
model uncertainty. When the system dynamics contain unknown parameters, a
finite set of samples can be used to formulate distributionally robust versions
of control barrier function and control Lyapunov function constraints. Control
synthesis with such distributionally robust constraints can be achieved by
solving a (convex) second-order cone program (SOCP). We provide one necessary
and two sufficient conditions to check the feasibility of such optimization
problems, characterize their computational complexity and numerically show that
they are significantly faster to check than direct use of SOCP solvers.
Finally, we also analyze the regularity of the resulting control laws.
</p>
</div>
</dd>
<dt><a name="item263">[263]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05823" title="Abstract">arXiv:2311.05823</a> (cross-list from physics.soc-ph) [<a href="/pdf/2311.05823" title="Download PDF">pdf</a>, <a href="/format/2311.05823" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Recurrent Dynamic Message Passing with Loops for Epidemics on Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Gao%2C+F">Fei Gao</a>, 
<a href="/search/physics?searchtype=author&query=Liu%2C+J">Jing Liu</a>, 
<a href="/search/physics?searchtype=author&query=Zhan%2C+Y">Yaqian Zhan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Physics and Society (physics.soc-ph)</span>; Disordered Systems and Neural Networks (cond-mat.dis-nn); Social and Information Networks (cs.SI)

</div>
<p class="mathjax">Several theoretical methods have been developed to approximate prevalence and
threshold of epidemics on networks. Among them, the recurrent dynamic
message-passing (rDMP) theory offers a state-of-the-art performance by
preventing the echo chamber effect in network edges. However, the rDMP theory
was derived in an intuitive \textit{ad-hoc} way, lacking a solid theoretical
foundation and resulting in a probabilistic inconsistency flaw. Furthermore,
real-world networks are clustered and full of local loops like triangles,
whereas rDMP is based on the assumption of a locally tree-like network
structure, which makes rDMP potentially inefficient on real applications. In
this work, for the recurrent-state epidemics, we first demonstrate that the
echo chamber effect exits not only in edges but also in local loops, which
rDMP-like method can not avoid. We then correct the deficiency of rDMP in a
principled manner, leading to the natural introduction of new
\textit{higher-order} dynamic messages, extending rDMP to handle local loops.
By linearizing the extended message-passing equations, a new epidemic threshold
estimation is given by the inverse of the leading eigenvalue of a matrix named
\textit{triangular non-backtracking} matrix. Numerical experiments conducted on
synthetic and real-world networks to evaluate our method, the efficacy of which
is validated in epidemic prevalence and threshold prediction tasks. In
addition, our method has the potential to speed up the solution of the
immunization, influence maximization, and robustness optimization problems in
the networks.
</p>
</div>
</dd>
<dt><a name="item264">[264]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05836" title="Abstract">arXiv:2311.05836</a> (cross-list from eess.IV) [<a href="/pdf/2311.05836" title="Download PDF">pdf</a>, <a href="/format/2311.05836" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Uncertainty-aware Single View Volumetric Rendering for Medical Neural  Radiance Fields
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Hu%2C+J">Jing Hu</a>, 
<a href="/search/eess?searchtype=author&query=Fan%2C+Q">Qinrui Fan</a>, 
<a href="/search/eess?searchtype=author&query=Hu%2C+S">Shu Hu</a>, 
<a href="/search/eess?searchtype=author&query=Lyu%2C+S">Siwei Lyu</a>, 
<a href="/search/eess?searchtype=author&query=Wu%2C+X">Xi Wu</a>, 
<a href="/search/eess?searchtype=author&query=Wang%2C+X">Xin Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
<p class="mathjax">In the field of clinical medicine, computed tomography (CT) is an effective
medical imaging modality for the diagnosis of various pathologies. Compared
with X-ray images, CT images can provide more information, including
multi-planar slices and three-dimensional structures for clinical diagnosis.
However, CT imaging requires patients to be exposed to large doses of ionizing
radiation for a long time, which may cause irreversible physical harm. In this
paper, we propose an Uncertainty-aware MedNeRF (UMedNeRF) network based on
generated radiation fields. The network can learn a continuous representation
of CT projections from 2D X-ray images by obtaining the internal structure and
depth information and using adaptive loss weights to ensure the quality of the
generated images. Our model is trained on publicly available knee and chest
datasets, and we show the results of CT projection rendering with a single
X-ray and compare our method with other methods based on generated radiation
fields.
</p>
</div>
</dd>
<dt><a name="item265">[265]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05840" title="Abstract">arXiv:2311.05840</a> (cross-list from q-fin.ST) [<a href="/pdf/2311.05840" title="Download PDF">pdf</a>, <a href="/ps/2311.05840" title="Download PostScript">ps</a>, <a href="/format/2311.05840" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Predictive AI for SME and Large Enterprise Financial Performance  Management
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-fin?searchtype=author&query=Cuervo%2C+R">Ricardo Cuervo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages plus appendix. Thesis for MSc in AI at QMUL
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Statistical Finance (q-fin.ST)</span>; Artificial Intelligence (cs.AI); General Finance (q-fin.GN)

</div>
<p class="mathjax">Financial performance management is at the core of business management and
has historically relied on financial ratio analysis using Balance Sheet and
Income Statement data to assess company performance as compared with
competitors. Little progress has been made in predicting how a company will
perform or in assessing the risks (probabilities) of financial
underperformance. In this study I introduce a new set of financial and
macroeconomic ratios that supplement standard ratios of Balance Sheet and
Income Statement. I also provide a set of supervised learning models (ML
Regressors and Neural Networks) and Bayesian models to predict company
performance. I conclude that the new proposed variables improve model accuracy
when used in tandem with standard industry ratios. I also conclude that
Feedforward Neural Networks (FNN) are simpler to implement and perform best
across 6 predictive tasks (ROA, ROE, Net Margin, Op Margin, Cash Ratio and Op
Cash Generation); although Bayesian Networks (BN) can outperform FNN under very
specific conditions. BNs have the additional benefit of providing a probability
density function in addition to the predicted (expected) value. The study
findings have significant potential helping CFOs and CEOs assess risks of
financial underperformance to steer companies in more profitable directions;
supporting lenders in better assessing the condition of a company and providing
investors with tools to dissect financial statements of public companies more
accurately.
</p>
</div>
</dd>
<dt><a name="item266">[266]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05849" title="Abstract">arXiv:2311.05849</a> (cross-list from math.CT) [<a href="/pdf/2311.05849" title="Download PDF">pdf</a>, <a href="/format/2311.05849" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Strict Rezk completions of models of HoTT and homotopy canonicity
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Bocquet%2C+R">Rafa&#xeb;l Bocquet</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Category Theory (math.CT)</span>; Logic in Computer Science (cs.LO)

</div>
<p class="mathjax">We give a new constructive proof of homotopy canonicity for homotopy type
theory (HoTT). Canonicity proofs typically involve gluing constructions over
the syntax of type theory. We instead use a gluing construction over a "strict
Rezk completion" of the syntax of HoTT. The strict Rezk completion is specified
and constructed in the topos of cartesian cubical sets. It completes a model of
HoTT to an equivalent model satisfying a saturation condition, providing an
equivalence between terms of identity types and cubical paths between terms.
This generalizes the ordinary Rezk completion of a 1-category.
</p>
</div>
</dd>
<dt><a name="item267">[267]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05866" title="Abstract">arXiv:2311.05866</a> (cross-list from stat.ML) [<a href="/pdf/2311.05866" title="Download PDF">pdf</a>, <a href="/ps/2311.05866" title="Download PostScript">ps</a>, <a href="/format/2311.05866" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fair Supervised Learning with A Simple Random Sampler of Sensitive  Attributes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Sohn%2C+J">Jinwon Sohn</a>, 
<a href="/search/stat?searchtype=author&query=Song%2C+Q">Qifan Song</a>, 
<a href="/search/stat?searchtype=author&query=Lin%2C+G">Guang Lin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">As the data-driven decision process becomes dominating for industrial
applications, fairness-aware machine learning arouses great attention in
various areas. This work proposes fairness penalties learned by neural networks
with a simple random sampler of sensitive attributes for non-discriminatory
supervised learning. In contrast to many existing works that critically rely on
the discreteness of sensitive attributes and response variables, the proposed
penalty is able to handle versatile formats of the sensitive attributes, so it
is more extensively applicable in practice than many existing algorithms. This
penalty enables us to build a computationally efficient group-level
in-processing fairness-aware training framework. Empirical evidence shows that
our framework enjoys better utility and fairness measures on popular benchmark
data sets than competing methods. We also theoretically characterize estimation
errors and loss of utility of the proposed neural-penalized risk minimization
problem.
</p>
</div>
</dd>
<dt><a name="item268">[268]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05881" title="Abstract">arXiv:2311.05881</a> (cross-list from physics.app-ph) [<a href="/pdf/2311.05881" title="Download PDF">pdf</a>, <a href="/format/2311.05881" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Programmable Superconducting Optoelectronic Single-Photon Synapses with  Integrated Multi-State Memory
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Primavera%2C+B+A">Bryce A. Primavera</a>, 
<a href="/search/physics?searchtype=author&query=Khan%2C+S">Saeed Khan</a>, 
<a href="/search/physics?searchtype=author&query=Mirin%2C+R+P">Richard P. Mirin</a>, 
<a href="/search/physics?searchtype=author&query=Nam%2C+S+W">Sae Woo Nam</a>, 
<a href="/search/physics?searchtype=author&query=Shainline%2C+J+M">Jeffrey M. Shainline</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 pages, 11 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Applied Physics (physics.app-ph)</span>; Emerging Technologies (cs.ET); Neural and Evolutionary Computing (cs.NE)

</div>
<p class="mathjax">The co-location of memory and processing is a core principle of neuromorphic
computing. A local memory device for synaptic weight storage has long been
recognized as an enabling element for large-scale, high-performance
neuromorphic hardware. In this work, we demonstrate programmable
superconducting synapses with integrated memories for use in superconducting
optoelectronic neural systems. Superconducting nanowire single-photon detectors
and Josephson junctions are combined into programmable synaptic circuits that
exhibit single-photon sensitivity, memory cells with more than 400 internal
states, leaky integration of input spike events, and 0.4 fJ programming
energies (including cooling power). These results are attractive for
implementing a variety of supervised and unsupervised learning algorithms and
lay the foundation for a new hardware platform optimized for large-scale
spiking network accelerators.
</p>
</div>
</dd>
<dt><a name="item269">[269]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05889" title="Abstract">arXiv:2311.05889</a> (cross-list from eess.IV) [<a href="/pdf/2311.05889" title="Download PDF">pdf</a>, <a href="/format/2311.05889" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Semantic Map Guided Synthesis of Wireless Capsule Endoscopy Images using  Diffusion Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Lee%2C+H">Haejin Lee</a>, 
<a href="/search/eess?searchtype=author&query=Ju%2C+J">Jeongwoo Ju</a>, 
<a href="/search/eess?searchtype=author&query=Lee%2C+J">Jonghyuck Lee</a>, 
<a href="/search/eess?searchtype=author&query=Lee%2C+Y+J">Yeoun Joo Lee</a>, 
<a href="/search/eess?searchtype=author&query=Jung%2C+H">Heechul Jung</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
<p class="mathjax">Wireless capsule endoscopy (WCE) is a non-invasive method for visualizing the
gastrointestinal (GI) tract, crucial for diagnosing GI tract diseases. However,
interpreting WCE results can be time-consuming and tiring. Existing studies
have employed deep neural networks (DNNs) for automatic GI tract lesion
detection, but acquiring sufficient training examples, particularly due to
privacy concerns, remains a challenge. Public WCE databases lack diversity and
quantity. To address this, we propose a novel approach leveraging generative
models, specifically the diffusion model (DM), for generating diverse WCE
images. Our model incorporates semantic map resulted from visualization scale
(VS) engine, enhancing the controllability and diversity of generated images.
We evaluate our approach using visual inspection and visual Turing tests,
demonstrating its effectiveness in generating realistic and diverse WCE images.
</p>
</div>
</dd>
<dt><a name="item270">[270]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05961" title="Abstract">arXiv:2311.05961</a> (cross-list from math.DS) [<a href="/pdf/2311.05961" title="Download PDF">pdf</a>, <a href="/format/2311.05961" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Hierarchical deep learning-based adaptive time-stepping scheme for  multiscale simulations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Hamid%2C+A">Asif Hamid</a>, 
<a href="/search/math?searchtype=author&query=Rafiq%2C+D">Danish Rafiq</a>, 
<a href="/search/math?searchtype=author&query=Nahvi%2C+S+A">Shahkar Ahmad Nahvi</a>, 
<a href="/search/math?searchtype=author&query=Bazaz%2C+M+A">Mohammad Abid Bazaz</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Dynamical Systems (math.DS)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Multiscale is a hallmark feature of complex nonlinear systems. While the
simulation using the classical numerical methods is restricted by the local
\textit{Taylor} series constraints, the multiscale techniques are often limited
by finding heuristic closures. This study proposes a new method for simulating
multiscale problems using deep neural networks. By leveraging the hierarchical
learning of neural network time steppers, the method adapts time steps to
approximate dynamical system flow maps across timescales. This approach
achieves state-of-the-art performance in less computational time compared to
fixed-step neural network solvers. The proposed method is demonstrated on
several nonlinear dynamical systems, and source codes are provided for
implementation. This method has the potential to benefit multiscale analysis of
complex systems and encourage further investigation in this area.
</p>
</div>
</dd>
<dt><a name="item271">[271]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05967" title="Abstract">arXiv:2311.05967</a> (cross-list from physics.plasm-ph) [<a href="/pdf/2311.05967" title="Download PDF">pdf</a>, <a href="/format/2311.05967" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Plasma Surrogate Modelling using Fourier Neural Operators
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Gopakumar%2C+V">Vignesh Gopakumar</a>, 
<a href="/search/physics?searchtype=author&query=Pamela%2C+S">Stanislas Pamela</a>, 
<a href="/search/physics?searchtype=author&query=Zanisi%2C+L">Lorenzo Zanisi</a>, 
<a href="/search/physics?searchtype=author&query=Li%2C+Z">Zongyi Li</a>, 
<a href="/search/physics?searchtype=author&query=Gray%2C+A">Ander Gray</a>, 
<a href="/search/physics?searchtype=author&query=Brennand%2C+D">Daniel Brennand</a>, 
<a href="/search/physics?searchtype=author&query=Bhatia%2C+N">Nitesh Bhatia</a>, 
<a href="/search/physics?searchtype=author&query=Stathopoulos%2C+G">Gregory Stathopoulos</a>, 
<a href="/search/physics?searchtype=author&query=Kusner%2C+M">Matt Kusner</a>, 
<a href="/search/physics?searchtype=author&query=Deisenroth%2C+M+P">Marc Peter Deisenroth</a>, 
<a href="/search/physics?searchtype=author&query=Anandkumar%2C+A">Anima Anandkumar</a>, 
<a href="/search/physics?searchtype=author&query=JOREK+Team">JOREK Team</a>, 
<a href="/search/physics?searchtype=author&query=MAST+Team">MAST Team</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Plasma Physics (physics.plasm-ph)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Predicting plasma evolution within a Tokamak reactor is crucial to realizing
the goal of sustainable fusion. Capabilities in forecasting the spatio-temporal
evolution of plasma rapidly and accurately allow us to quickly iterate over
design and control strategies on current Tokamak devices and future reactors.
Modelling plasma evolution using numerical solvers is often expensive,
consuming many hours on supercomputers, and hence, we need alternative
inexpensive surrogate models. We demonstrate accurate predictions of plasma
evolution both in simulation and experimental domains using deep learning-based
surrogate modelling tools, viz., Fourier Neural Operators (FNO). We show that
FNO has a speedup of six orders of magnitude over traditional solvers in
predicting the plasma dynamics simulated from magnetohydrodynamic models, while
maintaining a high accuracy (MSE $\approx$ $10^{-5}$). Our modified version of
the FNO is capable of solving multi-variable Partial Differential Equations
(PDE), and can capture the dependence among the different variables in a single
model. FNOs can also predict plasma evolution on real-world experimental data
observed by the cameras positioned within the MAST Tokamak, i.e., cameras
looking across the central solenoid and the divertor in the Tokamak. We show
that FNOs are able to accurately forecast the evolution of plasma and have the
potential to be deployed for real-time monitoring. We also illustrate their
capability in forecasting the plasma shape, the locations of interactions of
the plasma with the central solenoid and the divertor for the full duration of
the plasma shot within MAST. The FNO offers a viable alternative for surrogate
modelling as it is quick to train and infer, and requires fewer data points,
while being able to do zero-shot super-resolution and getting high-fidelity
solutions.
</p>
</div>
</dd>
<dt><a name="item272">[272]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06002" title="Abstract">arXiv:2311.06002</a> (cross-list from eess.SP) [<a href="/pdf/2311.06002" title="Download PDF">pdf</a>, <a href="/format/2311.06002" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fully-Passive versus Semi-Passive IRS-Enabled Sensing: SNR and CRB  Comparison
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Song%2C+X">Xianxin Song</a>, 
<a href="/search/eess?searchtype=author&query=Li%2C+X">Xinmin Li</a>, 
<a href="/search/eess?searchtype=author&query=Qin%2C+X">Xiaoqi Qin</a>, 
<a href="/search/eess?searchtype=author&query=Xu%2C+J">Jie Xu</a>, 
<a href="/search/eess?searchtype=author&query=Han%2C+T+X">Tony Xiao Han</a>, 
<a href="/search/eess?searchtype=author&query=Ng%2C+D+W+K">Derrick Wing Kwan Ng</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages,7 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Information Theory (cs.IT)

</div>
<p class="mathjax">This paper investigates the sensing performance of two intelligent reflecting
surface (IRS)-enabled non-line-of-sight (NLoS) sensing systems with
fully-passive and semi-passive IRSs, respectively. In particular, we consider a
fundamental setup with one base station (BS), one uniform linear array (ULA)
IRS, and one point target in the NLoS region of the BS. Accordingly, we analyze
the sensing signal-to-noise ratio (SNR) performance for a target detection
scenario and the estimation Cram\'er-Rao bound (CRB) performance for a target's
direction-of-arrival (DoA) estimation scenario, in cases where the transmit
beamforming at the BS and the reflective beamforming at the IRS are jointly
optimized. First, for the target detection scenario, we characterize the
maximum sensing SNR when the BS-IRS channels are line-of-sight (LoS) and
Rayleigh fading, respectively. It is revealed that when the number of
reflecting elements $N$ equipped at the IRS becomes sufficiently large, the
maximum sensing SNR increases proportionally to $N^2$ for the semi-passive-IRS
sensing system, but proportionally to $N^4$ for the fully-passive-IRS
counterpart. Then, for the target's DoA estimation scenario, we analyze the
minimum CRB performance when the BS-IRS channel follows Rayleigh fading.
Specifically, when $N$ grows, the minimum CRB decreases inversely
proportionally to $N^4$ and $N^6$ for the semi-passive and fully-passive-IRS
sensing systems, respectively. Finally, numerical results are presented to
corroborate our analysis across various transmit and reflective beamforming
design schemes under general channel setups. It is shown that the
fully-passive-IRS sensing system outperforms the semi-passive counterpart when
$N$ exceeds a certain threshold. This advantage is attributed to the additional
reflective beamforming gain in the IRS-BS path, which efficiently compensates
for the path loss for a large $N$.
</p>
</div>
</dd>
<dt><a name="item273">[273]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06009" title="Abstract">arXiv:2311.06009</a> (cross-list from eess.IV) [<a href="/pdf/2311.06009" title="Download PDF">pdf</a>, <a href="/format/2311.06009" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Polar-Net: A Clinical-Friendly Model for Alzheimer&#x27;s Disease Detection  in OCTA Images
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Liu%2C+S">Shouyue Liu</a>, 
<a href="/search/eess?searchtype=author&query=Hao%2C+J">Jinkui Hao</a>, 
<a href="/search/eess?searchtype=author&query=Xu%2C+Y">Yanwu Xu</a>, 
<a href="/search/eess?searchtype=author&query=Fu%2C+H">Huazhu Fu</a>, 
<a href="/search/eess?searchtype=author&query=Guo%2C+X">Xinyu Guo</a>, 
<a href="/search/eess?searchtype=author&query=Liu%2C+J">Jiang Liu</a>, 
<a href="/search/eess?searchtype=author&query=Zheng%2C+Y">Yalin Zheng</a>, 
<a href="/search/eess?searchtype=author&query=Liu%2C+Y">Yonghuai Liu</a>, 
<a href="/search/eess?searchtype=author&query=Zhang%2C+J">Jiong Zhang</a>, 
<a href="/search/eess?searchtype=author&query=Zhao%2C+Y">Yitian Zhao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by MICCAI2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Optical Coherence Tomography Angiography (OCTA) is a promising tool for
detecting Alzheimer's disease (AD) by imaging the retinal microvasculature.
Ophthalmologists commonly use region-based analysis, such as the ETDRS grid, to
study OCTA image biomarkers and understand the correlation with AD. However,
existing studies have used general deep computer vision methods, which present
challenges in providing interpretable results and leveraging clinical prior
knowledge. To address these challenges, we propose a novel deep-learning
framework called Polar-Net. Our approach involves mapping OCTA images from
Cartesian coordinates to polar coordinates, which allows for the use of
approximate sector convolution and enables the implementation of the ETDRS
grid-based regional analysis method commonly used in clinical practice.
Furthermore, Polar-Net incorporates clinical prior information of each sector
region into the training process, which further enhances its performance.
Additionally, our framework adapts to acquire the importance of the
corresponding retinal region, which helps researchers and clinicians understand
the model's decision-making process in detecting AD and assess its conformity
to clinical observations. Through evaluations on private and public datasets,
we have demonstrated that Polar-Net outperforms existing state-of-the-art
methods and provides more valuable pathological evidence for the association
between retinal vascular changes and AD. In addition, we also show that the two
innovative modules introduced in our framework have a significant impact on
improving overall performance.
</p>
</div>
</dd>
<dt><a name="item274">[274]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06047" title="Abstract">arXiv:2311.06047</a> (cross-list from physics.soc-ph) [<a href="/pdf/2311.06047" title="Download PDF">pdf</a>, <a href="/format/2311.06047" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fast unfolding of communities in large networks: 15 years later
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Blondel%2C+V">Vincent Blondel</a>, 
<a href="/search/physics?searchtype=author&query=Guillaume%2C+J">Jean-Loup Guillaume</a>, 
<a href="/search/physics?searchtype=author&query=Lambiotte%2C+R">Renaud Lambiotte</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Physics and Society (physics.soc-ph)</span>; Social and Information Networks (cs.SI)

</div>
<p class="mathjax">The Louvain method was proposed 15 years ago as a heuristic method for the
fast detection of communities in large networks. During this period, it has
emerged as one of the most popular methods for community detection, the task of
partitioning vertices of a network into dense groups, usually called
communities or clusters. Here, after a short introduction to the method, we
give an overview of the different generalizations and modifications that have
been proposed in the literature, and also survey the quality functions, beyond
modularity, for which it has been implemented.
</p>
</div>
</dd>
<dt><a name="item275">[275]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06057" title="Abstract">arXiv:2311.06057</a> (cross-list from eess.IV) [<a href="/pdf/2311.06057" title="Download PDF">pdf</a>, <a href="/format/2311.06057" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Ulcerative Colitis Mayo Endoscopic Scoring Classification with Active  Learning and Generative Data Augmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=%C3%87a%C4%9Flar%2C+%C3%9C+M">&#xdc;mit Mert &#xc7;a&#x11f;lar</a>, 
<a href="/search/eess?searchtype=author&query=%C4%B0nci%2C+A">Alperen &#x130;nci</a>, 
<a href="/search/eess?searchtype=author&query=Hano%C4%9Flu%2C+O">O&#x11f;uz Hano&#x11f;lu</a>, 
<a href="/search/eess?searchtype=author&query=Polat%2C+G">G&#xf6;rkem Polat</a>, 
<a href="/search/eess?searchtype=author&query=Temizel%2C+A">Alptekin Temizel</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages, 3 figures, to be published in IEEE International Conference on Bioinformatics and Biomedicine (BIBM) 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
<p class="mathjax">Endoscopic imaging is commonly used to diagnose Ulcerative Colitis (UC) and
classify its severity. It has been shown that deep learning based methods are
effective in automated analysis of these images and can potentially be used to
aid medical doctors. Unleashing the full potential of these methods depends on
the availability of large amount of labeled images; however, obtaining and
labeling these images are quite challenging. In this paper, we propose a active
learning based generative augmentation method. The method involves generating a
large number of synthetic samples by training using a small dataset consisting
of real endoscopic images. The resulting data pool is narrowed down by using
active learning methods to select the most informative samples, which are then
used to train a classifier. We demonstrate the effectiveness of our method
through experiments on a publicly available endoscopic image dataset. The
results show that using synthesized samples in conjunction with active learning
leads to improved classification performance compared to using only the
original labeled examples and the baseline classification performance of 68.1%
increases to 74.5% in terms of Quadratic Weighted Kappa (QWK) Score. Another
observation is that, attaining equivalent performance using only real data
necessitated three times higher number of images.
</p>
</div>
</dd>
<dt><a name="item276">[276]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06074" title="Abstract">arXiv:2311.06074</a> (cross-list from q-bio.NC) [<a href="/pdf/2311.06074" title="Download PDF">pdf</a>, <a href="/format/2311.06074" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Two-compartment neuronal spiking model expressing brain-state specific  apical-amplification, -isolation and -drive regimes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-bio?searchtype=author&query=Pastorelli%2C+E">Elena Pastorelli</a>, 
<a href="/search/q-bio?searchtype=author&query=Yegenoglu%2C+A">Alper Yegenoglu</a>, 
<a href="/search/q-bio?searchtype=author&query=Kolodziej%2C+N">Nicole Kolodziej</a>, 
<a href="/search/q-bio?searchtype=author&query=Wybo%2C+W">Willem Wybo</a>, 
<a href="/search/q-bio?searchtype=author&query=Simula%2C+F">Francesco Simula</a>, 
<a href="/search/q-bio?searchtype=author&query=Diaz%2C+S">Sandra Diaz</a>, 
<a href="/search/q-bio?searchtype=author&query=Storm%2C+J+F">Johan Frederik Storm</a>, 
<a href="/search/q-bio?searchtype=author&query=Paolucci%2C+P+S">Pier Stanislao Paolucci</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 19 pages, 38 figures, paper
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neurons and Cognition (q-bio.NC)</span>; Neural and Evolutionary Computing (cs.NE)

</div>
<p class="mathjax">There is mounting experimental evidence that brain-state specific neural
mechanisms supported by connectomic architectures serve to combine past and
contextual knowledge with current, incoming flow of evidence (e.g. from sensory
systems). Such mechanisms are distributed across multiple spatial and temporal
scales and require dedicated support at the levels of individual neurons and
synapses. A prominent feature in the neocortex is the structure of large, deep
pyramidal neurons which show a peculiar separation between an apical dendritic
compartment and a basal dentritic/peri-somatic compartment, with distinctive
patterns of incoming connections and brain-state specific activation
mechanisms, namely apical-amplification, -isolation and -drive associated to
the wakefulness, deeper NREM sleep stages and REM sleep. The cognitive roles of
apical mechanisms have been demonstrated in behaving animals. In contrast,
classical models of learning spiking networks are based on single compartment
neurons that miss the description of mechanisms to combine apical and
basal/somatic information. This work aims to provide the computational
community with a two-compartment spiking neuron model which includes features
that are essential for supporting brain-state specific learning and with a
piece-wise linear transfer function (ThetaPlanes) at highest abstraction level
to be used in large scale bio-inspired artificial intelligence systems. A
machine learning algorithm, constrained by a set of fitness functions, selected
the parameters defining neurons expressing the desired apical mechanisms.
</p>
</div>
</dd>
<dt><a name="item277">[277]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06112" title="Abstract">arXiv:2311.06112</a> (cross-list from physics.flu-dyn) [<a href="/pdf/2311.06112" title="Download PDF">pdf</a>, <a href="/format/2311.06112" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Turbulence Scaling from Deep Learning Diffusion Generative Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Whittaker%2C+T">Tim Whittaker</a>, 
<a href="/search/physics?searchtype=author&query=Janik%2C+R+A">Romuald A. Janik</a>, 
<a href="/search/physics?searchtype=author&query=Oz%2C+Y">Yaron Oz</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Fluid Dynamics (physics.flu-dyn)</span>; Machine Learning (cs.LG); Chaotic Dynamics (nlin.CD)

</div>
<p class="mathjax">Complex spatial and temporal structures are inherent characteristics of
turbulent fluid flows and comprehending them poses a major challenge. This
comprehesion necessitates an understanding of the space of turbulent fluid flow
configurations. We employ a diffusion-based generative model to learn the
distribution of turbulent vorticity profiles and generate snapshots of
turbulent solutions to the incompressible Navier-Stokes equations. We consider
the inverse cascade in two spatial dimensions and generate diverse turbulent
solutions that differ from those in the training dataset. We analyze the
statistical scaling properties of the new turbulent profiles, calculate their
structure functions, energy power spectrum, velocity probability distribution
function and moments of local energy dissipation. All the learnt scaling
exponents are consistent with the expected Kolmogorov scaling and have lower
errors than the training ones. This agreement with established turbulence
characteristics provides strong evidence of the model's capability to capture
essential features of real-world turbulence.
</p>
</div>
</dd>
<dt><a name="item278">[278]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06118" title="Abstract">arXiv:2311.06118</a> (cross-list from eess.IV) [<a href="/pdf/2311.06118" title="Download PDF">pdf</a>, <a href="/format/2311.06118" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exploring the Efficacy of Base Data Augmentation Methods in Deep  Learning-Based Radiograph Classification of Knee Joint Osteoarthritis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Prezja%2C+F">Fabi Prezja</a>, 
<a href="/search/eess?searchtype=author&query=Annala%2C+L">Leevi Annala</a>, 
<a href="/search/eess?searchtype=author&query=Kiiskinen%2C+S">Sampsa Kiiskinen</a>, 
<a href="/search/eess?searchtype=author&query=Ojala%2C+T">Timo Ojala</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 pages, 10 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
<p class="mathjax">Diagnosing knee joint osteoarthritis (KOA), a major cause of disability
worldwide, is challenging due to subtle radiographic indicators and the varied
progression of the disease. Using deep learning for KOA diagnosis requires
broad, comprehensive datasets. However, obtaining these datasets poses
significant challenges due to patient privacy concerns and data collection
restrictions. Additive data augmentation, which enhances data variability,
emerges as a promising solution. Yet, it's unclear which augmentation
techniques are most effective for KOA. This study explored various data
augmentation methods, including adversarial augmentations, and their impact on
KOA classification model performance. While some techniques improved
performance, others commonly used underperformed. We identified potential
confounding regions within the images using adversarial augmentation. This was
evidenced by our models' ability to classify KL0 and KL4 grades accurately,
with the knee joint omitted. This observation suggested a model bias, which
might leverage unrelated features for classification currently present in
radiographs. Interestingly, removing the knee joint also led to an unexpected
improvement in KL1 classification accuracy. To better visualize these
paradoxical effects, we employed Grad-CAM, highlighting the associated regions.
Our study underscores the need for careful technique selection for improved
model performance and identifying and managing potential confounding regions in
radiographic KOA deep learning.
</p>
</div>
</dd>
<dt><a name="item279">[279]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06125" title="Abstract">arXiv:2311.06125</a> (cross-list from math.CA) [<a href="/pdf/2311.06125" title="Download PDF">pdf</a>, <a href="/format/2311.06125" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Loewner functions for bilinear systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Kergus%2C+P">Pauline Kergus</a>, 
<a href="/search/math?searchtype=author&query=Gosea%2C+I+V">Ion Victor Gosea</a>, 
<a href="/search/math?searchtype=author&query=Petreczky%2C+M">Mihaly Petreczky</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Classical Analysis and ODEs (math.CA)</span>; Systems and Control (eess.SY)

</div>
<p class="mathjax">This work brings together the moment matching approach based on Loewner
functions and the classical Loewner framework based on the Loewner pencil in
the case of bilinear systems. New Loewner functions are defined based on the
bilinear Loewner framework, and a Loewner equivalent model is produced using
these functions. This model is composed of infinite series that needs to be
truncated in order to be implemented in practice. In this context, a new notion
of approximate Loewner equivalence is introduced. In the end, it is shown that
the moment matching procedure based on the proposed Loewner functions and the
classical interpolatory bilinear Loewner framework both result in
$\kappa$-Loewner equivalent models, the main difference being that the latter
preserves bilinearity at the expense of a higher order.
</p>
</div>
</dd>
<dt><a name="item280">[280]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06130" title="Abstract">arXiv:2311.06130</a> (cross-list from math.OC) [<a href="/pdf/2311.06130" title="Download PDF">pdf</a>, <a href="/format/2311.06130" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> High-dimensional mixed-categorical Gaussian processes with application  to multidisciplinary design optimization for a green aircraft
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Saves%2C+P">Paul Saves</a>, 
<a href="/search/math?searchtype=author&query=Diouane%2C+Y">Youssef Diouane</a>, 
<a href="/search/math?searchtype=author&query=Bartoli%2C+N">Nathalie Bartoli</a>, 
<a href="/search/math?searchtype=author&query=Lefebvre%2C+T">Thierry Lefebvre</a>, 
<a href="/search/math?searchtype=author&query=Morlier%2C+J">Joseph Morlier</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Artificial Intelligence (cs.AI); Machine Learning (stat.ML)

</div>
<p class="mathjax">Multidisciplinary design optimization (MDO) methods aim at adapting numerical
optimization techniques to the design of engineering systems involving multiple
disciplines. In this context, a large number of mixed continuous, integer, and
categorical variables might arise during the optimization process, and
practical applications involve a significant number of design variables.
Recently, there has been a growing interest in mixed-categorical metamodels
based on Gaussian Process (GP) for Bayesian optimization. In particular, to
handle mixed-categorical variables, several existing approaches employ
different strategies to build the GP. These strategies either use continuous
kernels, such as the continuous relaxation or the Gower distance-based kernels,
or direct estimation of the correlation matrix, such as the exponential
homoscedastic hypersphere (EHH) or the Homoscedastic Hypersphere (HH) kernel.
Although the EHH and HH kernels are shown to be very efficient and lead to
accurate GPs, they are based on a large number of hyperparameters. In this
paper, we address this issue by constructing mixed-categorical GPs with fewer
hyperparameters using Partial Least Squares (PLS) regression. Our goal is to
generalize Kriging with PLS, commonly used for continuous inputs, to handle
mixed-categorical inputs. The proposed method is implemented in the open-source
software SMT and has been efficiently applied to structural and
multidisciplinary applications. Our method is used to effectively demonstrate
the structural behavior of a cantilever beam and facilitates MDO of a green
aircraft, resulting in a 439-kilogram reduction in the amount of fuel consumed
during a single aircraft mission.
</p>
</div>
</dd>
<dt><a name="item281">[281]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06138" title="Abstract">arXiv:2311.06138</a> (cross-list from stat.ML) [<a href="/pdf/2311.06138" title="Download PDF">pdf</a>, <a href="/format/2311.06138" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Minimum norm interpolation by perceptra: Explicit regularization and  implicit bias
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Park%2C+J">Jiyoung Park</a>, 
<a href="/search/stat?searchtype=author&query=Pelakh%2C+I">Ian Pelakh</a>, 
<a href="/search/stat?searchtype=author&query=Wojtowytsch%2C+S">Stephan Wojtowytsch</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Thirty-seventh Conference on Neural Information Processing Systems
  2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG); Optimization and Control (math.OC)

</div>
<p class="mathjax">We investigate how shallow ReLU networks interpolate between known regions.
Our analysis shows that empirical risk minimizers converge to a minimum norm
interpolant as the number of data points and parameters tends to infinity when
a weight decay regularizer is penalized with a coefficient which vanishes at a
precise rate as the network width and the number of data points grow. With and
without explicit regularization, we numerically study the implicit bias of
common optimization algorithms towards known minimum norm interpolants.
</p>
</div>
</dd>
<dt><a name="item282">[282]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06171" title="Abstract">arXiv:2311.06171</a> (cross-list from math.PR) [<a href="/pdf/2311.06171" title="Download PDF">pdf</a>, <a href="/ps/2311.06171" title="Download PostScript">ps</a>, <a href="/format/2311.06171" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fast relaxation of the random field Ising dynamics
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Alaoui%2C+A+E">Ahmed El Alaoui</a>, 
<a href="/search/math?searchtype=author&query=Eldan%2C+R">Ronen Eldan</a>, 
<a href="/search/math?searchtype=author&query=Gheissari%2C+R">Reza Gheissari</a>, 
<a href="/search/math?searchtype=author&query=Piana%2C+A">Arianna Piana</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 37 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Probability (math.PR)</span>; Data Structures and Algorithms (cs.DS); Mathematical Physics (math-ph)

</div>
<p class="mathjax">We study the convergence properties of Glauber dynamics for the random field
Ising model (RFIM) with ferromagnetic interactions on finite domains of
$\mathbb{Z}^d$, $d \ge 2$. Of particular interest is the Griffiths phase where
correlations decay exponentially fast in expectation over the quenched
disorder, but there exist arbitrarily large islands of weak fields where
low-temperature behavior is observed. Our results are twofold:
<br />1. Under weak spatial mixing (boundary-to-bulk exponential decay of
correlations) in expectation, we show that the dynamics satisfy a weak
Poincar\'e inequality -- equivalent to large-set expansion -- implying
algebraic relaxation to equilibrium over timescales polynomial in the volume
$N$ of the domain, and polynomial time mixing from a warm start. From this we
construct a polynomial-time approximate sampling algorithm based on running
Glauber dynamics over an increasing sequence of approximations of the domain.
<br />2. Under strong spatial mixing (exponential decay of correlations even near
boundary pinnings) in expectation, we prove a full Poincar\'e inequality,
implying exponential relaxation to equilibrium and $N^{o(1)}$-mixing time. Note
by way of example, both weak and strong spatial mixing hold at any temperature,
provided the external fields are strong enough.
<br />Our proofs combine a stochastic localization technique which has the effect
of increasing the variance of the field, with a field-dependent coarse graining
which controls the resulting sub-critical percolation process of sites with
weak fields.
</p>
</div>
</dd>
<dt><a name="item283">[283]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06185" title="Abstract">arXiv:2311.06185</a> (cross-list from eess.IV) [<a href="/pdf/2311.06185" title="Download PDF">pdf</a>, <a href="/format/2311.06185" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An Automated Pipeline for Tumour-Infiltrating Lymphocyte Scoring in  Breast Cancer
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Shephard%2C+A+J">Adam J Shephard</a>, 
<a href="/search/eess?searchtype=author&query=Jahanifar%2C+M">Mostafa Jahanifar</a>, 
<a href="/search/eess?searchtype=author&query=Wang%2C+R">Ruoyu Wang</a>, 
<a href="/search/eess?searchtype=author&query=Dawood%2C+M">Muhammad Dawood</a>, 
<a href="/search/eess?searchtype=author&query=Graham%2C+S">Simon Graham</a>, 
<a href="/search/eess?searchtype=author&query=Sidlauskas%2C+K">Kastytis Sidlauskas</a>, 
<a href="/search/eess?searchtype=author&query=Khurram%2C+S+A">Syed Ali Khurram</a>, 
<a href="/search/eess?searchtype=author&query=Rajpoot%2C+N+M">Nasir M Rajpoot</a>, 
<a href="/search/eess?searchtype=author&query=Raza%2C+S+E+A">Shan E Ahmed Raza</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages, 1 figure, 2 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG); Quantitative Methods (q-bio.QM)

</div>
<p class="mathjax">Tumour-infiltrating lymphocytes (TILs) are considered as a valuable
prognostic markers in both triple-negative and human epidermal growth factor
receptor 2 (HER2) breast cancer. In this study, we introduce an innovative deep
learning pipeline based on the Efficient-UNet architecture to compute a TILs
score for breast cancer whole slide images. Our pipeline first segments
tumour-stroma regions and generates a tumour bulk mask. Subsequently, it
detects TILs within the tumour-associated stroma, generating a TILs score by
closely mirroring the pathologist's workflow. Our method exhibits
state-of-the-art performance in segmenting tumour/stroma areas and TILs
detection, as demonstrated by internal cross-validation on the TiGER Challenge
training dataset and evaluation on the final leaderboards. Additionally, our
TILs score proves competitive in predicting survival outcomes within the same
challenge, underscoring the clinical relevance and potential of our automated
TILs scoring system as a breast cancer prognostic tool.
</p>
</div>
</dd>
<dt><a name="item284">[284]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06193" title="Abstract">arXiv:2311.06193</a> (cross-list from math.CO) [<a href="/pdf/2311.06193" title="Download PDF">pdf</a>, <a href="/format/2311.06193" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Density Formula: One Lemma to Bound Them All
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Kaufmann%2C+M">Michael Kaufmann</a>, 
<a href="/search/math?searchtype=author&query=Klemz%2C+B">Boris Klemz</a>, 
<a href="/search/math?searchtype=author&query=Knorr%2C+K">Kristin Knorr</a>, 
<a href="/search/math?searchtype=author&query=Reddy%2C+M+M">Meghana M. Reddy</a>, 
<a href="/search/math?searchtype=author&query=Schr%C3%B6der%2C+F">Felix Schr&#xf6;der</a>, 
<a href="/search/math?searchtype=author&query=Ueckerdt%2C+T">Torsten Ueckerdt</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Combinatorics (math.CO)</span>; Discrete Mathematics (cs.DM)

</div>
<p class="mathjax">We introduce the Density Formula for (topological) drawings of graphs in the
plane or on the sphere, which relates the number of edges, vertices, crossings,
and sizes of cells in the drawing. We demonstrate its capability by providing
several applications: we prove tight upper bounds on the edge density of
various beyond-planar graph classes, including so-called $k$-planar graphs with
$k=1,2$, fan-crossing / fan-planar graphs, $k$-bend RAC-graphs with $k=0,1,2$,
and quasiplanar graphs. In some cases ($1$-bend and $2$-bend RAC-graphs and
fan-crossing / fan-planar graphs), we thereby obtain the first tight upper
bounds on the edge density of the respective graph classes. In other cases, we
give new streamlined and significantly shorter proofs for bounds that were
already known in the literature. Thanks to the Density Formula, all of our
proofs are mostly elementary counting and mostly circumvent the typical
intricate case analysis found in earlier proofs. Further, in some cases (simple
and non-homotopic quasiplanar graphs), our alternative proofs using the Density
Formula lead to the first tight lower bound examples.
</p>
</div>
</dd>
<dt><a name="item285">[285]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06205" title="Abstract">arXiv:2311.06205</a> (cross-list from math.OC) [<a href="/pdf/2311.06205" title="Download PDF">pdf</a>, <a href="/format/2311.06205" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A nonsmooth optimization method
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Jia%2C+K">Kai Jia</a>, 
<a href="/search/math?searchtype=author&query=Rinard%2C+M">Martin Rinard</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Numerical Analysis (math.NA)

</div>
<p class="mathjax">We present NCCSG, a nonsmooth optimization method. In each iteration, NCCSG
finds the best length-constrained descent direction by considering the worst
bound over all local subgradients. NCCSG can take advantage of local smoothness
or local strong convexity of the objective function. We prove a few global
convergence rates of NCCSG. For well-behaved nonsmooth functions (characterized
by the weak smooth property), NCCSG converges in $O(\frac{1}{\epsilon} \log
\frac{1}{\epsilon})$ iterations, where $\epsilon$ is the desired optimality
gap. For smooth functions and strongly-convex smooth functions, NCCSG achieves
the lower bound of convergence rates of blackbox first-order methods, i.e.,
$O(\frac{1}{\epsilon})$ for smooth functions and $O(\log \frac{1}{\epsilon})$
for strongly-convex smooth functions. The efficiency of NCCSG depends on the
efficiency of solving a minimax optimization problem involving the
subdifferential of the objective function in each iteration.
</p>
</div>
</dd>
<dt><a name="item286">[286]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06212" title="Abstract">arXiv:2311.06212</a> (cross-list from stat.ML) [<a href="/pdf/2311.06212" title="Download PDF">pdf</a>, <a href="/format/2311.06212" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Differentiable VQ-VAE&#x27;s for Robust White Matter Streamline Encodings
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Lizarraga%2C+A">Andrew Lizarraga</a>, 
<a href="/search/stat?searchtype=author&query=Taraku%2C+B">Brandon Taraku</a>, 
<a href="/search/stat?searchtype=author&query=Honig%2C+E">Edouardo Honig</a>, 
<a href="/search/stat?searchtype=author&query=Wu%2C+Y+N">Ying Nian Wu</a>, 
<a href="/search/stat?searchtype=author&query=Joshi%2C+S+H">Shantanu H. Joshi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages, 4 figures, 1 table
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG); Applications (stat.AP)

</div>
<p class="mathjax">Given the complex geometry of white matter streamlines, Autoencoders have
been proposed as a dimension-reduction tool to simplify the analysis
streamlines in a low-dimensional latent spaces. However, despite these recent
successes, the majority of encoder architectures only perform dimension
reduction on single streamlines as opposed to a full bundle of streamlines.
This is a severe limitation of the encoder architecture that completely
disregards the global geometric structure of streamlines at the expense of
individual fibers. Moreover, the latent space may not be well structured which
leads to doubt into their interpretability. In this paper we propose a novel
Differentiable Vector Quantized Variational Autoencoder, which are engineered
to ingest entire bundles of streamlines as single data-point and provides
reliable trustworthy encodings that can then be later used to analyze
streamlines in the latent space. Comparisons with several state of the art
Autoencoders demonstrate superior performance in both encoding and synthesis.
</p>
</div>
</dd>
</dl>
<h3>Replacements for Mon, 13 Nov 23</h3>
<dl>
<dt><a name="item287">[287]</a>&nbsp;  <span class="list-identifier"><a href="/abs/1810.07168" title="Abstract">arXiv:1810.07168</a> (replaced) [<a href="/pdf/1810.07168" title="Download PDF">pdf</a>, <a href="/format/1810.07168" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An empirical evaluation of imbalanced data strategies from a  practitioner&#x27;s point of view
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wainer%2C+J">Jacques Wainer</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item288">[288]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2106.05665" title="Abstract">arXiv:2106.05665</a> (replaced) [<a href="/pdf/2106.05665" title="Download PDF">pdf</a>, <a href="/format/2106.05665" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Chanakya: Learning Runtime Decisions for Adaptive Real-Time Perception
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ghosh%2C+A">Anurag Ghosh</a>, 
<a href="/search/cs?searchtype=author&query=Balloli%2C+V">Vaibhav Balloli</a>, 
<a href="/search/cs?searchtype=author&query=Nambi%2C+A">Akshay Nambi</a>, 
<a href="/search/cs?searchtype=author&query=Singh%2C+A">Aditya Singh</a>, 
<a href="/search/cs?searchtype=author&query=Ganu%2C+T">Tanuja Ganu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> NeurIPS 2023 Accepted Paper
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item289">[289]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2108.08503" title="Abstract">arXiv:2108.08503</a> (replaced) [<a href="/pdf/2108.08503" title="Download PDF">pdf</a>, <a href="/format/2108.08503" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On Capacity Optimality of OAMP: Beyond IID Sensing Matrices and Gaussian  Signaling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+L">Lei Liu</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+S">Shansuo Liang</a>, 
<a href="/search/cs?searchtype=author&query=Ping%2C+L">Li Ping</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Double columns, 17 pages, 9 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
</div>
</dd>
<dt><a name="item290">[290]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2108.13672" title="Abstract">arXiv:2108.13672</a> (replaced) [<a href="/pdf/2108.13672" title="Download PDF">pdf</a>, <a href="/format/2108.13672" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SANSformers: Self-Supervised Forecasting in Electronic Health Records  with Attention-Free Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kumar%2C+Y">Yogesh Kumar</a>, 
<a href="/search/cs?searchtype=author&query=Ilin%2C+A">Alexander Ilin</a>, 
<a href="/search/cs?searchtype=author&query=Salo%2C+H">Henri Salo</a>, 
<a href="/search/cs?searchtype=author&query=Kulathinal%2C+S">Sangita Kulathinal</a>, 
<a href="/search/cs?searchtype=author&query=Leinonen%2C+M+K">Maarit K. Leinonen</a>, 
<a href="/search/cs?searchtype=author&query=Marttinen%2C+P">Pekka Marttinen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 17 pages, 11 figures, 11 tables, Submitted to an IEEE journal
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item291">[291]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2111.11524" title="Abstract">arXiv:2111.11524</a> (replaced) [<a href="/pdf/2111.11524" title="Download PDF">pdf</a>, <a href="/format/2111.11524" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Tenodesis Grasp Emulator: Kinematic Assessment of Wrist-Driven Orthotic  Control
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chang%2C+E+Y">Erin Y. Chang</a>, 
<a href="/search/cs?searchtype=author&query=Mardini%2C+R">Raghid Mardini</a>, 
<a href="/search/cs?searchtype=author&query=McPherson%2C+A+I+W">Andrew I. W. McPherson</a>, 
<a href="/search/cs?searchtype=author&query=Gloumakov%2C+Y">Yuri Gloumakov</a>, 
<a href="/search/cs?searchtype=author&query=Stuart%2C+H+S">Hannah S. Stuart</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, 11 figures, submitted to International Conference on Robotics and Automation (ICRA) 2022. Video Supplement: <a href="https://youtu.be/NIgKg5R3Roc">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
</div>
</dd>
<dt><a name="item292">[292]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2201.06157" title="Abstract">arXiv:2201.06157</a> (replaced) [<a href="/pdf/2201.06157" title="Download PDF">pdf</a>, <a href="/format/2201.06157" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Potential Game-Based Decision-Making for Autonomous Driving
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Liu%2C+M">Mushuang Liu</a>, 
<a href="/search/eess?searchtype=author&query=Kolmanovsky%2C+I">Ilya Kolmanovsky</a>, 
<a href="/search/eess?searchtype=author&query=Tseng%2C+H+E">H. Eric Tseng</a>, 
<a href="/search/eess?searchtype=author&query=Huang%2C+S">Suzhou Huang</a>, 
<a href="/search/eess?searchtype=author&query=Filev%2C+D">Dimitar Filev</a>, 
<a href="/search/eess?searchtype=author&query=Girard%2C+A">Anouck Girard</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
</div>
</dd>
<dt><a name="item293">[293]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2201.12955" title="Abstract">arXiv:2201.12955</a> (replaced) [<a href="/pdf/2201.12955" title="Download PDF">pdf</a>, <a href="/format/2201.12955" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Optimal Regret Is Achievable with Bounded Approximate Inference Error:  An Enhanced Bayesian Upper Confidence Bound Framework
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+Z">Ziyi Huang</a>, 
<a href="/search/cs?searchtype=author&query=Lam%2C+H">Henry Lam</a>, 
<a href="/search/cs?searchtype=author&query=Meisami%2C+A">Amirhossein Meisami</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Haofeng Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item294">[294]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2202.07881" title="Abstract">arXiv:2202.07881</a> (replaced) [<a href="/pdf/2202.07881" title="Download PDF">pdf</a>, <a href="/format/2202.07881" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The addition of temporal neighborhood makes the logic of prefixes and  sub-intervals EXPSPACE-complete
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bozzelli%2C+L">L. Bozzelli</a>, 
<a href="/search/cs?searchtype=author&query=Montanari%2C+A">A. Montanari</a>, 
<a href="/search/cs?searchtype=author&query=Peron%2C+A">A. Peron</a>, 
<a href="/search/cs?searchtype=author&query=Sala%2C+P">P. Sala</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: substantial text overlap with <a href="/abs/2109.08320">arXiv:2109.08320</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>

</div>
</div>
</dd>
<dt><a name="item295">[295]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2203.08317" title="Abstract">arXiv:2203.08317</a> (replaced) [<a href="/pdf/2203.08317" title="Download PDF">pdf</a>, <a href="/format/2203.08317" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> TAKDE: Temporal Adaptive Kernel Density Estimator for Real-Time Dynamic  Density Estimation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Wang%2C+Y">Yinsong Wang</a>, 
<a href="/search/stat?searchtype=author&query=Ding%2C+Y">Yu Ding</a>, 
<a href="/search/stat?searchtype=author&query=Shahrampour%2C+S">Shahin Shahrampour</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG); Signal Processing (eess.SP)

</div>
</div>
</dd>
<dt><a name="item296">[296]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2203.17255" title="Abstract">arXiv:2203.17255</a> (replaced) [<a href="/pdf/2203.17255" title="Download PDF">pdf</a>, <a href="/ps/2203.17255" title="Download PostScript">ps</a>, <a href="/format/2203.17255" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Cognitive Architecture for Machine Consciousness and Artificial  Superintelligence: Thought Is Structured by the Iterative Updating of Working  Memory
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-bio?searchtype=author&query=Reser%2C+J+E">Jared Edward Reser</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neurons and Cognition (q-bio.NC)</span>; Computation and Language (cs.CL); Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item297">[297]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2204.04954" title="Abstract">arXiv:2204.04954</a> (replaced) [<a href="/pdf/2204.04954" title="Download PDF">pdf</a>, <a href="/format/2204.04954" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Reinforcement Re-ranking with 2D Grid-based Recommendation Panels
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+S">Sirui Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xiao Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+X">Xu Chen</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zhiyu Li</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yuan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+Q">Quan Lin</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+J">Jun Xu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>

</div>
</div>
</dd>
<dt><a name="item298">[298]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2205.03553" title="Abstract">arXiv:2205.03553</a> (replaced) [<a href="/pdf/2205.03553" title="Download PDF">pdf</a>, <a href="/format/2205.03553" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> From Heavy Rain Removal to Detail Restoration: A Faster and Better  Network
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gao%2C+T">Tao Gao</a>, 
<a href="/search/cs?searchtype=author&query=Wen%2C+Y">Yuanbo Wen</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jing Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+K">Kaihao Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+T">Ting Chen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Image and Video Processing (eess.IV)

</div>
</div>
</dd>
<dt><a name="item299">[299]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2205.05328" title="Abstract">arXiv:2205.05328</a> (replaced) [<a href="/pdf/2205.05328" title="Download PDF">pdf</a>, <a href="/format/2205.05328" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fundamental Limits of Multiple-Access Integrated Sensing and  Communication Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yao Liu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+M">Min Li</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+A">An Liu</a>, 
<a href="/search/cs?searchtype=author&query=Ong%2C+L">Lawrence Ong</a>, 
<a href="/search/cs?searchtype=author&query=Yener%2C+A">Aylin Yener</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>

</div>
</div>
</dd>
<dt><a name="item300">[300]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2205.08443" title="Abstract">arXiv:2205.08443</a> (replaced) [<a href="/pdf/2205.08443" title="Download PDF">pdf</a>, <a href="/format/2205.08443" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the (In)security of Peer-to-Peer Decentralized Machine Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pasquini%2C+D">Dario Pasquini</a>, 
<a href="/search/cs?searchtype=author&query=Raynal%2C+M">Mathilde Raynal</a>, 
<a href="/search/cs?searchtype=author&query=Troncoso%2C+C">Carmela Troncoso</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> IEEE S&amp;P'23 (Previous title: "On the Privacy of Decentralized Machine Learning") + Fixed error in neighbors-discovery trick
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item301">[301]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2206.05359" title="Abstract">arXiv:2206.05359</a> (replaced) [<a href="/pdf/2206.05359" title="Download PDF">pdf</a>, <a href="/format/2206.05359" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Blades: A Unified Benchmark Suite for Byzantine Attacks and Defenses in  Federated Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+S">Shenghui Li</a>, 
<a href="/search/cs?searchtype=author&query=Ngai%2C+E">Edith Ngai</a>, 
<a href="/search/cs?searchtype=author&query=Ye%2C+F">Fanghua Ye</a>, 
<a href="/search/cs?searchtype=author&query=Ju%2C+L">Li Ju</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+T">Tianru Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Voigt%2C+T">Thiemo Voigt</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Distributed, Parallel, and Cluster Computing (cs.DC)

</div>
</div>
</dd>
<dt><a name="item302">[302]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2206.05658" title="Abstract">arXiv:2206.05658</a> (replaced) [<a href="/pdf/2206.05658" title="Download PDF">pdf</a>, <a href="/format/2206.05658" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Improving Pre-trained Language Model Fine-tuning with Noise Stability  Regularization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hua%2C+H">Hang Hua</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xingjian Li</a>, 
<a href="/search/cs?searchtype=author&query=Dou%2C+D">Dejing Dou</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+C">Cheng-Zhong Xu</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+J">Jiebo Luo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by TNNLS
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item303">[303]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2207.00282" title="Abstract">arXiv:2207.00282</a> (replaced) [<a href="/pdf/2207.00282" title="Download PDF">pdf</a>, <a href="/format/2207.00282" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> (Un)likelihood Training for Interpretable Embedding
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+J">Jiaxin Wu</a>, 
<a href="/search/cs?searchtype=author&query=Ngo%2C+C">Chong-Wah Ngo</a>, 
<a href="/search/cs?searchtype=author&query=Chan%2C+W">Wing-Kwong Chan</a>, 
<a href="/search/cs?searchtype=author&query=Hou%2C+Z">Zhijian Hou</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> accepted in ACM Transactions on Information Systems
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Information Retrieval (cs.IR); Multimedia (cs.MM)

</div>
</div>
</dd>
<dt><a name="item304">[304]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2207.11365" title="Abstract">arXiv:2207.11365</a> (replaced) [<a href="/pdf/2207.11365" title="Download PDF">pdf</a>, <a href="/format/2207.11365" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> EgoEnv: Human-centric environment representations from egocentric video
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nagarajan%2C+T">Tushar Nagarajan</a>, 
<a href="/search/cs?searchtype=author&query=Ramakrishnan%2C+S+K">Santhosh Kumar Ramakrishnan</a>, 
<a href="/search/cs?searchtype=author&query=Desai%2C+R">Ruta Desai</a>, 
<a href="/search/cs?searchtype=author&query=Hillis%2C+J">James Hillis</a>, 
<a href="/search/cs?searchtype=author&query=Grauman%2C+K">Kristen Grauman</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Published in NeurIPS 2023 (Oral)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item305">[305]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2208.00280" title="Abstract">arXiv:2208.00280</a> (replaced) [<a href="/pdf/2208.00280" title="Download PDF">pdf</a>, <a href="/ps/2208.00280" title="Download PostScript">ps</a>, <a href="/format/2208.00280" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Energy Demand Unawareness and the Popularity of Bitcoin: Evidence from  Nigeria
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Platt%2C+M">Moritz Platt</a>, 
<a href="/search/cs?searchtype=author&query=Ojeka%2C+S">Stephen Ojeka</a>, 
<a href="/search/cs?searchtype=author&query=Dr%C4%83gnoiu%2C+A">Andreea-Elena Dr&#x103;gnoiu</a>, 
<a href="/search/cs?searchtype=author&query=Ibelegbu%2C+O+E">Oserere Ejemen Ibelegbu</a>, 
<a href="/search/cs?searchtype=author&query=Pierangeli%2C+F">Francesco Pierangeli</a>, 
<a href="/search/cs?searchtype=author&query=Sedlmeir%2C+J">Johannes Sedlmeir</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zixin Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Early versions of this article were disseminated under the title "How to Make Users Adopt More Sustainable Cryptocurrencies: Evidence from Nigeria". Subsequently, the article has been renamed to "Energy Demand Unawareness and the Popularity of Bitcoin: Evidence from Nigeria", which is the title of the published version of record and the appropriate nomenclature for all citations of this work
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Oxford Open Energy, 2023, 2, oiad012
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>

</div>
</div>
</dd>
<dt><a name="item306">[306]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2208.02835" title="Abstract">arXiv:2208.02835</a> (replaced) [<a href="/pdf/2208.02835" title="Download PDF">pdf</a>, <a href="/format/2208.02835" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Safe and Human-Like Autonomous Driving: A Predictor-Corrector Potential  Game Approach
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Liu%2C+M">Mushuang Liu</a>, 
<a href="/search/eess?searchtype=author&query=Tseng%2C+H+E">H. Eric Tseng</a>, 
<a href="/search/eess?searchtype=author&query=Filev%2C+D">Dimitar Filev</a>, 
<a href="/search/eess?searchtype=author&query=Girard%2C+A">Anouck Girard</a>, 
<a href="/search/eess?searchtype=author&query=Kolmanovsky%2C+I">Ilya Kolmanovsky</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
</div>
</dd>
<dt><a name="item307">[307]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2209.02461" title="Abstract">arXiv:2209.02461</a> (replaced) [<a href="/pdf/2209.02461" title="Download PDF">pdf</a>, <a href="/format/2209.02461" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ABS+ Polar Codes: Exploiting More Linear Transforms on Adjacent Bits
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+G">Guodong Li</a>, 
<a href="/search/cs?searchtype=author&query=Ye%2C+M">Min Ye</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+S">Sihuang Hu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Final version to be published in IEEE Transactions on Information Theory
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>

</div>
</div>
</dd>
<dt><a name="item308">[308]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2209.12346" title="Abstract">arXiv:2209.12346</a> (replaced) [<a href="/pdf/2209.12346" title="Download PDF">pdf</a>, <a href="/ps/2209.12346" title="Download PostScript">ps</a>, <a href="/format/2209.12346" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exploring the Constraints on Artificial General Intelligence: A  Game-Theoretic No-Go Theorem
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/econ?searchtype=author&query=Ismail%2C+M+S">Mehmet S. Ismail</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 15 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Theoretical Economics (econ.TH)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item309">[309]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2209.12528" title="Abstract">arXiv:2209.12528</a> (replaced) [<a href="/pdf/2209.12528" title="Download PDF">pdf</a>, <a href="/format/2209.12528" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Dordis: Efficient Federated Learning with Dropout-Resilient Differential  Privacy
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jiang%2C+Z">Zhifeng Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+W">Wei Wang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+R">Ruichuan Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This article has been accepted to ACM EuroSys '24
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>

</div>
</div>
</dd>
<dt><a name="item310">[310]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2210.01738" title="Abstract">arXiv:2210.01738</a> (replaced) [<a href="/pdf/2210.01738" title="Download PDF">pdf</a>, <a href="/format/2210.01738" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ASIF: Coupled Data Turns Unimodal Models to Multimodal Without Training
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Norelli%2C+A">Antonio Norelli</a>, 
<a href="/search/cs?searchtype=author&query=Fumero%2C+M">Marco Fumero</a>, 
<a href="/search/cs?searchtype=author&query=Maiorca%2C+V">Valentino Maiorca</a>, 
<a href="/search/cs?searchtype=author&query=Moschella%2C+L">Luca Moschella</a>, 
<a href="/search/cs?searchtype=author&query=Rodol%C3%A0%2C+E">Emanuele Rodol&#xe0;</a>, 
<a href="/search/cs?searchtype=author&query=Locatello%2C+F">Francesco Locatello</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 17 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item311">[311]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2210.03852" title="Abstract">arXiv:2210.03852</a> (replaced) [<a href="/pdf/2210.03852" title="Download PDF">pdf</a>, <a href="/format/2210.03852" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Stackelberg POMDP: A Reinforcement Learning Approach for Economic Design
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Brero%2C+G">Gianluca Brero</a>, 
<a href="/search/cs?searchtype=author&query=Eden%2C+A">Alon Eden</a>, 
<a href="/search/cs?searchtype=author&query=Chakrabarti%2C+D">Darshan Chakrabarti</a>, 
<a href="/search/cs?searchtype=author&query=Gerstgrasser%2C+M">Matthias Gerstgrasser</a>, 
<a href="/search/cs?searchtype=author&query=Greenwald%2C+A">Amy Greenwald</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+V">Vincent Li</a>, 
<a href="/search/cs?searchtype=author&query=Parkes%2C+D+C">David C. Parkes</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>; Multiagent Systems (cs.MA)

</div>
</div>
</dd>
<dt><a name="item312">[312]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2210.08886" title="Abstract">arXiv:2210.08886</a> (replaced) [<a href="/pdf/2210.08886" title="Download PDF">pdf</a>, <a href="/format/2210.08886" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning Decentralized Linear Quadratic Regulator with $\sqrt{T}$ Regret
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Ye%2C+L">Lintao Ye</a>, 
<a href="/search/math?searchtype=author&query=Chi%2C+M">Ming Chi</a>, 
<a href="/search/math?searchtype=author&query=Liao%2C+R">Ruiquan Liao</a>, 
<a href="/search/math?searchtype=author&query=Gupta%2C+V">Vijay Gupta</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Machine Learning (cs.LG); Systems and Control (eess.SY)

</div>
</div>
</dd>
<dt><a name="item313">[313]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2210.09372" title="Abstract">arXiv:2210.09372</a> (replaced) [<a href="/pdf/2210.09372" title="Download PDF">pdf</a>, <a href="/format/2210.09372" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Task-Oriented and Semantics-Aware 6G Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Zhou%2C+H">Hui Zhou</a>, 
<a href="/search/eess?searchtype=author&query=Liu%2C+X">Xiaonan Liu</a>, 
<a href="/search/eess?searchtype=author&query=Deng%2C+Y">Yansha Deng</a>, 
<a href="/search/eess?searchtype=author&query=Pappas%2C+N">Nikolaos Pappas</a>, 
<a href="/search/eess?searchtype=author&query=Nallanathan%2C+A">Arumugam Nallanathan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Signal Processing (eess.SP)

</div>
</div>
</dd>
<dt><a name="item314">[314]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2211.04370" title="Abstract">arXiv:2211.04370</a> (replaced) [<a href="/pdf/2211.04370" title="Download PDF">pdf</a>, <a href="/format/2211.04370" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> NESTER: An Adaptive Neurosymbolic Method for Causal Effect Estimation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Reddy%2C+A+G">Abbavaram Gowtham Reddy</a>, 
<a href="/search/cs?searchtype=author&query=Balasubramanian%2C+V+N">Vineeth N Balasubramanian</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Preprint
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Machine Learning (cs.LG); Methodology (stat.ME)

</div>
</div>
</dd>
<dt><a name="item315">[315]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2211.06741" title="Abstract">arXiv:2211.06741</a> (replaced) [<a href="/pdf/2211.06741" title="Download PDF">pdf</a>, <a href="/ps/2211.06741" title="Download PostScript">ps</a>, <a href="/format/2211.06741" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Calibrating Control-Bounded ADCs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Malmberg%2C+H">Hampus Malmberg</a>, 
<a href="/search/eess?searchtype=author&query=Mettler%2C+T">Till Mettler</a>, 
<a href="/search/eess?searchtype=author&query=Burger%2C+T">Thomas Burger</a>, 
<a href="/search/eess?searchtype=author&query=Feyling%2C+F">Fredrik Feyling</a>, 
<a href="/search/eess?searchtype=author&query=Loeliger%2C+H">Hans-Andrea Loeliger</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages, 5 figures, submitted to ISCAS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Signal Processing (eess.SP)

</div>
</div>
</dd>
<dt><a name="item316">[316]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2211.08594" title="Abstract">arXiv:2211.08594</a> (replaced) [<a href="/pdf/2211.08594" title="Download PDF">pdf</a>, <a href="/format/2211.08594" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Orthogonal Polynomials Approximation Algorithm (OPAA):a functional  analytic approach to estimating probability densities
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bialokozowicz%2C+L+W">Lilian W. Bialokozowicz</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> New version of the paper based on reviewer feedback
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Functional Analysis (math.FA); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item317">[317]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2211.10413" title="Abstract">arXiv:2211.10413</a> (replaced) [<a href="/pdf/2211.10413" title="Download PDF">pdf</a>, <a href="/format/2211.10413" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> TSN-FlexTest: Flexible TSN Measurement Testbed (Extended Version)
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ulbricht%2C+M">Marian Ulbricht</a>, 
<a href="/search/cs?searchtype=author&query=Senk%2C+S">Stefan Senk</a>, 
<a href="/search/cs?searchtype=author&query=Nazari%2C+H+K">Hosein K. Nazari</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+H">How-Hang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Reisslein%2C+M">Martin Reisslein</a>, 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+G+T">Giang T. Nguyen</a>, 
<a href="/search/cs?searchtype=author&query=Fitzek%2C+F+H+P">Frank H. P. Fitzek</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 30 pages, 18 figures, 6 tables, IEEE TNSM, in print, 2024. Shorter version in print in IEEE Trans. on Network and Service Management (see related DOI below)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>

</div>
</div>
</dd>
<dt><a name="item318">[318]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2211.13374" title="Abstract">arXiv:2211.13374</a> (replaced) [<a href="/pdf/2211.13374" title="Download PDF">pdf</a>, <a href="/format/2211.13374" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Multivariate Non-Gaussian Bayesian Filter Using Power Moments
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Wu%2C+G">Guangyu Wu</a>, 
<a href="/search/stat?searchtype=author&query=Lindquist%2C+A">Anders Lindquist</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 pages, 4 figures. arXiv admin note: text overlap with <a href="/abs/2207.08519">arXiv:2207.08519</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Methodology (stat.ME)</span>; Systems and Control (eess.SY); Optimization and Control (math.OC)

</div>
</div>
</dd>
<dt><a name="item319">[319]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2211.16082" title="Abstract">arXiv:2211.16082</a> (replaced) [<a href="/pdf/2211.16082" title="Download PDF">pdf</a>, <a href="/ps/2211.16082" title="Download PostScript">ps</a>, <a href="/format/2211.16082" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Safeguarding the Unseen: a Study on Data Privacy in DeFi Protocols
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+Z">Zhuangtong Huang</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+J">Jiawei Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+Z">Zhongyu Huang</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+Y">Yixin Xu</a>, 
<a href="/search/cs?searchtype=author&query=Yen%2C+J">Jerome Yen</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Ye Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Distributed, Parallel, and Cluster Computing (cs.DC)

</div>
</div>
</dd>
<dt><a name="item320">[320]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2212.00186" title="Abstract">arXiv:2212.00186</a> (replaced) [<a href="/pdf/2212.00186" title="Download PDF">pdf</a>, <a href="/format/2212.00186" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multi-Task Imitation Learning for Linear Dynamical Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+T+T">Thomas T. Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Kang%2C+K">Katie Kang</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+B+D">Bruce D. Lee</a>, 
<a href="/search/cs?searchtype=author&query=Tomlin%2C+C">Claire Tomlin</a>, 
<a href="/search/cs?searchtype=author&query=Levine%2C+S">Sergey Levine</a>, 
<a href="/search/cs?searchtype=author&query=Tu%2C+S">Stephen Tu</a>, 
<a href="/search/cs?searchtype=author&query=Matni%2C+N">Nikolai Matni</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Appeared in L4DC 2023. V3: corrected typo in assumptions
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Systems and Control (eess.SY)

</div>
</div>
</dd>
<dt><a name="item321">[321]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2212.01596" title="Abstract">arXiv:2212.01596</a> (replaced) [<a href="/pdf/2212.01596" title="Download PDF">pdf</a>, <a href="/format/2212.01596" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Average degree of the essential variety
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Breiding%2C+P">Paul Breiding</a>, 
<a href="/search/math?searchtype=author&query=Fairchild%2C+S">Samantha Fairchild</a>, 
<a href="/search/math?searchtype=author&query=Santarsiero%2C+P">Pierpaola Santarsiero</a>, 
<a href="/search/math?searchtype=author&query=Shehu%2C+E">Elima Shehu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 18 pages, 2 figures, code included in source files
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Algebraic Geometry (math.AG)</span>; Computer Vision and Pattern Recognition (cs.CV); Geometric Topology (math.GT)

</div>
</div>
</dd>
<dt><a name="item322">[322]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2212.05159" title="Abstract">arXiv:2212.05159</a> (replaced) [<a href="/pdf/2212.05159" title="Download PDF">pdf</a>, <a href="/format/2212.05159" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Optimized Sparse Matrix Operations for Reverse Mode Automatic  Differentiation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nytko%2C+N">Nicolas Nytko</a>, 
<a href="/search/cs?searchtype=author&query=Taghibakhshi%2C+A">Ali Taghibakhshi</a>, 
<a href="/search/cs?searchtype=author&query=Zaman%2C+T+U">Tareq Uz Zaman</a>, 
<a href="/search/cs?searchtype=author&query=MacLachlan%2C+S">Scott MacLachlan</a>, 
<a href="/search/cs?searchtype=author&query=Olson%2C+L+N">Luke N. Olson</a>, 
<a href="/search/cs?searchtype=author&query=West%2C+M">Matt West</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Mathematical Software (cs.MS); Numerical Analysis (math.NA)

</div>
</div>
</dd>
<dt><a name="item323">[323]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2212.11493" title="Abstract">arXiv:2212.11493</a> (replaced) [<a href="/pdf/2212.11493" title="Download PDF">pdf</a>, <a href="/format/2212.11493" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Theory and construction of Quasi-Monte Carlo rules for option pricing  and density estimation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Gilbert%2C+A+D">Alexander D. Gilbert</a>, 
<a href="/search/math?searchtype=author&query=Kuo%2C+F+Y">Frances Y. Kuo</a>, 
<a href="/search/math?searchtype=author&query=Sloan%2C+I+H">Ian H. Sloan</a>, 
<a href="/search/math?searchtype=author&query=Srikumar%2C+A">Abirami Srikumar</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
</div>
</dd>
<dt><a name="item324">[324]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2212.11959" title="Abstract">arXiv:2212.11959</a> (replaced) [<a href="/pdf/2212.11959" title="Download PDF">pdf</a>, <a href="/format/2212.11959" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Nonlinear consensus+innovations under correlated heavy-tailed noises:  Mean square convergence rate and asymptotics
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Vukovic%2C+M">Manojlo Vukovic</a>, 
<a href="/search/math?searchtype=author&query=Jakovetic%2C+D">Dusan Jakovetic</a>, 
<a href="/search/math?searchtype=author&query=Bajovic%2C+D">Dragana Bajovic</a>, 
<a href="/search/math?searchtype=author&query=Kar%2C+S">Soummya Kar</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Information Theory (cs.IT)

</div>
</div>
</dd>
<dt><a name="item325">[325]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.00045" title="Abstract">arXiv:2302.00045</a> (replaced) [<a href="/pdf/2302.00045" title="Download PDF">pdf</a>, <a href="/format/2302.00045" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Neural Control of Parametric Solutions for High-dimensional Evolution  PDEs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Gaby%2C+N">Nathan Gaby</a>, 
<a href="/search/math?searchtype=author&query=Ye%2C+X">Xiaojing Ye</a>, 
<a href="/search/math?searchtype=author&query=Zhou%2C+H">Haomin Zhou</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted for publication SIAM Journal on Scientific Computing (To Appear)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Machine Learning (cs.LG); Optimization and Control (math.OC)

</div>
</div>
</dd>
<dt><a name="item326">[326]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.01377" title="Abstract">arXiv:2302.01377</a> (replaced) [<a href="/pdf/2302.01377" title="Download PDF">pdf</a>, <a href="/ps/2302.01377" title="Download PostScript">ps</a>, <a href="/format/2302.01377" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning with Exposure Constraints in Recommendation Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ben-Porat%2C+O">Omer Ben-Porat</a>, 
<a href="/search/cs?searchtype=author&query=Torkan%2C+R">Rotem Torkan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Published in The Web Conference 2023 (WWW 23)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item327">[327]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.01428" title="Abstract">arXiv:2302.01428</a> (replaced) [<a href="/pdf/2302.01428" title="Download PDF">pdf</a>, <a href="/format/2302.01428" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Understanding Reconstruction Attacks with the Neural Tangent Kernel and  Dataset Distillation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Loo%2C+N">Noel Loo</a>, 
<a href="/search/cs?searchtype=author&query=Hasani%2C+R">Ramin Hasani</a>, 
<a href="/search/cs?searchtype=author&query=Lechner%2C+M">Mathias Lechner</a>, 
<a href="/search/cs?searchtype=author&query=Amini%2C+A">Alexander Amini</a>, 
<a href="/search/cs?searchtype=author&query=Rus%2C+D">Daniela Rus</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Neural and Evolutionary Computing (cs.NE); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item328">[328]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.02118" title="Abstract">arXiv:2302.02118</a> (replaced) [<a href="/pdf/2302.02118" title="Download PDF">pdf</a>, <a href="/format/2302.02118" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SpotLess: Concurrent Rotational Consensus Made Practical through Rapid  View Synchronization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kang%2C+D">Dakai Kang</a>, 
<a href="/search/cs?searchtype=author&query=Rahnama%2C+S">Sajjad Rahnama</a>, 
<a href="/search/cs?searchtype=author&query=Hellings%2C+J">Jelle Hellings</a>, 
<a href="/search/cs?searchtype=author&query=Sadoghi%2C+M">Mohammad Sadoghi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 pages, 15 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Databases (cs.DB)</span>

</div>
</div>
</dd>
<dt><a name="item329">[329]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.02343" title="Abstract">arXiv:2302.02343</a> (replaced) [<a href="/pdf/2302.02343" title="Download PDF">pdf</a>, <a href="/format/2302.02343" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LExecutor: Learning-Guided Execution
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Souza%2C+B">Beatriz Souza</a>, 
<a href="/search/cs?searchtype=author&query=Pradel%2C+M">Michael Pradel</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted in research track of the ACM Joint European Software Engineering Conference and Symposium on the Foundations of Software Engineering (ESEC/FSE) 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>; Machine Learning (cs.LG); Programming Languages (cs.PL)

</div>
</div>
</dd>
<dt><a name="item330">[330]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.04071" title="Abstract">arXiv:2302.04071</a> (replaced) [<a href="/pdf/2302.04071" title="Download PDF">pdf</a>, <a href="/format/2302.04071" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Taming Local Effects in Graph-based Spatiotemporal Forecasting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cini%2C+A">Andrea Cini</a>, 
<a href="/search/cs?searchtype=author&query=Marisca%2C+I">Ivan Marisca</a>, 
<a href="/search/cs?searchtype=author&query=Zambon%2C+D">Daniele Zambon</a>, 
<a href="/search/cs?searchtype=author&query=Alippi%2C+C">Cesare Alippi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item331">[331]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.06755" title="Abstract">arXiv:2302.06755</a> (replaced) [<a href="/pdf/2302.06755" title="Download PDF">pdf</a>, <a href="/format/2302.06755" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Dataset Distillation with Convexified Implicit Gradients
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Loo%2C+N">Noel Loo</a>, 
<a href="/search/cs?searchtype=author&query=Hasani%2C+R">Ramin Hasani</a>, 
<a href="/search/cs?searchtype=author&query=Lechner%2C+M">Mathias Lechner</a>, 
<a href="/search/cs?searchtype=author&query=Rus%2C+D">Daniela Rus</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item332">[332]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.02637" title="Abstract">arXiv:2303.02637</a> (replaced) [<a href="/pdf/2303.02637" title="Download PDF">pdf</a>, <a href="/format/2303.02637" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Semi-Bayesian Nonparametric Estimator of the Maximum Mean Discrepancy  Measure: Applications in Goodness-of-Fit Testing and Generative Adversarial  Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Fazeli-Asl%2C+F">Forough Fazeli-Asl</a>, 
<a href="/search/stat?searchtype=author&query=Zhang%2C+M+M">Michael Minyi Zhang</a>, 
<a href="/search/stat?searchtype=author&query=Lin%2C+L">Lizhen Lin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Typos corrected, Secondary (simulation and theoretical) results added, Additional discussion added, references added
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG); Applications (stat.AP); Methodology (stat.ME)

</div>
</div>
</dd>
<dt><a name="item333">[333]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.08090" title="Abstract">arXiv:2303.08090</a> (replaced) [<a href="/pdf/2303.08090" title="Download PDF">pdf</a>, <a href="/format/2303.08090" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A global exploratory comparison of country self-citations 1996-2019
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Baccini%2C+A">Alberto Baccini</a>, 
<a href="/search/physics?searchtype=author&query=Petrovich%2C+E">Eugenio Petrovich</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 44 pages, 15 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Physics and Society (physics.soc-ph)</span>; Digital Libraries (cs.DL)

</div>
</div>
</dd>
<dt><a name="item334">[334]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.08994" title="Abstract">arXiv:2303.08994</a> (replaced) [<a href="/pdf/2303.08994" title="Download PDF">pdf</a>, <a href="/format/2303.08994" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Physics-Informed Neural Networks for Time-Domain Simulations: Accuracy,  Computational Cost, and Flexibility
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Stiasny%2C+J">Jochen Stiasny</a>, 
<a href="/search/eess?searchtype=author&query=Chatzivasileiadis%2C+S">Spyros Chatzivasileiadis</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Published in Electric Power Systems Research
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Electric Power Systems Research, Volume 224, 2023, 109748
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item335">[335]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.10996" title="Abstract">arXiv:2303.10996</a> (replaced) [<a href="/pdf/2303.10996" title="Download PDF">pdf</a>, <a href="/format/2303.10996" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An analysis of $\mathbb{P}$-invariance and dynamical compensation  properties from a control perspective
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Ashyani%2C+A">Akram Ashyani</a>, 
<a href="/search/eess?searchtype=author&query=Wu%2C+Y">Yu-Heng Wu</a>, 
<a href="/search/eess?searchtype=author&query=Hsu%2C+H">Huan-Wei Hsu</a>, 
<a href="/search/eess?searchtype=author&query=Nordling%2C+T+E+M">Torbj&#xf6;rn E. M. Nordling</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Optimization and Control (math.OC); Biological Physics (physics.bio-ph); Quantitative Methods (q-bio.QM)

</div>
</div>
</dd>
<dt><a name="item336">[336]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.11408" title="Abstract">arXiv:2303.11408</a> (replaced) [<a href="/pdf/2303.11408" title="Download PDF">pdf</a>, <a href="/format/2303.11408" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Stable Bias: Analyzing Societal Representations in Diffusion Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Luccioni%2C+A+S">Alexandra Sasha Luccioni</a>, 
<a href="/search/cs?searchtype=author&query=Akiki%2C+C">Christopher Akiki</a>, 
<a href="/search/cs?searchtype=author&query=Mitchell%2C+M">Margaret Mitchell</a>, 
<a href="/search/cs?searchtype=author&query=Jernite%2C+Y">Yacine Jernite</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to NeurIPS Datasets and Benchmarks 2023 (spotlight)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>

</div>
</div>
</dd>
<dt><a name="item337">[337]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.17896" title="Abstract">arXiv:2303.17896</a> (replaced) [<a href="/pdf/2303.17896" title="Download PDF">pdf</a>, <a href="/format/2303.17896" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exploring the Limits of Deep Image Clustering using Pretrained Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Adaloglou%2C+N">Nikolas Adaloglou</a>, 
<a href="/search/cs?searchtype=author&query=Michels%2C+F">Felix Michels</a>, 
<a href="/search/cs?searchtype=author&query=Kalisch%2C+H">Hamza Kalisch</a>, 
<a href="/search/cs?searchtype=author&query=Kollmann%2C+M">Markus Kollmann</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at BMVC2023. Code at <a href="https://github.com/HHU-MMBS/TEMI-official-BMVC2023">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item338">[338]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.02169" title="Abstract">arXiv:2304.02169</a> (replaced) [<a href="/pdf/2304.02169" title="Download PDF">pdf</a>, <a href="/format/2304.02169" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Synthesize High-dimensional Longitudinal Electronic Health Records via  Hierarchical Autoregressive Language Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Theodorou%2C+B">Brandon Theodorou</a>, 
<a href="/search/cs?searchtype=author&query=Xiao%2C+C">Cao Xiao</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+J">Jimeng Sun</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Nat Commun 14, 5305 (2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item339">[339]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.02754" title="Abstract">arXiv:2304.02754</a> (replaced) [<a href="/pdf/2304.02754" title="Download PDF">pdf</a>, <a href="/format/2304.02754" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Conceptual structure coheres in human cognition but not in large  language models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Suresh%2C+S">Siddharth Suresh</a>, 
<a href="/search/cs?searchtype=author&query=Mukherjee%2C+K">Kushin Mukherjee</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+X">Xizheng Yu</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+W">Wei-Chun Huang</a>, 
<a href="/search/cs?searchtype=author&query=Padua%2C+L">Lisa Padua</a>, 
<a href="/search/cs?searchtype=author&query=Rogers%2C+T+T">Timothy T Rogers</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computation and Language (cs.CL); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item340">[340]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.04307" title="Abstract">arXiv:2304.04307</a> (replaced) [<a href="/pdf/2304.04307" title="Download PDF">pdf</a>, <a href="/format/2304.04307" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PriorCVAE: scalable MCMC parameter inference with Bayesian deep  generative modelling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Semenova%2C+E">Elizaveta Semenova</a>, 
<a href="/search/stat?searchtype=author&query=Verma%2C+P">Prakhar Verma</a>, 
<a href="/search/stat?searchtype=author&query=Cairney-Leeming%2C+M">Max Cairney-Leeming</a>, 
<a href="/search/stat?searchtype=author&query=Solin%2C+A">Arno Solin</a>, 
<a href="/search/stat?searchtype=author&query=Bhatt%2C+S">Samir Bhatt</a>, 
<a href="/search/stat?searchtype=author&query=Flaxman%2C+S">Seth Flaxman</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item341">[341]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.05077" title="Abstract">arXiv:2304.05077</a> (replaced) [<a href="/pdf/2304.05077" title="Download PDF">pdf</a>, <a href="/ps/2304.05077" title="Download PostScript">ps</a>, <a href="/format/2304.05077" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> If consciousness is dynamically relevant, artificial intelligence isn&#x27;t  conscious
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kleiner%2C+J">Johannes Kleiner</a>, 
<a href="/search/cs?searchtype=author&query=Ludwig%2C+T">Tim Ludwig</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
</div>
</dd>
<dt><a name="item342">[342]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.05727" title="Abstract">arXiv:2304.05727</a> (replaced) [<a href="/pdf/2304.05727" title="Download PDF">pdf</a>, <a href="/format/2304.05727" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Preemptively Pruning Clever-Hans Strategies in Deep Neural Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Linhardt%2C+L">Lorenz Linhardt</a>, 
<a href="/search/cs?searchtype=author&query=M%C3%BCller%2C+K">Klaus-Robert M&#xfc;ller</a>, 
<a href="/search/cs?searchtype=author&query=Montavon%2C+G">Gr&#xe9;goire Montavon</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 18 pages + supplement
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item343">[343]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.06105" title="Abstract">arXiv:2304.06105</a> (replaced) [<a href="/pdf/2304.06105" title="Download PDF">pdf</a>, <a href="/format/2304.06105" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Scalable Cell-Free Massive MIMO Unsourced Random Access System
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gkagkos%2C+M">Michail Gkagkos</a>, 
<a href="/search/cs?searchtype=author&query=Chamberland%2C+J">Jean-Francois Chamberland</a>, 
<a href="/search/cs?searchtype=author&query=Georghiades%2C+C+N">Costas N. Georghiades</a>, 
<a href="/search/cs?searchtype=author&query=Narayanan%2C+K+R">Krishna R. Narayanan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Changed the channel model
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
</div>
</dd>
<dt><a name="item344">[344]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.06244" title="Abstract">arXiv:2304.06244</a> (replaced) [<a href="/pdf/2304.06244" title="Download PDF">pdf</a>, <a href="/format/2304.06244" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Computationally-Efficient Neural Image Compression with Shallow Decoders
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Yang%2C+Y">Yibo Yang</a>, 
<a href="/search/eess?searchtype=author&query=Mandt%2C+S">Stephan Mandt</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Updated version of the ICCV 2023 paper. Previously titled "Asymmetrically-powered Neural Image Compression with Shallow Decoders" on arXiv
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item345">[345]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.10593" title="Abstract">arXiv:2304.10593</a> (replaced) [<a href="/pdf/2304.10593" title="Download PDF">pdf</a>, <a href="/format/2304.10593" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DeepReShape: Redesigning Neural Networks for Efficient Private Inference
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jha%2C+N+K">Nandan Kumar Jha</a>, 
<a href="/search/cs?searchtype=author&query=Reagen%2C+B">Brandon Reagen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 37 pages, 23 Figures, and 17 Tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
</div>
</dd>
<dt><a name="item346">[346]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.14012" title="Abstract">arXiv:2304.14012</a> (replaced) [<a href="/pdf/2304.14012" title="Download PDF">pdf</a>, <a href="/format/2304.14012" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Direct Visual Servoing Based on Discrete Orthogonal Moments
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yuhan Chen</a>, 
<a href="/search/cs?searchtype=author&query=Meng%2C+M+Q+-">Max Q.-H. Meng</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+L">Li Liu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Systems and Control (eess.SY)

</div>
</div>
</dd>
<dt><a name="item347">[347]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.00150" title="Abstract">arXiv:2305.00150</a> (replaced) [<a href="/e-print/2305.00150" title="Download source">src</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A locking-free mixed enriched Galerkin method of arbitrary order for  linear elasticity using the stress-displacement formulation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Zhao%2C+Z">Zhongshu Zhao</a>, 
<a href="/search/math?searchtype=author&query=Peng%2C+H">Hui Peng</a>, 
<a href="/search/math?searchtype=author&query=Zhai%2C+Q">Qilong Zhai</a>, 
<a href="/search/math?searchtype=author&query=Zhang%2C+Q">Qian Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> An error is identified in the analysis of inf-sup condition on page 16
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
</div>
</dd>
<dt><a name="item348">[348]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.01135" title="Abstract">arXiv:2305.01135</a> (replaced) [<a href="/pdf/2305.01135" title="Download PDF">pdf</a>, <a href="/format/2305.01135" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A New Wave in Robotics: Survey on Recent mmWave Radar Applications in  Robotics
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Harlow%2C+K">Kyle Harlow</a>, 
<a href="/search/cs?searchtype=author&query=Jang%2C+H">Hyesu Jang</a>, 
<a href="/search/cs?searchtype=author&query=Barfoot%2C+T+D">Timothy D. Barfoot</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+A">Ayoung Kim</a>, 
<a href="/search/cs?searchtype=author&query=Heckman%2C+C">Christoffer Heckman</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 20 Pages, 7 Figures, 2 Tables, TRO Submission pending
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
</div>
</dd>
<dt><a name="item349">[349]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.02133" title="Abstract">arXiv:2305.02133</a> (replaced) [<a href="/pdf/2305.02133" title="Download PDF">pdf</a>, <a href="/ps/2305.02133" title="Download PostScript">ps</a>, <a href="/format/2305.02133" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Frank number and nowhere-zero flows on graphs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Goedgebeur%2C+J">Jan Goedgebeur</a>, 
<a href="/search/math?searchtype=author&query=M%C3%A1%C4%8Dajov%C3%A1%2C+E">Edita M&#xe1;&#x10d;ajov&#xe1;</a>, 
<a href="/search/math?searchtype=author&query=Renders%2C+J">Jarne Renders</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 22 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Combinatorics (math.CO)</span>; Discrete Mathematics (cs.DM)

</div>
</div>
</dd>
<dt><a name="item350">[350]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.02317" title="Abstract">arXiv:2305.02317</a> (replaced) [<a href="/pdf/2305.02317" title="Download PDF">pdf</a>, <a href="/format/2305.02317" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Visual Chain of Thought: Bridging Logical Gaps with Multimodal  Infillings
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rose%2C+D">Daniel Rose</a>, 
<a href="/search/cs?searchtype=author&query=Himakunthala%2C+V">Vaishnavi Himakunthala</a>, 
<a href="/search/cs?searchtype=author&query=Ouyang%2C+A">Andy Ouyang</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+R">Ryan He</a>, 
<a href="/search/cs?searchtype=author&query=Mei%2C+A">Alex Mei</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+Y">Yujie Lu</a>, 
<a href="/search/cs?searchtype=author&query=Saxon%2C+M">Michael Saxon</a>, 
<a href="/search/cs?searchtype=author&query=Sonar%2C+C">Chinmay Sonar</a>, 
<a href="/search/cs?searchtype=author&query=Mirza%2C+D">Diba Mirza</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+W+Y">William Yang Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item351">[351]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.06982" title="Abstract">arXiv:2305.06982</a> (replaced) [<a href="/pdf/2305.06982" title="Download PDF">pdf</a>, <a href="/ps/2305.06982" title="Download PostScript">ps</a>, <a href="/format/2305.06982" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> How Much Partiality Is Needed for a Theory of Computability?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Spreen%2C+D">Dieter Spreen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>; Logic (math.LO)

</div>
</div>
</dd>
<dt><a name="item352">[352]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.07862" title="Abstract">arXiv:2305.07862</a> (replaced) [<a href="/pdf/2305.07862" title="Download PDF">pdf</a>, <a href="/ps/2305.07862" title="Download PostScript">ps</a>, <a href="/format/2305.07862" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Research on Cooperative Search Technology of Heterogeneous UAVs in  Complex Environments
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Liu%2C+Z">Zhenchang Liu</a>, 
<a href="/search/eess?searchtype=author&query=Hao%2C+M">Mingrui Hao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 26 pages, 26 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
</div>
</dd>
<dt><a name="item353">[353]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.09156" title="Abstract">arXiv:2305.09156</a> (replaced) [<a href="/pdf/2305.09156" title="Download PDF">pdf</a>, <a href="/format/2305.09156" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Modelling Human Visual Motion Processing with Trainable Motion Energy  Sensing and a Self-attention Network
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sun%2C+Z">Zitang Sun</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yen-Ju Chen</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yung-hao Yang</a>, 
<a href="/search/cs?searchtype=author&query=Nishida%2C+S">Shin&#x27;ya Nishida</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> accepted by NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Neurons and Cognition (q-bio.NC)

</div>
</div>
</dd>
<dt><a name="item354">[354]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.09957" title="Abstract">arXiv:2305.09957</a> (replaced) [<a href="/pdf/2305.09957" title="Download PDF">pdf</a>, <a href="/format/2305.09957" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deep quantum neural networks form Gaussian processes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Garc%C3%ADa-Mart%C3%ADn%2C+D">Diego Garc&#xed;a-Mart&#xed;n</a>, 
<a href="/search/quant-ph?searchtype=author&query=Larocca%2C+M">Martin Larocca</a>, 
<a href="/search/quant-ph?searchtype=author&query=Cerezo%2C+M">M. Cerezo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12+36 pages, 3+6 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Machine Learning (cs.LG); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item355">[355]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.12553" title="Abstract">arXiv:2305.12553</a> (replaced) [<a href="/pdf/2305.12553" title="Download PDF">pdf</a>, <a href="/format/2305.12553" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Markov $&#x3b1;$-Potential Games: Equilibrium Approximation and Regret  Analysis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Guo%2C+X">Xin Guo</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xinyu Li</a>, 
<a href="/search/cs?searchtype=author&query=Maheshwari%2C+C">Chinmay Maheshwari</a>, 
<a href="/search/cs?searchtype=author&query=Sastry%2C+S">Shankar Sastry</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+M">Manxi Wu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 35 pages, 3 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>; Artificial Intelligence (cs.AI); Multiagent Systems (cs.MA); Systems and Control (eess.SY); Dynamical Systems (math.DS)

</div>
</div>
</dd>
<dt><a name="item356">[356]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.12998" title="Abstract">arXiv:2305.12998</a> (replaced) [<a href="/pdf/2305.12998" title="Download PDF">pdf</a>, <a href="/format/2305.12998" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MFT: Long-Term Tracking of Every Pixel
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Neoral%2C+M">Michal Neoral</a>, 
<a href="/search/cs?searchtype=author&query=%C5%A0er%C3%BDch%2C+J">Jon&#xe1;&#x161; &#x160;er&#xfd;ch</a>, 
<a href="/search/cs?searchtype=author&query=Matas%2C+J">Ji&#x159;&#xed; Matas</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> accepted to WACV 2024. Code at <a href="https://github.com/serycjon/MFT">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item357">[357]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.13385" title="Abstract">arXiv:2305.13385</a> (replaced) [<a href="/pdf/2305.13385" title="Download PDF">pdf</a>, <a href="/format/2305.13385" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Hybrid Communication Approach for Metadata Exchange in Geo-Distributed  Fog Computing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kruber%2C+M">Marvin Kruber</a>, 
<a href="/search/cs?searchtype=author&query=Pfandzelter%2C+T">Tobias Pfandzelter</a>, 
<a href="/search/cs?searchtype=author&query=Bermbach%2C+D">David Bermbach</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>

</div>
</div>
</dd>
<dt><a name="item358">[358]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.13971" title="Abstract">arXiv:2305.13971</a> (replaced) [<a href="/pdf/2305.13971" title="Download PDF">pdf</a>, <a href="/format/2305.13971" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Grammar-Constrained Decoding for Structured NLP Tasks without Finetuning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Geng%2C+S">Saibo Geng</a>, 
<a href="/search/cs?searchtype=author&query=Josifoski%2C+M">Martin Josifoski</a>, 
<a href="/search/cs?searchtype=author&query=Peyrard%2C+M">Maxime Peyrard</a>, 
<a href="/search/cs?searchtype=author&query=West%2C+R">Robert West</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at EMNLP 2023 Main Conference
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item359">[359]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.14016" title="Abstract">arXiv:2305.14016</a> (replaced) [<a href="/pdf/2305.14016" title="Download PDF">pdf</a>, <a href="/format/2305.14016" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Target-Agnostic Gender-Aware Contrastive Learning for Mitigating Bias in  Multilingual Machine Translation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lee%2C+M">Minwoo Lee</a>, 
<a href="/search/cs?searchtype=author&query=Koh%2C+H">Hyukhun Koh</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+K">Kang-il Lee</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+D">Dongdong Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+M">Minsung Kim</a>, 
<a href="/search/cs?searchtype=author&query=Jung%2C+K">Kyomin Jung</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to EMNLP 2023 Main Conference
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item360">[360]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.17328" title="Abstract">arXiv:2305.17328</a> (replaced) [<a href="/pdf/2305.17328" title="Download PDF">pdf</a>, <a href="/format/2305.17328" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Zero-TPrune: Zero-Shot Token Pruning through Leveraging of the Attention  Graph in Pre-Trained Transformers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Hongjie Wang</a>, 
<a href="/search/cs?searchtype=author&query=Dedhia%2C+B">Bhishma Dedhia</a>, 
<a href="/search/cs?searchtype=author&query=Jha%2C+N+K">Niraj K. Jha</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 18 pages, 20 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Image and Video Processing (eess.IV)

</div>
</div>
</dd>
<dt><a name="item361">[361]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.18292" title="Abstract">arXiv:2305.18292</a> (replaced) [<a href="/pdf/2305.18292" title="Download PDF">pdf</a>, <a href="/format/2305.18292" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Mix-of-Show: Decentralized Low-Rank Adaptation for Multi-Concept  Customization of Diffusion Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gu%2C+Y">Yuchao Gu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xintao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+J+Z">Jay Zhangjie Wu</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+Y">Yujun Shi</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yunpeng Chen</a>, 
<a href="/search/cs?searchtype=author&query=Fan%2C+Z">Zihan Fan</a>, 
<a href="/search/cs?searchtype=author&query=Xiao%2C+W">Wuyou Xiao</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+R">Rui Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Chang%2C+S">Shuning Chang</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+W">Weijia Wu</a>, 
<a href="/search/cs?searchtype=author&query=Ge%2C+Y">Yixiao Ge</a>, 
<a href="/search/cs?searchtype=author&query=Shan%2C+Y">Ying Shan</a>, 
<a href="/search/cs?searchtype=author&query=Shou%2C+M+Z">Mike Zheng Shou</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item362">[362]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.19429" title="Abstract">arXiv:2305.19429</a> (replaced) [<a href="/pdf/2305.19429" title="Download PDF">pdf</a>, <a href="/format/2305.19429" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Adapting Fairness Interventions to Missing Values
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Feng%2C+R">Raymond Feng</a>, 
<a href="/search/cs?searchtype=author&query=Calmon%2C+F+P">Flavio P. Calmon</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Hao Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computers and Society (cs.CY); Information Theory (cs.IT); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item363">[363]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.19454" title="Abstract">arXiv:2305.19454</a> (replaced) [<a href="/pdf/2305.19454" title="Download PDF">pdf</a>, <a href="/format/2305.19454" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Dynamic Sparsity Is Channel-Level Sparsity Learner
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yin%2C+L">Lu Yin</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+G">Gen Li</a>, 
<a href="/search/cs?searchtype=author&query=Fang%2C+M">Meng Fang</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+L">Li Shen</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+T">Tianjin Huang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zhangyang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Menkovski%2C+V">Vlado Menkovski</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+X">Xiaolong Ma</a>, 
<a href="/search/cs?searchtype=author&query=Pechenizkiy%2C+M">Mykola Pechenizkiy</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+S">Shiwei Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by the 37th Conference on Neural Information Processing Systems (NeurIPS 2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item364">[364]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.00297" title="Abstract">arXiv:2306.00297</a> (replaced) [<a href="/pdf/2306.00297" title="Download PDF">pdf</a>, <a href="/format/2306.00297" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Transformers learn to implement preconditioned gradient descent for  in-context learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ahn%2C+K">Kwangjun Ahn</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+X">Xiang Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Daneshmand%2C+H">Hadi Daneshmand</a>, 
<a href="/search/cs?searchtype=author&query=Sra%2C+S">Suvrit Sra</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Improved presentation and added new results for the nonlinear activation case; 37th Conference on Neural Information Processing Systems (NeurIPS 2023)
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> 37th Conference on Neural Information Processing Systems (NeurIPS
  2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item365">[365]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.05179" title="Abstract">arXiv:2306.05179</a> (replaced) [<a href="/pdf/2306.05179" title="Download PDF">pdf</a>, <a href="/format/2306.05179" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> M3Exam: A Multilingual, Multimodal, Multilevel Benchmark for Examining  Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+W">Wenxuan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Aljunied%2C+S+M">Sharifah Mahani Aljunied</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+C">Chang Gao</a>, 
<a href="/search/cs?searchtype=author&query=Chia%2C+Y+K">Yew Ken Chia</a>, 
<a href="/search/cs?searchtype=author&query=Bing%2C+L">Lidong Bing</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> NeurIPS 2023 (Datasets and Benchmarks)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item366">[366]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.05674" title="Abstract">arXiv:2306.05674</a> (replaced) [<a href="/pdf/2306.05674" title="Download PDF">pdf</a>, <a href="/format/2306.05674" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Efficient Uncertainty Quantification and Reduction for  Over-Parameterized Neural Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Huang%2C+Z">Ziyi Huang</a>, 
<a href="/search/stat?searchtype=author&query=Lam%2C+H">Henry Lam</a>, 
<a href="/search/stat?searchtype=author&query=Zhang%2C+H">Haofeng Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item367">[367]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.05780" title="Abstract">arXiv:2306.05780</a> (replaced) [<a href="/pdf/2306.05780" title="Download PDF">pdf</a>, <a href="/ps/2306.05780" title="Download PostScript">ps</a>, <a href="/format/2306.05780" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A space-time DG method for the Schr&#xf6;dinger equation with variable  potential
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=G%C3%B3mez%2C+S">Sergio G&#xf3;mez</a>, 
<a href="/search/math?searchtype=author&query=Moiola%2C+A">Andrea Moiola</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
</div>
</dd>
<dt><a name="item368">[368]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.08477" title="Abstract">arXiv:2306.08477</a> (replaced) [<a href="/pdf/2306.08477" title="Download PDF">pdf</a>, <a href="/format/2306.08477" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> From Driver to Supervisor: Comparing Cognitive Load and EEG-based  Attentional Resource Allocation across Automation Levels
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Figalov%C3%A1%2C+N">Nikol Figalov&#xe1;</a>, 
<a href="/search/cs?searchtype=author&query=Bieg%2C+H">Hans-Joachim Bieg</a>, 
<a href="/search/cs?searchtype=author&query=Reiser%2C+J+E">Julian Elias Reiser</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yuan-Cheng Liu</a>, 
<a href="/search/cs?searchtype=author&query=Baumann%2C+M">Martin Baumann</a>, 
<a href="/search/cs?searchtype=author&query=Chuang%2C+L">Lewis Chuang</a>, 
<a href="/search/cs?searchtype=author&query=Pollatos%2C+O">Olga Pollatos</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 17 pages, 4 figures
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> International Journal of Human-Computer Studies, Volume 182, 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
</div>
</dd>
<dt><a name="item369">[369]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.08616" title="Abstract">arXiv:2306.08616</a> (replaced) [<a href="/pdf/2306.08616" title="Download PDF">pdf</a>, <a href="/format/2306.08616" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Automatic Identification of Violation Symptoms of Architecture  Erosion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+R">Ruiyin Li</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+P">Peng Liang</a>, 
<a href="/search/cs?searchtype=author&query=Avgeriou%2C+P">Paris Avgeriou</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 20 pages, 4 images, 7 tables, Revision submitted to TSE (2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
</div>
</dd>
<dt><a name="item370">[370]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.09384" title="Abstract">arXiv:2306.09384</a> (replaced) [<a href="/pdf/2306.09384" title="Download PDF">pdf</a>, <a href="/format/2306.09384" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MobileASR: A resource-aware on-device learning framework for user voice  personalization applications on mobile phones
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Sasindran%2C+Z">Zitha Sasindran</a>, 
<a href="/search/eess?searchtype=author&query=Yelchuri%2C+H">Harsha Yelchuri</a>, 
<a href="/search/eess?searchtype=author&query=Rao%2C+P">Pooja Rao</a>, 
<a href="/search/eess?searchtype=author&query=Prabhakar%2C+T+V">T. V. Prabhakar</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted in AIMLSystems 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item371">[371]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.12818" title="Abstract">arXiv:2306.12818</a> (replaced) [<a href="/pdf/2306.12818" title="Download PDF">pdf</a>, <a href="/format/2306.12818" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> StrainTensorNet: Predicting crystal structure elastic properties using  SE(3)-equivariant graph neural networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cond-mat?searchtype=author&query=Pakornchote%2C+T">Teerachote Pakornchote</a>, 
<a href="/search/cond-mat?searchtype=author&query=Ektarawong%2C+A">Annop Ektarawong</a>, 
<a href="/search/cond-mat?searchtype=author&query=Chotibut%2C+T">Thiparat Chotibut</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 24 pages, 15 figures. Accepted for publication in Physical Review Research, with the model being renamed to StrainTensorNet
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Disordered Systems and Neural Networks (cond-mat.dis-nn)</span>; Materials Science (cond-mat.mtrl-sci); Machine Learning (cs.LG); Computational Physics (physics.comp-ph)

</div>
</div>
</dd>
<dt><a name="item372">[372]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.13001" title="Abstract">arXiv:2306.13001</a> (replaced) [<a href="/pdf/2306.13001" title="Download PDF">pdf</a>, <a href="/format/2306.13001" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Sixth-Order Hybrid Finite Difference Methods for Elliptic Interface  Problems with Mixed Boundary Conditions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Feng%2C+Q">Qiwei Feng</a>, 
<a href="/search/math?searchtype=author&query=Han%2C+B">Bin Han</a>, 
<a href="/search/math?searchtype=author&query=Minev%2C+P">Peter Minev</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
</div>
</dd>
<dt><a name="item373">[373]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.13302" title="Abstract">arXiv:2306.13302</a> (replaced) [<a href="/pdf/2306.13302" title="Download PDF">pdf</a>, <a href="/ps/2306.13302" title="Download PostScript">ps</a>, <a href="/format/2306.13302" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An Overview about Emerging Technologies of Autonomous Driving
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+Y">Yu Huang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yue Chen</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Z">Zijiang Yang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item374">[374]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.15362" title="Abstract">arXiv:2306.15362</a> (replaced) [<a href="/pdf/2306.15362" title="Download PDF">pdf</a>, <a href="/format/2306.15362" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Planning Landmark Based Goal Recognition Revisited: Does Using Initial  State Landmarks Make Sense?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wilken%2C+N">Nils Wilken</a>, 
<a href="/search/cs?searchtype=author&query=Cohausz%2C+L">Lea Cohausz</a>, 
<a href="/search/cs?searchtype=author&query=Bartelt%2C+C">Christian Bartelt</a>, 
<a href="/search/cs?searchtype=author&query=Stuckenschmidt%2C+H">Heiner Stuckenschmidt</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Full publication: Wilken, N., Cohausz, L., Bartelt, C., Stuckenschmidt, H. (2023). Planning Landmark Based Goal Recognition Revisited: Does Using Initial State Landmarks Make Sense?. In: Seipel, D., Steen, A. (eds) KI 2023: Advances in Artificial Intelligence. KI 2023. Lecture Notes in Computer Science(), vol 14236. Springer, Cham. arXiv admin note: text overlap with <a href="/abs/2301.10571">arXiv:2301.10571</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
</div>
</dd>
<dt><a name="item375">[375]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.15410" title="Abstract">arXiv:2306.15410</a> (replaced) [<a href="/pdf/2306.15410" title="Download PDF">pdf</a>, <a href="/format/2306.15410" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AutoGraph: Predicting Lane Graphs from Traffic Observations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Z%C3%BCrn%2C+J">Jannik Z&#xfc;rn</a>, 
<a href="/search/cs?searchtype=author&query=Posner%2C+I">Ingmar Posner</a>, 
<a href="/search/cs?searchtype=author&query=Burgard%2C+W">Wolfram Burgard</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 6 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item376">[376]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.16838" title="Abstract">arXiv:2306.16838</a> (replaced) [<a href="/pdf/2306.16838" title="Download PDF">pdf</a>, <a href="/format/2306.16838" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Solving Kernel Ridge Regression with Gradient-Based Optimization Methods
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Allerbo%2C+O">Oskar Allerbo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Article <a href="/abs/2306.16838">arXiv:2306.16838v1</a> has been updated and split into two articles: this article and <a href="/abs/2311.01762">arXiv:2311.01762</a>. Thus, some of the content in <a href="/abs/2306.16838">arXiv:2306.16838v1</a> is not a part of <a href="/abs/2306.16838">arXiv:2306.16838v2</a>, but of <a href="/abs/2311.01762">arXiv:2311.01762</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG); Optimization and Control (math.OC); Methodology (stat.ME)

</div>
</div>
</dd>
<dt><a name="item377">[377]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.17473" title="Abstract">arXiv:2306.17473</a> (replaced) [<a href="/pdf/2306.17473" title="Download PDF">pdf</a>, <a href="/ps/2306.17473" title="Download PostScript">ps</a>, <a href="/format/2306.17473" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An Orbital Solution for WASP-12 b: Updated Ephemeris and Evidence for  Decay Leveraging Citizen Science Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/astro-ph?searchtype=author&query=Nediyedath%2C+A+S">Avinash S. Nediyedath</a>, 
<a href="/search/astro-ph?searchtype=author&query=Fowler%2C+M+J">Martin J. Fowler</a>, 
<a href="/search/astro-ph?searchtype=author&query=Norris%2C+A">A. Norris</a>, 
<a href="/search/astro-ph?searchtype=author&query=Maidur%2C+S+R">Shivaraj R. Maidur</a>, 
<a href="/search/astro-ph?searchtype=author&query=Pearson%2C+K+A">Kyle A. Pearson</a>, 
<a href="/search/astro-ph?searchtype=author&query=Dixon%2C+S">S. Dixon</a>, 
<a href="/search/astro-ph?searchtype=author&query=Lewin%2C+P">P. Lewin</a>, 
<a href="/search/astro-ph?searchtype=author&query=Kovacs%2C+A+O">Andre O. Kovacs</a>, 
<a href="/search/astro-ph?searchtype=author&query=Odasso%2C+A">A. Odasso</a>, 
<a href="/search/astro-ph?searchtype=author&query=Davis%2C+K">K. Davis</a>, 
<a href="/search/astro-ph?searchtype=author&query=Primm%2C+M">M. Primm</a>, 
<a href="/search/astro-ph?searchtype=author&query=Das%2C+P">P. Das</a>, 
<a href="/search/astro-ph?searchtype=author&query=Martin%2C+B+E">Bryan E. Martin</a>, 
<a href="/search/astro-ph?searchtype=author&query=Lalla%2C+D">D. Lalla</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> <a href="https://app.aavso.org/jaavso/article/3901/">this https URL</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> JAAVSO Volume 51 number 2 (2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Earth and Planetary Astrophysics (astro-ph.EP)</span>; Computers and Society (cs.CY); Physics and Society (physics.soc-ph)

</div>
</div>
</dd>
<dt><a name="item378">[378]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.01073" title="Abstract">arXiv:2307.01073</a> (replaced) [<a href="/pdf/2307.01073" title="Download PDF">pdf</a>, <a href="/format/2307.01073" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> What Distributions are Robust to Indiscriminate Poisoning Attacks for  Linear Learners?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Suya%2C+F">Fnu Suya</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xiao Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Tian%2C+Y">Yuan Tian</a>, 
<a href="/search/cs?searchtype=author&query=Evans%2C+D">David Evans</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> NeurIPS 2023 camera-ready version, 39 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Cryptography and Security (cs.CR)

</div>
</div>
</dd>
<dt><a name="item379">[379]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.02509" title="Abstract">arXiv:2307.02509</a> (replaced) [<a href="/pdf/2307.02509" title="Download PDF">pdf</a>, <a href="/format/2307.02509" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Wasserstein Auto-Encoders of Merge Trees (and Persistence Diagrams)
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pont%2C+M">Mahieu Pont</a>, 
<a href="/search/cs?searchtype=author&query=Tierny%2C+J">Julien Tierny</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: text overlap with <a href="/abs/2207.10960">arXiv:2207.10960</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computational Geometry (cs.CG); Computer Vision and Pattern Recognition (cs.CV); Graphics (cs.GR)

</div>
</div>
</dd>
<dt><a name="item380">[380]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.03604" title="Abstract">arXiv:2307.03604</a> (replaced) [<a href="/pdf/2307.03604" title="Download PDF">pdf</a>, <a href="/ps/2307.03604" title="Download PostScript">ps</a>, <a href="/format/2307.03604" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Cascading Failures in the Global Financial System: A Dynamical Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Stella%2C+L">Leonardo Stella</a>, 
<a href="/search/math?searchtype=author&query=Bauso%2C+D">Dario Bauso</a>, 
<a href="/search/math?searchtype=author&query=Blanchini%2C+F">Franco Blanchini</a>, 
<a href="/search/math?searchtype=author&query=Colaneri%2C+P">Patrizio Colaneri</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Systems and Control (eess.SY)

</div>
</div>
</dd>
<dt><a name="item381">[381]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.05016" title="Abstract">arXiv:2307.05016</a> (replaced) [<a href="/pdf/2307.05016" title="Download PDF">pdf</a>, <a href="/format/2307.05016" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> TRansPose: Large-Scale Multispectral Dataset for Transparent Object
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kim%2C+J">Jeongyun Kim</a>, 
<a href="/search/cs?searchtype=author&query=Jeon%2C+M">Myung-Hwan Jeon</a>, 
<a href="/search/cs?searchtype=author&query=Jung%2C+S">Sangwoo Jung</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+W">Wooseong Yang</a>, 
<a href="/search/cs?searchtype=author&query=Jung%2C+M">Minwoo Jung</a>, 
<a href="/search/cs?searchtype=author&query=Shin%2C+J">Jaeho Shin</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+A">Ayoung Kim</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> The International Journal of Robotics Research (IJRR)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Robotics (cs.RO)

</div>
</div>
</dd>
<dt><a name="item382">[382]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.05936" title="Abstract">arXiv:2307.05936</a> (replaced) [<a href="/pdf/2307.05936" title="Download PDF">pdf</a>, <a href="/format/2307.05936" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Introducing Packet-Level Analysis in Programmable Data Planes to Advance  Network Intrusion Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Doriguzzi-Corin%2C+R">Roberto Doriguzzi-Corin</a>, 
<a href="/search/cs?searchtype=author&query=Knob%2C+L+A+D">Luis Augusto Dias Knob</a>, 
<a href="/search/cs?searchtype=author&query=Mendozzi%2C+L">Luca Mendozzi</a>, 
<a href="/search/cs?searchtype=author&query=Siracusa%2C+D">Domenico Siracusa</a>, 
<a href="/search/cs?searchtype=author&query=Savi%2C+M">Marco Savi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Networking and Internet Architecture (cs.NI)

</div>
</div>
</dd>
<dt><a name="item383">[383]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.06285" title="Abstract">arXiv:2307.06285</a> (replaced) [<a href="/pdf/2307.06285" title="Download PDF">pdf</a>, <a href="/ps/2307.06285" title="Download PostScript">ps</a>, <a href="/format/2307.06285" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Smoothed Analysis of the Koml&#xf3;s Conjecture: Rademacher Noise
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Aigner-Horev%2C+E">Elad Aigner-Horev</a>, 
<a href="/search/math?searchtype=author&query=Hefetz%2C+D">Dan Hefetz</a>, 
<a href="/search/math?searchtype=author&query=Trushkin%2C+M">Michael Trushkin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> For version 3, some oversights have been corrected and more importantly the dependency between n and d has been significantly improved to reach optimum. For Version 4 we simply forgot to update the abstract in the Arxiv metadata as to reflect the optimality of the relation of n and d
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Combinatorics (math.CO)</span>; Discrete Mathematics (cs.DM); Information Theory (cs.IT); Probability (math.PR)

</div>
</div>
</dd>
<dt><a name="item384">[384]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.11349" title="Abstract">arXiv:2307.11349</a> (replaced) [<a href="/pdf/2307.11349" title="Download PDF">pdf</a>, <a href="/format/2307.11349" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> EV-Planner: Energy-Efficient Robot Navigation via Event-Based  Physics-Guided Neuromorphic Planner
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sanyal%2C+S">Sourav Sanyal</a>, 
<a href="/search/cs?searchtype=author&query=Manna%2C+R+K">Rohan Kumar Manna</a>, 
<a href="/search/cs?searchtype=author&query=Roy%2C+K">Kaushik Roy</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
</div>
</dd>
<dt><a name="item385">[385]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.14899" title="Abstract">arXiv:2307.14899</a> (replaced) [<a href="/pdf/2307.14899" title="Download PDF">pdf</a>, <a href="/format/2307.14899" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Retrieval-based Text Selection for Addressing Class-Imbalanced Data in  Classification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ahmadi%2C+S">Sareh Ahmadi</a>, 
<a href="/search/cs?searchtype=author&query=Shah%2C+A">Aditya Shah</a>, 
<a href="/search/cs?searchtype=author&query=Fox%2C+E">Edward Fox</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item386">[386]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.15870" title="Abstract">arXiv:2307.15870</a> (replaced) [<a href="/pdf/2307.15870" title="Download PDF">pdf</a>, <a href="/format/2307.15870" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Efficient Semi-Supervised Federated Learning for Heterogeneous  Participants
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sun%2C+Z">Zhipeng Sun</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+Y">Yang Xu</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+H">Hongli Xu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zhiyuan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Liao%2C+Y">Yunming Liao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 pages, 12 figures, conference
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Distributed, Parallel, and Cluster Computing (cs.DC)

</div>
</div>
</dd>
<dt><a name="item387">[387]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.00177" title="Abstract">arXiv:2308.00177</a> (replaced) [<a href="/pdf/2308.00177" title="Download PDF">pdf</a>, <a href="/format/2308.00177" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Pretrained deep models outperform GBDTs in Learning-To-Rank under label  scarcity
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hou%2C+C">Charlie Hou</a>, 
<a href="/search/cs?searchtype=author&query=Thekumparampil%2C+K+K">Kiran Koshy Thekumparampil</a>, 
<a href="/search/cs?searchtype=author&query=Shavlovsky%2C+M">Michael Shavlovsky</a>, 
<a href="/search/cs?searchtype=author&query=Fanti%2C+G">Giulia Fanti</a>, 
<a href="/search/cs?searchtype=author&query=Dattatreya%2C+Y">Yesh Dattatreya</a>, 
<a href="/search/cs?searchtype=author&query=Sanghavi%2C+S">Sujay Sanghavi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ICML-MFPL 2023 Workshop Oral
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item388">[388]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.02442" title="Abstract">arXiv:2308.02442</a> (replaced) [<a href="/pdf/2308.02442" title="Download PDF">pdf</a>, <a href="/format/2308.02442" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Distribution-Informed Adaptation for kNN Graph Construction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Min%2C+S">Shaojie Min</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Ji Liu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Information Retrieval (cs.IR); Social and Information Networks (cs.SI)

</div>
</div>
</dd>
<dt><a name="item389">[389]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.07827" title="Abstract">arXiv:2308.07827</a> (replaced) [<a href="/pdf/2308.07827" title="Download PDF">pdf</a>, <a href="/format/2308.07827" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning Better Keypoints for Multi-Object 6DoF Pose Estimation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+Y">Yangzheng Wu</a>, 
<a href="/search/cs?searchtype=author&query=Greenspan%2C+M">Michael Greenspan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> WACV 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item390">[390]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.09876" title="Abstract">arXiv:2308.09876</a> (replaced) [<a href="/pdf/2308.09876" title="Download PDF">pdf</a>, <a href="/format/2308.09876" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Characterizing Usability Issue Discussions in Open Source Software  Projects
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sanei%2C+A">Arghavan Sanei</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+J">Jinghui Cheng</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 26 pages, 2 figures, accepted to CSCW2024; supplementary material available at: <a href="https://github.com/HCDLab/UsabilityIssuesSupplementaryMaterial">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Software Engineering (cs.SE)

</div>
</div>
</dd>
<dt><a name="item391">[391]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10664" title="Abstract">arXiv:2308.10664</a> (replaced) [<a href="/pdf/2308.10664" title="Download PDF">pdf</a>, <a href="/format/2308.10664" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Safe Deep Reinforcement Learning Approach for Energy Efficient  Federated Learning in Wireless Communication Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Koursioumpas%2C+N">Nikolaos Koursioumpas</a>, 
<a href="/search/cs?searchtype=author&query=Magoula%2C+L">Lina Magoula</a>, 
<a href="/search/cs?searchtype=author&query=Petropouleas%2C+N">Nikolaos Petropouleas</a>, 
<a href="/search/cs?searchtype=author&query=Thanopoulos%2C+A">Alexandros-Ioannis Thanopoulos</a>, 
<a href="/search/cs?searchtype=author&query=Panagea%2C+T">Theodora Panagea</a>, 
<a href="/search/cs?searchtype=author&query=Alonistioti%2C+N">Nancy Alonistioti</a>, 
<a href="/search/cs?searchtype=author&query=Gutierrez-Estevez%2C+M+A">M. A. Gutierrez-Estevez</a>, 
<a href="/search/cs?searchtype=author&query=Khalili%2C+R">Ramin Khalili</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> R1 Phase of Revisions. 29 Pages Single Column, 6 Figures, Submitted for possible publication in the IEEE Transactions on Green Communications and Networking (TGCN). arXiv admin note: text overlap with <a href="/abs/2306.14237">arXiv:2306.14237</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item392">[392]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10697" title="Abstract">arXiv:2308.10697</a> (replaced) [<a href="/pdf/2308.10697" title="Download PDF">pdf</a>, <a href="/format/2308.10697" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Beyond expectations: Residual Dynamic Mode Decomposition and Variance  for Stochastic Dynamical Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Colbrook%2C+M+J">Matthew J. Colbrook</a>, 
<a href="/search/math?searchtype=author&query=Li%2C+Q">Qin Li</a>, 
<a href="/search/math?searchtype=author&query=Raut%2C+R+V">Ryan V. Raut</a>, 
<a href="/search/math?searchtype=author&query=Townsend%2C+A">Alex Townsend</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Dynamical Systems (math.DS)</span>; Machine Learning (cs.LG); Numerical Analysis (math.NA); Spectral Theory (math.SP); Chaotic Dynamics (nlin.CD)

</div>
</div>
</dd>
<dt><a name="item393">[393]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.12483" title="Abstract">arXiv:2308.12483</a> (replaced) [<a href="/pdf/2308.12483" title="Download PDF">pdf</a>, <a href="/ps/2308.12483" title="Download PostScript">ps</a>, <a href="/format/2308.12483" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Linear-Sized Spectral Sparsifiers and the Kadison-Singer Problem
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Paschalidis%2C+P">Phevos Paschalidis</a>, 
<a href="/search/cs?searchtype=author&query=Zhuang%2C+A">Ashley Zhuang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>; Discrete Mathematics (cs.DM); Combinatorics (math.CO)

</div>
</div>
</dd>
<dt><a name="item394">[394]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.14960" title="Abstract">arXiv:2308.14960</a> (replaced) [<a href="/pdf/2308.14960" title="Download PDF">pdf</a>, <a href="/format/2308.14960" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Read-only Prompt Optimization for Vision-Language Few-shot Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lee%2C+D">Dongjun Lee</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+S">Seokwon Song</a>, 
<a href="/search/cs?searchtype=author&query=Suh%2C+J">Jihee Suh</a>, 
<a href="/search/cs?searchtype=author&query=Choi%2C+J">Joonmyung Choi</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+S">Sanghyeok Lee</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+H+J">Hyunwoo J.Kim</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at ICCV2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item395">[395]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.15158" title="Abstract">arXiv:2308.15158</a> (replaced) [<a href="/pdf/2308.15158" title="Download PDF">pdf</a>, <a href="/format/2308.15158" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An Advanced Tree Algorithm with Interference Cancellation in Uplink and  Downlink
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Vogel%2C+Q">Quirin Vogel</a>, 
<a href="/search/cs?searchtype=author&query=Deshpande%2C+Y">Yash Deshpande</a>, 
<a href="/search/cs?searchtype=author&query=Stefanovi%C4%87%2C+%C4%8C">&#x10c;edomir Stefanovi&#x107;</a>, 
<a href="/search/cs?searchtype=author&query=Kellerer%2C+W">Wolfgang Kellerer</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This paper was be presented at the ASILOMAR Conference on Signals, Systems, and Computers. Copyright IEEE 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Networking and Internet Architecture (cs.NI)

</div>
</div>
</dd>
<dt><a name="item396">[396]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08036" title="Abstract">arXiv:2309.08036</a> (replaced) [<a href="/pdf/2309.08036" title="Download PDF">pdf</a>, <a href="/format/2309.08036" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> BEA: Revisiting anchor-based object detection DNN using Budding Ensemble  Architecture
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Qutub%2C+S+S">Syed Sha Qutub</a>, 
<a href="/search/cs?searchtype=author&query=Kose%2C+N">Neslihan Kose</a>, 
<a href="/search/cs?searchtype=author&query=Rosales%2C+R">Rafael Rosales</a>, 
<a href="/search/cs?searchtype=author&query=Paulitsch%2C+M">Michael Paulitsch</a>, 
<a href="/search/cs?searchtype=author&query=Hagn%2C+K">Korbinian Hagn</a>, 
<a href="/search/cs?searchtype=author&query=Geissler%2C+F">Florian Geissler</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+Y">Yang Peng</a>, 
<a href="/search/cs?searchtype=author&query=Hinz%2C+G">Gereon Hinz</a>, 
<a href="/search/cs?searchtype=author&query=Knoll%2C+A">Alois Knoll</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages, 5 pages supplementary material. Accepted at BMVC-2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item397">[397]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.09609" title="Abstract">arXiv:2309.09609</a> (replaced) [<a href="/pdf/2309.09609" title="Download PDF">pdf</a>, <a href="/format/2309.09609" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Comparing Performance and Portability between CUDA and SYCL for Protein  Database Search on NVIDIA, AMD, and Intel GPUs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Costanzo%2C+M">Manuel Costanzo</a>, 
<a href="/search/cs?searchtype=author&query=Rucci%2C+E">Enzo Rucci</a>, 
<a href="/search/cs?searchtype=author&query=S%C3%A1nchez%2C+C+G">Carlos Garc&#xed;a S&#xe1;nchez</a>, 
<a href="/search/cs?searchtype=author&query=Naiouf%2C+M">Marcelo Naiouf</a>, 
<a href="/search/cs?searchtype=author&query=Prieto-Mat%C3%ADas%2C+M">Manuel Prieto-Mat&#xed;as</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This article was accepted for publication in 2023 IEEE 35th International Symposium on Computer Architecture and High Performance Computing (SBAC-PAD)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Programming Languages (cs.PL)</span>

</div>
</div>
</dd>
<dt><a name="item398">[398]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.12482" title="Abstract">arXiv:2309.12482</a> (replaced) [<a href="/pdf/2309.12482" title="Download PDF">pdf</a>, <a href="/format/2309.12482" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> State2Explanation: Concept-Based Explanations to Benefit Agent Learning  and User Understanding
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Das%2C+D">Devleena Das</a>, 
<a href="/search/cs?searchtype=author&query=Chernova%2C+S">Sonia Chernova</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+B">Been Kim</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item399">[399]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.12981" title="Abstract">arXiv:2309.12981</a> (replaced) [<a href="/pdf/2309.12981" title="Download PDF">pdf</a>, <a href="/ps/2309.12981" title="Download PostScript">ps</a>, <a href="/format/2309.12981" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Wordification: A New Way of Teaching English Spelling Patterns
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Whalen%2C+L">Lexington Whalen</a>, 
<a href="/search/cs?searchtype=author&query=Bickel%2C+N">Nathan Bickel</a>, 
<a href="/search/cs?searchtype=author&query=Comandur%2C+S">Shash Comandur</a>, 
<a href="/search/cs?searchtype=author&query=Craven%2C+D">Dalton Craven</a>, 
<a href="/search/cs?searchtype=author&query=Dubinsky%2C+S">Stanley Dubinsky</a>, 
<a href="/search/cs?searchtype=author&query=Valafar%2C+H">Homayoun Valafar</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 7 figures, IEEE International Conference on Frontiers in Education
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Other Computer Science (cs.OH)</span>; Computation and Language (cs.CL)

</div>
</div>
</dd>
<dt><a name="item400">[400]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13135" title="Abstract">arXiv:2309.13135</a> (replaced) [<a href="/pdf/2309.13135" title="Download PDF">pdf</a>, <a href="/format/2309.13135" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Forecasting Response to Treatment with Global Deep Learning and  Patient-Specific Pharmacokinetic Priors
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Potosnak%2C+W">Willa Potosnak</a>, 
<a href="/search/cs?searchtype=author&query=Challu%2C+C">Cristian Challu</a>, 
<a href="/search/cs?searchtype=author&query=Olivares%2C+K+G">Kin G. Olivares</a>, 
<a href="/search/cs?searchtype=author&query=Dubrawski%2C+A">Artur Dubrawski</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Extended Abstract presented at Machine Learning for Health (ML4H) symposium 2023, December 10th, 2023, New Orleans, United States, 8 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Quantitative Methods (q-bio.QM)

</div>
</div>
</dd>
<dt><a name="item401">[401]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15877" title="Abstract">arXiv:2309.15877</a> (replaced) [<a href="/pdf/2309.15877" title="Download PDF">pdf</a>, <a href="/format/2309.15877" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Neuro-Inspired Hierarchical Multimodal Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xiao%2C+X">Xiongye Xiao</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+G">Gengshuo Liu</a>, 
<a href="/search/cs?searchtype=author&query=Gupta%2C+G">Gaurav Gupta</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+D">Defu Cao</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+S">Shixuan Li</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yaxing Li</a>, 
<a href="/search/cs?searchtype=author&query=Fang%2C+T">Tianqing Fang</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+M">Mingxi Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Bogdan%2C+P">Paul Bogdan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item402">[402]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.17340" title="Abstract">arXiv:2309.17340</a> (replaced) [<a href="/pdf/2309.17340" title="Download PDF">pdf</a>, <a href="/format/2309.17340" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Outage-Watch: Early Prediction of Outages using Extreme Event  Regularizer
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Agarwal%2C+S">Shubham Agarwal</a>, 
<a href="/search/cs?searchtype=author&query=Chakraborty%2C+S">Sarthak Chakraborty</a>, 
<a href="/search/cs?searchtype=author&query=Garg%2C+S">Shaddy Garg</a>, 
<a href="/search/cs?searchtype=author&query=Bisht%2C+S">Sumit Bisht</a>, 
<a href="/search/cs?searchtype=author&query=Jain%2C+C">Chahat Jain</a>, 
<a href="/search/cs?searchtype=author&query=Gonuguntla%2C+A">Ashritha Gonuguntla</a>, 
<a href="/search/cs?searchtype=author&query=Saini%2C+S">Shiv Saini</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to ESEC/FSE 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item403">[403]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.00233" title="Abstract">arXiv:2310.00233</a> (replaced) [<a href="/pdf/2310.00233" title="Download PDF">pdf</a>, <a href="/format/2310.00233" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CausalImages: An R Package for Causal Inference with Earth Observation,  Bio-medical, and Social Science Images
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jerzak%2C+C+T">Connor T. Jerzak</a>, 
<a href="/search/cs?searchtype=author&query=Daoud%2C+A">Adel Daoud</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> For accompanying software, see <a href="https://github.com/AIandGlobalDevelopmentLab/causalimages-software">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Methodology (stat.ME)

</div>
</div>
</dd>
<dt><a name="item404">[404]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.00564" title="Abstract">arXiv:2310.00564</a> (replaced) [<a href="/pdf/2310.00564" title="Download PDF">pdf</a>, <a href="/format/2310.00564" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DYNAP-SE2: a scalable multi-core dynamic neuromorphic asynchronous  spiking neural network processor
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Richter%2C+O">Ole Richter</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+C">Chenxi Wu</a>, 
<a href="/search/cs?searchtype=author&query=Whatley%2C+A+M">Adrian M. Whatley</a>, 
<a href="/search/cs?searchtype=author&query=K%C3%B6stinger%2C+G">German K&#xf6;stinger</a>, 
<a href="/search/cs?searchtype=author&query=Nielsen%2C+C">Carsten Nielsen</a>, 
<a href="/search/cs?searchtype=author&query=Qiao%2C+N">Ning Qiao</a>, 
<a href="/search/cs?searchtype=author&query=Indiveri%2C+G">Giacomo Indiveri</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> *Ole Richter and Chenxi Wu contributed equally
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neural and Evolutionary Computing (cs.NE)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item405">[405]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.00723" title="Abstract">arXiv:2310.00723</a> (replaced) [<a href="/pdf/2310.00723" title="Download PDF">pdf</a>, <a href="/format/2310.00723" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> HOH: Markerless Multimodal Human-Object-Human Handover Dataset with  Large Object Count
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wiederhold%2C+N">Noah Wiederhold</a>, 
<a href="/search/cs?searchtype=author&query=Megyeri%2C+A">Ava Megyeri</a>, 
<a href="/search/cs?searchtype=author&query=Paris%2C+D">DiMaggio Paris</a>, 
<a href="/search/cs?searchtype=author&query=Banerjee%2C+S">Sean Banerjee</a>, 
<a href="/search/cs?searchtype=author&query=Banerjee%2C+N+K">Natasha Kholgade Banerjee</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> NeurIPS 2023 Datasets and Benchmarks
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Robotics (cs.RO)

</div>
</div>
</dd>
<dt><a name="item406">[406]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.02232" title="Abstract">arXiv:2310.02232</a> (replaced) [<a href="/pdf/2310.02232" title="Download PDF">pdf</a>, <a href="/format/2310.02232" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> HoloNets: Spectral Convolutions do extend to Directed Graphs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Koke%2C+C">Christian Koke</a>, 
<a href="/search/cs?searchtype=author&query=Cremers%2C+D">Daniel Cremers</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: text overlap with <a href="/abs/2310.00431">arXiv:2310.00431</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Social and Information Networks (cs.SI)

</div>
</div>
</dd>
<dt><a name="item407">[407]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.02416" title="Abstract">arXiv:2310.02416</a> (replaced) [<a href="/pdf/2310.02416" title="Download PDF">pdf</a>, <a href="/format/2310.02416" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Bag of Tricks for Fully Test-Time Adaptation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mounsaveng%2C+S">Saypraseuth Mounsaveng</a>, 
<a href="/search/cs?searchtype=author&query=Chiaroni%2C+F">Florent Chiaroni</a>, 
<a href="/search/cs?searchtype=author&query=Boudiaf%2C+M">Malik Boudiaf</a>, 
<a href="/search/cs?searchtype=author&query=Pedersoli%2C+M">Marco Pedersoli</a>, 
<a href="/search/cs?searchtype=author&query=Ayed%2C+I+B">Ismail Ben Ayed</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at WACV 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item408">[408]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.02519" title="Abstract">arXiv:2310.02519</a> (replaced) [<a href="/pdf/2310.02519" title="Download PDF">pdf</a>, <a href="/format/2310.02519" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Parameterized Convex Minorant for Objective Function Approximation in  Amortized Optimization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kim%2C+J">Jinrae Kim</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+Y">Youdan Kim</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 4 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Optimization and Control (math.OC)

</div>
</div>
</dd>
<dt><a name="item409">[409]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.02919" title="Abstract">arXiv:2310.02919</a> (replaced) [<a href="/pdf/2310.02919" title="Download PDF">pdf</a>, <a href="/format/2310.02919" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Attention-based Multi-task Learning for Base Editor Outcome Prediction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mollaysa%2C+A">Amina Mollaysa</a>, 
<a href="/search/cs?searchtype=author&query=Allam%2C+A">Ahmed Allam</a>, 
<a href="/search/cs?searchtype=author&query=Krauthammer%2C+M">Michael Krauthammer</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item410">[410]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.03192" title="Abstract">arXiv:2310.03192</a> (replaced) [<a href="/pdf/2310.03192" title="Download PDF">pdf</a>, <a href="/format/2310.03192" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Generative AI in the Classroom: Can Students Remain Active Learners?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Abdelghani%2C+R">Rania Abdelghani</a>, 
<a href="/search/cs?searchtype=author&query=Sauz%C3%A9on%2C+H">H&#xe9;l&#xe8;ne Sauz&#xe9;on</a>, 
<a href="/search/cs?searchtype=author&query=Oudeyer%2C+P">Pierre-Yves Oudeyer</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>

</div>
</div>
</dd>
<dt><a name="item411">[411]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.04010" title="Abstract">arXiv:2310.04010</a> (replaced) [<a href="/pdf/2310.04010" title="Download PDF">pdf</a>, <a href="/format/2310.04010" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Excision And Recovery: Visual Defect Obfuscation Based Self-Supervised  Anomaly Detection Strategy
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Park%2C+Y">YeongHyeon Park</a>, 
<a href="/search/cs?searchtype=author&query=Kang%2C+S">Sungho Kang</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+M+J">Myung Jin Kim</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+Y">Yeonho Lee</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+H+S">Hyeong Seok Kim</a>, 
<a href="/search/cs?searchtype=author&query=Yi%2C+J">Juneho Yi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 5 figures, 5 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Image and Video Processing (eess.IV)

</div>
</div>
</dd>
<dt><a name="item412">[412]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.04213" title="Abstract">arXiv:2310.04213</a> (replaced) [<a href="/pdf/2310.04213" title="Download PDF">pdf</a>, <a href="/format/2310.04213" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Topology-Aware Neural Networks for Fast Contingency Analysis of Power  Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Nakiganda%2C+A+M">Agnes M. Nakiganda</a>, 
<a href="/search/eess?searchtype=author&query=Cheylan%2C+C">Catherine Cheylan</a>, 
<a href="/search/eess?searchtype=author&query=Chatzivasileiadis%2C+S">Spyros Chatzivasileiadis</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
</div>
</dd>
<dt><a name="item413">[413]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.04935" title="Abstract">arXiv:2310.04935</a> (replaced) [<a href="/pdf/2310.04935" title="Download PDF">pdf</a>, <a href="/format/2310.04935" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Statistical Guarantees for Variational Autoencoders using PAC-Bayesian  Theory
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mbacke%2C+S+D">Sokhna Diarra Mbacke</a>, 
<a href="/search/cs?searchtype=author&query=Clerc%2C+F">Florence Clerc</a>, 
<a href="/search/cs?searchtype=author&query=Germain%2C+P">Pascal Germain</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Spotlight Paper at NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item414">[414]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.05057" title="Abstract">arXiv:2310.05057</a> (replaced) [<a href="/pdf/2310.05057" title="Download PDF">pdf</a>, <a href="/format/2310.05057" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> BRAINTEASER: Lateral Thinking Puzzles for Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jiang%2C+Y">Yifan Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Ilievski%2C+F">Filip Ilievski</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+K">Kaixin Ma</a>, 
<a href="/search/cs?searchtype=author&query=Sourati%2C+Z">Zhivar Sourati</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item415">[415]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.06079" title="Abstract">arXiv:2310.06079</a> (replaced) [<a href="/pdf/2310.06079" title="Download PDF">pdf</a>, <a href="/format/2310.06079" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Anomalous diffusion and price impact in the fluid-limit of an order book
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-fin?searchtype=author&query=Diana%2C+D">Derick Diana</a>, 
<a href="/search/q-fin?searchtype=author&query=Gebbie%2C+T">Tim Gebbie</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 35 pages, 23 figures, 4 tables; streamlined discussion
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Finance (q-fin.CP)</span>; Computational Engineering, Finance, and Science (cs.CE); Adaptation and Self-Organizing Systems (nlin.AO); Trading and Market Microstructure (q-fin.TR)

</div>
</div>
</dd>
<dt><a name="item416">[416]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.06552" title="Abstract">arXiv:2310.06552</a> (replaced) [<a href="/pdf/2310.06552" title="Download PDF">pdf</a>, <a href="/format/2310.06552" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Automated clinical coding using off-the-shelf large language models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Boyle%2C+J+S">Joseph S. Boyle</a>, 
<a href="/search/cs?searchtype=author&query=Kascenas%2C+A">Antanas Kascenas</a>, 
<a href="/search/cs?searchtype=author&query=Lok%2C+P">Pat Lok</a>, 
<a href="/search/cs?searchtype=author&query=Liakata%2C+M">Maria Liakata</a>, 
<a href="/search/cs?searchtype=author&query=O%27Neil%2C+A+Q">Alison Q. O&#x27;Neil</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to the NeurIPS 2023 workshop Deep Generative Models For Health (DGM4H). 9 pages, 3 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computation and Language (cs.CL)

</div>
</div>
</dd>
<dt><a name="item417">[417]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07325" title="Abstract">arXiv:2310.07325</a> (replaced) [<a href="/pdf/2310.07325" title="Download PDF">pdf</a>, <a href="/format/2310.07325" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An Adversarial Example for Direct Logit Attribution: Memory Management  in gelu-4l
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dao%2C+J">James Dao</a>, 
<a href="/search/cs?searchtype=author&query=Lau%2C+Y">Yeu-Tong Lau</a>, 
<a href="/search/cs?searchtype=author&query=Rager%2C+C">Can Rager</a>, 
<a href="/search/cs?searchtype=author&query=Janiak%2C+J">Jett Janiak</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item418">[418]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07672" title="Abstract">arXiv:2310.07672</a> (replaced) [<a href="/pdf/2310.07672" title="Download PDF">pdf</a>, <a href="/format/2310.07672" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Stabilizing Estimates of Shapley Values with Control Variates
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Goldwasser%2C+J">Jeremy Goldwasser</a>, 
<a href="/search/stat?searchtype=author&query=Hooker%2C+G">Giles Hooker</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item419">[419]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.09183" title="Abstract">arXiv:2310.09183</a> (replaced) [<a href="/pdf/2310.09183" title="Download PDF">pdf</a>, <a href="/format/2310.09183" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PRIOR: Personalized Prior for Reactivating the Information Overlooked in  Federated Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shi%2C+M">Mingjia Shi</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Y">Yuhao Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+K">Kai Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Huaizheng Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+S">Shudong Huang</a>, 
<a href="/search/cs?searchtype=author&query=Ye%2C+Q">Qing Ye</a>, 
<a href="/search/cs?searchtype=author&query=Lv%2C+J">Jiangcheng Lv</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Distributed, Parallel, and Cluster Computing (cs.DC)

</div>
</div>
</dd>
<dt><a name="item420">[420]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.09346" title="Abstract">arXiv:2310.09346</a> (replaced) [<a href="/pdf/2310.09346" title="Download PDF">pdf</a>, <a href="/format/2310.09346" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> HaptiCharger: Robotic Charging of Electric Vehicles Based on Human  Haptic Patterns
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Alyounes%2C+O">Oussama Alyounes</a>, 
<a href="/search/cs?searchtype=author&query=Cabrera%2C+M+A">Miguel Altamirano Cabrera</a>, 
<a href="/search/cs?searchtype=author&query=Tsetserukou%2C+D">Dzmitry Tsetserukou</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Manuscript accepted to IEEE ROBIO 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
</div>
</dd>
<dt><a name="item421">[421]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.09998" title="Abstract">arXiv:2310.09998</a> (replaced) [<a href="/pdf/2310.09998" title="Download PDF">pdf</a>, <a href="/format/2310.09998" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SeUNet-Trans: A Simple yet Effective UNet-Transformer Model for Medical  Image Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Pham%2C+T">Tan-Hanh Pham</a>, 
<a href="/search/eess?searchtype=author&query=Li%2C+X">Xianqi Li</a>, 
<a href="/search/eess?searchtype=author&query=Nguyen%2C+K">Kim-Doang Nguyen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item422">[422]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.13001" title="Abstract">arXiv:2310.13001</a> (replaced) [<a href="/pdf/2310.13001" title="Download PDF">pdf</a>, <a href="/ps/2310.13001" title="Download PostScript">ps</a>, <a href="/format/2310.13001" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Conversational Financial Information Retrieval Model (ConFIRM)
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Choi%2C+S">Stephen Choi</a>, 
<a href="/search/cs?searchtype=author&query=Gazeley%2C+W">William Gazeley</a>, 
<a href="/search/cs?searchtype=author&query=Wong%2C+S+H">Siu Ho Wong</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+T">Tingting Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 2 figures, 2 tables, 2 appendices
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Artificial Intelligence (cs.AI); Computational Engineering, Finance, and Science (cs.CE); Computation and Language (cs.CL); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item423">[423]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.14194" title="Abstract">arXiv:2310.14194</a> (replaced) [<a href="/pdf/2310.14194" title="Download PDF">pdf</a>, <a href="/format/2310.14194" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Distractor-aware Event-based Tracking
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fu%2C+Y">Yingkai Fu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+M">Meng Li</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+W">Wenxi Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yuanchen Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jiqing Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Yin%2C+B">Baocai Yin</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+X">Xiaopeng Wei</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+X">Xin Yang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item424">[424]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.15823" title="Abstract">arXiv:2310.15823</a> (replaced) [<a href="/pdf/2310.15823" title="Download PDF">pdf</a>, <a href="/format/2310.15823" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Rosetta Stone at the Arabic Reverse Dictionary Shared Task: A Hop From  Language Modeling To Word--Definition Alignment
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=ElBakry%2C+A">Ahmed ElBakry</a>, 
<a href="/search/cs?searchtype=author&query=Gabr%2C+M">Mohamed Gabr</a>, 
<a href="/search/cs?searchtype=author&query=ElNokrashy%2C+M">Muhammad ElNokrashy</a>, 
<a href="/search/cs?searchtype=author&query=AlKhamissi%2C+B">Badr AlKhamissi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ArabicNLP 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item425">[425]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.15952" title="Abstract">arXiv:2310.15952</a> (replaced) [<a href="/pdf/2310.15952" title="Download PDF">pdf</a>, <a href="/format/2310.15952" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Improving Robustness and Reliability in Medical Image Classification  with Latent-Guided Diffusion and Nested-Ensembles
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shen%2C+X">Xing Shen</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+H">Hengguan Huang</a>, 
<a href="/search/cs?searchtype=author&query=Nichyporuk%2C+B">Brennan Nichyporuk</a>, 
<a href="/search/cs?searchtype=author&query=Arbel%2C+T">Tal Arbel</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, 6 figures, 7 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item426">[426]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.18765" title="Abstract">arXiv:2310.18765</a> (replaced) [<a href="/pdf/2310.18765" title="Download PDF">pdf</a>, <a href="/format/2310.18765" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Rethinking Semi-Supervised Imbalanced Node Classification from  Bias-Variance Decomposition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yan%2C+D">Divin Yan</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+G">Gengchen Wei</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+C">Chen Yang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+S">Shengzhong Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+Z">Zengfeng Huang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by NeurIPS 2023
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Thirty-seventh Conference on Neural Information Processing
  Systems.(NeurIPS 2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item427">[427]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.19025" title="Abstract">arXiv:2310.19025</a> (replaced) [<a href="/pdf/2310.19025" title="Download PDF">pdf</a>, <a href="/ps/2310.19025" title="Download PostScript">ps</a>, <a href="/format/2310.19025" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An Improved Relaxation for Oracle-Efficient Adversarial Contextual  Bandits
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Banihashem%2C+K">Kiarash Banihashem</a>, 
<a href="/search/cs?searchtype=author&query=Hajiaghayi%2C+M">MohammadTaghi Hajiaghayi</a>, 
<a href="/search/cs?searchtype=author&query=Shin%2C+S">Suho Shin</a>, 
<a href="/search/cs?searchtype=author&query=Springer%2C+M">Max Springer</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Appears in NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Data Structures and Algorithms (cs.DS); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item428">[428]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.19139" title="Abstract">arXiv:2310.19139</a> (replaced) [<a href="/pdf/2310.19139" title="Download PDF">pdf</a>, <a href="/format/2310.19139" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Back to the Future! Studying Data Cleanness in Defects4J and its Impact  on Fault Localization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+A+R">An Ran Chen</a>, 
<a href="/search/cs?searchtype=author&query=Rafi%2C+M+N">Md Nakhla Rafi</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+T">Tse-Hsun Chen</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Shaohua Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
</div>
</dd>
<dt><a name="item429">[429]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.19277" title="Abstract">arXiv:2310.19277</a> (replaced) [<a href="/pdf/2310.19277" title="Download PDF">pdf</a>, <a href="/format/2310.19277" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Clustering based Multiple Anchors High-Dimensional Model Representation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Xiong%2C+M">Meixin Xiong</a>, 
<a href="/search/math?searchtype=author&query=Chen%2C+L">Liuhong Chen</a>, 
<a href="/search/math?searchtype=author&query=Ming%2C+J">Ju Ming</a>, 
<a href="/search/math?searchtype=author&query=Pan%2C+X">Xingchen Pan</a>, 
<a href="/search/math?searchtype=author&query=Yan%2C+X">Xinyu Yan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
</div>
</dd>
<dt><a name="item430">[430]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.19477" title="Abstract">arXiv:2310.19477</a> (replaced) [<a href="/pdf/2310.19477" title="Download PDF">pdf</a>, <a href="/format/2310.19477" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> VDIP-TGV: Blind Image Deconvolution via Variational Deep Image Prior  Empowered by Total Generalized Variation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+T">Tingting Wu</a>, 
<a href="/search/cs?searchtype=author&query=Du%2C+Z">Zhiyan Du</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zhi Li</a>, 
<a href="/search/cs?searchtype=author&query=Fan%2C+F">Feng-Lei Fan</a>, 
<a href="/search/cs?searchtype=author&query=Zeng%2C+T">Tieyong Zeng</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Multimedia (cs.MM); Image and Video Processing (eess.IV)

</div>
</div>
</dd>
<dt><a name="item431">[431]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.19531" title="Abstract">arXiv:2310.19531</a> (replaced) [<a href="/pdf/2310.19531" title="Download PDF">pdf</a>, <a href="/format/2310.19531" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> InfoEntropy Loss to Mitigate Bias of Learning Difficulties for  Generative Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Su%2C+Z">Zhenpeng Su</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+X">Xing Wu</a>, 
<a href="/search/cs?searchtype=author&query=Bai%2C+X">Xue Bai</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+Z">Zijia Lin</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+H">Hui Chen</a>, 
<a href="/search/cs?searchtype=author&query=Ding%2C+G">Guiguang Ding</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+W">Wei Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+S">Songlin Hu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item432">[432]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.19805" title="Abstract">arXiv:2310.19805</a> (replaced) [<a href="/pdf/2310.19805" title="Download PDF">pdf</a>, <a href="/format/2310.19805" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Sample Efficient Reward Augmentation in offline-to-online Reinforcement  Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Ziqi Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Xiong%2C+X">Xiao Xiong</a>, 
<a href="/search/cs?searchtype=author&query=Zhuang%2C+Z">Zifeng Zhuang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jinxin Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+D">Donglin Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 23 pages, 11 Figures, and 6 Tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item433">[433]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.19981" title="Abstract">arXiv:2310.19981</a> (replaced) [<a href="/pdf/2310.19981" title="Download PDF">pdf</a>, <a href="/ps/2310.19981" title="Download PostScript">ps</a>, <a href="/format/2310.19981" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> &#x27;Person&#x27; == Light-skinned, Western Man, and Sexualization of Women of  Color: Stereotypes in Stable Diffusion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ghosh%2C+S">Sourojit Ghosh</a>, 
<a href="/search/cs?searchtype=author&query=Caliskan%2C+A">Aylin Caliskan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Upcoming publication, Findings of EMNLP 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item434">[434]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.20463" title="Abstract">arXiv:2310.20463</a> (replaced) [<a href="/pdf/2310.20463" title="Download PDF">pdf</a>, <a href="/ps/2310.20463" title="Download PostScript">ps</a>, <a href="/format/2310.20463" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Interpretable Neural PDE Solvers using Symbolic Frameworks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lee%2C+Y+Y+R">Yolanne Yi Ran Lee</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to the NeurIPS 2023 AI for Science Workshop. arXiv admin note: text overlap with <a href="/abs/2310.19763">arXiv:2310.19763</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
</div>
</dd>
<dt><a name="item435">[435]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.00157" title="Abstract">arXiv:2311.00157</a> (replaced) [<a href="/pdf/2311.00157" title="Download PDF">pdf</a>, <a href="/format/2311.00157" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Score Normalization for a Faster Diffusion Exponential Integrator  Sampler
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xia%2C+G">Guoxuan Xia</a>, 
<a href="/search/cs?searchtype=author&query=Danier%2C+D">Duolikun Danier</a>, 
<a href="/search/cs?searchtype=author&query=Das%2C+A">Ayan Das</a>, 
<a href="/search/cs?searchtype=author&query=Fotiadis%2C+S">Stathi Fotiadis</a>, 
<a href="/search/cs?searchtype=author&query=Nabiei%2C+F">Farhang Nabiei</a>, 
<a href="/search/cs?searchtype=author&query=Sengupta%2C+U">Ushnish Sengupta</a>, 
<a href="/search/cs?searchtype=author&query=Bernacchia%2C+A">Alberto Bernacchia</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item436">[436]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.00530" title="Abstract">arXiv:2311.00530</a> (replaced) [<a href="/pdf/2311.00530" title="Download PDF">pdf</a>, <a href="/format/2311.00530" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Development of LLMs for Embodied Navigation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lin%2C+J">Jinzhou Lin</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+H">Han Gao</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+R">Rongtao Xu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+C">Changwei Wang</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+L">Li Guo</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+S">Shibiao Xu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
</div>
</dd>
<dt><a name="item437">[437]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.00992" title="Abstract">arXiv:2311.00992</a> (replaced) [<a href="/pdf/2311.00992" title="Download PDF">pdf</a>, <a href="/ps/2311.00992" title="Download PostScript">ps</a>, <a href="/format/2311.00992" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Computing random $r$-orthogonal Latin squares
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bereg%2C+S">Sergey Bereg</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Discrete Mathematics (cs.DM)</span>; Combinatorics (math.CO)

</div>
</div>
</dd>
<dt><a name="item438">[438]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01026" title="Abstract">arXiv:2311.01026</a> (replaced) [<a href="/pdf/2311.01026" title="Download PDF">pdf</a>, <a href="/ps/2311.01026" title="Download PostScript">ps</a>, <a href="/format/2311.01026" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Constant Factor Approximation for Directed Feedback Vertex Set in  Graphs of Bounded Genus
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sun%2C+H">Hao Sun</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>; Discrete Mathematics (cs.DM)

</div>
</div>
</dd>
<dt><a name="item439">[439]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01149" title="Abstract">arXiv:2311.01149</a> (replaced) [<a href="/pdf/2311.01149" title="Download PDF">pdf</a>, <a href="/format/2311.01149" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ChineseWebText: Large-scale High-quality Chinese Web Text Extracted with  Effective Evaluation Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Jianghao Chen</a>, 
<a href="/search/cs?searchtype=author&query=Jian%2C+P">Pu Jian</a>, 
<a href="/search/cs?searchtype=author&query=Xi%2C+T">Tengxiao Xi</a>, 
<a href="/search/cs?searchtype=author&query=Yi%2C+D">Dongyi Yi</a>, 
<a href="/search/cs?searchtype=author&query=Du%2C+Q">Qianlong Du</a>, 
<a href="/search/cs?searchtype=author&query=Ding%2C+C">Chenglin Ding</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+G">Guibo Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Zong%2C+C">Chengqing Zong</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jinqiao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jiajun Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item440">[440]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01282" title="Abstract">arXiv:2311.01282</a> (replaced) [<a href="/pdf/2311.01282" title="Download PDF">pdf</a>, <a href="/format/2311.01282" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FlashDecoding++: Faster Large Language Model Inference on GPUs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hong%2C+K">Ke Hong</a>, 
<a href="/search/cs?searchtype=author&query=Dai%2C+G">Guohao Dai</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+J">Jiaming Xu</a>, 
<a href="/search/cs?searchtype=author&query=Mao%2C+Q">Qiuli Mao</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xiuhong Li</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jun Liu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+K">Kangdi Chen</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+Y">Yuhan Dong</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yu Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computation and Language (cs.CL)

</div>
</div>
</dd>
<dt><a name="item441">[441]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01490" title="Abstract">arXiv:2311.01490</a> (replaced) [<a href="/pdf/2311.01490" title="Download PDF">pdf</a>, <a href="/ps/2311.01490" title="Download PostScript">ps</a>, <a href="/format/2311.01490" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Behavior of Large Language Models When Prompted to Generate Code  Explanations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Oli%2C+P">Priti Oli</a>, 
<a href="/search/cs?searchtype=author&query=Banjade%2C+R">Rabin Banjade</a>, 
<a href="/search/cs?searchtype=author&query=Chapagain%2C+J">Jeevan Chapagain</a>, 
<a href="/search/cs?searchtype=author&query=Rus%2C+V">Vasile Rus</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item442">[442]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02329" title="Abstract">arXiv:2311.02329</a> (replaced) [<a href="/pdf/2311.02329" title="Download PDF">pdf</a>, <a href="/format/2311.02329" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Complex Organ Mask Guided Radiology Report Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gu%2C+T">Tiancheng Gu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+D">Dongnan Liu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zhiyuan Li</a>, 
<a href="/search/cs?searchtype=author&query=Cai%2C+W">Weidong Cai</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 7 images. Accepted by WACV 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item443">[443]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03421" title="Abstract">arXiv:2311.03421</a> (replaced) [<a href="/pdf/2311.03421" title="Download PDF">pdf</a>, <a href="/format/2311.03421" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Hopfield-Enhanced Deep Neural Networks for Artifact-Resilient Brain  State Decoding
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-bio?searchtype=author&query=Marin-Llobet%2C+A">Arnau Marin-Llobet</a>, 
<a href="/search/q-bio?searchtype=author&query=Manasanch%2C+A">Arnau Manasanch</a>, 
<a href="/search/q-bio?searchtype=author&query=Sanchez-Vives%2C+M+V">Maria V. Sanchez-Vives</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neurons and Cognition (q-bio.NC)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item444">[444]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03486" title="Abstract">arXiv:2311.03486</a> (replaced) [<a href="/pdf/2311.03486" title="Download PDF">pdf</a>, <a href="/format/2311.03486" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fostering Human Learning in Sequential Decision-Making: Understanding  the Role of Evaluative Feedback
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gupta%2C+P">Piyush Gupta</a>, 
<a href="/search/cs?searchtype=author&query=Biswas%2C+S">Subir Biswas</a>, 
<a href="/search/cs?searchtype=author&query=Srivastava%2C+V">Vaibhav Srivastava</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
</div>
</dd>
<dt><a name="item445">[445]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03508" title="Abstract">arXiv:2311.03508</a> (replaced) [<a href="/pdf/2311.03508" title="Download PDF">pdf</a>, <a href="/format/2311.03508" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Astrocytes as a mechanism for meta-plasticity and contextually-guided  network function
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-bio?searchtype=author&query=Gong%2C+L">Lulu Gong</a>, 
<a href="/search/q-bio?searchtype=author&query=Pasqualetti%2C+F">Fabio Pasqualetti</a>, 
<a href="/search/q-bio?searchtype=author&query=Papouin%2C+T">Thomas Papouin</a>, 
<a href="/search/q-bio?searchtype=author&query=Ching%2C+S">ShiNung Ching</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 42 pages, 14 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neurons and Cognition (q-bio.NC)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item446">[446]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03698" title="Abstract">arXiv:2311.03698</a> (replaced) [<a href="/pdf/2311.03698" title="Download PDF">pdf</a>, <a href="/format/2311.03698" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Novel Variational Lower Bound for Inverse Reinforcement Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gui%2C+Y">Yikang Gui</a>, 
<a href="/search/cs?searchtype=author&query=Doshi%2C+P">Prashant Doshi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Robotics (cs.RO)

</div>
</div>
</dd>
<dt><a name="item447">[447]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04257" title="Abstract">arXiv:2311.04257</a> (replaced) [<a href="/pdf/2311.04257" title="Download PDF">pdf</a>, <a href="/format/2311.04257" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> mPLUG-Owl2: Revolutionizing Multi-modal Large Language Model with  Modality Collaboration
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ye%2C+Q">Qinghao Ye</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+H">Haiyang Xu</a>, 
<a href="/search/cs?searchtype=author&query=Ye%2C+J">Jiabo Ye</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+M">Ming Yan</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+A">Anwen Hu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+H">Haowei Liu</a>, 
<a href="/search/cs?searchtype=author&query=Qian%2C+Q">Qi Qian</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Ji Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+F">Fei Huang</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+J">Jingren Zhou</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item448">[448]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04338" title="Abstract">arXiv:2311.04338</a> (replaced) [<a href="/pdf/2311.04338" title="Download PDF">pdf</a>, <a href="/format/2311.04338" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Convex Methods for Constrained Linear Bandits
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Afsharrad%2C+A">Amirhossein Afsharrad</a>, 
<a href="/search/cs?searchtype=author&query=Moradipari%2C+A">Ahmadreza Moradipari</a>, 
<a href="/search/cs?searchtype=author&query=Lall%2C+S">Sanjay Lall</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Systems and Control (eess.SY)

</div>
</div>
</dd>
<dt><a name="item449">[449]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04498" title="Abstract">arXiv:2311.04498</a> (replaced) [<a href="/pdf/2311.04498" title="Download PDF">pdf</a>, <a href="/format/2311.04498" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> NExT-Chat: An LMM for Chat, Detection and Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+A">Ao Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+L">Liming Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+C">Chen-Wei Xie</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+Y">Yun Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Ji%2C+W">Wei Ji</a>, 
<a href="/search/cs?searchtype=author&query=Chua%2C+T">Tat-Seng Chua</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Technical Report
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL)

</div>
</div>
</dd>
<dt><a name="item450">[450]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04522" title="Abstract">arXiv:2311.04522</a> (replaced) [<a href="/pdf/2311.04522" title="Download PDF">pdf</a>, <a href="/format/2311.04522" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Long-term Time Series Forecasting based on Decomposition and Neural  Ordinary Differential Equations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lim%2C+S">Seonkyu Lim</a>, 
<a href="/search/cs?searchtype=author&query=Park%2C+J">Jaehyeon Park</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+S">Seojin Kim</a>, 
<a href="/search/cs?searchtype=author&query=Wi%2C+H">Hyowon Wi</a>, 
<a href="/search/cs?searchtype=author&query=Lim%2C+H">Haksoo Lim</a>, 
<a href="/search/cs?searchtype=author&query=Jeon%2C+J">Jinsung Jeon</a>, 
<a href="/search/cs?searchtype=author&query=Choi%2C+J">Jeongwhan Choi</a>, 
<a href="/search/cs?searchtype=author&query=Park%2C+N">Noseong Park</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at IEEE BigData 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item451">[451]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04688" title="Abstract">arXiv:2311.04688</a> (replaced) [<a href="/pdf/2311.04688" title="Download PDF">pdf</a>, <a href="/format/2311.04688" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Single Server Private Information Retrieval Protocols With Codes Over  Rings
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bodur%2C+%C5%9E">&#x15e;eyma Bodur</a>, 
<a href="/search/cs?searchtype=author&query=Mart%C3%ADnez-Moro%2C+E">Edgar Mart&#xed;nez-Moro</a>, 
<a href="/search/cs?searchtype=author&query=Ruano%2C+D">Diego Ruano</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>

</div>
</div>
</dd>
<dt><a name="item452">[452]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04698" title="Abstract">arXiv:2311.04698</a> (replaced) [<a href="/pdf/2311.04698" title="Download PDF">pdf</a>, <a href="/format/2311.04698" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Challenging Common Assumptions in Multi-task Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Elich%2C+C">Cathrin Elich</a>, 
<a href="/search/cs?searchtype=author&query=Kirchdorfer%2C+L">Lukas Kirchdorfer</a>, 
<a href="/search/cs?searchtype=author&query=K%C3%B6hler%2C+J+M">Jan M. K&#xf6;hler</a>, 
<a href="/search/cs?searchtype=author&query=Schott%2C+L">Lukas Schott</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> -
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item453">[453]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05024" title="Abstract">arXiv:2311.05024</a> (replaced) [<a href="/pdf/2311.05024" title="Download PDF">pdf</a>, <a href="/ps/2311.05024" title="Download PostScript">ps</a>, <a href="/format/2311.05024" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Einstien-Multidimensional Extrapolation methods
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Bentbib%2C+A+H">A. H. Bentbib</a>, 
<a href="/search/math?searchtype=author&query=Jbilou%2C+K">K. Jbilou</a>, 
<a href="/search/math?searchtype=author&query=Tahiri%2C+R">R. Tahiri</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
</div>
</dd>
<dt><a name="item454">[454]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05143" title="Abstract">arXiv:2311.05143</a> (replaced) [<a href="/pdf/2311.05143" title="Download PDF">pdf</a>, <a href="/format/2311.05143" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SCAAT: Improving Neural Network Interpretability via Saliency  Constrained Adaptive Adversarial Training
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+R">Rui Xu</a>, 
<a href="/search/cs?searchtype=author&query=Qin%2C+W">Wenkang Qin</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+P">Peixiang Huang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Hao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+L">Lin Luo</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item455">[455]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05221" title="Abstract">arXiv:2311.05221</a> (replaced) [<a href="/pdf/2311.05221" title="Download PDF">pdf</a>, <a href="/format/2311.05221" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Let&#x27;s Get the FACS Straight -- Reconstructing Obstructed Facial Features
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=B%C3%BCchner%2C+T">Tim B&#xfc;chner</a>, 
<a href="/search/cs?searchtype=author&query=Sickert%2C+S">Sven Sickert</a>, 
<a href="/search/cs?searchtype=author&query=Volk%2C+G+F">Gerd Fabian Volk</a>, 
<a href="/search/cs?searchtype=author&query=Anders%2C+C">Christoph Anders</a>, 
<a href="/search/cs?searchtype=author&query=Guntinas-Lichius%2C+O">Orlando Guntinas-Lichius</a>, 
<a href="/search/cs?searchtype=author&query=Denzler%2C+J">Joachim Denzler</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> VISAPP 2023 paper
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item456">[456]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05243" title="Abstract">arXiv:2311.05243</a> (replaced) [<a href="/pdf/2311.05243" title="Download PDF">pdf</a>, <a href="/format/2311.05243" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A higher-order transformation approach to the formalization and analysis  of BPMN using graph transformation systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kr%C3%A4uter%2C+T">Tim Kr&#xe4;uter</a>, 
<a href="/search/cs?searchtype=author&query=Rutle%2C+A">Adrian Rutle</a>, 
<a href="/search/cs?searchtype=author&query=K%C3%B6nig%2C+H">Harald K&#xf6;nig</a>, 
<a href="/search/cs?searchtype=author&query=Lamo%2C+Y">Yngve Lamo</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
</div>
</dd>
<dt><a name="item457">[457]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05487" title="Abstract">arXiv:2311.05487</a> (replaced) [<a href="/pdf/2311.05487" title="Download PDF">pdf</a>, <a href="/format/2311.05487" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> News and Misinformation Consumption in Europe: A Longitudinal  Cross-Country Perspective
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Baqir%2C+A">Anees Baqir</a>, 
<a href="/search/cs?searchtype=author&query=Galeazzi%2C+A">Alessandro Galeazzi</a>, 
<a href="/search/cs?searchtype=author&query=Zollo%2C+F">Fabiana Zollo</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>; Computers and Society (cs.CY)

</div>
</div>
</dd>
</dl>
<ul>
<li><a href="/list/cs/new?skip=0&amp;show=2000">New submissions</a></li>
<li><a href="#item249">Cross-lists</a></li>
<li><a href="#item287">Replacements</a></li>
</ul>
<small>[ total of 457 entries:  <b>1-457</b>  ]</small><br />
<small>[ showing up to 2000 entries per page:  <a href="/list/cs/new?skip=0&amp;show=1000">fewer</a> |  <font color="#999999">more</font> ]</small><br />
</div>
<br/><small><a id="mathjax_toggle" href="javascript:setMathjaxCookie()">Disable MathJax</a> (<a href="/help/mathjax">What is MathJax?</a>)</small><script type="text/javascript" language="javascript">mathjaxToggle();</script>

<hr />
<p>Links to:
<a href="/" accesskey="a">arXiv</a>,
<a href="/form/cs">form interface</a>,
<a href="/find/cs">find</a>,
<a href="/archive/cs">cs</a>, <a href="/list/cs/recent">recent</a>, <a href="/list/cs/2311">2311</a>,
<a href="/help/contact">contact</a>,
<a href="/help/" accesskey="h"><span class="accesskey">h</span>elp</a>&nbsp;
<small>(<a href="/help/accesskeys">Access key</a> information)</small>
</p>
<hr />
</div>
</div>
 <footer style="clear: both;">
      <div class="columns is-desktop" role="navigation" aria-label="Secondary" style="margin: -0.75em -0.75em 0.75em -0.75em">
        <!-- Macro-Column 1 -->
        <div class="column" style="padding: 0;">
          <div class="columns">
            <div class="column">
              <ul style="list-style: none; line-height: 2;">
                <li><a href="https://arxiv.org/about">About</a></li>
                <li><a href="https://arxiv.org/help">Help</a></li>
              </ul>
            </div>
            <div class="column">
              <ul style="list-style: none; line-height: 2;">
                <li>
                  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon filter-black" role="presentation"><title>contact arXiv</title><desc>Click here to contact arXiv</desc><path d="M502.3 190.8c3.9-3.1 9.7-.2 9.7 4.7V400c0 26.5-21.5 48-48 48H48c-26.5 0-48-21.5-48-48V195.6c0-5 5.7-7.8 9.7-4.7 22.4 17.4 52.1 39.5 154.1 113.6 21.1 15.4 56.7 47.8 92.2 47.6 35.7.3 72-32.8 92.3-47.6 102-74.1 131.6-96.3 154-113.7zM256 320c23.2.4 56.6-29.2 73.4-41.4 132.7-96.3 142.8-104.7 173.4-128.7 5.8-4.5 9.2-11.5 9.2-18.9v-19c0-26.5-21.5-48-48-48H48C21.5 64 0 85.5 0 112v19c0 7.4 3.4 14.3 9.2 18.9 30.6 23.9 40.7 32.4 173.4 128.7 16.8 12.2 50.2 41.8 73.4 41.4z"/></svg>
                  <a href="https://arxiv.org/help/contact"> Contact</a>
                </li>
                <li>
                  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon filter-black" role="presentation"><title>subscribe to arXiv mailings</title><desc>Click here to subscribe</desc><path d="M476 3.2L12.5 270.6c-18.1 10.4-15.8 35.6 2.2 43.2L121 358.4l287.3-253.2c5.5-4.9 13.3 2.6 8.6 8.3L176 407v80.5c0 23.6 28.5 32.9 42.5 15.8L282 426l124.6 52.2c14.2 6 30.4-2.9 33-18.2l72-432C515 7.8 493.3-6.8 476 3.2z"/></svg>
                  <a href="https://arxiv.org/help/subscribe"> Subscribe</a>
                </li>
              </ul>
            </div>
          </div>
        </div>
        <!-- End Macro-Column 1 -->
        <!-- Macro-Column 2 -->
        <div class="column" style="padding: 0;">
          <div class="columns">
            <div class="column">
              <ul style="list-style: none; line-height: 2;">
                <li><a href="https://arxiv.org/help/license">Copyright</a></li>
                <li><a href="https://arxiv.org/help/policies/privacy_policy">Privacy Policy</a></li>
              </ul>
            </div>
            <div class="column sorry-app-links">
              <ul style="list-style: none; line-height: 2;">
                <li><a href="https://arxiv.org/help/web_accessibility">Web Accessibility Assistance</a></li>
                <li>
                  <p class="help">
                    <a class="a11y-main-link" href="https://status.arxiv.org" target="_blank">arXiv Operational Status <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 256 512" class="icon filter-dark_grey" role="presentation"><path d="M224.3 273l-136 136c-9.4 9.4-24.6 9.4-33.9 0l-22.6-22.6c-9.4-9.4-9.4-24.6 0-33.9l96.4-96.4-96.4-96.4c-9.4-9.4-9.4-24.6 0-33.9L54.3 103c9.4-9.4 24.6-9.4 33.9 0l136 136c9.5 9.4 9.5 24.6.1 34z"/></svg></a><br>
                    Get status notifications via
                    <a class="is-link" href="https://subscribe.sorryapp.com/24846f03/email/new" target="_blank"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon filter-black" role="presentation"><path d="M502.3 190.8c3.9-3.1 9.7-.2 9.7 4.7V400c0 26.5-21.5 48-48 48H48c-26.5 0-48-21.5-48-48V195.6c0-5 5.7-7.8 9.7-4.7 22.4 17.4 52.1 39.5 154.1 113.6 21.1 15.4 56.7 47.8 92.2 47.6 35.7.3 72-32.8 92.3-47.6 102-74.1 131.6-96.3 154-113.7zM256 320c23.2.4 56.6-29.2 73.4-41.4 132.7-96.3 142.8-104.7 173.4-128.7 5.8-4.5 9.2-11.5 9.2-18.9v-19c0-26.5-21.5-48-48-48H48C21.5 64 0 85.5 0 112v19c0 7.4 3.4 14.3 9.2 18.9 30.6 23.9 40.7 32.4 173.4 128.7 16.8 12.2 50.2 41.8 73.4 41.4z"/></svg>email</a>
                    or <a class="is-link" href="https://subscribe.sorryapp.com/24846f03/slack/new" target="_blank"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512" class="icon filter-black" role="presentation"><path d="M94.12 315.1c0 25.9-21.16 47.06-47.06 47.06S0 341 0 315.1c0-25.9 21.16-47.06 47.06-47.06h47.06v47.06zm23.72 0c0-25.9 21.16-47.06 47.06-47.06s47.06 21.16 47.06 47.06v117.84c0 25.9-21.16 47.06-47.06 47.06s-47.06-21.16-47.06-47.06V315.1zm47.06-188.98c-25.9 0-47.06-21.16-47.06-47.06S139 32 164.9 32s47.06 21.16 47.06 47.06v47.06H164.9zm0 23.72c25.9 0 47.06 21.16 47.06 47.06s-21.16 47.06-47.06 47.06H47.06C21.16 243.96 0 222.8 0 196.9s21.16-47.06 47.06-47.06H164.9zm188.98 47.06c0-25.9 21.16-47.06 47.06-47.06 25.9 0 47.06 21.16 47.06 47.06s-21.16 47.06-47.06 47.06h-47.06V196.9zm-23.72 0c0 25.9-21.16 47.06-47.06 47.06-25.9 0-47.06-21.16-47.06-47.06V79.06c0-25.9 21.16-47.06 47.06-47.06 25.9 0 47.06 21.16 47.06 47.06V196.9zM283.1 385.88c25.9 0 47.06 21.16 47.06 47.06 0 25.9-21.16 47.06-47.06 47.06-25.9 0-47.06-21.16-47.06-47.06v-47.06h47.06zm0-23.72c-25.9 0-47.06-21.16-47.06-47.06 0-25.9 21.16-47.06 47.06-47.06h117.84c25.9 0 47.06 21.16 47.06 47.06 0 25.9-21.16 47.06-47.06 47.06H283.1z"/></svg>slack</a>
                  </p>
                </li>
              </ul>
            </div>
          </div>
        </div> <!-- end MetaColumn 2 -->
        <!-- End Macro-Column 2 -->
      </div>
    </footer>
</body>
</html>
