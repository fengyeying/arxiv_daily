<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en">
<head>
<title>Computer Science  authors/titles &quot;new&quot;</title>
<link rel="shortcut icon" href="/favicon.ico" type="image/x-icon" />
<link rel="stylesheet" type="text/css" media="screen" href="//static.arxiv.org/static/browse/0.3.2.8/css/arXiv.css?v=20220215" />
<link rel="stylesheet" type="text/css" media="screen" href="/bibex/bibex.css?20181009">
<link rel="stylesheet" type="text/css" media="screen" href="https://static.arxiv.org/static/browse/0.3.8/css/browse_search.css" />
<link rel="alternate" type="application/rss+xml" title="Computer Science " href="http://arxiv.org/rss/cs"/>
<script src="/js/mathjaxToggle.min.js" type="text/javascript"></script>


</head>
<body class="with-cu-identity">

<div id="cu-identity">
<div id="cu-logo">
<a href="https://www.cornell.edu/"><img src="//static.arxiv.org/icons/cu/cornell-reduced-white-SMALL.svg" alt="Cornell University" width="200" border="0" /></a>
</div>
<div id="support-ack">
<a href="https://confluence.cornell.edu/x/ALlRF">We gratefully acknowledge support from<br /> the Simons Foundation and member institutions.</a>
</div>
</div>
<div id="header">
<h1 class="header-breadcrumbs"><a href="/"><img src="//static.arxiv.org/images/arxiv-logo-one-color-white.svg" aria-label="logo" alt="arxiv logo" width="85" style="width:85px;margin-right:8px;"></a> <span>&gt;</span> <a href="/list/cs/recent">cs</a></h1>
<div class="search-block level-right">
<form class="level-item mini-search" method="GET" action="https://arxiv.org/search" _lpchecked="1">
<div class="field has-addons">
<div class="control">
<input class="input is-small" type="text" name="query" placeholder="Search..." aria-label="Search term or terms" data-com.agilebits.onepassword.user-edited="yes">
<p class="help"><a href="https://arxiv.org/help">Help</a> | <a href="https://arxiv.org/search/advanced">Advanced Search</a></p>
</div>
<div class="control">
<div class="select is-small">
<select name="searchtype" aria-label="Field to search">
<option value="all" selected="selected">All fields</option>
<option value="title">Title</option>
<option value="author">Author</option>
<option value="abstract">Abstract</option>
<option value="comments">Comments</option>
<option value="journal_ref">Journal reference</option>
<option value="acm_class">ACM classification</option>
<option value="msc_class">MSC classification</option>
<option value="report_num">Report number</option>
<option value="paper_id">arXiv identifier</option>
<option value="doi">DOI</option>
<option value="orcid">ORCID</option>
<option value="author_id">arXiv author ID</option>
<option value="help">Help pages</option>
<option value="full_text">Full text</option>
</select>
</div>
</div>
<button class="button is-small is-cul-darker">Search</button>
</div>
</form>
</div>
</div>
<div id="content">
<div id="dlpage">
<h1>Computer Science </h1>
<h2>New submissions</h2>
<div class="list-dateline">Submissions received from  Mon  6 Nov 23  to  Tue  7 Nov 23, announced Wed,  8 Nov 23</div>
<ul>
<li><a href="/list/cs/new?skip=0&amp;show=2000">New submissions</a></li>
<li><a href="#item368">Cross-lists</a></li>
<li><a href="#item411">Replacements</a></li>
</ul>
<small>[ total of 677 entries:  <b>1-677</b>  ]</small><br />
<small>[ showing up to 2000 entries per page:  <a href="/list/cs/new?skip=0&amp;show=1000">fewer</a> |  <font color="#999999">more</font> ]</small><br />
<h3>New submissions for Wed,  8 Nov 23</h3>
<dl>
<dt><a name="item1">[1]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03358" title="Abstract">arXiv:2311.03358</a> [<a href="/pdf/2311.03358" title="Download PDF">pdf</a>, <a href="/format/2311.03358" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Understanding and Analyzing Rationale in Commit Messages using a  Knowledge Graph Approach
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dhaouadi%2C+M">Mouna Dhaouadi</a>, 
<a href="/search/cs?searchtype=author&query=Oakes%2C+B+J">Bentley James Oakes</a>, 
<a href="/search/cs?searchtype=author&query=Famelis%2C+M">Michalis Famelis</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
<p class="mathjax">Extracting rationale information from commit messages allows developers to
better understand a system and its past development. Here we present our
ongoing work on the Kantara end-to-end rationale reconstruction pipeline to a)
structure rationale information in an ontologically-based knowledge graph, b)
extract and classify this information from commits, and c) produce analysis
reports and visualizations for developers. We also present our work on creating
a labelled dataset for our running example of the Out-of-Memory component of
the Linux kernel. This dataset is used as ground truth for our evaluation of
NLP classification techniques which show promising results, especially the
multi-classification technique XGBoost.
</p>
</div>
</dd>
<dt><a name="item2">[2]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03359" title="Abstract">arXiv:2311.03359</a> [<a href="/pdf/2311.03359" title="Download PDF">pdf</a>, <a href="/ps/2311.03359" title="Download PostScript">ps</a>, <a href="/format/2311.03359" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Prompted Software Engineering in the Era of AI Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kim%2C+D">Dae-Kyoo Kim</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 1 figure
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
<p class="mathjax">This paper introduces prompted software engineering (PSE), which integrates
prompt engineering to build effective prompts for language-based AI models, to
enhance the software development process. PSE enables the use of AI models in
software development to produce high-quality software with fewer resources,
automating tedious tasks and allowing developers to focus on more innovative
aspects. However, effective prompts are necessary to guide software development
in generating accurate, relevant, and useful responses, while mitigating risks
of misleading outputs. This paper describes how productive prompts should be
built throughout the software development cycle.
</p>
</div>
</dd>
<dt><a name="item3">[3]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03360" title="Abstract">arXiv:2311.03360</a> [<a href="/pdf/2311.03360" title="Download PDF">pdf</a>, <a href="/ps/2311.03360" title="Download PostScript">ps</a>, <a href="/format/2311.03360" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Performance Analysis of Security Certificate Management System in  Vehicle-to-Everything (V2X)
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+A+C+H">Abel C. H. Chen</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+C">Cheng-Kang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+C">Chun-Feng Lin</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+B">Bon-Yeh Lin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> in Chinese language
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Networking and Internet Architecture (cs.NI); Software Engineering (cs.SE)

</div>
<p class="mathjax">In Vehicle-to-Everything (V2X) communications, providing accurate information
and safeguarding the privacy of end entities is one of the crucial information
security issues. Therefore, several international standardization organizations
have begun to develop V2X communication security standards in recent years. For
instance, the IEEE 1609.2.1 standard designs a Security Credential Management
System (SCMS) that specifies certificate application and issuance processes, as
well as certificate revocation processes. Furthermore, the IEEE 1609.2 standard
defines certificate formats and Secure Protocol Data Units (SPDUs) for secure
data transmission based on these standards. As a result, end entity
manufacturers and SCMS providers worldwide have started building V2X security
systems in accordance with these standards and conducting interoperability
testing. Although international standards mainly employ Elliptic-Curve
Cryptography (ECC) for signature/verification and encryption/decryption
functions, performance analysis remains a crucial issue for the practical
deployment of these systems. Therefore, this study implements end entities and
a SCMS conforming to IEEE 1609.2 and IEEE 1609.2.1 standards. It measures the
computation and transmission times for each security communication action
within the system from the perspective of end entities and identifies potential
system bottlenecks. In the experimental results, this study analyzes the most
performance-intensive actions and provides relevant suggestions for enhancing
system efficiency for SCMS developers to reference.
</p>
</div>
</dd>
<dt><a name="item4">[4]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03361" title="Abstract">arXiv:2311.03361</a> [<a href="/pdf/2311.03361" title="Download PDF">pdf</a>, <a href="/ps/2311.03361" title="Download PostScript">ps</a>, <a href="/format/2311.03361" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Agile, User-Centered Design and Quality in Software Processes for Mobile  Application Development Teaching
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=L%C3%B3pez%2C+M+I+C">Manuel Ignacio Castillo L&#xf3;pez</a>, 
<a href="/search/cs?searchtype=author&query=Cervantes%2C+A+L+E">Ana Libia Eslava Cervantes</a>, 
<a href="/search/cs?searchtype=author&query=de+la+Cruz+Mart%C3%ADnez%2C+G">Gustavo de la Cruz Mart&#xed;nez</a>, 
<a href="/search/cs?searchtype=author&query=Arjona%2C+J+L+O">Jorge Luis Ortega Arjona</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 17 pages, 6 figures. arXiv admin note: substantial text overlap with <a href="/abs/2308.07494">arXiv:2308.07494</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> International Journal of Software Engineering &amp; Applications
  (2023), vol. 15, no. 5, pages 1-17
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>; Software Engineering (cs.SE)

</div>
<p class="mathjax">Agile methods in undergraduate courses have been explored in an effort to
close the gap between industry and professional profiles. We have structured an
Android application development course based on a tailored user-centered Agile
process for development of educational digital tools. This process is based on
Scrum and Extreme Programming in combination with User Experience (UX)
approaches. The course is executed in two phases: the first half of the
semester presents theory on Agile and mobile applications development, the
latter half is managed as a workshop where students develop for an actual
client. The introduction of UX and user-centered design exploiting the close
relationship with stakeholders expected from Agile processes allows for
different quality features development. Since 2019 two of the projects have
been extended and one project has been developed with the described process and
course alumni. Students and stakeholders have found value in the generated
products and process.
</p>
</div>
</dd>
<dt><a name="item5">[5]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03362" title="Abstract">arXiv:2311.03362</a> [<a href="/pdf/2311.03362" title="Download PDF">pdf</a>, <a href="/ps/2311.03362" title="Download PostScript">ps</a>, <a href="/format/2311.03362" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Simulation-based Safety Assurance for an AVP System incorporating  Learning-Enabled Components
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Esen%2C+H">Hasan Esen</a>, 
<a href="/search/cs?searchtype=author&query=Liao%2C+B+H">Brian Hsuan-Cheng Liao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 9 figures, 2 tables, presented at the 10th International Symposium on Development Methodology
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">There have been major developments in Automated Driving (AD) and Driving
Assist Systems (ADAS) in recent years. However, their safety assurance, thus
methodologies for testing, verification and validation AD/ADAS safety-critical
applications remain as one the main challenges. Inevitably AI also penetrates
into AD/ADAS applications, such as object detection. Despite important
benefits, adoption of such learned-enabled components and systems in
safety-critical scenarios causes that conventional testing approaches (e.g.,
distance-based testing in automotive) quickly become infeasible. Similarly,
safety engineering approaches usually assume model-based components and do not
handle learning-enabled ones well. The authors have participated in the
public-funded project FOCETA , and developed an Automated Valet Parking (AVP)
use case. As the nature of the baseline implementation is imperfect, it offers
a space for continuous improvement based on modelling, verification,
validation, and monitoring techniques. In this publication, we explain the
simulation-based development platform that is designed to verify and validate
safety-critical learning-enabled systems in continuous engineering loops.
</p>
</div>
</dd>
<dt><a name="item6">[6]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03363" title="Abstract">arXiv:2311.03363</a> [<a href="/pdf/2311.03363" title="Download PDF">pdf</a>, <a href="/ps/2311.03363" title="Download PostScript">ps</a>, <a href="/format/2311.03363" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Path to a Modular and Standards-based Digital Health Ecosystem
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Schmiedmayer%2C+P">Paul Schmiedmayer</a>, 
<a href="/search/cs?searchtype=author&query=Ravi%2C+V">Vishnu Ravi</a>, 
<a href="/search/cs?searchtype=author&query=Aalami%2C+O">Oliver Aalami</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> IEEE-EMBS International Conference on Biomedical and Health Informatics (BHI'23) - Workshop - Unraveling Challenges in Time Series Analysis with Open Source Tools for Digital Health Applications
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
<p class="mathjax">Software engineering for digital health applications entails several
challenges, including heterogeneous data acquisition, data standardization,
software reuse, security, and privacy considerations. We explore these
challenges and how our Stanford Spezi ecosystem addresses these challenges by
providing a modular and standards-based open-source digital health ecosystem.
Spezi enables developers to select and integrate modules according to their
needs and facilitates an open-source community to democratize access to
building digital health innovations.
</p>
</div>
</dd>
<dt><a name="item7">[7]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03364" title="Abstract">arXiv:2311.03364</a> [<a href="/pdf/2311.03364" title="Download PDF">pdf</a>, <a href="/format/2311.03364" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> BDD-Based Framework with RL Integration: An approach for videogames  automated testing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mastain%2C+V">Vincent Mastain</a>, 
<a href="/search/cs?searchtype=author&query=Petrillo%2C+F">Fabio Petrillo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 4 pages, 3 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
<p class="mathjax">Testing plays a vital role in software development, but in the realm of video
games, the process differs from traditional software development practices.
Game developers typically rely on human testers who are provided with
checklists to evaluate various elements. While major game developers already
employ automated testing using script-based bots, the increasing complexity of
video games is pushing the limits of scripted solutions, necessitating the
adoption of more advanced testing strategies. To assist game studios in
enhancing the quality of their games through automated testing, we propose the
integration of Behavior Driven Development (BDD) with Reinforcement Learning
(RL). This positional paper summarizes our proposal and framework under
development.
</p>
</div>
</dd>
<dt><a name="item8">[8]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03365" title="Abstract">arXiv:2311.03365</a> [<a href="/pdf/2311.03365" title="Download PDF">pdf</a>, <a href="/format/2311.03365" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Leveraging Generative AI: Improving Software Metadata Classification  with Generated Code-Comment Pairs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Syed%2C+S">Samah Syed</a>, 
<a href="/search/cs?searchtype=author&query=S%2C+A+D">Angel Deborah S</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages, 2 figures, 3 tables, Has been accepted for the Information Retrieval in Software Engineering track at Forum for Information Retrieval Evaluation 2023
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Information Retrieval in Software Engineering track at Forum for
  Information Retrieval Evaluation 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Machine Learning (cs.LG)

</div>
<p class="mathjax">In software development, code comments play a crucial role in enhancing code
comprehension and collaboration. This research paper addresses the challenge of
objectively classifying code comments as "Useful" or "Not Useful." We propose a
novel solution that harnesses contextualized embeddings, particularly BERT, to
automate this classification process. We address this task by incorporating
generated code and comment pairs. The initial dataset comprised 9048 pairs of
code and comments written in C, labeled as either Useful or Not Useful. To
augment this dataset, we sourced an additional 739 lines of code-comment pairs
and generated labels using a Large Language Model Architecture, specifically
BERT. The primary objective was to build classification models that can
effectively differentiate between useful and not useful code comments. Various
machine learning algorithms were employed, including Logistic Regression,
Decision Tree, K-Nearest Neighbors (KNN), Support Vector Machine (SVM),
Gradient Boosting, Random Forest, and a Neural Network. Each algorithm was
evaluated using precision, recall, and F1-score metrics, both with the original
seed dataset and the augmented dataset. This study showcases the potential of
generative AI for enhancing binary code comment quality classification models,
providing valuable insights for software developers and researchers in the
field of natural language processing and software engineering.
</p>
</div>
</dd>
<dt><a name="item9">[9]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03366" title="Abstract">arXiv:2311.03366</a> [<a href="/pdf/2311.03366" title="Download PDF">pdf</a>, <a href="/format/2311.03366" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Neural Rankers for Code Generation via Inter-Cluster Modeling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=To%2C+H+Q">Hung Quoc To</a>, 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+M+H">Minh Huynh Nguyen</a>, 
<a href="/search/cs?searchtype=author&query=Bui%2C+N+D+Q">Nghi D. Q. Bui</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Code Large Language Models (CodeLLMs) have ushered in a new era of code
generation advancements. However, selecting the best solutions from among all
possible CodeLLM solutions remains a challenge. Previous methods frequently
overlooked the intricate functional similarities and interactions between
clusters, resulting in suboptimal results. In this work, we introduce
\textit{SRank}, a novel reranking strategy for selecting the best solution from
code generation that focuses on modeling inter-cluster relationship. By
quantifying the functional overlap between clusters, our approach provides a
better ranking strategy of code solutions. Empirical results show that our
method achieves a remarkable results on pass@1 score. For instance, on the
Human-Eval benchmark, we achieve 69.66\% in pass@1 with Codex002, 75.31\% for
WizardCoder, 53.99\% for StarCoder and 60.55\% for CodeGen, which surpass the
state-of-the-arts solution ranking methods, such as CodeT and Coder-Reviewer on
the same CodeLLM with significant margin ($\approx 6.1\%$ improvement on
average). Comparing to the random sampling method, we can achieve an average
improvement of $\approx 23.07\%$ on Human-Eval and 17.64\% on MBPP. Even in
scenarios with limited test inputs, our approach demonstrates robustness and
superiority, marking a new state-of-the-arts in code generation reranking.
</p>
</div>
</dd>
<dt><a name="item10">[10]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03367" title="Abstract">arXiv:2311.03367</a> [<a href="/pdf/2311.03367" title="Download PDF">pdf</a>, <a href="/ps/2311.03367" title="Download PostScript">ps</a>, <a href="/format/2311.03367" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Taxonomy of Decentralized Identifier Methods for Practitioners
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hoops%2C+F">Felix Hoops</a>, 
<a href="/search/cs?searchtype=author&query=M%C3%BChle%2C+A">Alexander M&#xfc;hle</a>, 
<a href="/search/cs?searchtype=author&query=Matthes%2C+F">Florian Matthes</a>, 
<a href="/search/cs?searchtype=author&query=Meinel%2C+C">Christoph Meinel</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> 2023 IEEE International Conference on Decentralized Applications
  and Infrastructures (DAPPS), Athens, Greece, 2023, pp. 57-65
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
<p class="mathjax">A core part of the new identity management paradigm of Self-Sovereign
Identity (SSI) is the W3C Decentralized Identifiers (DIDs) standard. The
diversity of interoperable implementations encouraged by the paradigm is key
for a less centralized future, and it is made possible by the concept of DIDs.
However, this leads to a kind of dilemma of choices, where practitioners are
faced with the difficult decision of which methods to choose and support in
their applications. Due to the decentralized development of DID method
specifications and the overwhelming number of different choices, it is hard to
get an overview. In this paper, we propose a taxonomy of DID methods with the
goal to empower practitioners to make informed decisions when selecting DID
methods. To that end, our taxonomy is designed to provide an overview of the
current landscape while providing adoption-relevant characteristics. For this
purpose, we rely on the Nickerson et al. methodology for taxonomy creation,
utilizing both conceptual-to-empirical and empirical-to-conceptual approaches.
During the iterative process, we collect and survey an extensive and
potentially exhaustive list of around 160 DID methods from various sources. The
taxonomy we arrive at uses a total of 7 dimensions and 22 characteristics to
span the contemporary design space of DID methods from the perspective of a
practitioner. In addition to elaborating on these characteristics, we also
discuss how a practitioner can use the taxonomy to select suitable DID methods
for a specific use case.
</p>
</div>
</dd>
<dt><a name="item11">[11]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03369" title="Abstract">arXiv:2311.03369</a> [<a href="/pdf/2311.03369" title="Download PDF">pdf</a>, <a href="/format/2311.03369" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Can We Trust the Similarity Measurement in Federated Learning?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zhilin Wang</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+Q">Qin Hu</a>, 
<a href="/search/cs?searchtype=author&query=Zou%2C+X">Xukai Zou</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Cryptography and Security (cs.CR)

</div>
<p class="mathjax">Is it secure to measure the reliability of local models by similarity in
federated learning (FL)? This paper delves into an unexplored security threat
concerning applying similarity metrics, such as the L_2 norm, Euclidean
distance, and cosine similarity, in protecting FL. We first uncover the
deficiencies of similarity metrics that high-dimensional local models,
including benign and poisoned models, may be evaluated to have the same
similarity while being significantly different in the parameter values. We then
leverage this finding to devise a novel untargeted model poisoning attack,
Faker, which launches the attack by simultaneously maximizing the evaluated
similarity of the poisoned local model and the difference in the parameter
values. Experimental results based on seven datasets and eight defenses show
that Faker outperforms the state-of-the-art benchmark attacks by 1.1-9.0X in
reducing accuracy and 1.2-8.0X in saving time cost, which even holds for the
case of a single malicious client with limited knowledge about the FL system.
Moreover, Faker can degrade the performance of the global model by attacking
only once. We also preliminarily explore extending Faker to other attacks, such
as backdoor attacks and Sybil attacks. Lastly, we provide a model evaluation
strategy, called the similarity of partial parameters (SPP), to defend against
Faker. Given that numerous mechanisms in FL utilize similarity metrics to
assess local models, this work suggests that we should be vigilant regarding
the potential risks of using these metrics.
</p>
</div>
</dd>
<dt><a name="item12">[12]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03372" title="Abstract">arXiv:2311.03372</a> [<a href="/pdf/2311.03372" title="Download PDF">pdf</a>, <a href="/ps/2311.03372" title="Download PostScript">ps</a>, <a href="/format/2311.03372" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Declaration of Software Independence
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jamroga%2C+W">Wojciech Jamroga</a>, 
<a href="/search/cs?searchtype=author&query=Ryan%2C+P+Y+A">Peter Y.A. Ryan</a>, 
<a href="/search/cs?searchtype=author&query=Schneider%2C+S">Steve Schneider</a>, 
<a href="/search/cs?searchtype=author&query=Schurmann%2C+C">Carsten Schurmann</a>, 
<a href="/search/cs?searchtype=author&query=Stark%2C+P+B">Philip B. Stark</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
<p class="mathjax">A voting system should not merely report the outcome: it should also provide
sufficient evidence to convince reasonable observers that the reported outcome
is correct. Many deployed systems, notably paperless DRE machines still in use
in US elections, fail certainly the second, and quite possibly the first of
these requirements. Rivest and Wack proposed the principle of software
independence (SI) as a guiding principle and requirement for voting systems. In
essence, a voting system is SI if its reliance on software is
``tamper-evident'', that is, if there is a way to detect that material changes
were made to the software without inspecting that software. This important
notion has so far been formulated only informally.
<br />Here, we provide more formal mathematical definitions of SI. This exposes
some subtleties and gaps in the original definition, among them: what elements
of a system must be trusted for an election or system to be SI, how to
formalize ``detection'' of a change to an election outcome, the fact that SI is
with respect to a set of detection mechanisms (which must be legal and
practical), the need to limit false alarms, and how SI applies when the social
choice function is not deterministic.
</p>
</div>
</dd>
<dt><a name="item13">[13]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03373" title="Abstract">arXiv:2311.03373</a> [<a href="/pdf/2311.03373" title="Download PDF">pdf</a>, <a href="/format/2311.03373" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Unscrambling the Rectification of Adversarial Attacks Transferability  across Computer Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nowroozi%2C+E">Ehsan Nowroozi</a>, 
<a href="/search/cs?searchtype=author&query=Ghelichkhani%2C+S">Samaneh Ghelichkhani</a>, 
<a href="/search/cs?searchtype=author&query=Haider%2C+I">Imran Haider</a>, 
<a href="/search/cs?searchtype=author&query=Dehghantanha%2C+A">Ali Dehghantanha</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Convolutional neural networks (CNNs) models play a vital role in achieving
state-of-the-art performances in various technological fields. CNNs are not
limited to Natural Language Processing (NLP) or Computer Vision (CV) but also
have substantial applications in other technological domains, particularly in
cybersecurity. The reliability of CNN's models can be compromised because of
their susceptibility to adversarial attacks, which can be generated
effortlessly, easily applied, and transferred in real-world scenarios.
<br />In this paper, we present a novel and comprehensive method to improve the
strength of attacks and assess the transferability of adversarial examples in
CNNs when such strength changes, as well as whether the transferability
property issue exists in computer network applications. In the context of our
study, we initially examined six distinct modes of attack: the Carlini and
Wagner (C&amp;W), Fast Gradient Sign Method (FGSM), Iterative Fast Gradient Sign
Method (I-FGSM), Jacobian-based Saliency Map (JSMA), Limited-memory Broyden
fletcher Goldfarb Shanno (L-BFGS), and Projected Gradient Descent (PGD) attack.
We applied these attack techniques on two popular datasets: the CIC and UNSW
datasets. The outcomes of our experiment demonstrate that an improvement in
transferability occurs in the targeted scenarios for FGSM, JSMA, LBFGS, and
other attacks. Our findings further indicate that the threats to security posed
by adversarial examples, even in computer network applications, necessitate the
development of novel defense mechanisms to enhance the security of DL-based
techniques.
</p>
</div>
</dd>
<dt><a name="item14">[14]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03374" title="Abstract">arXiv:2311.03374</a> [<a href="/pdf/2311.03374" title="Download PDF">pdf</a>, <a href="/format/2311.03374" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Generative AI for Software Metadata: Overview of the Information  Retrieval in Software Engineering Track at FIRE 2023
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Majumdar%2C+S">Srijoni Majumdar</a>, 
<a href="/search/cs?searchtype=author&query=Paul%2C+S">Soumen Paul</a>, 
<a href="/search/cs?searchtype=author&query=Paul%2C+D">Debjyoti Paul</a>, 
<a href="/search/cs?searchtype=author&query=Bandyopadhyay%2C+A">Ayan Bandyopadhyay</a>, 
<a href="/search/cs?searchtype=author&query=Chattopadhyay%2C+S">Samiran Chattopadhyay</a>, 
<a href="/search/cs?searchtype=author&query=Das%2C+P+P">Partha Pratim Das</a>, 
<a href="/search/cs?searchtype=author&query=Clough%2C+P+D">Paul D Clough</a>, 
<a href="/search/cs?searchtype=author&query=Majumder%2C+P">Prasenjit Majumder</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Overview Paper of the Information Retrieval of Software Engineering Track at the Forum for Information Retrieval, 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>; Artificial Intelligence (cs.AI); Information Retrieval (cs.IR)

</div>
<p class="mathjax">The Information Retrieval in Software Engineering (IRSE) track aims to
develop solutions for automated evaluation of code comments in a machine
learning framework based on human and large language model generated labels. In
this track, there is a binary classification task to classify comments as
useful and not useful. The dataset consists of 9048 code comments and
surrounding code snippet pairs extracted from open source github C based
projects and an additional dataset generated individually by teams using large
language models. Overall 56 experiments have been submitted by 17 teams from
various universities and software companies. The submissions have been
evaluated quantitatively using the F1-Score and qualitatively based on the type
of features developed, the supervised learning model used and their
corresponding hyper-parameters. The labels generated from large language models
increase the bias in the prediction model but lead to less over-fitted results.
</p>
</div>
</dd>
<dt><a name="item15">[15]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03375" title="Abstract">arXiv:2311.03375</a> [<a href="/pdf/2311.03375" title="Download PDF">pdf</a>, <a href="/format/2311.03375" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Edge AI Inference in Heterogeneous Constrained Computing: Feasibility  and Opportunities
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Morabito%2C+R">Roberto Morabito</a>, 
<a href="/search/cs?searchtype=author&query=Tatipamula%2C+M">Mallik Tatipamula</a>, 
<a href="/search/cs?searchtype=author&query=Tarkoma%2C+S">Sasu Tarkoma</a>, 
<a href="/search/cs?searchtype=author&query=Chiang%2C+M">Mung Chiang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This paper has been accepted for publication in the proceedings of the IEEE International Workshop on Computer Aided Modeling and Design of Communication Links and Networks 2023 (IEEE CAMAD 2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Hardware Architecture (cs.AR)</span>; Artificial Intelligence (cs.AI); Distributed, Parallel, and Cluster Computing (cs.DC); Networking and Internet Architecture (cs.NI)

</div>
<p class="mathjax">The network edge's role in Artificial Intelligence (AI) inference processing
is rapidly expanding, driven by a plethora of applications seeking
computational advantages. These applications strive for data-driven efficiency,
leveraging robust AI capabilities and prioritizing real-time responsiveness.
However, as demand grows, so does system complexity. The proliferation of AI
inference accelerators showcases innovation but also underscores challenges,
particularly the varied software and hardware configurations of these devices.
This diversity, while advantageous for certain tasks, introduces hurdles in
device integration and coordination. In this paper, our objectives are
three-fold. Firstly, we outline the requirements and components of a framework
that accommodates hardware diversity. Next, we assess the impact of device
heterogeneity on AI inference performance, identifying strategies to optimize
outcomes without compromising service quality. Lastly, we shed light on the
prevailing challenges and opportunities in this domain, offering insights for
both the research community and industry stakeholders.
</p>
</div>
</dd>
<dt><a name="item16">[16]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03376" title="Abstract">arXiv:2311.03376</a> [<a href="/pdf/2311.03376" title="Download PDF">pdf</a>, <a href="/format/2311.03376" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Blocked Collaborative Bandits: Online Collaborative Filtering with  Per-Item Budget Constraints
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pal%2C+S">Soumyabrata Pal</a>, 
<a href="/search/cs?searchtype=author&query=Suggala%2C+A+S">Arun Sai Suggala</a>, 
<a href="/search/cs?searchtype=author&query=Shanmugam%2C+K">Karthikeyan Shanmugam</a>, 
<a href="/search/cs?searchtype=author&query=Jain%2C+P">Prateek Jain</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 44 pages, To Appear in NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Machine Learning (cs.LG); Machine Learning (stat.ML)

</div>
<p class="mathjax">We consider the problem of \emph{blocked} collaborative bandits where there
are multiple users, each with an associated multi-armed bandit problem. These
users are grouped into \emph{latent} clusters such that the mean reward vectors
of users within the same cluster are identical. Our goal is to design
algorithms that maximize the cumulative reward accrued by all the users over
time, under the \emph{constraint} that no arm of a user is pulled more than
$\mathsf{B}$ times. This problem has been originally considered by
\cite{Bresler:2014}, and designing regret-optimal algorithms for it has since
remained an open problem. In this work, we propose an algorithm called
\texttt{B-LATTICE} (Blocked Latent bAndiTs via maTrIx ComplEtion) that
collaborates across users, while simultaneously satisfying the budget
constraints, to maximize their cumulative rewards. Theoretically, under certain
reasonable assumptions on the latent structure, with $\mathsf{M}$ users,
$\mathsf{N}$ arms, $\mathsf{T}$ rounds per user, and $\mathsf{C}=O(1)$ latent
clusters, \texttt{B-LATTICE} achieves a per-user regret of
$\widetilde{O}(\sqrt{\mathsf{T}(1 + \mathsf{N}\mathsf{M}^{-1})}$ under a budget
constraint of $\mathsf{B}=\Theta(\log \mathsf{T})$. These are the first
sub-linear regret bounds for this problem, and match the minimax regret bounds
when $\mathsf{B}=\mathsf{T}$. Empirically, we demonstrate that our algorithm
has superior performance over baselines even when $\mathsf{B}=1$.
\texttt{B-LATTICE} runs in phases where in each phase it clusters users into
groups and collaborates across users within a group to quickly learn their
reward models.
</p>
</div>
</dd>
<dt><a name="item17">[17]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03379" title="Abstract">arXiv:2311.03379</a> [<a href="/pdf/2311.03379" title="Download PDF">pdf</a>, <a href="/format/2311.03379" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> HIDA: A Hierarchical Dataflow Compiler for High-Level Synthesis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ye%2C+H">Hanchen Ye</a>, 
<a href="/search/cs?searchtype=author&query=Jun%2C+H">Hyegang Jun</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+D">Deming Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ASPLOS'24
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Hardware Architecture (cs.AR)</span>; Programming Languages (cs.PL)

</div>
<p class="mathjax">Dataflow architectures are growing in popularity due to their potential to
mitigate the challenges posed by the memory wall inherent to the Von Neumann
architecture. At the same time, high-level synthesis (HLS) has demonstrated its
efficacy as a design methodology for generating efficient dataflow
architectures within a short development cycle. However, existing HLS tools
rely on developers to explore the vast dataflow design space, ultimately
leading to suboptimal designs. This phenomenon is especially concerning as the
size of the HLS design grows. To tackle these challenges, we introduce HIDA, a
new scalable and hierarchical HLS framework that can systematically convert an
algorithmic description into a dataflow implementation on hardware. We first
propose a collection of efficient and versatile dataflow representations for
modeling the hierarchical dataflow structure. Capitalizing on these
representations, we develop an automated optimizer that decomposes the dataflow
optimization problem into multiple levels based on the inherent dataflow
hierarchy. Using FPGAs as an evaluation platform, working with a set of neural
networks modeled in PyTorch, HIDA achieves up to 8.54$\times$ higher throughput
compared to the state-of-the-art (SOTA) HLS optimization tool. Furthermore,
despite being fully automated and able to handle various applications, HIDA
achieves 1.29$\times$ higher throughput over the SOTA RTL-based neural network
accelerators on an FPGA.
</p>
</div>
</dd>
<dt><a name="item18">[18]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03380" title="Abstract">arXiv:2311.03380</a> [<a href="/pdf/2311.03380" title="Download PDF">pdf</a>, <a href="/ps/2311.03380" title="Download PostScript">ps</a>, <a href="/format/2311.03380" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An attempt to generate new bridge types from latent space of variational  autoencoder
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Hongjun Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages, 8 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Try to generate new bridge types using generative artificial intelligence
technology. The grayscale images of the bridge facade with the change of
component width was rendered by 3dsMax animation software, and then the OpenCV
module performed an appropriate amount of geometric transformation (rotation,
horizontal scale, vertical scale) to obtain the image dataset of three-span
beam bridge, arch bridge, cable-stayed bridge and suspension bridge. Based on
Python programming language, TensorFlow and Keras deep learning platform
framework, variational autoencoder was constructed and trained, and
low-dimensional bridge-type latent space that is convenient for vector
operations was obtained. Variational autoencoder can combine two bridge types
on the basis of the original of human into one that is a new bridge type.
Generative artificial intelligence technology can assist bridge designers in
bridge-type innovation, and can be used as copilot.
</p>
</div>
</dd>
<dt><a name="item19">[19]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03381" title="Abstract">arXiv:2311.03381</a> [<a href="/pdf/2311.03381" title="Download PDF">pdf</a>, <a href="/format/2311.03381" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Separating and Learning Latent Confounders to Enhancing User Preferences  Modeling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+H">Hangtong Xu</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+Y">Yuanbo Xu</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yongjian Yang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Methodology (stat.ME)

</div>
<p class="mathjax">Recommender models aim to capture user preferences from historical feedback
and then predict user-specific feedback on candidate items. However, the
presence of various unmeasured confounders causes deviations between the user
preferences in the historical feedback and the true preferences, resulting in
models not meeting their expected performance. Existing debias models either
(1) specific to solving one particular bias or (2) directly obtain auxiliary
information from user historical feedback, which cannot identify whether the
learned preferences are true user preferences or mixed with unmeasured
confounders. Moreover, we find that the former recommender system is not only a
successor to unmeasured confounders but also acts as an unmeasured confounder
affecting user preference modeling, which has always been neglected in previous
studies. To this end, we incorporate the effect of the former recommender
system and treat it as a proxy for all unmeasured confounders. We propose a
novel framework, \textbf{S}eparating and \textbf{L}earning Latent Confounders
\textbf{F}or \textbf{R}ecommendation (\textbf{SLFR}), which obtains the
representation of unmeasured confounders to identify the counterfactual
feedback by disentangling user preferences and unmeasured confounders, then
guides the target model to capture the true preferences of users. Extensive
experiments in five real-world datasets validate the advantages of our method.
</p>
</div>
</dd>
<dt><a name="item20">[20]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03382" title="Abstract">arXiv:2311.03382</a> [<a href="/pdf/2311.03382" title="Download PDF">pdf</a>, <a href="/format/2311.03382" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Causal Structure Representation Learning of Confounders in Latent Space  for Recommendation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+H">Hangtong Xu</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+Y">Yuanbo Xu</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yongjian Yang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Methodology (stat.ME)

</div>
<p class="mathjax">Inferring user preferences from the historical feedback of users is a
valuable problem in recommender systems. Conventional approaches often rely on
the assumption that user preferences in the feedback data are equivalent to the
real user preferences without additional noise, which simplifies the problem
modeling. However, there are various confounders during user-item interactions,
such as weather and even the recommendation system itself. Therefore,
neglecting the influence of confounders will result in inaccurate user
preferences and suboptimal performance of the model. Furthermore, the
unobservability of confounders poses a challenge in further addressing the
problem. To address these issues, we refine the problem and propose a more
rational solution. Specifically, we consider the influence of confounders,
disentangle them from user preferences in the latent space, and employ causal
graphs to model their interdependencies without specific labels. By cleverly
combining local and global causal graphs, we capture the user-specificity of
confounders on user preferences. We theoretically demonstrate the
identifiability of the obtained causal graph. Finally, we propose our model
based on Variational Autoencoders, named Causal Structure representation
learning of Confounders in latent space (CSC). We conducted extensive
experiments on one synthetic dataset and five real-world datasets,
demonstrating the superiority of our model. Furthermore, we demonstrate that
the learned causal representations of confounders are controllable, potentially
offering users fine-grained control over the objectives of their recommendation
lists with the learned causal graphs.
</p>
</div>
</dd>
<dt><a name="item21">[21]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03383" title="Abstract">arXiv:2311.03383</a> [<a href="/pdf/2311.03383" title="Download PDF">pdf</a>, <a href="/format/2311.03383" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Toward Reinforcement Learning-based Rectilinear Macro Placement Under  Human Constraints
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Le%2C+T+P">Tuyen P. Le</a>, 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+H+T">Hieu T. Nguyen</a>, 
<a href="/search/cs?searchtype=author&query=Baek%2C+S">Seungyeol Baek</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+T">Taeyoun Kim</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+J">Jungwoo Lee</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+S">Seongjung Kim</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+H">Hyunjin Kim</a>, 
<a href="/search/cs?searchtype=author&query=Jung%2C+M">Misu Jung</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+D">Daehoon Kim</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+S">Seokyong Lee</a>, 
<a href="/search/cs?searchtype=author&query=Choi%2C+D">Daewoo Choi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Fast ML for Science @ ICCAD 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Hardware Architecture (cs.AR); Human-Computer Interaction (cs.HC)

</div>
<p class="mathjax">Macro placement is a critical phase in chip design, which becomes more
intricate when involving general rectilinear macros and layout areas.
Furthermore, macro placement that incorporates human-like constraints, such as
design hierarchy and peripheral bias, has the potential to significantly reduce
the amount of additional manual labor required from designers. This study
proposes a methodology that leverages an approach suggested by Google's Circuit
Training (G-CT) to provide a learning-based macro placer that not only supports
placing rectilinear cases, but also adheres to crucial human-like design
principles. Our experimental results demonstrate the effectiveness of our
framework in achieving power-performance-area (PPA) metrics and in obtaining
placements of high quality, comparable to those produced with human
intervention. Additionally, our methodology shows potential as a generalized
model to address diverse macro shapes and layout areas.
</p>
</div>
</dd>
<dt><a name="item22">[22]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03384" title="Abstract">arXiv:2311.03384</a> [<a href="/pdf/2311.03384" title="Download PDF">pdf</a>, <a href="/ps/2311.03384" title="Download PostScript">ps</a>, <a href="/format/2311.03384" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Serious Games in Digital Gaming: A Comprehensive Review of Applications,  Game Engines and Advancements
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gazis%2C+A">Alexandros Gazis</a>, 
<a href="/search/cs?searchtype=author&query=Katsiri%2C+E">Eleftheria Katsiri</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, 98 references, This is an Accepted Manuscript of an article published by Wseas Transactions on Computer Research on 2023, available online: <a href="http://dx.doi.org/10.37394/232018.2023.11.2">this http URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
<p class="mathjax">Serious games are defined as applied games that focus on the gamification of
an experience (e.g., learning and training activities) and are not strictly for
entertainment purposes. In recent years, serious games have become increasingly
popular due to their ability to simultaneously educate and entertain users. In
this review, we provide a comprehensive overview of the different types of
digital games and expand on the serious games genre while focusing on its
various applications. Furthermore, we present the most widely used game engines
used in the game development industry and extend the Unity game machine
advantages. Lastly, we conclude our research with a detailed comparison of the
two most popular choices (Unreal and Unity engines) and their respective
advantages and disadvantages while providing future suggestions for serious
digital game development.
</p>
</div>
</dd>
<dt><a name="item23">[23]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03385" title="Abstract">arXiv:2311.03385</a> [<a href="/pdf/2311.03385" title="Download PDF">pdf</a>, <a href="/format/2311.03385" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Intelligent Stress Assessment for e-Coaching
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lai%2C+K">Kenneth Lai</a>, 
<a href="/search/cs?searchtype=author&query=Yanushkevich%2C+S">Svetlana Yanushkevich</a>, 
<a href="/search/cs?searchtype=author&query=Shmerko%2C+V">Vlad Shmerko</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> submitted to IEEE Symposium Series on Computational Intelligence. arXiv admin note: substantial text overlap with <a href="/abs/2105.11437">arXiv:2105.11437</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">This paper considers the adaptation of the e-coaching concept at times of
emergencies and disasters, through aiding the e-coaching with intelligent tools
for monitoring humans' affective state. The states such as anxiety, panic,
avoidance, and stress, if properly detected, can be mitigated using the
e-coaching tactic and strategy. In this work, we focus on a stress monitoring
assistant tool developed on machine learning techniques. We provide the results
of an experimental study using the proposed method.
</p>
</div>
</dd>
<dt><a name="item24">[24]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03386" title="Abstract">arXiv:2311.03386</a> [<a href="/pdf/2311.03386" title="Download PDF">pdf</a>, <a href="/format/2311.03386" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Simple and Efficient Baseline for Data Attribution on Images
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Singla%2C+V">Vasu Singla</a>, 
<a href="/search/cs?searchtype=author&query=Sandoval-Segura%2C+P">Pedro Sandoval-Segura</a>, 
<a href="/search/cs?searchtype=author&query=Goldblum%2C+M">Micah Goldblum</a>, 
<a href="/search/cs?searchtype=author&query=Geiping%2C+J">Jonas Geiping</a>, 
<a href="/search/cs?searchtype=author&query=Goldstein%2C+T">Tom Goldstein</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Code available at <a href="https://github.com/vasusingla/simple-data-attribution">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Data attribution methods play a crucial role in understanding machine
learning models, providing insight into which training data points are most
responsible for model outputs during deployment. However, current
state-of-the-art approaches require a large ensemble of as many as 300,000
models to accurately attribute model predictions. These approaches therefore
come at a high computational cost, are memory intensive, and are hard to scale
to large models or datasets. In this work, we focus on a minimalist baseline,
utilizing the feature space of a backbone pretrained via self-supervised
learning to perform data attribution. Our method is model-agnostic and scales
easily to large datasets. We show results on CIFAR-10 and ImageNet, achieving
strong performance that rivals or outperforms state-of-the-art approaches at a
fraction of the compute or memory cost. Contrary to prior work, our results
reinforce the intuition that a model's prediction on one image is most impacted
by visually similar training samples. Our approach serves as a simple and
efficient baseline for data attribution on images.
</p>
</div>
</dd>
<dt><a name="item25">[25]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03387" title="Abstract">arXiv:2311.03387</a> [<a href="/pdf/2311.03387" title="Download PDF">pdf</a>, <a href="/format/2311.03387" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Determination of droplet size from wide-angle light scattering image  data using convolutional neural networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kirstein%2C+T">Tom Kirstein</a>, 
<a href="/search/cs?searchtype=author&query=A%C3%9Fmann%2C+S">Simon A&#xdf;mann</a>, 
<a href="/search/cs?searchtype=author&query=Furat%2C+O">Orkun Furat</a>, 
<a href="/search/cs?searchtype=author&query=Will%2C+S">Stefan Will</a>, 
<a href="/search/cs?searchtype=author&query=Schmidt%2C+V">Volker Schmidt</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Wide-angle light scattering (WALS) offers the possibility of a highly
temporally and spatially resolved measurement of droplets in spray-based
methods for nanoparticle synthesis. The size of these droplets is a critical
variable affecting the final properties of synthesized materials such as
hetero-aggregates. However, conventional methods for determining droplet sizes
from WALS image data are labor-intensive and may introduce biases, particularly
when applied to complex systems like spray flame synthesis (SFS). To address
these challenges, we introduce a fully automatic machine learning-based
approach that employs convolutional neural networks (CNNs) in order to
streamline the droplet sizing process. This CNN-based methodology offers
further advantages: it requires few manual labels and can utilize transfer
learning, making it a promising alternative to conventional methods,
specifically with respect to efficiency. To evaluate the performance of our
machine learning models, we consider WALS data from an ethanol spray flame
process at various heights above the burner surface (HABs), where the models
are trained and cross-validated on a large dataset comprising nearly 35000 WALS
images.
</p>
</div>
</dd>
<dt><a name="item26">[26]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03388" title="Abstract">arXiv:2311.03388</a> [<a href="/pdf/2311.03388" title="Download PDF">pdf</a>, <a href="/format/2311.03388" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Attention-based Models for Snow-Water Equivalent Prediction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Thapa%2C+K+K">Krishu K. Thapa</a>, 
<a href="/search/cs?searchtype=author&query=Singh%2C+B">Bhupinderjeet Singh</a>, 
<a href="/search/cs?searchtype=author&query=Savalkar%2C+S">Supriya Savalkar</a>, 
<a href="/search/cs?searchtype=author&query=Fern%2C+A">Alan Fern</a>, 
<a href="/search/cs?searchtype=author&query=Rajagopalan%2C+K">Kirti Rajagopalan</a>, 
<a href="/search/cs?searchtype=author&query=Kalyanaraman%2C+A">Ananth Kalyanaraman</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, To be published in Proceedings of The Thirty-Sixth Annual Conference on Innovative Applications of Artificial Intelligence (IAAI-24)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Atmospheric and Oceanic Physics (physics.ao-ph)

</div>
<p class="mathjax">Snow Water-Equivalent (SWE) -- the amount of water available if snowpack is
melted -- is a key decision variable used by water management agencies to make
irrigation, flood control, power generation and drought management decisions.
SWE values vary spatiotemporally -- affected by weather, topography and other
environmental factors. While daily SWE can be measured by Snow Telemetry
(SNOTEL) stations with requisite instrumentation, such stations are spatially
sparse requiring interpolation techniques to create spatiotemporally complete
data. While recent efforts have explored machine learning (ML) for SWE
prediction, a number of recent ML advances have yet to be considered. The main
contribution of this paper is to explore one such ML advance, attention
mechanisms, for SWE prediction. Our hypothesis is that attention has a unique
ability to capture and exploit correlations that may exist across locations or
the temporal spectrum (or both). We present a generic attention-based modeling
framework for SWE prediction and adapt it to capture spatial attention and
temporal attention. Our experimental results on 323 SNOTEL stations in the
Western U.S. demonstrate that our attention-based models outperform other
machine learning approaches. We also provide key results highlighting the
differences between spatial and temporal attention in this context and a
roadmap toward deployment for generating spatially-complete SWE maps.
</p>
</div>
</dd>
<dt><a name="item27">[27]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03390" title="Abstract">arXiv:2311.03390</a> [<a href="/pdf/2311.03390" title="Download PDF">pdf</a>, <a href="/ps/2311.03390" title="Download PostScript">ps</a>, <a href="/format/2311.03390" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FPGA-QHAR: Throughput-Optimized for Quantized Human Action Recognition  on The Edge
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Alhussain%2C+A">Azzam Alhussain</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+M">Mingjie Lin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages, 7 Figures, 2 tables, 20th IEEE HONET 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Image and Video Processing (eess.IV)

</div>
<p class="mathjax">Accelerating Human Action Recognition (HAR) efficiently for real-time
surveillance and robotic systems on edge chips remains a challenging research
field, given its high computational and memory requirements. This paper
proposed an integrated end-to-end HAR scalable HW/SW accelerator co-design
based on an enhanced 8-bit quantized Two-Stream SimpleNet-PyTorch CNN
architecture. Our network accelerator was trained on UCF101 and UCF24 datasets
and implemented on edge SoC-FPGA. Our development uses partially streaming
dataflow architecture to achieve higher throughput versus network design and
resource utilization trade-off. We also fused all convolutional, batch-norm,
and ReLU operations into a single homogeneous layer and utilized the
Lucas-Kanade motion flow method to enable a high parallelism accelerator design
and optimized on-chip engine computing.Furthermore, our proposed methodology
achieved nearly 81% prediction accuracy with an approximately 24 FPS real-time
inference throughput at 187MHz on ZCU104, which is 1.7x - 1.9x higher than the
prior research. Lastly, the designed framework was benchmarked against several
hardware chips for higher throughput and performance measurements and is now
available as an open-source project on GitHub for training and implementation
on edge platforms.
</p>
</div>
</dd>
<dt><a name="item28">[28]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03393" title="Abstract">arXiv:2311.03393</a> [<a href="/pdf/2311.03393" title="Download PDF">pdf</a>, <a href="/format/2311.03393" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Sketching Multidimensional Time Series for Fast Discord Mining
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yeh%2C+C+M">Chin-Chia Michael Yeh</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+Y">Yan Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Pan%2C+M">Menghai Pan</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+H">Huiyuan Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhuang%2C+Z">Zhongfang Zhuang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Junpeng Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+L">Liang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+W">Wei Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Phillips%2C+J+M">Jeff M. Phillips</a>, 
<a href="/search/cs?searchtype=author&query=Keogh%2C+E">Eamonn Keogh</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Databases (cs.DB)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Time series discords are a useful primitive for time series anomaly
detection, and the matrix profile is capable of capturing discord effectively.
There exist many research efforts to improve the scalability of discord
discovery with respect to the length of time series. However, there is
surprisingly little work focused on reducing the time complexity of matrix
profile computation associated with dimensionality of a multidimensional time
series. In this work, we propose a sketch for discord mining among
multi-dimensional time series. After an initial pre-processing of the sketch as
fast as reading the data, the discord mining has runtime independent of the
dimensionality of the original data. On several real world examples from water
treatment and transportation, the proposed algorithm improves the throughput by
at least an order of magnitude (50X) and only has minimal impact on the quality
of the approximated solution. Additionally, the proposed method can handle the
dynamic addition or deletion of dimensions inconsequential overhead. This
allows a data analyst to consider "what-if" scenarios in real time while
exploring the data.
</p>
</div>
</dd>
<dt><a name="item29">[29]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03395" title="Abstract">arXiv:2311.03395</a> [<a href="/pdf/2311.03395" title="Download PDF">pdf</a>, <a href="/format/2311.03395" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Newvision: application for helping blind people using deep learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bobba%2C+K+S">Kumar Srinivas Bobba</a>, 
<a href="/search/cs?searchtype=author&query=K%2C+K">Kartheeban K</a>, 
<a href="/search/cs?searchtype=author&query=Boddu%2C+V+K+S">Vamsi Krishna Sai Boddu</a>, 
<a href="/search/cs?searchtype=author&query=Bolla%2C+V+M+S">Vijaya Mani Surendra Bolla</a>, 
<a href="/search/cs?searchtype=author&query=Bugga%2C+D">Dinesh Bugga</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">As able-bodied people, we often take our vision for granted. For people who
are visually impaired, however, their disability can have a significant impact
on their daily lives. We are developing proprietary headgear that will help
visually impaired people navigate their surroundings, identify objects and
people, read text, and avoid obstacles. The headgear will use a combination of
computer vision, distance estimation with ultrasonic sensors, voice
recognition, and voice assistants to provide users with real-time information
about their environment. Users will be able to interact with the headgear
through voice commands, such as ''What is that?'' to identify an object or
''Navigate to the front door'' to find their way around. The headgear will then
provide the user with a verbal description of the object or spoken navigation
instructions. We believe that this headgear has the potential to make a
significant difference in the lives of visually impaired people, allowing them
to live more independently and participate more fully in society.
</p>
</div>
</dd>
<dt><a name="item30">[30]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03396" title="Abstract">arXiv:2311.03396</a> [<a href="/pdf/2311.03396" title="Download PDF">pdf</a>, <a href="/format/2311.03396" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Differentially Private Pre-Trained Model Fusion using Decentralized  Federated Graph Matching
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+Q">Qian Chen</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yiqiang Chen</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+X">Xinlong Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+T">Teng Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Dai%2C+W">Weiwei Dai</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+W">Wuliang Huang</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+Z">Zhen Yan</a>, 
<a href="/search/cs?searchtype=author&query=Ye%2C+B">Bo Ye</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Cryptography and Security (cs.CR)

</div>
<p class="mathjax">Model fusion is becoming a crucial component in the context of
model-as-a-service scenarios, enabling the delivery of high-quality model
services to local users. However, this approach introduces privacy risks and
imposes certain limitations on its applications. Ensuring secure model exchange
and knowledge fusion among users becomes a significant challenge in this
setting. To tackle this issue, we propose PrivFusion, a novel architecture that
preserves privacy while facilitating model fusion under the constraints of
local differential privacy. PrivFusion leverages a graph-based structure,
enabling the fusion of models from multiple parties without necessitating
retraining. By employing randomized mechanisms, PrivFusion ensures privacy
guarantees throughout the fusion process. To enhance model privacy, our
approach incorporates a hybrid local differentially private mechanism and
decentralized federated graph matching, effectively protecting both activation
values and weights. Additionally, we introduce a perturbation filter adapter to
alleviate the impact of randomized noise, thereby preserving the utility of the
fused model. Through extensive experiments conducted on diverse image datasets
and real-world healthcare applications, we provide empirical evidence
showcasing the effectiveness of PrivFusion in maintaining model performance
while preserving privacy. Our contributions offer valuable insights and
practical solutions for secure and collaborative data analysis within the
domain of privacy-preserving model fusion.
</p>
</div>
</dd>
<dt><a name="item31">[31]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03401" title="Abstract">arXiv:2311.03401</a> [<a href="/pdf/2311.03401" title="Download PDF">pdf</a>, <a href="/format/2311.03401" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Enhancing AI Research Paper Analysis: Methodology Component Extraction  using Factored Transformer-based Sequence Modeling Approach
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ghosh%2C+M">Madhusudan Ghosh</a>, 
<a href="/search/cs?searchtype=author&query=Ganguly%2C+D">Debasis Ganguly</a>, 
<a href="/search/cs?searchtype=author&query=Basuchowdhuri%2C+P">Partha Basuchowdhuri</a>, 
<a href="/search/cs?searchtype=author&query=Naskar%2C+S+K">Sudip Kumar Naskar</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Digital Libraries (cs.DL); Machine Learning (cs.LG)

</div>
<p class="mathjax">Research in scientific disciplines evolves, often rapidly, over time with the
emergence of novel methodologies and their associated terminologies. While
methodologies themselves being conceptual in nature and rather difficult to
automatically extract and characterise, in this paper, we seek to develop
supervised models for automatic extraction of the names of the various
constituents of a methodology, e.g., `R-CNN', `ELMo' etc. The main research
challenge for this task is effectively modeling the contexts around these
methodology component names in a few-shot or even a zero-shot setting. The main
contributions of this paper towards effectively identifying new evolving
scientific methodology names are as follows: i) we propose a factored approach
to sequence modeling, which leverages a broad-level category information of
methodology domains, e.g., `NLP', `RL' etc.; ii) to demonstrate the feasibility
of our proposed approach of identifying methodology component names under a
practical setting of fast evolving AI literature, we conduct experiments
following a simulated chronological setup (newer methodologies not seen during
the training process); iii) our experiments demonstrate that the factored
approach outperforms state-of-the-art baselines by margins of up to 9.257\% for
the methodology extraction task with the few-shot setup.
</p>
</div>
</dd>
<dt><a name="item32">[32]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03402" title="Abstract">arXiv:2311.03402</a> [<a href="/pdf/2311.03402" title="Download PDF">pdf</a>, <a href="/format/2311.03402" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CycleCL: Self-supervised Learning for Periodic Videos
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Destro%2C+M">Matteo Destro</a>, 
<a href="/search/cs?searchtype=author&query=Gygli%2C+M">Michael Gygli</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at WACV 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Analyzing periodic video sequences is a key topic in applications such as
automatic production systems, remote sensing, medical applications, or physical
training. An example is counting repetitions of a physical exercise. Due to the
distinct characteristics of periodic data, self-supervised methods designed for
standard image datasets do not capture changes relevant to the progression of
the cycle and fail to ignore unrelated noise. They thus do not work well on
periodic data. In this paper, we propose CycleCL, a self-supervised learning
method specifically designed to work with periodic data. We start from the
insight that a good visual representation for periodic data should be sensitive
to the phase of a cycle, but be invariant to the exact repetition, i.e. it
should generate identical representations for a specific phase throughout all
repetitions. We exploit the repetitions in videos to design a novel contrastive
learning method based on a triplet loss that optimizes for these desired
properties. Our method uses pre-trained features to sample pairs of frames from
approximately the same phase and negative pairs of frames from different
phases. Then, we iterate between optimizing a feature encoder and resampling
triplets, until convergence. By optimizing a model this way, we are able to
learn features that have the mentioned desired properties. We evaluate CycleCL
on an industrial and multiple human actions datasets, where it significantly
outperforms previous video-based self-supervised learning methods on all tasks.
</p>
</div>
</dd>
<dt><a name="item33">[33]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03405" title="Abstract">arXiv:2311.03405</a> [<a href="/pdf/2311.03405" title="Download PDF">pdf</a>, <a href="/format/2311.03405" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Communication Efficient and Privacy-Preserving Federated Learning Based  on Evolution Strategies
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lan%2C+G">Guangchen Lan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Federated learning (FL) is an emerging paradigm for training deep neural
networks (DNNs) in distributed manners. Current FL approaches all suffer from
high communication overhead and information leakage. In this work, we present a
federated learning algorithm based on evolution strategies (FedES), a
zeroth-order training method. Instead of transmitting model parameters, FedES
only communicates loss values, and thus has very low communication overhead.
Moreover, a third party is unable to estimate gradients without knowing the
pre-shared seed, which protects data privacy. Experimental results demonstrate
FedES can achieve the above benefits while keeping convergence performance the
same as that with back propagation methods.
</p>
</div>
</dd>
<dt><a name="item34">[34]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03408" title="Abstract">arXiv:2311.03408</a> [<a href="/pdf/2311.03408" title="Download PDF">pdf</a>, <a href="/format/2311.03408" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Training Multi-layer Neural Networks on Ising Machine
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Song%2C+X">Xujie Song</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+T">Tong Liu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+S+E">Shengbo Eben Li</a>, 
<a href="/search/cs?searchtype=author&query=Duan%2C+J">Jingliang Duan</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+W">Wenxuan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+K">Keqiang Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Neural and Evolutionary Computing (cs.NE); Quantum Physics (quant-ph)

</div>
<p class="mathjax">As a dedicated quantum device, Ising machines could solve large-scale binary
optimization problems in milliseconds. There is emerging interest in utilizing
Ising machines to train feedforward neural networks due to the prosperity of
generative artificial intelligence. However, existing methods can only train
single-layer feedforward networks because of the complex nonlinear network
topology. This paper proposes an Ising learning algorithm to train quantized
neural network (QNN), by incorporating two essential techinques, namely binary
representation of topological network and order reduction of loss function. As
far as we know, this is the first algorithm to train multi-layer feedforward
networks on Ising machines, providing an alternative to gradient-based
backpropagation. Firstly, training QNN is formulated as a quadratic constrained
binary optimization (QCBO) problem by representing neuron connection and
activation function as equality constraints. All quantized variables are
encoded by binary bits based on binary encoding protocol. Secondly, QCBO is
converted to a quadratic unconstrained binary optimization (QUBO) problem, that
can be efficiently solved on Ising machines. The conversion leverages both
penalty function and Rosenberg order reduction, who together eliminate equality
constraints and reduce high-order loss function into a quadratic one. With some
assumptions, theoretical analysis shows the space complexity of our algorithm
is $\mathcal{O}(H^2L + HLN\log H)$, quantifying the required number of Ising
spins. Finally, the algorithm effectiveness is validated with a simulated Ising
machine on MNIST dataset. After annealing 700 ms, the classification accuracy
achieves 98.3%. Among 100 runs, the success probability of finding the optimal
solution is 72%. Along with the increasing number of spins on Ising machine,
our algorithm has the potential to train deeper neural networks.
</p>
</div>
</dd>
<dt><a name="item35">[35]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03410" title="Abstract">arXiv:2311.03410</a> [<a href="/pdf/2311.03410" title="Download PDF">pdf</a>, <a href="/format/2311.03410" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DP-DCAN: Differentially Private Deep Contrastive Autoencoder Network for  Single-cell Clustering
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Huifa Li</a>, 
<a href="/search/cs?searchtype=author&query=Fu%2C+J">Jie Fu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Z">Zhili Chen</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+X">Xiaomin Yang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+H">Haitao Liu</a>, 
<a href="/search/cs?searchtype=author&query=Ling%2C+X">Xinpeng Ling</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Genomics (q-bio.GN)

</div>
<p class="mathjax">Single-cell RNA sequencing (scRNA-seq) is important to transcriptomic
analysis of gene expression. Recently, deep learning has facilitated the
analysis of high-dimensional single-cell data. Unfortunately, deep learning
models may leak sensitive information about users. As a result, Differential
Privacy (DP) is increasingly used to protect privacy. However, existing DP
methods usually perturb whole neural networks to achieve differential privacy,
and hence result in great performance overheads. To address this challenge, in
this paper, we take advantage of the uniqueness of the autoencoder that it
outputs only the dimension-reduced vector in the middle of the network, and
design a Differentially Private Deep Contrastive Autoencoder Network (DP-DCAN)
by partial network perturbation for single-cell clustering. Since only partial
network is added with noise, the performance improvement is obvious and
twofold: one part of network is trained with less noise due to a bigger privacy
budget, and the other part is trained without any noise. Experimental results
of six datasets have verified that DP-DCAN is superior to the traditional DP
scheme with whole network perturbation. Moreover, DP-DCAN demonstrates strong
robustness to adversarial attacks. The code is available at
https://github.com/LFD-byte/DP-DCAN.
</p>
</div>
</dd>
<dt><a name="item36">[36]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03413" title="Abstract">arXiv:2311.03413</a> [<a href="/pdf/2311.03413" title="Download PDF">pdf</a>, <a href="/format/2311.03413" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Discret2Di -- Deep Learning based Discretization for Model-based  Diagnosis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Moddemann%2C+L">Lukas Moddemann</a>, 
<a href="/search/cs?searchtype=author&query=Steude%2C+H+S">Henrik Sebastian Steude</a>, 
<a href="/search/cs?searchtype=author&query=Diedrich%2C+A">Alexander Diedrich</a>, 
<a href="/search/cs?searchtype=author&query=Niggemann%2C+O">Oliver Niggemann</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Consistency-based diagnosis is an established approach to diagnose technical
applications, but suffers from significant modeling efforts, especially for
dynamic multi-modal time series. Machine learning seems to be an obvious
solution, which becomes less obvious when looking at details: Which notion of
consistency can be used? If logical calculi are still to be used, how can
dynamic time series be transferred into the discrete world?
<br />This paper presents the methodology Discret2Di for automated learning of
logical expressions for consistency-based diagnosis. While these logical
calculi have advantages by providing a clear notion of consistency, they have
the key problem of relying on a discretization of the dynamic system. The
solution presented combines machine learning from both the time series and the
symbolic domain to automate the learning of logical rules for consistency-based
diagnosis.
</p>
</div>
</dd>
<dt><a name="item37">[37]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03414" title="Abstract">arXiv:2311.03414</a> [<a href="/pdf/2311.03414" title="Download PDF">pdf</a>, <a href="/format/2311.03414" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Generative Neural Network Approach for 3D Multi-Criteria Design  Generation and Optimization of an Engine Mount for an Unmanned Air Vehicle
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Petroll%2C+C">Christoph Petroll</a>, 
<a href="/search/cs?searchtype=author&query=Eilermann%2C+S">Sebastian Eilermann</a>, 
<a href="/search/cs?searchtype=author&query=Hoefer%2C+P">Philipp Hoefer</a>, 
<a href="/search/cs?searchtype=author&query=Niggemann%2C+O">Oliver Niggemann</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">One of the most promising developments in computer vision in recent years is
the use of generative neural networks for functionality condition-based 3D
design reconstruction and generation. Here, neural networks learn dependencies
between functionalities and a geometry in a very effective way. For a neural
network the functionalities are translated in conditions to a certain geometry.
But the more conditions the design generation needs to reflect, the more
difficult it is to learn clear dependencies. This leads to a multi criteria
design problem due various conditions, which are not considered in the neural
network structure so far.
<br />In this paper, we address this multi-criteria challenge for a 3D design use
case related to an unmanned aerial vehicle (UAV) motor mount. We generate
10,000 abstract 3D designs and subject them all to simulations for three
physical disciplines: mechanics, thermodynamics, and aerodynamics. Then, we
train a Conditional Variational Autoencoder (CVAE) using the geometry and
corresponding multicriteria functional constraints as input. We use our trained
CVAE as well as the Marching cubes algorithm to generate meshes for simulation
based evaluation. The results are then evaluated with the generated UAV
designs. Subsequently, we demonstrate the ability to generate optimized designs
under self-defined functionality conditions using the trained neural network.
</p>
</div>
</dd>
<dt><a name="item38">[38]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03415" title="Abstract">arXiv:2311.03415</a> [<a href="/pdf/2311.03415" title="Download PDF">pdf</a>, <a href="/format/2311.03415" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PowerFlowNet: Leveraging Message Passing GNNs for Improved Power Flow  Approximation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lin%2C+N">Nan Lin</a>, 
<a href="/search/cs?searchtype=author&query=Orfanoudakis%2C+S">Stavros Orfanoudakis</a>, 
<a href="/search/cs?searchtype=author&query=Cardenas%2C+N+O">Nathan Ordonez Cardenas</a>, 
<a href="/search/cs?searchtype=author&query=Giraldo%2C+J+S">Juan S. Giraldo</a>, 
<a href="/search/cs?searchtype=author&query=Vergara%2C+P+P">Pedro P. Vergara</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 7 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Systems and Control (eess.SY)

</div>
<p class="mathjax">Accurate and efficient power flow (PF) analysis is crucial in modern
electrical networks' efficient operation and planning. Therefore, there is a
need for scalable algorithms capable of handling large-scale power networks
that can provide accurate and fast solutions. Graph Neural Networks (GNNs) have
emerged as a promising approach for enhancing the speed of PF approximations by
leveraging their ability to capture distinctive features from the underlying
power network graph. In this study, we introduce PowerFlowNet, a novel GNN
architecture for PF approximation that showcases similar performance with the
traditional Newton-Raphson method but achieves it 4 times faster in the simple
IEEE 14-bus system and 145 times faster in the realistic case of the French
high voltage network (6470rte). Meanwhile, it significantly outperforms other
traditional approximation methods, such as the DC relaxation method, in terms
of performance and execution time; therefore, making PowerFlowNet a highly
promising solution for real-world PF analysis. Furthermore, we verify the
efficacy of our approach by conducting an in-depth experimental evaluation,
thoroughly examining the performance, scalability, interpretability, and
architectural dependability of PowerFlowNet. The evaluation provides insights
into the behavior and potential applications of GNNs in power system analysis.
</p>
</div>
</dd>
<dt><a name="item39">[39]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03417" title="Abstract">arXiv:2311.03417</a> [<a href="/pdf/2311.03417" title="Download PDF">pdf</a>, <a href="/ps/2311.03417" title="Download PostScript">ps</a>, <a href="/format/2311.03417" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Federated Learning for Clinical Structured Data: A Benchmark Comparison  of Engineering and Statistical Approaches
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+S">Siqi Li</a>, 
<a href="/search/cs?searchtype=author&query=Miao%2C+D">Di Miao</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Q">Qiming Wu</a>, 
<a href="/search/cs?searchtype=author&query=Hong%2C+C">Chuan Hong</a>, 
<a href="/search/cs?searchtype=author&query=D%27Agostino%2C+D">Danny D&#x27;Agostino</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xin Li</a>, 
<a href="/search/cs?searchtype=author&query=Ning%2C+Y">Yilin Ning</a>, 
<a href="/search/cs?searchtype=author&query=Shang%2C+Y">Yuqing Shang</a>, 
<a href="/search/cs?searchtype=author&query=Fu%2C+H">Huazhu Fu</a>, 
<a href="/search/cs?searchtype=author&query=Ong%2C+M+E+H">Marcus Eng Hock Ong</a>, 
<a href="/search/cs?searchtype=author&query=Haddadi%2C+H">Hamed Haddadi</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+N">Nan Liu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Federated learning (FL) has shown promising potential in safeguarding data
privacy in healthcare collaborations. While the term "FL" was originally coined
by the engineering community, the statistical field has also explored similar
privacy-preserving algorithms. Statistical FL algorithms, however, remain
considerably less recognized than their engineering counterparts. Our goal was
to bridge the gap by presenting the first comprehensive comparison of FL
frameworks from both engineering and statistical domains. We evaluated five FL
frameworks using both simulated and real-world data. The results indicate that
statistical FL algorithms yield less biased point estimates for model
coefficients and offer convenient confidence interval estimations. In contrast,
engineering-based methods tend to generate more accurate predictions, sometimes
surpassing central pooled and statistical FL models. This study underscores the
relative strengths and weaknesses of both types of methods, emphasizing the
need for increased awareness and their integration in future FL applications.
</p>
</div>
</dd>
<dt><a name="item40">[40]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03420" title="Abstract">arXiv:2311.03420</a> [<a href="/pdf/2311.03420" title="Download PDF">pdf</a>, <a href="/format/2311.03420" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Text Augmentations with R-drop for Classification of Tweets Self  Reporting Covid-19
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Francis%2C+S">Sumam Francis</a>, 
<a href="/search/cs?searchtype=author&query=Moens%2C+M">Marie-Francine Moens</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This paper has been peer-reviewed and accepted for presentation at SMM4H'23 at AMIA 2023 Annual Symposium
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Information Retrieval (cs.IR); Machine Learning (cs.LG)

</div>
<p class="mathjax">This paper presents models created for the Social Media Mining for Health
2023 shared task. Our team addressed the first task, classifying tweets that
self-report Covid-19 diagnosis. Our approach involves a classification model
that incorporates diverse textual augmentations and utilizes R-drop to augment
data and mitigate overfitting, boosting model efficacy. Our leading model,
enhanced with R-drop and augmentations like synonym substitution, reserved
words, and back translations, outperforms the task mean and median scores. Our
system achieves an impressive F1 score of 0.877 on the test set.
</p>
</div>
</dd>
<dt><a name="item41">[41]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03422" title="Abstract">arXiv:2311.03422</a> [<a href="/pdf/2311.03422" title="Download PDF">pdf</a>, <a href="/format/2311.03422" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Efficient and Low-Footprint Object Classification using Spatial Contrast
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Belding%2C+M">Matthew Belding</a>, 
<a href="/search/cs?searchtype=author&query=Stumpp%2C+D+C">Daniel C. Stumpp</a>, 
<a href="/search/cs?searchtype=author&query=Kubendran%2C+R">Rajkumar Kubendran</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages, 6 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Neural and Evolutionary Computing (cs.NE); Image and Video Processing (eess.IV)

</div>
<p class="mathjax">Event-based vision sensors traditionally compute temporal contrast that
offers potential for low-power and low-latency sensing and computing. In this
research, an alternative paradigm for event-based sensors using localized
spatial contrast (SC) under two different thresholding techniques, relative and
absolute, is investigated. Given the slow maturity of spatial contrast in
comparison to temporal-based sensors, a theoretical simulated output of such a
hardware sensor is explored. Furthermore, we evaluate traffic sign
classification using the German Traffic Sign dataset (GTSRB) with well-known
Deep Neural Networks (DNNs). This study shows that spatial contrast can
effectively capture salient image features needed for classification using a
Binarized DNN with significant reduction in input data usage (at least 12X) and
memory resources (17.5X), compared to high precision RGB images and DNN, with
only a small loss (~2%) in macro F1-score. Binarized MicronNet achieves an
F1-score of 94.4% using spatial contrast, compared to only 56.3% when using RGB
input images. Thus, SC offers great promise for deployment in power and
resource constrained edge computing environments.
</p>
</div>
</dd>
<dt><a name="item42">[42]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03424" title="Abstract">arXiv:2311.03424</a> [<a href="/pdf/2311.03424" title="Download PDF">pdf</a>, <a href="/format/2311.03424" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Using Symmetries to Lift Satisfiability Checking
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Carbonnelle%2C+P">Pierre Carbonnelle</a>, 
<a href="/search/cs?searchtype=author&query=Schenner%2C+G">Gottfried Schenner</a>, 
<a href="/search/cs?searchtype=author&query=Bruynooghe%2C+M">Maurice Bruynooghe</a>, 
<a href="/search/cs?searchtype=author&query=Bogaerts%2C+B">Bart Bogaerts</a>, 
<a href="/search/cs?searchtype=author&query=Denecker%2C+M">Marc Denecker</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">We analyze how symmetries can be used to compress structures (also known as
interpretations) onto a smaller domain without loss of information. This
analysis suggests the possibility to solve satisfiability problems in the
compressed domain for better performance. Thus, we propose a 2-step novel
method: (i) the sentence to be satisfied is automatically translated into an
equisatisfiable sentence over a ``lifted'' vocabulary that allows domain
compression; (ii) satisfiability of the lifted sentence is checked by growing
the (initially unknown) compressed domain until a satisfying structure is
found. The key issue is to ensure that this satisfying structure can always be
expanded into an uncompressed structure that satisfies the original sentence to
be satisfied. We present an adequate translation for sentences in typed
first-order logic extended with aggregates. Our experimental evaluation shows
large speedups for generative configuration problems. The method also has
applications in the verification of software operating on complex data
structures. Further refinements of the translation are left for future work.
</p>
</div>
</dd>
<dt><a name="item43">[43]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03425" title="Abstract">arXiv:2311.03425</a> [<a href="/pdf/2311.03425" title="Download PDF">pdf</a>, <a href="/ps/2311.03425" title="Download PostScript">ps</a>, <a href="/format/2311.03425" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An AI-Guided Data Centric Strategy to Detect and Mitigate Biases in  Healthcare Datasets
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gulamali%2C+F+F">Faris F. Gulamali</a>, 
<a href="/search/cs?searchtype=author&query=Sawant%2C+A+S">Ashwin S. Sawant</a>, 
<a href="/search/cs?searchtype=author&query=Liharska%2C+L">Lora Liharska</a>, 
<a href="/search/cs?searchtype=author&query=Horowitz%2C+C+R">Carol R. Horowitz</a>, 
<a href="/search/cs?searchtype=author&query=Chan%2C+L">Lili Chan</a>, 
<a href="/search/cs?searchtype=author&query=Kovatch%2C+P+H">Patricia H. Kovatch</a>, 
<a href="/search/cs?searchtype=author&query=Hofer%2C+I">Ira Hofer</a>, 
<a href="/search/cs?searchtype=author&query=Singh%2C+K">Karandeep Singh</a>, 
<a href="/search/cs?searchtype=author&query=Richardson%2C+L+D">Lynne D. Richardson</a>, 
<a href="/search/cs?searchtype=author&query=Mensah%2C+E">Emmanuel Mensah</a>, 
<a href="/search/cs?searchtype=author&query=Charney%2C+A+W">Alexander W Charney</a>, 
<a href="/search/cs?searchtype=author&query=Reich%2C+D+L">David L. Reich</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+J">Jianying Hu</a>, 
<a href="/search/cs?searchtype=author&query=Nadkarni%2C+G+N">Girish N. Nadkarni</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">The adoption of diagnosis and prognostic algorithms in healthcare has led to
concerns about the perpetuation of bias against disadvantaged groups of
individuals. Deep learning methods to detect and mitigate bias have revolved
around modifying models, optimization strategies, and threshold calibration
with varying levels of success. Here, we generate a data-centric,
model-agnostic, task-agnostic approach to evaluate dataset bias by
investigating the relationship between how easily different groups are learned
at small sample sizes (AEquity). We then apply a systematic analysis of AEq
values across subpopulations to identify and mitigate manifestations of racial
bias in two known cases in healthcare - Chest X-rays diagnosis with deep
convolutional neural networks and healthcare utilization prediction with
multivariate logistic regression. AEq is a novel and broadly applicable metric
that can be applied to advance equity by diagnosing and remediating bias in
healthcare datasets.
</p>
</div>
</dd>
<dt><a name="item44">[44]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03426" title="Abstract">arXiv:2311.03426</a> [<a href="/pdf/2311.03426" title="Download PDF">pdf</a>, <a href="/format/2311.03426" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GQKVA: Efficient Pre-training of Transformers by Grouping Queries, Keys,  and Values
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Javadi%2C+F">Farnoosh Javadi</a>, 
<a href="/search/cs?searchtype=author&query=Ahmed%2C+W">Walid Ahmed</a>, 
<a href="/search/cs?searchtype=author&query=Hajimolahoseini%2C+H">Habib Hajimolahoseini</a>, 
<a href="/search/cs?searchtype=author&query=Ataiefard%2C+F">Foozhan Ataiefard</a>, 
<a href="/search/cs?searchtype=author&query=Hassanpour%2C+M">Mohammad Hassanpour</a>, 
<a href="/search/cs?searchtype=author&query=Asani%2C+S">Saina Asani</a>, 
<a href="/search/cs?searchtype=author&query=Wen%2C+A">Austin Wen</a>, 
<a href="/search/cs?searchtype=author&query=Awad%2C+O+M">Omar Mohamed Awad</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+K">Kangling Liu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yang Liu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Massive transformer-based models face several challenges, including slow and
computationally intensive pre-training and over-parametrization. This paper
addresses these challenges by proposing a versatile method called GQKVA, which
generalizes query, key, and value grouping techniques. GQKVA is designed to
speed up transformer pre-training while reducing the model size. Our
experiments with various GQKVA variants highlight a clear trade-off between
performance and model size, allowing for customized choices based on resource
and time limitations. Our findings also indicate that the conventional
multi-head attention approach is not always the best choice, as there are
lighter and faster alternatives available. We tested our method on ViT, which
achieved an approximate 0.3% increase in accuracy while reducing the model size
by about 4% in the task of image classification. Additionally, our most
aggressive model reduction experiment resulted in a reduction of approximately
15% in model size, with only around a 1% drop in accuracy.
</p>
</div>
</dd>
<dt><a name="item45">[45]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03427" title="Abstract">arXiv:2311.03427</a> [<a href="/pdf/2311.03427" title="Download PDF">pdf</a>, <a href="/format/2311.03427" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> TSP-Transformer: Task-Specific Prompts Boosted Transformer for Holistic  Scene Understanding
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Shuo Wang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jing Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Z">Zibo Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Lian%2C+D">Dongze Lian</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+B">Binbin Huang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xiaomei Wang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zhengxin Li</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+S">Shenghua Gao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> WACV 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Holistic scene understanding includes semantic segmentation, surface normal
estimation, object boundary detection, depth estimation, etc. The key aspect of
this problem is to learn representation effectively, as each subtask builds
upon not only correlated but also distinct attributes. Inspired by
visual-prompt tuning, we propose a Task-Specific Prompts Transformer, dubbed
TSP-Transformer, for holistic scene understanding. It features a vanilla
transformer in the early stage and tasks-specific prompts transformer encoder
in the lateral stage, where tasks-specific prompts are augmented. By doing so,
the transformer layer learns the generic information from the shared parts and
is endowed with task-specific capacity. First, the tasks-specific prompts serve
as induced priors for each task effectively. Moreover, the task-specific
prompts can be seen as switches to favor task-specific representation learning
for different tasks. Extensive experiments on NYUD-v2 and PASCAL-Context show
that our method achieves state-of-the-art performance, validating the
effectiveness of our method for holistic scene understanding. We also provide
our code in the following link https://github.com/tb2-sy/TSP-Transformer.
</p>
</div>
</dd>
<dt><a name="item46">[46]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03449" title="Abstract">arXiv:2311.03449</a> [<a href="/pdf/2311.03449" title="Download PDF">pdf</a>, <a href="/format/2311.03449" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Into the LAIONs Den: Investigating Hate in Multimodal Datasets
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Birhane%2C+A">Abeba Birhane</a>, 
<a href="/search/cs?searchtype=author&query=Prabhu%2C+V">Vinay Prabhu</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+S">Sang Han</a>, 
<a href="/search/cs?searchtype=author&query=Boddeti%2C+V+N">Vishnu Naresh Boddeti</a>, 
<a href="/search/cs?searchtype=author&query=Luccioni%2C+A+S">Alexandra Sasha Luccioni</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To appear at 37th Conference on Neural Information Processing Systems (NeurIPS 2023) Datasets and Benchmarks Track. arXiv admin note: substantial text overlap with <a href="/abs/2306.13141">arXiv:2306.13141</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>

</div>
<p class="mathjax">'Scale the model, scale the data, scale the compute' is the reigning
sentiment in the world of generative AI today. While the impact of model
scaling has been extensively studied, we are only beginning to scratch the
surface of data scaling and its consequences. This is especially of critical
importance in the context of vision-language datasets such as LAION. These
datasets are continually growing in size and are built based on large-scale
internet dumps such as the Common Crawl, which is known to have numerous
drawbacks ranging from quality, legality, and content. The datasets then serve
as the backbone for large generative models, contributing to the
operationalization and perpetuation of harmful societal and historical biases
and stereotypes. In this paper, we investigate the effect of scaling datasets
on hateful content through a comparative audit of two datasets: LAION-400M and
LAION-2B. Our results show that hate content increased by nearly 12% with
dataset scale, measured both qualitatively and quantitatively using a metric
that we term as Hate Content Rate (HCR). We also found that filtering dataset
contents based on Not Safe For Work (NSFW) values calculated based on images
alone does not exclude all the harmful content in alt-text. Instead, we found
that trace amounts of hateful, targeted, and aggressive text remain even when
carrying out conservative filtering. We end with a reflection and a discussion
of the significance of our results for dataset curation and usage in the AI
community. Code and the meta-data assets curated in this paper are publicly
available at https://github.com/vinayprabhu/hate_scaling. Content warning: This
paper contains examples of hateful text that might be disturbing, distressing,
and/or offensive.
</p>
</div>
</dd>
<dt><a name="item47">[47]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03468" title="Abstract">arXiv:2311.03468</a> [<a href="/pdf/2311.03468" title="Download PDF">pdf</a>, <a href="/format/2311.03468" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FinA: Fairness of Adverse Effects in Decision-Making of  Human-Cyber-Physical-System
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhao%2C+T">Tianyu Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Elmalaki%2C+S">Salma Elmalaki</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computers and Society (cs.CY); Human-Computer Interaction (cs.HC); Machine Learning (cs.LG); Numerical Analysis (math.NA)

</div>
<p class="mathjax">Ensuring fairness in decision-making systems within
Human-Cyber-Physical-Systems (HCPS) is a pressing concern, particularly when
diverse individuals, each with varying behaviors and expectations, coexist
within the same application space, influenced by a shared set of control
actions in the system. The long-term adverse effects of these actions further
pose the challenge, as historical experiences and interactions shape individual
perceptions of fairness. This paper addresses the challenge of fairness from an
equity perspective of adverse effects, taking into account the dynamic nature
of human behavior and evolving preferences while recognizing the lasting impact
of adverse effects. We formally introduce the concept of
Fairness-in-Adverse-Effects (FinA) within the HCPS context. We put forth a
comprehensive set of five formulations for FinA, encompassing both the
instantaneous and long-term aspects of adverse effects. To empirically validate
the effectiveness of our FinA approach, we conducted an evaluation within the
domain of smart homes, a pertinent HCPS application. The outcomes of our
evaluation demonstrate that the adoption of FinA significantly enhances the
overall perception of fairness among individuals, yielding an average
improvement of 66.7% when compared to the state-of-the-art method.
</p>
</div>
</dd>
<dt><a name="item48">[48]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03470" title="Abstract">arXiv:2311.03470</a> [<a href="/pdf/2311.03470" title="Download PDF">pdf</a>, <a href="/format/2311.03470" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Orion: A Fully Homomorphic Encryption Compiler for Private Deep Neural  Network Inference
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ebel%2C+A">Austin Ebel</a>, 
<a href="/search/cs?searchtype=author&query=Garimella%2C+K">Karthik Garimella</a>, 
<a href="/search/cs?searchtype=author&query=Reagen%2C+B">Brandon Reagen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 8 figures, 4 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">Fully Homomorphic Encryption (FHE) has the potential to substantially improve
privacy and security by enabling computation on encrypted data. This is
especially true with deep learning, as today many popular user services are
powered by neural networks. One of the major challenges facing wide-scale
deployment of FHE-secured neural inference is effectively mapping them to the
FHE domain. FHE poses many programming challenges including packing large
vectors, handling expensive rotations, and correctly implementing complex
strided convolutions. This makes programming FHE inferences prone to poor
performance and errors. In this paper we overcome these challenges with Orion,
an automated optimizing FHE compiler for neural inference. Orion automatically
maps PyTorch-specified networks to FHE, handling common layer types and
arbitrary tensor shapes and strides. Moreover, we develop novel optimizations
that balance dense FHE vector packing, efficient rotations, and minimize
operations to improve performance. We have implemented Orion, which will be
open sourced, and evaluated it on common benchmarks used by the FHE deep
learning community. We compare Orion to multiple state-of-the-art solutions and
report iso-accuracy speedups ranging from 2.7$\times$ to 20.5$\times$.
</p>
</div>
</dd>
<dt><a name="item49">[49]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03476" title="Abstract">arXiv:2311.03476</a> [<a href="/pdf/2311.03476" title="Download PDF">pdf</a>, <a href="/ps/2311.03476" title="Download PostScript">ps</a>, <a href="/format/2311.03476" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Lessons Learned from Efforts to Standardize Streaming In SQL
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Petride%2C+S">Sabina Petride</a>, 
<a href="/search/cs?searchtype=author&query=Sotolongo%2C+D">Dan Sotolongo</a>, 
<a href="/search/cs?searchtype=author&query=Michels%2C+J">Jan Michels</a>, 
<a href="/search/cs?searchtype=author&query=Witkowski%2C+A">Andrew Witkowski</a>, 
<a href="/search/cs?searchtype=author&query=Haas%2C+C">Cara Haas</a>, 
<a href="/search/cs?searchtype=author&query=Hughes%2C+J">Jim Hughes</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Databases (cs.DB)</span>

</div>
<p class="mathjax">Acknowledging the reality of streaming languages and platforms overlapping
with SQL and database systems, in 2019 INCTIS Data Management established an
Expert Group with the focused mission to initiate the process of standardizing
streaming support in SQL. Over time, the roster included companies like Actian,
Alibaba, Amazon Web Services, Confluent, dbt Labs, Google, Hazelcast, IBM,
Materialize, Microsoft, Oracle, Snowflake, SQLstream and Timeplus. For the span
of more than one year, representatives of each company have presented key
features of their streaming product or, in some cases, multiple streaming
products. These were live technical Q&amp;A sessions accompanied by summary or
position papers, which are unquestionably valuable. As expected, substantial
time was spent in clarifying what common terms meant in each system and setting
up a glossary. These sessions were followed by clarification notes and debates,
and decisions that appeared mandatory to allow further progress. This first
phase was followed by the next phase, which consisted of the group meetings, in
which the expert group (EG) agreed on main exit criteria topics that a
streaming solution in SQL must address, and position papers and follow-ups were
written and discussed. This paper summarizes these group efforts, up to the
summer of 2023.
</p>
</div>
</dd>
<dt><a name="item50">[50]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03477" title="Abstract">arXiv:2311.03477</a> [<a href="/pdf/2311.03477" title="Download PDF">pdf</a>, <a href="/format/2311.03477" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Repairing Learning-Enabled Controllers While Preserving What Works
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Lu%2C+P">Pengyuan Lu</a>, 
<a href="/search/eess?searchtype=author&query=Cleaveland%2C+M">Matthew Cleaveland</a>, 
<a href="/search/eess?searchtype=author&query=Sokolsky%2C+O">Oleg Sokolsky</a>, 
<a href="/search/eess?searchtype=author&query=Lee%2C+I">Insup Lee</a>, 
<a href="/search/eess?searchtype=author&query=Ruchkin%2C+I">Ivan Ruchkin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">Learning-enabled controllers have been adopted in various cyber-physical
systems (CPS). When a learning-enabled controller fails to accomplish its task
from a set of initial states, researchers leverage repair algorithms to
fine-tune the controller's parameters. However, existing repair techniques do
not preserve previously correct behaviors. Specifically, when modifying the
parameters to repair trajectories from a subset of initial states, another
subset may be compromised. Therefore, the repair may break previously correct
scenarios, introducing new risks that may not be accounted for. Due to this
issue, repairing the entire initial state space may be hard or even infeasible.
As a response, we formulate the Repair with Preservation (RwP) problem, which
calls for preserving the already-correct scenarios during repair. To tackle
this problem, we design the Incremental Simulated Annealing Repair (ISAR)
algorithm, which leverages simulated annealing on a barriered energy function
to safeguard the already-correct initial states while repairing as many
additional ones as possible. Moreover, formal verification is utilized to
guarantee the repair results. Case studies on an Unmanned Underwater Vehicle
(UUV) and OpenAI Gym Mountain Car (MC) show that ISAR not only preserves
correct behaviors from previously verified initial state regions, but also
repairs 81.4% and 23.5% of broken state spaces in the two benchmarks. Moreover,
the average STL robustnesses of the ISAR repaired controllers are larger than
those of the controllers repaired using baseline methods.
</p>
</div>
</dd>
<dt><a name="item51">[51]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03478" title="Abstract">arXiv:2311.03478</a> [<a href="/pdf/2311.03478" title="Download PDF">pdf</a>, <a href="/format/2311.03478" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multi Loss-based Feature Fusion and Top Two Voting Ensemble Decision  Strategy for Facial Expression Recognition in the Wild
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhou%2C+G">Guangyao Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+Y">Yuanlun Xie</a>, 
<a href="/search/cs?searchtype=author&query=Tian%2C+W">Wenhong Tian</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 8 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Facial expression recognition (FER) in the wild is a challenging task
affected by the image quality and has attracted broad interest in computer
vision. There is no research using feature fusion and ensemble strategy for FER
simultaneously. Different from previous studies, this paper applies both
internal feature fusion for a single model and feature fusion among multiple
networks, as well as the ensemble strategy. This paper proposes one novel
single model named R18+FAML, as well as one ensemble model named
R18+FAML-FGA-T2V to improve the performance of the FER in the wild. Based on
the structure of ResNet18 (R18), R18+FAML combines internal Feature fusion and
three Attention blocks using Multiple Loss functions (FAML) to improve the
diversity of the feature extraction. To improve the performance of R18+FAML, we
propose a Feature fusion among networks based on the Genetic Algorithm (FGA),
which can fuse the convolution kernels for feature extraction of multiple
networks. On the basis of R18+FAML and FGA, we propose one ensemble strategy,
i.e., the Top Two Voting (T2V) to support the classification of FER, which can
consider more classification information comprehensively. Combining the above
strategies, R18+FAML-FGA-T2V can focus on the main expression-aware areas.
Extensive experiments demonstrate that our single model R18+FAML and the
ensemble model R18+FAML-FGA-T2V achieve the accuracies of $\left( 90.32, 62.17,
65.83 \right)\%$ and $\left( 91.59, 63.27, 66.63 \right)\%$ on three
challenging unbalanced FER datasets RAF-DB, AffectNet-8 and AffectNet-7
respectively, both outperforming the state-of-the-art results.
</p>
</div>
</dd>
<dt><a name="item52">[52]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03484" title="Abstract">arXiv:2311.03484</a> [<a href="/pdf/2311.03484" title="Download PDF">pdf</a>, <a href="/format/2311.03484" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Osprey: Multi-Session Autonomous Aerial Mapping with LiDAR-based SLAM  and Next Best View Planning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Border%2C+R">Rowan Border</a>, 
<a href="/search/cs?searchtype=author&query=Chebrolu%2C+N">Nived Chebrolu</a>, 
<a href="/search/cs?searchtype=author&query=Tao%2C+Y">Yifu Tao</a>, 
<a href="/search/cs?searchtype=author&query=Gammell%2C+J+D">Jonathan D. Gammell</a>, 
<a href="/search/cs?searchtype=author&query=Fallon%2C+M">Maurice Fallon</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to Field Robotics, Manuscript #FR-23-0016. 25 pages, 15 figures, 3 tables. Video available at <a href="https://www.youtube.com/watch?v=CVIXu2qUQJ8">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Aerial mapping systems are important for many surveying applications (e.g.,
industrial inspection or agricultural monitoring). Semi-autonomous mapping with
GPS-guided aerial platforms that fly preplanned missions is already widely
available but fully autonomous systems can significantly improve efficiency.
Autonomously mapping complex 3D structures requires a system that performs
online mapping and mission planning. This paper presents Osprey, an autonomous
aerial mapping system with state-of-the-art multi-session mapping capabilities.
It enables a non-expert operator to specify a bounded target area that the
aerial platform can then map autonomously, over multiple flights if necessary.
Field experiments with Osprey demonstrate that this system can achieve greater
map coverage of large industrial sites than manual surveys with a pilot-flown
aerial platform or a terrestrial laser scanner (TLS). Three sites, with a total
ground coverage of $7085$ m$^2$ and a maximum height of $27$ m, were mapped in
separate missions using $112$ minutes of autonomous flight time. True colour
maps were created from images captured by Osprey using pointcloud and NeRF
reconstruction methods. These maps provide useful data for structural
inspection tasks.
</p>
</div>
</dd>
<dt><a name="item53">[53]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03485" title="Abstract">arXiv:2311.03485</a> [<a href="/pdf/2311.03485" title="Download PDF">pdf</a>, <a href="/format/2311.03485" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CLIP-Motion: Learning Reward Functions for Robotic Actions Using  Consecutive Observations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dang%2C+X">Xuzhe Dang</a>, 
<a href="/search/cs?searchtype=author&query=Edelkamp%2C+S">Stefan Edelkamp</a>, 
<a href="/search/cs?searchtype=author&query=Ribault%2C+N">Nicolas Ribault</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">This paper presents a novel method for learning reward functions for robotic
motions by harnessing the power of a CLIP-based model. Traditional reward
function design often hinges on manual feature engineering, which can struggle
to generalize across an array of tasks. Our approach circumvents this challenge
by capitalizing on CLIP's capability to process both state features and image
inputs effectively. Given a pair of consecutive observations, our model excels
in identifying the motion executed between them. We showcase results spanning
various robotic activities, such as directing a gripper to a designated target
and adjusting the position of a cube. Through experimental evaluations, we
underline the proficiency of our method in precisely deducing motion and its
promise to enhance reinforcement learning training in the realm of robotics.
</p>
</div>
</dd>
<dt><a name="item54">[54]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03486" title="Abstract">arXiv:2311.03486</a> [<a href="/pdf/2311.03486" title="Download PDF">pdf</a>, <a href="/format/2311.03486" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fostering Human Learning in Sequential Decision-Making: Understanding  the Role of Evaluative Feedback
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gupta%2C+P">Piyush Gupta</a>, 
<a href="/search/cs?searchtype=author&query=Biswas%2C+S">Subir Biswas</a>, 
<a href="/search/cs?searchtype=author&query=Srivastava%2C+V">Vaibhav Srivastava</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">Cognitive rehabilitation, STEM skill acquisition, and coaching games such as
chess often require tutoring decision-making strategies. The advancement of
AI-driven tutoring systems for facilitating human learning requires an
understanding of the impact of evaluative feedback on human decision-making and
skill development. To this end, we conduct human experiments using Amazon
Mechanical Turk to study the influence of evaluative feedback on human
decision-making in sequential tasks. In these experiments, participants solve
the Tower of Hanoi puzzle and receive AI-generated feedback while solving it.
We examine how this feedback affects their learning and skill transfer to
related tasks. We also explore various computational models to understand how
people incorporate evaluative feedback into their decision-making processes.
</p>
</div>
</dd>
<dt><a name="item55">[55]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03488" title="Abstract">arXiv:2311.03488</a> [<a href="/pdf/2311.03488" title="Download PDF">pdf</a>, <a href="/format/2311.03488" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multi-Resolution Diffusion for Privacy-Sensitive Recommender Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lilienthal%2C+D">Derek Lilienthal</a>, 
<a href="/search/cs?searchtype=author&query=Mello%2C+P">Paul Mello</a>, 
<a href="/search/cs?searchtype=author&query=Eirinaki%2C+M">Magdalini Eirinaki</a>, 
<a href="/search/cs?searchtype=author&query=Tiomkin%2C+S">Stas Tiomkin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages, 14 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Artificial Intelligence (cs.AI); Cryptography and Security (cs.CR); Machine Learning (cs.LG)

</div>
<p class="mathjax">While recommender systems have become an integral component of the Web
experience, their heavy reliance on user data raises privacy and security
concerns. Substituting user data with synthetic data can address these
concerns, but accurately replicating these real-world datasets has been a
notoriously challenging problem. Recent advancements in generative AI have
demonstrated the impressive capabilities of diffusion models in generating
realistic data across various domains. In this work we introduce a Score-based
Diffusion Recommendation Model (SDRM), which captures the intricate patterns of
real-world datasets required for training highly accurate recommender systems.
SDRM allows for the generation of synthetic data that can replace existing
datasets to preserve user privacy, or augment existing datasets to address
excessive data sparsity. Our method outperforms competing baselines such as
generative adversarial networks, variational autoencoders, and recently
proposed diffusion models in synthesizing various datasets to replace or
augment the original data by an average improvement of 4.30% in Recall@$n$ and
4.65% in NDCG@$n$.
</p>
</div>
</dd>
<dt><a name="item56">[56]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03489" title="Abstract">arXiv:2311.03489</a> [<a href="/pdf/2311.03489" title="Download PDF">pdf</a>, <a href="/ps/2311.03489" title="Download PostScript">ps</a>, <a href="/format/2311.03489" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Leveraging High-Level Synthesis and Large Language Models to Generate,  Simulate, and Deploy a Uniform Random Number Generator Hardware Design
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Meech%2C+J+T">James T. Meech</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Hardware Architecture (cs.AR)</span>; Machine Learning (cs.LG); Programming Languages (cs.PL)

</div>
<p class="mathjax">We present a new high-level synthesis methodology for using large language
model tools to generate hardware designs. The methodology uses exclusively
open-source tools excluding the large language model. As a case study, we use
our methodology to generate a permuted congruential random number generator
design with a wishbone interface. We verify the functionality and quality of
the random number generator design using large language model-generated
simulations and the Dieharder randomness test suite. We document all the large
language model chat logs, Python scripts, Verilog scripts, and simulation
results used in the case study. We believe that our method of hardware design
generation coupled with the open source silicon 130 nm design tools will
revolutionize application-specific integrated circuit design. Our methodology
significantly lowers the bar to entry when building domain-specific computing
accelerators for the Internet of Things and proof of concept prototypes for
later fabrication in more modern process nodes.
</p>
</div>
</dd>
<dt><a name="item57">[57]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03496" title="Abstract">arXiv:2311.03496</a> [<a href="/pdf/2311.03496" title="Download PDF">pdf</a>, <a href="/format/2311.03496" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Asynchronous Local Computations in Distributed Bayesian Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bhar%2C+K">Kinjal Bhar</a>, 
<a href="/search/cs?searchtype=author&query=Bai%2C+H">He Bai</a>, 
<a href="/search/cs?searchtype=author&query=George%2C+J">Jemin George</a>, 
<a href="/search/cs?searchtype=author&query=Busart%2C+C">Carl Busart</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Distributed, Parallel, and Cluster Computing (cs.DC); Multiagent Systems (cs.MA)

</div>
<p class="mathjax">Due to the expanding scope of machine learning (ML) to the fields of sensor
networking, cooperative robotics and many other multi-agent systems,
distributed deployment of inference algorithms has received a lot of attention.
These algorithms involve collaboratively learning unknown parameters from
dispersed data collected by multiple agents. There are two competing aspects in
such algorithms, namely, intra-agent computation and inter-agent communication.
Traditionally, algorithms are designed to perform both synchronously. However,
certain circumstances need frugal use of communication channels as they are
either unreliable, time-consuming, or resource-expensive. In this paper, we
propose gossip-based asynchronous communication to leverage fast computations
and reduce communication overhead simultaneously. We analyze the effects of
multiple (local) intra-agent computations by the active agents between
successive inter-agent communications. For local computations, Bayesian
sampling via unadjusted Langevin algorithm (ULA) MCMC is utilized. The
communication is assumed to be over a connected graph (e.g., as in
decentralized learning), however, the results can be extended to coordinated
communication where there is a central server (e.g., federated learning). We
theoretically quantify the convergence rates in the process. To demonstrate the
efficacy of the proposed algorithm, we present simulations on a toy problem as
well as on real world data sets to train ML models to perform classification
tasks. We observe faster initial convergence and improved performance accuracy,
especially in the low data range. We achieve on average 78% and over 90%
classification accuracy respectively on the Gamma Telescope and mHealth data
sets from the UCI ML repository.
</p>
</div>
</dd>
<dt><a name="item58">[58]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03498" title="Abstract">arXiv:2311.03498</a> [<a href="/pdf/2311.03498" title="Download PDF">pdf</a>, <a href="/format/2311.03498" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> In-Context Exemplars as Clues to Retrieving from Large Associative  Memory
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhao%2C+J">Jiachen Zhao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Neural Conversational AI @ ICML 2023, Associative Memory &amp; Hopfield Networks @ NIPS, 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Recently, large language models (LLMs) have made remarkable progress in
natural language processing. The most representative ability of LLMs is
in-context learning (ICL), which enables LLMs to learn patterns from in-context
exemplars without training. The performance of ICL greatly depends on the
exemplars used. However, how to choose exemplars remains unclear due to the
lack of understanding of how in-context learning works. In this paper, we
present a novel perspective on ICL by conceptualizing it as contextual
retrieval from a model of associative memory. We establish a theoretical
framework of ICL based on Hopfield Networks. Based on our framework, we look
into how in-context exemplars influence the performance of ICL and propose more
efficient active exemplar selection. Our study sheds new light on the mechanism
of ICL by connecting it to memory retrieval, with potential implications for
advancing the understanding of LLMs.
</p>
</div>
</dd>
<dt><a name="item59">[59]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03504" title="Abstract">arXiv:2311.03504</a> [<a href="/pdf/2311.03504" title="Download PDF">pdf</a>, <a href="/format/2311.03504" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Convolution finite element-based digital image correlation for  displacement and strain measurements
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lu%2C+Y">Ye Lu</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+W">Weidong Zhu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Engineering, Finance, and Science (cs.CE)</span>; Numerical Analysis (math.NA)

</div>
<p class="mathjax">This work presents a novel global digital image correlation (DIC) method,
based on a newly developed convolution finite element (C-FE) approximation. The
convolution approximation can rely on the mesh of linear finite elements and
enables arbitrarily high order approximations without adding more degrees of
freedom. Therefore, the C-FE based DIC can be more accurate than {the} usual FE
based DIC by providing highly smooth and accurate displacement and strain
results with the same element size. The detailed formulation and implementation
of the method have been discussed in this work. The controlling parameters in
the method include the polynomial order, patch size, and dilation. A general
choice of the parameters and their potential adaptivity have been discussed.
The proposed DIC method has been tested by several representative examples,
including the DIC challenge 2.0 benchmark problems, with comparison to the
usual FE based DIC. C-FE outperformed FE in all the DIC results for the tested
examples. This work demonstrates the potential of C-FE and opens a new avenue
to enable highly smooth, accurate, and robust DIC analysis for full-field
displacement and strain measurements.
</p>
</div>
</dd>
<dt><a name="item60">[60]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03509" title="Abstract">arXiv:2311.03509</a> [<a href="/pdf/2311.03509" title="Download PDF">pdf</a>, <a href="/format/2311.03509" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MFAAN: Unveiling Audio Deepfakes with a Multi-Feature Authenticity  Network
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Krishnan%2C+K+S">Karthik Sivarama Krishnan</a>, 
<a href="/search/cs?searchtype=author&query=Krishnan%2C+K+S">Koushik Sivarama Krishnan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Artificial Intelligence (cs.AI); Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">In the contemporary digital age, the proliferation of deepfakes presents a
formidable challenge to the sanctity of information dissemination. Audio
deepfakes, in particular, can be deceptively realistic, posing significant
risks in misinformation campaigns. To address this threat, we introduce the
Multi-Feature Audio Authenticity Network (MFAAN), an advanced architecture
tailored for the detection of fabricated audio content. MFAAN incorporates
multiple parallel paths designed to harness the strengths of different audio
representations, including Mel-frequency cepstral coefficients (MFCC),
linear-frequency cepstral coefficients (LFCC), and Chroma Short Time Fourier
Transform (Chroma-STFT). By synergistically fusing these features, MFAAN
achieves a nuanced understanding of audio content, facilitating robust
differentiation between genuine and manipulated recordings. Preliminary
evaluations of MFAAN on two benchmark datasets, 'In-the-Wild' Audio Deepfake
Data and The Fake-or-Real Dataset, demonstrate its superior performance,
achieving accuracies of 98.93% and 94.47% respectively. Such results not only
underscore the efficacy of MFAAN but also highlight its potential as a pivotal
tool in the ongoing battle against deepfake audio content.
</p>
</div>
</dd>
<dt><a name="item61">[61]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03510" title="Abstract">arXiv:2311.03510</a> [<a href="/pdf/2311.03510" title="Download PDF">pdf</a>, <a href="/format/2311.03510" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Spoken Dialogue System for Medical Prescription Acquisition on  Smartphone: Development, Corpus and Evaluation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kocabiyikoglu%2C+A+C">Ali Can Kocabiyikoglu</a>, 
<a href="/search/cs?searchtype=author&query=Portet%2C+F">Fran&#xe7;ois Portet</a>, 
<a href="/search/cs?searchtype=author&query=Babouchkine%2C+J">Jean-Marc Babouchkine</a>, 
<a href="/search/cs?searchtype=author&query=Gibert%2C+P">Prudence Gibert</a>, 
<a href="/search/cs?searchtype=author&query=Blanchon%2C+H">Herv&#xe9; Blanchon</a>, 
<a href="/search/cs?searchtype=author&query=Gavazzi%2C+G">Ga&#xeb;tan Gavazzi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Hospital information systems (HIS) have become an essential part of
healthcare institutions and now incorporate prescribing support software.
Prescription support software allows for structured information capture, which
improves the safety, appropriateness and efficiency of prescriptions and
reduces the number of adverse drug events (ADEs). However, such a system
increases the amount of time physicians spend at a computer entering
information instead of providing medical care. In addition, any new visiting
clinician must learn to manage complex interfaces since each HIS has its own
interfaces. In this paper, we present a natural language interface for
e-prescribing software in the form of a spoken dialogue system accessible on a
smartphone. This system allows prescribers to record their prescriptions
verbally, a form of interaction closer to their usual practice. The system
extracts the formal representation of the prescription ready to be checked by
the prescribing software and uses the dialogue to request mandatory
information, correct errors or warn of particular situations. Since, to the
best of our knowledge, there is no existing voice-based prescription dialogue
system, we present the system developed in a low-resource environment, focusing
on dialogue modeling, semantic extraction and data augmentation. The system was
evaluated in the wild with 55 participants. This evaluation showed that our
system has an average prescription time of 66.15 seconds for physicians and
35.64 seconds for other experts, and a task success rate of 76\% for physicians
and 72\% for other experts. All evaluation data were recorded and annotated to
form PxCorpus, the first spoken drug prescription corpus that has been made
fully available to the community
(\url{https://doi.org/10.5281/zenodo.6524162}).
</p>
</div>
</dd>
<dt><a name="item62">[62]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03517" title="Abstract">arXiv:2311.03517</a> [<a href="/pdf/2311.03517" title="Download PDF">pdf</a>, <a href="/format/2311.03517" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SoundCam: A Dataset for Finding Humans Using Room Acoustics
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+M">Mason Wang</a>, 
<a href="/search/cs?searchtype=author&query=Clarke%2C+S">Samuel Clarke</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jui-Hsien Wang</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+R">Ruohan Gao</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+J">Jiajun Wu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> In NeurIPS 2023 Datasets and Benchmarks Track. Project page: <a href="https://masonlwang.com/soundcam/.">this https URL</a> Wang and Clarke contributed equally to this work
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Computer Vision and Pattern Recognition (cs.CV); Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">A room's acoustic properties are a product of the room's geometry, the
objects within the room, and their specific positions. A room's acoustic
properties can be characterized by its impulse response (RIR) between a source
and listener location, or roughly inferred from recordings of natural signals
present in the room. Variations in the positions of objects in a room can
effect measurable changes in the room's acoustic properties, as characterized
by the RIR. Existing datasets of RIRs either do not systematically vary
positions of objects in an environment, or they consist of only simulated RIRs.
We present SoundCam, the largest dataset of unique RIRs from in-the-wild rooms
publicly released to date. It includes 5,000 10-channel real-world measurements
of room impulse responses and 2,000 10-channel recordings of music in three
different rooms, including a controlled acoustic lab, an in-the-wild living
room, and a conference room, with different humans in positions throughout each
room. We show that these measurements can be used for interesting tasks, such
as detecting and identifying humans, and tracking their positions.
</p>
</div>
</dd>
<dt><a name="item63">[63]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03518" title="Abstract">arXiv:2311.03518</a> [<a href="/pdf/2311.03518" title="Download PDF">pdf</a>, <a href="/ps/2311.03518" title="Download PostScript">ps</a>, <a href="/format/2311.03518" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> High-resolution power equipment recognition based on improved  self-attention
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+S">Siyi Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+C">Cheng Liu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xiang Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhai%2C+X">Xin Zhai</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+Z">Zhen Wei</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+S">Sizhe Li</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+X">Xun Ma</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">The current trend of automating inspections at substations has sparked a
surge in interest in the field of transformer image recognition. However, due
to restrictions in the number of parameters in existing models, high-resolution
images can't be directly applied, leaving significant room for enhancing
recognition accuracy. Addressing this challenge, the paper introduces a novel
improvement on deep self-attention networks tailored for this issue. The
proposed model comprises four key components: a foundational network, a region
proposal network, a module for extracting and segmenting target areas, and a
final prediction network. The innovative approach of this paper differentiates
itself by decoupling the processes of part localization and recognition,
initially using low-resolution images for localization followed by
high-resolution images for recognition. Moreover, the deep self-attention
network's prediction mechanism uniquely incorporates the semantic context of
images, resulting in substantially improved recognition performance.
Comparative experiments validate that this method outperforms the two other
prevalent target recognition models, offering a groundbreaking perspective for
automating electrical equipment inspections.
</p>
</div>
</dd>
<dt><a name="item64">[64]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03520" title="Abstract">arXiv:2311.03520</a> [<a href="/pdf/2311.03520" title="Download PDF">pdf</a>, <a href="/format/2311.03520" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Brain Networks and Intelligence: A Graph Neural Network Based Approach  to Resting State fMRI Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Thapaliya%2C+B">Bishal Thapaliya</a>, 
<a href="/search/cs?searchtype=author&query=Akbas%2C+E">Esra Akbas</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Jiayu Chen</a>, 
<a href="/search/cs?searchtype=author&query=Sapkota%2C+R">Raam Sapkota</a>, 
<a href="/search/cs?searchtype=author&query=Ray%2C+B">Bhaskar Ray</a>, 
<a href="/search/cs?searchtype=author&query=Suresh%2C+P">Pranav Suresh</a>, 
<a href="/search/cs?searchtype=author&query=Calhoun%2C+V">Vince Calhoun</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jingyu Liu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Neurons and Cognition (q-bio.NC)

</div>
<p class="mathjax">Resting-state functional magnetic resonance imaging (rsfMRI) is a powerful
tool for investigating the relationship between brain function and cognitive
processes as it allows for the functional organization of the brain to be
captured without relying on a specific task or stimuli. In this paper, we
present a novel modeling architecture called BrainRGIN for predicting
intelligence (fluid, crystallized, and total intelligence) using graph neural
networks on rsfMRI derived static functional network connectivity matrices.
Extending from the existing graph convolution networks, our approach
incorporates a clustering-based embedding and graph isomorphism network in the
graph convolutional layer to reflect the nature of the brain sub-network
organization and efficient network expression, in combination with TopK pooling
and attention-based readout functions. We evaluated our proposed architecture
on a large dataset, specifically the Adolescent Brain Cognitive Development
Dataset, and demonstrated its effectiveness in predicting individual
differences in intelligence. Our model achieved lower mean squared errors and
higher correlation scores than existing relevant graph architectures and other
traditional machine learning models for all of the intelligence prediction
tasks. The middle frontal gyrus exhibited a significant contribution to both
fluid and crystallized intelligence, suggesting their pivotal role in these
cognitive processes. Total composite scores identified a diverse set of brain
regions to be relevant which underscores the complex nature of total
intelligence.
</p>
</div>
</dd>
<dt><a name="item65">[65]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03524" title="Abstract">arXiv:2311.03524</a> [<a href="/pdf/2311.03524" title="Download PDF">pdf</a>, <a href="/format/2311.03524" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Graph-Theoretic Framework for Understanding Open-World Semi-Supervised  Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sun%2C+Y">Yiyou Sun</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+Z">Zhenmei Shi</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yixuan Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to NeurIPS 2023 (Spotlight)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Open-world semi-supervised learning aims at inferring both known and novel
classes in unlabeled data, by harnessing prior knowledge from a labeled set
with known classes. Despite its importance, there is a lack of theoretical
foundations for this problem. This paper bridges the gap by formalizing a
graph-theoretic framework tailored for the open-world setting, where the
clustering can be theoretically characterized by graph factorization. Our
graph-theoretic framework illuminates practical algorithms and provides
guarantees. In particular, based on our graph formulation, we apply the
algorithm called Spectral Open-world Representation Learning (SORL), and show
that minimizing our loss is equivalent to performing spectral decomposition on
the graph. Such equivalence allows us to derive a provable error bound on the
clustering performance for both known and novel classes, and analyze rigorously
when labeled data helps. Empirically, SORL can match or outperform several
strong baselines on common benchmark datasets, which is appealing for practical
usage while enjoying theoretical guarantees.
</p>
</div>
</dd>
<dt><a name="item66">[66]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03526" title="Abstract">arXiv:2311.03526</a> [<a href="/pdf/2311.03526" title="Download PDF">pdf</a>, <a href="/format/2311.03526" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Automated Negative Sampling in Implicit Recommendation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lyu%2C+F">Fuyuan Lyu</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+Y">Yaochen Hu</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+X">Xing Tang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yingxue Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+R">Ruiming Tang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xue Liu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>

</div>
<p class="mathjax">Negative sampling methods are vital in implicit recommendation models as they
allow us to obtain negative instances from massive unlabeled data. Most
existing approaches focus on sampling hard negative samples in various ways.
These studies are orthogonal to the recommendation model and implicit datasets.
However, such an idea contradicts the common belief in AutoML that the model
and dataset should be matched. Empirical experiments suggest that the
best-performing negative sampler depends on the implicit dataset and the
specific recommendation model. Hence, we propose a hypothesis that the negative
sampler should align with the capacity of the recommendation models as well as
the statistics of the datasets to achieve optimal performance. A mismatch
between these three would result in sub-optimal outcomes. An intuitive idea to
address the mismatch problem is to exhaustively select the best-performing
negative sampler given the model and dataset. However, such an approach is
computationally expensive and time-consuming, leaving the problem unsolved. In
this work, we propose the AutoSample framework that adaptively selects the
best-performing negative sampler among candidates. Specifically, we propose a
loss-to-instance approximation to transform the negative sampler search task
into the learning task over a weighted sum, enabling end-to-end training of the
model. We also designed an adaptive search algorithm to extensively and
efficiently explore the search space. A specific initialization approach is
also obtained to better utilize the obtained model parameters during the search
stage, which is similar to curriculum learning and leads to better performance
and less computation resource consumption. We evaluate the proposed framework
on four benchmarks over three models. Extensive experiments demonstrate the
effectiveness and efficiency of our proposed framework.
</p>
</div>
</dd>
<dt><a name="item67">[67]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03527" title="Abstract">arXiv:2311.03527</a> [<a href="/pdf/2311.03527" title="Download PDF">pdf</a>, <a href="/format/2311.03527" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Type II Hamiltonian Lie Group Variational Integrators with Applications  to Geometric Adjoint Sensitivity Analysis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Tran%2C+B+K">Brian K. Tran</a>, 
<a href="/search/math?searchtype=author&query=Leok%2C+M">Melvin Leok</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Optimization and Control (math.OC)

</div>
<p class="mathjax">Variational integrators for Euler--Lagrange equations and Hamilton's
equations are a class of structure-preserving numerical methods that respect
the conservative properties of such systems. Lie group variational integrators
are a particular class of these integrators that apply to systems which evolve
over the tangent bundle and cotangent bundle of Lie groups. Traditionally,
these are constructed from a variational principle which assumes fixed position
endpoints. In this paper, we instead construct Lie group variational
integrators with a novel Type II variational principle on the cotangent bundle
of a Lie group which allows for Type II boundary conditions, i.e., fixed
initial position and final momenta; these boundary conditions are particularly
important for adjoint sensitivity analysis, which is the motivating application
in our paper. In general, such Type II variational principles are only globally
defined on vector spaces or locally defined on general manifolds; however, by
left translation, we are able to define this variational principle globally on
cotangent bundles of Lie groups. By developing the continuous and discrete Type
II variational principles over Lie groups, we construct a structure-preserving
Lie group variational integrator that is both symplectic and
momentum-preserving. Subsequently, we introduce adjoint systems on Lie groups,
and show how these adjoint systems can be used to perform geometric adjoint
sensitivity analysis for optimization problems on Lie groups. Finally, we
conclude with two numerical examples to show how adjoint sensitivity analysis
can be used to solve initial-value optimization problems and optimal control
problems on Lie groups.
</p>
</div>
</dd>
<dt><a name="item68">[68]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03530" title="Abstract">arXiv:2311.03530</a> [<a href="/pdf/2311.03530" title="Download PDF">pdf</a>, <a href="/ps/2311.03530" title="Download PostScript">ps</a>, <a href="/format/2311.03530" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DAO Decentralization: Voting-Bloc Entropy, Bribery, and Dark DAOs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Austgen%2C+J">James Austgen</a>, 
<a href="/search/cs?searchtype=author&query=F%C3%A1brega%2C+A">Andr&#xe9;s F&#xe1;brega</a>, 
<a href="/search/cs?searchtype=author&query=Allen%2C+S">Sarah Allen</a>, 
<a href="/search/cs?searchtype=author&query=Babel%2C+K">Kushal Babel</a>, 
<a href="/search/cs?searchtype=author&query=Kelkar%2C+M">Mahimna Kelkar</a>, 
<a href="/search/cs?searchtype=author&query=Juels%2C+A">Ari Juels</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">Decentralized Autonomous Organizations (DAOs) use smart contracts to foster
communities working toward common goals. Existing definitions of
decentralization, however-the 'D' in DAO-fall short of capturing key properties
characteristic of diverse and equitable participation. We propose a new metric
called Voting-Bloc Entropy (VBE, pronounced ''vibe'') that formalizes a broad
notion of decentralization in voting on DAO proposals. VBE measures the
similarity of participants' utility functions across a set of proposals. We use
VBE to prove a number of results about the decentralizing effects of vote
delegation, proposal bundling, bribery, and quadratic voting. Our results lead
to practical suggestions for enhancing DAO decentralization. One of our results
highlights the risk of systemic bribery with increasing DAO decentralization.
To show that this threat is realistic, we present the first practical
realization of a Dark DAO, a proposed mechanism for privacy-preserving
corruption of identity systems, including those used in DAO voting. Our
Dark-DAO prototype uses trusted execution environments (TEEs) in the Oasis
Sapphire blockchain for attacks on Ethereum DAOs. It demonstrates that Dark
DAOs constitute a realistic future concern for DAO governance.
</p>
</div>
</dd>
<dt><a name="item69">[69]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03532" title="Abstract">arXiv:2311.03532</a> [<a href="/pdf/2311.03532" title="Download PDF">pdf</a>, <a href="/format/2311.03532" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Fairness Stitch: Unveiling the Potential of Model Stitching in  Neural Network De-Biasing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sulaiman%2C+M">Modar Sulaiman</a>, 
<a href="/search/cs?searchtype=author&query=Roy%2C+K">Kallol Roy</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Information Theory (cs.IT)

</div>
<p class="mathjax">The pursuit of fairness in machine learning models has emerged as a critical
research challenge in different applications ranging from bank loan approval to
face detection. Despite the widespread adoption of artificial intelligence
algorithms across various domains, concerns persist regarding the presence of
biases and discrimination within these models. To address this pressing issue,
this study introduces a novel method called "The Fairness Stitch (TFS)" to
enhance fairness in deep learning models. This method combines model stitching
and training jointly, while incorporating fairness constraints. In this
research, we assess the effectiveness of our proposed method by conducting a
comprehensive evaluation of two well-known datasets, CelebA and UTKFace. We
systematically compare the performance of our approach with the existing
baseline method. Our findings reveal a notable improvement in achieving a
balanced trade-off between fairness and performance, highlighting the promising
potential of our method to address bias-related challenges and foster equitable
outcomes in machine learning models. This paper poses a challenge to the
conventional wisdom of the effectiveness of the last layer in deep learning
models for de-biasing.
</p>
</div>
</dd>
<dt><a name="item70">[70]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03533" title="Abstract">arXiv:2311.03533</a> [<a href="/pdf/2311.03533" title="Download PDF">pdf</a>, <a href="/format/2311.03533" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Quantifying Uncertainty in Natural Language Explanations of Large  Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tanneru%2C+S+H">Sree Harsha Tanneru</a>, 
<a href="/search/cs?searchtype=author&query=Agarwal%2C+C">Chirag Agarwal</a>, 
<a href="/search/cs?searchtype=author&query=Lakkaraju%2C+H">Himabindu Lakkaraju</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Large Language Models (LLMs) are increasingly used as powerful tools for
several high-stakes natural language processing (NLP) applications. Recent
prompting works claim to elicit intermediate reasoning steps and key tokens
that serve as proxy explanations for LLM predictions. However, there is no
certainty whether these explanations are reliable and reflect the LLMs
behavior. In this work, we make one of the first attempts at quantifying the
uncertainty in explanations of LLMs. To this end, we propose two novel metrics
-- $\textit{Verbalized Uncertainty}$ and $\textit{Probing Uncertainty}$ -- to
quantify the uncertainty of generated explanations. While verbalized
uncertainty involves prompting the LLM to express its confidence in its
explanations, probing uncertainty leverages sample and model perturbations as a
means to quantify the uncertainty. Our empirical analysis of benchmark datasets
reveals that verbalized uncertainty is not a reliable estimate of explanation
confidence. Further, we show that the probing uncertainty estimates are
correlated with the faithfulness of an explanation, with lower uncertainty
corresponding to explanations with higher faithfulness. Our study provides
insights into the challenges and opportunities of quantifying uncertainty in
LLM explanations, contributing to the broader discussion of the trustworthiness
of foundation models.
</p>
</div>
</dd>
<dt><a name="item71">[71]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03534" title="Abstract">arXiv:2311.03534</a> [<a href="/pdf/2311.03534" title="Download PDF">pdf</a>, <a href="/format/2311.03534" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PcLast: Discovering Plannable Continuous Latent States
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Koul%2C+A">Anurag Koul</a>, 
<a href="/search/cs?searchtype=author&query=Sujit%2C+S">Shivakanth Sujit</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+S">Shaoru Chen</a>, 
<a href="/search/cs?searchtype=author&query=Evans%2C+B">Ben Evans</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+L">Lili Wu</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+B">Byron Xu</a>, 
<a href="/search/cs?searchtype=author&query=Chari%2C+R">Rajan Chari</a>, 
<a href="/search/cs?searchtype=author&query=Islam%2C+R">Riashat Islam</a>, 
<a href="/search/cs?searchtype=author&query=Seraj%2C+R">Raihan Seraj</a>, 
<a href="/search/cs?searchtype=author&query=Efroni%2C+Y">Yonathan Efroni</a>, 
<a href="/search/cs?searchtype=author&query=Molu%2C+L">Lekan Molu</a>, 
<a href="/search/cs?searchtype=author&query=Dudik%2C+M">Miro Dudik</a>, 
<a href="/search/cs?searchtype=author&query=Langford%2C+J">John Langford</a>, 
<a href="/search/cs?searchtype=author&query=Lamb%2C+A">Alex Lamb</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Pre-Print
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Robotics (cs.RO)

</div>
<p class="mathjax">Goal-conditioned planning benefits from learned low-dimensional
representations of rich, high-dimensional observations. While compact latent
representations, typically learned from variational autoencoders or inverse
dynamics, enable goal-conditioned planning they ignore state affordances, thus
hampering their sample-efficient planning capabilities. In this paper, we learn
a representation that associates reachable states together for effective onward
planning. We first learn a latent representation with multi-step inverse
dynamics (to remove distracting information); and then transform this
representation to associate reachable states together in $\ell_2$ space. Our
proposals are rigorously tested in various simulation testbeds. Numerical
results in reward-based and reward-free settings show significant improvements
in sampling efficiency, and yields layered state abstractions that enable
computationally efficient hierarchical planning.
</p>
</div>
</dd>
<dt><a name="item72">[72]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03535" title="Abstract">arXiv:2311.03535</a> [<a href="/pdf/2311.03535" title="Download PDF">pdf</a>, <a href="/format/2311.03535" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Enhancing Performance Monitoring in C/C++ Programs with EDPM: A  Domain-Specific Language for Performance Monitoring
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Holmqvist%2C+D+W">David Weisskopf Holmqvist</a>, 
<a href="/search/cs?searchtype=author&query=Memeti%2C+S">Suejb Memeti</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This is a preprint of the article scheduled for publication in the proceedings of the First Workshop on Tools for Data Locality, Power and Performance (TDLPP 2023), published by Springer
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Performance (cs.PF)</span>; Programming Languages (cs.PL)

</div>
<p class="mathjax">The utilization of performance monitoring probes is a valuable tool for
programmers to gather performance data. However, the manual insertion of these
probes can result in an increase in code size, code obfuscation, and an added
burden of learning different APIs associated with performance monitoring tools.
To mitigate these issues, EDPM, an embedded domain-specific language, was
developed to provide a higher level of abstraction for annotating regions of
code that require instrumentation in C and C++ programs. This paper presents
the design and implementation of EDPM and compares it to the well-known tool
PAPI, in terms of required lines of code, flexibility in configuring regions,
and performance overhead. The results of this study demonstrate that EDPM is a
low-resolution profiling tool that offers a reduction in required lines of code
and enables programmers to express various configurations of regions.
Furthermore, the design of EDPM is such that its pragmas are ignored by the
standard compiler, allowing for seamless integration into existing software
processes without disrupting build systems or increasing the size of the
executable. Additionally, the design of the EDPM pre-compiler allows for the
extension of available performance counters while maintaining a high level of
abstraction for programmers. Therefore, EDPM offers a promising solution to
simplify and optimize performance monitoring in C and C++ programs.
</p>
</div>
</dd>
<dt><a name="item73">[73]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03537" title="Abstract">arXiv:2311.03537</a> [<a href="/pdf/2311.03537" title="Download PDF">pdf</a>, <a href="/format/2311.03537" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Leveraging point annotations in segmentation learning with boundary loss
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Breznik%2C+E">Eva Breznik</a>, 
<a href="/search/cs?searchtype=author&query=Kervadec%2C+H">Hoel Kervadec</a>, 
<a href="/search/cs?searchtype=author&query=Malmberg%2C+F">Filip Malmberg</a>, 
<a href="/search/cs?searchtype=author&query=Kullberg%2C+J">Joel Kullberg</a>, 
<a href="/search/cs?searchtype=author&query=Ahlstr%C3%B6m%2C+H">H&#xe5;kan Ahlstr&#xf6;m</a>, 
<a href="/search/cs?searchtype=author&query=de+Bruijne%2C+M">Marleen de Bruijne</a>, 
<a href="/search/cs?searchtype=author&query=Strand%2C+R">Robin Strand</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">This paper investigates the combination of intensity-based distance maps with
boundary loss for point-supervised semantic segmentation. By design the
boundary loss imposes a stronger penalty on the false positives the farther
away from the object they occur. Hence it is intuitively inappropriate for weak
supervision, where the ground truth label may be much smaller than the actual
object and a certain amount of false positives (w.r.t. the weak ground truth)
is actually desirable. Using intensity-aware distances instead may alleviate
this drawback, allowing for a certain amount of false positives without a
significant increase to the training loss. The motivation for applying the
boundary loss directly under weak supervision lies in its great success for
fully supervised segmentation tasks, but also in not requiring extra priors or
outside information that is usually required -- in some form -- with existing
weakly supervised methods in the literature. This formulation also remains
potentially more attractive than existing CRF-based regularizers, due to its
simplicity and computational efficiency. We perform experiments on two
multi-class datasets; ACDC (heart segmentation) and POEM (whole-body abdominal
organ segmentation). Preliminary results are encouraging and show that this
supervision strategy has great potential. On ACDC it outperforms the CRF-loss
based approach, and on POEM data it performs on par with it. The code for all
our experiments is openly available.
</p>
</div>
</dd>
<dt><a name="item74">[74]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03542" title="Abstract">arXiv:2311.03542</a> [<a href="/pdf/2311.03542" title="Download PDF">pdf</a>, <a href="/format/2311.03542" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Indexing Techniques for Graph Reachability Queries
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+C">Chao Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Bonifati%2C+A">Angela Bonifati</a>, 
<a href="/search/cs?searchtype=author&query=%C3%96zsu%2C+M+T">M. Tamer &#xd6;zsu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Databases (cs.DB)</span>

</div>
<p class="mathjax">We survey graph reachability indexing techniques for efficient processing of
graph reachability queries in two types of popular graph models: plain graphs
and edge-labeled graphs. Reachability queries are fundamental in graph
processing, and reachability indexes are specialized data structures tailored
for speeding up such queries. Work on this topic goes back four decades -- we
include 33 of the proposed techniques. Plain graphs contain only vertices and
edges, with reachability queries checking path existence between a source and
target vertex. Edge-labeled graphs, in contrast, augment plain graphs by adding
edge labels. Reachability queries in edge-labeled graphs incorporate path
constraints based on edge labels, assessing both path existence and compliance
with constraints.
<br />We categorize techniques in both plain and edge-labeled graphs and discuss
the approaches according to this classification, using existing techniques as
exemplars. We discuss the main challenges within each class and how these might
be addressed in other approaches. We conclude with a discussion of the open
research challenges and future research directions, along the lines of
integrating reachability indexes into graph data management systems. This
survey serves as a comprehensive resource for researchers and practitioners
interested in the advancements, techniques, and challenges on reachability
indexing in graph analytics.
</p>
</div>
</dd>
<dt><a name="item75">[75]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03543" title="Abstract">arXiv:2311.03543</a> [<a href="/pdf/2311.03543" title="Download PDF">pdf</a>, <a href="/format/2311.03543" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Enabling Dynamic Selection of Implementation Variants in Component-Based  Parallel Programming for Heterogeneous Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Memeti%2C+S">Suejb Memeti</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This is a preprint of the article scheduled for publication in the proceedings of The 21st International Workshop on Algorithms, Models and Tools for Parallel Computing on Heterogeneous Platforms (HeteroPar 2023), published by Springer
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>; Programming Languages (cs.PL)

</div>
<p class="mathjax">Heterogeneous systems, consisting of CPUs and GPUs, offer the capability to
address the demands of compute- and data-intensive applications. However,
programming such systems is challenging, requiring knowledge of various
parallel programming frameworks. This paper introduces COMPAR, a
component-based parallel programming framework that enables the exposure and
selection of multiple implementation variants of components at runtime. The
framework leverages compiler directive-based language extensions to annotate
the source code and generate the necessary glue code for the StarPU runtime
system. COMPAR provides a unified view of implementation variants and allows
for intelligent selection based on runtime context. Our evaluation demonstrates
the effectiveness of COMPAR through benchmark applications. The proposed
approach simplifies heterogeneous parallel programming and promotes code reuse
while achieving optimal performance.
</p>
</div>
</dd>
<dt><a name="item76">[76]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03545" title="Abstract">arXiv:2311.03545</a> [<a href="/pdf/2311.03545" title="Download PDF">pdf</a>, <a href="/ps/2311.03545" title="Download PostScript">ps</a>, <a href="/format/2311.03545" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Time-optimal Design and Control of Electric Race Cars Equipped with  Multi-speed Transmissions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Cartignij%2C+C">Camiel Cartignij</a>, 
<a href="/search/eess?searchtype=author&query=Salazar%2C+M">Mauro Salazar</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to VPPC 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">This paper presents a framework to jointly optimize the design and control of
an electric race car equipped with a multiple-gear transmission, specifically
accounting for the discrete gearshift dynamics. We formulate the problem as a
mixed-integer optimal control problem, and deal with its complexity by
combining convex optimization and Pontryagin's Minimum Principle in a
computationally efficient iterative algorithm satisfying necessary conditions
for optimality upon convergence. Finally, we leverage our framework to compute
the achievable lap time of a race car equipped with a fixed-gear transmission,
a continuously variable transmission and a multiple-gear transmission with 2 to
4 speeds, revealing that a multiple-gear transmission can strike the best
trade-off in terms of electric motor control, and transmission weight and
efficiency, ultimately yielding the overall best lap time.
</p>
</div>
</dd>
<dt><a name="item77">[77]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03547" title="Abstract">arXiv:2311.03547</a> [<a href="/pdf/2311.03547" title="Download PDF">pdf</a>, <a href="/format/2311.03547" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> InterVLS: Interactive Model Understanding and Improvement with  Vision-Language Surrogates
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+J">Jinbin Huang</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+W">Wenbin He</a>, 
<a href="/search/cs?searchtype=author&query=Gou%2C+L">Liang Gou</a>, 
<a href="/search/cs?searchtype=author&query=Ren%2C+L">Liu Ren</a>, 
<a href="/search/cs?searchtype=author&query=Bryan%2C+C">Chris Bryan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computer Vision and Pattern Recognition (cs.CV); Human-Computer Interaction (cs.HC); Machine Learning (cs.LG)

</div>
<p class="mathjax">Deep learning models are widely used in critical applications, highlighting
the need for pre-deployment model understanding and improvement. Visual
concept-based methods, while increasingly used for this purpose, face
challenges: (1) most concepts lack interpretability, (2) existing methods
require model knowledge, often unavailable at run time. Additionally, (3) there
lacks a no-code method for post-understanding model improvement. Addressing
these, we present InterVLS. The system facilitates model understanding by
discovering text-aligned concepts, measuring their influence with
model-agnostic linear surrogates. Employing visual analytics, InterVLS offers
concept-based explanations and performance insights. It enables users to adjust
concept influences to update a model, facilitating no-code model improvement.
We evaluate InterVLS in a user study, illustrating its functionality with two
scenarios. Results indicates that InterVLS is effective to help users identify
influential concepts to a model, gain insights and adjust concept influence to
improve the model. We conclude with a discussion based on our study results.
</p>
</div>
</dd>
<dt><a name="item78">[78]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03550" title="Abstract">arXiv:2311.03550</a> [<a href="/pdf/2311.03550" title="Download PDF">pdf</a>, <a href="/format/2311.03550" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> United We Stand, Divided We Fall: UnityGraph for Unsupervised Procedure  Learning from Videos
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bansal%2C+S">Siddhant Bansal</a>, 
<a href="/search/cs?searchtype=author&query=Arora%2C+C">Chetan Arora</a>, 
<a href="/search/cs?searchtype=author&query=Jawahar%2C+C+V">C.V. Jawahar</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, 6 figures, Accepted in Winter Conference on Applications of Computer Vision (WACV), 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Given multiple videos of the same task, procedure learning addresses
identifying the key-steps and determining their order to perform the task. For
this purpose, existing approaches use the signal generated from a pair of
videos. This makes key-steps discovery challenging as the algorithms lack
inter-videos perspective. Instead, we propose an unsupervised Graph-based
Procedure Learning (GPL) framework. GPL consists of the novel UnityGraph that
represents all the videos of a task as a graph to obtain both intra-video and
inter-videos context. Further, to obtain similar embeddings for the same
key-steps, the embeddings of UnityGraph are updated in an unsupervised manner
using the Node2Vec algorithm. Finally, to identify the key-steps, we cluster
the embeddings using KMeans. We test GPL on benchmark ProceL, CrossTask, and
EgoProceL datasets and achieve an average improvement of 2% on third-person
datasets and 3.6% on EgoProceL over the state-of-the-art.
</p>
</div>
</dd>
<dt><a name="item79">[79]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03551" title="Abstract">arXiv:2311.03551</a> [<a href="/pdf/2311.03551" title="Download PDF">pdf</a>, <a href="/format/2311.03551" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Context Unlocks Emotions: Text-based Emotion Classification Dataset  Auditing with Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+D">Daniel Yang</a>, 
<a href="/search/cs?searchtype=author&query=Kommineni%2C+A">Aditya Kommineni</a>, 
<a href="/search/cs?searchtype=author&query=Alshehri%2C+M">Mohammad Alshehri</a>, 
<a href="/search/cs?searchtype=author&query=Mohanty%2C+N">Nilamadhab Mohanty</a>, 
<a href="/search/cs?searchtype=author&query=Modi%2C+V">Vedant Modi</a>, 
<a href="/search/cs?searchtype=author&query=Gratch%2C+J">Jonathan Gratch</a>, 
<a href="/search/cs?searchtype=author&query=Narayanan%2C+S">Shrikanth Narayanan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">The lack of contextual information in text data can make the annotation
process of text-based emotion classification datasets challenging. As a result,
such datasets often contain labels that fail to consider all the relevant
emotions in the vocabulary. This misalignment between text inputs and labels
can degrade the performance of machine learning models trained on top of them.
As re-annotating entire datasets is a costly and time-consuming task that
cannot be done at scale, we propose to use the expressive capabilities of large
language models to synthesize additional context for input text to increase its
alignment with the annotated emotional labels. In this work, we propose a
formal definition of textual context to motivate a prompting strategy to
enhance such contextual information. We provide both human and empirical
evaluation to demonstrate the efficacy of the enhanced context. Our method
improves alignment between inputs and their human-annotated labels from both an
empirical and human-evaluated standpoint.
</p>
</div>
</dd>
<dt><a name="item80">[80]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03552" title="Abstract">arXiv:2311.03552</a> [<a href="/pdf/2311.03552" title="Download PDF">pdf</a>, <a href="/format/2311.03552" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Modeling and Control of Diesel Engine Emissions using Multi-layer Neural  Networks and Economic Model Predictive Control
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Zhang%2C+J">Jiadi Zhang</a>, 
<a href="/search/eess?searchtype=author&query=Li%2C+X">Xiao Li</a>, 
<a href="/search/eess?searchtype=author&query=Amini%2C+M+R">Mohammad Reza Amini</a>, 
<a href="/search/eess?searchtype=author&query=Kolmanovsky%2C+I">Ilya Kolmanovsky</a>, 
<a href="/search/eess?searchtype=author&query=Tsutsumi%2C+M">Munechika Tsutsumi</a>, 
<a href="/search/eess?searchtype=author&query=Nakada%2C+H">Hayato Nakada</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">This paper presents the results of developing a multi-layer Neural Network
(NN) to represent diesel engine emissions and integrating this NN into control
design. Firstly, a NN is trained and validated to simultaneously predict oxides
of nitrogen (N Ox) and Soot using both transient and steady-state data. Based
on the input-output correlation analysis, inputs to NN with the highest
influence on the emissions are selected while keeping the NN structure simple.
Secondly, a co-simulation framework is implemented to integrate the NN
emissions model with a model of a diesel engine airpath system built in
GT-Power and used to identify a low-order linear parameter-varying (LPV) model
for emissions prediction. Finally, an economic supervisory model predictive
controller (MPC) is developed using the LPV emissions model to adjust setpoints
to an inner-loop airpath tracking MPC. Simulation results are reported
illustrating the capability of the resulting controller to reduce N Ox, meet
the target Soot limit, and track the adjusted intake manifold pressure and
exhaust gas recirculation (EGR) rate targets.
</p>
</div>
</dd>
<dt><a name="item81">[81]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03553" title="Abstract">arXiv:2311.03553</a> [<a href="/pdf/2311.03553" title="Download PDF">pdf</a>, <a href="/format/2311.03553" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> iDb-A*: Iterative Search and Optimization for Optimal Kinodynamic Motion  Planning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ortiz-Haro%2C+J">Joaquim Ortiz-Haro</a>, 
<a href="/search/cs?searchtype=author&query=Hoenig%2C+W">Wolfgang Hoenig</a>, 
<a href="/search/cs?searchtype=author&query=Hartmann%2C+V+N">Valentin N. Hartmann</a>, 
<a href="/search/cs?searchtype=author&query=Toussaint%2C+M">Marc Toussaint</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Motion planning for robotic systems with complex dynamics is a challenging
problem. While recent sampling-based algorithms achieve asymptotic optimality
by propagating random control inputs, their empirical convergence rate is often
poor, especially in high-dimensional systems such as multirotors. An
alternative approach is to first plan with a simplified geometric model and
then use trajectory optimization to follow the reference path while accounting
for the true dynamics. However, this approach may fail to produce a valid
trajectory if the initial guess is not close to a dynamically feasible
trajectory. In this paper, we present Iterative Discontinuity Bounded A*
(iDb-A*), a novel kinodynamic motion planner that combines search and
optimization iteratively. The search step utilizes a finite set of short
trajectories (motion primitives) that are interconnected while allowing for a
bounded discontinuity between them. The optimization step locally repairs the
discontinuities with trajectory optimization. By progressively reducing the
allowed discontinuity and incorporating more motion primitives, our algorithm
achieves asymptotic optimality with excellent any-time performance. We provide
a benchmark of 43 problems across eight different dynamical systems, including
different versions of unicycles and multirotors. Compared to state-of-the-art
methods, iDb-A* consistently solves more problem instances and finds lower-cost
solutions more rapidly.
</p>
</div>
</dd>
<dt><a name="item82">[82]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03555" title="Abstract">arXiv:2311.03555</a> [<a href="/pdf/2311.03555" title="Download PDF">pdf</a>, <a href="/format/2311.03555" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Model Predictive Control of Diesel Engine Emissions Based on Neural  Network Modeling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Zhang%2C+J">Jiadi Zhang</a>, 
<a href="/search/eess?searchtype=author&query=Li%2C+X">Xiao Li</a>, 
<a href="/search/eess?searchtype=author&query=Kolmanovsky%2C+I">Ilya Kolmanovsky</a>, 
<a href="/search/eess?searchtype=author&query=Tsutsumi%2C+M">Munechika Tsutsumi</a>, 
<a href="/search/eess?searchtype=author&query=Nakada%2C+H">Hayato Nakada</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">This paper addresses the control of diesel engine nitrogen oxides (NOx) and
Soot emissions through the application of Model Predictive Control (MPC). The
developments described in the paper are based on a high-fidelity model of the
engine airpath and torque response in GT-Power, which is extended with a
feedforward neural network (FNN)-based model of engine out (feedgas) emissions
identified from experimental engine data to enable the controller co-simulation
and performance verification. A Recurrent Neural Network (RNN) is then
identified for use as a prediction model in the implementation of a nonlinear
economic MPC that adjusts intake manifold pressure and EGR rate set-points to
the inner loop airpath controller as well as the engine fueling rate. Based on
GT-Power engine model and FNN emissions model, the closed-loop simulations of
the control system and the plant model, over different driving cycles,
demonstrate the capability to shape engine out emissions response by adjusting
weights and constraints in economic MPC formulation.
</p>
</div>
</dd>
<dt><a name="item83">[83]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03557" title="Abstract">arXiv:2311.03557</a> [<a href="/pdf/2311.03557" title="Download PDF">pdf</a>, <a href="/format/2311.03557" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Spatio-Temporal Similarity Measure based Multi-Task Learning for  Predicting Alzheimer&#x27;s Disease Progression using MRI Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xulong Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yu Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+M">Menghui Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+T">Tong Liu</a>, 
<a href="/search/cs?searchtype=author&query=Qi%2C+J">Jun Qi</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+P">Po Yang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV); Image and Video Processing (eess.IV)

</div>
<p class="mathjax">Identifying and utilising various biomarkers for tracking Alzheimer's disease
(AD) progression have received many recent attentions and enable helping
clinicians make the prompt decisions. Traditional progression models focus on
extracting morphological biomarkers in regions of interest (ROIs) from MRI/PET
images, such as regional average cortical thickness and regional volume. They
are effective but ignore the relationships between brain ROIs over time, which
would lead to synergistic deterioration. For exploring the synergistic
deteriorating relationship between these biomarkers, in this paper, we propose
a novel spatio-temporal similarity measure based multi-task learning approach
for effectively predicting AD progression and sensitively capturing the
critical relationships between biomarkers. Specifically, we firstly define a
temporal measure for estimating the magnitude and velocity of biomarker change
over time, which indicate a changing trend(temporal). Converting this trend
into the vector, we then compare this variability between biomarkers in a
unified vector space(spatial). The experimental results show that compared with
directly ROI based learning, our proposed method is more effective in
predicting disease progression. Our method also enables performing longitudinal
stability selection to identify the changing relationships between biomarkers,
which play a key role in disease progression. We prove that the synergistic
deteriorating biomarkers between cortical volumes or surface areas have a
significant effect on the cognitive prediction.
</p>
</div>
</dd>
<dt><a name="item84">[84]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03559" title="Abstract">arXiv:2311.03559</a> [<a href="/pdf/2311.03559" title="Download PDF">pdf</a>, <a href="/format/2311.03559" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Algebraic Conditions on One-Step Breadth-First Search
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fu%2C+E">Emma Fu</a>, 
<a href="/search/cs?searchtype=author&query=Jananthan%2C+H">Hayden Jananthan</a>, 
<a href="/search/cs?searchtype=author&query=Kepner%2C+J">Jeremy Kepner</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages, 2 figures, accepted to IEEE URTC 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Discrete Mathematics (cs.DM)</span>

</div>
<p class="mathjax">The GraphBLAS community has demonstrated the power of linear
algebra-leveraged graph algorithms, such as matrix-vector products for
breadth-first search (BFS) traversals. This paper investigates the algebraic
conditions needed for such computations when working with directed hypergraphs,
represented by incidence arrays with entries from an arbitrary value set with
binary addition and multiplication operations. Our results show the one-step
BFS traversal is equivalent to requiring specific algebraic properties of those
operations. Assuming identity elements 0, 1 for operations, we show that the
two operations must be zero-sum-free, zero-divisor-free, and 0 must be an
annihilator under multiplication. Additionally, associativity and commutativity
are shown to be necessary and sufficient for independence of the one-step BFS
computation from several arbitrary conventions. These results aid in
application and algorithm development by determining the efficacy of a value
set in computations.
</p>
</div>
</dd>
<dt><a name="item85">[85]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03561" title="Abstract">arXiv:2311.03561</a> [<a href="/pdf/2311.03561" title="Download PDF">pdf</a>, <a href="/format/2311.03561" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Sea You Later: Metadata-Guided Long-Term Re-Identification for UAV-Based  Multi-Object Tracking
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+C">Cheng-Yen Yang</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+H">Hsiang-Wei Huang</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+Z">Zhongyu Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Kuo%2C+H">Heng-Cheng Kuo</a>, 
<a href="/search/cs?searchtype=author&query=Mei%2C+J">Jie Mei</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+C">Chung-I Huang</a>, 
<a href="/search/cs?searchtype=author&query=Hwang%2C+J">Jenq-Neng Hwang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 1st place method of the UAV-based Multi-Object Tracking with Reidentification Challenge in MaCVi WACV 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Re-identification (ReID) in multi-object tracking (MOT) for UAVs in maritime
computer vision has been challenging for several reasons. More specifically,
short-term re-identification (ReID) is difficult due to the nature of the
characteristics of small targets and the sudden movement of the drone's gimbal.
Long-term ReID suffers from the lack of useful appearance diversity. In
response to these challenges, we present an adaptable motion-based MOT
algorithm, called Metadata Guided MOT (MG-MOT). This algorithm effectively
merges short-term tracking data into coherent long-term tracks, harnessing
crucial metadata from UAVs, including GPS position, drone altitude, and camera
orientations. Extensive experiments are conducted to validate the efficacy of
our MOT algorithm. Utilizing the challenging SeaDroneSee tracking dataset,
which encompasses the aforementioned scenarios, we achieve a much-improved
performance in the latest edition of the UAV-based Maritime Object Tracking
Challenge with a state-of-the-art HOTA of 69.5% and an IDF1 of 85.9% on the
testing split.
</p>
</div>
</dd>
<dt><a name="item86">[86]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03562" title="Abstract">arXiv:2311.03562</a> [<a href="/pdf/2311.03562" title="Download PDF">pdf</a>, <a href="/format/2311.03562" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> From Bits to Insights: Exploring Network Traffic, Traffic Matrices, and  Heavy-Tailed Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Howard%2C+C">Christopher Howard</a>, 
<a href="/search/cs?searchtype=author&query=Jananthan%2C+H">Hayden Jananthan</a>, 
<a href="/search/cs?searchtype=author&query=Kepner%2C+J">Jeremy Kepner</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages, 5 figures, accepted to IEEE URTC 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>

</div>
<p class="mathjax">With the Internet a central component of modern society, entire industries
and fields have developed both in support and against cybersecurity. For cyber
operators to best understand their networks, they must conduct detailed traffic
analyses. A growing recognition is the ubiquity of heavy-tailed characteristics
in network traffic. However, a thorough analysis of cybersecurity programs
suggests little statistics educational background, worsened by the observation
that college-level statistics courses largely lack heavy-tailed content,
meaning cyber operators are both ill-equipped to appropriately analyze their
network traffic and unable to easily access resources that could help. In
response, we developed an accessible Jupyter Notebook module that guides
individuals--regardless of statistical background--through traffic matrix
creation, heavy-tailed data identification, data visualization, and
distribution fitting. Such content empowers cyber operators, improving analyses
and design.
</p>
</div>
</dd>
<dt><a name="item87">[87]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03564" title="Abstract">arXiv:2311.03564</a> [<a href="/pdf/2311.03564" title="Download PDF">pdf</a>, <a href="/ps/2311.03564" title="Download PostScript">ps</a>, <a href="/format/2311.03564" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Low-Rank MDPs with Continuous Action Spaces
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bennett%2C+A">Andrew Bennett</a>, 
<a href="/search/cs?searchtype=author&query=Kallus%2C+N">Nathan Kallus</a>, 
<a href="/search/cs?searchtype=author&query=Oprescu%2C+M">Miruna Oprescu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 20 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Machine Learning (stat.ML)

</div>
<p class="mathjax">Low-Rank Markov Decision Processes (MDPs) have recently emerged as a
promising framework within the domain of reinforcement learning (RL), as they
allow for provably approximately correct (PAC) learning guarantees while also
incorporating ML algorithms for representation learning. However, current
methods for low-rank MDPs are limited in that they only consider finite action
spaces, and give vacuous bounds as $|\mathcal{A}| \to \infty$, which greatly
limits their applicability. In this work, we study the problem of extending
such methods to settings with continuous actions, and explore multiple concrete
approaches for performing this extension. As a case study, we consider the
seminal FLAMBE algorithm (Agarwal et al., 2020), which is a reward-agnostic
method for PAC RL with low-rank MDPs. We show that, without any modifications
to the algorithm, we obtain similar PAC bound when actions are allowed to be
continuous. Specifically, when the model for transition functions satisfies a
Holder smoothness condition w.r.t. actions, and either the policy class has a
uniformly bounded minimum density or the reward function is also Holder smooth,
we obtain a polynomial PAC bound that depends on the order of smoothness.
</p>
</div>
</dd>
<dt><a name="item88">[88]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03565" title="Abstract">arXiv:2311.03565</a> [<a href="/pdf/2311.03565" title="Download PDF">pdf</a>, <a href="/format/2311.03565" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MIRAGE: Multi-Binary Image Risk Assessment with Attack Graph Employment
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tayouri%2C+D">David Tayouri</a>, 
<a href="/search/cs?searchtype=author&query=Nachum%2C+T">Telem Nachum</a>, 
<a href="/search/cs?searchtype=author&query=Shabtai%2C+A">Asaf Shabtai</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">Attackers can exploit known vulnerabilities to infiltrate a device's firmware
and the communication between firmware binaries, in order to pass between them.
To improve cybersecurity, organizations must identify and mitigate the risks of
the firmware they use. An attack graph (AG) can be used to assess and visually
display firmware's risks by organizing the identified vulnerabilities into
attack paths composed of sequences of actions attackers may perform to
compromise firmware images. In this paper, we utilize AGs for firmware risk
assessment. We propose MIRAGE (Multi-binary Image Risk Assessment with Attack
Graph Employment), a framework for identifying potential attack vectors and
vulnerable interactions between firmware binaries; MIRAGE accomplishes this by
generating AGs for firmware inter-binary communication. The use cases of the
proposed firmware AG generation framework include the identification of risky
external interactions, supply chain risk assessment, and security analysis with
digital twins. To evaluate the MIRAGE framework, we collected a dataset of 703
firmware images. We also propose a model for examining the risks of firmware
binaries, demonstrate the model's implementation on the dataset of firmware
images, and list the riskiest binaries.
</p>
</div>
</dd>
<dt><a name="item89">[89]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03566" title="Abstract">arXiv:2311.03566</a> [<a href="/pdf/2311.03566" title="Download PDF">pdf</a>, <a href="/format/2311.03566" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Measuring Adversarial Datasets
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bai%2C+Y">Yuanchen Bai</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+R">Raoyi Huang</a>, 
<a href="/search/cs?searchtype=author&query=Viswanathan%2C+V">Vijay Viswanathan</a>, 
<a href="/search/cs?searchtype=author&query=Kuo%2C+T">Tzu-Sheng Kuo</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+T">Tongshuang Wu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ART of Safety workshop (AACL 2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computation and Language (cs.CL); Human-Computer Interaction (cs.HC)

</div>
<p class="mathjax">In the era of widespread public use of AI systems across various domains,
ensuring adversarial robustness has become increasingly vital to maintain
safety and prevent undesirable errors. Researchers have curated various
adversarial datasets (through perturbations) for capturing model deficiencies
that cannot be revealed in standard benchmark datasets. However, little is
known about how these adversarial examples differ from the original data
points, and there is still no methodology to measure the intended and
unintended consequences of those adversarial transformations. In this research,
we conducted a systematic survey of existing quantifiable metrics that describe
text instances in NLP tasks, among dimensions of difficulty, diversity, and
disagreement. We selected several current adversarial effect datasets and
compared the distributions between the original and their adversarial
counterparts. The results provide valuable insights into what makes these
datasets more challenging from a metrics perspective and whether they align
with underlying assumptions.
</p>
</div>
</dd>
<dt><a name="item90">[90]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03567" title="Abstract">arXiv:2311.03567</a> [<a href="/pdf/2311.03567" title="Download PDF">pdf</a>, <a href="/format/2311.03567" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Inclusive Portraits: Race-Aware Human-in-the-Loop Technology
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Flores-Saviaga%2C+C">Claudia Flores-Saviaga</a>, 
<a href="/search/cs?searchtype=author&query=Curtis%2C+C">Christopher Curtis</a>, 
<a href="/search/cs?searchtype=author&query=Savage%2C+S">Saiph Savage</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Equity and Access in Algorithms, Mechanisms, and Optimization
  (EAAMO 2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">AI has revolutionized the processing of various services, including the
automatic facial verification of people. Automated approaches have demonstrated
their speed and efficiency in verifying a large volume of faces, but they can
face challenges when processing content from certain communities, including
communities of people of color. This challenge has prompted the adoption of
"human-in-the-loop" (HITL) approaches, where human workers collaborate with the
AI to minimize errors. However, most HITL approaches do not consider workers'
individual characteristics and backgrounds. This paper proposes a new approach,
called Inclusive Portraits (IP), that connects with social theories around race
to design a racially-aware human-in-the-loop system. Our experiments have
provided evidence that incorporating race into human-in-the-loop (HITL) systems
for facial verification can significantly enhance performance, especially for
services delivered to people of color. Our findings also highlight the
importance of considering individual worker characteristics in the design of
HITL systems, rather than treating workers as a homogenous group. Our research
has significant design implications for developing AI-enhanced services that
are more inclusive and equitable.
</p>
</div>
</dd>
<dt><a name="item91">[91]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03570" title="Abstract">arXiv:2311.03570</a> [<a href="/pdf/2311.03570" title="Download PDF">pdf</a>, <a href="/format/2311.03570" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Cal-DETR: Calibrated Detection Transformer
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Munir%2C+M+A">Muhammad Akhtar Munir</a>, 
<a href="/search/cs?searchtype=author&query=Khan%2C+S">Salman Khan</a>, 
<a href="/search/cs?searchtype=author&query=Khan%2C+M+H">Muhammad Haris Khan</a>, 
<a href="/search/cs?searchtype=author&query=Ali%2C+M">Mohsen Ali</a>, 
<a href="/search/cs?searchtype=author&query=Khan%2C+F+S">Fahad Shahbaz Khan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Albeit revealing impressive predictive performance for several computer
vision tasks, deep neural networks (DNNs) are prone to making overconfident
predictions. This limits the adoption and wider utilization of DNNs in many
safety-critical applications. There have been recent efforts toward calibrating
DNNs, however, almost all of them focus on the classification task.
Surprisingly, very little attention has been devoted to calibrating modern
DNN-based object detectors, especially detection transformers, which have
recently demonstrated promising detection performance and are influential in
many decision-making systems. In this work, we address the problem by proposing
a mechanism for calibrated detection transformers (Cal-DETR), particularly for
Deformable-DETR, UP-DETR and DINO. We pursue the train-time calibration route
and make the following contributions. First, we propose a simple yet effective
approach for quantifying uncertainty in transformer-based object detectors.
Second, we develop an uncertainty-guided logit modulation mechanism that
leverages the uncertainty to modulate the class logits. Third, we develop a
logit mixing approach that acts as a regularizer with detection-specific losses
and is also complementary to the uncertainty-guided logit modulation technique
to further improve the calibration performance. Lastly, we conduct extensive
experiments across three in-domain and four out-domain scenarios. Results
corroborate the effectiveness of Cal-DETR against the competing train-time
methods in calibrating both in-domain and out-domain detections while
maintaining or even improving the detection performance. Our codebase and
pre-trained models can be accessed at
\url{https://github.com/akhtarvision/cal-detr}.
</p>
</div>
</dd>
<dt><a name="item92">[92]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03572" title="Abstract">arXiv:2311.03572</a> [<a href="/pdf/2311.03572" title="Download PDF">pdf</a>, <a href="/format/2311.03572" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Unsupervised Region-Growing Network for Object Segmentation in  Atmospheric Turbulence
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Qin%2C+D">Dehao Qin</a>, 
<a href="/search/cs?searchtype=author&query=Saha%2C+R">Ripon Saha</a>, 
<a href="/search/cs?searchtype=author&query=Jayasuriya%2C+S">Suren Jayasuriya</a>, 
<a href="/search/cs?searchtype=author&query=Ye%2C+J">Jinwei Ye</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+N">Nianyi Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages, 4 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">In this paper, we present a two-stage unsupervised foreground object
segmentation network tailored for dynamic scenes affected by atmospheric
turbulence. In the first stage, we utilize averaged optical flow from
turbulence-distorted image sequences to feed a novel region-growing algorithm,
crafting preliminary masks for each moving object in the video. In the second
stage, we employ a U-Net architecture with consistency and grouping losses to
further refine these masks optimizing their spatio-temporal alignment. Our
approach does not require labeled training data and works across varied
turbulence strengths for long-range video. Furthermore, we release the first
moving object segmentation dataset of turbulence-affected videos, complete with
manually annotated ground truth masks. Our method, evaluated on this new
dataset, demonstrates superior segmentation accuracy and robustness as compared
to current state-of-the-art unsupervised methods.
</p>
</div>
</dd>
<dt><a name="item93">[93]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03573" title="Abstract">arXiv:2311.03573</a> [<a href="/pdf/2311.03573" title="Download PDF">pdf</a>, <a href="/ps/2311.03573" title="Download PostScript">ps</a>, <a href="/format/2311.03573" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DonationChain: A New Platform for Blockchain-Based Donation-Tracking  System
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nari%2C+C">Chaimaa Nari</a>, 
<a href="/search/cs?searchtype=author&query=Cicio%C4%9Flu%2C+M">Murtaza Cicio&#x11f;lu</a>, 
<a href="/search/cs?searchtype=author&query=%C3%87alhan%2C+A">Ali &#xc7;alhan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">A donation-tracking system using smart contracts and blockchain technology
has the potential to revolutionize the way charitable giving is tracked and
managed. This article explores how smart contracts and blockchain can be used
to create a transparent and secure ledger for tracking charitable donations. We
discuss the limitations of traditional donation systems and how a
blockchain-based system can help overcome these challenges. We describe how
smart contracts work, how they can be used in donation tracking, and the
benefits they offer, including automated processes, reduced transaction fees,
and increased accountability. We also discuss how blockchain technology
provides a decentralized and tamper-proof ledger that can increase transparency
and help prevent fraud. Finally, we examine some of the challenges that must be
addressed when implementing a smart contract-based donation tracking system,
such as the need for technical expertise and the potential for security
breaches. Overall, a donation-tracking system using smart contracts and
blockchain has the potential to increase trust and accountability in the
donation process, which can ultimately help ensure that donations are used for
their intended purposes.
</p>
</div>
</dd>
<dt><a name="item94">[94]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03574" title="Abstract">arXiv:2311.03574</a> [<a href="/pdf/2311.03574" title="Download PDF">pdf</a>, <a href="/ps/2311.03574" title="Download PostScript">ps</a>, <a href="/format/2311.03574" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fuzzy Relational Databases via Associative Arrays
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Min%2C+K">Kevin Min</a>, 
<a href="/search/cs?searchtype=author&query=Jananthan%2C+H">Hayden Jananthan</a>, 
<a href="/search/cs?searchtype=author&query=Kepner%2C+J">Jeremy Kepner</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages, accepted to IEEE URTC 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Databases (cs.DB)</span>

</div>
<p class="mathjax">The increasing rise in artificial intelligence has made the use of imprecise
language in computer programs like ChatGPT more prominent. Fuzzy logic
addresses this form of imprecise language by introducing the concept of fuzzy
sets, where elements belong to the set with a certain membership value (called
the fuzzy value). This paper combines fuzzy data with relational algebra to
provide the mathematical foundation for a fuzzy database querying language,
describing various useful operations in the language of linear algebra and
multiset operations, in addition to rigorously proving key identities.
</p>
</div>
</dd>
<dt><a name="item95">[95]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03579" title="Abstract">arXiv:2311.03579</a> [<a href="/pdf/2311.03579" title="Download PDF">pdf</a>, <a href="/ps/2311.03579" title="Download PostScript">ps</a>, <a href="/format/2311.03579" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Downlink Rate Maximization with Reconfigurable Intelligent Surface  Assisted Full-Duplex Transmissions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shen%2C+L">Li-Hsiang Shen</a>, 
<a href="/search/cs?searchtype=author&query=Ku%2C+C">Chia-Jou Ku</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+K">Kai-Ten Feng</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: substantial text overlap with <a href="/abs/2306.05693">arXiv:2306.05693</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Systems and Control (eess.SY)

</div>
<p class="mathjax">Reconfigurable intelligent surfaces (RIS) as an effective technique for
intelligently manipulating channel paths through reflection to serve desired
users. Full-duplex (FD) systems, enabling simultaneous transmission and
reception from a base station (BS), offer the theoretical advantage of doubled
spectrum efficiency. However, the presence of strong self-interference (SI) in
FD systems significantly degrades performance, which can be mitigated by
leveraging the capabilities of RIS. In this work, we consider joint BS and RIS
beamforming for maximizing the downlink (DL) transmission rate while
guaranteeing uplink (UL) rate requirement. We propose an FD-RIS beamforming
(FRIS) scheme by adopting penalty convex-concave programming. Simulation
results demonstrate the UL/DL rate improvements achieved by considering various
levels of imperfect CSI. The proposed FRIS scheme validates their effectiveness
across different RIS deployments and RIS/BS configurations. FRIS has achieved
the highest rate compared to the other approximation method, conventional
beamforming techniques, HD systems, and deployment without RIS.
</p>
</div>
</dd>
<dt><a name="item96">[96]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03581" title="Abstract">arXiv:2311.03581</a> [<a href="/pdf/2311.03581" title="Download PDF">pdf</a>, <a href="/format/2311.03581" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Numerical schemes for coupled systems of nonconservative hyperbolic  equations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Kolbe%2C+N">Niklas Kolbe</a>, 
<a href="/search/math?searchtype=author&query=Herty%2C+M">Michael Herty</a>, 
<a href="/search/math?searchtype=author&query=M%C3%BCller%2C+S">Siegfried M&#xfc;ller</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 27 pages, 4 figures, 2 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">A new linear relaxation system for nonconservative hyperbolic systems is
introduced, in which a nonlocal source term accounts for the nonconservative
product of the original system. Using an asymptotic analysis the relaxation
limit and its stability are investigated. It is shown that the
path-conservative Lax-Friedrichs scheme arises from a discrete limit of an
implicit-explicit scheme for the relaxation system. The relaxation approach is
further employed to couple two nonconservative systems at a static interface. A
coupling strategy motivated from conservative Kirchhoff conditions is
introduced and a corresponding Riemann solver provided. A fully discrete scheme
for coupled nonconservative products is derived and studied in terms of
path-conservation. Numerical experiments applying the approach to a coupled
model of vascular blood flow are presented.
</p>
</div>
</dd>
<dt><a name="item97">[97]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03583" title="Abstract">arXiv:2311.03583</a> [<a href="/pdf/2311.03583" title="Download PDF">pdf</a>, <a href="/format/2311.03583" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Finding Increasingly Large Extremal Graphs with AlphaZero and Tabu  Search
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mehrabian%2C+A">Abbas Mehrabian</a>, 
<a href="/search/cs?searchtype=author&query=Anand%2C+A">Ankit Anand</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+H">Hyunjik Kim</a>, 
<a href="/search/cs?searchtype=author&query=Sonnerat%2C+N">Nicolas Sonnerat</a>, 
<a href="/search/cs?searchtype=author&query=Balog%2C+M">Matej Balog</a>, 
<a href="/search/cs?searchtype=author&query=Comanici%2C+G">Gheorghe Comanici</a>, 
<a href="/search/cs?searchtype=author&query=Berariu%2C+T">Tudor Berariu</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+A">Andrew Lee</a>, 
<a href="/search/cs?searchtype=author&query=Ruoss%2C+A">Anian Ruoss</a>, 
<a href="/search/cs?searchtype=author&query=Bulanova%2C+A">Anna Bulanova</a>, 
<a href="/search/cs?searchtype=author&query=Toyama%2C+D">Daniel Toyama</a>, 
<a href="/search/cs?searchtype=author&query=Blackwell%2C+S">Sam Blackwell</a>, 
<a href="/search/cs?searchtype=author&query=Paredes%2C+B+R">Bernardino Romera Paredes</a>, 
<a href="/search/cs?searchtype=author&query=Veli%C4%8Dkovi%C4%87%2C+P">Petar Veli&#x10d;kovi&#x107;</a>, 
<a href="/search/cs?searchtype=author&query=Orseau%2C+L">Laurent Orseau</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+J">Joonkyung Lee</a>, 
<a href="/search/cs?searchtype=author&query=Naredla%2C+A+M">Anurag Murty Naredla</a>, 
<a href="/search/cs?searchtype=author&query=Precup%2C+D">Doina Precup</a>, 
<a href="/search/cs?searchtype=author&query=Wagner%2C+A+Z">Adam Zsolt Wagner</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at MATH AI workshop at NeurIPS 2023, First three authors contributed equally, Last two authors have equal senior contribution
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Discrete Mathematics (cs.DM); Machine Learning (cs.LG)

</div>
<p class="mathjax">This work studies a central extremal graph theory problem inspired by a 1975
conjecture of Erd\H{o}s, which aims to find graphs with a given size (number of
nodes) that maximize the number of edges without having 3- or 4-cycles. We
formulate this problem as a sequential decision-making problem and compare
AlphaZero, a neural network-guided tree search, with tabu search, a heuristic
local search method. Using either method, by introducing a curriculum --
jump-starting the search for larger graphs using good graphs found at smaller
sizes -- we improve the state-of-the-art lower bounds for several sizes. We
also propose a flexible graph-generation environment and a
permutation-invariant network architecture for learning to search in the space
of graphs.
</p>
</div>
</dd>
<dt><a name="item98">[98]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03584" title="Abstract">arXiv:2311.03584</a> [<a href="/pdf/2311.03584" title="Download PDF">pdf</a>, <a href="/format/2311.03584" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Dimensions of Online Conflict: Towards Modeling Agonism
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Canute%2C+M">Matt Canute</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+M">Mali Jin</a>, 
<a href="/search/cs?searchtype=author&query=holtzclaw%2C+h">hannah holtzclaw</a>, 
<a href="/search/cs?searchtype=author&query=Lusoli%2C+A">Alberto Lusoli</a>, 
<a href="/search/cs?searchtype=author&query=Adams%2C+P+R">Philippa R Adams</a>, 
<a href="/search/cs?searchtype=author&query=Pandya%2C+M">Mugdha Pandya</a>, 
<a href="/search/cs?searchtype=author&query=Taboada%2C+M">Maite Taboada</a>, 
<a href="/search/cs?searchtype=author&query=Maynard%2C+D">Diana Maynard</a>, 
<a href="/search/cs?searchtype=author&query=Chun%2C+W+H+K">Wendy Hui Kyong Chun</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To appear
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> "Findings of the 2023 Conference on Empirical Methods in Natural
  Language Processing (EMNLP)". Singapore. December 6-10, 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Agonism plays a vital role in democratic dialogue by fostering diverse
perspectives and robust discussions. Within the realm of online conflict there
is another type: hateful antagonism, which undermines constructive dialogue.
Detecting conflict online is central to platform moderation and monetization.
It is also vital for democratic dialogue, but only when it takes the form of
agonism. To model these two types of conflict, we collected Twitter
conversations related to trending controversial topics. We introduce a
comprehensive annotation schema for labelling different dimensions of conflict
in the conversations, such as the source of conflict, the target, and the
rhetorical strategies deployed. Using this schema, we annotated approximately
4,000 conversations with multiple labels. We then trained both logistic
regression and transformer-based models on the dataset, incorporating context
from the conversation, including the number of participants and the structure
of the interactions. Results show that contextual labels are helpful in
identifying conflict and make the models robust to variations in topic. Our
research contributes a conceptualization of different dimensions of conflict, a
richly annotated dataset, and promising results that can contribute to content
moderation.
</p>
</div>
</dd>
<dt><a name="item99">[99]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03585" title="Abstract">arXiv:2311.03585</a> [<a href="/pdf/2311.03585" title="Download PDF">pdf</a>, <a href="/ps/2311.03585" title="Download PostScript">ps</a>, <a href="/format/2311.03585" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> OpenBSD formal driver verification with SeL4
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nicolae%2C+A">Adriana Nicolae</a>, 
<a href="/search/cs?searchtype=author&query=Irofti%2C+P">Paul Irofti</a>, 
<a href="/search/cs?searchtype=author&query=Leustean%2C+I">Ioana Leustean</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Logic in Computer Science (cs.LO); Operating Systems (cs.OS)

</div>
<p class="mathjax">The seL4 microkernel is currently the only kernel that has been fully
formally verified. In general, the increased interest in ensuring the security
of a kernel's code results from its important role in the entire operating
system. One of the basic features of an operating system is that it abstracts
the handling of devices. This abstraction is represented by device drivers -
the software that manages the hardware. A proper verification of the software
component could ensure that the device would work properly unless there is a
hardware failure.In this paper, we choose to model the behavior of a device
driver and build the proof that the code implementation matches the expected
behavior. The proof was written in Isabelle/HOL, the code translation from C to
Isabelle was done automatically by the use of the C-to-Isabelle Parser and
AutoCorres tools. We choose Isabelle theorem prover because its efficiency was
already shown through the verification of seL4 microkernel.
</p>
</div>
</dd>
<dt><a name="item100">[100]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03588" title="Abstract">arXiv:2311.03588</a> [<a href="/pdf/2311.03588" title="Download PDF">pdf</a>, <a href="/ps/2311.03588" title="Download PostScript">ps</a>, <a href="/format/2311.03588" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Pinky: A Modern Malware-oriented Dynamic Information Retrieval Tool
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Irofti%2C+P">Paul Irofti</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Operating Systems (cs.OS); Software Engineering (cs.SE)

</div>
<p class="mathjax">We present here a reverse engineering tool that can be used for information
retrieval and anti-malware techniques. Our main contribution is the design and
implementation of an instrumentation framework aimed at providing insight on
the emulation process. Sample emulation is achieved via translation of the
binary code to an intermediate representation followed by compilation and
execution. The design makes this a versatile tool that can be used for multiple
task such as information retrieval, reverse engineering, debugging, and
integration with anti-malware products.
</p>
</div>
</dd>
<dt><a name="item101">[101]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03592" title="Abstract">arXiv:2311.03592</a> [<a href="/pdf/2311.03592" title="Download PDF">pdf</a>, <a href="/format/2311.03592" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Sketching methods with small window guarantee using minimum decycling  sets
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mar%C3%A7ais%2C+G">Guillaume Mar&#xe7;ais</a>, 
<a href="/search/cs?searchtype=author&query=DeBlasio%2C+D">Dan DeBlasio</a>, 
<a href="/search/cs?searchtype=author&query=Kingsford%2C+C">Carl Kingsford</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Code available at <a href="https://github.com/Kingsford-Group/mdsscope">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>; Genomics (q-bio.GN)

</div>
<p class="mathjax">Most sequence sketching methods work by selecting specific $k$-mers from
sequences so that the similarity between two sequences can be estimated using
only the sketches. Estimating sequence similarity is much faster using sketches
than using sequence alignment, hence sketching methods are used to reduce the
computational requirements of computational biology software packages.
Applications using sketches often rely on properties of the $k$-mer selection
procedure to ensure that using a sketch does not degrade the quality of the
results compared with using sequence alignment. In particular the window
guarantee ensures that no long region of the sequence goes unrepresented in the
sketch.
<br />A sketching method with a window guarantee corresponds to a Decycling Set,
aka an unavoidable sets of $k$-mers. Any long enough sequence must contain a
$k$-mer from any decycling set (hence, it is unavoidable). Conversely, a
decycling set defines a sketching method by selecting the $k$-mers from the
set. Although current methods use one of a small number of sketching method
families, the space of decycling sets is much larger, and largely unexplored.
Finding decycling sets with desirable characteristics is a promising approach
to discovering new sketching methods with improved performance (e.g., with
small window guarantee).
<br />The Minimum Decycling Sets (MDSs) are of particular interest because of their
small size. Only two algorithms, by Mykkeltveit and Champarnaud, are known to
generate two particular MDSs, although there is a vast number of alternative
MDSs. We provide a simple method that allows one to explore the space of MDSs
and to find sets optimized for desirable properties. We give evidence that the
Mykkeltveit sets are close to optimal regarding one particular property, the
remaining path length.
</p>
</div>
</dd>
<dt><a name="item102">[102]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03600" title="Abstract">arXiv:2311.03600</a> [<a href="/pdf/2311.03600" title="Download PDF">pdf</a>, <a href="/format/2311.03600" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Scalable and Efficient Continual Learning from Demonstration via  Hypernetwork-generated Stable Dynamics Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Auddy%2C+S">Sayantan Auddy</a>, 
<a href="/search/cs?searchtype=author&query=Hollenstein%2C+J">Jakob Hollenstein</a>, 
<a href="/search/cs?searchtype=author&query=Saveriano%2C+M">Matteo Saveriano</a>, 
<a href="/search/cs?searchtype=author&query=Rodr%C3%ADguez-S%C3%A1nchez%2C+A">Antonio Rodr&#xed;guez-S&#xe1;nchez</a>, 
<a href="/search/cs?searchtype=author&query=Piater%2C+J">Justus Piater</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This paper is currently under internal review
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Learning from demonstration (LfD) provides an efficient way to train robots.
The learned motions should be convergent and stable, but to be truly effective
in the real world, LfD-capable robots should also be able to remember multiple
motion skills. Multi-skill retention is a capability missing from existing
stable-LfD approaches. On the other hand, recent work on continual-LfD has
shown that hypernetwork-generated neural ordinary differential equation
solvers, can learn multiple LfD tasks sequentially, but this approach lacks
stability guarantees. We propose an approach for stable continual-LfD in which
a hypernetwork generates two networks: a trajectory learning dynamics model,
and a trajectory stabilizing Lyapunov function. The introduction of stability
not only generates stable trajectories but also greatly improves continual
learning performance, especially in the size-efficient chunked hypernetworks.
With our approach, we can continually train a single model to predict the
position and orientation trajectories of the robot's end-effector
simultaneously for multiple real world tasks without retraining on past
demonstrations. We also propose stochastic regularization with a single
randomly sampled regularization term in hypernetworks, which reduces the
cumulative training time cost for $N$ tasks from $\mathcal{O}(N^2)$ to
$\mathcal{O}(N)$ without any loss in performance in real-world tasks. We
empirically evaluate our approach on the popular LASA dataset, on
high-dimensional extensions of LASA (including up to 32 dimensions) to assess
scalability, and on a novel extended robotic task dataset (RoboTasks9) to
assess real-world performance. In trajectory error metrics, stability metrics
and continual learning metrics our approach performs favorably, compared to
other baselines. Code and datasets will be shared after submission.
</p>
</div>
</dd>
<dt><a name="item103">[103]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03606" title="Abstract">arXiv:2311.03606</a> [<a href="/pdf/2311.03606" title="Download PDF">pdf</a>, <a href="/format/2311.03606" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multimodal Stress Detection Using Facial Landmarks and Biometric Signals
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hosseini%2C+M">Majid Hosseini</a>, 
<a href="/search/cs?searchtype=author&query=Bodaghi%2C+M">Morteza Bodaghi</a>, 
<a href="/search/cs?searchtype=author&query=Bhupatiraju%2C+R+T">Ravi Teja Bhupatiraju</a>, 
<a href="/search/cs?searchtype=author&query=Maida%2C+A">Anthony Maida</a>, 
<a href="/search/cs?searchtype=author&query=Gottumukkala%2C+R">Raju Gottumukkala</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 pages, 8 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">The development of various sensing technologies is improving measurements of
stress and the well-being of individuals. Although progress has been made with
single signal modalities like wearables and facial emotion recognition,
integrating multiple modalities provides a more comprehensive understanding of
stress, given that stress manifests differently across different people.
Multi-modal learning aims to capitalize on the strength of each modality rather
than relying on a single signal. Given the complexity of processing and
integrating high-dimensional data from limited subjects, more research is
needed. Numerous research efforts have been focused on fusing stress and
emotion signals at an early stage, e.g., feature-level fusion using basic
machine learning methods and 1D-CNN Methods. This paper proposes a multi-modal
learning approach for stress detection that integrates facial landmarks and
biometric signals. We test this multi-modal integration with various
early-fusion and late-fusion techniques to integrate the 1D-CNN model from
biometric signals and 2-D CNN using facial landmarks. We evaluate these
architectures using a rigorous test of models' generalizability using the
leave-one-subject-out mechanism, i.e., all samples related to a single subject
are left out to train the model. Our findings show that late-fusion achieved
94.39\% accuracy, and early-fusion surpassed it with a 98.38\% accuracy rate.
This research contributes valuable insights into enhancing stress detection
through a multi-modal approach. The proposed research offers important
knowledge in improving stress detection using a multi-modal approach.
</p>
</div>
</dd>
<dt><a name="item104">[104]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03608" title="Abstract">arXiv:2311.03608</a> [<a href="/pdf/2311.03608" title="Download PDF">pdf</a>, <a href="/format/2311.03608" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Implicit Knowledge in Unawareness Structures
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Belardinelli%2C+G">Gaia Belardinelli</a>, 
<a href="/search/cs?searchtype=author&query=Schipper%2C+B+C">Burkhard C. Schipper</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 45 pages. arXiv admin note: substantial text overlap with <a href="/abs/2307.05041">arXiv:2307.05041</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>; Computer Science and Game Theory (cs.GT)

</div>
<p class="mathjax">Awareness structures by Fagin and Halpern (1988) (FH) feature a syntactic
awareness correspondence and accessibility relations modeling implicit
knowledge. They are a flexible model of unawareness, and best interpreted from
a outside modeler's perspective. Unawareness structures by Heifetz, Meier, and
Schipper (2006, 2008) (HMS) model awareness by a lattice of state spaces and
explicit knowledge via possibility correspondences. Sublattices thereof can be
interpreted as subjective views of agents. Open questions include (1) how
implicit knowledge can be defined in HMS structures, and (2) in which way FH
structures can be extended to model the agents' subjective views. In this
paper, we address (1) by defining implicit knowledge such that it is consistent
with explicit knowledge in HMS models. We also introduce a variant of HMS
models that instead of explicit knowledge, takes implicit knowledge and
awareness as primitives. Further, we address (2) by introducing a category of
FH models that are modally equivalent relative to sublanguages and can be
interpreted as agents' subjective views depending on their awareness. These
constructions allow us to show an equivalence between HMS and FH models. As a
corollary, we obtain soundness and completeness of HMS models with respect to
the Logic of Propositional Awareness, based on a language featuring both
implicit and explicit knowledge.
</p>
</div>
</dd>
<dt><a name="item105">[105]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03609" title="Abstract">arXiv:2311.03609</a> [<a href="/pdf/2311.03609" title="Download PDF">pdf</a>, <a href="/format/2311.03609" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Testing RadiX-Nets: Advances in Viable Sparse Topologies
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kwak%2C+K">Kevin Kwak</a>, 
<a href="/search/cs?searchtype=author&query=West%2C+Z">Zack West</a>, 
<a href="/search/cs?searchtype=author&query=Jananthan%2C+H">Hayden Jananthan</a>, 
<a href="/search/cs?searchtype=author&query=Kepner%2C+J">Jeremy Kepner</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages, 8 figures, accepted to IEEE URTC 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">The exponential growth of data has sparked computational demands on ML
research and industry use. Sparsification of hyper-parametrized deep neural
networks (DNNs) creates simpler representations of complex data. Past research
has shown that some sparse networks achieve similar performance as dense ones,
reducing runtime and storage. RadiX-Nets, a subgroup of sparse DNNs, maintain
uniformity which counteracts their lack of neural connections. Generation,
independent of a dense network, yields faster asymptotic training and removes
the need for costly pruning. However, little work has been done on RadiX-Nets,
making testing challenging. This paper presents a testing suite for RadiX-Nets
in TensorFlow. We test RadiX-Net performance to streamline processing in
scalable models, revealing relationships between network topology,
initialization, and training behavior. We also encounter "strange models" that
train inconsistently and to lower accuracy while models of similar sparsity
train well.
</p>
</div>
</dd>
<dt><a name="item106">[106]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03611" title="Abstract">arXiv:2311.03611</a> [<a href="/pdf/2311.03611" title="Download PDF">pdf</a>, <a href="/format/2311.03611" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Plug-and-Play Stability for Intracortical Brain-Computer Interfaces: A  One-Year Demonstration of Seamless Brain-to-Text Communication
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fan%2C+C">Chaofei Fan</a>, 
<a href="/search/cs?searchtype=author&query=Hahn%2C+N">Nick Hahn</a>, 
<a href="/search/cs?searchtype=author&query=Kamdar%2C+F">Foram Kamdar</a>, 
<a href="/search/cs?searchtype=author&query=Avansino%2C+D">Donald Avansino</a>, 
<a href="/search/cs?searchtype=author&query=Wilson%2C+G+H">Guy H. Wilson</a>, 
<a href="/search/cs?searchtype=author&query=Hochberg%2C+L">Leigh Hochberg</a>, 
<a href="/search/cs?searchtype=author&query=Shenoy%2C+K+V">Krishna V. Shenoy</a>, 
<a href="/search/cs?searchtype=author&query=Henderson%2C+J+M">Jaimie M. Henderson</a>, 
<a href="/search/cs?searchtype=author&query=Willett%2C+F+R">Francis R. Willett</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Machine Learning (cs.LG); Neurons and Cognition (q-bio.NC)

</div>
<p class="mathjax">Intracortical brain-computer interfaces (iBCIs) have shown promise for
restoring rapid communication to people with neurological disorders such as
amyotrophic lateral sclerosis (ALS). However, to maintain high performance over
time, iBCIs typically need frequent recalibration to combat changes in the
neural recordings that accrue over days. This requires iBCI users to stop using
the iBCI and engage in supervised data collection, making the iBCI system hard
to use. In this paper, we propose a method that enables self-recalibration of
communication iBCIs without interrupting the user. Our method leverages large
language models (LMs) to automatically correct errors in iBCI outputs. The
self-recalibration process uses these corrected outputs ("pseudo-labels") to
continually update the iBCI decoder online. Over a period of more than one year
(403 days), we evaluated our Continual Online Recalibration with Pseudo-labels
(CORP) framework with one clinical trial participant. CORP achieved a stable
decoding accuracy of 93.84% in an online handwriting iBCI task, significantly
outperforming other baseline methods. Notably, this is the longest-running iBCI
stability demonstration involving a human participant. Our results provide the
first evidence for long-term stabilization of a plug-and-play, high-performance
communication iBCI, addressing a major barrier for the clinical translation of
iBCIs.
</p>
</div>
</dd>
<dt><a name="item107">[107]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03612" title="Abstract">arXiv:2311.03612</a> [<a href="/pdf/2311.03612" title="Download PDF">pdf</a>, <a href="/format/2311.03612" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> BlockEmulator: An Emulator Enabling to Test Blockchain Sharding  Protocols
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+H">Huawei Huang</a>, 
<a href="/search/cs?searchtype=author&query=Ye%2C+G">Guang Ye</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Q">Qinde Chen</a>, 
<a href="/search/cs?searchtype=author&query=Yin%2C+Z">Zhaokang Yin</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+X">Xiaofei Luo</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+J">Jianru Lin</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Q">Qinglin Yang</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+Z">Zibin Zheng</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Distributed, Parallel, and Cluster Computing (cs.DC)

</div>
<p class="mathjax">Numerous blockchain simulators have been proposed to allow researchers to
simulate mainstream blockchains. However, we have not yet found a testbed that
enables researchers to develop and evaluate their new consensus algorithms or
new protocols for blockchain sharding systems. To fill this gap, we develop
BlockEmulator, which is designed as an experimental platform, particularly for
emulating blockchain sharding mechanisms. BlockEmulator adopts a lightweight
blockchain architecture such that developers can only focus on implementing
their new protocols or mechanisms. Using layered modules and useful programming
interfaces offered by BlockEmulator, researchers can implement a new protocol
with minimum effort. Through experiments, we test various functionalities of
BlockEmulator in two steps. Firstly, we prove the correctness of the emulation
results yielded by BlockEmulator by comparing the theoretical analysis with the
observed experiment results. Secondly, other experimental results demonstrate
that BlockEmulator can facilitate the measurement of a series of metrics,
including throughput, transaction confirmation latency, cross-shard transaction
ratio, the queuing size of transaction pools, workload distribution across
blockchain shards, etc. We have made BlockEmulator open-source in Github.
</p>
</div>
</dd>
<dt><a name="item108">[108]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03614" title="Abstract">arXiv:2311.03614</a> [<a href="/pdf/2311.03614" title="Download PDF">pdf</a>, <a href="/format/2311.03614" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> STONYBOOK: A System and Resource for Large-Scale Analysis of Novels
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pethe%2C+C">Charuta Pethe</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+A">Allen Kim</a>, 
<a href="/search/cs?searchtype=author&query=Prabhakar%2C+R">Rajesh Prabhakar</a>, 
<a href="/search/cs?searchtype=author&query=Pial%2C+T">Tanzir Pial</a>, 
<a href="/search/cs?searchtype=author&query=Skiena%2C+S">Steven Skiena</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 12 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Books have historically been the primary mechanism through which narratives
are transmitted. We have developed a collection of resources for the
large-scale analysis of novels, including: (1) an open source end-to-end NLP
analysis pipeline for the annotation of novels into a standard XML format, (2)
a collection of 49,207 distinct cleaned and annotated novels, and (3) a
database with an associated web interface for the large-scale aggregate
analysis of these literary works. We describe the major functionalities
provided in the annotation system along with their utilities. We present
samples of analysis artifacts from our website, such as visualizations of
character occurrences and interactions, similar books, representative
vocabulary, part of speech statistics, and readability metrics. We also
describe the use of the annotated format in qualitative and quantitative
analysis across large corpora of novels.
</p>
</div>
</dd>
<dt><a name="item109">[109]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03615" title="Abstract">arXiv:2311.03615</a> [<a href="/pdf/2311.03615" title="Download PDF">pdf</a>, <a href="/format/2311.03615" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CAFE: Carbon-Aware Federated Learning in Geographically Distributed Data  Centers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bian%2C+J">Jieming Bian</a>, 
<a href="/search/cs?searchtype=author&query=Ren%2C+S">Shaolei Ren</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+J">Jie Xu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Preprint
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Distributed, Parallel, and Cluster Computing (cs.DC)

</div>
<p class="mathjax">Training large-scale artificial intelligence (AI) models demands significant
computational power and energy, leading to increased carbon footprint with
potential environmental repercussions. This paper delves into the challenges of
training AI models across geographically distributed (geo-distributed) data
centers, emphasizing the balance between learning performance and carbon
footprint. We consider Federated Learning (FL) as a solution, which prioritizes
model parameter exchange over raw data, ensuring data privacy and compliance
with local regulations. Given the variability in carbon intensity across
regions, we propose a new framework called CAFE (short for Carbon-Aware
Federated Learning) to optimize training within a fixed carbon footprint
budget. Our approach incorporates coreset selection to assess learning
performance, employs the Lyapunov drift-plus-penalty framework to address the
unpredictability of future carbon intensity, and devises an efficient algorithm
to address the combinatorial complexity of the data center selection. Through
extensive simulations using real-world carbon intensity data, we demonstrate
the efficacy of our algorithm, highlighting its superiority over existing
methods in optimizing learning performance while minimizing environmental
impact.
</p>
</div>
</dd>
<dt><a name="item110">[110]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03616" title="Abstract">arXiv:2311.03616</a> [<a href="/pdf/2311.03616" title="Download PDF">pdf</a>, <a href="/format/2311.03616" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Governance Capture in a Self-Governing Community: A Qualitative  Comparison of the Serbo-Croatian Wikipedias
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kharazian%2C+Z">Zarine Kharazian</a>, 
<a href="/search/cs?searchtype=author&query=Starbird%2C+K">Kate Starbird</a>, 
<a href="/search/cs?searchtype=author&query=Hill%2C+B+M">Benjamin Mako Hill</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 26 pages, 2 figures. Accepted for publication in Proceedings of the ACM on Human-Computer Interaction (CSCW 2024)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>; Human-Computer Interaction (cs.HC)

</div>
<p class="mathjax">What types of governance arrangements makes some self-governed online groups
more vulnerable to disinformation campaigns? To answer this question, we
present a qualitative comparative analysis of the Croatian and Serbian
Wikipedia editions. We do so because between at least 2011 and 2020, the
Croatian language version of Wikipedia was taken over by a small group of
administrators who introduced far-right bias and outright disinformation;
dissenting editorial voices were reverted, banned, and blocked. Although
Serbian Wikipedia is roughly similar in size and age, shares many linguistic
and cultural features, and faced similar threats, it seems to have largely
avoided this fate. Based on a grounded theory analysis of interviews with
members of both communities and others in cross-functional platform-level
roles, we propose that the convergence of three features -- high perceived
value as a target, limited early bureaucratic openness, and a preference for
personalistic, informal forms of organization over formal ones -- produced a
window of opportunity for governance capture on Croatian Wikipedia. Our
findings illustrate that online community governing infrastructures can play a
crucial role in systematic disinformation campaigns and other influence
operations.
</p>
</div>
</dd>
<dt><a name="item111">[111]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03619" title="Abstract">arXiv:2311.03619</a> [<a href="/pdf/2311.03619" title="Download PDF">pdf</a>, <a href="/ps/2311.03619" title="Download PostScript">ps</a>, <a href="/format/2311.03619" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Construction and Fast Decoding of Binary Linear Sum-Rank-Metric Codes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+H">Hao Chen</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Z">Zhiqiang Chen</a>, 
<a href="/search/cs?searchtype=author&query=Qi%2C+Y">Yanfeng Qi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 37 pages, submitted
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>

</div>
<p class="mathjax">Sum-rank-metric codes have wide applications in the multishot network coding
and the distributed storage. Linearized Reed-Solomon codes, sum-rank BCH codes
and their Welch-Berlekamp type decoding algorithms were proposed and studied.
They are sum-rank versions of Reed-Solomon codes and BCH codes in the Hamming
metric. In this paper, we construct binary linear sum-rank-metric codes of the
matrix size $2 \times 2$, from BCH, Goppa and additive quaternary Hamming
metric codes. Larger sum-rank-metric codes than these sum-rank BCH codes of the
same minimum sum-rank distances are obtained. Then a reduction of the decoding
in the sum-rank-metric to the decoding in the Hamming metric is given. Fast
decoding algorithms of BCH and Goppa type binary linear sum-rank-metric codes
of the block length $t$ and the matrix size $2 \times 2$, which are better than
these sum-rank BCH codes, are presented. These fast decoding algorithms for BCH
and Goppa type binary linear sum-rank-metric codes of the matrix size $2 \times
2$ need at most $O(t^2)$ operations in the field ${\bf F}_4$. Asymptotically
good sequences of quadratic-time encodable and decodable binary linear
sum-rank-metric codes of the matrix size $2 \times 2$ satisfying
$$R_{sr}(\delta_{sr}) \geq
1-\frac{1}{2}(H_4(\frac{4}{3}\delta_{sr})+H_4(2\delta_{sr})),$$ can be
constructed from Goppa codes.
</p>
</div>
</dd>
<dt><a name="item112">[112]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03620" title="Abstract">arXiv:2311.03620</a> [<a href="/pdf/2311.03620" title="Download PDF">pdf</a>, <a href="/format/2311.03620" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FusionViT: Hierarchical 3D Object Detection via LiDAR-Camera Vision  Transformer Fusion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xiang%2C+X">Xinhao Xiang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jiawei Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">For 3D object detection, both camera and lidar have been demonstrated to be
useful sensory devices for providing complementary information about the same
scenery with data representations in different modalities, e.g., 2D RGB image
vs 3D point cloud. An effective representation learning and fusion of such
multi-modal sensor data is necessary and critical for better 3D object
detection performance. To solve the problem, in this paper, we will introduce a
novel vision transformer-based 3D object detection model, namely FusionViT.
Different from the existing 3D object detection approaches, FusionViT is a
pure-ViT based framework, which adopts a hierarchical architecture by extending
the transformer model to embed both images and point clouds for effective
representation learning. Such multi-modal data embedding representations will
be further fused together via a fusion vision transformer model prior to
feeding the learned features to the object detection head for both detection
and localization of the 3D objects in the input scenery. To demonstrate the
effectiveness of FusionViT, extensive experiments have been done on real-world
traffic object detection benchmark datasets KITTI and Waymo Open. Notably, our
FusionViT model can achieve state-of-the-art performance and outperforms not
only the existing baseline methods that merely rely on camera images or lidar
point clouds, but also the latest multi-modal image-point cloud deep fusion
approaches.
</p>
</div>
</dd>
<dt><a name="item113">[113]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03621" title="Abstract">arXiv:2311.03621</a> [<a href="/pdf/2311.03621" title="Download PDF">pdf</a>, <a href="/format/2311.03621" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exploring Latent Spaces of Tonal Music using Variational Autoencoders
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Carvalho%2C+N">N&#xe1;dia Carvalho</a>, 
<a href="/search/cs?searchtype=author&query=Bernardes%2C+G">Gilberto Bernardes</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Machine Learning (cs.LG); Multimedia (cs.MM); Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">Variational Autoencoders (VAEs) have proven to be effective models for
producing latent representations of cognitive and semantic value. We assess the
degree to which VAEs trained on a prototypical tonal music corpus of 371 Bach's
chorales define latent spaces representative of the circle of fifths and the
hierarchical relation of each key component pitch as drawn in music cognition.
In detail, we compare the latent space of different VAE corpus encodings --
Piano roll, MIDI, ABC, Tonnetz, DFT of pitch, and pitch class distributions --
in providing a pitch space for key relations that align with cognitive
distances. We evaluate the model performance of these encodings using objective
metrics to capture accuracy, mean square error (MSE), KL-divergence, and
computational cost. The ABC encoding performs the best in reconstructing the
original data, while the Pitch DFT seems to capture more information from the
latent space. Furthermore, an objective evaluation of 12 major or minor
transpositions per piece is adopted to quantify the alignment of 1) intra- and
inter-segment distances per key and 2) the key distances to cognitive pitch
spaces. Our results show that Pitch DFT VAE latent spaces align best with
cognitive spaces and provide a common-tone space where overlapping objects
within a key are fuzzy clusters, which impose a well-defined order of
structural significance or stability -- i.e., a tonal hierarchy. Tonal
hierarchies of different keys can be used to measure key distances and the
relationships of their in-key components at multiple hierarchies (e.g., notes
and chords). The implementation of our VAE and the encodings framework are made
available online.
</p>
</div>
</dd>
<dt><a name="item114">[114]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03622" title="Abstract">arXiv:2311.03622</a> [<a href="/pdf/2311.03622" title="Download PDF">pdf</a>, <a href="/format/2311.03622" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> TWIST: Teacher-Student World Model Distillation for Efficient  Sim-to-Real Transfer
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yamada%2C+J">Jun Yamada</a>, 
<a href="/search/cs?searchtype=author&query=Rigter%2C+M">Marc Rigter</a>, 
<a href="/search/cs?searchtype=author&query=Collins%2C+J">Jack Collins</a>, 
<a href="/search/cs?searchtype=author&query=Posner%2C+I">Ingmar Posner</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, 6 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
<p class="mathjax">Model-based RL is a promising approach for real-world robotics due to its
improved sample efficiency and generalization capabilities compared to
model-free RL. However, effective model-based RL solutions for vision-based
real-world applications require bridging the sim-to-real gap for any world
model learnt. Due to its significant computational cost, standard domain
randomisation does not provide an effective solution to this problem. This
paper proposes TWIST (Teacher-Student World Model Distillation for Sim-to-Real
Transfer) to achieve efficient sim-to-real transfer of vision-based model-based
RL using distillation. Specifically, TWIST leverages state observations as
readily accessible, privileged information commonly garnered from a simulator
to significantly accelerate sim-to-real transfer. Specifically, a teacher world
model is trained efficiently on state information. At the same time, a matching
dataset is collected of domain-randomised image observations. The teacher world
model then supervises a student world model that takes the domain-randomised
image observations as input. By distilling the learned latent dynamics model
from the teacher to the student model, TWIST achieves efficient and effective
sim-to-real transfer for vision-based model-based RL tasks. Experiments in
simulated and real robotics tasks demonstrate that our approach outperforms
naive domain randomisation and model-free methods in terms of sample efficiency
and task performance of sim-to-real transfer.
</p>
</div>
</dd>
<dt><a name="item115">[115]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03623" title="Abstract">arXiv:2311.03623</a> [<a href="/pdf/2311.03623" title="Download PDF">pdf</a>, <a href="/format/2311.03623" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Stochastic convergence of regularized solutions for backward heat  conduction problems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Wang%2C+Z">Zhongjian Wang</a>, 
<a href="/search/math?searchtype=author&query=Zhang%2C+W">Wenlong Zhang</a>, 
<a href="/search/math?searchtype=author&query=Zhang%2C+Z">Zhiwen Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">In this paper, we study the stochastic convergence of regularized solutions
for backward heat conduction problems. These problems are recognized as
ill-posed due to the exponential decay of eigenvalues associated with the
forward problems. We derive an error estimate for the least-squares regularized
minimization problem within the framework of stochastic convergence. Our
analysis reveals that the optimal error of the Tikhonov-type least-squares
optimization problem depends on the noise level, the number of sensors, and the
underlying ground truth. Moreover, we propose a self-adaptive algorithm to
identify the optimal regularization parameter for the optimization problem
without requiring knowledge of the noise level or any other prior information,
which will be very practical in applications. We present numerical examples to
demonstrate the accuracy and efficiency of our proposed method. These numerical
results show that our method is efficient in solving backward heat conduction
problems.
</p>
</div>
</dd>
<dt><a name="item116">[116]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03624" title="Abstract">arXiv:2311.03624</a> [<a href="/pdf/2311.03624" title="Download PDF">pdf</a>, <a href="/ps/2311.03624" title="Download PostScript">ps</a>, <a href="/format/2311.03624" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Are Words Enough? On the semantic conditioning of affective music  generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Forero%2C+J">Jorge Forero</a>, 
<a href="/search/cs?searchtype=author&query=Bernardes%2C+G">Gilberto Bernardes</a>, 
<a href="/search/cs?searchtype=author&query=Mendes%2C+M">M&#xf3;nica Mendes</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Multimedia (cs.MM)</span>; Machine Learning (cs.LG); Sound (cs.SD); Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">Music has been commonly recognized as a means of expressing emotions. In this
sense, an intense debate emerges from the need to verbalize musical emotions.
This concern seems highly relevant today, considering the exponential growth of
natural language processing using deep learning models where it is possible to
prompt semantic propositions to generate music automatically. This scoping
review aims to analyze and discuss the possibilities of music generation
conditioned by emotions. To address this topic, we propose a historical
perspective that encompasses the different disciplines and methods contributing
to this topic. In detail, we review two main paradigms adopted in automatic
music generation: rules-based and machine-learning models. Of note are the deep
learning architectures that aim to generate high-fidelity music from textual
descriptions. These models raise fundamental questions about the expressivity
of music, including whether emotions can be represented with words or expressed
through them. We conclude that overcoming the limitation and ambiguity of
language to express emotions through music, some of the use of deep learning
with natural language has the potential to impact the creative industries by
providing powerful tools to prompt and generate new musical works.
</p>
</div>
</dd>
<dt><a name="item117">[117]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03626" title="Abstract">arXiv:2311.03626</a> [<a href="/pdf/2311.03626" title="Download PDF">pdf</a>, <a href="/format/2311.03626" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PINNs-TF2: Fast and User-Friendly Physics-Informed Neural Networks in  TensorFlow V2
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bafghi%2C+R+A">Reza Akbarian Bafghi</a>, 
<a href="/search/cs?searchtype=author&query=Raissi%2C+M">Maziar Raissi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at Machine Learning and the Physical Sciences Workshop, NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Engineering, Finance, and Science (cs.CE)</span>

</div>
<p class="mathjax">Physics-informed neural networks (PINNs) have gained prominence for their
capability to tackle supervised learning tasks that conform to physical laws,
notably nonlinear partial differential equations (PDEs). This paper presents
"PINNs-TF2", a Python package built on the TensorFlow V2 framework. It not only
accelerates PINNs implementation but also simplifies user interactions by
abstracting complex PDE challenges. We underscore the pivotal role of compilers
in PINNs, highlighting their ability to boost performance by up to 119x. Across
eight diverse examples, our package, integrated with XLA compilers,
demonstrated its flexibility and achieved an average speed-up of 18.12 times
over TensorFlow V1. Moreover, a real-world case study is implemented to
underscore the compilers' potential to handle many trainable parameters and
large batch sizes. For community engagement and future enhancements, our
package's source code is openly available at:
https://github.com/rezaakb/pinns-tf2.
</p>
</div>
</dd>
<dt><a name="item118">[118]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03627" title="Abstract">arXiv:2311.03627</a> [<a href="/pdf/2311.03627" title="Download PDF">pdf</a>, <a href="/format/2311.03627" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GNAT: A General Narrative Alignment Tool
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pial%2C+T">Tanzir Pial</a>, 
<a href="/search/cs?searchtype=author&query=Skiena%2C+S">Steven Skiena</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 17 pages, 5 figures, 8 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Algorithmic sequence alignment identifies similar segments shared between
pairs of documents, and is fundamental to many NLP tasks. But it is difficult
to recognize similarities between distant versions of narratives such as
translations and retellings, particularly for summaries and abridgements which
are much shorter than the original novels.
<br />We develop a general approach to narrative alignment coupling the
Smith-Waterman algorithm from bioinformatics with modern text similarity
metrics. We show that the background of alignment scores fits a Gumbel
distribution, enabling us to define rigorous p-values on the significance of
any alignment. We apply and evaluate our general narrative alignment tool
(GNAT) on four distinct problem domains differing greatly in both the relative
and absolute length of documents, namely summary-to-book alignment, translated
book alignment, short story alignment, and plagiarism detection --
demonstrating the power and performance of our methods.
</p>
</div>
</dd>
<dt><a name="item119">[119]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03628" title="Abstract">arXiv:2311.03628</a> [<a href="/pdf/2311.03628" title="Download PDF">pdf</a>, <a href="/format/2311.03628" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Reinforcement Twinning: from digital twins to model-based reinforcement  learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Schena%2C+L">Lorenzo Schena</a>, 
<a href="/search/eess?searchtype=author&query=Marques%2C+P">Pedro Marques</a>, 
<a href="/search/eess?searchtype=author&query=Poletti%2C+R">Romain Poletti</a>, 
<a href="/search/eess?searchtype=author&query=Ahizi%2C+S">Samuel Ahizi</a>, 
<a href="/search/eess?searchtype=author&query=Van+den+Berghe%2C+J">Jan Van den Berghe</a>, 
<a href="/search/eess?searchtype=author&query=Mendez%2C+M+A">Miguel A. Mendez</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> submitted Journal of Computational Science
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">We propose a novel framework for simultaneously training the digital twin of
an engineering system and an associated control agent. The training of the twin
combines methods from data assimilation and system identification, while the
training of the control agent combines model-based optimal control and
model-free reinforcement learning. The combined training of the control agent
is achieved by letting it evolve independently along two paths (one driven by a
model-based optimal control and another driven by reinforcement learning) and
using the virtual environment offered by the digital twin as a playground for
confrontation and indirect interaction. This interaction occurs as an "expert
demonstrator", where the best policy is selected for the interaction with the
real environment and "taught" to the other if the independent training
stagnates. We refer to this framework as Reinforcement Twinning (RT). The
framework is tested on three vastly different engineering systems and control
tasks, namely (1) the control of a wind turbine subject to time-varying wind
speed, (2) the trajectory control of flapping-wing micro air vehicles (FWMAVs)
subject to wind gusts, and (3) the mitigation of thermal loads in the
management of cryogenic storage tanks. The test cases are implemented using
simplified models for which the ground truth on the closure law is available.
The results show that the adjoint-based training of the digital twin is
remarkably sample-efficient and completed within a few iterations. Concerning
the control agent training, the results show that the model-based and the
model-free control training benefit from the learning experience and the
complementary learning approach of each other. The encouraging results open the
path towards implementing the RT framework on real systems.
</p>
</div>
</dd>
<dt><a name="item120">[120]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03629" title="Abstract">arXiv:2311.03629</a> [<a href="/pdf/2311.03629" title="Download PDF">pdf</a>, <a href="/format/2311.03629" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Random Field Augmentations for Self-Supervised Representation Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mansfield%2C+P+A">Philip Andrew Mansfield</a>, 
<a href="/search/cs?searchtype=author&query=Afkanpour%2C+A">Arash Afkanpour</a>, 
<a href="/search/cs?searchtype=author&query=Morningstar%2C+W+R">Warren Richard Morningstar</a>, 
<a href="/search/cs?searchtype=author&query=Singhal%2C+K">Karan Singhal</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Self-supervised representation learning is heavily dependent on data
augmentations to specify the invariances encoded in representations. Previous
work has shown that applying diverse data augmentations is crucial to
downstream performance, but augmentation techniques remain under-explored. In
this work, we propose a new family of local transformations based on Gaussian
random fields to generate image augmentations for self-supervised
representation learning. These transformations generalize the well-established
affine and color transformations (translation, rotation, color jitter, etc.)
and greatly increase the space of augmentations by allowing transformation
parameter values to vary from pixel to pixel. The parameters are treated as
continuous functions of spatial coordinates, and modeled as independent
Gaussian random fields. Empirical results show the effectiveness of the new
transformations for self-supervised representation learning. Specifically, we
achieve a 1.7% top-1 accuracy improvement over baseline on ImageNet downstream
classification, and a 3.6% improvement on out-of-distribution iNaturalist
downstream classification. However, due to the flexibility of the new
transformations, learned representations are sensitive to hyperparameters.
While mild transformations improve representations, we observe that strong
transformations can degrade the structure of an image, indicating that
balancing the diversity and strength of augmentations is important for
improving generalization of learned representations.
</p>
</div>
</dd>
<dt><a name="item121">[121]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03630" title="Abstract">arXiv:2311.03630</a> [<a href="/pdf/2311.03630" title="Download PDF">pdf</a>, <a href="/format/2311.03630" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Counterfactual Data Augmentation with Contrastive Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Aloui%2C+A">Ahmed Aloui</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+J">Juncheng Dong</a>, 
<a href="/search/cs?searchtype=author&query=Le%2C+C+P">Cat P. Le</a>, 
<a href="/search/cs?searchtype=author&query=Tarokh%2C+V">Vahid Tarokh</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Methodology (stat.ME); Machine Learning (stat.ML)

</div>
<p class="mathjax">Statistical disparity between distinct treatment groups is one of the most
significant challenges for estimating Conditional Average Treatment Effects
(CATE). To address this, we introduce a model-agnostic data augmentation method
that imputes the counterfactual outcomes for a selected subset of individuals.
Specifically, we utilize contrastive learning to learn a representation space
and a similarity measure such that in the learned representation space close
individuals identified by the learned similarity measure have similar potential
outcomes. This property ensures reliable imputation of counterfactual outcomes
for the individuals with close neighbors from the alternative treatment group.
By augmenting the original dataset with these reliable imputations, we can
effectively reduce the discrepancy between different treatment groups, while
inducing minimal imputation error. The augmented dataset is subsequently
employed to train CATE estimation models. Theoretical analysis and experimental
studies on synthetic and semi-synthetic benchmarks demonstrate that our method
achieves significant improvements in both performance and robustness to
overfitting across state-of-the-art models.
</p>
</div>
</dd>
<dt><a name="item122">[122]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03631" title="Abstract">arXiv:2311.03631</a> [<a href="/pdf/2311.03631" title="Download PDF">pdf</a>, <a href="/format/2311.03631" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Novel data structures for label based queries specifically efficient for  billion+ property graph networks using Kinetica-Graph
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Karamete%2C+B+K">Bilge Kaan Karamete</a>, 
<a href="/search/cs?searchtype=author&query=Glaser%2C+E">Eli Glaser</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages, 12 figures, 19 references
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>; Databases (cs.DB)

</div>
<p class="mathjax">This paper discusses a novel data structure that efficiently implements label
based graph queries particularly for very large graphs. The major issues in
large graph databases is the memory foot-print of label based property
associations to graph entities and subsequent query speeds. To this end, unlike
the available graph databases, that use key-value pairs using map like
associative containers, we have devised a novel data structure that is superior
in its memory foot-print as well as its fast search characteristics without any
compromise on the number of labels that can be associated to graph nodes and
edges. We will demonstrate the power of this novel unconventional data
structure over billion plus graphs within the context.
</p>
</div>
</dd>
<dt><a name="item123">[123]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03633" title="Abstract">arXiv:2311.03633</a> [<a href="/pdf/2311.03633" title="Download PDF">pdf</a>, <a href="/format/2311.03633" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Innovation and Word Usage Patterns in Machine Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Borges%2C+V+B">V&#xed;tor Bandeira Borges</a>, 
<a href="/search/cs?searchtype=author&query=Cajueiro%2C+D+O">Daniel Oliveira Cajueiro</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computation and Language (cs.CL)

</div>
<p class="mathjax">In this study, we delve into the dynamic landscape of machine learning
research evolution. Initially, through the utilization of Latent Dirichlet
Allocation, we discern pivotal themes and fundamental concepts that have
emerged within the realm of machine learning. Subsequently, we undertake a
comprehensive analysis to track the evolutionary trajectories of these
identified themes. To quantify the novelty and divergence of research
contributions, we employ the Kullback-Leibler Divergence metric. This
statistical measure serves as a proxy for ``surprise'', indicating the extent
of differentiation between the content of academic papers and the subsequent
developments in research. By amalgamating these insights, we gain the ability
to ascertain the pivotal roles played by prominent researchers and the
significance of specific academic venues (periodicals and conferences) within
the machine learning domain.
</p>
</div>
</dd>
<dt><a name="item124">[124]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03636" title="Abstract">arXiv:2311.03636</a> [<a href="/pdf/2311.03636" title="Download PDF">pdf</a>, <a href="/ps/2311.03636" title="Download PostScript">ps</a>, <a href="/format/2311.03636" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Analysis of the User Perception of Chatbots in Education Using A Partial  Least Squares Structural Equation Modeling Approach
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hasan%2C+M+R">Md Rabiul Hasan</a>, 
<a href="/search/cs?searchtype=author&query=Chowdhury%2C+N+I">Nahian Ismail Chowdhury</a>, 
<a href="/search/cs?searchtype=author&query=Rahman%2C+M+H">Md Hadisur Rahman</a>, 
<a href="/search/cs?searchtype=author&query=Syed%2C+M+A+B">Md Asif Bin Syed</a>, 
<a href="/search/cs?searchtype=author&query=Ryu%2C+J">JuHyeong Ryu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Chatbot, ChatGPT, Google BARD, Interactive AI, PLS-SEM, Technology Acceptance Model, Technology Readiness Index
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">The integration of Artificial Intelligence (AI) into education is a recent
development, with chatbots emerging as a noteworthy addition to this
transformative landscape. As online learning platforms rapidly advance,
students need to adapt swiftly to excel in this dynamic environment.
Consequently, understanding the acceptance of chatbots, particularly those
employing Large Language Model (LLM) such as Chat Generative Pretrained
Transformer (ChatGPT), Google Bard, and other interactive AI technologies, is
of paramount importance. However, existing research on chatbots in education
has overlooked key behavior-related aspects, such as Optimism, Innovativeness,
Discomfort, Insecurity, Transparency, Ethics, Interaction, Engagement, and
Accuracy, creating a significant literature gap. To address this gap, this
study employs Partial Least Squares Structural Equation Modeling (PLS-SEM) to
investigate the determinant of chatbots adoption in education among students,
considering the Technology Readiness Index (TRI) and Technology Acceptance
Model (TAM). Utilizing a five-point Likert scale for data collection, we
gathered a total of 185 responses, which were analyzed using R-Studio software.
We established 12 hypotheses to achieve its objectives. The results showed that
Optimism and Innovativeness are positively associated with Perceived Ease of
Use (PEOU) and Perceived Usefulness (PU). Conversely, Discomfort and Insecurity
negatively impact PEOU, with only Insecurity negatively affecting PU. These
findings provide insights for future technology designers, elucidating critical
user behavior factors influencing chatbots adoption and utilization in
educational contexts.
</p>
</div>
</dd>
<dt><a name="item125">[125]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03639" title="Abstract">arXiv:2311.03639</a> [<a href="/pdf/2311.03639" title="Download PDF">pdf</a>, <a href="/format/2311.03639" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Physics-Guided Bi-Fidelity Fourier-Featured Operator Learning  Framework for Predicting Time Evolution of Drag and Lift Coefficients
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mollaali%2C+A">Amirhossein Mollaali</a>, 
<a href="/search/cs?searchtype=author&query=Sahin%2C+I">Izzet Sahin</a>, 
<a href="/search/cs?searchtype=author&query=Raza%2C+I">Iqrar Raza</a>, 
<a href="/search/cs?searchtype=author&query=Moya%2C+C">Christian Moya</a>, 
<a href="/search/cs?searchtype=author&query=Paniagua%2C+G">Guillermo Paniagua</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+G">Guang Lin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 24 pages, 10 figures, 5 tables- submitted to Fluid
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Numerical Analysis (math.NA); Fluid Dynamics (physics.flu-dyn)

</div>
<p class="mathjax">In the pursuit of accurate experimental and computational data while
minimizing effort, there is a constant need for high-fidelity results. However,
achieving such results often requires significant computational resources. To
address this challenge, this paper proposes a deep operator learning-based
framework that requires a limited high-fidelity dataset for training. We
introduce a novel physics-guided, bi-fidelity, Fourier-featured Deep Operator
Network (DeepONet) framework that effectively combines low and high-fidelity
datasets, leveraging the strengths of each. In our methodology, we began by
designing a physics-guided Fourier-featured DeepONet, drawing inspiration from
the intrinsic physical behavior of the target solution. Subsequently, we train
this network to primarily learn the low-fidelity solution, utilizing an
extensive dataset. This process ensures a comprehensive grasp of the
foundational solution patterns. Following this foundational learning, the
low-fidelity deep operator network's output is enhanced using a physics-guided
Fourier-featured residual deep operator network. This network refines the
initial low-fidelity output, achieving the high-fidelity solution by employing
a small high-fidelity dataset for training. Notably, in our framework, we
employ the Fourier feature network as the Trunk network for the DeepONets,
given its proficiency in capturing and learning the oscillatory nature of the
target solution with high precision. We validate our approach using a
well-known 2D benchmark cylinder problem, which aims to predict the time
trajectories of lift and drag coefficients. The results highlight that the
physics-guided Fourier-featured deep operator network, serving as a
foundational building block of our framework, possesses superior predictive
capability for the lift and drag coefficients compared to its data-driven
counterparts.
</p>
</div>
</dd>
<dt><a name="item126">[126]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03645" title="Abstract">arXiv:2311.03645</a> [<a href="/pdf/2311.03645" title="Download PDF">pdf</a>, <a href="/format/2311.03645" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Minimizing Pentagons in the Plane through Automated Reasoning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Subercaseaux%2C+B">Bernardo Subercaseaux</a>, 
<a href="/search/cs?searchtype=author&query=Mackey%2C+J">John Mackey</a>, 
<a href="/search/cs?searchtype=author&query=Heule%2C+M+J+H">Marijn J. H. Heule</a>, 
<a href="/search/cs?searchtype=author&query=Martins%2C+R">Ruben Martins</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Geometry (cs.CG)</span>; Discrete Mathematics (cs.DM)

</div>
<p class="mathjax">We study $\mu_5(n)$, the minimum number of convex pentagons induced by $n$
points in the plane in general position. Despite a significant body of research
in understanding $\mu_4(n)$, the variant concerning convex quadrilaterals, not
much is known about $\mu_5(n)$. We present two explicit constructions, inspired
by point placements obtained through a combination of Stochastic Local Search
and a program for realizability of point sets, that provide $\mu_5(n) \leq
\binom{\lfloor n/2 \rfloor}{5} + \binom{\lceil n/2 \rceil}{5}$. Furthermore, we
conjecture this bound to be optimal, and provide partial evidence by leveraging
a MaxSAT encoding that allows us to verify our conjecture for $n \leq 16$.
</p>
</div>
</dd>
<dt><a name="item127">[127]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03648" title="Abstract">arXiv:2311.03648</a> [<a href="/pdf/2311.03648" title="Download PDF">pdf</a>, <a href="/format/2311.03648" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Instruct Me More! Random Prompting for Visual In-Context Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jiahao Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+B">Bowen Wang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+L">Liangzhi Li</a>, 
<a href="/search/cs?searchtype=author&query=Nakashima%2C+Y">Yuta Nakashima</a>, 
<a href="/search/cs?searchtype=author&query=Nagahara%2C+H">Hajime Nagahara</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at WACV 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Large-scale models trained on extensive datasets, have emerged as the
preferred approach due to their high generalizability across various tasks.
In-context learning (ICL), a popular strategy in natural language processing,
uses such models for different tasks by providing instructive prompts but
without updating model parameters. This idea is now being explored in computer
vision, where an input-output image pair (called an in-context pair) is
supplied to the model with a query image as a prompt to exemplify the desired
output. The efficacy of visual ICL often depends on the quality of the prompts.
We thus introduce a method coined Instruct Me More (InMeMo), which augments
in-context pairs with a learnable perturbation (prompt), to explore its
potential. Our experiments on mainstream tasks reveal that InMeMo surpasses the
current state-of-the-art performance. Specifically, compared to the baseline
without learnable prompt, InMeMo boosts mIoU scores by 7.35 and 15.13 for
foreground segmentation and single object detection tasks, respectively. Our
findings suggest that InMeMo offers a versatile and efficient way to enhance
the performance of visual ICL with lightweight training. Code is available at
https://github.com/Jackieam/InMeMo.
</p>
</div>
</dd>
<dt><a name="item128">[128]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03650" title="Abstract">arXiv:2311.03650</a> [<a href="/pdf/2311.03650" title="Download PDF">pdf</a>, <a href="/format/2311.03650" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Image Generation and Learning Strategy for Deep Document Forgery  Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Okamoto%2C+Y">Yamato Okamoto</a>, 
<a href="/search/cs?searchtype=author&query=Genki%2C+O">Osada Genki</a>, 
<a href="/search/cs?searchtype=author&query=Yahiro%2C+I">Iu Yahiro</a>, 
<a href="/search/cs?searchtype=author&query=Hasegawa%2C+R">Rintaro Hasegawa</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+P">Peifei Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Kataoka%2C+H">Hirokatsu Kataoka</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">In recent years, document processing has flourished and brought numerous
benefits. However, there has been a significant rise in reported cases of
forged document images. Specifically, recent advancements in deep neural
network (DNN) methods for generative tasks may amplify the threat of document
forgery. Traditional approaches for forged document images created by prevalent
copy-move methods are unsuitable against those created by DNN-based methods, as
we have verified. To address this issue, we construct a training dataset of
document forgery images, named FD-VIED, by emulating possible attacks, such as
text addition, removal, and replacement with recent DNN-methods. Additionally,
we introduce an effective pre-training approach through self-supervised
learning with both natural images and document images. In our experiments, we
demonstrate that our approach enhances detection performance.
</p>
</div>
</dd>
<dt><a name="item129">[129]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03651" title="Abstract">arXiv:2311.03651</a> [<a href="/pdf/2311.03651" title="Download PDF">pdf</a>, <a href="/format/2311.03651" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SeRO: Self-Supervised Reinforcement Learning for Recovery from  Out-of-Distribution Situations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kim%2C+C">Chan Kim</a>, 
<a href="/search/cs?searchtype=author&query=Cho%2C+J">Jaekyung Cho</a>, 
<a href="/search/cs?searchtype=author&query=Bobda%2C+C">Christophe Bobda</a>, 
<a href="/search/cs?searchtype=author&query=Seo%2C+S">Seung-Woo Seo</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+S">Seong-Woo Kim</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages, 5 figures. Proceedings of the 32nd International Joint Conference on Artificial Intelligence, 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Robotics (cs.RO)

</div>
<p class="mathjax">Robotic agents trained using reinforcement learning have the problem of
taking unreliable actions in an out-of-distribution (OOD) state. Agents can
easily become OOD in real-world environments because it is almost impossible
for them to visit and learn the entire state space during training.
Unfortunately, unreliable actions do not ensure that agents perform their
original tasks successfully. Therefore, agents should be able to recognize
whether they are in OOD states and learn how to return to the learned state
distribution rather than continue to take unreliable actions. In this study, we
propose a novel method for retraining agents to recover from OOD situations in
a self-supervised manner when they fall into OOD states. Our in-depth
experimental results demonstrate that our method substantially improves the
agent's ability to recover from OOD situations in terms of sample efficiency
and restoration of the performance for the original tasks. Moreover, we show
that our method can retrain the agent to recover from OOD situations even when
in-distribution states are difficult to visit through exploration.
</p>
</div>
</dd>
<dt><a name="item130">[130]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03653" title="Abstract">arXiv:2311.03653</a> [<a href="/pdf/2311.03653" title="Download PDF">pdf</a>, <a href="/ps/2311.03653" title="Download PostScript">ps</a>, <a href="/format/2311.03653" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the Performance of LoRa Empowered Communication for Wireless Body  Area Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+M">Minling Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Cai%2C+G">Guofa Cai</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+Z">Zhiping Xu</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+J">Jiguang He</a>, 
<a href="/search/cs?searchtype=author&query=Juntti%2C+M">Markku Juntti</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">To remotely monitor the physiological status of the human body, long range
(LoRa) communication has been considered as an eminently suitable candidate for
wireless body area networks (WBANs). Typically, a Rayleigh-lognormal fading
channel is encountered by the LoRa links of the WBAN. In this context, we
characterize the performance of the LoRa system in WBAN scenarios with an
emphasis on the physical (PHY) layer and medium access control (MAC) layer in
the face of Rayleigh-lognormal fading channels and the same spreading factor
interference. Specifically, closed-form approximate bit error probability (BEP)
expressions are derived for the LoRa system. The results show that increasing
the SF and reducing the interference efficiently mitigate the shadowing
effects. Moreover, in the quest for the most suitable MAC protocol for LoRa
based WBANs, three MAC protocols are critically appraised, namely the pure
ALOHA, slotted ALOHA, and carrier-sense multiple access. The coverage
probability, energy efficiency, throughput, and system delay of the three MAC
protocols are analyzed in Rayleigh-lognormal fading channel. Furthermore, the
performance of the equal-interval-based and equal-area-based schemes is
analyzed to guide the choice of the SF. Our simulation results confirm the
accuracy of the mathematical analysis and provide some useful insights for the
future design of LoRa based WBANs.
</p>
</div>
</dd>
<dt><a name="item131">[131]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03655" title="Abstract">arXiv:2311.03655</a> [<a href="/pdf/2311.03655" title="Download PDF">pdf</a>, <a href="/format/2311.03655" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PUMA: Fully Decentralized Uncertainty-aware Multiagent Trajectory  Planner with Real-time Image Segmentation-based Frame Alignment
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kondo%2C+K">Kota Kondo</a>, 
<a href="/search/cs?searchtype=author&query=Tewari%2C+C+T">Claudius T. Tewari</a>, 
<a href="/search/cs?searchtype=author&query=Peterson%2C+M+B">Mason B. Peterson</a>, 
<a href="/search/cs?searchtype=author&query=Thomas%2C+A">Annika Thomas</a>, 
<a href="/search/cs?searchtype=author&query=Kinnari%2C+J">Jouko Kinnari</a>, 
<a href="/search/cs?searchtype=author&query=Tagliabue%2C+A">Andrea Tagliabue</a>, 
<a href="/search/cs?searchtype=author&query=How%2C+J+P">Jonathan P. How</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, 13 figures, conference paper
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Multiagent Systems (cs.MA)

</div>
<p class="mathjax">Fully decentralized, multiagent trajectory planners enable complex tasks like
search and rescue or package delivery by ensuring safe navigation in unknown
environments. However, deconflicting trajectories with other agents and
ensuring collision-free paths in a fully decentralized setting is complicated
by dynamic elements and localization uncertainty. To this end, this paper
presents (1) an uncertainty-aware multiagent trajectory planner and (2) an
image segmentation-based frame alignment pipeline. The uncertainty-aware
planner propagates uncertainty associated with the future motion of detected
obstacles, and by incorporating this propagated uncertainty into optimization
constraints, the planner effectively navigates around obstacles. Unlike
conventional methods that emphasize explicit obstacle tracking, our approach
integrates implicit tracking. Sharing trajectories between agents can cause
potential collisions due to frame misalignment. Addressing this, we introduce a
novel frame alignment pipeline that rectifies inter-agent frame misalignment.
This method leverages a zero-shot image segmentation model for detecting
objects in the environment and a data association framework based on geometric
consistency for map alignment. Our approach accurately aligns frames with only
0.18 m and 2.7 deg of mean frame alignment error in our most challenging
simulation scenario. In addition, we conducted hardware experiments and
successfully achieved 0.29 m and 2.59 deg of frame alignment error. Together
with the alignment framework, our planner ensures safe navigation in unknown
environments and collision avoidance in decentralized settings.
</p>
</div>
</dd>
<dt><a name="item132">[132]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03657" title="Abstract">arXiv:2311.03657</a> [<a href="/pdf/2311.03657" title="Download PDF">pdf</a>, <a href="/format/2311.03657" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> 6DVF: Data Visualisation Framework for mHealth Apps
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Alshehhi%2C+Y+A">Yasmeen Anjeer Alshehhi</a>, 
<a href="/search/cs?searchtype=author&query=Ahmad%2C+K">Khlood Ahmad</a>, 
<a href="/search/cs?searchtype=author&query=Abdelrazek%2C+M">Mohamed Abdelrazek</a>, 
<a href="/search/cs?searchtype=author&query=Bonti%2C+A">Alessio Bonti</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">The widespread of data visualisation tools on smartphones has provided end
users an easy way to track their health data, leading designers to put more
effort into delivering suitable visualisations. Both academia and industry have
developed several frameworks to guide the creation of informative and
well-designed charts, such as the visualisation and design framework and Google
Material Design.
<br />Despite the typical focus on design and chart types in these existing
frameworks, our study highlights the need to incorporate additional components
when developing data visualisations. The needs of non-expert users, the nature
of the data being represented, and the mobile environment are often not
prioritised in these frameworks, leading to visualisations that do not meet
user needs and expectations. To address these issues, we propose our
Six-Dimensions Data Visualisation Framework (6DVF) to assist in the design and
evaluation of visualisations on mobile devices. Finally, we present our initial
findings from a designer evaluation experiment.
</p>
</div>
</dd>
<dt><a name="item133">[133]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03658" title="Abstract">arXiv:2311.03658</a> [<a href="/pdf/2311.03658" title="Download PDF">pdf</a>, <a href="/format/2311.03658" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Linear Representation Hypothesis and the Geometry of Large Language  Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Park%2C+K">Kiho Park</a>, 
<a href="/search/cs?searchtype=author&query=Choe%2C+Y+J">Yo Joong Choe</a>, 
<a href="/search/cs?searchtype=author&query=Veitch%2C+V">Victor Veitch</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted for an oral presentation at NeurIPS 2023 Workshop on Causal Representation Learning. Code is available at <a href="https://github.com/KihoPark/linear_rep_geometry">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Machine Learning (stat.ML)

</div>
<p class="mathjax">Informally, the 'linear representation hypothesis' is the idea that
high-level concepts are represented linearly as directions in some
representation space. In this paper, we address two closely related questions:
What does "linear representation" actually mean? And, how do we make sense of
geometric notions (e.g., cosine similarity or projection) in the representation
space? To answer these, we use the language of counterfactuals to give two
formalizations of "linear representation", one in the output (word)
representation space, and one in the input (sentence) space. We then prove
these connect to linear probing and model steering, respectively. To make sense
of geometric notions, we use the formalization to identify a particular
(non-Euclidean) inner product that respects language structure in a sense we
make precise. Using this causal inner product, we show how to unify all notions
of linear representation. In particular, this allows the construction of probes
and steering vectors using counterfactual pairs. Experiments with LLaMA-2
demonstrate the existence of linear representations of concepts, the connection
to interpretation and control, and the fundamental role of the choice of inner
product.
</p>
</div>
</dd>
<dt><a name="item134">[134]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03659" title="Abstract">arXiv:2311.03659</a> [<a href="/pdf/2311.03659" title="Download PDF">pdf</a>, <a href="/format/2311.03659" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GNN-Based Beamforming for Sum-Rate Maximization in MU-MISO Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Li%2C+Y">Yuhang Li</a>, 
<a href="/search/eess?searchtype=author&query=Lu%2C+Y">Yang Lu</a>, 
<a href="/search/eess?searchtype=author&query=Ai%2C+B">Bo Ai</a>, 
<a href="/search/eess?searchtype=author&query=Dobre%2C+O+A">Octavia A. Dobre</a>, 
<a href="/search/eess?searchtype=author&query=Ding%2C+Z">Zhiguo Ding</a>, 
<a href="/search/eess?searchtype=author&query=Niyato%2C+D">Dusit Niyato</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">The advantages of graph neural networks (GNNs) in leveraging the graph
topology of wireless networks have drawn increasing attentions. This paper
studies the GNN-based learning approach for the sum-rate maximization in
multiple-user multiple-input single-output (MU-MISO) networks subject to the
users' individual data rate requirements and the power budget of the base
station. By modeling the MU-MISO network as a graph, a GNN-based architecture
named CRGAT is proposed to directly map the channel state information to the
beamforming vectors. The attention-enabled aggregation and the
residual-assisted combination are adopted to enhance the learning capability
and avoid the oversmoothing issue. Furthermore, a novel activation function is
proposed for the constraint due to the limited power budget at the base
station. The CRGAT is trained in an unsupervised learning manner with two
proposed loss functions. An evaluation method is proposed for the
learning-based approach, based on which the effectiveness of the proposed CRGAT
is validated in comparison with several convex optimization and learning based
approaches. Numerical results are provided to reveal the advantages of the
CRGAT including the millisecond-level response with limited optimality
performance loss, the scalability to different number of users and power
budgets, and the adaptability to different system settings.
</p>
</div>
</dd>
<dt><a name="item135">[135]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03661" title="Abstract">arXiv:2311.03661</a> [<a href="/pdf/2311.03661" title="Download PDF">pdf</a>, <a href="/format/2311.03661" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Graph Neural Networks for Power Grid Operational Risk Assessment
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Zhang%2C+Y">Yadong Zhang</a>, 
<a href="/search/eess?searchtype=author&query=Karve%2C+P+M">Pranav M Karve</a>, 
<a href="/search/eess?searchtype=author&query=Mahadevan%2C+S">Sankaran Mahadevan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Manuscript submitted to IEEE Transactions on Power Systems
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">In this article, the utility of graph neural network (GNN) surrogates for
Monte Carlo (MC) sampling-based risk quantification in daily operations of
power grid is investigated. The MC simulation process necessitates solving a
large number of optimal power flow (OPF) problems corresponding to the sample
values of stochastic grid variables (power demand and renewable generation),
which is computationally prohibitive. Computationally inexpensive surrogates of
the OPF problem provide an attractive alternative for expedited MC simulation.
GNN surrogates are especially suitable due to their superior ability to handle
graph-structured data. Therefore, GNN surrogates of OPF problem are trained
using supervised learning. They are then used to obtain Monte Carlo (MC)
samples of the quantities of interest (operating reserve, transmission line
flow) given the (hours-ahead) probabilistic wind generation and load forecast.
The utility of GNN surrogates is evaluated by comparing OPF-based and GNN-based
grid reliability and risk for IEEE Case118 synthetic grid. It is shown that the
GNN surrogates are sufficiently accurate for predicting the (bus-level,
branch-level and system-level) grid state and enable fast as well as accurate
operational risk quantification for power grids. The article thus develops
various tools for fast reliability and risk quantification for real-world power
grids using GNNs.
</p>
</div>
</dd>
<dt><a name="item136">[136]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03663" title="Abstract">arXiv:2311.03663</a> [<a href="/pdf/2311.03663" title="Download PDF">pdf</a>, <a href="/format/2311.03663" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Generalization of NLP Models: Notion and Causation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Elangovan%2C+A">Aparna Elangovan</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+J">Jiayuan He</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yuan Li</a>, 
<a href="/search/cs?searchtype=author&query=Verspoor%2C+K">Karin Verspoor</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">The NLP community typically relies on performance of a model on a held-out
test set to assess generalization. Performance drops observed in datasets
outside of official test sets are generally attributed to
"out-of-distribution'' effects. Here, we explore the foundations of
generalizability and study the various factors that affect it, articulating
generalizability lessons from clinical studies. In clinical research
generalizability depends on (a) internal validity of experiments to ensure
controlled measurement of cause and effect, and (b) external validity or
transportability of the results to the wider population. We present the need to
ensure internal validity when building machine learning models in natural
language processing, especially where results may be impacted by spurious
correlations in the data. We demonstrate how spurious factors, such as the
distance between entities in relation extraction tasks, can affect model
internal validity and in turn adversely impact generalization. We also offer
guidance on how to analyze generalization failures.
</p>
</div>
</dd>
<dt><a name="item137">[137]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03664" title="Abstract">arXiv:2311.03664</a> [<a href="/pdf/2311.03664" title="Download PDF">pdf</a>, <a href="/ps/2311.03664" title="Download PostScript">ps</a>, <a href="/format/2311.03664" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Healthcare Security Breaches in the United States: Insights and their  Socio-Technical Implications
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Moncy%2C+M+M">Megha M. Moncy</a>, 
<a href="/search/cs?searchtype=author&query=Afreen%2C+S">Sadia Afreen</a>, 
<a href="/search/cs?searchtype=author&query=Purkayastha%2C+S">Saptarshi Purkayastha</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted for presentation at the Workshop on Information Security and Privacy (WISP) 2023 Hosted by AIS SIGSEC Hyderabad, India, Sunday, December 10, 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>; Cryptography and Security (cs.CR)

</div>
<p class="mathjax">This research examines the pivotal role of human behavior in the realm of
healthcare data management, situated at the confluence of technological
advancements and human conduct. An in-depth analysis of security breaches in
the United States from 2009 to the present elucidates the dominance of
human-induced security breaches. While technological weak points are certainly
a concern, our study highlights that a significant proportion of breaches are
precipitated by human errors and practices, thus pinpointing a conspicuous
deficiency in training, awareness, and organizational architecture. In spite of
stringent federal mandates, such as the Health Insurance Portability and
Accountability Act (HIPAA) and the Health Information Technology for Economic
and Clinical Health (HITECH) Act, breaches persist, emphasizing the
indispensable role of human factors within this domain. Such oversights not
only jeopardize patient data confidentiality but also undermine the
foundational trust inherent in the healthcare infrastructure. By probing the
socio-technical facets of healthcare security infringements, this article
advocates for an integrated, dynamic, and holistic approach to healthcare data
security. The findings underscore the imperative of augmenting technological
defenses while concurrently elevating human conduct and institutional ethos,
thereby cultivating a robust and impervious healthcare data management
environment.
</p>
</div>
</dd>
<dt><a name="item138">[138]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03665" title="Abstract">arXiv:2311.03665</a> [<a href="/pdf/2311.03665" title="Download PDF">pdf</a>, <a href="/format/2311.03665" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Faster Algorithms for Cycle Hitting Problems on Disk Graphs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=An%2C+S">Shinwoo An</a>, 
<a href="/search/cs?searchtype=author&query=Cho%2C+K">Kyungjin Cho</a>, 
<a href="/search/cs?searchtype=author&query=Oh%2C+E">Eunjin Oh</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> WADS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Geometry (cs.CG)</span>; Data Structures and Algorithms (cs.DS)

</div>
<p class="mathjax">In this paper, we consider three hitting problems on a disk intersection
graph: Triangle Hitting Set, Feedback Vertex Set, and Odd Cycle Transversal.
Given a disk intersection graph $G$, our goal is to compute a set of vertices
hitting all triangles, all cycles, or all odd cycles, respectively. Our
algorithms run in time $2^{\tilde O(k^{4/5})}n^{O(1)}$, $2^{\tilde
O(k^{9/10})}n^{O(1)}$, and $2^{\tilde O(k^{19/20})}n^{O(1)}$, respectively,
where $n$ denotes the number of vertices of $G$. These do not require a
geometric representation of a disk graph. If a geometric representation of a
disk graph is given as input, we can solve these problems more efficiently. In
this way, we improve the algorithms for those three problem by Lokshtanov et
al. [SODA 2022].
</p>
</div>
</dd>
<dt><a name="item139">[139]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03669" title="Abstract">arXiv:2311.03669</a> [<a href="/pdf/2311.03669" title="Download PDF">pdf</a>, <a href="/format/2311.03669" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Stable Modular Control via Contraction Theory for Reinforcement Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Song%2C+B">Bing Song</a>, 
<a href="/search/cs?searchtype=author&query=Slotine%2C+J">Jean-Jacques Slotine</a>, 
<a href="/search/cs?searchtype=author&query=Pham%2C+Q">Quang-Cuong Pham</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Systems and Control (eess.SY)

</div>
<p class="mathjax">We propose a novel way to integrate control techniques with reinforcement
learning (RL) for stability, robustness, and generalization: leveraging
contraction theory to realize modularity in neural control, which ensures that
combining stable subsystems can automatically preserve the stability. We
realize such modularity via signal composition and dynamic decomposition.
Signal composition creates the latent space, within which RL applies to
maximizing rewards. Dynamic decomposition is realized by coordinate
transformation that creates an auxiliary space, within which the latent signals
are coupled in the way that their combination can preserve stability provided
each signal, that is, each subsystem, has stable self-feedbacks. Leveraging
modularity, the nonlinear stability problem is deconstructed into algebraically
solvable ones, the stability of the subsystems in the auxiliary space, yielding
linear constraints on the input gradients of control networks that can be as
simple as switching the signs of network weights. This minimally invasive
method for stability allows arguably easy integration into the modular neural
architectures in machine learning, like hierarchical RL, and improves their
performance. We demonstrate in simulation the necessity and the effectiveness
of our method: the necessity for robustness and generalization, and the
effectiveness in improving hierarchical RL for manipulation learning.
</p>
</div>
</dd>
<dt><a name="item140">[140]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03672" title="Abstract">arXiv:2311.03672</a> [<a href="/pdf/2311.03672" title="Download PDF">pdf</a>, <a href="/format/2311.03672" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CBSiMT: Mitigating Hallucination in Simultaneous Machine Translation  with Weighted Prefix-to-Prefix Training
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+M">Mengge Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+W">Wen Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xiang Li</a>, 
<a href="/search/cs?searchtype=author&query=Tian%2C+Y">Yanzhi Tian</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+Y">Yuhang Guo</a>, 
<a href="/search/cs?searchtype=author&query=Luan%2C+J">Jian Luan</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+B">Bin Wang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+S">Shuoying Chen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Simultaneous machine translation (SiMT) is a challenging task that requires
starting translation before the full source sentence is available.
Prefix-to-prefix framework is often applied to SiMT, which learns to predict
target tokens using only a partial source prefix. However, due to the word
order difference between languages, misaligned prefix pairs would make SiMT
models suffer from serious hallucination problems, i.e. target outputs that are
unfaithful to source inputs. Such problems can not only produce target tokens
that are not supported by the source prefix, but also hinder generating the
correct translation by receiving more source words. In this work, we propose a
Confidence-Based Simultaneous Machine Translation (CBSiMT) framework, which
uses model confidence to perceive hallucination tokens and mitigates their
negative impact with weighted prefix-to-prefix training. Specifically,
token-level and sentence-level weights are calculated based on model confidence
and acted on the loss function. We explicitly quantify the faithfulness of the
generated target tokens using the token-level weight, and employ the
sentence-level weight to alleviate the disturbance of sentence pairs with
serious word order differences on the model. Experimental results on MuST-C
English-to-Chinese and WMT15 German-to-English SiMT tasks demonstrate that our
method can consistently improve translation quality at most latency regimes,
with up to 2 BLEU scores improvement at low latency.
</p>
</div>
</dd>
<dt><a name="item141">[141]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03679" title="Abstract">arXiv:2311.03679</a> [<a href="/pdf/2311.03679" title="Download PDF">pdf</a>, <a href="/format/2311.03679" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Unsupervised convolutional neural network fusion approach for change  detection in remote sensing images
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yan%2C+W">Weidong Yan</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+P">Pei Yan</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+L">Li Cao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Image and Video Processing (eess.IV)

</div>
<p class="mathjax">With the rapid development of deep learning, a variety of change detection
methods based on deep learning have emerged in recent years. However, these
methods usually require a large number of training samples to train the network
model, so it is very expensive. In this paper, we introduce a completely
unsupervised shallow convolutional neural network (USCNN) fusion approach for
change detection. Firstly, the bi-temporal images are transformed into
different feature spaces by using convolution kernels of different sizes to
extract multi-scale information of the images. Secondly, the output features of
bi-temporal images at the same convolution kernels are subtracted to obtain the
corresponding difference images, and the difference feature images at the same
scale are fused into one feature image by using 1 * 1 convolution layer.
Finally, the output features of different scales are concatenated and a 1 * 1
convolution layer is used to fuse the multi-scale information of the image. The
model parameters are obtained by a redesigned sparse function. Our model has
three features: the entire training process is conducted in an unsupervised
manner, the network architecture is shallow, and the objective function is
sparse. Thus, it can be seen as a kind of lightweight network model.
Experimental results on four real remote sensing datasets indicate the
feasibility and effectiveness of the proposed approach.
</p>
</div>
</dd>
<dt><a name="item142">[142]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03680" title="Abstract">arXiv:2311.03680</a> [<a href="/pdf/2311.03680" title="Download PDF">pdf</a>, <a href="/format/2311.03680" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deep Bayesian Reinforcement Learning for Spacecraft Proximity Maneuvers  and Docking
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Du%2C+D">Desong Du</a>, 
<a href="/search/cs?searchtype=author&query=Qi%2C+N">Naiming Qi</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yanfang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Pan%2C+W">Wei Pan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">In the pursuit of autonomous spacecraft proximity maneuvers and docking(PMD),
we introduce a novel Bayesian actor-critic reinforcement learning algorithm to
learn a control policy with the stability guarantee. The PMD task is formulated
as a Markov decision process that reflects the relative dynamic model, the
docking cone and the cost function. Drawing from the principles of Lyapunov
theory, we frame the temporal difference learning as a constrained Gaussian
process regression problem. This innovative approach allows the state-value
function to be expressed as a Lyapunov function, leveraging the Gaussian
process and deep kernel learning. We develop a novel Bayesian quadrature policy
optimization procedure to analytically compute the policy gradient while
integrating Lyapunov-based stability constraints. This integration is pivotal
in satisfying the rigorous safety demands of spaceflight missions. The proposed
algorithm has been experimentally evaluated on a spacecraft air-bearing testbed
and shows impressive and promising performance.
</p>
</div>
</dd>
<dt><a name="item143">[143]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03682" title="Abstract">arXiv:2311.03682</a> [<a href="/pdf/2311.03682" title="Download PDF">pdf</a>, <a href="/ps/2311.03682" title="Download PostScript">ps</a>, <a href="/format/2311.03682" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Incentive Design for Eco-driving in Urban Transportation Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Niazi%2C+M+U+B">M. Umar B. Niazi</a>, 
<a href="/search/eess?searchtype=author&query=Cho%2C+J">Jung-Hoon Cho</a>, 
<a href="/search/eess?searchtype=author&query=Dahleh%2C+M+A">Munther A. Dahleh</a>, 
<a href="/search/eess?searchtype=author&query=Dong%2C+R">Roy Dong</a>, 
<a href="/search/eess?searchtype=author&query=Wu%2C+C">Cathy Wu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Social and Information Networks (cs.SI); Optimization and Control (math.OC)

</div>
<p class="mathjax">Eco-driving emerges as a cost-effective and efficient strategy to mitigate
greenhouse gas emissions in urban transportation networks. Acknowledging the
persuasive influence of incentives in shaping driver behavior, this paper
presents the `eco-planner,' a digital platform devised to promote eco-driving
practices in urban transportation. At the outset of their trips, users provide
the platform with their trip details and travel time preferences, enabling the
eco-planner to formulate personalized eco-driving recommendations and
corresponding incentives, while adhering to its budgetary constraints. Upon
trip completion, incentives are transferred to users who comply with the
recommendations and effectively reduce their emissions. By comparing our
proposed incentive mechanism with a baseline scheme that offers uniform
incentives to all users, we demonstrate that our approach achieves superior
emission reductions and increased user compliance with a smaller budget.
</p>
</div>
</dd>
<dt><a name="item144">[144]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03683" title="Abstract">arXiv:2311.03683</a> [<a href="/pdf/2311.03683" title="Download PDF">pdf</a>, <a href="/format/2311.03683" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Preventing Arbitrarily High Confidence on Far-Away Data in  Point-Estimated Discriminative Neural Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rashid%2C+A">Ahmad Rashid</a>, 
<a href="/search/cs?searchtype=author&query=Hacker%2C+S">Serena Hacker</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+G">Guojun Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Kristiadi%2C+A">Agustinus Kristiadi</a>, 
<a href="/search/cs?searchtype=author&query=Poupart%2C+P">Pascal Poupart</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Discriminatively trained, deterministic neural networks are the de facto
choice for classification problems. However, even though they achieve
state-of-the-art results on in-domain test sets, they tend to be overconfident
on out-of-distribution (OOD) data. For instance, ReLU networks -- a popular
class of neural network architectures -- have been shown to almost always yield
high confidence predictions when the test data are far away from the training
set, even when they are trained with OOD data. We overcome this problem by
adding a term to the output of the neural network that corresponds to the logit
of an extra class, that we design to dominate the logits of the original
classes as we move away from the training data.This technique provably prevents
arbitrarily high confidence on far-away test data while maintaining a simple
discriminative point-estimate training. Evaluation on various benchmarks
demonstrates strong performance against competitive baselines on both far-away
and realistic OOD data.
</p>
</div>
</dd>
<dt><a name="item145">[145]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03685" title="Abstract">arXiv:2311.03685</a> [<a href="/pdf/2311.03685" title="Download PDF">pdf</a>, <a href="/ps/2311.03685" title="Download PostScript">ps</a>, <a href="/format/2311.03685" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Dynamic Non-monotone Submodular Maximization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Banihashem%2C+K">Kiarash Banihashem</a>, 
<a href="/search/cs?searchtype=author&query=Biabani%2C+L">Leyla Biabani</a>, 
<a href="/search/cs?searchtype=author&query=Goudarzi%2C+S">Samira Goudarzi</a>, 
<a href="/search/cs?searchtype=author&query=Hajiaghayi%2C+M">MohammadTaghi Hajiaghayi</a>, 
<a href="/search/cs?searchtype=author&query=Jabbarzade%2C+P">Peyman Jabbarzade</a>, 
<a href="/search/cs?searchtype=author&query=Monemizadeh%2C+M">Morteza Monemizadeh</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Maximizing submodular functions has been increasingly used in many
applications of machine learning, such as data summarization, recommendation
systems, and feature selection. Moreover, there has been a growing interest in
both submodular maximization and dynamic algorithms. In 2020, Monemizadeh and
Lattanzi, Mitrovic, Norouzi{-}Fard, Tarnawski, and Zadimoghaddam initiated
developing dynamic algorithms for the monotone submodular maximization problem
under the cardinality constraint $k$. Recently, there have been some
improvements on the topic made by Banihashem, Biabani, Goudarzi, Hajiaghayi,
Jabbarzade, and Monemizadeh. In 2022, Chen and Peng studied the complexity of
this problem and raised an important open question: "Can we extend [fully
dynamic] results (algorithm or hardness) to non-monotone submodular
maximization?". We affirmatively answer their question by demonstrating a
reduction from maximizing a non-monotone submodular function under the
cardinality constraint $k$ to maximizing a monotone submodular function under
the same constraint. Through this reduction, we obtain the first dynamic
algorithms to solve the non-monotone submodular maximization problem under the
cardinality constraint $k$. Our algorithms maintain an
$(8+\epsilon)$-approximate of the solution and use expected amortized
$O(\epsilon^{-3}k^3\log^3(n)\log(k))$ or $O(\epsilon^{-1}k^2\log^3(k))$ oracle
queries per update, respectively. Furthermore, we showcase the benefits of our
dynamic algorithm for video summarization and max-cut problems on several
real-world data sets.
</p>
</div>
</dd>
<dt><a name="item146">[146]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03687" title="Abstract">arXiv:2311.03687</a> [<a href="/pdf/2311.03687" title="Download PDF">pdf</a>, <a href="/format/2311.03687" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Dissecting the Runtime Performance of the Training, Fine-tuning, and  Inference of Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+L">Longteng Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xiang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zeyu Li</a>, 
<a href="/search/cs?searchtype=author&query=Pan%2C+X">Xinglin Pan</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+P">Peijie Dong</a>, 
<a href="/search/cs?searchtype=author&query=Fan%2C+R">Ruibo Fan</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+R">Rui Guo</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xin Wang</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+Q">Qiong Luo</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+S">Shaohuai Shi</a>, 
<a href="/search/cs?searchtype=author&query=Chu%2C+X">Xiaowen Chu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Performance (cs.PF)</span>; Computation and Language (cs.CL); Machine Learning (cs.LG)

</div>
<p class="mathjax">Large Language Models (LLMs) have seen great advance in both academia and
industry, and their popularity results in numerous open-source frameworks and
techniques in accelerating LLM pre-training, fine-tuning, and inference.
Training and deploying LLMs are expensive as it requires considerable computing
resources and memory, hence many efficient approaches have been developed for
improving system pipelines as well as operators. However, the runtime
performance can vary significantly across hardware and software stacks, which
makes it difficult to choose the best configuration. In this work, we aim to
benchmark the performance from both macro and micro perspectives. First, we
benchmark the end-to-end performance of pre-training, fine-tuning, and serving
LLMs in different sizes , i.e., 7, 13, and 70 billion parameters (7B, 13B, and
70B) on three 8-GPU platforms with and without individual optimization
techniques, including ZeRO, quantization, recomputation, FlashAttention. Then,
we dive deeper to provide a detailed runtime analysis of the sub-modules,
including computing and communication operators in LLMs. For end users, our
benchmark and findings help better understand different optimization
techniques, training and inference frameworks, together with hardware platforms
in choosing configurations for deploying LLMs. For researchers, our in-depth
module-wise analyses discover potential opportunities for future work to
further optimize the runtime performance of LLMs.
</p>
</div>
</dd>
<dt><a name="item147">[147]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03688" title="Abstract">arXiv:2311.03688</a> [<a href="/pdf/2311.03688" title="Download PDF">pdf</a>, <a href="/ps/2311.03688" title="Download PostScript">ps</a>, <a href="/format/2311.03688" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Minimum distance and special fibers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tohaneanu%2C+S+O">Stefan O. Tohaneanu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Commutative Algebra (math.AC)

</div>
<p class="mathjax">In this note we prove that the minimum distance of a linear code equals one
plus the $\alpha$-invariant of the special fiber of an ideal constructed from
any parity-check matrix of the linear code.
</p>
</div>
</dd>
<dt><a name="item148">[148]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03695" title="Abstract">arXiv:2311.03695</a> [<a href="/pdf/2311.03695" title="Download PDF">pdf</a>, <a href="/format/2311.03695" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Context Shift Reduction for Offline Meta-Reinforcement Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gao%2C+Y">Yunkai Gao</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+R">Rui Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+J">Jiaming Guo</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+F">Fan Wu</a>, 
<a href="/search/cs?searchtype=author&query=Yi%2C+Q">Qi Yi</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+S">Shaohui Peng</a>, 
<a href="/search/cs?searchtype=author&query=Lan%2C+S">Siming Lan</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+R">Ruizhi Chen</a>, 
<a href="/search/cs?searchtype=author&query=Du%2C+Z">Zidong Du</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+X">Xing Hu</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+Q">Qi Guo</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+L">Ling Li</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yunji Chen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Offline meta-reinforcement learning (OMRL) utilizes pre-collected offline
datasets to enhance the agent's generalization ability on unseen tasks.
However, the context shift problem arises due to the distribution discrepancy
between the contexts used for training (from the behavior policy) and testing
(from the exploration policy). The context shift problem leads to incorrect
task inference and further deteriorates the generalization ability of the
meta-policy. Existing OMRL methods either overlook this problem or attempt to
mitigate it with additional information. In this paper, we propose a novel
approach called Context Shift Reduction for OMRL (CSRO) to address the context
shift problem with only offline datasets. The key insight of CSRO is to
minimize the influence of policy in context during both the meta-training and
meta-test phases. During meta-training, we design a max-min mutual information
representation learning mechanism to diminish the impact of the behavior policy
on task representation. In the meta-test phase, we introduce the non-prior
context collection strategy to reduce the effect of the exploration policy.
Experimental results demonstrate that CSRO significantly reduces the context
shift and improves the generalization ability, surpassing previous methods
across various challenging domains.
</p>
</div>
</dd>
<dt><a name="item149">[149]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03696" title="Abstract">arXiv:2311.03696</a> [<a href="/pdf/2311.03696" title="Download PDF">pdf</a>, <a href="/format/2311.03696" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Bilingual Corpus Mining and Multistage Fine-Tuning for Improving Machine  Translation of Lecture Transcripts
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Song%2C+H">Haiyue Song</a>, 
<a href="/search/cs?searchtype=author&query=Dabre%2C+R">Raj Dabre</a>, 
<a href="/search/cs?searchtype=author&query=Chu%2C+C">Chenhui Chu</a>, 
<a href="/search/cs?searchtype=author&query=Fujita%2C+A">Atsushi Fujita</a>, 
<a href="/search/cs?searchtype=author&query=Kurohashi%2C+S">Sadao Kurohashi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to the Journal of Information Processing (JIP). arXiv admin note: text overlap with <a href="/abs/1912.11739">arXiv:1912.11739</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Lecture transcript translation helps learners understand online courses,
however, building a high-quality lecture machine translation system lacks
publicly available parallel corpora. To address this, we examine a framework
for parallel corpus mining, which provides a quick and effective way to mine a
parallel corpus from publicly available lectures on Coursera. To create the
parallel corpora, we propose a dynamic programming based sentence alignment
algorithm which leverages the cosine similarity of machine-translated
sentences. The sentence alignment F1 score reaches 96%, which is higher than
using the BERTScore, LASER, or sentBERT methods. For both English--Japanese and
English--Chinese lecture translations, we extracted parallel corpora of
approximately 50,000 lines and created development and test sets through manual
filtering for benchmarking translation performance. Through machine translation
experiments, we show that the mined corpora enhance the quality of lecture
transcript translation when used in conjunction with out-of-domain parallel
corpora via multistage fine-tuning. Furthermore, this study also suggests
guidelines for gathering and cleaning corpora, mining parallel sentences,
cleaning noise in the mined data, and creating high-quality evaluation splits.
For the sake of reproducibility, we have released the corpora as well as the
code to create them. The dataset is available at
https://github.com/shyyhs/CourseraParallelCorpusMining.
</p>
</div>
</dd>
<dt><a name="item150">[150]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03697" title="Abstract">arXiv:2311.03697</a> [<a href="/pdf/2311.03697" title="Download PDF">pdf</a>, <a href="/format/2311.03697" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Autonomous Crop Monitoring: Inserting Sensors in Cluttered  Environments
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lee%2C+M">Moonyoung Lee</a>, 
<a href="/search/cs?searchtype=author&query=Berger%2C+A">Aaron Berger</a>, 
<a href="/search/cs?searchtype=author&query=Guri%2C+D">Dominic Guri</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+K">Kevin Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Coffee%2C+L">Lisa Coffee</a>, 
<a href="/search/cs?searchtype=author&query=Kantor%2C+G">George Kantor</a>, 
<a href="/search/cs?searchtype=author&query=Kroemer%2C+O">Oliver Kroemer</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">We present a contact-based phenotyping robot platform that can autonomously
insert nitrate sensors into cornstalks to proactively monitor macronutrient
levels in crops. This task is challenging because inserting such sensors
requires sub-centimeter precision in an environment which contains high levels
of clutter, lighting variation, and occlusion. To address these challenges, we
develop a robust perception-action pipeline to detect and grasp stalks, and
create a custom robot gripper which mechanically aligns the sensor before
inserting it into the stalk. Through experimental validation on 48 unique
stalks in a cornfield in Iowa, we demonstrate our platform's capability of
detecting a stalk with 94% success, grasping a stalk with 90% success, and
inserting a sensor with 60% success. In addition to developing an autonomous
phenotyping research platform, we share key challenges and insights obtained
from deployment in the field. Our research platform is open-sourced, with
additional information available at https://kantor-lab.github.io/cornbot.
</p>
</div>
</dd>
<dt><a name="item151">[151]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03698" title="Abstract">arXiv:2311.03698</a> [<a href="/pdf/2311.03698" title="Download PDF">pdf</a>, <a href="/format/2311.03698" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Novel Variational Lower Bound for Inverse Reinforcement Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gui%2C+Y">Yikang Gui</a>, 
<a href="/search/cs?searchtype=author&query=Doshi%2C+P">Prashant Doshi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Robotics (cs.RO)

</div>
<p class="mathjax">Inverse reinforcement learning (IRL) seeks to learn the reward function from
expert trajectories, to understand the task for imitation or collaboration
thereby removing the need for manual reward engineering. However, IRL in the
context of large, high-dimensional problems with unknown dynamics has been
particularly challenging. In this paper, we present a new Variational Lower
Bound for IRL (VLB-IRL), which is derived under the framework of a
probabilistic graphical model with an optimality node. Our method
simultaneously learns the reward function and policy under the learned reward
function by maximizing the lower bound, which is equivalent to minimizing the
reverse Kullback-Leibler divergence between an approximated distribution of
optimality given the reward function and the true distribution of optimality
given trajectories. This leads to a new IRL method that learns a valid reward
function such that the policy under the learned reward achieves expert-level
performance on several known domains. Importantly, the method outperforms the
existing state-of-the-art IRL algorithms on these domains by demonstrating
better reward from the learned policy.
</p>
</div>
</dd>
<dt><a name="item152">[152]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03701" title="Abstract">arXiv:2311.03701</a> [<a href="/pdf/2311.03701" title="Download PDF">pdf</a>, <a href="/format/2311.03701" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Hypothesis Network Planned Exploration for Rapid Meta-Reinforcement  Learning Adaptation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jacobson%2C+M+J">Maxwell Joseph Jacobson</a>, 
<a href="/search/cs?searchtype=author&query=Xue%2C+Y">Yexiang Xue</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Meta Reinforcement Learning (Meta RL) trains agents that adapt to
fast-changing environments and tasks. Current strategies often lose adaption
efficiency due to the passive nature of model exploration, causing delayed
understanding of new transition dynamics. This results in particularly
fast-evolving tasks being impossible to solve. We propose a novel approach,
Hypothesis Network Planned Exploration (HyPE), that integrates an active and
planned exploration process via the hypothesis network to optimize adaptation
speed. HyPE uses a generative hypothesis network to form potential models of
state transition dynamics, then eliminates incorrect models through
strategically devised experiments. Evaluated on a symbolic version of the
Alchemy game, HyPE outpaces baseline methods in adaptation speed and model
accuracy, validating its potential in enhancing reinforcement learning
adaptation in rapidly evolving settings.
</p>
</div>
</dd>
<dt><a name="item153">[153]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03703" title="Abstract">arXiv:2311.03703</a> [<a href="/pdf/2311.03703" title="Download PDF">pdf</a>, <a href="/format/2311.03703" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Pipeline Parallelism for DNN Inference with Practical Performance  Guarantees
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Archer%2C+A">Aaron Archer</a>, 
<a href="/search/cs?searchtype=author&query=Fahrbach%2C+M">Matthew Fahrbach</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+K">Kuikui Liu</a>, 
<a href="/search/cs?searchtype=author&query=Prabhu%2C+P">Prakash Prabhu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 18 pages, 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Distributed, Parallel, and Cluster Computing (cs.DC)

</div>
<p class="mathjax">We optimize pipeline parallelism for deep neural network (DNN) inference by
partitioning model graphs into $k$ stages and minimizing the running time of
the bottleneck stage, including communication. We design practical algorithms
for this NP-hard problem and show that they are nearly optimal in practice by
comparing against strong lower bounds obtained via novel mixed-integer
programming (MIP) formulations. We apply these algorithms and lower-bound
methods to production models to achieve substantially improved approximation
guarantees compared to standard combinatorial lower bounds. For example,
evaluated via geometric means across production data with $k=16$ pipeline
stages, our MIP formulations more than double the lower bounds, improving the
approximation ratio from $2.175$ to $1.058$. This work shows that while
max-throughput partitioning is theoretically hard, we have a handle on the
algorithmic side of the problem in practice and much of the remaining challenge
is in developing more accurate cost models to feed into the partitioning
algorithms.
</p>
</div>
</dd>
<dt><a name="item154">[154]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03705" title="Abstract">arXiv:2311.03705</a> [<a href="/pdf/2311.03705" title="Download PDF">pdf</a>, <a href="/format/2311.03705" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Efficient Bottom-Up Synthesis for Programs with Local Variables
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xiang Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+X">Xiangyu Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+R">Rui Dong</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yihong Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xinyu Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to POPL 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Programming Languages (cs.PL)</span>; Artificial Intelligence (cs.AI); Software Engineering (cs.SE)

</div>
<p class="mathjax">We propose a new synthesis algorithm that can efficiently search programs
with local variables (e.g., those introduced by lambdas). Prior bottom-up
synthesis algorithms are not able to evaluate programs with free local
variables, and therefore cannot effectively reduce the search space of such
programs (e.g., using standard observational equivalence reduction techniques),
making synthesis slow. Our algorithm can reduce the space of programs with
local variables. The key idea, dubbed lifted interpretation, is to lift up the
program interpretation process, from evaluating one program at a time to
simultaneously evaluating all programs from a grammar. Lifted interpretation
provides a mechanism to systematically enumerate all binding contexts for local
variables, thereby enabling us to evaluate and reduce the space of programs
with local variables. Our ideas are instantiated in the domain of web
automation. The resulting tool, Arborist, can automate a significantly broader
range of challenging tasks more efficiently than state-of-the-art techniques
including WebRobot and Helena.
</p>
</div>
</dd>
<dt><a name="item155">[155]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03707" title="Abstract">arXiv:2311.03707</a> [<a href="/pdf/2311.03707" title="Download PDF">pdf</a>, <a href="/format/2311.03707" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The NeurIPS 2022 Neural MMO Challenge: A Massively Multiagent  Competition with Specialization and Trade
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+E">Enhong Liu</a>, 
<a href="/search/cs?searchtype=author&query=Suarez%2C+J">Joseph Suarez</a>, 
<a href="/search/cs?searchtype=author&query=You%2C+C">Chenhui You</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+B">Bo Wu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+B">Bingcheng Chen</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+J">Jun Hu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Jiaxin Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+X">Xiaolong Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+C">Clare Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Togelius%2C+J">Julian Togelius</a>, 
<a href="/search/cs?searchtype=author&query=Mohanty%2C+S">Sharada Mohanty</a>, 
<a href="/search/cs?searchtype=author&query=Hong%2C+W">Weijun Hong</a>, 
<a href="/search/cs?searchtype=author&query=Du%2C+R">Rui Du</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yibing Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Q">Qinwen Wang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xinhang Li</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+Z">Zheng Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xiang Li</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+Y">Yuejia Huang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+K">Kun Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+H">Hanhui Yang</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+S">Shiqi Tang</a>, 
<a href="/search/cs?searchtype=author&query=Isola%2C+P">Phillip Isola</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Machine Learning (cs.LG); Multiagent Systems (cs.MA)

</div>
<p class="mathjax">In this paper, we present the results of the NeurIPS-2022 Neural MMO
Challenge, which attracted 500 participants and received over 1,600
submissions. Like the previous IJCAI-2022 Neural MMO Challenge, it involved
agents from 16 populations surviving in procedurally generated worlds by
collecting resources and defeating opponents. This year's competition runs on
the latest v1.6 Neural MMO, which introduces new equipment, combat, trading,
and a better scoring system. These elements combine to pose additional
robustness and generalization challenges not present in previous competitions.
This paper summarizes the design and results of the challenge, explores the
potential of this environment as a benchmark for learning methods, and presents
some practical reinforcement learning training approaches for complex tasks
with sparse rewards. Additionally, we have open-sourced our baselines,
including environment wrappers, benchmarks, and visualization tools for future
research.
</p>
</div>
</dd>
<dt><a name="item156">[156]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03711" title="Abstract">arXiv:2311.03711</a> [<a href="/pdf/2311.03711" title="Download PDF">pdf</a>, <a href="/format/2311.03711" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Mitigating Estimation Errors by Twin TD-Regularized Actor and Critic for  Deep Reinforcement Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhong%2C+J">Junmin Zhong</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+R">Ruofan Wu</a>, 
<a href="/search/cs?searchtype=author&query=Si%2C+J">Jennie Si</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">We address the issue of estimation bias in deep reinforcement learning (DRL)
by introducing solution mechanisms that include a new, twin TD-regularized
actor-critic (TDR) method. It aims at reducing both over and under-estimation
errors. With TDR and by combining good DRL improvements, such as distributional
learning and long N-step surrogate stage reward (LNSS) method, we show that our
new TDR-based actor-critic learning has enabled DRL methods to outperform their
respective baselines in challenging environments in DeepMind Control Suite.
Furthermore, they elevate TD3 and SAC respectively to a level of performance
comparable to that of D4PG (the current SOTA), and they also improve the
performance of D4PG to a new SOTA level measured by mean reward, convergence
speed, learning success rate, and learning variance.
</p>
</div>
</dd>
<dt><a name="item157">[157]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03712" title="Abstract">arXiv:2311.03712</a> [<a href="/pdf/2311.03712" title="Download PDF">pdf</a>, <a href="/format/2311.03712" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Contributions of Individual Generators to Nodal Carbon Emissions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Chen%2C+Y">Yize Chen</a>, 
<a href="/search/eess?searchtype=author&query=Deka%2C+D">Deepyjoti Deka</a>, 
<a href="/search/eess?searchtype=author&query=Shi%2C+Y">Yuanyuan Shi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at ACM e-Energy 2024. Code available at <a href="https://github.com/chennnnnyize/Carbon_Emission_Power_Grids">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">Recent shifts toward sustainable energy systems have witnessed the fast
deployment of carbon-free and carbon-efficient generations across the power
networks. However, the benefits of carbon reduction are not experienced evenly
throughout the grid. Each generator can have distinct carbon emission rates.
Due to the existence of physical power flows, nodal power consumption is met by
a combination of a set of generators, while such combination is determined by
network topology, generators' characteristics and power demand. This paper
describes a technique based on physical power flow model, which can efficiently
compute the nodal carbon emissions contributed by each single generator given
the generation and power flow information. We also extend the technique to
calculate both the nodal average carbon emission and marginal carbon emission
rates. Simulation results validate the effectiveness of the calculations, while
our technique provides a fundamental tool for applications such as carbon
auditing, carbon-oriented demand management and future carbon-oriented capacity
expansion.
</p>
</div>
</dd>
<dt><a name="item158">[158]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03714" title="Abstract">arXiv:2311.03714</a> [<a href="/pdf/2311.03714" title="Download PDF">pdf</a>, <a href="/ps/2311.03714" title="Download PostScript">ps</a>, <a href="/format/2311.03714" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Loss Balancing for Fair Supervised Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Khalili%2C+M+M">Mohammad Mahdi Khalili</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xueru Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Abroshan%2C+M">Mahed Abroshan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This paper has been published in the Fortieth International Conference on Machine Learning (ICML 2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Supervised learning models have been used in various domains such as lending,
college admission, face recognition, natural language processing, etc. However,
they may inherit pre-existing biases from training data and exhibit
discrimination against protected social groups. Various fairness notions have
been proposed to address unfairness issues. In this work, we focus on Equalized
Loss (EL), a fairness notion that requires the expected loss to be
(approximately) equalized across different groups. Imposing EL on the learning
process leads to a non-convex optimization problem even if the loss function is
convex, and the existing fair learning algorithms cannot properly be adopted to
find the fair predictor under the EL constraint. This paper introduces an
algorithm that can leverage off-the-shelf convex programming tools (e.g.,
CVXPY) to efficiently find the global optimum of this non-convex optimization.
In particular, we propose the ELminimizer algorithm, which finds the optimal
fair predictor under EL by reducing the non-convex optimization to a sequence
of convex optimization problems. We theoretically prove that our algorithm
finds the global optimal solution under certain conditions. Then, we support
our theoretical results through several empirical studies.
</p>
</div>
</dd>
<dt><a name="item159">[159]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03716" title="Abstract">arXiv:2311.03716</a> [<a href="/pdf/2311.03716" title="Download PDF">pdf</a>, <a href="/ps/2311.03716" title="Download PostScript">ps</a>, <a href="/format/2311.03716" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LLM as an Art Director (LaDi): Using LLMs to improve Text-to-Media  Generators
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Roush%2C+A">Allen Roush</a>, 
<a href="/search/cs?searchtype=author&query=Zakirov%2C+E">Emil Zakirov</a>, 
<a href="/search/cs?searchtype=author&query=Shirokov%2C+A">Artemiy Shirokov</a>, 
<a href="/search/cs?searchtype=author&query=Lunina%2C+P">Polina Lunina</a>, 
<a href="/search/cs?searchtype=author&query=Gane%2C+J">Jack Gane</a>, 
<a href="/search/cs?searchtype=author&query=Duffy%2C+A">Alexander Duffy</a>, 
<a href="/search/cs?searchtype=author&query=Basil%2C+C">Charlie Basil</a>, 
<a href="/search/cs?searchtype=author&query=Whitcomb%2C+A">Aber Whitcomb</a>, 
<a href="/search/cs?searchtype=author&query=Benedetto%2C+J">Jim Benedetto</a>, 
<a href="/search/cs?searchtype=author&query=DeWolfe%2C+C">Chris DeWolfe</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, System Demonstration/Industry paper. Preprint
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Recent advancements in text-to-image generation have revolutionized numerous
fields, including art and cinema, by automating the generation of high-quality,
context-aware images and video. However, the utility of these technologies is
often limited by the inadequacy of text prompts in guiding the generator to
produce artistically coherent and subject-relevant images. In this paper, We
describe the techniques that can be used to make Large Language Models (LLMs)
act as Art Directors that enhance image and video generation. We describe our
unified system for this called "LaDi". We explore how LaDi integrates multiple
techniques for augmenting the capabilities of text-to-image generators (T2Is)
and text-to-video generators (T2Vs), with a focus on constrained decoding,
intelligent prompting, fine-tuning, and retrieval. LaDi and these techniques
are being used today in apps and platforms developed by Plai Labs.
</p>
</div>
</dd>
<dt><a name="item160">[160]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03721" title="Abstract">arXiv:2311.03721</a> [<a href="/pdf/2311.03721" title="Download PDF">pdf</a>, <a href="/format/2311.03721" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ClimateSet: A Large-Scale Climate Model Dataset for Machine Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kaltenborn%2C+J">Julia Kaltenborn</a>, 
<a href="/search/cs?searchtype=author&query=Lange%2C+C+E+E">Charlotte E. E. Lange</a>, 
<a href="/search/cs?searchtype=author&query=Ramesh%2C+V">Venkatesh Ramesh</a>, 
<a href="/search/cs?searchtype=author&query=Brouillard%2C+P">Philippe Brouillard</a>, 
<a href="/search/cs?searchtype=author&query=Gurwicz%2C+Y">Yaniv Gurwicz</a>, 
<a href="/search/cs?searchtype=author&query=Nagda%2C+C">Chandni Nagda</a>, 
<a href="/search/cs?searchtype=author&query=Runge%2C+J">Jakob Runge</a>, 
<a href="/search/cs?searchtype=author&query=Nowack%2C+P">Peer Nowack</a>, 
<a href="/search/cs?searchtype=author&query=Rolnick%2C+D">David Rolnick</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To be published in the 37th Conference on Neural Information Processing Systems (NeurIPS 2023): Track on Datasets and Benchmarks. Project website: <a href="https://climateset.github.io/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computational Engineering, Finance, and Science (cs.CE); Atmospheric and Oceanic Physics (physics.ao-ph)

</div>
<p class="mathjax">Climate models have been key for assessing the impact of climate change and
simulating future climate scenarios. The machine learning (ML) community has
taken an increased interest in supporting climate scientists' efforts on
various tasks such as climate model emulation, downscaling, and prediction
tasks. Many of those tasks have been addressed on datasets created with single
climate models. However, both the climate science and ML communities have
suggested that to address those tasks at scale, we need large, consistent, and
ML-ready climate model datasets. Here, we introduce ClimateSet, a dataset
containing the inputs and outputs of 36 climate models from the Input4MIPs and
CMIP6 archives. In addition, we provide a modular dataset pipeline for
retrieving and preprocessing additional climate models and scenarios. We
showcase the potential of our dataset by using it as a benchmark for ML-based
climate model emulation. We gain new insights about the performance and
generalization capabilities of the different ML models by analyzing their
performance across different climate models. Furthermore, the dataset can be
used to train an ML emulator on several climate models instead of just one.
Such a "super emulator" can quickly project new climate change scenarios,
complementing existing scenarios already provided to policymakers. We believe
ClimateSet will create the basis needed for the ML community to tackle
climate-related tasks at scale.
</p>
</div>
</dd>
<dt><a name="item161">[161]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03722" title="Abstract">arXiv:2311.03722</a> [<a href="/pdf/2311.03722" title="Download PDF">pdf</a>, <a href="/format/2311.03722" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Inertial Guided Uncertainty Estimation of Feature Correspondence in  Visual-Inertial Odometry/SLAM
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yoon%2C+S">Seongwook Yoon</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+J">Jaehyun Kim</a>, 
<a href="/search/cs?searchtype=author&query=Sull%2C+S">Sanghoon Sull</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Visual odometry and Simultaneous Localization And Mapping (SLAM) has been
studied as one of the most important tasks in the areas of computer vision and
robotics, to contribute to autonomous navigation and augmented reality systems.
In case of feature-based odometry/SLAM, a moving visual sensor observes a set
of 3D points from different viewpoints, correspondences between the projected
2D points in each image are usually established by feature tracking and
matching. However, since the corresponding point could be erroneous and noisy,
reliable uncertainty estimation can improve the accuracy of odometry/SLAM
methods. In addition, inertial measurement unit is utilized to aid the visual
sensor in terms of Visual-Inertial fusion. In this paper, we propose a method
to estimate the uncertainty of feature correspondence using an inertial
guidance robust to image degradation caused by motion blur, illumination change
and occlusion. Modeling a guidance distribution to sample possible
correspondence, we fit the distribution to an energy function based on image
error, yielding more robust uncertainty than conventional methods. We also
demonstrate the feasibility of our approach by incorporating it into one of
recent visual-inertial odometry/SLAM algorithms for public datasets.
</p>
</div>
</dd>
<dt><a name="item162">[162]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03725" title="Abstract">arXiv:2311.03725</a> [<a href="/pdf/2311.03725" title="Download PDF">pdf</a>, <a href="/ps/2311.03725" title="Download PostScript">ps</a>, <a href="/format/2311.03725" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DeepInspect: An AI-Powered Defect Detection for Manufacturing Industries
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kumbhar%2C+A">Arti Kumbhar</a>, 
<a href="/search/cs?searchtype=author&query=Chougale%2C+A">Amruta Chougale</a>, 
<a href="/search/cs?searchtype=author&query=Lokhande%2C+P">Priya Lokhande</a>, 
<a href="/search/cs?searchtype=author&query=Navaghane%2C+S">Saloni Navaghane</a>, 
<a href="/search/cs?searchtype=author&query=Burud%2C+A">Aditi Burud</a>, 
<a href="/search/cs?searchtype=author&query=Nimbalkar%2C+S">Saee Nimbalkar</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Research Paper for Defect Detection for Manufacturing Industries Using Deep Learning Techniques: 5 pages, 8 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Image and Video Processing (eess.IV)

</div>
<p class="mathjax">Utilizing Convolutional Neural Networks (CNNs), Recurrent Neural Networks
(RNNs), and Generative Adversarial Networks (GANs), our system introduces an
innovative approach to defect detection in manufacturing. This technology
excels in precisely identifying faults by extracting intricate details from
product photographs, utilizing RNNs to detect evolving errors and generating
synthetic defect data to bolster the model's robustness and adaptability across
various defect scenarios. The project leverages a deep learning framework to
automate real-time flaw detection in the manufacturing process. It harnesses
extensive datasets of annotated images to discern complex defect patterns. This
integrated system seamlessly fits into production workflows, thereby boosting
efficiency and elevating product quality. As a result, it reduces waste and
operational costs, ultimately enhancing market competitiveness.
</p>
</div>
</dd>
<dt><a name="item163">[163]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03731" title="Abstract">arXiv:2311.03731</a> [<a href="/pdf/2311.03731" title="Download PDF">pdf</a>, <a href="/format/2311.03731" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Survey of Large Language Models Attribution
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+D">Dongfang Li</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+Z">Zetian Sun</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+X">Xinshuo Hu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zhenyu Liu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Z">Ziyang Chen</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+B">Baotian Hu</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+A">Aiguo Wu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+M">Min Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Open-domain generative systems have gained significant attention in the field
of conversational AI (e.g., generative search engines). This paper presents a
comprehensive review of the attribution mechanisms employed by these systems,
particularly large language models. Though attribution or citation improve the
factuality and verifiability, issues like ambiguous knowledge reservoirs,
inherent biases, and the drawbacks of excessive attribution can hinder the
effectiveness of these systems. The aim of this survey is to provide valuable
insights for researchers, aiding in the refinement of attribution methodologies
to enhance the reliability and veracity of responses generated by open-domain
generative systems. We believe that this field is still in its early stages;
hence, we maintain a repository to keep track of ongoing studies at
https://github.com/HITsz-TMG/awesome-llm-attributions.
</p>
</div>
</dd>
<dt><a name="item164">[164]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03732" title="Abstract">arXiv:2311.03732</a> [<a href="/pdf/2311.03732" title="Download PDF">pdf</a>, <a href="/format/2311.03732" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning to Learn for Few-shot Continual Active Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ho%2C+S">Stella Ho</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+M">Ming Liu</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+S">Shang Gao</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+L">Longxiang Gao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computation and Language (cs.CL)

</div>
<p class="mathjax">Continual learning strives to ensure stability in solving previously seen
tasks while demonstrating plasticity in a novel domain. Recent advances in CL
are mostly confined to a supervised learning setting, especially in NLP domain.
In this work, we consider a few-shot continual active learning (CAL) setting
where labeled data is inadequate, and unlabeled data is abundant but with a
limited annotation budget. We propose a simple but efficient method, called
Meta-Continual Active Learning. Specifically, we employ meta-learning and
experience replay to address the trade-off between stability and plasticity. As
a result, it finds an optimal initialization that efficiently utilizes
annotated information for fast adaptation while preventing catastrophic
forgetting of past tasks. We conduct extensive experiments to validate the
effectiveness of the proposed method and analyze the effect of various active
learning strategies and memory sample selection methods in a few-shot CAL
setup. Our experiment results demonstrate that random sampling is the best
default strategy for both active learning and memory sample selection to solve
few-shot CAL problems.
</p>
</div>
</dd>
<dt><a name="item165">[165]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03733" title="Abstract">arXiv:2311.03733</a> [<a href="/pdf/2311.03733" title="Download PDF">pdf</a>, <a href="/format/2311.03733" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Improved weight initialization for deep and narrow feedforward neural  network
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lee%2C+H">Hyunwoo Lee</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+Y">Yunho Kim</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+S">Seungyeop Yang</a>, 
<a href="/search/cs?searchtype=author&query=Choi%2C+H">Hayoung Choi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 page
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Neural and Evolutionary Computing (cs.NE)

</div>
<p class="mathjax">Appropriate weight initialization settings, along with the ReLU activation
function, have been a cornerstone of modern deep learning, making it possible
to train and deploy highly effective and efficient neural network models across
diverse artificial intelligence. The problem of dying ReLU, where ReLU neurons
become inactive and yield zero output, presents a significant challenge in the
training of deep neural networks with ReLU activation function. Theoretical
research and various methods have been introduced to address the problem.
However, even with these methods and research, training remains challenging for
extremely deep and narrow feedforward networks with ReLU activation function.
In this paper, we propose a new weight initialization method to address this
issue. We prove the properties of the proposed initial weight matrix and
demonstrate how these properties facilitate the effective propagation of signal
vectors. Through a series of experiments and comparisons with existing methods,
we demonstrate the effectiveness of the new initialization method.
</p>
</div>
</dd>
<dt><a name="item166">[166]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03734" title="Abstract">arXiv:2311.03734</a> [<a href="/pdf/2311.03734" title="Download PDF">pdf</a>, <a href="/format/2311.03734" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Leveraging Structured Information for Explainable Multi-hop Question  Answering and Reasoning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+R">Ruosen Li</a>, 
<a href="/search/cs?searchtype=author&query=Du%2C+X">Xinya Du</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Findings of EMNLP 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Neural models, including large language models (LLMs), achieve superior
performance on multi-hop question-answering. To elicit reasoning capabilities
from LLMs, recent works propose using the chain-of-thought (CoT) mechanism to
generate both the reasoning chain and the answer, which enhances the model's
capabilities in conducting multi-hop reasoning. However, several challenges
still remain: such as struggling with inaccurate reasoning, hallucinations, and
lack of interpretability. On the other hand, information extraction (IE)
identifies entities, relations, and events grounded to the text. The extracted
structured information can be easily interpreted by humans and machines
(Grishman, 2019). In this work, we investigate constructing and leveraging
extracted semantic structures (graphs) for multi-hop question answering,
especially the reasoning process. Empirical results and human evaluations show
that our framework: generates more faithful reasoning chains and substantially
improves the QA performance on two benchmark datasets. Moreover, the extracted
structures themselves naturally provide grounded explanations that are
preferred by humans, as compared to the generated reasoning chains and
saliency-based explanations.
</p>
</div>
</dd>
<dt><a name="item167">[167]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03736" title="Abstract">arXiv:2311.03736</a> [<a href="/pdf/2311.03736" title="Download PDF">pdf</a>, <a href="/format/2311.03736" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Neural MMO 2.0: A Massively Multi-task Addition to Massively Multi-agent  Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Su%C3%A1rez%2C+J">Joseph Su&#xe1;rez</a>, 
<a href="/search/cs?searchtype=author&query=Isola%2C+P">Phillip Isola</a>, 
<a href="/search/cs?searchtype=author&query=Choe%2C+K+W">Kyoung Whan Choe</a>, 
<a href="/search/cs?searchtype=author&query=Bloomin%2C+D">David Bloomin</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+H+X">Hao Xiang Li</a>, 
<a href="/search/cs?searchtype=author&query=Pinnaparaju%2C+N">Nikhil Pinnaparaju</a>, 
<a href="/search/cs?searchtype=author&query=Kanna%2C+N">Nishaanth Kanna</a>, 
<a href="/search/cs?searchtype=author&query=Scott%2C+D">Daniel Scott</a>, 
<a href="/search/cs?searchtype=author&query=Sullivan%2C+R">Ryan Sullivan</a>, 
<a href="/search/cs?searchtype=author&query=Shuman%2C+R+S">Rose S. Shuman</a>, 
<a href="/search/cs?searchtype=author&query=de+Alc%C3%A2ntara%2C+L">Lucas de Alc&#xe2;ntara</a>, 
<a href="/search/cs?searchtype=author&query=Bradley%2C+H">Herbie Bradley</a>, 
<a href="/search/cs?searchtype=author&query=Castricato%2C+L">Louis Castricato</a>, 
<a href="/search/cs?searchtype=author&query=You%2C+K">Kirsty You</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+Y">Yuhao Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Q">Qimai Li</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Jiaxin Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+X">Xiaolong Zhu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Machine Learning (cs.LG); Multiagent Systems (cs.MA)

</div>
<p class="mathjax">Neural MMO 2.0 is a massively multi-agent environment for reinforcement
learning research. The key feature of this new version is a flexible task
system that allows users to define a broad range of objectives and reward
signals. We challenge researchers to train agents capable of generalizing to
tasks, maps, and opponents never seen during training. Neural MMO features
procedurally generated maps with 128 agents in the standard setting and support
for up to. Version 2.0 is a complete rewrite of its predecessor with three-fold
improved performance and compatibility with CleanRL. We release the platform as
free and open-source software with comprehensive documentation available at
neuralmmo.github.io and an active community Discord. To spark initial research
on this new platform, we are concurrently running a competition at NeurIPS
2023.
</p>
</div>
</dd>
<dt><a name="item168">[168]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03737" title="Abstract">arXiv:2311.03737</a> [<a href="/pdf/2311.03737" title="Download PDF">pdf</a>, <a href="/ps/2311.03737" title="Download PostScript">ps</a>, <a href="/format/2311.03737" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Lagrangian Modelling and Motion Stability of Synchronous Generator Power  Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Ji%2C+F">Feng Ji</a>, 
<a href="/search/eess?searchtype=author&query=Gao%2C+L">Lu Gao</a>, 
<a href="/search/eess?searchtype=author&query=Lin%2C+C">Chang Lin</a>, 
<a href="/search/eess?searchtype=author&query=Liu%2C+Y">Yang Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 20 pages, 11 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">This paper proposes to analyze the motion stability of synchro-nous generator
power systems using a Lagrangian model derived in the configuration space of
generalized position and speed. In the first place, a Lagrangian model of
synchronous generators is derived based on Lagrangian mechanics. The
generalized potential energy of inductors and generalized kinetic energy of
capacitors are defined. The mechanical and electrical dynamics can be modelled
in a unified manner through constructing a Lagrangian function. Taking the
first benchmark model of subsynchronous oscillation as an example, a Lagragian
model is construct-ed and numerical solution of the model is obtained to
validate the accuracy and effectiveness of the model. Compared with the
traditional EMTP model in PSCAD, the obtained Lagrangian model is able to
accurately describe the electromagnetic transient process of the system.
Moreover, the Lagrangian model is analytical, which enables to analyze the
motion stability of the system using Lyapunov motion stability theory. The
Lagrangian model can not only be used to discuss the power angle stability, but
also used for analyzing the stability of node voltages and frequency. It
provides the feasibility for studying the unified stability of power systems.
</p>
</div>
</dd>
<dt><a name="item169">[169]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03739" title="Abstract">arXiv:2311.03739</a> [<a href="/pdf/2311.03739" title="Download PDF">pdf</a>, <a href="/format/2311.03739" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Leveraging Large Language Models for Automated Proof Synthesis in Rust
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yao%2C+J">Jianan Yao</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Z">Ziqiao Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+W">Weiteng Chen</a>, 
<a href="/search/cs?searchtype=author&query=Cui%2C+W">Weidong Cui</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Formal Languages and Automata Theory (cs.FL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Formal verification can provably guarantee the correctness of critical system
software, but the high proof burden has long hindered its wide adoption.
Recently, Large Language Models (LLMs) have shown success in code analysis and
synthesis. In this paper, we present a combination of LLMs and static analysis
to synthesize invariants, assertions, and other proof structures for a
Rust-based formal verification framework called Verus. In a few-shot setting,
LLMs demonstrate impressive logical ability in generating postconditions and
loop invariants, especially when analyzing short code snippets. However, LLMs
lack the ability to retain and propagate context information, a strength of
traditional static analysis. Based on these observations, we developed a
prototype based on OpenAI's GPT-4 model. Our prototype decomposes the
verification task into multiple smaller ones, iteratively queries GPT-4, and
combines its output with lightweight static analysis. We evaluated the
prototype with a developer in the automation loop on 20 vector-manipulating
programs. The results demonstrate that it significantly reduces human effort in
writing entry-level proof code.
</p>
</div>
</dd>
<dt><a name="item170">[170]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03742" title="Abstract">arXiv:2311.03742</a> [<a href="/pdf/2311.03742" title="Download PDF">pdf</a>, <a href="/format/2311.03742" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> 3DifFusionDet: Diffusion Model for 3D Object Detection with Robust  LiDAR-Camera Fusion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xiang%2C+X">Xinhao Xiang</a>, 
<a href="/search/cs?searchtype=author&query=Dr%C3%A4ger%2C+S">Simon Dr&#xe4;ger</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jiawei Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Good 3D object detection performance from LiDAR-Camera sensors demands
seamless feature alignment and fusion strategies. We propose the 3DifFusionDet
framework in this paper, which structures 3D object detection as a denoising
diffusion process from noisy 3D boxes to target boxes. In this framework,
ground truth boxes diffuse in a random distribution for training, and the model
learns to reverse the noising process. During inference, the model gradually
refines a set of boxes that were generated at random to the outcomes. Under the
feature align strategy, the progressive refinement method could make a
significant contribution to robust LiDAR-Camera fusion. The iterative
refinement process could also demonstrate great adaptability by applying the
framework to various detecting circumstances where varying levels of accuracy
and speed are required. Extensive experiments on KITTI, a benchmark for
real-world traffic object identification, revealed that 3DifFusionDet is able
to perform favorably in comparison to earlier, well-respected detectors.
</p>
</div>
</dd>
<dt><a name="item171">[171]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03745" title="Abstract">arXiv:2311.03745</a> [<a href="/pdf/2311.03745" title="Download PDF">pdf</a>, <a href="/format/2311.03745" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Unsupervised Video Summarization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Hanqing Li</a>, 
<a href="/search/cs?searchtype=author&query=Klabjan%2C+D">Diego Klabjan</a>, 
<a href="/search/cs?searchtype=author&query=Utke%2C+J">Jean Utke</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">This paper introduces a new, unsupervised method for automatic video
summarization using ideas from generative adversarial networks but eliminating
the discriminator, having a simple loss function, and separating training of
different parts of the model. An iterative training strategy is also applied by
alternately training the reconstructor and the frame selector for multiple
iterations. Furthermore, a trainable mask vector is added to the model in
summary generation during training and evaluation. The method also includes an
unsupervised model selection algorithm. Results from experiments on two public
datasets (SumMe and TVSum) and four datasets we created (Soccer, LoL, MLB, and
ShortMLB) demonstrate the effectiveness of each component on the model
performance, particularly the iterative training strategy. Evaluations and
comparisons with the state-of-the-art methods highlight the advantages of the
proposed method in performance, stability, and training efficiency.
</p>
</div>
</dd>
<dt><a name="item172">[172]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03746" title="Abstract">arXiv:2311.03746</a> [<a href="/pdf/2311.03746" title="Download PDF">pdf</a>, <a href="/format/2311.03746" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Enhanced physics-informed neural networks with domain scaling and  residual correction methods for multi-frequency elliptic problems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Jang%2C+D">Deok-Kyu Jang</a>, 
<a href="/search/math?searchtype=author&query=Kim%2C+H+H">Hyea Hyun Kim</a>, 
<a href="/search/math?searchtype=author&query=Kim%2C+K">Kyungsoo Kim</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Machine Learning (cs.LG); Computational Physics (physics.comp-ph)

</div>
<p class="mathjax">In this paper, neural network approximation methods are developed for
elliptic partial differential equations with multi-frequency solutions. Neural
network work approximation methods have advantages over classical approaches in
that they can be applied without much concerns on the form of the differential
equations or the shape or dimension of the problem domain. When applied to
problems with multi-frequency solutions, the performance and accuracy of neural
network approximation methods are strongly affected by the contrast of the
high- and low-frequency parts in the solutions. To address this issue, domain
scaling and residual correction methods are proposed. The efficiency and
accuracy of the proposed methods are demonstrated for multi-frequency model
problems.
</p>
</div>
</dd>
<dt><a name="item173">[173]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03747" title="Abstract">arXiv:2311.03747</a> [<a href="/pdf/2311.03747" title="Download PDF">pdf</a>, <a href="/ps/2311.03747" title="Download PostScript">ps</a>, <a href="/format/2311.03747" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SBCFormer: Lightweight Network Capable of Full-size ImageNet  Classification at 1 FPS on Single Board Computers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lu%2C+X">Xiangyong Lu</a>, 
<a href="/search/cs?searchtype=author&query=Suganuma%2C+M">Masanori Suganuma</a>, 
<a href="/search/cs?searchtype=author&query=Okatani%2C+T">Takayuki Okatani</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages, 2 figures, WACV2024
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Proceedings of the IEEE/CVF Winter Conference on Applications of
  Computer Vision (WACV2024)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Computer vision has become increasingly prevalent in solving real-world
problems across diverse domains, including smart agriculture, fishery, and
livestock management. These applications may not require processing many image
frames per second, leading practitioners to use single board computers (SBCs).
Although many lightweight networks have been developed for mobile/edge devices,
they primarily target smartphones with more powerful processors and not SBCs
with the low-end CPUs. This paper introduces a CNN-ViT hybrid network called
SBCFormer, which achieves high accuracy and fast computation on such low-end
CPUs. The hardware constraints of these CPUs make the Transformer's attention
mechanism preferable to convolution. However, using attention on low-end CPUs
presents a challenge: high-resolution internal feature maps demand excessive
computational resources, but reducing their resolution results in the loss of
local image details. SBCFormer introduces an architectural design to address
this issue. As a result, SBCFormer achieves the highest trade-off between
accuracy and speed on a Raspberry Pi 4 Model B with an ARM-Cortex A72 CPU. For
the first time, it achieves an ImageNet-1K top-1 accuracy of around 80% at a
speed of 1.0 frame/sec on the SBC. Code is available at
https://github.com/xyongLu/SBCFormer.
</p>
</div>
</dd>
<dt><a name="item174">[174]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03748" title="Abstract">arXiv:2311.03748</a> [<a href="/pdf/2311.03748" title="Download PDF">pdf</a>, <a href="/format/2311.03748" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Unified Low-Resource Sequence Labeling by Sample-Aware Dynamic Sparse  Finetuning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Das%2C+S+S+S">Sarkar Snigdha Sarathi Das</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+R+H">Ranran Haoran Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+P">Peng Shi</a>, 
<a href="/search/cs?searchtype=author&query=Yin%2C+W">Wenpeng Yin</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+R">Rui Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by EMNLP 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Unified Sequence Labeling that articulates different sequence labeling
problems such as Named Entity Recognition, Relation Extraction, Semantic Role
Labeling, etc. in a generalized sequence-to-sequence format opens up the
opportunity to make the maximum utilization of large language model knowledge
toward structured prediction. Unfortunately, this requires formatting them into
specialized augmented format unknown to the base pretrained language model
(PLMs) necessitating finetuning to the target format. This significantly bounds
its usefulness in data-limited settings where finetuning large models cannot
properly generalize to the target format. To address this challenge and
leverage PLM knowledge effectively, we propose FISH-DIP, a sample-aware dynamic
sparse finetuning strategy that selectively focuses on a fraction of
parameters, informed by feedback from highly regressing examples, during the
fine-tuning process. By leveraging the dynamism of sparsity, our approach
mitigates the impact of well-learned samples and prioritizes underperforming
instances for improvement in generalization. Across five tasks of sequence
labeling, we demonstrate that FISH-DIP can smoothly optimize the model in low
resource settings offering upto 40% performance improvements over full
fine-tuning depending on target evaluation settings. Also, compared to
in-context learning and other parameter-efficient fine-tuning approaches,
FISH-DIP performs comparably or better, notably in extreme low-resource
settings.
</p>
</div>
</dd>
<dt><a name="item175">[175]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03749" title="Abstract">arXiv:2311.03749</a> [<a href="/pdf/2311.03749" title="Download PDF">pdf</a>, <a href="/ps/2311.03749" title="Download PostScript">ps</a>, <a href="/format/2311.03749" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multiclass Segmentation using Teeth Attention Modules for Dental X-ray  Images
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ghafoor%2C+A">Afnan Ghafoor</a>, 
<a href="/search/cs?searchtype=author&query=Moon%2C+S">Seong-Yong Moon</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+B">Bumshik Lee</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">This paper proposed a cutting-edge multiclass teeth segmentation architecture
that integrates an M-Net-like structure with Swin Transformers and a novel
component named Teeth Attention Block (TAB). Existing teeth image segmentation
methods have issues with less accurate and unreliable segmentation outcomes due
to the complex and varying morphology of teeth, although teeth segmentation in
dental panoramic images is essential for dental disease diagnosis. We propose a
novel teeth segmentation model incorporating an M-Net-like structure with Swin
Transformers and TAB. The proposed TAB utilizes a unique attention mechanism
that focuses specifically on the complex structures of teeth. The attention
mechanism in TAB precisely highlights key elements of teeth features in
panoramic images, resulting in more accurate segmentation outcomes. The
proposed architecture effectively captures local and global contextual
information, accurately defining each tooth and its surrounding structures.
Furthermore, we employ a multiscale supervision strategy, which leverages the
left and right legs of the U-Net structure, boosting the performance of the
segmentation with enhanced feature representation. The squared Dice loss is
utilized to tackle the class imbalance issue, ensuring accurate segmentation
across all classes. The proposed method was validated on a panoramic teeth
X-ray dataset, which was taken in a real-world dental diagnosis. The
experimental results demonstrate the efficacy of our proposed architecture for
tooth segmentation on multiple benchmark dental image datasets, outperforming
existing state-of-the-art methods in objective metrics and visual examinations.
This study has the potential to significantly enhance dental image analysis and
contribute to advances in dental applications.
</p>
</div>
</dd>
<dt><a name="item176">[176]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03753" title="Abstract">arXiv:2311.03753</a> [<a href="/pdf/2311.03753" title="Download PDF">pdf</a>, <a href="/format/2311.03753" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> COOL: A Constraint Object-Oriented Logic Programming Language and its  Neural-Symbolic Compilation System
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Han%2C+J">Jipeng Han</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 48 pages, 8 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computation and Language (cs.CL); Distributed, Parallel, and Cluster Computing (cs.DC); Formal Languages and Automata Theory (cs.FL); Human-Computer Interaction (cs.HC)

</div>
<p class="mathjax">This paper explores the integration of neural networks with logic
programming, addressing the longstanding challenges of combining the
generalization and learning capabilities of neural networks with the precision
of symbolic logic. Traditional attempts at this integration have been hampered
by difficulties in initial data acquisition, the reliability of undertrained
networks, and the complexity of reusing and augmenting trained models. To
overcome these issues, we introduce the COOL (Constraint Object-Oriented Logic)
programming language, an innovative approach that seamlessly combines logical
reasoning with neural network technologies. COOL is engineered to autonomously
handle data collection, mitigating the need for user-supplied initial data. It
incorporates user prompts into the coding process to reduce the risks of
undertraining and enhances the interaction among models throughout their
lifecycle to promote the reuse and augmentation of networks. Furthermore, the
foundational principles and algorithms in COOL's design and its compilation
system could provide valuable insights for future developments in programming
languages and neural network architectures.
</p>
</div>
</dd>
<dt><a name="item177">[177]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03754" title="Abstract">arXiv:2311.03754</a> [<a href="/pdf/2311.03754" title="Download PDF">pdf</a>, <a href="/format/2311.03754" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Which is better? Exploring Prompting Strategy For LLM-based Metrics
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kim%2C+J">Joonghoon Kim</a>, 
<a href="/search/cs?searchtype=author&query=Park%2C+S">Saeran Park</a>, 
<a href="/search/cs?searchtype=author&query=Jeong%2C+K">Kiyoon Jeong</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+S">Sangmin Lee</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+S+H">Seung Hun Han</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+J">Jiyoon Lee</a>, 
<a href="/search/cs?searchtype=author&query=Kang%2C+P">Pilsung Kang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Eval4NLP 2023 shared task winner on both Small and Large model Track for Summarization
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">This paper describes the DSBA submissions to the Prompting Large Language
Models as Explainable Metrics shared task, where systems were submitted to two
tracks: small and large summarization tracks. With advanced Large Language
Models (LLMs) such as GPT-4, evaluating the quality of Natural Language
Generation (NLG) has become increasingly paramount. Traditional
similarity-based metrics such as BLEU and ROUGE have shown to misalign with
human evaluation and are ill-suited for open-ended generation tasks. To address
this issue, we explore the potential capability of LLM-based metrics,
especially leveraging open-source LLMs. In this study, wide range of prompts
and prompting techniques are systematically analyzed with three approaches:
prompting strategy, score aggregation, and explainability. Our research focuses
on formulating effective prompt templates, determining the granularity of NLG
quality scores and assessing the impact of in-context examples on LLM-based
evaluation. Furthermore, three aggregation strategies are compared to identify
the most reliable method for aggregating NLG quality scores. To examine
explainability, we devise a strategy that generates rationales for the scores
and analyzes the characteristics of the explanation produced by the open-source
LLMs. Extensive experiments provide insights regarding evaluation capabilities
of open-source LLMs and suggest effective prompting strategies.
</p>
</div>
</dd>
<dt><a name="item178">[178]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03755" title="Abstract">arXiv:2311.03755</a> [<a href="/pdf/2311.03755" title="Download PDF">pdf</a>, <a href="/format/2311.03755" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multilingual Mathematical Autoformalization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jiang%2C+A+Q">Albert Q. Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+W">Wenda Li</a>, 
<a href="/search/cs?searchtype=author&query=Jamnik%2C+M">Mateja Jamnik</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Autoformalization is the task of translating natural language materials into
machine-verifiable formalisations. Progress in autoformalization research is
hindered by the lack of a sizeable dataset consisting of informal-formal pairs
expressing the same essence. Existing methods tend to circumvent this challenge
by manually curating small corpora or using few-shot learning with large
language models. But these methods suffer from data scarcity and formal
language acquisition difficulty. In this work, we create $\texttt{MMA}$, a
large, flexible, multilingual, and multi-domain dataset of informal-formal
pairs, by using a language model to translate in the reverse direction, that
is, from formal mathematical statements into corresponding informal ones.
Experiments show that language models fine-tuned on $\texttt{MMA}$ produce
$16-18\%$ of statements acceptable with minimal corrections on the
$\texttt{miniF2F}$ and $\texttt{ProofNet}$ benchmarks, up from $0\%$ with the
base model. We demonstrate that fine-tuning on multilingual formal data results
in more capable autoformalization models even when deployed on monolingual
tasks.
</p>
</div>
</dd>
<dt><a name="item179">[179]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03756" title="Abstract">arXiv:2311.03756</a> [<a href="/pdf/2311.03756" title="Download PDF">pdf</a>, <a href="/format/2311.03756" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning Decentralized Traffic Signal Controllers with Multi-Agent Graph  Reinforcement Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yao Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+Z">Zhiwen Yu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jun Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+L">Liang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Luan%2C+T+H">Tom H. Luan</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+B">Bin Guo</a>, 
<a href="/search/cs?searchtype=author&query=Yuen%2C+C">Chau Yuen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Systems and Control (eess.SY)

</div>
<p class="mathjax">This paper considers optimal traffic signal control in smart cities, which
has been taken as a complex networked system control problem. Given the
interacting dynamics among traffic lights and road networks, attaining
controller adaptivity and scalability stands out as a primary challenge.
Capturing the spatial-temporal correlation among traffic lights under the
framework of Multi-Agent Reinforcement Learning (MARL) is a promising solution.
Nevertheless, existing MARL algorithms ignore effective information aggregation
which is fundamental for improving the learning capacity of decentralized
agents. In this paper, we design a new decentralized control architecture with
improved environmental observability to capture the spatial-temporal
correlation. Specifically, we first develop a topology-aware information
aggregation strategy to extract correlation-related information from
unstructured data gathered in the road network. Particularly, we transfer the
road network topology into a graph shift operator by forming a diffusion
process on the topology, which subsequently facilitates the construction of
graph signals. A diffusion convolution module is developed, forming a new MARL
algorithm, which endows agents with the capabilities of graph learning.
Extensive experiments based on both synthetic and real-world datasets verify
that our proposal outperforms existing decentralized algorithms.
</p>
</div>
</dd>
<dt><a name="item180">[180]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03758" title="Abstract">arXiv:2311.03758</a> [<a href="/pdf/2311.03758" title="Download PDF">pdf</a>, <a href="/format/2311.03758" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Large Language Model based Long-tail Query Rewriting in Taobao Search
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Peng%2C+W">Wenjun Peng</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+G">Guiyang Li</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+Y">Yue Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zilong Wang</a>, 
<a href="/search/cs?searchtype=author&query=Ou%2C+D">Dan Ou</a>, 
<a href="/search/cs?searchtype=author&query=Zeng%2C+X">Xiaoyi Zeng</a>, 
<a href="/search/cs?searchtype=author&query=Tongxu">Tongxu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+E">Enhong Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> WWW Industry Under Review
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>

</div>
<p class="mathjax">In the realm of e-commerce search, the significance of semantic matching
cannot be overstated, as it directly impacts both user experience and company
revenue. Query rewriting serves as an important technique to bridge semantic
gaps inherent in the semantic matching process. However, existing query
rewriting methods often struggle to effectively optimize long-tail queries and
alleviate the phenomenon of \textit{``\nothing''} caused by semantic gap. In
this paper, we present \textbf{\method}, a comprehensive framework that
\textbf{B}ridges the s\textbf{E}mantic gap for long-tail \textbf{QUE}ries.
\method comprises three stages: multi-instruction supervised fine tuning (SFT),
offline feedback, and objective alignment. Specifically, we first construct a
rewriting dataset based on rejection sampling, and mix it with multiple
auxiliary tasks data to fine tune our large language model (LLM) in a
supervised fashion during the first stage. Subsequently, with the well-trained
LLM, we employ beam search to generate multiple candidate rewrites, which would
be fed into Taobao offline system to simulate the retrieval process and obtain
the partial order. Leveraging the partial order of candidate rewrites, we
introduce a contrastive learning method to highlight the distinctions between
rewrites and align the model with the Taobao online objectives. Offline
experiments prove the effectiveness of our method in enhancing retrieval
performance. Online A/B tests reveal that our method can significantly boost
gross merchandise volume (GMV), number of transaction (\#Trans) and unique
visitor (UV) for long-tail queries. \method has been deployed on Taobao, one of
most popular online shopping platforms in China, since October 2023.
</p>
</div>
</dd>
<dt><a name="item181">[181]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03760" title="Abstract">arXiv:2311.03760</a> [<a href="/pdf/2311.03760" title="Download PDF">pdf</a>, <a href="/format/2311.03760" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Posterior Sampling-Based Bayesian Optimization with Tighter Bayesian  Regret Bounds
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Takeno%2C+S">Shion Takeno</a>, 
<a href="/search/cs?searchtype=author&query=Inatsu%2C+Y">Yu Inatsu</a>, 
<a href="/search/cs?searchtype=author&query=Karasuyama%2C+M">Masayuki Karasuyama</a>, 
<a href="/search/cs?searchtype=author&query=Takeuchi%2C+I">Ichiro Takeuchi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 28 pages, 3 figures, 2 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
<p class="mathjax">Among various acquisition functions (AFs) in Bayesian optimization (BO),
Gaussian process upper confidence bound (GP-UCB) and Thompson sampling (TS) are
well-known options with established theoretical properties regarding Bayesian
cumulative regret (BCR). Recently, it has been shown that a randomized variant
of GP-UCB achieves a tighter BCR bound compared with GP-UCB, which we call the
tighter BCR bound for brevity. Inspired by this study, this paper first shows
that TS achieves the tighter BCR bound. On the other hand, GP-UCB and TS often
practically suffer from manual hyperparameter tuning and over-exploration
issues, respectively. To overcome these difficulties, we propose yet another AF
called a probability of improvement from the maximum of a sample path (PIMS).
We show that PIMS achieves the tighter BCR bound and avoids the hyperparameter
tuning, unlike GP-UCB. Furthermore, we demonstrate a wide range of experiments,
focusing on the effectiveness of PIMS that mitigates the practical issues of
GP-UCB and TS.
</p>
</div>
</dd>
<dt><a name="item182">[182]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03761" title="Abstract">arXiv:2311.03761</a> [<a href="/pdf/2311.03761" title="Download PDF">pdf</a>, <a href="/format/2311.03761" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Augmenting Radio Signals with Wavelet Transform for Deep Learning-Based  Modulation Recognition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+T">Tao Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+S">Shilian Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Qiu%2C+K">Kunfeng Qiu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+L">Luxin Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Xuan%2C+Q">Qi Xuan</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+X">Xiaoniu Yang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Signal Processing (eess.SP)

</div>
<p class="mathjax">The use of deep learning for radio modulation recognition has become
prevalent in recent years. This approach automatically extracts
high-dimensional features from large datasets, facilitating the accurate
classification of modulation schemes. However, in real-world scenarios, it may
not be feasible to gather sufficient training data in advance. Data
augmentation is a method used to increase the diversity and quantity of
training dataset and to reduce data sparsity and imbalance. In this paper, we
propose data augmentation methods that involve replacing detail coefficients
decomposed by discrete wavelet transform for reconstructing to generate new
samples and expand the training set. Different generation methods are used to
generate replacement sequences. Simulation results indicate that our proposed
methods significantly outperform the other augmentation methods.
</p>
</div>
</dd>
<dt><a name="item183">[183]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03762" title="Abstract">arXiv:2311.03762</a> [<a href="/pdf/2311.03762" title="Download PDF">pdf</a>, <a href="/format/2311.03762" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Image change detection with only a few samples
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+K">Ke Liu</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+Z">Zhaoyi Song</a>, 
<a href="/search/cs?searchtype=author&query=Bai%2C+H">Haoyue Bai</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 7 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">This paper considers image change detection with only a small number of
samples, which is a significant problem in terms of a few annotations
available. A major impediment of image change detection task is the lack of
large annotated datasets covering a wide variety of scenes. Change detection
models trained on insufficient datasets have shown poor generalization
capability. To address the poor generalization issue, we propose using simple
image processing methods for generating synthetic but informative datasets, and
design an early fusion network based on object detection which could outperform
the siamese neural network. Our key insight is that the synthetic data enables
the trained model to have good generalization ability for various scenarios. We
compare the model trained on the synthetic data with that on the real-world
data captured from a challenging dataset, CDNet, using six different test sets.
The results demonstrate that the synthetic data is informative enough to
achieve higher generalization ability than the insufficient real-world data.
Besides, the experiment shows that utilizing a few (often tens of) samples to
fine-tune the model trained on the synthetic data will achieve excellent
results.
</p>
</div>
</dd>
<dt><a name="item184">[184]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03764" title="Abstract">arXiv:2311.03764</a> [<a href="/pdf/2311.03764" title="Download PDF">pdf</a>, <a href="/format/2311.03764" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Neuro-GPT: Developing A Foundation Model for EEG
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cui%2C+W">Wenhui Cui</a>, 
<a href="/search/cs?searchtype=author&query=Jeong%2C+W">Woojae Jeong</a>, 
<a href="/search/cs?searchtype=author&query=Th%C3%B6lke%2C+P">Philipp Th&#xf6;lke</a>, 
<a href="/search/cs?searchtype=author&query=Medani%2C+T">Takfarinas Medani</a>, 
<a href="/search/cs?searchtype=author&query=Jerbi%2C+K">Karim Jerbi</a>, 
<a href="/search/cs?searchtype=author&query=Joshi%2C+A+A">Anand A. Joshi</a>, 
<a href="/search/cs?searchtype=author&query=Leahy%2C+R+M">Richard M. Leahy</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">To handle the scarcity and heterogeneity of electroencephalography (EEG) data
in Brain-Computer Interface (BCI) tasks, and to harness the vast public data,
we propose Neuro-GPT, a foundation model consisting of an EEG encoder and a GPT
model. The foundation model is pre-trained on a large-scale public EEG dataset,
using a self-supervised task which learns how to reconstruct the masked chunk
in EEG. We then fine-tune the foundation model on a Motor Imagery
Classification task where only 9 subjects are available. Experiments
demonstrated that applying foundation model can significantly improve
classification performance compared to the model trained from scratch, which
provides evidence for the advanced generalizability of foundation model and the
ability to address the challenges of data scarcity and heterogeneity.
</p>
</div>
</dd>
<dt><a name="item185">[185]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03767" title="Abstract">arXiv:2311.03767</a> [<a href="/pdf/2311.03767" title="Download PDF">pdf</a>, <a href="/format/2311.03767" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Gender Inflected or Bias Inflicted: On Using Grammatical Gender Cues for  Bias Evaluation in Machine Translation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Singh%2C+P">Pushpdeep Singh</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages, 3 figures, 3 tables, Accepted at AACL-IJCNLP SRW 2023 (Best Paper Award)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Neural Machine Translation (NMT) models are state-of-the-art for machine
translation. However, these models are known to have various social biases,
especially gender bias. Most of the work on evaluating gender bias in NMT has
focused primarily on English as the source language. For source languages
different from English, most of the studies use gender-neutral sentences to
evaluate gender bias. However, practically, many sentences that we encounter do
have gender information. Therefore, it makes more sense to evaluate for bias
using such sentences. This allows us to determine if NMT models can identify
the correct gender based on the grammatical gender cues in the source sentence
rather than relying on biased correlations with, say, occupation terms. To
demonstrate our point, in this work, we use Hindi as the source language and
construct two sets of gender-specific sentences: OTSC-Hindi and WinoMT-Hindi
that we use to evaluate different Hindi-English (HI-EN) NMT systems
automatically for gender bias. Our work highlights the importance of
considering the nature of language when designing such extrinsic bias
evaluation datasets.
</p>
</div>
</dd>
<dt><a name="item186">[186]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03768" title="Abstract">arXiv:2311.03768</a> [<a href="/pdf/2311.03768" title="Download PDF">pdf</a>, <a href="/format/2311.03768" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PT-Tuning: Bridging the Gap between Time Series Masked Reconstruction  and Forecasting via Prompt Token Tuning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+H">Hao Liu</a>, 
<a href="/search/cs?searchtype=author&query=Gan%2C+J">Jinrui Gan</a>, 
<a href="/search/cs?searchtype=author&query=Fan%2C+X">Xiaoxuan Fan</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yi Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+C">Chuanxian Luo</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jing Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+G">Guangxin Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Qian%2C+Y">Yucheng Qian</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+C">Changwei Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+H">Huan Ma</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+Z">Zhenyu Guo</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Self-supervised learning has been actively studied in time series domain
recently, especially for masked reconstruction. Most of these methods follow
the "Pre-training + Fine-tuning" paradigm in which a new decoder replaces the
pre-trained decoder to fit for a specific downstream task, leading to
inconsistency of upstream and downstream tasks. In this paper, we first point
out that the unification of task objectives and adaptation for task difficulty
are critical for bridging the gap between time series masked reconstruction and
forecasting. By reserving the pre-trained mask token during fine-tuning stage,
the forecasting task can be taken as a special case of masked reconstruction,
where the future values are masked and reconstructed based on history values.
It guarantees the consistency of task objectives but there is still a gap in
task difficulty. Because masked reconstruction can utilize contextual
information while forecasting can only use historical information to
reconstruct. To further mitigate the existed gap, we propose a simple yet
effective prompt token tuning (PT-Tuning) paradigm, in which all pre-trained
parameters are frozen and only a few trainable prompt tokens are added to
extended mask tokens in element-wise manner. Extensive experiments on
real-world datasets demonstrate the superiority of our proposed paradigm with
state-of-the-art performance compared to representation learning and end-to-end
supervised forecasting methods.
</p>
</div>
</dd>
<dt><a name="item187">[187]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03770" title="Abstract">arXiv:2311.03770</a> [<a href="/pdf/2311.03770" title="Download PDF">pdf</a>, <a href="/format/2311.03770" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Lightweight Portrait Matting via Regional Attention and Refinement
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhong%2C+Y">Yatao Zhong</a>, 
<a href="/search/cs?searchtype=author&query=Zharkov%2C+I">Ilya Zharkov</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">We present a lightweight model for high resolution portrait matting. The
model does not use any auxiliary inputs such as trimaps or background captures
and achieves real time performance for HD videos and near real time for 4K. Our
model is built upon a two-stage framework with a low resolution network for
coarse alpha estimation followed by a refinement network for local region
improvement. However, a naive implementation of the two-stage model suffers
from poor matting quality if not utilizing any auxiliary inputs. We address the
performance gap by leveraging the vision transformer (ViT) as the backbone of
the low resolution network, motivated by the observation that the tokenization
step of ViT can reduce spatial resolution while retain as much pixel
information as possible. To inform local regions of the context, we propose a
novel cross region attention (CRA) module in the refinement network to
propagate the contextual information across the neighboring regions. We
demonstrate that our method achieves superior results and outperforms other
baselines on three benchmark datasets while only uses $1/20$ of the FLOPS
compared to the existing state-of-the-art model.
</p>
</div>
</dd>
<dt><a name="item188">[188]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03772" title="Abstract">arXiv:2311.03772</a> [<a href="/pdf/2311.03772" title="Download PDF">pdf</a>, <a href="/format/2311.03772" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Asymptotically Steerable Finite Fourier-Bessel Transforms and Closure  under Convolution
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Farashahi%2C+A+G">Arash Ghaani Farashahi</a>, 
<a href="/search/math?searchtype=author&query=Chirikjian%2C+G+S">Gregory S. Chirikjian</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Functional Analysis (math.FA)

</div>
<p class="mathjax">This paper develops a constructive numerical scheme for Fourier-Bessel
approximations on disks compatible with convolutions supported on disks. We
address accurate finite Fourier-Bessel transforms (FFBT) and inverse finite
Fourier-Bessel transforms (iFFBT) of functions on disks using the discrete
Fourier Transform (DFT) on Cartesian grids. Whereas the DFT and its fast
implementation (FFT) are ubiquitous and are powerful for computing
convolutions, they are not exactly steerable under rotations. In contrast,
Fourier-Bessel expansions are steerable, but lose both this property and the
preservation of band limits under convolution. This work captures the best
features of both as the band limit is allowed to increase. The
convergence/error analysis and asymptotic steerability of FFBT/ iFFBT are
investigated. Conditions are established for the FFBT to converge to the
Fourier-Bessel coefficient and for the iFFBT to uniformly approximate the
Fourier-Bessel partial sums. The matrix form of the finite transforms is
discussed. The implementation of the discrete method to compute numerical
approximation of convolutions of compactly supported functions on disks is
considered as well.
</p>
</div>
</dd>
<dt><a name="item189">[189]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03774" title="Abstract">arXiv:2311.03774</a> [<a href="/pdf/2311.03774" title="Download PDF">pdf</a>, <a href="/format/2311.03774" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Meta-Adapter: An Online Few-shot Learner for Vision-Language Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cheng%2C+C">Cheng Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+L">Lin Song</a>, 
<a href="/search/cs?searchtype=author&query=Xue%2C+R">Ruoyi Xue</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Hang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+H">Hongbin Sun</a>, 
<a href="/search/cs?searchtype=author&query=Ge%2C+Y">Yixiao Ge</a>, 
<a href="/search/cs?searchtype=author&query=Shan%2C+Y">Ying Shan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">The contrastive vision-language pre-training, known as CLIP, demonstrates
remarkable potential in perceiving open-world visual concepts, enabling
effective zero-shot image recognition. Nevertheless, few-shot learning methods
based on CLIP typically require offline fine-tuning of the parameters on
few-shot samples, resulting in longer inference time and the risk of
over-fitting in certain domains. To tackle these challenges, we propose the
Meta-Adapter, a lightweight residual-style adapter, to refine the CLIP features
guided by the few-shot samples in an online manner. With a few training
samples, our method can enable effective few-shot learning capabilities and
generalize to unseen data or tasks without additional fine-tuning, achieving
competitive performance and high efficiency. Without bells and whistles, our
approach outperforms the state-of-the-art online few-shot learning method by an
average of 3.6\% on eight image classification datasets with higher inference
speed. Furthermore, our model is simple and flexible, serving as a
plug-and-play module directly applicable to downstream tasks. Without further
fine-tuning, Meta-Adapter obtains notable performance improvements in
open-vocabulary object detection and segmentation tasks.
</p>
</div>
</dd>
<dt><a name="item190">[190]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03775" title="Abstract">arXiv:2311.03775</a> [<a href="/pdf/2311.03775" title="Download PDF">pdf</a>, <a href="/ps/2311.03775" title="Download PostScript">ps</a>, <a href="/format/2311.03775" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multi-Beam Forming with Movable-Antenna Array
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ma%2C+W">Wenyan Ma</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+L">Lipeng Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+R">Rui Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages, 4 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">Conventional multi-beam forming with fixed-position antenna (FPA) arrays
needs to trade-off between maximizing the beamforming gain over desired
directions and minimizing the interference power over undesired directions. In
this letter, we study the enhanced multi-beam forming with a linear
movable-antenna (MA) array by exploiting the new degrees of freedom (DoFs) via
antennas' position optimization. Specifically, we jointly optimize the antenna
position vector (APV) and antenna weight vector (AWV) to maximize the minimum
beamforming gain over multiple desired directions, subject to a given
constraint on the maximum interference power over undesired directions. We
propose an efficient alternating optimization algorithm to find a suboptimal
solution by iteratively optimizing one of the APV and AWV with the other being
fixed. Numerical results show that the proposed multi-beam forming design with
MA arrays can significantly outperform that with the traditional FPA arrays and
other benchmark schemes in terms of both beamforming gain and interference
suppression.
</p>
</div>
</dd>
<dt><a name="item191">[191]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03778" title="Abstract">arXiv:2311.03778</a> [<a href="/pdf/2311.03778" title="Download PDF">pdf</a>, <a href="/format/2311.03778" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Bridging the Information Gap Between Domain-Specific Model and General  LLM for Personalized Recommendation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+W">Wenxuan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+H">Hongzhi Liu</a>, 
<a href="/search/cs?searchtype=author&query=Du%2C+Y">Yingpeng Du</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+C">Chen Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+Y">Yang Song</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+H">Hengshu Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Z">Zhonghai Wu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>

</div>
<p class="mathjax">Generative large language models(LLMs) are proficient in solving general
problems but often struggle to handle domain-specific tasks. This is because
most of domain-specific tasks, such as personalized recommendation, rely on
task-related information for optimal performance. Current methods attempt to
supplement task-related information to LLMs by designing appropriate prompts or
employing supervised fine-tuning techniques. Nevertheless, these methods
encounter the certain issue that information such as community behavior pattern
in RS domain is challenging to express in natural language, which limits the
capability of LLMs to surpass state-of-the-art domain-specific models. On the
other hand, domain-specific models for personalized recommendation which mainly
rely on user interactions are susceptible to data sparsity due to their limited
common knowledge capabilities. To address these issues, we proposes a method to
bridge the information gap between the domain-specific models and the general
large language models. Specifically, we propose an information sharing module
which serves as an information storage mechanism and also acts as a bridge for
collaborative training between the LLMs and domain-specific models. By doing
so, we can improve the performance of LLM-based recommendation with the help of
user behavior pattern information mined by domain-specific models. On the other
hand, the recommendation performance of domain-specific models can also be
improved with the help of common knowledge learned by LLMs. Experimental
results on three real-world datasets have demonstrated the effectiveness of the
proposed method.
</p>
</div>
</dd>
<dt><a name="item192">[192]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03780" title="Abstract">arXiv:2311.03780</a> [<a href="/pdf/2311.03780" title="Download PDF">pdf</a>, <a href="/format/2311.03780" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Ensembling Textual and Structure-Based Models for Knowledge Graph  Completion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nandi%2C+A">Ananjan Nandi</a>, 
<a href="/search/cs?searchtype=author&query=Kaur%2C+N">Navdeep Kaur</a>, 
<a href="/search/cs?searchtype=author&query=Singla%2C+P">Parag Singla</a>, 
<a href="/search/cs?searchtype=author&query=Mausam">Mausam</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages, 2 figures, 9 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">We consider two popular approaches to Knowledge Graph Completion (KGC):
textual models that rely on textual entity descriptions, and structure-based
models that exploit the connectivity structure of the Knowledge Graph (KG).
Preliminary experiments show that these approaches have complementary
strengths: structure-based models perform well when the gold answer is easily
reachable from the query head in the KG, while textual models exploit
descriptions to give good performance even when the gold answer is not
reachable. In response, we explore ensembling as a way of combining the best of
both approaches. We propose a novel method for learning query-dependent
ensemble weights by using the distributions of scores assigned by individual
models to all candidate entities. Our ensemble baseline achieves
state-of-the-art results on three standard KGC datasets, with up to 6.8 pt MRR
and 8.3 pt Hits@1 gains over best individual models.
</p>
</div>
</dd>
<dt><a name="item193">[193]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03782" title="Abstract">arXiv:2311.03782</a> [<a href="/pdf/2311.03782" title="Download PDF">pdf</a>, <a href="/format/2311.03782" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CapST: An Enhanced and Lightweight Method for Deepfake Video  Classification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ahmad%2C+W">Wasim Ahmad</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+Y">Yan-Tsung Peng</a>, 
<a href="/search/cs?searchtype=author&query=Chang%2C+Y">Yuan-Hao Chang</a>, 
<a href="/search/cs?searchtype=author&query=Ganfure%2C+G+O">Gaddisa Olani Ganfure</a>, 
<a href="/search/cs?searchtype=author&query=Khan%2C+S">Sarwar Khan</a>, 
<a href="/search/cs?searchtype=author&query=Shahzad%2C+S+A">Sahibzada Adil Shahzad</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to a IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems: 14 pages, 7 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">The proliferation of deepfake videos, synthetic media produced through
advanced Artificial Intelligence techniques has raised significant concerns
across various sectors, encompassing realms such as politics, entertainment,
and security. In response, this research introduces an innovative and
streamlined model designed to classify deepfake videos generated by five
distinct encoders adeptly. Our approach not only achieves state of the art
performance but also optimizes computational resources. At its core, our
solution employs part of a VGG19bn as a backbone to efficiently extract
features, a strategy proven effective in image-related tasks. We integrate a
Capsule Network coupled with a Spatial Temporal attention mechanism to bolster
the model's classification capabilities while conserving resources. This
combination captures intricate hierarchies among features, facilitating robust
identification of deepfake attributes. Delving into the intricacies of our
innovation, we introduce an existing video level fusion technique that artfully
capitalizes on temporal attention mechanisms. This mechanism serves to handle
concatenated feature vectors, capitalizing on the intrinsic temporal
dependencies embedded within deepfake videos. By aggregating insights across
frames, our model gains a holistic comprehension of video content, resulting in
more precise predictions. Experimental results on an extensive benchmark
dataset of deepfake videos called DFDM showcase the efficacy of our proposed
method. Notably, our approach achieves up to a 4 percent improvement in
accurately categorizing deepfake videos compared to baseline models, all while
demanding fewer computational resources.
</p>
</div>
</dd>
<dt><a name="item194">[194]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03783" title="Abstract">arXiv:2311.03783</a> [<a href="/pdf/2311.03783" title="Download PDF">pdf</a>, <a href="/format/2311.03783" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Scene-Driven Multimodal Knowledge Graph Construction for Embodied AI
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yaoxian%2C+S">Song Yaoxian</a>, 
<a href="/search/cs?searchtype=author&query=Penglei%2C+S">Sun Penglei</a>, 
<a href="/search/cs?searchtype=author&query=Haoyu%2C+L">Liu Haoyu</a>, 
<a href="/search/cs?searchtype=author&query=Zhixu%2C+L">Li Zhixu</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+S">Song Wei</a>, 
<a href="/search/cs?searchtype=author&query=Yanghua%2C+X">Xiao Yanghua</a>, 
<a href="/search/cs?searchtype=author&query=Xiaofang%2C+Z">Zhou Xiaofang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages, 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Robotics (cs.RO); Symbolic Computation (cs.SC)

</div>
<p class="mathjax">Embodied AI is one of the most popular studies in artificial intelligence and
robotics, which can effectively improve the intelligence of real-world agents
(i.e. robots) serving human beings. Scene knowledge is important for an agent
to understand the surroundings and make correct decisions in the varied open
world. Currently, knowledge base for embodied tasks is missing and most
existing work use general knowledge base or pre-trained models to enhance the
intelligence of an agent. For conventional knowledge base, it is sparse,
insufficient in capacity and cost in data collection. For pre-trained models,
they face the uncertainty of knowledge and hard maintenance. To overcome the
challenges of scene knowledge, we propose a scene-driven multimodal knowledge
graph (Scene-MMKG) construction method combining conventional knowledge
engineering and large language models. A unified scene knowledge injection
framework is introduced for knowledge representation. To evaluate the
advantages of our proposed method, we instantiate Scene-MMKG considering
typical indoor robotic functionalities (Manipulation and Mobility), named
ManipMob-MMKG. Comparisons in characteristics indicate our instantiated
ManipMob-MMKG has broad superiority in data-collection efficiency and knowledge
quality. Experimental results on typical embodied tasks show that
knowledge-enhanced methods using our instantiated ManipMob-MMKG can improve the
performance obviously without re-designing model structures complexly. Our
project can be found at https://sites.google.com/view/manipmob-mmkg
</p>
</div>
</dd>
<dt><a name="item195">[195]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03784" title="Abstract">arXiv:2311.03784</a> [<a href="/pdf/2311.03784" title="Download PDF">pdf</a>, <a href="/format/2311.03784" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> UP-NeRF: Unconstrained Pose-Prior-Free Neural Radiance Fields
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kim%2C+I">Injae Kim</a>, 
<a href="/search/cs?searchtype=author&query=Choi%2C+M">Minhyuk Choi</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+H+J">Hyunwoo J. Kim</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Neural Information Processing Systems (NeurIPS), 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Neural Radiance Field (NeRF) has enabled novel view synthesis with high
fidelity given images and camera poses. Subsequent works even succeeded in
eliminating the necessity of pose priors by jointly optimizing NeRF and camera
pose. However, these works are limited to relatively simple settings such as
photometrically consistent and occluder-free image collections or a sequence of
images from a video. So they have difficulty handling unconstrained images with
varying illumination and transient occluders. In this paper, we propose
\textbf{UP-NeRF} (\textbf{U}nconstrained \textbf{P}ose-prior-free
\textbf{Ne}ural \textbf{R}adiance \textbf{F}ields) to optimize NeRF with
unconstrained image collections without camera pose prior. We tackle these
challenges with surrogate tasks that optimize color-insensitive feature fields
and a separate module for transient occluders to block their influence on pose
estimation. In addition, we introduce a candidate head to enable more robust
pose estimation and transient-aware depth supervision to minimize the effect of
incorrect prior. Our experiments verify the superior performance of our method
compared to the baselines including BARF and its variants in a challenging
internet photo collection, \textit{Phototourism} dataset. The code of UP-NeRF
is available at \url{https://github.com/mlvlab/UP-NeRF}.
</p>
</div>
</dd>
<dt><a name="item196">[196]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03785" title="Abstract">arXiv:2311.03785</a> [<a href="/pdf/2311.03785" title="Download PDF">pdf</a>, <a href="/format/2311.03785" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Self-MI: Efficient Multimodal Fusion via Self-Supervised Multi-Task  Learning with Auxiliary Mutual Information Maximization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+C+T">Cam-Van Thi Nguyen</a>, 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+N+T">Ngoc-Hoa Thi Nguyen</a>, 
<a href="/search/cs?searchtype=author&query=Le%2C+D">Duc-Trong Le</a>, 
<a href="/search/cs?searchtype=author&query=Ha%2C+Q">Quang-Thuy Ha</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at The 37th Pacific Asia Conference on Language, Information and Computation (PACLIC 37)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Multimedia (cs.MM)

</div>
<p class="mathjax">Multimodal representation learning poses significant challenges in capturing
informative and distinct features from multiple modalities. Existing methods
often struggle to exploit the unique characteristics of each modality due to
unified multimodal annotations. In this study, we propose Self-MI in the
self-supervised learning fashion, which also leverage Contrastive Predictive
Coding (CPC) as an auxiliary technique to maximize the Mutual Information (MI)
between unimodal input pairs and the multimodal fusion result with unimodal
inputs. Moreover, we design a label generation module, $ULG_{MI}$ for short,
that enables us to create meaningful and informative labels for each modality
in a self-supervised manner. By maximizing the Mutual Information, we encourage
better alignment between the multimodal fusion and the individual modalities,
facilitating improved multimodal fusion. Extensive experiments on three
benchmark datasets including CMU-MOSI, CMU-MOSEI, and SIMS, demonstrate the
effectiveness of Self-MI in enhancing the multimodal fusion task.
</p>
</div>
</dd>
<dt><a name="item197">[197]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03788" title="Abstract">arXiv:2311.03788</a> [<a href="/pdf/2311.03788" title="Download PDF">pdf</a>, <a href="/format/2311.03788" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Language Representation Projection: Can We Transfer Factual Knowledge  across Languages in Multilingual Language Models?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+S">Shaoyang Xu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Junzhuo Li</a>, 
<a href="/search/cs?searchtype=author&query=Xiong%2C+D">Deyi Xiong</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by EMNLP 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Multilingual pretrained language models serve as repositories of multilingual
factual knowledge. Nevertheless, a substantial performance gap of factual
knowledge probing exists between high-resource languages and low-resource
languages, suggesting limited implicit factual knowledge transfer across
languages in multilingual pretrained language models. This paper investigates
the feasibility of explicitly transferring relatively rich factual knowledge
from English to non-English languages. To accomplish this, we propose two
parameter-free $\textbf{L}$anguage $\textbf{R}$epresentation
$\textbf{P}$rojection modules (LRP2). The first module converts non-English
representations into English-like equivalents, while the second module reverts
English-like representations back into representations of the corresponding
non-English language. Experimental results on the mLAMA dataset demonstrate
that LRP2 significantly improves factual knowledge retrieval accuracy and
facilitates knowledge transferability across diverse non-English languages. We
further investigate the working mechanism of LRP2 from the perspectives of
representation space and cross-lingual knowledge neuron.
</p>
</div>
</dd>
<dt><a name="item198">[198]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03792" title="Abstract">arXiv:2311.03792</a> [<a href="/pdf/2311.03792" title="Download PDF">pdf</a>, <a href="/format/2311.03792" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Character-Level Bangla Text-to-IPA Transcription Using Transformer  Architecture with Sequence Alignment
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hasan%2C+J">Jakir Hasan</a>, 
<a href="/search/cs?searchtype=author&query=Datta%2C+S">Shrestha Datta</a>, 
<a href="/search/cs?searchtype=author&query=Debnath%2C+A">Ameya Debnath</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Achieved top position with a word error rate of 0.10582 in the public ranking of DataVerse Challenge - ITVerse 2023 (link: <a href="https://www.kaggle.com/competitions/dataverse_2023/">this https URL</a>). All codes can be found on the respective competition webpage
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">The International Phonetic Alphabet (IPA) is indispensable in language
learning and understanding, aiding users in accurate pronunciation and
comprehension. Additionally, it plays a pivotal role in speech therapy,
linguistic research, accurate transliteration, and the development of
text-to-speech systems, making it an essential tool across diverse fields.
Bangla being 7th as one of the widely used languages, gives rise to the need
for IPA in its domain. Its IPA mapping is too diverse to be captured manually
giving the need for Artificial Intelligence and Machine Learning in this field.
In this study, we have utilized a transformer-based sequence-to-sequence model
at the letter and symbol level to get the IPA of each Bangla word as the
variation of IPA in association of different words is almost null. Our
transformer model only consisted of 8.5 million parameters with only a single
decoder and encoder layer. Additionally, to handle the punctuation marks and
the occurrence of foreign languages in the text, we have utilized manual
mapping as the model won't be able to learn to separate them from Bangla words
while decreasing our required computational resources. Finally, maintaining the
relative position of the sentence component IPAs and generation of the combined
IPA has led us to achieve the top position with a word error rate of 0.10582 in
the public ranking of DataVerse Challenge - ITVerse 2023
(https://www.kaggle.com/competitions/dataverse_2023/).
</p>
</div>
</dd>
<dt><a name="item199">[199]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03793" title="Abstract">arXiv:2311.03793</a> [<a href="/pdf/2311.03793" title="Download PDF">pdf</a>, <a href="/format/2311.03793" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> HaptStarter: Designing Haptic Stimulus Start System for Deaf and Hard of  Hearing Sprinters
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shitara%2C+A">Akihisa Shitara</a>, 
<a href="/search/cs?searchtype=author&query=Namatame%2C+M">Miki Namatame</a>, 
<a href="/search/cs?searchtype=author&query=Sarcar%2C+S">Sayan Sarcar</a>, 
<a href="/search/cs?searchtype=author&query=Ochiai%2C+Y">Yoichi Ochiai</a>, 
<a href="/search/cs?searchtype=author&query=Shiraishi%2C+Y">Yuhki Shiraishi</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> International Journal of Human-Computer Studies, Volume 182, 2024,
  103168
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">In this study, we design and develop HaptStarter -- a haptic stimulus start
system -- to improve the starting performance of the deaf and hard of hearing
(DHH) sprinters. A DHH person has a physical ability nearly equivalent to
hearing; however, the difficulties in perceiving audio information lead to
differences in their performance in sports.
<br />Furthermore, the visual reaction time is slower than the auditory reaction
time (ART), while the haptic reaction time is equivalent to it.
<br />However, a light stimulus start system is increasingly being used in sprint
races to aid DHH sprinters. In this study, we design a brand-new haptic
stimulus start system for DHH sprinters; we also determine and leverage an
optimum haptic stimulus interface. The proposed method has the potential to
contribute toward the development of prototypes based on the universal design
principle for everyone (DHH, blind and low-vision, and other disabled sprinters
with wheelchairs or artificial arms or legs, etc.) by focusing on the
overlapping area of sports and disability with human-computer interaction.
</p>
</div>
</dd>
<dt><a name="item200">[200]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03797" title="Abstract">arXiv:2311.03797</a> [<a href="/pdf/2311.03797" title="Download PDF">pdf</a>, <a href="/ps/2311.03797" title="Download PostScript">ps</a>, <a href="/format/2311.03797" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> User-level Differentially Private Stochastic Convex Optimization:  Efficient Algorithms with Optimal Rates
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Asi%2C+H">Hilal Asi</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+D">Daogao Liu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Cryptography and Security (cs.CR); Data Structures and Algorithms (cs.DS); Optimization and Control (math.OC)

</div>
<p class="mathjax">We study differentially private stochastic convex optimization (DP-SCO) under
user-level privacy, where each user may hold multiple data items. Existing work
for user-level DP-SCO either requires super-polynomial runtime [Ghazi et al.
(2023)] or requires the number of users to grow polynomially with the
dimensionality of the problem with additional strict assumptions [Bassily et
al. (2023)]. We develop new algorithms for user-level DP-SCO that obtain
optimal rates for both convex and strongly convex functions in polynomial time
and require the number of users to grow only logarithmically in the dimension.
Moreover, our algorithms are the first to obtain optimal rates for non-smooth
functions in polynomial time. These algorithms are based on multiple-pass
DP-SGD, combined with a novel private mean estimation procedure for
concentrated data, which applies an outlier removal step before estimating the
mean of the gradients.
</p>
</div>
</dd>
<dt><a name="item201">[201]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03798" title="Abstract">arXiv:2311.03798</a> [<a href="/pdf/2311.03798" title="Download PDF">pdf</a>, <a href="/format/2311.03798" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Noisy Pair Corrector for Dense Retrieval
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Hang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Gong%2C+Y">Yeyun Gong</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+X">Xingwei He</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+D">Dayiheng Liu</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+D">Daya Guo</a>, 
<a href="/search/cs?searchtype=author&query=Lv%2C+J">Jiancheng Lv</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+J">Jian Guo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Findings of EMNLP 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Most dense retrieval models contain an implicit assumption: the training
query-document pairs are exactly matched. Since it is expensive to annotate the
corpus manually, training pairs in real-world applications are usually
collected automatically, which inevitably introduces mismatched-pair noise. In
this paper, we explore an interesting and challenging problem in dense
retrieval, how to train an effective model with mismatched-pair noise. To solve
this problem, we propose a novel approach called Noisy Pair Corrector (NPC),
which consists of a detection module and a correction module. The detection
module estimates noise pairs by calculating the perplexity between annotated
positive and easy negative documents. The correction module utilizes an
exponential moving average (EMA) model to provide a soft supervised signal,
aiding in mitigating the effects of noise. We conduct experiments on
text-retrieval benchmarks Natural Question and TriviaQA, code-search benchmarks
StaQC and SO-DS. Experimental results show that NPC achieves excellent
performance in handling both synthetic and realistic noise.
</p>
</div>
</dd>
<dt><a name="item202">[202]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03799" title="Abstract">arXiv:2311.03799</a> [<a href="/pdf/2311.03799" title="Download PDF">pdf</a>, <a href="/format/2311.03799" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Detecting Any Human-Object Interaction Relationship: Universal HOI  Detector with Spatial Prompt Learning on Foundation Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cao%2C+Y">Yichao Cao</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+Q">Qingfei Tang</a>, 
<a href="/search/cs?searchtype=author&query=Su%2C+X">Xiu Su</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+C">Chen Song</a>, 
<a href="/search/cs?searchtype=author&query=You%2C+S">Shan You</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+X">Xiaobo Lu</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+C">Chang Xu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Human-object interaction (HOI) detection aims to comprehend the intricate
relationships between humans and objects, predicting $&lt;human, action, object&gt;$
triplets, and serving as the foundation for numerous computer vision tasks. The
complexity and diversity of human-object interactions in the real world,
however, pose significant challenges for both annotation and recognition,
particularly in recognizing interactions within an open world context. This
study explores the universal interaction recognition in an open-world setting
through the use of Vision-Language (VL) foundation models and large language
models (LLMs). The proposed method is dubbed as \emph{\textbf{UniHOI}}. We
conduct a deep analysis of the three hierarchical features inherent in visual
HOI detectors and propose a method for high-level relation extraction aimed at
VL foundation models, which we call HO prompt-based learning. Our design
includes an HO Prompt-guided Decoder (HOPD), facilitates the association of
high-level relation representations in the foundation model with various HO
pairs within the image. Furthermore, we utilize a LLM (\emph{i.e.} GPT) for
interaction interpretation, generating a richer linguistic understanding for
complex HOIs. For open-category interaction recognition, our method supports
either of two input types: interaction phrase or interpretive sentence. Our
efficient architecture design and learning methods effectively unleash the
potential of the VL foundation models and LLMs, allowing UniHOI to surpass all
existing methods with a substantial margin, under both supervised and zero-shot
settings. The code and pre-trained weights are available at:
\url{https://github.com/Caoyichao/UniHOI}.
</p>
</div>
</dd>
<dt><a name="item203">[203]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03806" title="Abstract">arXiv:2311.03806</a> [<a href="/pdf/2311.03806" title="Download PDF">pdf</a>, <a href="/ps/2311.03806" title="Download PostScript">ps</a>, <a href="/format/2311.03806" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exploring the transformation of user interactions to Adaptive  Human-Machine Interfaces
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Carrera-Rivera%2C+A">Angela Carrera-Rivera</a>, 
<a href="/search/cs?searchtype=author&query=Reguera-Bakhache%2C+D">Daniel Reguera-Bakhache</a>, 
<a href="/search/cs?searchtype=author&query=Larrinaga%2C+F">Felix Larrinaga</a>, 
<a href="/search/cs?searchtype=author&query=Lasa%2C+G">Ganix Lasa</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> XXIII International Conference on Human Computer Interaction , Lleida, Spain, September,2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">Human-machine interfaces (HMI) facilitate communication between humans and
machines, and their importance has increased in modern technology. However,
traditional HMIs are often static and do not adapt to individual user
preferences or behavior. Adaptive User Interfaces (AUIs) have become
increasingly important in providing personalized user experiences. Machine
learning techniques have gained traction in User Experience (UX) research to
provide smart adaptations that can reduce user cognitive load. This paper
presents an ongoing exploration of a method for generating adaptive user
interfaces by analyzing user interactions and contextual data. It also provides
an illustrative example using Markov chains to predict the next step for users
interacting with an app for an industrial mixing machine. Furthermore, the
paper conducts an offline evaluation of the approach, focusing on the precision
of the recommendations. The study emphasizes the importance of incorporating
user interactions and contextual data into the design of adaptive HMIs, while
acknowledging the existing challenges and potential benefits.
</p>
</div>
</dd>
<dt><a name="item204">[204]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03809" title="Abstract">arXiv:2311.03809</a> [<a href="/pdf/2311.03809" title="Download PDF">pdf</a>, <a href="/format/2311.03809" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SoK: Security Below the OS -- A Security Analysis of UEFI
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Surve%2C+P+P">Priyanka Prakash Surve</a>, 
<a href="/search/cs?searchtype=author&query=Brodt%2C+O">Oleg Brodt</a>, 
<a href="/search/cs?searchtype=author&query=Yampolskiy%2C+M">Mark Yampolskiy</a>, 
<a href="/search/cs?searchtype=author&query=Elovici%2C+Y">Yuval Elovici</a>, 
<a href="/search/cs?searchtype=author&query=Shabtai%2C+A">Asaf Shabtai</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">The Unified Extensible Firmware Interface (UEFI) is a linchpin of modern
computing systems, governing secure system initialization and booting. This
paper is urgently needed because of the surge in UEFI-related attacks and
vulnerabilities in recent years. Motivated by this urgent concern, we undertake
an extensive exploration of the UEFI landscape, dissecting its distribution
supply chain, booting process, and security features. We carefully study a
spectrum of UEFI-targeted attacks and proofs of concept (PoCs) for exploiting
UEFI-related vulnerabilities. Building upon these insights, we construct a
comprehensive attack threat model encompassing threat actors, attack vectors,
attack types, vulnerabilities, attack capabilities, and attacker objectives.
Drawing inspiration from the MITRE ATT&amp;CK framework, we present a MITRE
ATT&amp;CK-like taxonomy delineating tactics, techniques, and sub-techniques in the
context of UEFI attacks. This taxonomy can provide a road map for identifying
existing gaps and developing new techniques for rootkit prevention, detection,
and removal. Finally, the paper discusses existing countermeasures against UEFI
attacks including a variety of technical and operational measures that can be
implemented to lower the risk of UEFI attacks to an acceptable level. This
paper seeks to clarify the complexities of UEFI and equip the cybersecurity
community with the necessary knowledge to strengthen the security of this
critical component against a growing threat landscape.
</p>
</div>
</dd>
<dt><a name="item205">[205]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03810" title="Abstract">arXiv:2311.03810</a> [<a href="/pdf/2311.03810" title="Download PDF">pdf</a>, <a href="/format/2311.03810" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Rethinking and Improving Multi-task Learning for End-to-end Speech  Translation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yuhao Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+C">Chen Xu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+B">Bei Li</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+H">Hao Chen</a>, 
<a href="/search/cs?searchtype=author&query=Xiao%2C+T">Tong Xiao</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+C">Chunliang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+J">Jingbo Zhu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to EMNLP2023 main conference
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Sound (cs.SD); Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">Significant improvements in end-to-end speech translation (ST) have been
achieved through the application of multi-task learning. However, the extent to
which auxiliary tasks are highly consistent with the ST task, and how much this
approach truly helps, have not been thoroughly studied. In this paper, we
investigate the consistency between different tasks, considering different
times and modules. We find that the textual encoder primarily facilitates
cross-modal conversion, but the presence of noise in speech impedes the
consistency between text and speech representations. Furthermore, we propose an
improved multi-task learning (IMTL) approach for the ST task, which bridges the
modal gap by mitigating the difference in length and representation. We conduct
experiments on the MuST-C dataset. The results demonstrate that our method
attains state-of-the-art results. Moreover, when additional data is used, we
achieve the new SOTA result on MuST-C English to Spanish task with 20.8% of the
training time required by the current SOTA method.
</p>
</div>
</dd>
<dt><a name="item206">[206]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03812" title="Abstract">arXiv:2311.03812</a> [<a href="/pdf/2311.03812" title="Download PDF">pdf</a>, <a href="/ps/2311.03812" title="Download PostScript">ps</a>, <a href="/format/2311.03812" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Conversations in Galician: a Large Language Model for an  Underrepresented Language
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bao%2C+E">Eliseo Bao</a>, 
<a href="/search/cs?searchtype=author&query=P%C3%A9rez%2C+A">Anxo P&#xe9;rez</a>, 
<a href="/search/cs?searchtype=author&query=Parapar%2C+J">Javier Parapar</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">The recent proliferation of Large Conversation Language Models has
highlighted the economic significance of widespread access to this type of AI
technologies in the current information age. Nevertheless, prevailing models
have primarily been trained on corpora consisting of documents written in
popular languages. The dearth of such cutting-edge tools for low-resource
languages further exacerbates their underrepresentation in the current economic
landscape, thereby impacting their native speakers. This paper introduces two
novel resources designed to enhance Natural Language Processing (NLP) for the
Galician language. We present a Galician adaptation of the Alpaca dataset,
comprising 52,000 instructions and demonstrations. This dataset proves
invaluable for enhancing language models by fine-tuning them to more accurately
adhere to provided instructions. Additionally, as a demonstration of the
dataset utility, we fine-tuned LLaMA-7B to comprehend and respond in Galician,
a language not originally supported by the model, by following the Alpaca
format. This work contributes to the research on multilingual models tailored
for low-resource settings, a crucial endeavor in ensuring the inclusion of all
linguistic communities in the development of Large Language Models. Another
noteworthy aspect of this research is the exploration of how knowledge of a
closely related language, in this case, Portuguese, can assist in generating
coherent text when training resources are scarce. Both the Galician Alpaca
dataset and Cabuxa-7B are publicly accessible on our Huggingface Hub, and we
have made the source code available to facilitate replication of this
experiment and encourage further advancements for underrepresented languages.
</p>
</div>
</dd>
<dt><a name="item207">[207]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03815" title="Abstract">arXiv:2311.03815</a> [<a href="/pdf/2311.03815" title="Download PDF">pdf</a>, <a href="/format/2311.03815" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Integrated Sensing, Communication, and Computing for Cost-effective  Multimodal Federated Perception
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+N">Ning Chen</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+Z">Zhipeng Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Fan%2C+X">Xuwei Fan</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+B">Bangzhen Huang</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Y">Yifeng Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+L">Lianfen Huang</a>, 
<a href="/search/cs?searchtype=author&query=Du%2C+X">Xiaojiang Du</a>, 
<a href="/search/cs?searchtype=author&query=Guizani%2C+M">Mohsen Guizani</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">Federated learning (FL) is a classic paradigm of 6G edge intelligence (EI),
which alleviates privacy leaks and high communication pressure caused by
traditional centralized data processing in the artificial intelligence of
things (AIoT). The implementation of multimodal federated perception (MFP)
services involves three sub-processes, including sensing-based multimodal data
generation, communication-based model transmission, and computing-based model
training, ultimately relying on available underlying multi-domain physical
resources such as time, frequency, and computing power. How to reasonably
coordinate the multi-domain resources scheduling among sensing, communication,
and computing, therefore, is crucial to the MFP networks. To address the above
issues, this paper investigates service-oriented resource management with
integrated sensing, communication, and computing (ISCC). With the incentive
mechanism of the MFP service market, the resources management problem is
redefined as a social welfare maximization problem, where the idea of
"expanding resources" and "reducing costs" is used to improve learning
performance gain and reduce resource costs. Experimental results demonstrate
the effectiveness and robustness of the proposed resource scheduling
mechanisms.
</p>
</div>
</dd>
<dt><a name="item208">[208]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03818" title="Abstract">arXiv:2311.03818</a> [<a href="/pdf/2311.03818" title="Download PDF">pdf</a>, <a href="/format/2311.03818" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Theoretical Patchability Quantification for IP-Level Hardware Patching  Designs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+W">Wei-Kai Liu</a>, 
<a href="/search/cs?searchtype=author&query=Tan%2C+B">Benjamin Tan</a>, 
<a href="/search/cs?searchtype=author&query=Fung%2C+J+M">Jason M. Fung</a>, 
<a href="/search/cs?searchtype=author&query=Chakrabarty%2C+K">Krishnendu Chakrabarty</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">As the complexity of System-on-Chip (SoC) designs continues to increase,
ensuring thorough verification becomes a significant challenge for system
integrators. The complexity of verification can result in undetected bugs.
Unlike software or firmware bugs, hardware bugs are hard to fix after
deployment and they require additional logic, i.e., patching logic integrated
with the design in advance in order to patch. However, the absence of a
standardized metric for defining "patchability" leaves system integrators
relying on their understanding of each IP and security requirements to engineer
ad hoc patching designs. In this paper, we propose a theoretical patchability
quantification method to analyze designs at the Register Transfer Level (RTL)
with provided patching options. Our quantification defines patchability as a
combination of observability and controllability so that we can analyze and
compare the patchability of IP variations. This quantification is a systematic
approach to estimate each patching architecture's ability to patch at run-time
and complements existing patching works. In experiments, we compare several
design options of the same patching architecture and discuss their differences
in terms of theoretical patchability and how many potential weaknesses can be
mitigated.
</p>
</div>
</dd>
<dt><a name="item209">[209]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03823" title="Abstract">arXiv:2311.03823</a> [<a href="/pdf/2311.03823" title="Download PDF">pdf</a>, <a href="/format/2311.03823" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Data-informed uncertainty quantification for laser-based powder bed  fusion additive manufacturing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chiappetta%2C+M">Mihaela Chiappetta</a>, 
<a href="/search/cs?searchtype=author&query=Piazzola%2C+C">Chiara Piazzola</a>, 
<a href="/search/cs?searchtype=author&query=Tamellini%2C+L">Lorenzo Tamellini</a>, 
<a href="/search/cs?searchtype=author&query=Reali%2C+A">Alessandro Reali</a>, 
<a href="/search/cs?searchtype=author&query=Auricchio%2C+F">Ferdinando Auricchio</a>, 
<a href="/search/cs?searchtype=author&query=Carraturo%2C+M">Massimo Carraturo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 25 pages, 13 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Engineering, Finance, and Science (cs.CE)</span>

</div>
<p class="mathjax">We present an efficient approach to quantify the uncertainties associated
with the numerical simulations of the laser-based powder bed fusion of metal
processes. Our study focuses on a thermomechanical model of an Inconel 625
cantilever beam, based on the AMBench2018-01 benchmark proposed by the National
Institute of Standards and Technology (NIST). The proposed approach consists of
a forward uncertainty quantification analysis of the residual strain of the
cantilever beam given the uncertainty on some of the parameters of the
numerical simulation, namely the powder convection coefficient and the
activation temperature. The uncertainty on such parameters is modeled by a
data-informed probability density function obtained by a Bayesian inversion
procedure, based on the displacement experimental data provided by NIST. To
overcome the computational challenges of both the Bayesian inversion and the
forward uncertainty quantification analysis we employ a multi-fidelity
surrogate modeling technique, specifically the multi-index stochastic
collocation method. The proposed approach allows us to achieve a 33\% reduction
in the uncertainties on the prediction of residual strains compared with what
we would get basing the forward UQ analysis on a-priori ranges for the
uncertain parameters, and in particular the mode of the probability density
function of such quantities (i.e., its ``most likely value'', roughly speaking)
results to be in good agreement with the experimental data provided by NIST,
even though only displacement data were used for the Bayesian inversion
procedure.
</p>
</div>
</dd>
<dt><a name="item210">[210]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03825" title="Abstract">arXiv:2311.03825</a> [<a href="/pdf/2311.03825" title="Download PDF">pdf</a>, <a href="/format/2311.03825" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> IC-SECURE: Intelligent System for Assisting Security Experts in  Generating Playbooks for Automated Incident Response
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kremer%2C+R">Ryuta Kremer</a>, 
<a href="/search/cs?searchtype=author&query=Wudali%2C+P+N">Prasanna N. Wudali</a>, 
<a href="/search/cs?searchtype=author&query=Momiyama%2C+S">Satoru Momiyama</a>, 
<a href="/search/cs?searchtype=author&query=Araki%2C+T">Toshinori Araki</a>, 
<a href="/search/cs?searchtype=author&query=Furukawa%2C+J">Jun Furukawa</a>, 
<a href="/search/cs?searchtype=author&query=Elovici%2C+Y">Yuval Elovici</a>, 
<a href="/search/cs?searchtype=author&query=Shabtai%2C+A">Asaf Shabtai</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">Security orchestration, automation, and response (SOAR) systems ingest alerts
from security information and event management (SIEM) system, and then trigger
relevant playbooks that automate and orchestrate the execution of a sequence of
security activities. SOAR systems have two major limitations: (i) security
analysts need to define, create and change playbooks manually, and (ii) the
choice between multiple playbooks that could be triggered is based on rules
defined by security analysts. To address these limitations, recent studies in
the field of artificial intelligence for cybersecurity suggested the task of
interactive playbook creation. In this paper, we propose IC-SECURE, an
interactive playbook creation solution based on a novel deep learning-based
approach that provides recommendations to security analysts during the playbook
creation process. IC-SECURE captures the context in the form of alert data and
current status of incomplete playbook, required to make reasonable
recommendation for next module that should be included in the new playbook
being created. We created three evaluation datasets, each of which involved a
combination of a set of alert rules and a set of playbooks from a SOAR
platform. We evaluated IC-SECURE under various settings, and compared our
results with two state-of-the-art recommender system methods. In our evaluation
IC-SECURE demonstrated superior performance compared to other methods by
consistently recommending the correct security module, achieving precision@1 &gt;
0.8 and recall@3 &gt; 0.92
</p>
</div>
</dd>
<dt><a name="item211">[211]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03826" title="Abstract">arXiv:2311.03826</a> [<a href="/pdf/2311.03826" title="Download PDF">pdf</a>, <a href="/format/2311.03826" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Accelerating Unstructured SpGEMM using Structured In-situ Computing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Huize Li</a>, 
<a href="/search/cs?searchtype=author&query=Mitra%2C+T">Tulika Mitra</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Hardware Architecture (cs.AR)</span>

</div>
<p class="mathjax">Sparse matrix-matrix multiplication (SpGEMM) is a critical kernel widely
employed in machine learning and graph algorithms. However, real-world
matrices' high sparsity makes SpGEMM memory-intensive. In-situ computing offers
the potential to accelerate memory-intensive applications through high
bandwidth and parallelism. Nevertheless, the irregular distribution of
non-zeros renders SpGEMM a typical unstructured software. In contrast, in-situ
computing platforms follow a fixed calculation manner, making them structured
hardware. The mismatch between unstructured software and structured hardware
leads to sub-optimal performance of current solutions.
<br />In this paper, we propose SPLIM, a novel in-situ computing SpGEMM
accelerator. SPLIM involves two innovations. First, we present a novel
computation paradigm that converts SpGEMM into structured in-situ
multiplication and unstructured accumulation. Second, we develop a unique
coordinates alignment method utilizing in-situ search operations, effectively
transforming unstructured accumulation into high parallel searching operations.
Our experimental results demonstrate that SPLIM achieves 275.74$\times$
performance improvement and 687.19$\times$ energy saving compared to NVIDIA RTX
A6000 GPU.
</p>
</div>
</dd>
<dt><a name="item212">[212]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03828" title="Abstract">arXiv:2311.03828</a> [<a href="/pdf/2311.03828" title="Download PDF">pdf</a>, <a href="/format/2311.03828" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multi-view Information Integration and Propagation for Occluded Person  Re-identification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dong%2C+N">Neng Dong</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+S">Shuanglin Yan</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+H">Hao Tang</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+J">Jinhui Tang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+L">Liyan Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Occluded person re-identification (re-ID) presents a challenging task due to
occlusion perturbations. Although great efforts have been made to prevent the
model from being disturbed by occlusion noise, most current solutions only
capture information from a single image, disregarding the rich complementary
information available in multiple images depicting the same pedestrian. In this
paper, we propose a novel framework called Multi-view Information Integration
and Propagation (MVI$^{2}$P). Specifically, realizing the potential of
multi-view images in effectively characterizing the occluded target pedestrian,
we integrate feature maps of which to create a comprehensive representation.
During this process, to avoid introducing occlusion noise, we develop a
CAMs-aware Localization module that selectively integrates information
contributing to the identification. Additionally, considering the divergence in
the discriminative nature of different images, we design a probability-aware
Quantification module to emphatically integrate highly reliable information.
Moreover, as multiple images with the same identity are not accessible in the
testing stage, we devise an Information Propagation (IP) mechanism to distill
knowledge from the comprehensive representation to that of a single occluded
image. Extensive experiments and analyses have unequivocally demonstrated the
effectiveness and superiority of the proposed MVI$^{2}$P. The code will be
released at \url{https://github.com/nengdong96/MVIIP}.
</p>
</div>
</dd>
<dt><a name="item213">[213]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03830" title="Abstract">arXiv:2311.03830</a> [<a href="/pdf/2311.03830" title="Download PDF">pdf</a>, <a href="/format/2311.03830" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Reducing Spatial Fitting Error in Distillation of Denoising Diffusion  Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhou%2C+S">Shengzhe Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+Z">Zejian Lee</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+S">Shengyuan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Hou%2C+L">Lefan Hou</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+C">Changyuan Yang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+G">Guang Yang</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+L">Lingyun Sun</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Denoising Diffusion models have exhibited remarkable capabilities in image
generation. However, generating high-quality samples requires a large number of
iterations. Knowledge distillation for diffusion models is an effective method
to address this limitation with a shortened sampling process but causes
degraded generative quality. Based on our analysis with bias-variance
decomposition and experimental observations, we attribute the degradation to
the spatial fitting error occurring in the training of both the teacher and
student model. Accordingly, we propose $\textbf{S}$patial
$\textbf{F}$itting-$\textbf{E}$rror $\textbf{R}$eduction
$\textbf{D}$istillation model ($\textbf{SFERD}$). SFERD utilizes attention
guidance from the teacher model and a designed semantic gradient predictor to
reduce the student's fitting error. Empirically, our proposed model facilitates
high-quality sample generation in a few function evaluations. We achieve an FID
of 5.31 on CIFAR-10 and 9.39 on ImageNet 64$\times$64 with only one step,
outperforming existing diffusion methods. Our study provides a new perspective
on diffusion distillation by highlighting the intrinsic denoising ability of
models.
</p>
</div>
</dd>
<dt><a name="item214">[214]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03831" title="Abstract">arXiv:2311.03831</a> [<a href="/pdf/2311.03831" title="Download PDF">pdf</a>, <a href="/format/2311.03831" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Difference Based Content Networking
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mosko%2C+M">Marc Mosko</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>

</div>
<p class="mathjax">Difference Based Content Networking (DBCN) uses diffs between versions to
optimize the amount of data sent on the network for version updates of data
files. This paper describes several variations on DBCN based on binary diffs,
content object diffs, byte offset diffs, and chunk catalog diffs. Existing CCNx
versioning methods use total replication of data file bytes between versions,
resulting in poor efficiency in data transfer.
</p>
</div>
</dd>
<dt><a name="item215">[215]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03832" title="Abstract">arXiv:2311.03832</a> [<a href="/pdf/2311.03832" title="Download PDF">pdf</a>, <a href="/format/2311.03832" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Requirements Engineering using Generative AI: Prompts and Prompting  Patterns
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ronanki%2C+K">Krishna Ronanki</a>, 
<a href="/search/cs?searchtype=author&query=Cabrero-Daniel%2C+B">Beatriz Cabrero-Daniel</a>, 
<a href="/search/cs?searchtype=author&query=Horkoff%2C+J">Jennifer Horkoff</a>, 
<a href="/search/cs?searchtype=author&query=Berger%2C+C">Christian Berger</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
<p class="mathjax">[Context]: Companies are increasingly recognizing the importance of
automating Requirements Engineering (RE) tasks due to their resource-intensive
nature. The advent of GenAI has made these tasks more amenable to automation,
thanks to its ability to understand and interpret context effectively.
[Problem]: However, in the context of GenAI, prompt engineering is a critical
factor for success. Despite this, we currently lack tools and methods to
systematically assess and determine the most effective prompt patterns to
employ for a particular RE task. [Method]: Two tasks related to requirements,
specifically requirement classification and tracing, were automated using the
GPT-3.5 turbo API. The performance evaluation involved assessing various
prompts created using 5 prompt patterns and implemented programmatically to
perform the selected RE tasks, focusing on metrics such as precision, recall,
accuracy, and F-Score. [Results]: This paper evaluates the effectiveness of the
5 prompt patterns' ability to make GPT-3.5 turbo perform the selected RE tasks
and offers recommendations on which prompt pattern to use for a specific RE
task. Additionally, it also provides an evaluation framework as a reference for
researchers and practitioners who want to evaluate different prompt patterns
for different RE tasks.
</p>
</div>
</dd>
<dt><a name="item216">[216]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03837" title="Abstract">arXiv:2311.03837</a> [<a href="/pdf/2311.03837" title="Download PDF">pdf</a>, <a href="/format/2311.03837" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> OLaLa: Ontology Matching with Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hertling%2C+S">Sven Hertling</a>, 
<a href="/search/cs?searchtype=author&query=Paulheim%2C+H">Heiko Paulheim</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at K-CAP 2023 conference
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Computation and Language (cs.CL)

</div>
<p class="mathjax">Ontology (and more generally: Knowledge Graph) Matching is a challenging task
where information in natural language is one of the most important signals to
process. With the rise of Large Language Models, it is possible to incorporate
this knowledge in a better way into the matching pipeline. A number of
decisions still need to be taken, e.g., how to generate a prompt that is useful
to the model, how information in the KG can be formulated in prompts, which
Large Language Model to choose, how to provide existing correspondences to the
model, how to generate candidates, etc. In this paper, we present a prototype
that explores these questions by applying zero-shot and few-shot prompting with
multiple open Large Language Models to different tasks of the Ontology
Alignment Evaluation Initiative (OAEI). We show that with only a handful of
examples and a well-designed prompt, it is possible to achieve results that are
en par with supervised matching systems which use a much larger portion of the
ground truth.
</p>
</div>
</dd>
<dt><a name="item217">[217]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03838" title="Abstract">arXiv:2311.03838</a> [<a href="/pdf/2311.03838" title="Download PDF">pdf</a>, <a href="/format/2311.03838" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Autonomous Exploration and General Visual Inspection of Ship Ballast  Water Tanks using Aerial Robots
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dharmadhikari%2C+M">Mihir Dharmadhikari</a>, 
<a href="/search/cs?searchtype=author&query=De+Petris%2C+P">Paolo De Petris</a>, 
<a href="/search/cs?searchtype=author&query=Kulkarni%2C+M">Mihir Kulkarni</a>, 
<a href="/search/cs?searchtype=author&query=Khedekar%2C+N">Nikhil Khedekar</a>, 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+H">Huan Nguyen</a>, 
<a href="/search/cs?searchtype=author&query=Stene%2C+A+E">Arnt Erik Stene</a>, 
<a href="/search/cs?searchtype=author&query=Sj%C3%B8vold%2C+E">Eivind Sj&#xf8;vold</a>, 
<a href="/search/cs?searchtype=author&query=Solheim%2C+K">Kristian Solheim</a>, 
<a href="/search/cs?searchtype=author&query=Gussiaas%2C+B">Bente Gussiaas</a>, 
<a href="/search/cs?searchtype=author&query=Alexis%2C+K">Kostas Alexis</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 7 figures, accepted for publication at the 2023 IEEE International Conference on Advanced Robotics (ICAR)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">This paper presents a solution for the autonomous exploration and inspection
of Ballast Water Tanks (BWTs) of marine vessels using aerial robots. Ballast
tank compartments are critical for a vessel's safety and correspond to confined
environments often connected through particularly narrow manholes. The method
enables their volumetric exploration combined with visual inspection subject to
constraints regarding the viewing distance from a surface. We present
evaluation studies in simulation, in a mission consisting of 18 BWT
compartments, and in 3 field experiments inside real vessels. The data from one
of the experiments is also post-processed to generate semantically-segmented
meshes of inspection-important geometries. Geometric models can be associated
with onboard camera images for detailed and intuitive analysis.
</p>
</div>
</dd>
<dt><a name="item218">[218]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03839" title="Abstract">arXiv:2311.03839</a> [<a href="/pdf/2311.03839" title="Download PDF">pdf</a>, <a href="/format/2311.03839" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Aspects of human memory and Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Janik%2C+R+A">Romuald A. Janik</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13+3 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Neurons and Cognition (q-bio.NC)

</div>
<p class="mathjax">Large Language Models (LLMs) are huge artificial neural networks which
primarily serve to generate text, but also provide a very sophisticated
probabilistic model of language use. Since generating a semantically consistent
text requires a form of effective memory, we investigate the memory properties
of LLMs and find surprising similarities with key characteristics of human
memory. This result strongly suggests that the biological features of human
memory leave an imprint on the way that we structure our textual narratives.
</p>
</div>
</dd>
<dt><a name="item219">[219]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03841" title="Abstract">arXiv:2311.03841</a> [<a href="/pdf/2311.03841" title="Download PDF">pdf</a>, <a href="/ps/2311.03841" title="Download PostScript">ps</a>, <a href="/format/2311.03841" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Preliminary Design of Scalable Hardware Integrated Platform for LLRF  Application
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jiang%2C+L">Lin Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Wen%2C+J">Jingjun Wen</a>, 
<a href="/search/cs?searchtype=author&query=Xue%2C+T">Tao Xue</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+X">Xiaowei Guo</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+H">Haoyan Yang</a>, 
<a href="/search/cs?searchtype=author&query=Pan%2C+Q">Qiutong Pan</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jianmin Li</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yinong Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+L">Liangjun Wei</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Talk presented at LLRF Workshop 2023 (LLRF2023, arXiv: <a href="/abs/2310.03199">2310.03199</a>)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Hardware Architecture (cs.AR)</span>; Accelerator Physics (physics.acc-ph)

</div>
<p class="mathjax">In this paper, the SHIP4LLRF (Scalable Hardware Integrated Platform for LLRF)
based on 6U VPX-standard was designed preliminarily, which includes 6U mother
board and two HPC FPGA mezzanine cards (FMCs). The ADC and DAC FMC is based on
ADS54J60 from TI and LTC2000Y-16 form ADI, respectively. The system mother
board is based on Xilinx Kintex UltraScale KU060, which also features 64-bit
DDR4 SDRAM, QSFP and USB3.0 interfaces. Each FMC connector is assigned 58 pairs
of LVDS standard IOs and 8 pairs of GTH high-speed serial lanes. Besides, the
mother board is equipped with the self-developed ZYNQBee2 module based on
ZYNQ7010 for slow control such as EPICS. All ADC or DAC raw data in each
SHIP4LLEF is compressed loss-less without triggering and transmitted to the
process board. A scalar quantization method which is in development is used for
lossless compression of ADC raw data, the process board will decompress the ADC
data and perform a digital algorithm to measure the amplitude and phase of the
high frequency signal. This de-sign is scalable for testing and upgradability,
mean-while, the trigger-less data transmission enable this system participate
in both local (rack-scale) and accelerator-wide communication networks.
</p>
</div>
</dd>
<dt><a name="item220">[220]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03850" title="Abstract">arXiv:2311.03850</a> [<a href="/pdf/2311.03850" title="Download PDF">pdf</a>, <a href="/format/2311.03850" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Predictive Sampling for Efficient Pairwise Subjective Image Quality  Assessment
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mohammadi%2C+S">Shima Mohammadi</a>, 
<a href="/search/cs?searchtype=author&query=Ascenso%2C+J">Jo&#xe3;o Ascenso</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages, 5 figures, accepted by ACM MM 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Multimedia (cs.MM)</span>

</div>
<p class="mathjax">Subjective image quality assessment studies are used in many scenarios, such
as the evaluation of compression, super-resolution, and denoising solutions.
Among the available subjective test methodologies, pair comparison is
attracting popularity due to its simplicity, reliability, and robustness to
changes in the test conditions, e.g. display resolutions. The main problem that
impairs its wide acceptance is that the number of pairs to compare by subjects
grows quadratically with the number of stimuli that must be considered.
Usually, the paired comparison data obtained is fed into an aggregation model
to obtain a final score for each degraded image and thus, not every comparison
contributes equally to the final quality score. In the past years, several
solutions that sample pairs (from all possible combinations) have been
proposed, from random sampling to active sampling based on the past subjects'
decisions. This paper introduces a novel sampling solution called
\textbf{P}redictive \textbf{S}ampling for \textbf{P}airwise \textbf{C}omparison
(PS-PC) which exploits the characteristics of the input data to make a
prediction of which pairs should be evaluated by subjects. The proposed
solution exploits popular machine learning techniques to select the most
informative pairs for subjects to evaluate, while for the other remaining
pairs, it predicts the subjects' preferences. The experimental results show
that PS-PC is the best choice among the available sampling algorithms with
higher performance for the same number of pairs. Moreover, since the choice of
the pairs is done \emph{a priori} before the subjective test starts, the
algorithm is not required to run during the test and thus much more simple to
deploy in online crowdsourcing subjective tests.
</p>
</div>
</dd>
<dt><a name="item221">[221]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03852" title="Abstract">arXiv:2311.03852</a> [<a href="/pdf/2311.03852" title="Download PDF">pdf</a>, <a href="/ps/2311.03852" title="Download PostScript">ps</a>, <a href="/format/2311.03852" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Improved MDL Estimators Using Fiber Bundle of Local Exponential Families  for Non-exponential Families
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Miyamoto%2C+K">Kohei Miyamoto</a>, 
<a href="/search/cs?searchtype=author&query=Barron%2C+A+R">Andrew R. Barron</a>, 
<a href="/search/cs?searchtype=author&query=Takeuchi%2C+J">Jun&#x27;ichi Takeuchi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 29 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Minimum Description Length (MDL) estimators, using two-part codes for
universal coding, are analyzed. For general parametric families under certain
regularity conditions, we introduce a two-part code whose regret is close to
the minimax regret, where regret of a code with respect to a target family M is
the difference between the code length of the code and the ideal code length
achieved by an element in M. This is a generalization of the result for
exponential families by Gr\"unwald. Our code is constructed by using an
augmented structure of M with a bundle of local exponential families for data
description, which is not needed for exponential families. This result gives a
tight upper bound on risk and loss of the MDL estimators based on the theory
introduced by Barron and Cover in 1991. Further, we show that we can apply the
result to mixture families, which are a typical example of non-exponential
families.
</p>
</div>
</dd>
<dt><a name="item222">[222]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03853" title="Abstract">arXiv:2311.03853</a> [<a href="/pdf/2311.03853" title="Download PDF">pdf</a>, <a href="/format/2311.03853" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On Deep Reinforcement Learning for Traffic Steering Intelligent ORAN
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kavehmadavani%2C+F">Fatemeh Kavehmadavani</a>, 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+V">Van-Dinh Nguyen</a>, 
<a href="/search/cs?searchtype=author&query=Vu%2C+T+X">Thang X. Vu</a>, 
<a href="/search/cs?searchtype=author&query=Chatzinotas%2C+S">Symeon Chatzinotas</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>

</div>
<p class="mathjax">This paper aims to develop the intelligent traffic steering (TS) framework,
which has recently been considered as one of the key developments of 3GPP for
advanced 5G. Since achieving key performance indicators (KPIs) for
heterogeneous services may not be possible in the monolithic architecture, a
novel deep reinforcement learning (DRL)-based TS algorithm is proposed at the
non-real-time (non-RT) RAN intelligent controller (RIC) within the open radio
access network (ORAN) architecture. To enable ORAN's intelligence, we
distribute traffic load onto appropriate paths, which helps efficiently
allocate resources to end users in a downlink multi-service scenario. Our
proposed approach employs a three-step hierarchical process that involves
heuristics, machine learning, and convex optimization to steer traffic flows.
Through system-level simulations, we show the superior performance of the
proposed intelligent TS scheme, surpassing established benchmark systems by
45.50%.
</p>
</div>
</dd>
<dt><a name="item223">[223]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03854" title="Abstract">arXiv:2311.03854</a> [<a href="/pdf/2311.03854" title="Download PDF">pdf</a>, <a href="/format/2311.03854" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Design and Experimental Verification of a Jumping Legged Robot for  Martian Lava Tube Exploration
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Olsen%2C+J+A">J&#xf8;rgen Anker Olsen</a>, 
<a href="/search/cs?searchtype=author&query=Alexis%2C+K">Kostas Alexis</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 21st International Conference on Advanced Robotics (ICAR 2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">The potential of Martian lava tubes for resource extraction and habitat
sheltering highlights the need for robots capable to undertake the grueling
task of their exploration. Driven by this motivation, in this work we introduce
a legged robot system optimized for jumping in the low gravity of Mars,
designed with leg configurations adaptable to both bipedal and quadrupedal
systems. This design utilizes torque-controlled actuators coupled with springs
for high-power jumping, robust locomotion, and an energy-efficient resting
pose. Key design features include a 5-bar mechanism as leg concept, combined
with springs connected by a high-strength cord. The selected 5-bar link lengths
and spring stiffness were optimized for maximizing the jump height in Martian
gravity and realized as a robot leg. Two such legs combined with a compact body
allowed jump testing of a bipedal prototype. The robot is 0.472 m tall and
weighs 7.9 kg. Jump testing with significant safety margins resulted in a
measured jump height of 1.141 m in Earth's gravity, while a total of 4 jumping
experiments are presented. Simulations utilizing the full motor torque and
kinematic limits of the design resulted in a maximum possible jump height of
1.52 m in Earth's gravity and 3.63 m in Mars' gravity, highlighting the
versatility of jumping as a form of locomotion and overcoming obstacles in
lower gravity.
</p>
</div>
</dd>
<dt><a name="item224">[224]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03855" title="Abstract">arXiv:2311.03855</a> [<a href="/pdf/2311.03855" title="Download PDF">pdf</a>, <a href="/format/2311.03855" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Terrain Recognition and Contact Force Estimation through a Sensorized  Paw for Legged Robots
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Vangen%2C+A">Aleksander Vangen</a>, 
<a href="/search/cs?searchtype=author&query=Barnwal%2C+T">Tejal Barnwal</a>, 
<a href="/search/cs?searchtype=author&query=Olsen%2C+J+A">J&#xf8;rgen Anker Olsen</a>, 
<a href="/search/cs?searchtype=author&query=Alexis%2C+K">Kostas Alexis</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 21st International Conference on Advanced Robotics (ICAR 2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">This paper introduces the Terrain Recognition And Contact Force Estimation
Paw, a compact and sensorized shoe designed for legged robots. The paw
end-effector is made of silicon that deforms upon the application of contact
forces, while an embedded micro camera is utilized to capture images of the
deformed inner surface inside the shoe, and a microphone picks up audio
signals. Processed through machine learning techniques, the images are mapped
to compute an accurate estimate of the cumulative 3D force vector, while the
audio signals are analyzed to identify the terrain class (e.g., gravel, snow).
By leveraging its on-edge computation ability, the paw enhances the
capabilities of legged robots by providing key information in real-time that
can be used to adapt locomotion control strategies. To assess the performance
of this novel sensorized paw, we conducted experiments on the data collected
through a specially-designed testbed for force estimation, as well as data from
recordings of the audio signatures of different terrains interacting with the
paw. The results demonstrate the accuracy and effectiveness of the system,
highlighting its potential for improving legged robot performance.
</p>
</div>
</dd>
<dt><a name="item225">[225]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03857" title="Abstract">arXiv:2311.03857</a> [<a href="/pdf/2311.03857" title="Download PDF">pdf</a>, <a href="/format/2311.03857" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Hypergraphs with node attributes: structure and inference
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Badalyan%2C+A">Anna Badalyan</a>, 
<a href="/search/cs?searchtype=author&query=Ruggeri%2C+N">Nicol&#xf2; Ruggeri</a>, 
<a href="/search/cs?searchtype=author&query=De+Bacco%2C+C">Caterina De Bacco</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages, 7 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>; Data Analysis, Statistics and Probability (physics.data-an); Physics and Society (physics.soc-ph); Machine Learning (stat.ML)

</div>
<p class="mathjax">Many networked datasets with units interacting in groups of two or more,
encoded with hypergraphs, are accompanied by extra information about nodes,
such as the role of an individual in a workplace. Here we show how these node
attributes can be used to improve our understanding of the structure resulting
from higher-order interactions. We consider the problem of community detection
in hypergraphs and develop a principled model that combines higher-order
interactions and node attributes to better represent the observed interactions
and to detect communities more accurately than using either of these types of
information alone. The method learns automatically from the input data the
extent to which structure and attributes contribute to explain the data, down
weighing or discarding attributes if not informative. Our algorithmic
implementation is efficient and scales to large hypergraphs and interactions of
large numbers of units. We apply our method to a variety of systems, showing
strong performance in hyperedge prediction tasks and in selecting community
divisions that correlate with attributes when these are informative, but
discarding them otherwise. Our approach illustrates the advantage of using
informative node attributes when available with higher-order data.
</p>
</div>
</dd>
<dt><a name="item226">[226]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03863" title="Abstract">arXiv:2311.03863</a> [<a href="/pdf/2311.03863" title="Download PDF">pdf</a>, <a href="/ps/2311.03863" title="Download PostScript">ps</a>, <a href="/format/2311.03863" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An Explainable Framework for Machine learning-Based Reactive Power  Optimization of Distribution Network
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Liao%2C+W">Wenlong Liao</a>, 
<a href="/search/eess?searchtype=author&query=Sch%C3%A4fer%2C+B">Benjamin Sch&#xe4;fer</a>, 
<a href="/search/eess?searchtype=author&query=Qin%2C+D">Dalin Qin</a>, 
<a href="/search/eess?searchtype=author&query=Zhang%2C+G">Gonghao Zhang</a>, 
<a href="/search/eess?searchtype=author&query=Wang%2C+Z">Zhixian Wang</a>, 
<a href="/search/eess?searchtype=author&query=Yang%2C+Z">Zhe Yang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> It was submitted to the 23rd Power Systems Computation Conference (PSCC 2024) on Sept.2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">To reduce the heavy computational burden of reactive power optimization of
distribution networks, machine learning models are receiving increasing
attention. However, most machine learning models (e.g., neural networks) are
usually considered as black boxes, making it challenging for power system
operators to identify and comprehend potential biases or errors in the
decision-making process of machine learning models. To address this issue, an
explainable machine-learning framework is proposed to optimize the reactive
power in distribution networks. Firstly, a Shapley additive explanation
framework is presented to measure the contribution of each input feature to the
solution of reactive power optimizations generated from machine learning
models. Secondly, a model-agnostic approximation method is developed to
estimate Shapley values, so as to avoid the heavy computational burden
associated with direct calculations of Shapley values. The simulation results
show that the proposed explainable framework can accurately explain the
solution of the machine learning model-based reactive power optimization by
using visual analytics, from both global and instance perspectives. Moreover,
the proposed explainable framework is model-agnostic, and thus applicable to
various models (e.g., neural networks).
</p>
</div>
</dd>
<dt><a name="item227">[227]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03864" title="Abstract">arXiv:2311.03864</a> [<a href="/pdf/2311.03864" title="Download PDF">pdf</a>, <a href="/format/2311.03864" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Modelling and Simulations of Ferroelectric Materials and  Ferroelectric-Based Nanoelectronic Devices
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Esseni%2C+D">David Esseni</a>, 
<a href="/search/cs?searchtype=author&query=Driussi%2C+F">Francesco Driussi</a>, 
<a href="/search/cs?searchtype=author&query=Lizzit%2C+D">Daniel Lizzit</a>, 
<a href="/search/cs?searchtype=author&query=Massarotto%2C+M">Marco Massarotto</a>, 
<a href="/search/cs?searchtype=author&query=Segatto%2C+M">Mattia Segatto</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Presented at the International Conference on Simulation of Semiconductor Processes and Devices (SISPAD) 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Emerging Technologies (cs.ET)</span>

</div>
<p class="mathjax">This paper provides a brief introduction to the phenomenological aspects of
the polarization in ferrroelectric materials, and then an analysis of a few
selected topics related to the modelling of ferroelectrics. The description of
ferroelectric-based devices is quite challenging, particularly because the
ferroelectric is frequently stacked with other dielectrics or with a
semiconductor, as opposed to being placed between metal electrodes. Predictive
modelling of ferroelectric devices is admittedly difficult, and thus the
scrutiny and calibration of the models by comparison to sound experimental data
is of paramount importance.
</p>
</div>
</dd>
<dt><a name="item228">[228]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03865" title="Abstract">arXiv:2311.03865</a> [<a href="/pdf/2311.03865" title="Download PDF">pdf</a>, <a href="/format/2311.03865" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FD-MIA: Efficient Attacks on Fairness-enhanced Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tian%2C+H">Huan Tian</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+G">Guangsheng Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+B">Bo Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+T">Tianqing Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Ding%2C+M">Ming Ding</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+W">Wanlei Zhou</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Under review
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Cryptography and Security (cs.CR)

</div>
<p class="mathjax">Previous studies have developed fairness methods for biased models that
exhibit discriminatory behaviors towards specific subgroups. While these models
have shown promise in achieving fair predictions, recent research has
identified their potential vulnerability to score-based membership inference
attacks (MIAs). In these attacks, adversaries can infer whether a particular
data sample was used during training by analyzing the model's prediction
scores. However, our investigations reveal that these score-based MIAs are
ineffective when targeting fairness-enhanced models in binary classifications.
The attack models trained to launch the MIAs degrade into simplistic threshold
models, resulting in lower attack performance. Meanwhile, we observe that
fairness methods often lead to prediction performance degradation for the
majority subgroups of the training data. This raises the barrier to successful
attacks and widens the prediction gaps between member and non-member data.
Building upon these insights, we propose an efficient MIA method against
fairness-enhanced models based on fairness discrepancy results (FD-MIA). It
leverages the difference in the predictions from both the original and
fairness-enhanced models and exploits the observed prediction gaps as attack
clues. We also explore potential strategies for mitigating privacy leakages.
Extensive experiments validate our findings and demonstrate the efficacy of the
proposed method.
</p>
</div>
</dd>
<dt><a name="item229">[229]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03866" title="Abstract">arXiv:2311.03866</a> [<a href="/pdf/2311.03866" title="Download PDF">pdf</a>, <a href="/format/2311.03866" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SCONE-GAN: Semantic Contrastive learning-based Generative Adversarial  Network for an end-to-end image translation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Abbasnejad%2C+I">Iman Abbasnejad</a>, 
<a href="/search/cs?searchtype=author&query=Zambetta%2C+F">Fabio Zambetta</a>, 
<a href="/search/cs?searchtype=author&query=Salim%2C+F">Flora Salim</a>, 
<a href="/search/cs?searchtype=author&query=Wiley%2C+T">Timothy Wiley</a>, 
<a href="/search/cs?searchtype=author&query=Chan%2C+J">Jeffrey Chan</a>, 
<a href="/search/cs?searchtype=author&query=Gallagher%2C+R">Russell Gallagher</a>, 
<a href="/search/cs?searchtype=author&query=Abbasnejad%2C+E">Ehsan Abbasnejad</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages, 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">SCONE-GAN presents an end-to-end image translation, which is shown to be
effective for learning to generate realistic and diverse scenery images. Most
current image-to-image translation approaches are devised as two mappings: a
translation from the source to target domain and another to represent its
inverse. While successful in many applications, these approaches may suffer
from generating trivial solutions with limited diversity. That is because these
methods learn more frequent associations rather than the scene structures. To
mitigate the problem, we propose SCONE-GAN that utilises graph convolutional
networks to learn the objects dependencies, maintain the image structure and
preserve its semantics while transferring images into the target domain. For
more realistic and diverse image generation we introduce style reference image.
We enforce the model to maximize the mutual information between the style image
and output. The proposed method explicitly maximizes the mutual information
between the related patches, thus encouraging the generator to produce more
diverse images. We validate the proposed algorithm for image-to-image
translation and stylizing outdoor images. Both qualitative and quantitative
results demonstrate the effectiveness of our approach on four dataset.
</p>
</div>
</dd>
<dt><a name="item230">[230]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03867" title="Abstract">arXiv:2311.03867</a> [<a href="/pdf/2311.03867" title="Download PDF">pdf</a>, <a href="/format/2311.03867" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Comparative Study of Knowledge Transfer Methods for Misaligned Urban  Building Labels
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Neupane%2C+B">Bipul Neupane</a>, 
<a href="/search/cs?searchtype=author&query=Aryal%2C+J">Jagannath Aryal</a>, 
<a href="/search/cs?searchtype=author&query=Rajabifard%2C+A">Abbas Rajabifard</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This work has been submitted to Elsevier for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Misalignment in Earth observation (EO) images and building labels impact the
training of accurate convolutional neural networks (CNNs) for semantic
segmentation of building footprints. Recently, three Teacher-Student knowledge
transfer methods have been introduced to address this issue: supervised domain
adaptation (SDA), knowledge distillation (KD), and deep mutual learning (DML).
However, these methods are merely studied for different urban buildings
(low-rise, mid-rise, high-rise, and skyscrapers), where misalignment increases
with building height and spatial resolution. In this study, we present a
workflow for the systematic comparative study of the three methods. The
workflow first identifies the best (with the highest evaluation scores)
hyperparameters, lightweight CNNs for the Student (among 43 CNNs from Computer
Vision), and encoder-decoder networks (EDNs) for both Teachers and Students.
Secondly, three building footprint datasets are developed to train and evaluate
the identified Teachers and Students in the three transfer methods. The results
show that U-Net with VGG19 (U-VGG19) is the best Teacher, and
U-EfficientNetv2B3 and U-EfficientNet-lite0 are among the best Students. With
these Teacher-Student pairs, SDA could yield upto 0.943, 0.868, 0.912, and
0.697 F1 scores in the low-rise, mid-rise, high-rise, and skyscrapers
respectively. KD and DML provide model compression of upto 82%, despite
marginal loss in performance. This new comparison concludes that SDA is the
most effective method to address the misalignment problem, while KD and DML can
efficiently compress network size without significant loss in performance. The
158 experiments and datasets developed in this study will be valuable to
minimise the misaligned labels.
</p>
</div>
</dd>
<dt><a name="item231">[231]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03869" title="Abstract">arXiv:2311.03869</a> [<a href="/pdf/2311.03869" title="Download PDF">pdf</a>, <a href="/format/2311.03869" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fleet Sizing for the Flash Delivery Problem from Multiple Depots a Case  Study in Amsterdam
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kronmueller%2C+M">Maximilian Kronmueller</a>, 
<a href="/search/cs?searchtype=author&query=Fielbaum%2C+A">Andres Fielbaum</a>, 
<a href="/search/cs?searchtype=author&query=Alonso-Mora%2C+J">Javier Alonso-Mora</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Multiagent Systems (cs.MA)</span>; Robotics (cs.RO); Optimization and Control (math.OC)

</div>
<p class="mathjax">In this paper, we present a novel approach for fleet sizing in the context of
flash delivery, a time-sensitive delivery service that requires the fulfilment
of customer requests in minutes. Our approach effectively combines individual
delivery requests into groups and generates optimized operational plans that
can be executed by a single vehicle or autonomous robot. The groups are formed
using a modified routing approach for the flash delivery problem. Combining the
groups into operational plans is done by solving an integer linear problem. To
evaluate the effectiveness of our approach, we compare it against three
alternative methods: fixed vehicle routing, non-pooled deliveries and a
strategy encouraging the pooling of requests. The results demonstrate the value
of our proposed approach, showcasing its ability to optimize the fleet and
improve operational efficiency. Our experimental analysis is based on a
real-world dataset provided by a Dutch retailer, allowing us to gain valuable
insights into the design of flash delivery operations and to analyze the effect
of the maximum allowed delay, the number of stores to pick up goods from and
the employed cost functions.
</p>
</div>
</dd>
<dt><a name="item232">[232]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03873" title="Abstract">arXiv:2311.03873</a> [<a href="/pdf/2311.03873" title="Download PDF">pdf</a>, <a href="/format/2311.03873" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Mini but Mighty: Finetuning ViTs with Mini Adapters
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Marouf%2C+I+E">Imad Eddine Marouf</a>, 
<a href="/search/cs?searchtype=author&query=Tartaglione%2C+E">Enzo Tartaglione</a>, 
<a href="/search/cs?searchtype=author&query=Lathuili%C3%A8re%2C+S">St&#xe9;phane Lathuili&#xe8;re</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> WACV2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Vision Transformers (ViTs) have become one of the dominant architectures in
computer vision, and pre-trained ViT models are commonly adapted to new tasks
via fine-tuning. Recent works proposed several parameter-efficient transfer
learning methods, such as adapters, to avoid the prohibitive training and
storage cost of finetuning. In this work, we observe that adapters perform
poorly when the dimension of adapters is small, and we propose MiMi, a training
framework that addresses this issue. We start with large adapters which can
reach high performance, and iteratively reduce their size. To enable automatic
estimation of the hidden dimension of every adapter, we also introduce a new
scoring function, specifically designed for adapters, that compares the neuron
importance across layers. Our method outperforms existing methods in finding
the best trade-off between accuracy and trained parameters across the three
dataset benchmarks DomainNet, VTAB, and Multi-task, for a total of 29 datasets.
</p>
</div>
</dd>
<dt><a name="item233">[233]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03881" title="Abstract">arXiv:2311.03881</a> [<a href="/pdf/2311.03881" title="Download PDF">pdf</a>, <a href="/format/2311.03881" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Sparse Contrastive Learning of Sentence Embeddings
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=An%2C+R">Ruize An</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+C">Chen Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+D">Dawei Song</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages, 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Recently, SimCSE has shown the feasibility of contrastive learning in
training sentence embeddings and illustrates its expressiveness in spanning an
aligned and uniform embedding space. However, prior studies have shown that
dense models could contain harmful parameters that affect the model
performance, and it is no wonder that SimCSE can as well be invented with such
parameters. Driven by this, parameter sparsification is applied, where
alignment and uniformity scores are used to measure the contribution of each
parameter to the overall quality of sentence embeddings. Drawing from a
preliminary study, we consider parameters with minimal contributions to be
detrimental, as their sparsification results in improved model performance. To
discuss the ubiquity of detrimental parameters and remove them, more
experiments on the standard semantic textual similarity (STS) tasks and
transfer learning tasks are conducted, and the results show that the proposed
sparsified SimCSE (SparseCSE) has excellent performance in comparison with
SimCSE. Furthermore, through in-depth analysis, we establish the validity and
stability of our sparsification method, showcasing that the embedding space
generated by SparseCSE exhibits improved alignment compared to that produced by
SimCSE. Importantly, the uniformity yet remains uncompromised.
</p>
</div>
</dd>
<dt><a name="item234">[234]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03883" title="Abstract">arXiv:2311.03883</a> [<a href="/pdf/2311.03883" title="Download PDF">pdf</a>, <a href="/format/2311.03883" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multiderivative time integration methods preserving nonlinear  functionals via relaxation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Ranocha%2C+H">Hendrik Ranocha</a>, 
<a href="/search/math?searchtype=author&query=Sch%C3%BCtz%2C+J">Jochen Sch&#xfc;tz</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">We combine the recent relaxation approach with multiderivative Runge-Kutta
methods to preserve conservation or dissipation of entropy functionals for
ordinary and partial differential equations. Relaxation methods are minor
modifications of explicit and implicit schemes, requiring only the solution of
a single scalar equation per time step in addition to the baseline scheme. We
demonstrate the robustness of the resulting methods for a range of test
problems including the 3D compressible Euler equations. In particular, we point
out improved error growth rates for certain entropy-conservative problems
including nonlinear dispersive wave equations.
</p>
</div>
</dd>
<dt><a name="item235">[235]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03886" title="Abstract">arXiv:2311.03886</a> [<a href="/pdf/2311.03886" title="Download PDF">pdf</a>, <a href="/format/2311.03886" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Formulating Discrete Probability Flow Through Optimal Transport
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+P">Pengze Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Yin%2C+H">Hubery Yin</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+C">Chen Li</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+X">Xiaohua Xie</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accept by NeurIPS2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Optimization and Control (math.OC)

</div>
<p class="mathjax">Continuous diffusion models are commonly acknowledged to display a
deterministic probability flow, whereas discrete diffusion models do not. In
this paper, we aim to establish the fundamental theory for the probability flow
of discrete diffusion models. Specifically, we first prove that the continuous
probability flow is the Monge optimal transport map under certain conditions,
and also present an equivalent evidence for discrete cases. In view of these
findings, we are then able to define the discrete probability flow in line with
the principles of optimal transport. Finally, drawing upon our newly
established definitions, we propose a novel sampling method that surpasses
previous discrete diffusion models in its ability to generate more certain
outcomes. Extensive experiments on the synthetic toy dataset and the CIFAR-10
dataset have validated the effectiveness of our proposed discrete probability
flow. Code is released at:
https://github.com/PangzeCheung/Discrete-Probability-Flow.
</p>
</div>
</dd>
<dt><a name="item236">[236]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03889" title="Abstract">arXiv:2311.03889</a> [<a href="/pdf/2311.03889" title="Download PDF">pdf</a>, <a href="/format/2311.03889" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Efficiently Detecting Performance Changes in FaaS Application Releases
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Grambow%2C+M">Martin Grambow</a>, 
<a href="/search/cs?searchtype=author&query=Dockenfu%C3%9F%2C+T">Tim Dockenfu&#xdf;</a>, 
<a href="/search/cs?searchtype=author&query=Schirmer%2C+T">Trever Schirmer</a>, 
<a href="/search/cs?searchtype=author&query=Japke%2C+N">Nils Japke</a>, 
<a href="/search/cs?searchtype=author&query=Bermbach%2C+D">David Bermbach</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted for publication in 9th International Workshop on Serverless Computing (WoSC '23), ACM 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>

</div>
<p class="mathjax">The source code of Function as a Service (FaaS) applications is constantly
being refined. To detect if a source code change introduces a significant
performance regression, the traditional benchmarking approach evaluates both
the old and new function version separately using numerous artificial requests.
<br />In this paper, we describe a wrapper approach that enables the Randomized
Multiple Interleaved Trials (RMIT) benchmark execution methodology in FaaS
environments and use bootstrapping percentile intervals to derive more accurate
confidence intervals of detected performance changes. We evaluate our approach
using two public FaaS providers, an artificial performance issue, and several
benchmark configuration parameters. We conclude that RMIT can shrink the width
of confidence intervals in the results from 10.65% using the traditional
approach to 0.37% using RMIT and thus enables a more fine-grained performance
change detection.
</p>
</div>
</dd>
<dt><a name="item237">[237]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03893" title="Abstract">arXiv:2311.03893</a> [<a href="/pdf/2311.03893" title="Download PDF">pdf</a>, <a href="/format/2311.03893" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Understanding Tool Discovery and Tool Innovation Using Active Inference
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Collis%2C+P">Poppy Collis</a>, 
<a href="/search/cs?searchtype=author&query=Kinghorn%2C+P+F">Paul F Kinghorn</a>, 
<a href="/search/cs?searchtype=author&query=Buckley%2C+C+L">Christopher L Buckley</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, 8 pages, accepted for International Workshop on Active Inference 2023, due to be published in IWAI 2023, CCIS 1915 proceedings (Springer) 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Neurons and Cognition (q-bio.NC)

</div>
<p class="mathjax">The ability to invent new tools has been identified as an important facet of
our ability as a species to problem solve in dynamic and novel environments.
While the use of tools by artificial agents presents a challenging task and has
been widely identified as a key goal in the field of autonomous robotics, far
less research has tackled the invention of new tools by agents. In this paper,
(1) we articulate the distinction between tool discovery and tool innovation by
providing a minimal description of the two concepts under the formalism of
active inference. We then (2) apply this description to construct a toy model
of tool innovation by introducing the notion of tool affordances into the
hidden states of the agent's probabilistic generative model. This particular
state factorisation facilitates the ability to not just discover tools but
invent them through the offline induction of an appropriate tool property. We
discuss the implications of these preliminary results and outline future
directions of research.
</p>
</div>
</dd>
<dt><a name="item238">[238]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03895" title="Abstract">arXiv:2311.03895</a> [<a href="/pdf/2311.03895" title="Download PDF">pdf</a>, <a href="/ps/2311.03895" title="Download PostScript">ps</a>, <a href="/format/2311.03895" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Improved Deterministic Streaming Algorithms for Non-monotone Submodular  Maximization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sun%2C+X">Xiaoming Sun</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jialin Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+S">Shuo Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>

</div>
<p class="mathjax">Submodular maximization is one of the central topics in combinatorial
optimization. It has found numerous applications in the real world. Streaming
algorithms for submodule maximization have gained attention in recent years,
allowing for real-time processing of large data sets by looking at each piece
of data only once. However, most of the state-of-the-art algorithms are subject
to monotone cardinality constraint. There remain non-negligible gaps with
respect to approximation ratios between cardinality and other constraints like
$d$-knapsack in non-monotone submodular maximization.
<br />In this paper, we propose deterministic algorithms with improved
approximation ratios for non-monotone submodular maximization. Specifically,
for the cardinality constraint, we provide a deterministic $1/6-\epsilon$
approximation algorithm with $O(\frac{k\log k}{\epsilon})$ memory and sublinear
query time, while the previous best algorithm is randomized with a $0.1921$
approximation ratio. To the best of our knowledge, this is the first
deterministic streaming algorithm for the cardinality constraint. For the
$d$-knapsack constraint, we provide a deterministic $\frac{1}{4(d+1)}-\epsilon$
approximation algorithm with $O(\frac{b\log b}{\epsilon})$ memory and
$O(\frac{\log b}{\epsilon})$ query time per element. To the best of our
knowledge, there is currently no streaming algorithm for this constraint.
</p>
</div>
</dd>
<dt><a name="item239">[239]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03896" title="Abstract">arXiv:2311.03896</a> [<a href="/pdf/2311.03896" title="Download PDF">pdf</a>, <a href="/format/2311.03896" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> iACOS: Advancing Implicit Sentiment Extraction with Informative and  Adaptive Negative Examples
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+X">Xiancai Xu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jia-Dong Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Xiong%2C+L">Lei Xiong</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zhishang Liu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Aspect-based sentiment analysis (ABSA) have been extensively studied, but
little light has been shed on the quadruple extraction consisting of four
fundamental elements: aspects, categories, opinions and sentiments, especially
with implicit aspects and opinions. In this paper, we propose a new method
iACOS for extracting Implicit Aspects with Categories and Opinions with
Sentiments. First, iACOS appends two implicit tokens at the end of a text to
capture the context-aware representation of all tokens including implicit
aspects and opinions. Second, iACOS develops a sequence labeling model over the
context-aware token representation to co-extract explicit and implicit aspects
and opinions. Third, iACOS devises a multi-label classifier with a specialized
multi-head attention for discovering aspect-opinion pairs and predicting their
categories and sentiments simultaneously. Fourth, iACOS leverages informative
and adaptive negative examples to jointly train the multi-label classifier and
the other two classifiers on categories and sentiments by multi-task learning.
Finally, the experimental results show that iACOS significantly outperforms
other quadruple extraction baselines according to the F1 score on two public
benchmark datasets.
</p>
</div>
</dd>
<dt><a name="item240">[240]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03897" title="Abstract">arXiv:2311.03897</a> [<a href="/pdf/2311.03897" title="Download PDF">pdf</a>, <a href="/format/2311.03897" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Temporal Graph Representation Learning with Adaptive Augmentation  Contrastive
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+H">Hongjiang Chen</a>, 
<a href="/search/cs?searchtype=author&query=Jiao%2C+P">Pengfei Jiao</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+H">Huijun Tang</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+H">Huaming Wu</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Joint European Conference on Machine Learning and Knowledge
  Discovery in Databases, pp. 683-699. 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Temporal graph representation learning aims to generate low-dimensional
dynamic node embeddings to capture temporal information as well as structural
and property information. Current representation learning methods for temporal
networks often focus on capturing fine-grained information, which may lead to
the model capturing random noise instead of essential semantic information.
While graph contrastive learning has shown promise in dealing with noise, it
only applies to static graphs or snapshots and may not be suitable for handling
time-dependent noise. To alleviate the above challenge, we propose a novel
Temporal Graph representation learning with Adaptive augmentation Contrastive
(TGAC) model. The adaptive augmentation on the temporal graph is made by
combining prior knowledge with temporal information, and the contrastive
objective function is constructed by defining the augmented inter-view contrast
and intra-view contrast. To complement TGAC, we propose three adaptive
augmentation strategies that modify topological features to reduce noise from
the network. Our extensive experiments on various real networks demonstrate
that the proposed model outperforms other temporal graph representation
learning methods.
</p>
</div>
</dd>
<dt><a name="item241">[241]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03899" title="Abstract">arXiv:2311.03899</a> [<a href="/pdf/2311.03899" title="Download PDF">pdf</a>, <a href="/format/2311.03899" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning-Based Latency-Constrained Fronthaul Compression Optimization in  C-RAN
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gr%C3%B6nland%2C+A">Axel Gr&#xf6;nland</a>, 
<a href="/search/cs?searchtype=author&query=Klaiqi%2C+B">Bleron Klaiqi</a>, 
<a href="/search/cs?searchtype=author&query=Gelabert%2C+X">Xavier Gelabert</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted for publication at IEEE International Workshop on Computer Aided Modeling and Design of Communication Links and Networks (CAMAD) 6 to 8 November 2023, Edinburgh, Scotland. arXiv admin note: text overlap with <a href="/abs/2309.15060">arXiv:2309.15060</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">The evolution of wireless mobile networks towards cloudification, where Radio
Access Network (RAN) functions can be hosted at either a central or distributed
locations, offers many benefits like low cost deployment, higher capacity, and
improved hardware utilization. Nevertheless, the flexibility in the functional
deployment comes at the cost of stringent fronthaul (FH) capacity and latency
requirements. One possible approach to deal with these rigorous constraints is
to use FH compression techniques. To ensure that FH capacity and latency
requirements are met, more FH compression is applied during high load, while
less compression is applied during medium and low load to improve FH
utilization and air interface performance. In this paper, a model-free deep
reinforcement learning (DRL) based FH compression (DRL-FC) framework is
proposed that dynamically controls FH compression through various configuration
parameters such as modulation order, precoder granularity, and precoder weight
quantization that affect both FH load and air interface performance. Simulation
results show that DRL-FC exhibits significantly higher FH utilization (68.7% on
average) and air interface throughput than a reference scheme (i.e. with no
applied compression) across different FH load levels. At the same time, the
proposed DRL-FC framework is able to meet the predefined FH latency constraints
(in our case set to 260 $\mu$s) under various FH loads.
</p>
</div>
</dd>
<dt><a name="item242">[242]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03900" title="Abstract">arXiv:2311.03900</a> [<a href="/pdf/2311.03900" title="Download PDF">pdf</a>, <a href="/ps/2311.03900" title="Download PostScript">ps</a>, <a href="/format/2311.03900" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Why Fair Automated Hiring Systems Breach EU Non-Discrimination Law
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Poe%2C+R+L">Robert Lee Poe</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This article was written for, accepted by, and presented at the First Workshop on ML, Law, and Society, under the "Non-Functional Tradeoffs, Law and Society" call for papers at the European Conference on Machine Learning and Principles and Practice of Knowledge Discovery in Databases - Workshop and Tutorial Track
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>

</div>
<p class="mathjax">Employment selection processes that use automated hiring systems based on
machine learning are becoming increasingly commonplace. Meanwhile, concerns
about algorithmic direct and indirect discrimination that result from such
systems are front-and-center, and the technical solutions provided by the
research community often systematically deviate from the principle of equal
treatment to combat disparate or adverse impacts on groups based on protected
attributes. Those technical solutions are now being used in commercially
available automated hiring systems, potentially engaging in real-world
discrimination. Algorithmic fairness and algorithmic non-discrimination are not
the same. This article examines a conflict between the two: whether such hiring
systems are compliant with EU non-discrimination law.
</p>
</div>
</dd>
<dt><a name="item243">[243]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03901" title="Abstract">arXiv:2311.03901</a> [<a href="/pdf/2311.03901" title="Download PDF">pdf</a>, <a href="/ps/2311.03901" title="Download PostScript">ps</a>, <a href="/format/2311.03901" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Parikh&#x27;s Theorem Made Symbolic
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hague%2C+M">Matthew Hague</a>, 
<a href="/search/cs?searchtype=author&query=Je%C5%BC%2C+A">Artur Je&#x17c;</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+A+W">Anthony W. Lin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted tp POPL '24
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Formal Languages and Automata Theory (cs.FL)</span>; Logic in Computer Science (cs.LO)

</div>
<p class="mathjax">Parikh's Theorem is a fundamental result in automata theory with numerous
applications in computer science: software verification (e.g. infinite-state
verification, string constraints, and theory of arrays), verification of
cryptographic protocols (e.g. using Horn clauses modulo equational theories)
and database querying (e.g. evaluating path-queries in graph databases).
Parikh's Theorem states that the letter-counting abstraction of a language
recognized by finite automata or context-free grammars is definable in
Presburger Arithmetic. Unfortunately, real-world applications typically require
large alphabets - which are well-known to be not amenable to explicit treatment
of the alphabets.
<br />Symbolic automata have proven in the last decade to be an effective
algorithmic framework for handling large finite or even infinite alphabets. A
symbolic automaton employs an effective boolean algebra, which offers a
symbolic representation of character sets and often lends itself to an
exponentially more succinct representation of a language. Instead of
letter-counting, Parikh's Theorem for symbolic automata amounts to counting the
number of times different predicates are satisfied by an input sequence.
Unfortunately, naively applying Parikh's Theorem from classical automata theory
to symbolic automata yields existential Presburger formulas of exponential
size. We provide a new construction for Parikh's Theorem for symbolic automata
and grammars, which avoids this exponential blowup: our algorithm computes an
existential formula in polynomial-time over (quantifier-free) Presburger and
the base theory. In fact, our algorithm extends to the model of parametric
symbolic grammars, which are one of the most expressive models of languages
over infinite alphabets. We have implemented our algorithm and show it can be
used to solve string constraints that are difficult to solve by existing
solvers.
</p>
</div>
</dd>
<dt><a name="item244">[244]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03904" title="Abstract">arXiv:2311.03904</a> [<a href="/pdf/2311.03904" title="Download PDF">pdf</a>, <a href="/format/2311.03904" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> RobustMat: Neural Diffusion for Street Landmark Patch Matching under  Challenging Environments
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=She%2C+R">Rui She</a>, 
<a href="/search/cs?searchtype=author&query=Kang%2C+Q">Qiyu Kang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Sijie Wang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yuan-Rui Yang</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+K">Kai Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+Y">Yang Song</a>, 
<a href="/search/cs?searchtype=author&query=Tay%2C+W+P">Wee Peng Tay</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">For autonomous vehicles (AVs), visual perception techniques based on sensors
like cameras play crucial roles in information acquisition and processing. In
various computer perception tasks for AVs, it may be helpful to match landmark
patches taken by an onboard camera with other landmark patches captured at a
different time or saved in a street scene image database. To perform matching
under challenging driving environments caused by changing seasons, weather, and
illumination, we utilize the spatial neighborhood information of each patch. We
propose an approach, named RobustMat, which derives its robustness to
perturbations from neural differential equations. A convolutional neural ODE
diffusion module is used to learn the feature representation for the landmark
patches. A graph neural PDE diffusion module then aggregates information from
neighboring landmark patches in the street scene. Finally, feature similarity
learning outputs the final matching score. Our approach is evaluated on several
street scene datasets and demonstrated to achieve state-of-the-art matching
results under environmental perturbations.
</p>
</div>
</dd>
<dt><a name="item245">[245]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03909" title="Abstract">arXiv:2311.03909</a> [<a href="/pdf/2311.03909" title="Download PDF">pdf</a>, <a href="/ps/2311.03909" title="Download PostScript">ps</a>, <a href="/format/2311.03909" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Primal Separation and Approximation for the $\{0, 1/2\}$-closure
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Brandl%2C+L">Lukas Brandl</a>, 
<a href="/search/cs?searchtype=author&query=Schulz%2C+A+S">Andreas S. Schulz</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Discrete Mathematics (cs.DM)</span>; Combinatorics (math.CO); Optimization and Control (math.OC)

</div>
<p class="mathjax">We advance the theoretical study of $\{0, 1/2\}$-cuts for integer programming
problems $\max\{c^T x \colon A x \leq b, x \text{ integer}\}$. Such cuts are
Gomory-Chv\'atal cuts that only need multipliers of value $0$ or $1/2$ in their
derivation. The intersection of all $\{0, 1/2\}$-cuts derived from $Ax \le b$
is denoted by $P_{1/2}$ and called the $\{0,1/2\}$-closure of $P = \{x : Ax \le
b\}$. The primal separation problem for $\{0, 1/2\}$-cuts is: Given a vertex
$\hat x$ of the integer hull of $P$ and some fractional point $x^* \in P$, does
there exist a $\{0,1/2\}$-cut that is tight at $\hat x$ and violated by $x^*$?
Primal separation is the key ingredient of primal cutting-plane approaches to
integer programming. In general, primal separation for $\{0,1/2\}$-cuts is
NP-hard. We present two cases for which primal separation is solvable in
polynomial time. As an interesting side product, we obtain a(nother) simple
proof that matching can be solved in polynomial time.
<br />Furthermore, since optimization over the Gomory-Chv\'atal closure is also
NP-hard, there has been recent research on solving the optimization problem
over the Gomory-Chv\'atal closure approximately. In a similar spirit, we show
that the optimization problem over the $\{0,1/2\}$-closure can be solved in
polynomial time up to a factor $(1 + \varepsilon)$, for any fixed $\varepsilon
&gt; 0$.
</p>
</div>
</dd>
<dt><a name="item246">[246]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03910" title="Abstract">arXiv:2311.03910</a> [<a href="/pdf/2311.03910" title="Download PDF">pdf</a>, <a href="/ps/2311.03910" title="Download PostScript">ps</a>, <a href="/format/2311.03910" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Structure of universal formulas
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yarotsky%2C+D">Dmitry Yarotsky</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Data Structures and Algorithms (cs.DS); Neural and Evolutionary Computing (cs.NE); Classical Analysis and ODEs (math.CA)

</div>
<p class="mathjax">By universal formulas we understand parameterized analytic expressions that
have a fixed complexity, but nevertheless can approximate any continuous
function on a compact set. There exist various examples of such formulas,
including some in the form of neural networks. In this paper we analyze the
essential structural elements of these highly expressive models. We introduce a
hierarchy of expressiveness classes connecting the global approximability
property to the weaker property of infinite VC dimension, and prove a series of
classification results for several increasingly complex functional families. In
particular, we introduce a general family of
polynomially-exponentially-algebraic functions that, as we prove, is subject to
polynomial constraints. As a consequence, we show that fixed-size neural
networks with not more than one layer of neurons having transcendental
activations (e.g., sine or standard sigmoid) cannot in general approximate
functions on arbitrary finite sets. On the other hand, we give examples of
functional families, including two-hidden-layer neural networks, that
approximate functions on arbitrary finite sets, but fail to do that on the
whole domain of definition.
</p>
</div>
</dd>
<dt><a name="item247">[247]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03912" title="Abstract">arXiv:2311.03912</a> [<a href="/pdf/2311.03912" title="Download PDF">pdf</a>, <a href="/format/2311.03912" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FLORA: Fine-grained Low-Rank Architecture Search for Vision Transformer
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chang%2C+C">Chi-Chih Chang</a>, 
<a href="/search/cs?searchtype=author&query=Sung%2C+Y">Yuan-Yao Sung</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+S">Shixing Yu</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+N">Ning-Chi Huang</a>, 
<a href="/search/cs?searchtype=author&query=Marculescu%2C+D">Diana Marculescu</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+K">Kai-Chiang Wu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by WACV 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Vision Transformers (ViT) have recently demonstrated success across a myriad
of computer vision tasks. However, their elevated computational demands pose
significant challenges for real-world deployment. While low-rank approximation
stands out as a renowned method to reduce computational loads, efficiently
automating the target rank selection in ViT remains a challenge. Drawing from
the notable similarity and alignment between the processes of rank selection
and One-Shot NAS, we introduce FLORA, an end-to-end automatic framework based
on NAS. To overcome the design challenge of supernet posed by vast search
space, FLORA employs a low-rank aware candidate filtering strategy. This method
adeptly identifies and eliminates underperforming candidates, effectively
alleviating potential undertraining and interference among subnetworks. To
further enhance the quality of low-rank supernets, we design a low-rank
specific training paradigm. First, we propose weight inheritance to construct
supernet and enable gradient sharing among low-rank modules. Secondly, we adopt
low-rank aware sampling to strategically allocate training resources, taking
into account inherited information from pre-trained models. Empirical results
underscore FLORA's efficacy. With our method, a more fine-grained rank
configuration can be generated automatically and yield up to 33% extra FLOPs
reduction compared to a simple uniform configuration. More specific,
FLORA-DeiT-B/FLORA-Swin-B can save up to 55%/42% FLOPs almost without
performance degradtion. Importantly, FLORA boasts both versatility and
orthogonality, offering an extra 21%-26% FLOPs reduction when integrated with
leading compression techniques or compact hybrid structures. Our code is
publicly available at https://github.com/shadowpa0327/FLORA.
</p>
</div>
</dd>
<dt><a name="item248">[248]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03919" title="Abstract">arXiv:2311.03919</a> [<a href="/pdf/2311.03919" title="Download PDF">pdf</a>, <a href="/format/2311.03919" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Unveiling the Invisible: Detection and Evaluation of Prototype Pollution  Gadgets with Dynamic Taint Analysis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shcherbakov%2C+M">Mikhail Shcherbakov</a>, 
<a href="/search/cs?searchtype=author&query=Moosbrugger%2C+P">Paul Moosbrugger</a>, 
<a href="/search/cs?searchtype=author&query=Balliu%2C+M">Musard Balliu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Programming Languages (cs.PL)

</div>
<p class="mathjax">For better or worse, JavaScript is the cornerstone of modern Web.
Prototype-based languages like JavaScript are susceptible to prototype
pollution vulnerabilities, enabling an attacker to inject arbitrary properties
into an object's prototype. The attacker can subsequently capitalize on the
injected properties by executing otherwise benign pieces of code, so-called
gadgets, that perform security-sensitive operations. The success of an attack
largely depends on the presence of gadgets, leading to high-profile exploits
such as privilege escalation and arbitrary code execution (ACE).
<br />This paper proposes Dasty, the first semi-automated pipeline to help
developers identify gadgets in their applications' software supply chain. Dasty
targets server-side Node.js applications and relies on an enhancement of
dynamic taint analysis which we implement with the dynamic AST-level
instrumentation. Moreover, Dasty provides support for visualization of code
flows with an IDE, thus facilitating the subsequent manual analysis for
building proof-of-concept exploits. To illustrate the danger of gadgets, we use
Dasty in a study of the most dependent-upon NPM packages to analyze the
presence of gadgets leading to ACE. Dasty identifies 1,269 server-side
packages, of which 631 have code flows that may reach dangerous sinks. We
manually prioritize and verify the candidate flows to build proof-of-concept
exploits for 49 NPM packages, including popular packages such as ejs,
nodemailer and workerpool. To investigate how Dasty integrates with existing
tools to find end-to-end exploits, we conduct an in-depth analysis of a popular
data visualization dashboard to find one high-severity CVE-2023-31415 leading
to remote code execution. For the first time, our results systematically
demonstrate the dangers of server-side gadgets and call for further research to
solve the problem.
</p>
</div>
</dd>
<dt><a name="item249">[249]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03920" title="Abstract">arXiv:2311.03920</a> [<a href="/pdf/2311.03920" title="Download PDF">pdf</a>, <a href="/format/2311.03920" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An Intelligent Edge-Deployable Indoor Air Quality Monitoring and  Activity Recognition Approach
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Berkani%2C+M+R+A">Mohamed Rafik Aymene Berkani</a>, 
<a href="/search/cs?searchtype=author&query=Chouchane%2C+A">Ammar Chouchane</a>, 
<a href="/search/cs?searchtype=author&query=Himeur%2C+Y">Yassine Himeur</a>, 
<a href="/search/cs?searchtype=author&query=Ouamane%2C+A">Abdelmalik Ouamane</a>, 
<a href="/search/cs?searchtype=author&query=Amira%2C+A">Abbes Amira</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages, 6 figures, and 4 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>; Computational Engineering, Finance, and Science (cs.CE)

</div>
<p class="mathjax">The surveillance of indoor air quality is paramount for ensuring
environmental safety, a task made increasingly viable due to advancements in
technology and the application of artificial intelligence and deep learning
(DL) tools. This paper introduces an intelligent system dedicated to monitoring
air quality and categorizing activities within indoor environments using a DL
approach based on 1D Convolutional Neural Networks (1D-CNNs). Our system
integrates six diverse sensors to gather measurement parameters, which
subsequently train a 1D CNN model for activity recognition. This proposed model
boasts a lightweight and edge-deployable design, rendering it ideal for
real-time applications. We conducted our experiments utilizing an air quality
dataset specifically designed for Activity of Daily Living (ADL)
classification. The results illustrate the proposed model's efficacy, achieving
a remarkable accuracy of 97.00%, a minimal loss value of 0.15%, and a swift
prediction time of 41 milliseconds.
</p>
</div>
</dd>
<dt><a name="item250">[250]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03923" title="Abstract">arXiv:2311.03923</a> [<a href="/pdf/2311.03923" title="Download PDF">pdf</a>, <a href="/format/2311.03923" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Hardware Aware Evolutionary Neural Architecture Search using  Representation Similarity Metric
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sinha%2C+N">Nilotpal Sinha</a>, 
<a href="/search/cs?searchtype=author&query=Shabayek%2C+A+E+R">Abd El Rahman Shabayek</a>, 
<a href="/search/cs?searchtype=author&query=Kacem%2C+A">Anis Kacem</a>, 
<a href="/search/cs?searchtype=author&query=Rostami%2C+P">Peyman Rostami</a>, 
<a href="/search/cs?searchtype=author&query=Shneider%2C+C">Carl Shneider</a>, 
<a href="/search/cs?searchtype=author&query=Aouada%2C+D">Djamila Aouada</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> WACV 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neural and Evolutionary Computing (cs.NE)</span>

</div>
<p class="mathjax">Hardware-aware Neural Architecture Search (HW-NAS) is a technique used to
automatically design the architecture of a neural network for a specific task
and target hardware. However, evaluating the performance of candidate
architectures is a key challenge in HW-NAS, as it requires significant
computational resources. To address this challenge, we propose an efficient
hardware-aware evolution-based NAS approach called HW-EvRSNAS. Our approach
re-frames the neural architecture search problem as finding an architecture
with performance similar to that of a reference model for a target hardware,
while adhering to a cost constraint for that hardware. This is achieved through
a representation similarity metric known as Representation Mutual Information
(RMI) employed as a proxy performance evaluator. It measures the mutual
information between the hidden layer representations of a reference model and
those of sampled architectures using a single training batch. We also use a
penalty term that penalizes the search process in proportion to how far an
architecture's hardware cost is from the desired hardware cost threshold. This
resulted in a significantly reduced search time compared to the literature that
reached up to 8000x speedups resulting in lower CO2 emissions. The proposed
approach is evaluated on two different search spaces while using lower
computational resources. Furthermore, our approach is thoroughly examined on
six different edge devices under various hardware cost constraints.
</p>
</div>
</dd>
<dt><a name="item251">[251]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03926" title="Abstract">arXiv:2311.03926</a> [<a href="/pdf/2311.03926" title="Download PDF">pdf</a>, <a href="/ps/2311.03926" title="Download PostScript">ps</a>, <a href="/format/2311.03926" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the Coupling of Hamilton&#x27;s Principle and Thermodynamic Extremal  Principles
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hackl%2C+K">Klaus Hackl</a>, 
<a href="/search/cs?searchtype=author&query=Svoboda%2C+J">Ji&#x159;&#xed; Svoboda</a>, 
<a href="/search/cs?searchtype=author&query=Fischer%2C+F+D">Franz Dieter Fischer</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Engineering, Finance, and Science (cs.CE)</span>

</div>
<p class="mathjax">Extremal principles can generally be divided into two rather distinct
classes. There are, on the one hand side, formulations based on the Lagrangian
or Hamiltonian mechanics, respectively, dealing with time dependent problems,
but essentially resting on conservation of energy and thus being not applicable
to dissipative systems in a consistent way. On the other hand, there are
formulations based essentially on maximizing the dissipation, working
efficiently for the description of dissipative systems, but being not suitable
for including inertia effects. Many at-tempts can be found in the literature to
overcome this split into incompatible principles. How-ever, essentially all of
them possess an unnatural appearance. In this work, we suggest a solution to
this dilemma resting on an additional assumption based on the thermodynamic
driving forces involved. Applications to a simple dissipative structure and a
material with varying mass demonstrate the capability of the proposed approach.
</p>
</div>
</dd>
<dt><a name="item252">[252]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03928" title="Abstract">arXiv:2311.03928</a> [<a href="/pdf/2311.03928" title="Download PDF">pdf</a>, <a href="/format/2311.03928" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Improving Korean NLP Tasks with Linguistically Informed Subword  Tokenization and Sub-character Decomposition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jeon%2C+T">Taehee Jeon</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+B">Bongseok Yang</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+C">Changhwan Kim</a>, 
<a href="/search/cs?searchtype=author&query=Lim%2C+Y">Yoonseob Lim</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 3 figures, 5 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">We introduce a morpheme-aware subword tokenization method that utilizes
sub-character decomposition to address the challenges of applying Byte Pair
Encoding (BPE) to Korean, a language characterized by its rich morphology and
unique writing system. Our approach balances linguistic accuracy with
computational efficiency in Pre-trained Language Models (PLMs). Our evaluations
show that this technique achieves good performances overall, notably improving
results in the syntactic task of NIKL-CoLA. This suggests that integrating
morpheme type information can enhance language models' syntactic and semantic
capabilities, indicating that adopting more linguistic insights can further
improve performance beyond standard morphological analysis.
</p>
</div>
</dd>
<dt><a name="item253">[253]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03932" title="Abstract">arXiv:2311.03932</a> [<a href="/pdf/2311.03932" title="Download PDF">pdf</a>, <a href="/format/2311.03932" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> TempoGRAPHer: Aggregation Based Temporal Graph Exploration
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tsoukanara%2C+E">Evangelia Tsoukanara</a>, 
<a href="/search/cs?searchtype=author&query=Koloniari%2C+G">Georgia Koloniari</a>, 
<a href="/search/cs?searchtype=author&query=Pitoura%2C+E">Evaggelia Pitoura</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>

</div>
<p class="mathjax">Graphs offer a generic abstraction for modeling entities, and the
interactions and relationships between them. Most real world graphs, such as
social and cooperation networks evolve over time, and exploring their evolution
may reveal important information. In this paper, we present TempoGRAPHer, a
system for visualizing and analyzing the evolution of a temporal attributed
graph. TempoGRAPHer supports both temporal and attribute aggregation. It also
allows graph exploration by identifying periods of significant growth,
shrinkage, or stability. Temporal exploration is supported by two complementary
strategies, namely skyline and interaction-based exploration. Skyline-based
exploration provides insights on the overall trends in the evolution, while
interaction-based exploration offers a closer look at specific parts of the
graph evolution history where significant changes appeared. We showcase the
usefulness of TempoGRAPHer in understanding graph evolution by presenting a
detailed scenario that explores the evolution of a contact network between
primary school students.
</p>
</div>
</dd>
<dt><a name="item254">[254]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03938" title="Abstract">arXiv:2311.03938</a> [<a href="/pdf/2311.03938" title="Download PDF">pdf</a>, <a href="/format/2311.03938" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Analysis of NaN Divergence in Training Monocular Depth Estimation Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kim%2C+B+J">Bum Jun Kim</a>, 
<a href="/search/cs?searchtype=author&query=Jang%2C+H">Hyeonah Jang</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+S+W">Sang Woo Kim</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 3 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">The latest advances in deep learning have facilitated the development of
highly accurate monocular depth estimation models. However, when training a
monocular depth estimation network, practitioners and researchers have observed
not a number (NaN) loss, which disrupts gradient descent optimization. Although
several practitioners have reported the stochastic and mysterious occurrence of
NaN loss that bothers training, its root cause is not discussed in the
literature. This study conducted an in-depth analysis of NaN loss during
training a monocular depth estimation network and identified three types of
vulnerabilities that cause NaN loss: 1) the use of square root loss, which
leads to an unstable gradient; 2) the log-sigmoid function, which exhibits
numerical stability issues; and 3) certain variance implementations, which
yield incorrect computations. Furthermore, for each vulnerability, the
occurrence of NaN loss was demonstrated and practical guidelines to prevent NaN
loss were presented. Experiments showed that both optimization stability and
performance on monocular depth estimation could be improved by following our
guidelines.
</p>
</div>
</dd>
<dt><a name="item255">[255]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03942" title="Abstract">arXiv:2311.03942</a> [<a href="/pdf/2311.03942" title="Download PDF">pdf</a>, <a href="/format/2311.03942" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Music Meta Ontology: a flexible semantic model for the  interoperability of music metadata
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=de+Berardinis%2C+J">Jacopo de Berardinis</a>, 
<a href="/search/cs?searchtype=author&query=Carriero%2C+V+A">Valentina Anita Carriero</a>, 
<a href="/search/cs?searchtype=author&query=Mero%C3%B1o-Pe%C3%B1uela%2C+A">Albert Mero&#xf1;o-Pe&#xf1;uela</a>, 
<a href="/search/cs?searchtype=author&query=Poltronieri%2C+A">Andrea Poltronieri</a>, 
<a href="/search/cs?searchtype=author&query=Presutti%2C+V">Valentina Presutti</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Proceedings of the the 24th International Society for Music
  Information Retrieval Conference, ISMIR 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Artificial Intelligence (cs.AI); Multimedia (cs.MM)

</div>
<p class="mathjax">The semantic description of music metadata is a key requirement for the
creation of music datasets that can be aligned, integrated, and accessed for
information retrieval and knowledge discovery. It is nonetheless an open
challenge due to the complexity of musical concepts arising from different
genres, styles, and periods -- standing to benefit from a lingua franca to
accommodate various stakeholders (musicologists, librarians, data engineers,
etc.). To initiate this transition, we introduce the Music Meta ontology, a
rich and flexible semantic model to describe music metadata related to artists,
compositions, performances, recordings, and links. We follow eXtreme Design
methodologies and best practices for data engineering, to reflect the
perspectives and the requirements of various stakeholders into the design of
the model, while leveraging ontology design patterns and accounting for
provenance at different levels (claims, links). After presenting the main
features of Music Meta, we provide a first evaluation of the model, alignments
to other schema (Music Ontology, DOREMUS, Wikidata), and support for data
transformation.
</p>
</div>
</dd>
<dt><a name="item256">[256]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03943" title="Abstract">arXiv:2311.03943</a> [<a href="/pdf/2311.03943" title="Download PDF">pdf</a>, <a href="/format/2311.03943" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CLIP Guided Image-perceptive Prompt Learning for Image Enhancement
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zinuo Li</a>, 
<a href="/search/cs?searchtype=author&query=Ke%2C+Q">Qiuhong Ke</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+W">Weiwen Chen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Image enhancement is a significant research area in the fields of computer
vision and image processing. In recent years, many learning-based methods for
image enhancement have been developed, where the Look-up-table (LUT) has proven
to be an effective tool. In this paper, we delve into the potential of
Contrastive Language-Image Pre-Training (CLIP) Guided Prompt Learning,
proposing a simple structure called CLIP-LUT for image enhancement. We found
that the prior knowledge of CLIP can effectively discern the quality of
degraded images, which can provide reliable guidance. To be specific, We
initially learn image-perceptive prompts to distinguish between original and
target images using CLIP model, in the meanwhile, we introduce a very simple
network by incorporating a simple baseline to predict the weights of three
different LUT as enhancement network. The obtained prompts are used to steer
the enhancement network like a loss function and improve the performance of
model. We demonstrate that by simply combining a straightforward method with
CLIP, we can obtain satisfactory results.
</p>
</div>
</dd>
<dt><a name="item257">[257]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03952" title="Abstract">arXiv:2311.03952</a> [<a href="/pdf/2311.03952" title="Download PDF">pdf</a>, <a href="/format/2311.03952" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An Analysis of Dialogue Repair in Voice Assistants
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Galbraith%2C+M">Matthew Galbraith</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 3 pages. Part of WTF 23 workshop proceedings
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Human-Computer Interaction (cs.HC); Robotics (cs.RO)

</div>
<p class="mathjax">Spoken dialogue systems have transformed human-machine interaction by
providing real-time responses to queries. However, misunderstandings between
the user and system persist. This study explores the significance of
interactional language in dialogue repair between virtual assistants and users
by analyzing interactions with Google Assistant and Siri, focusing on their
utilization and response to the other-initiated repair strategy "huh?"
prevalent in human-human interaction. Findings reveal several
assistant-generated strategies but an inability to replicate human-like repair
strategies such as "huh?". English and Spanish user acceptability surveys show
differences in users' repair strategy preferences and assistant usage, with
both similarities and disparities among the two surveyed languages. These
results shed light on inequalities between interactional language in
human-human interaction and human-machine interaction, underscoring the need
for further research on the impact of interactional language in human-machine
interaction in English and beyond.
</p>
</div>
</dd>
<dt><a name="item258">[258]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03955" title="Abstract">arXiv:2311.03955</a> [<a href="/pdf/2311.03955" title="Download PDF">pdf</a>, <a href="/ps/2311.03955" title="Download PostScript">ps</a>, <a href="/format/2311.03955" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Elastic Information Bottleneck
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ni%2C+Y">Yuyan Ni</a>, 
<a href="/search/cs?searchtype=author&query=Lan%2C+Y">Yanyan Lan</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+A">Ao Liu</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+Z">Zhiming Ma</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Information bottleneck is an information-theoretic principle of
representation learning that aims to learn a maximally compressed
representation that preserves as much information about labels as possible.
Under this principle, two different methods have been proposed, i.e.,
information bottleneck (IB) and deterministic information bottleneck (DIB), and
have gained significant progress in explaining the representation mechanisms of
deep learning algorithms. However, these theoretical and empirical successes
are only valid with the assumption that training and test data are drawn from
the same distribution, which is clearly not satisfied in many real-world
applications. In this paper, we study their generalization abilities within a
transfer learning scenario, where the target error could be decomposed into
three components, i.e., source empirical error, source generalization gap (SG),
and representation discrepancy (RD). Comparing IB and DIB on these terms, we
prove that DIB's SG bound is tighter than IB's while DIB's RD is larger than
IB's. Therefore, it is difficult to tell which one is better. To balance the
trade-off between SG and the RD, we propose an elastic information bottleneck
(EIB) to interpolate between the IB and DIB regularizers, which guarantees a
Pareto frontier within the IB framework. Additionally, simulations and real
data experiments show that EIB has the ability to achieve better domain
adaptation results than IB and DIB, which validates the correctness of our
theories.
</p>
</div>
</dd>
<dt><a name="item259">[259]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03956" title="Abstract">arXiv:2311.03956</a> [<a href="/pdf/2311.03956" title="Download PDF">pdf</a>, <a href="/format/2311.03956" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Cup Curriculum: Curriculum Learning on Model Capacity
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Scharr%2C+L">Luca Scharr</a>, 
<a href="/search/cs?searchtype=author&query=Toborek%2C+V">Vanessa Toborek</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages, 5 figures, both including appendix, OPT 2023 workshop of NeurIPS 2023 conference
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Curriculum learning (CL) aims to increase the performance of a learner on a
given task by applying a specialized learning strategy. This strategy focuses
on either the dataset, the task, or the model. There is little to no work
analysing the possibilities to apply CL on the model capacity in natural
language processing. To close this gap, we propose the cup curriculum. In a
first phase of training we use a variation of iterative magnitude pruning to
reduce model capacity. These weights are reintroduced in a second phase,
resulting in the model capacity to show a cup-shaped curve over the training
iterations. We empirically evaluate different strategies of the cup curriculum
and show that it outperforms early stopping reliably while exhibiting a high
resilience to overfitting.
</p>
</div>
</dd>
<dt><a name="item260">[260]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03957" title="Abstract">arXiv:2311.03957</a> [<a href="/pdf/2311.03957" title="Download PDF">pdf</a>, <a href="/format/2311.03957" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Self-Contained and Automatic Calibration of a Multi-Fingered Hand Using  Only Pairwise Contact Measurements
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tenhumberg%2C+J">Johannes Tenhumberg</a>, 
<a href="/search/cs?searchtype=author&query=Sievers%2C+L">Leon Sievers</a>, 
<a href="/search/cs?searchtype=author&query=B%C3%A4uml%2C+B">Berthold B&#xe4;uml</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Presented at the 2023 IEEE-RAS International Conference on Humanoid Robots
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">A self-contained calibration procedure that can be performed automatically
without additional external sensors or tools is a significant advantage,
especially for complex robotic systems. Here, we show that the kinematics of a
multi-fingered robotic hand can be precisely calibrated only by moving the tips
of the fingers pairwise into contact. The only prerequisite for this is
sensitive contact detection, e.g., by torque-sensing in the joints (as in our
DLR-Hand II) or tactile skin. The measurement function for a given joint
configuration is the distance between the modeled fingertip geometries, but the
actual measurement is always zero. In an in-depth analysis, we prove that this
contact-based calibration determines all quantities needed for manipulating
objects with the hand, i.e., the difference vectors of the fingertips, and that
it is as sensitive as a calibration using an external visual tracking system
and markers. We describe the complete calibration scheme, including the
selection of optimal sample joint configurations and search motions for the
contacts despite the initial kinematic uncertainties. In a real-world
calibration experiment for the torque-controlled four-fingered DLR-Hand II, the
maximal error of 17.7mm can be reduced to only 3.7mm.
</p>
</div>
</dd>
<dt><a name="item261">[261]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03959" title="Abstract">arXiv:2311.03959</a> [<a href="/pdf/2311.03959" title="Download PDF">pdf</a>, <a href="/format/2311.03959" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Improving the Effectiveness of Deep Generative Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+R">Ruyu Wang</a>, 
<a href="/search/cs?searchtype=author&query=Schmedding%2C+S">Sabrina Schmedding</a>, 
<a href="/search/cs?searchtype=author&query=Huber%2C+M+F">Marco F. Huber</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by WACV2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Recent deep generative models (DGMs) such as generative adversarial networks
(GANs) and diffusion probabilistic models (DPMs) have shown their impressive
ability in generating high-fidelity photorealistic images. Although looking
appealing to human eyes, training a model on purely synthetic images for
downstream image processing tasks like image classification often results in an
undesired performance drop compared to training on real data. Previous works
have demonstrated that enhancing a real dataset with synthetic images from DGMs
can be beneficial. However, the improvements were subjected to certain
circumstances and yet were not comparable to adding the same number of real
images. In this work, we propose a new taxonomy to describe factors
contributing to this commonly observed phenomenon and investigate it on the
popular CIFAR-10 dataset. We hypothesize that the Content Gap accounts for a
large portion of the performance drop when using synthetic images from DGM and
propose strategies to better utilize them in downstream tasks. Extensive
experiments on multiple datasets showcase that our method outperforms baselines
on downstream classification tasks both in case of training on synthetic only
(Synthetic-to-Real) and training on a mix of real and synthetic data (Data
Augmentation), particularly in the data-scarce scenario.
</p>
</div>
</dd>
<dt><a name="item262">[262]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03963" title="Abstract">arXiv:2311.03963</a> [<a href="/pdf/2311.03963" title="Download PDF">pdf</a>, <a href="/format/2311.03963" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An Expectation-Realization Model for Metaphor Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Uduehi%2C+O+O">Oseremen O. Uduehi</a>, 
<a href="/search/cs?searchtype=author&query=Bunescu%2C+R+C">Razvan C. Bunescu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">We propose a metaphor detection architecture that is structured around two
main modules: an expectation component that estimates representations of
literal word expectations given a context, and a realization component that
computes representations of actual word meanings in context. The overall
architecture is trained to learn expectation-realization (ER) patterns that
characterize metaphorical uses of words. When evaluated on three metaphor
datasets for within distribution, out of distribution, and novel metaphor
generalization, the proposed method is shown to obtain results that are
competitive or better than state-of-the art. Further increases in metaphor
detection accuracy are obtained through ensembling of ER models.
</p>
</div>
</dd>
<dt><a name="item263">[263]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03964" title="Abstract">arXiv:2311.03964</a> [<a href="/pdf/2311.03964" title="Download PDF">pdf</a>, <a href="/format/2311.03964" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Enhancing Multimodal Compositional Reasoning of Visual Language Models  with Generative Negative Mining
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sahin%2C+U">Ugur Sahin</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Hang Li</a>, 
<a href="/search/cs?searchtype=author&query=Khan%2C+Q">Qadeer Khan</a>, 
<a href="/search/cs?searchtype=author&query=Cremers%2C+D">Daniel Cremers</a>, 
<a href="/search/cs?searchtype=author&query=Tresp%2C+V">Volker Tresp</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to WACV
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Contemporary large-scale visual language models (VLMs) exhibit strong
representation capacities, making them ubiquitous for enhancing image and text
understanding tasks. They are often trained in a contrastive manner on a large
and diverse corpus of images and corresponding text captions scraped from the
internet. Despite this, VLMs often struggle with compositional reasoning tasks
which require a fine-grained understanding of the complex interactions of
objects and their attributes. This failure can be attributed to two main
factors: 1) Contrastive approaches have traditionally focused on mining
negative examples from existing datasets. However, the mined negative examples
might not be difficult for the model to discriminate from the positive. An
alternative to mining would be negative sample generation 2) But existing
generative approaches primarily focus on generating hard negative texts
associated with a given image. Mining in the other direction, i.e., generating
negative image samples associated with a given text has been ignored. To
overcome both these limitations, we propose a framework that not only mines in
both directions but also generates challenging negative samples in both
modalities, i.e., images and texts. Leveraging these generative hard negative
samples, we significantly enhance VLMs' performance in tasks involving
multimodal compositional reasoning. Our code and dataset are released at
https://ugorsahin.github.io/enhancing-multimodal-compositional-reasoning-of-vlm.html.
</p>
</div>
</dd>
<dt><a name="item264">[264]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03965" title="Abstract">arXiv:2311.03965</a> [<a href="/pdf/2311.03965" title="Download PDF">pdf</a>, <a href="/format/2311.03965" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fast Sun-aligned Outdoor Scene Relighting based on TensoRF
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chang%2C+Y">Yeonjin Chang</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+Y">Yearim Kim</a>, 
<a href="/search/cs?searchtype=author&query=Seo%2C+S">Seunghyeon Seo</a>, 
<a href="/search/cs?searchtype=author&query=Yi%2C+J">Jung Yi</a>, 
<a href="/search/cs?searchtype=author&query=Kwak%2C+N">Nojun Kwak</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> WACV 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">In this work, we introduce our method of outdoor scene relighting for Neural
Radiance Fields (NeRF) named Sun-aligned Relighting TensoRF (SR-TensoRF).
SR-TensoRF offers a lightweight and rapid pipeline aligned with the sun,
thereby achieving a simplified workflow that eliminates the need for
environment maps. Our sun-alignment strategy is motivated by the insight that
shadows, unlike viewpoint-dependent albedo, are determined by light direction.
We directly use the sun direction as an input during shadow generation,
simplifying the requirements of the inference process significantly. Moreover,
SR-TensoRF leverages the training efficiency of TensoRF by incorporating our
proposed cubemap concept, resulting in notable acceleration in both training
and rendering processes compared to existing methods.
</p>
</div>
</dd>
<dt><a name="item265">[265]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03967" title="Abstract">arXiv:2311.03967</a> [<a href="/pdf/2311.03967" title="Download PDF">pdf</a>, <a href="/format/2311.03967" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CeCNN: Copula-enhanced convolutional neural networks in joint prediction  of refraction error and axial length based on ultra-widefield fundus images
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhong%2C+C">Chong Zhong</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yang Li</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+D">Danjuan Yang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+M">Meiyan Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+X">Xingyao Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Fu%2C+B">Bo Fu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+C+C">Catherine C. Liu</a>, 
<a href="/search/cs?searchtype=author&query=Welsh%2C+A+H">A.H. Welsh</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (stat.ML)

</div>
<p class="mathjax">Ultra-widefield (UWF) fundus images are replacing traditional fundus images
in screening, detection, prediction, and treatment of complications related to
myopia because their much broader visual range is advantageous for highly
myopic eyes. Spherical equivalent (SE) is extensively used as the main myopia
outcome measure, and axial length (AL) has drawn increasing interest as an
important ocular component for assessing myopia. Cutting-edge studies show that
SE and AL are strongly correlated. Using the joint information from SE and AL
is potentially better than using either separately. In the deep learning
community, though there is research on multiple-response tasks with a 3D image
biomarker, dependence among responses is only sporadically taken into
consideration. Inspired by the spirit that information extracted from the data
by statistical methods can improve the prediction accuracy of deep learning
models, we formulate a class of multivariate response regression models with a
higher-order tensor biomarker, for the bivariate tasks of
regression-classification and regression-regression. Specifically, we propose a
copula-enhanced convolutional neural network (CeCNN) framework that
incorporates the dependence between responses through a Gaussian copula (with
parameters estimated from a warm-up CNN) and uses the induced copula-likelihood
loss with the backbone CNNs. We establish the statistical framework and
algorithms for the aforementioned two bivariate tasks. We show that the CeCNN
has better prediction accuracy after adding the dependency information to the
backbone models. The modeling and the proposed CeCNN algorithm are applicable
beyond the UWF scenario and can be effective with other backbones beyond ResNet
and LeNet.
</p>
</div>
</dd>
<dt><a name="item266">[266]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03969" title="Abstract">arXiv:2311.03969</a> [<a href="/pdf/2311.03969" title="Download PDF">pdf</a>, <a href="/format/2311.03969" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Factoring Hate Speech: A New Annotation Framework to Study Hate Speech  in Social Media
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ron%2C+G">Gal Ron</a>, 
<a href="/search/cs?searchtype=author&query=Levi%2C+E">Effi Levi</a>, 
<a href="/search/cs?searchtype=author&query=Oshri%2C+O">Odelia Oshri</a>, 
<a href="/search/cs?searchtype=author&query=Shenhav%2C+S+R">Shaul R. Shenhav</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to the 7th Workshop on Online Abuse and Harms (WOAH), ACL 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">In this work we propose a novel annotation scheme which factors hate speech
into five separate discursive categories. To evaluate our scheme, we construct
a corpus of over 2.9M Twitter posts containing hateful expressions directed at
Jews, and annotate a sample dataset of 1,050 tweets. We present a statistical
analysis of the annotated dataset as well as discuss annotation examples, and
conclude by discussing promising directions for future work.
</p>
</div>
</dd>
<dt><a name="item267">[267]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03970" title="Abstract">arXiv:2311.03970</a> [<a href="/pdf/2311.03970" title="Download PDF">pdf</a>, <a href="/format/2311.03970" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Bias and Diversity in Synthetic-based Face Recognition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huber%2C+M">Marco Huber</a>, 
<a href="/search/cs?searchtype=author&query=Luu%2C+A+T">Anh Thi Luu</a>, 
<a href="/search/cs?searchtype=author&query=Boutros%2C+F">Fadi Boutros</a>, 
<a href="/search/cs?searchtype=author&query=Kuijper%2C+A">Arjan Kuijper</a>, 
<a href="/search/cs?searchtype=author&query=Damer%2C+N">Naser Damer</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted for presentation at WACV2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Synthetic data is emerging as a substitute for authentic data to solve
ethical and legal challenges in handling authentic face data. The current
models can create real-looking face images of people who do not exist. However,
it is a known and sensitive problem that face recognition systems are
susceptible to bias, i.e. performance differences between different demographic
and non-demographics attributes, which can lead to unfair decisions. In this
work, we investigate how the diversity of synthetic face recognition datasets
compares to authentic datasets, and how the distribution of the training data
of the generative models affects the distribution of the synthetic data. To do
this, we looked at the distribution of gender, ethnicity, age, and head
position. Furthermore, we investigated the concrete bias of three recent
synthetic-based face recognition models on the studied attributes in comparison
to a baseline model trained on authentic data. Our results show that the
generator generate a similar distribution as the used training data in terms of
the different attributes. With regard to bias, it can be seen that the
synthetic-based models share a similar bias behavior with the authentic-based
models. However, with the uncovered lower intra-identity attribute consistency
seems to be beneficial in reducing bias.
</p>
</div>
</dd>
<dt><a name="item268">[268]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03974" title="Abstract">arXiv:2311.03974</a> [<a href="/pdf/2311.03974" title="Download PDF">pdf</a>, <a href="/ps/2311.03974" title="Download PostScript">ps</a>, <a href="/format/2311.03974" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> NOMA Enabled Multi-Access Edge Computing: A Joint MU-MIMO Precoding and  Computation Offloading Design
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+D">Deyou Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+M">Meng Wang</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+S">Shuo Shi</a>, 
<a href="/search/cs?searchtype=author&query=Xiao%2C+M">Ming Xiao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">This letter investigates computation offloading and transmit precoding
co-design for multi-access edge computing (MEC), where multiple MEC users (MUs)
equipped with multiple antennas access the MEC server in a non-orthogonal
multiple access manner. We aim to minimize the total energy consumption of all
MUs while satisfying the latency constraints by jointly optimizing the
computational frequency, offloading ratio, and precoding matrix of each MU. For
tractability, we first decompose the original problem into three subproblems
and then solve these subproblems iteratively until convergence. Simulation
results validate the convergence of the proposed method and demonstrate its
superiority over baseline algorithms.
</p>
</div>
</dd>
<dt><a name="item269">[269]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03975" title="Abstract">arXiv:2311.03975</a> [<a href="/pdf/2311.03975" title="Download PDF">pdf</a>, <a href="/format/2311.03975" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Adaptive 3D Geometry-based Stochastic Channel Prediction for 3D DL  Selection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zarour%2C+M">Mervat Zarour</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Q">Qiuheng Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Melnyk%2C+S">Sergiy Melnyk</a>, 
<a href="/search/cs?searchtype=author&query=Schotten%2C+H+D">Hans D. Schotten</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> IEEE copy right. This work has been submitted to the IEEE WCNC2024 for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>

</div>
<p class="mathjax">This paper addresses the challenges of mobile user requirements in shadowing
and multi-fading environments, focusing on the Downlink (DL) radio node
selection based on Uplink (UL) channel estimation. One of the key issues
tackled in this research is the prediction performance in scenarios where
estimated channels are integrated. An adaptive deep learning approach is
proposed to improve performance, offering a compelling alternative to
traditional interpolation techniques for air-to-ground link selection on
demand. Moreover, our study considers a 3D channel model, which provides a more
realistic and accurate representation than 2D models, particularly in the
context of 3D network node distributions. This consideration becomes crucial in
addressing the complex multipath fading effects within geometric stochastic 3D
3GPP channel models in urban environments. Furthermore, our research emphasises
the need for adaptive prediction mechanisms that carefully balance the
trade-off between DL link forecasted frequency response accuracy and the
complexity requirements associated with estimation and prediction. This paper
contributes to advancing 3D radio resource management by addressing these
challenges, enabling more efficient and reliable communication for
energy-constrained flying network nodes in dynamic environments.
</p>
</div>
</dd>
<dt><a name="item270">[270]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03976" title="Abstract">arXiv:2311.03976</a> [<a href="/pdf/2311.03976" title="Download PDF">pdf</a>, <a href="/format/2311.03976" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Its All Graph To Me: Foundational Topology Models with Contrastive  Learning on Multiple Domains
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Davies%2C+A+O">Alex O. Davies</a>, 
<a href="/search/cs?searchtype=author&query=Green%2C+R+W">Riku W. Green</a>, 
<a href="/search/cs?searchtype=author&query=Ajmeri%2C+N+S">Nirav S. Ajmeri</a>, 
<a href="/search/cs?searchtype=author&query=Filho%2C+T+M+S">Telmo M. Silva Filho</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Presented at the NeurIPS 2023 New Frontiers in Graph Learning workshop
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Representations and embeddings of graph data have been essential in many
domains of research.
<br />The principle benefit of learning such representations is that the
pre-trained model can be fine-tuned on smaller datasets where data or labels
are scarse.
<br />Existing models, however, are domain specific; for example a model trained on
molecular graphs is fine-tuned on other molecular graphs.
<br />This means that in many application cases the choice of pre-trained model can
be arbitrary, and novel domains may lack an appropriate pre-trained model.
<br />This is of particular issue where data is scarse, precluding traditional
supervised methods.
<br />In this work we use adversarial contrastive learning to present a \method, a
model pre-trained on many graph domains.
<br />We train the model only on topologies but include node labels in evaluation.
<br />We evaluate the efficacy of its learnt representations on various downstream
tasks.
<br />Against baseline models pre-trained on single domains, as well as un-trained
models and non-transferred models, we show that performance is equal or better
using our single model.
<br />This includes when node labels are used in evaluation, where performance is
consistently superior to single-domain or non-pre-trained models.
</p>
</div>
</dd>
<dt><a name="item271">[271]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03982" title="Abstract">arXiv:2311.03982</a> [<a href="/pdf/2311.03982" title="Download PDF">pdf</a>, <a href="/ps/2311.03982" title="Download PostScript">ps</a>, <a href="/format/2311.03982" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Federated Learning via Active RIS Assisted Over-the-Air Computation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+D">Deyou Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Xiao%2C+M">Ming Xiao</a>, 
<a href="/search/cs?searchtype=author&query=Skoglund%2C+M">Mikael Skoglund</a>, 
<a href="/search/cs?searchtype=author&query=Poor%2C+H+V">H. Vincent Poor</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This paper was submitted to the IEEE International Conference on Machine Learning for Communication and Networking (ICMLCN), Stockholm, Sweden, 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">In this paper, we propose leveraging the active reconfigurable intelligence
surface (RIS) to support reliable gradient aggregation for over-the-air
computation (AirComp) enabled federated learning (FL) systems. An analysis of
the FL convergence property reveals that minimizing gradient aggregation errors
in each training round is crucial for narrowing the convergence gap. As such,
we formulate an optimization problem, aiming to minimize these errors by
jointly optimizing the transceiver design and RIS configuration. To handle the
formulated highly non-convex problem, we devise a two-layer alternative
optimization framework to decompose it into several convex subproblems, each
solvable optimally. Simulation results demonstrate the superiority of the
active RIS in reducing gradient aggregation errors compared to its passive
counterpart.
</p>
</div>
</dd>
<dt><a name="item272">[272]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03985" title="Abstract">arXiv:2311.03985</a> [<a href="/pdf/2311.03985" title="Download PDF">pdf</a>, <a href="/format/2311.03985" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Quadrotor Experimental Dynamic Identification with Comprehensive NARX  Neural Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Telli%2C+K">Khaled Telli</a>, 
<a href="/search/cs?searchtype=author&query=Kraa%2C+O">Okba Kraa</a>, 
<a href="/search/cs?searchtype=author&query=Himeur%2C+Y">Yassine Himeur</a>, 
<a href="/search/cs?searchtype=author&query=Boumehraz%2C+M">Mohamed Boumehraz</a>, 
<a href="/search/cs?searchtype=author&query=Atalla%2C+S">Shadi Atalla</a>, 
<a href="/search/cs?searchtype=author&query=Mansoor%2C+W">Wathiq Mansoor</a>, 
<a href="/search/cs?searchtype=author&query=Ouamane%2C+A">Abdelmalik Ouamane</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages, 10 figures, and 0 table
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Engineering, Finance, and Science (cs.CE)</span>; Computers and Society (cs.CY)

</div>
<p class="mathjax">This research paper delves into the field of quadrotor dynamics, which are
famous by their nonlinearity, under-actuation, and multivariable nature. Due to
the critical need for precise modeling and control in this context we explore
the capabilities of NARX (Nonlinear AutoRegressive with eXogenous inputs)
Neural Networks (NN). These networks are employed for comprehensive and
accurate modeling of quadrotor behaviors, take advantage of their ability to
capture the hided dynamics. Our research encompasses a rigorous experimental
setup, including the use of PRBS (Pseudo-random binary sequence) signals for
excitation, to validate the efficacy of NARX-NN in predicting and controlling
quadrotor dynamics. The results reveal exceptional accuracy, with fit
percentages exceeding 99% on both estimation and validation data. Moreover, we
identified the quadrotor dynamics using different NARX NN structures, including
the NARX model with a sigmoid NN, NARX feedforward NN, and cascade NN. In
summary, our study positions NARX-NN as a transformative tool for quadrotor
applications, ranging from autonomous navigation to aerial robotics, thanks to
their accurate and comprehensive modeling capabilities.
</p>
</div>
</dd>
<dt><a name="item273">[273]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03986" title="Abstract">arXiv:2311.03986</a> [<a href="/pdf/2311.03986" title="Download PDF">pdf</a>, <a href="/format/2311.03986" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multimodal extended reality applications offer benefits for volumetric  biomedical image analysis in research and medicine
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Krieger%2C+K">Kathrin Krieger</a>, 
<a href="/search/cs?searchtype=author&query=Egger%2C+J">Jan Egger</a>, 
<a href="/search/cs?searchtype=author&query=Kleesiek%2C+J">Jens Kleesiek</a>, 
<a href="/search/cs?searchtype=author&query=Gunzer%2C+M">Matthias Gunzer</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Jianxu Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>; Graphics (cs.GR); Human-Computer Interaction (cs.HC)

</div>
<p class="mathjax">3D data from high-resolution volumetric imaging is a central resource for
diagnosis and treatment in modern medicine. While the fast development of AI
enhances imaging and analysis, commonly used visualization methods lag far
behind. Recent research used extended reality (XR) for perceiving 3D images
with visual depth perception and touch, but used restricting haptic devices.
While unrestricted touch is beneficial for volumetric data examination,
implementing natural haptic interaction with XR is challenging. The research
question is whether a multimodal XR application with intutitive haptic
interaction adds value and should be pursued. In a study, 24 expterts for
biomedical images in research and medicine. explored 3D anatomical medical
shapes with 3 applications: a multimodal virtual reality (VR) prototype using
haptic gloves, a simple VR prototype using VR controllers, and a commonly used
standard PC application. Results of the standardized questionnaires showed no
significant differences between the three application types regarding usability
and no significant difference between both VR applications regarding presence.
Participants agreed to statements that VR visualizations provide better depth
information, that using the hands instead of controllers simplifies data
exploration, that the multimodal VR prototype allows intuitive data
exploration, and that it is beneficial over traditional data examination
methods. While most participants mentioned the manual interaction as best
aspect, they also found it the most improvable. We conclude that a multimodal
XR application with improved manual interaction adds value for volumetric
biomedical data examination. We will proceed with our open-source research
project ISH3DE (Intuitive Stereoptic Haptic 3D Data Exploration) to serve
medical education, therapeutic decisions, surgery preparations, or research
data analysis.
</p>
</div>
</dd>
<dt><a name="item274">[274]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03989" title="Abstract">arXiv:2311.03989</a> [<a href="/pdf/2311.03989" title="Download PDF">pdf</a>, <a href="/format/2311.03989" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learned Causal Method Prediction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gupta%2C+S">Shantanu Gupta</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+C">Cheng Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Hilmkil%2C+A">Agrin Hilmkil</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Methodology (stat.ME)

</div>
<p class="mathjax">For a given causal question, it is important to efficiently decide which
causal inference method to use for a given dataset. This is challenging because
causal methods typically rely on complex and difficult-to-verify assumptions,
and cross-validation is not applicable since ground truth causal quantities are
unobserved.In this work, we propose CAusal Method Predictor (CAMP), a framework
for predicting the best method for a given dataset. To this end, we generate
datasets from a diverse set of synthetic causal models, score the candidate
methods, and train a model to directly predict the highest-scoring method for
that dataset. Next, by formulating a self-supervised pre-training objective
centered on dataset assumptions relevant for causal inference, we significantly
reduce the need for costly labeled data and enhance training efficiency. Our
strategy learns to map implicit dataset properties to the best method in a
data-driven manner. In our experiments, we focus on method prediction for
causal discovery. CAMP outperforms selecting any individual candidate method
and demonstrates promising generalization to unseen semi-synthetic and
real-world benchmarks.
</p>
</div>
</dd>
<dt><a name="item275">[275]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03996" title="Abstract">arXiv:2311.03996</a> [<a href="/pdf/2311.03996" title="Download PDF">pdf</a>, <a href="/format/2311.03996" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An Initialization Schema for Neuronal Networks on Tabular Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fuhl%2C+W">Wolfgang Fuhl</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Nowadays, many modern applications require heterogeneous tabular data, which
is still a challenging task in terms of regression and classification. Many
approaches have been proposed to adapt neural networks for this task, but
still, boosting and bagging of decision trees are the best-performing methods
for this task. In this paper, we show that a binomial initialized neural
network can be used effectively on tabular data. The proposed approach shows a
simple but effective approach for initializing the first hidden layer in neural
networks. We also show that this initializing schema can be used to jointly
train ensembles by adding gradient masking to batch entries and using the
binomial initialization for the last layer in a neural network. For this
purpose, we modified the hinge binary loss and the soft max loss to make them
applicable for joint ensemble training. We evaluate our approach on multiple
public datasets and showcase the improved performance compared to other neural
network-based approaches. In addition, we discuss the limitations and possible
further research of our approach for improving the applicability of neural
networks to tabular data.
<br />Link:
https://es-cloud.cs.uni-tuebingen.de/d/8e2ab8c3fdd444e1a135/?p=%2FInitializationNeuronalNetworksTabularData&amp;mode=list
</p>
</div>
</dd>
<dt><a name="item276">[276]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03998" title="Abstract">arXiv:2311.03998</a> [<a href="/pdf/2311.03998" title="Download PDF">pdf</a>, <a href="/format/2311.03998" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exploring Jiu-Jitsu Argumentation for Writing Peer Review Rebuttals
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Purkayastha%2C+S">Sukannya Purkayastha</a>, 
<a href="/search/cs?searchtype=author&query=Lauscher%2C+A">Anne Lauscher</a>, 
<a href="/search/cs?searchtype=author&query=Gurevych%2C+I">Iryna Gurevych</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at EMNLP Main Conference 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">In many domains of argumentation, people's arguments are driven by so-called
attitude roots, i.e., underlying beliefs and world views, and their
corresponding attitude themes. Given the strength of these latent drivers of
arguments, recent work in psychology suggests that instead of directly
countering surface-level reasoning (e.g., falsifying given premises), one
should follow an argumentation style inspired by the Jiu-Jitsu 'soft' combat
system (Hornsey and Fielding, 2017): first, identify an arguer's attitude roots
and themes, and then choose a prototypical rebuttal that is aligned with those
drivers instead of invalidating those. In this work, we are the first to
explore Jiu-Jitsu argumentation for peer review by proposing the novel task of
attitude and theme-guided rebuttal generation. To this end, we enrich an
existing dataset for discourse structure in peer reviews with attitude roots,
attitude themes, and canonical rebuttals. To facilitate this process, we recast
established annotation concepts from the domain of peer reviews (e.g., aspects
a review sentence is relating to) and train domain-specific models. We then
propose strong rebuttal generation strategies, which we benchmark on our novel
dataset for the task of end-to-end attitude and theme-guided rebuttal
generation and two subtasks.
</p>
</div>
</dd>
<dt><a name="item277">[277]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03999" title="Abstract">arXiv:2311.03999</a> [<a href="/pdf/2311.03999" title="Download PDF">pdf</a>, <a href="/ps/2311.03999" title="Download PostScript">ps</a>, <a href="/format/2311.03999" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Human-AI Collaboration in Thematic Analysis using ChatGPT: A User Study  and Design Recommendations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yan%2C+L">Lixiang Yan</a>, 
<a href="/search/cs?searchtype=author&query=Echeverria%2C+V">Vanessa Echeverria</a>, 
<a href="/search/cs?searchtype=author&query=Nieto%2C+G+F">Gloria Fernandez Nieto</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+Y">Yueqiao Jin</a>, 
<a href="/search/cs?searchtype=author&query=Swiecki%2C+Z">Zachari Swiecki</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+L">Linxuan Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Ga%C5%A1evi%C4%87%2C+D">Dragan Ga&#x161;evi&#x107;</a>, 
<a href="/search/cs?searchtype=author&query=Martinez-Maldonado%2C+R">Roberto Martinez-Maldonado</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Generative artificial intelligence (GenAI) offers promising potential for
advancing human-AI collaboration in qualitative research. However, existing
works focused on conventional machine-learning and pattern-based AI systems,
and little is known about how researchers interact with GenAI in qualitative
research. This work delves into researchers' perceptions of their collaboration
with GenAI, specifically ChatGPT. Through a user study involving ten
qualitative researchers, we found ChatGPT to be a valuable collaborator for
thematic analysis, enhancing coding efficiency, aiding initial data
exploration, offering granular quantitative insights, and assisting
comprehension for non-native speakers and non-experts. Yet, concerns about its
trustworthiness and accuracy, reliability and consistency, limited contextual
understanding, and broader acceptance within the research community persist. We
contribute five actionable design recommendations to foster effective human-AI
collaboration. These include incorporating transparent explanatory mechanisms,
enhancing interface and integration capabilities, prioritising contextual
understanding and customisation, embedding human-AI feedback loops and
iterative functionality, and strengthening trust through validation mechanisms.
</p>
</div>
</dd>
<dt><a name="item278">[278]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04002" title="Abstract">arXiv:2311.04002</a> [<a href="/pdf/2311.04002" title="Download PDF">pdf</a>, <a href="/ps/2311.04002" title="Download PostScript">ps</a>, <a href="/format/2311.04002" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Enhanced Information Extraction from Cylindrical Visual-Tactile Sensors  via Image Fusion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zilan Li</a>, 
<a href="/search/cs?searchtype=author&query=Zou%2C+Z">Zhibin Zou</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+W">Weiliang Xu</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Y">Yuanzhi Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+G">Guoyuan Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+X">Xuan Huang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xinming Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Vision-based tactile sensors equipped with planar contact structures acquire
the shape, force, and motion states of objects in contact. The limited planar
contact area presents a challenge in acquiring information about larger target
objects. In contrast, vision-based tactile sensors with cylindrical contact
structures could extend the contact area by rolling, which can acquire much
tactile information that exceeds the sensing projection area in a single
contact. However, the tactile data acquired by cylindrical structures does not
consistently correspond to the same depth level. Therefore, stitching and
analyzing the data in an extended contact area is a challenging problem. In
this work, we propose an image fusion method based on cylindrical vision-based
tactile sensors. The method takes advantage of the changing characteristics of
the contact depth of cylindrical structures, extracts the effective information
of different contact depths in the frequency domain, and performs differential
fusion for the information characteristics. The results show that in object
contact confronting an area larger than single sensing, the images fused with
our proposed method have higher information and structural similarity compared
with the method of stitching based on motion distance sampling. Meanwhile, it
is robust to sampling time. We complement this method with a deep neural
network to illustrate its potential for fusing and recognizing object contact
information using cylindrical vision-based tactile sensors.
</p>
</div>
</dd>
<dt><a name="item279">[279]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04007" title="Abstract">arXiv:2311.04007</a> [<a href="/pdf/2311.04007" title="Download PDF">pdf</a>, <a href="/format/2311.04007" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Energy Prediction Smart-Meter Dataset: Analysis of Previous  Competitions and Beyond
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pekaslan%2C+D">Direnc Pekaslan</a>, 
<a href="/search/cs?searchtype=author&query=Alonso-Moral%2C+J+M">Jose Maria Alonso-Moral</a>, 
<a href="/search/cs?searchtype=author&query=Bandara%2C+K">Kasun Bandara</a>, 
<a href="/search/cs?searchtype=author&query=Bergmeir%2C+C">Christoph Bergmeir</a>, 
<a href="/search/cs?searchtype=author&query=Bernabe-Moreno%2C+J">Juan Bernabe-Moreno</a>, 
<a href="/search/cs?searchtype=author&query=Eigenmann%2C+R">Robert Eigenmann</a>, 
<a href="/search/cs?searchtype=author&query=Einecke%2C+N">Nils Einecke</a>, 
<a href="/search/cs?searchtype=author&query=Ergen%2C+S">Selvi Ergen</a>, 
<a href="/search/cs?searchtype=author&query=Godahewa%2C+R">Rakshitha Godahewa</a>, 
<a href="/search/cs?searchtype=author&query=Hewamalage%2C+H">Hansika Hewamalage</a>, 
<a href="/search/cs?searchtype=author&query=Lago%2C+J">Jesus Lago</a>, 
<a href="/search/cs?searchtype=author&query=Limmer%2C+S">Steffen Limmer</a>, 
<a href="/search/cs?searchtype=author&query=Rebhan%2C+S">Sven Rebhan</a>, 
<a href="/search/cs?searchtype=author&query=Rabinovich%2C+B">Boris Rabinovich</a>, 
<a href="/search/cs?searchtype=author&query=Rajapasksha%2C+D">Dilini Rajapasksha</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+H">Heda Song</a>, 
<a href="/search/cs?searchtype=author&query=Wagner%2C+C">Christian Wagner</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+W">Wenlong Wu</a>, 
<a href="/search/cs?searchtype=author&query=Magdalena%2C+L">Luis Magdalena</a>, 
<a href="/search/cs?searchtype=author&query=Triguero%2C+I">Isaac Triguero</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">This paper presents the real-world smart-meter dataset and offers an analysis
of solutions derived from the Energy Prediction Technical Challenges, focusing
primarily on two key competitions: the IEEE Computational Intelligence Society
(IEEE-CIS) Technical Challenge on Energy Prediction from Smart Meter data in
2020 (named EP) and its follow-up challenge at the IEEE International
Conference on Fuzzy Systems (FUZZ-IEEE) in 2021 (named as XEP). These
competitions focus on accurate energy consumption forecasting and the
importance of interpretability in understanding the underlying factors. The
challenge aims to predict monthly and yearly estimated consumption for
households, addressing the accurate billing problem with limited historical
smart meter data. The dataset comprises 3,248 smart meters, with varying data
availability ranging from a minimum of one month to a year. This paper delves
into the challenges, solutions and analysing issues related to the provided
real-world smart meter data, developing accurate predictions at the household
level, and introducing evaluation criteria for assessing interpretability.
Additionally, this paper discusses aspects beyond the competitions:
opportunities for energy disaggregation and pattern detection applications at
the household level, significance of communicating energy-driven factors for
optimised billing, and emphasising the importance of responsible AI and data
privacy considerations. These aspects provide insights into the broader
implications and potential advancements in energy consumption prediction.
Overall, these competitions provide a dataset for residential energy research
and serve as a catalyst for exploring accurate forecasting, enhancing
interpretability, and driving progress towards the discussion of various
aspects such as energy disaggregation, demand response programs or behavioural
interventions.
</p>
</div>
</dd>
<dt><a name="item280">[280]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04009" title="Abstract">arXiv:2311.04009</a> [<a href="/pdf/2311.04009" title="Download PDF">pdf</a>, <a href="/format/2311.04009" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AGNES: Abstraction-guided Framework for Deep Neural Networks Security
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dhonthi%2C+A">Akshay Dhonthi</a>, 
<a href="/search/cs?searchtype=author&query=Eiermann%2C+M">Marcello Eiermann</a>, 
<a href="/search/cs?searchtype=author&query=Hahn%2C+E+M">Ernst Moritz Hahn</a>, 
<a href="/search/cs?searchtype=author&query=Hashemi%2C+V">Vahid Hashemi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages, 6 Figures, 4 Tables, Accepted at 25th International Conference on Verification, Model Checking, and Abstract Interpretation (VMCAI 2024)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Cryptography and Security (cs.CR); Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Deep Neural Networks (DNNs) are becoming widespread, particularly in
safety-critical areas. One prominent application is image recognition in
autonomous driving, where the correct classification of objects, such as
traffic signs, is essential for safe driving. Unfortunately, DNNs are prone to
backdoors, meaning that they concentrate on attributes of the image that should
be irrelevant for their correct classification. Backdoors are integrated into a
DNN during training, either with malicious intent (such as a manipulated
training process, because of which a yellow sticker always leads to a traffic
sign being recognised as a stop sign) or unintentional (such as a rural
background leading to any traffic sign being recognised as animal crossing,
because of biased training data).
<br />In this paper, we introduce AGNES, a tool to detect backdoors in DNNs for
image recognition. We discuss the principle approach on which AGNES is based.
Afterwards, we show that our tool performs better than many state-of-the-art
methods for multiple relevant case studies.
</p>
</div>
</dd>
<dt><a name="item281">[281]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04011" title="Abstract">arXiv:2311.04011</a> [<a href="/pdf/2311.04011" title="Download PDF">pdf</a>, <a href="/format/2311.04011" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Coverage Hole Elimination System in Industrial Environment
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zarour%2C+M">Mervat Zarour</a>, 
<a href="/search/cs?searchtype=author&query=Tayade%2C+S">Shreya Tayade</a>, 
<a href="/search/cs?searchtype=author&query=Melnyk%2C+S">Sergiy Melnyk</a>, 
<a href="/search/cs?searchtype=author&query=Schotten%2C+H+D">Hans D. Schotten</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> IEEE copyright
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> 2023 IEEE 97th Vehicular Technology Conference (VTC2023-Spring)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">The paper proposes a framework to identify and avoid the coverage hole in an
indoor industry environment. We assume an edge cloud co-located controller that
followers the Automated Guided Vehicle (AGV) movement on a factory floor over a
wireless channel. The coverage holes are caused due to blockage, path-loss, and
fading effects. An AGV in the coverage hole may lose connectivity to the
edge-cloud and become unstable. To avoid connectivity loss, we proposed a
framework that identifies the position of coverage hole using a Support- Vector
Machine (SVM) classifier model and constructs a binary coverage hole map
incorporating the AGV trajectory re-planning to avoid the identified coverage
hole. The AGV's re-planned trajectory is optimized and selected to avoid
coverage hole the shortest coverage-hole-free trajectory. We further
investigated the look-ahead time's impact on the AGV's re-planned trajectory
performance. The results reveal that an AGV's re-planned trajectory can be
shorter and further optimized if the coverage hole position is known ahead of
time
</p>
</div>
</dd>
<dt><a name="item282">[282]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04012" title="Abstract">arXiv:2311.04012</a> [<a href="/pdf/2311.04012" title="Download PDF">pdf</a>, <a href="/format/2311.04012" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Memory AMP for Generalized MIMO: Coding Principle and  Information-Theoretic Optimality
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yufei Chen</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+L">Lei Liu</a>, 
<a href="/search/cs?searchtype=author&query=Chi%2C+Y">Yuhao Chi</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Ying Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zhaoyang Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 pages, 13 figures, accepted by IEEE TWC. arXiv admin note: substantial text overlap with <a href="/abs/2310.17943">arXiv:2310.17943</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">To support complex communication scenarios in next-generation wireless
communications, this paper focuses on a generalized MIMO (GMIMO) with practical
assumptions, such as massive antennas, practical channel coding, arbitrary
input distributions, and general right-unitarily-invariant channel matrices
(covering Rayleigh fading, certain ill-conditioned and correlated channel
matrices). The orthogonal/vector approximate message passing (OAMP/VAMP)
receiver has been proved to be information-theoretically optimal in GMIMO, but
it is limited to high-complexity LMMSE. To solve this problem, a low-complexity
memory approximate message passing (MAMP) receiver has recently been shown to
be Bayes optimal but limited to uncoded systems. Therefore, how to design a
low-complexity and information-theoretically optimal receiver for GMIMO is
still an open issue. To address this issue, this paper proposes an
information-theoretically optimal MAMP receiver and investigates its achievable
rate analysis and optimal coding principle. Specifically, due to the
long-memory linear detection, state evolution (SE) for MAMP is intricately
multidimensional and cannot be used directly to analyze its achievable rate. To
avoid this difficulty, a simplified single-input single-output variational SE
(VSE) for MAMP is developed by leveraging the SE fixed-point consistent
property of MAMP and OAMP/VAMP. The achievable rate of MAMP is calculated using
the VSE, and the optimal coding principle is established to maximize the
achievable rate. On this basis, the information-theoretic optimality of MAMP is
proved rigorously. Numerical results show that the finite-length performances
of MAMP with practical optimized LDPC codes are 0.5-2.7 dB away from the
associated constrained capacities. It is worth noting that MAMP can achieve the
same performances as OAMP/VAMP with 0.4% of the time consumption for
large-scale systems.
</p>
</div>
</dd>
<dt><a name="item283">[283]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04014" title="Abstract">arXiv:2311.04014</a> [<a href="/pdf/2311.04014" title="Download PDF">pdf</a>, <a href="/format/2311.04014" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Method to Improve the Performance of Reinforcement Learning Based on  the Y Operator for a Class of Stochastic Differential Equation-Based  Child-Mother Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yin%2C+C">Cheng Yin</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yi Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages, 2 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Optimization and Control (math.OC)

</div>
<p class="mathjax">This paper introduces a novel operator, termed the Y operator, to elevate
control performance in Actor-Critic(AC) based reinforcement learning for
systems governed by stochastic differential equations(SDEs). The Y operator
ingeniously integrates the stochasticity of a class of child-mother system into
the Critic network's loss function, yielding substantial advancements in the
control performance of RL algorithms.Additionally, the Y operator elegantly
reformulates the challenge of solving partial differential equations for the
state-value function into a parallel problem for the drift and diffusion
functions within the system's SDEs.A rigorous mathematical proof confirms the
operator's validity.This transformation enables the Y Operator-based
Reinforcement Learning(YORL) framework to efficiently tackle optimal control
problems in both model-based and data-driven systems.The superiority of YORL is
demonstrated through linear and nonlinear numerical examples showing its
enhanced performance over existing methods post convergence.
</p>
</div>
</dd>
<dt><a name="item284">[284]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04015" title="Abstract">arXiv:2311.04015</a> [<a href="/pdf/2311.04015" title="Download PDF">pdf</a>, <a href="/ps/2311.04015" title="Download PostScript">ps</a>, <a href="/format/2311.04015" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Expressivity of ReLU-Networks under Convex Relaxations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Baader%2C+M">Maximilian Baader</a>, 
<a href="/search/cs?searchtype=author&query=M%C3%BCller%2C+M+N">Mark Niklas M&#xfc;ller</a>, 
<a href="/search/cs?searchtype=author&query=Mao%2C+Y">Yuhao Mao</a>, 
<a href="/search/cs?searchtype=author&query=Vechev%2C+M">Martin Vechev</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Convex relaxations are a key component of training and certifying provably
safe neural networks. However, despite substantial progress, a wide and poorly
understood accuracy gap to standard networks remains, raising the question of
whether this is due to fundamental limitations of convex relaxations. Initial
work investigating this question focused on the simple and widely used IBP
relaxation. It revealed that some univariate, convex, continuous piecewise
linear (CPWL) functions cannot be encoded by any ReLU network such that its
IBP-analysis is precise. To explore whether this limitation is shared by more
advanced convex relaxations, we conduct the first in-depth study on the
expressive power of ReLU networks across all commonly used convex relaxations.
We show that: (i) more advanced relaxations allow a larger class of univariate
functions to be expressed as precisely analyzable ReLU networks, (ii) more
precise relaxations can allow exponentially larger solution spaces of ReLU
networks encoding the same functions, and (iii) even using the most precise
single-neuron relaxations, it is impossible to construct precisely analyzable
ReLU networks that express multivariate, convex, monotone CPWL functions.
</p>
</div>
</dd>
<dt><a name="item285">[285]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04016" title="Abstract">arXiv:2311.04016</a> [<a href="/pdf/2311.04016" title="Download PDF">pdf</a>, <a href="/ps/2311.04016" title="Download PostScript">ps</a>, <a href="/format/2311.04016" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exploring Dataset-Scale Indicators of Data Quality
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Feuer%2C+B">Benjamin Feuer</a>, 
<a href="/search/cs?searchtype=author&query=Hegde%2C+C">Chinmay Hegde</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 1st Workshop on Attributing Model Behavior at Scale: 37th Conference on Neural Information Processing Systems (NeurIPS 2023). 7 pages, 1 figure
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Modern computer vision foundation models are trained on massive amounts of
data, incurring large economic and environmental costs. Recent research has
suggested that improving data quality can significantly reduce the need for
data quantity. But what constitutes data quality in computer vision? We posit
that the quality of a given dataset can be decomposed into distinct
sample-level and dataset-level constituents, and that the former have been more
extensively studied than the latter. We ablate the effects of two important
dataset-level constituents: label set design, and class balance. By monitoring
these constituents using key indicators we provide, researchers and
practitioners can better anticipate model performance, measured in terms of its
accuracy and robustness to distribution shifts.
</p>
</div>
</dd>
<dt><a name="item286">[286]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04020" title="Abstract">arXiv:2311.04020</a> [<a href="/pdf/2311.04020" title="Download PDF">pdf</a>, <a href="/format/2311.04020" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Analyzing Film Adaptation through Narrative Alignment
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pial%2C+T">Tanzir Pial</a>, 
<a href="/search/cs?searchtype=author&query=Salim%2C+S">Shahreen Salim</a>, 
<a href="/search/cs?searchtype=author&query=Pethe%2C+C">Charuta Pethe</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+A">Allen Kim</a>, 
<a href="/search/cs?searchtype=author&query=Skiena%2C+S">Steven Skiena</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 20 pages, 5 figures, 10 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Novels are often adapted into feature films, but the differences between the
two media usually require dropping sections of the source text from the movie
script. Here we study this screen adaptation process by constructing narrative
alignments using the Smith-Waterman local alignment algorithm coupled with
SBERT embedding distance to quantify text similarity between scenes and book
units. We use these alignments to perform an automated analysis of 40
adaptations, revealing insights into the screenwriting process concerning (i)
faithfulness of adaptation, (ii) importance of dialog, (iii) preservation of
narrative order, and (iv) gender representation issues reflective of the
Bechdel test.
</p>
</div>
</dd>
<dt><a name="item287">[287]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04030" title="Abstract">arXiv:2311.04030</a> [<a href="/pdf/2311.04030" title="Download PDF">pdf</a>, <a href="/format/2311.04030" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Biologically-Inspired Computational Model of Time Perception
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Louren%C3%A7o%2C+I">In&#xea;s Louren&#xe7;o</a>, 
<a href="/search/eess?searchtype=author&query=Mattila%2C+R">Robert Mattila</a>, 
<a href="/search/eess?searchtype=author&query=Ventura%2C+R">Rodrigo Ventura</a>, 
<a href="/search/eess?searchtype=author&query=Wahlberg%2C+B">Bo Wahlberg</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> IEEE Transactions on Cognitive and Developmental Systems 14 (2),
  258-268, 2021
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">Time perception - how humans and animals perceive the passage of time - forms
the basis for important cognitive skills such as decision-making, planning, and
communication. In this work, we propose a framework for examining the
mechanisms responsible for time perception. We first model neural time
perception as a combination of two known timing sources: internal neuronal
mechanisms and external (environmental) stimuli, and design a decision-making
framework to replicate them. We then implement this framework in a simulated
robot. We measure the agent's success on a temporal discrimination task
originally conducted by mice to evaluate its capacity to exploit temporal
knowledge. We conclude that the agent is able to perceive time similarly to
animals when it comes to their intrinsic mechanisms of interpreting time and
performing time-aware actions. Next, by analysing the behaviour of agents
equipped with the framework, we propose an estimator to infer characteristics
of the timing mechanisms intrinsic to the agents. In particular, we show that
from their empirical action probability distribution we are able to estimate
parameters used for perceiving time. Overall, our work shows promising results
when it comes to drawing conclusions regarding some of the characteristics
present in biological timing mechanisms.
</p>
</div>
</dd>
<dt><a name="item288">[288]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04031" title="Abstract">arXiv:2311.04031</a> [<a href="/pdf/2311.04031" title="Download PDF">pdf</a>, <a href="/format/2311.04031" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Ramsey Quantifiers in Linear Arithmetics
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bergstr%C3%A4%C3%9Fer%2C+P">Pascal Bergstr&#xe4;&#xdf;er</a>, 
<a href="/search/cs?searchtype=author&query=Ganardi%2C+M">Moses Ganardi</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+A+W">Anthony W. Lin</a>, 
<a href="/search/cs?searchtype=author&query=Zetzsche%2C+G">Georg Zetzsche</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>; Formal Languages and Automata Theory (cs.FL)

</div>
<p class="mathjax">We study Satisfiability Modulo Theories (SMT) enriched with the so-called
Ramsey quantifiers, which assert the existence of cliques (complete graphs) in
the graph induced by some formulas. The extended framework is known to have
applications in proving program termination (in particular, whether a
transitive binary predicate is well-founded), and monadic decomposability of
SMT formulas. Our main result is a new algorithm for eliminating Ramsey
quantifiers from three common SMT theories: Linear Integer Arithmetic (LIA),
Linear Real Arithmetic (LRA), and Linear Integer Real Arithmetic (LIRA). In
particular, if we work only with existentially quantified formulas, then our
algorithm runs in polynomial time and produces a formula of linear size. One
immediate consequence is that checking well-foundedness of a given formula in
the aforementioned theory defining a transitive predicate can be
straightforwardly handled by highly optimized SMT-solvers. We show also how
this provides a uniform semi-algorithm for verifying termination and liveness
with completeness guarantee (in fact, with an optimal computational complexity)
for several well-known classes of infinite-state systems, which include
succinct timed systems, one-counter systems, and monotonic counter systems.
Another immediate consequence is a solution to an open problem on checking
monadic decomposability of a given relation in quantifier-free fragments of LRA
and LIRA, which is an important problem in automated reasoning and constraint
databases. Our result immediately implies decidability of this problem with an
optimal complexity (coNP-complete) and enables exploitation of SMT-solvers. It
also provides a termination guarantee for the generic monadic decomposition
algorithm of Veanes et al. for LIA, LRA, and LIRA. We report encouraging
experimental results on a prototype implementation of our algorithms on
micro-benchmarks.
</p>
</div>
</dd>
<dt><a name="item289">[289]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04034" title="Abstract">arXiv:2311.04034</a> [<a href="/pdf/2311.04034" title="Download PDF">pdf</a>, <a href="/format/2311.04034" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Impact of HPO on AutoML Forecasting Ensembles
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hoffmann%2C+D">David Hoffmann</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">A forecasting ensemble consisting of a diverse range of estimators for both
local and global univariate forecasting, in particular MQ-CNN,DeepAR, Prophet,
NPTS, ARIMA and ETS, can be used to make forecasts for a variety of problems.
This paper delves into the aspect of adding different hyperparameter
optimization strategies to the deep learning models in such a setup (DeepAR and
MQ-CNN), exploring the trade-off between added training cost and the increase
in accuracy for different configurations. It shows that in such a setup, adding
hyperparameter optimization can lead to performance improvements, with the
final setup having a 9.9 % percent accuracy improvement with respect to the
avg-wQL over the baseline ensemble without HPO, accompanied by a 65.8 %
increase in end-to-end ensemble latency. This improvement is based on an
empirical analysis of combining the ensemble pipeline with different tuning
strategies, namely Bayesian Optimisation and Hyperband and different
configurations of those strategies. In the final configuration, the proposed
combination of ensemble learning and HPO outperforms the state of the art
commercial AutoML forecasting solution, Amazon Forecast, with a 3.5 % lower
error and 16.0 % lower end-to-end ensemble latency.
</p>
</div>
</dd>
<dt><a name="item290">[290]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04037" title="Abstract">arXiv:2311.04037</a> [<a href="/pdf/2311.04037" title="Download PDF">pdf</a>, <a href="/format/2311.04037" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Causal Discovery Under Local Privacy
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Binkyt%C4%97%2C+R">R&#x16b;ta Binkyt&#x117;</a>, 
<a href="/search/cs?searchtype=author&query=Pinz%C3%B3n%2C+C">Carlos Pinz&#xf3;n</a>, 
<a href="/search/cs?searchtype=author&query=Lesty%C3%A1n%2C+S">Szilvia Lesty&#xe1;n</a>, 
<a href="/search/cs?searchtype=author&query=Jung%2C+K">Kangsoo Jung</a>, 
<a href="/search/cs?searchtype=author&query=Arcolezi%2C+H+H">H&#xe9;ber H. Arcolezi</a>, 
<a href="/search/cs?searchtype=author&query=Palamidessi%2C+C">Catuscia Palamidessi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Methodology (stat.ME)

</div>
<p class="mathjax">Differential privacy is a widely adopted framework designed to safeguard the
sensitive information of data providers within a data set. It is based on the
application of controlled noise at the interface between the server that stores
and processes the data, and the data consumers. Local differential privacy is a
variant that allows data providers to apply the privatization mechanism
themselves on their data individually. Therefore it provides protection also in
contexts in which the server, or even the data collector, cannot be trusted.
The introduction of noise, however, inevitably affects the utility of the data,
particularly by distorting the correlations between individual data components.
This distortion can prove detrimental to tasks such as causal discovery. In
this paper, we consider various well-known locally differentially private
mechanisms and compare the trade-off between the privacy they provide, and the
accuracy of the causal structure produced by algorithms for causal learning
when applied to data obfuscated by these mechanisms. Our analysis yields
valuable insights for selecting appropriate local differentially private
protocols for causal discovery tasks. We foresee that our findings will aid
researchers and practitioners in conducting locally private causal discovery.
</p>
</div>
</dd>
<dt><a name="item291">[291]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04040" title="Abstract">arXiv:2311.04040</a> [<a href="/pdf/2311.04040" title="Download PDF">pdf</a>, <a href="/format/2311.04040" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Data exploitation: multi-task learning of object detection and semantic  segmentation on partially annotated data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=L%C3%AA%2C+H">Ho&#xe0;ng-&#xc2;n L&#xea;</a>, 
<a href="/search/cs?searchtype=author&query=Pham%2C+M">Minh-Tan Pham</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted for publishing at BMVC 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Multi-task partially annotated data where each data point is annotated for
only a single task are potentially helpful for data scarcity if a network can
leverage the inter-task relationship. In this paper, we study the joint
learning of object detection and semantic segmentation, the two most popular
vision problems, from multi-task data with partial annotations. Extensive
experiments are performed to evaluate each task performance and explore their
complementarity when a multi-task network cannot optimize both tasks
simultaneously. We propose employing knowledge distillation to leverage
joint-task optimization. The experimental results show favorable results for
multi-task learning and knowledge distillation over single-task learning and
even full supervision scenario. All code and data splits are available at
https://github.com/lhoangan/multas
</p>
</div>
</dd>
<dt><a name="item292">[292]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04042" title="Abstract">arXiv:2311.04042</a> [<a href="/pdf/2311.04042" title="Download PDF">pdf</a>, <a href="/format/2311.04042" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Analyzing Near-Infrared Hyperspectral Imaging for Protein Content  Regression and Grain Variety Classification Using Bulk References and Varying  Grain-to-Background Ratios
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Engstr%C3%B8m%2C+O+G">Ole-Christian Galbo Engstr&#xf8;m</a>, 
<a href="/search/cs?searchtype=author&query=Dreier%2C+E+S">Erik Schou Dreier</a>, 
<a href="/search/cs?searchtype=author&query=Jespersen%2C+B+M">Birthe M&#xf8;ller Jespersen</a>, 
<a href="/search/cs?searchtype=author&query=Pedersen%2C+K+S">Kim Steenstrup Pedersen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 19 pages, 17 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Based on previous work, we assess the use of NIR-HSI images for calibrating
models on two datasets, focusing on protein content regression and grain
variety classification. Limited reference data for protein content is expanded
by subsampling and associating it with the bulk sample. However, this method
introduces significant biases due to skewed leptokurtic prediction
distributions, affecting both PLS-R and deep CNN models. We propose adjustments
to mitigate these biases, improving mean protein reference predictions.
Additionally, we investigate the impact of grain-to-background ratios on both
tasks. Higher ratios yield more accurate predictions, but including lower-ratio
images in calibration enhances model robustness for such scenarios.
</p>
</div>
</dd>
<dt><a name="item293">[293]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04044" title="Abstract">arXiv:2311.04044</a> [<a href="/pdf/2311.04044" title="Download PDF">pdf</a>, <a href="/format/2311.04044" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> P-Bench: A Multi-level Privacy Evaluation Benchmark for Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Haoran Li</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+D">Dadi Guo</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+D">Donghao Li</a>, 
<a href="/search/cs?searchtype=author&query=Fan%2C+W">Wei Fan</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+Q">Qi Hu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xin Liu</a>, 
<a href="/search/cs?searchtype=author&query=Chan%2C+C">Chunkit Chan</a>, 
<a href="/search/cs?searchtype=author&query=Yao%2C+D">Duanyi Yao</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+Y">Yangqiu Song</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Work In Progress
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Cryptography and Security (cs.CR)

</div>
<p class="mathjax">The rapid development of language models (LMs) brings unprecedented
accessibility and usage for both models and users. On the one hand, powerful
LMs, trained with massive textual data, achieve state-of-the-art performance
over numerous downstream NLP tasks. On the other hand, more and more attention
is paid to unrestricted model accesses that may bring malicious privacy risks
of data leakage. To address these issues, many recent works propose
privacy-preserving language models (PPLMs) with differential privacy (DP).
Unfortunately, different DP implementations make it challenging for a fair
comparison among existing PPLMs. In this paper, we present P-Bench, a
multi-perspective privacy evaluation benchmark to empirically and intuitively
quantify the privacy leakage of LMs. Instead of only protecting and measuring
the privacy of protected data with DP parameters, P-Bench sheds light on the
neglected inference data privacy during actual usage. P-Bench first clearly
defines multi-faceted privacy objectives during private fine-tuning. Then,
P-Bench constructs a unified pipeline to perform private fine-tuning. Lastly,
P-Bench performs existing privacy attacks on LMs with pre-defined privacy
objectives as the empirical evaluation results. The empirical attack results
are used to fairly and intuitively evaluate the privacy leakage of various
PPLMs. We conduct extensive experiments on three datasets of GLUE for
mainstream LMs.
</p>
</div>
</dd>
<dt><a name="item294">[294]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04046" title="Abstract">arXiv:2311.04046</a> [<a href="/pdf/2311.04046" title="Download PDF">pdf</a>, <a href="/format/2311.04046" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Reinforcement Learning Fine-tuning of Language Models is Biased Towards  More Extractable Features
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cruz%2C+D">Diogo Cruz</a>, 
<a href="/search/cs?searchtype=author&query=Pona%2C+E">Edoardo Pona</a>, 
<a href="/search/cs?searchtype=author&query=Holness-Tofts%2C+A">Alex Holness-Tofts</a>, 
<a href="/search/cs?searchtype=author&query=Schmied%2C+E">Elias Schmied</a>, 
<a href="/search/cs?searchtype=author&query=Alonso%2C+V+A">V&#xed;ctor Abia Alonso</a>, 
<a href="/search/cs?searchtype=author&query=Griffin%2C+C">Charlie Griffin</a>, 
<a href="/search/cs?searchtype=author&query=Cirstea%2C+B">Bogdan-Ionut Cirstea</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computation and Language (cs.CL)

</div>
<p class="mathjax">Many capable large language models (LLMs) are developed via self-supervised
pre-training followed by a reinforcement-learning fine-tuning phase, often
based on human or AI feedback. During this stage, models may be guided by their
inductive biases to rely on simpler features which may be easier to extract, at
a cost to robustness and generalisation. We investigate whether principles
governing inductive biases in the supervised fine-tuning of LLMs also apply
when the fine-tuning process uses reinforcement learning. Following Lovering et
al (2021), we test two hypotheses: that features more $\textit{extractable}$
after pre-training are more likely to be utilised by the final policy, and that
the evidence for/against a feature predicts whether it will be utilised.
Through controlled experiments on synthetic and natural language tasks, we find
statistically significant correlations which constitute strong evidence for
these hypotheses.
</p>
</div>
</dd>
<dt><a name="item295">[295]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04052" title="Abstract">arXiv:2311.04052</a> [<a href="/pdf/2311.04052" title="Download PDF">pdf</a>, <a href="/ps/2311.04052" title="Download PostScript">ps</a>, <a href="/format/2311.04052" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Generative Structural Design Integrating BIM and Diffusion Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=He%2C+Z">Zhili He</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yu-Hsing Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jian Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 38 pages, 9 figures. Preprint submitted to Elsevier
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Intelligent structural design using AI can effectively reduce time overhead
and increase efficiency. It has potential to become the new design paradigm in
the future to assist and even replace engineers, and so it has become a
research hotspot in the academic community. However, current methods have some
limitations to be addressed, whether in terms of application scope, visual
quality of generated results, or evaluation metrics of results. This study
proposes a comprehensive solution. Firstly, we introduce building information
modeling (BIM) into intelligent structural design and establishes a structural
design pipeline integrating BIM and generative AI, which is a powerful
supplement to the previous frameworks that only considered CAD drawings. In
order to improve the perceptual quality and details of generations, this study
makes 3 contributions. Firstly, in terms of generation framework, inspired by
the process of human drawing, a novel 2-stage generation framework is proposed
to replace the traditional end-to-end framework to reduce the generation
difficulty for AI models. Secondly, in terms of generative AI tools adopted,
diffusion models (DMs) are introduced to replace widely used generative
adversarial network (GAN)-based models, and a novel physics-based conditional
diffusion model (PCDM) is proposed to consider different design prerequisites.
Thirdly, in terms of neural networks, an attention block (AB) consisting of a
self-attention block (SAB) and a parallel cross-attention block (PCAB) is
designed to facilitate cross-domain data fusion. The quantitative and
qualitative results demonstrate the powerful generation and representation
capabilities of PCDM. Necessary ablation studies are conducted to examine the
validity of the methods. This study also shows that DMs have the potential to
replace GANs and become the new benchmark for generative problems in civil
engineering.
</p>
</div>
</dd>
<dt><a name="item296">[296]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04055" title="Abstract">arXiv:2311.04055</a> [<a href="/pdf/2311.04055" title="Download PDF">pdf</a>, <a href="/ps/2311.04055" title="Download PostScript">ps</a>, <a href="/format/2311.04055" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Feature Space Renormalization for Semi-supervised Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sun%2C+J">Jun Sun</a>, 
<a href="/search/cs?searchtype=author&query=Mao%2C+Z">Zhongjie Mao</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+C">Chao Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+C">Chao Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+X">Xiao-Jun Wu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Version 1
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Semi-supervised learning (SSL) has been proven to be a powerful method for
leveraging unlabelled data to alleviate models' dependence on large labelled
datasets. The common framework among recent approaches is to train the model on
a large amount of unlabelled data with consistency regularization to constrain
the model predictions to be invariant to input perturbation. However, the
existing SSL frameworks still have room for improvement in the consistency
regularization method. Instead of regularizing category predictions in the
label space as in existing frameworks, this paper proposes a feature space
renormalization (FSR) mechanism for SSL. First, we propose a feature space
renormalization mechanism to substitute for the commonly used consistency
regularization mechanism to learn better discriminative features. To apply this
mechanism, we start by building a basic model and an empirical model and then
introduce our mechanism to renormalize the feature learning of the basic model
with the guidance of the empirical model. Second, we combine the proposed
mechanism with pseudo-labelling to obtain a novel effective SSL model named
FreMatch. The experimental results show that our method can achieve better
performance on a variety of standard SSL benchmark datasets, and the proposed
feature space renormalization mechanism can also enhance the performance of
other SSL approaches.
</p>
</div>
</dd>
<dt><a name="item297">[297]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04056" title="Abstract">arXiv:2311.04056</a> [<a href="/pdf/2311.04056" title="Download PDF">pdf</a>, <a href="/format/2311.04056" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multi-View Causal Representation Learning with Partial Observability
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yao%2C+D">Dingling Yao</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+D">Danru Xu</a>, 
<a href="/search/cs?searchtype=author&query=Lachapelle%2C+S">S&#xe9;bastien Lachapelle</a>, 
<a href="/search/cs?searchtype=author&query=Magliacane%2C+S">Sara Magliacane</a>, 
<a href="/search/cs?searchtype=author&query=Taslakian%2C+P">Perouz Taslakian</a>, 
<a href="/search/cs?searchtype=author&query=Martius%2C+G">Georg Martius</a>, 
<a href="/search/cs?searchtype=author&query=von+K%C3%BCgelgen%2C+J">Julius von K&#xfc;gelgen</a>, 
<a href="/search/cs?searchtype=author&query=Locatello%2C+F">Francesco Locatello</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 28 pages, 10 figures, 10 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">We present a unified framework for studying the identifiability of
representations learned from simultaneously observed views, such as different
data modalities. We allow a partially observed setting in which each view
constitutes a nonlinear mixture of a subset of underlying latent variables,
which can be causally related. We prove that the information shared across all
subsets of any number of views can be learned up to a smooth bijection using
contrastive learning and a single encoder per view. We also provide graphical
criteria indicating which latent variables can be identified through a simple
set of rules, which we refer to as identifiability algebra. Our general
framework and theoretical results unify and extend several previous works on
multi-view nonlinear ICA, disentanglement, and causal representation learning.
We experimentally validate our claims on numerical, image, and multi-modal data
sets. Further, we demonstrate that the performance of prior methods is
recovered in different special cases of our setup. Overall, we find that access
to multiple partial views enables us to identify a more fine-grained
representation, under the generally milder assumption of partial observability.
</p>
</div>
</dd>
<dt><a name="item298">[298]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04058" title="Abstract">arXiv:2311.04058</a> [<a href="/pdf/2311.04058" title="Download PDF">pdf</a>, <a href="/format/2311.04058" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> mmFUSION: Multimodal Fusion for 3D Objects Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ahmad%2C+J">Javed Ahmad</a>, 
<a href="/search/cs?searchtype=author&query=Del+Bue%2C+A">Alessio Del Bue</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages,
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Multi-sensor fusion is essential for accurate 3D object detection in
self-driving systems. Camera and LiDAR are the most commonly used sensors, and
usually, their fusion happens at the early or late stages of 3D detectors with
the help of regions of interest (RoIs). On the other hand, fusion at the
intermediate level is more adaptive because it does not need RoIs from
modalities but is complex as the features of both modalities are presented from
different points of view. In this paper, we propose a new intermediate-level
multi-modal fusion (mmFUSION) approach to overcome these challenges. First, the
mmFUSION uses separate encoders for each modality to compute features at a
desired lower space volume. Second, these features are fused through
cross-modality and multi-modality attention mechanisms proposed in mmFUSION.
The mmFUSION framework preserves multi-modal information and learns to
complement modalities' deficiencies through attention weights. The strong
multi-modal features from the mmFUSION framework are fed to a simple 3D
detection head for 3D predictions. We evaluate mmFUSION on the KITTI and
NuScenes dataset where it performs better than available early, intermediate,
late, and even two-stage based fusion schemes. The code with the mmdetection3D
project plugin will be publicly available soon.
</p>
</div>
</dd>
<dt><a name="item299">[299]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04059" title="Abstract">arXiv:2311.04059</a> [<a href="/pdf/2311.04059" title="Download PDF">pdf</a>, <a href="/ps/2311.04059" title="Download PostScript">ps</a>, <a href="/format/2311.04059" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Over-the-Air Computation Empowered Federated Learning: A Joint  Uplink-Downlink Design
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+D">Deyou Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Xiao%2C+M">Ming Xiao</a>, 
<a href="/search/cs?searchtype=author&query=Skoglund%2C+M">Mikael Skoglund</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This paper has been accepted by the IEEE 98th Vehicular Technology Conference (VTC2023-Fall), Hong Kong, China, 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>

</div>
<p class="mathjax">In this paper, we investigate the communication designs of over-the-air
computation (AirComp) empowered federated learning (FL) systems considering
uplink model aggregation and downlink model dissemination jointly. We first
derive an upper bound on the expected difference between the training loss and
the optimal loss, which reveals that optimizing the FL performance is
equivalent to minimizing the distortion in the received global gradient vector
at each edge node. As such, we jointly optimize each edge node transmit and
receive equalization coefficients along with the edge server forwarding matrix
to minimize the maximum gradient distortion across all edge nodes. We further
utilize the MNIST dataset to evaluate the performance of the considered FL
system in the context of the handwritten digit recognition task. Experiment
results show that deploying multiple antennas at the edge server significantly
reduces the distortion in the received global gradient vector, leading to a
notable improvement in recognition accuracy compared to the single antenna
case.
</p>
</div>
</dd>
<dt><a name="item300">[300]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04060" title="Abstract">arXiv:2311.04060</a> [<a href="/pdf/2311.04060" title="Download PDF">pdf</a>, <a href="/format/2311.04060" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Estimator-Coupled Reinforcement Learning for Robust Purely Tactile  In-Hand Manipulation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=R%C3%B6stel%2C+L">Lennart R&#xf6;stel</a>, 
<a href="/search/cs?searchtype=author&query=Pitz%2C+J">Johannes Pitz</a>, 
<a href="/search/cs?searchtype=author&query=Sievers%2C+L">Leon Sievers</a>, 
<a href="/search/cs?searchtype=author&query=B%C3%A4uml%2C+B">Berthold B&#xe4;uml</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">This paper identifies and addresses the problems with naively combining
(reinforcement) learning-based controllers and state estimators for robotic
in-hand manipulation. Specifically, we tackle the challenging task of purely
tactile, goal-conditioned, dextrous in-hand reorientation with the hand
pointing downwards. Due to the limited sensing available, many control
strategies that are feasible in simulation when having full knowledge of the
object's state do not allow for accurate state estimation. Hence, separately
training the controller and the estimator and combining the two at test time
leads to poor performance. We solve this problem by coupling the control policy
to the state estimator already during training in simulation. This approach
leads to more robust state estimation and overall higher performance on the
task while maintaining an interpretability advantage over end-to-end policy
learning. With our GPU-accelerated implementation, learning from scratch takes
a median training time of only 6.5 hours on a single, low-cost GPU. In
simulation experiments with the DLR-Hand II and for four significantly
different object shapes, we provide an in-depth analysis of the performance of
our approach. We demonstrate the successful sim2real transfer by rotating the
four objects to all 24 orientations in the $\pi/2$ discretization of SO(3),
which has never been achieved for such a diverse set of shapes. Finally, our
method can reorient a cube consecutively to nine goals (median), which was
beyond the reach of previous methods in this challenging setting.
</p>
</div>
</dd>
<dt><a name="item301">[301]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04061" title="Abstract">arXiv:2311.04061</a> [<a href="/pdf/2311.04061" title="Download PDF">pdf</a>, <a href="/format/2311.04061" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Neural Yarn-Level Appearance Model for Cloth Rendering
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Soh%2C+G+Y">Guan Yu Soh</a>, 
<a href="/search/cs?searchtype=author&query=Montazeri%2C+Z">Zahra Montazeri</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages, 10 figures, 3 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Graphics (cs.GR)</span>

</div>
<p class="mathjax">The realistic rendering of woven and knitted fabrics has posed significant
challenges throughout many years. Previously, fiber-based micro-appearance
models have achieved considerable success in attaining high levels of realism.
However, rendering such models remains complex due to the intricate internal
scatterings of hundreds or thousands of fibers within a yarn, requiring vast
amounts of memory and time to render. In this paper, we introduce a novel
framework to capture yarn-level appearance by tracing and aggregating many
light paths through the underlying fiber geometry. We then employ lightweight
neural networks to accurately model the aggregated BSDF, which allows for the
precise modeling of a diverse array of materials while offering substantial
improvements in speed and reductions in memory. Furthermore, we introduce a
novel importance sampling scheme to further speed up the rate of convergence.
We validate the efficacy and versatility of our framework through comparisons
with preceding fiber-based shading models and by replicating various real-world
fabrics. Our proposed model's enhanced performance and adaptability make it
especially beneficial for film and video game production applications.
</p>
</div>
</dd>
<dt><a name="item302">[302]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04064" title="Abstract">arXiv:2311.04064</a> [<a href="/pdf/2311.04064" title="Download PDF">pdf</a>, <a href="/format/2311.04064" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Implementation and Comparison of Methods to Extract Reliability KPIs out  of Textual Wind Turbine Maintenance Work Orders
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lutz%2C+M">Marc-Alexander Lutz</a>, 
<a href="/search/cs?searchtype=author&query=Sch%C3%A4fermeier%2C+B">Bastian Sch&#xe4;fermeier</a>, 
<a href="/search/cs?searchtype=author&query=Sexton%2C+R">Rachael Sexton</a>, 
<a href="/search/cs?searchtype=author&query=Sharp%2C+M">Michael Sharp</a>, 
<a href="/search/cs?searchtype=author&query=Dima%2C+A">Alden Dima</a>, 
<a href="/search/cs?searchtype=author&query=Faulstich%2C+S">Stefan Faulstich</a>, 
<a href="/search/cs?searchtype=author&query=Aluri%2C+J+M">Jagan Mohini Aluri</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Maintenance work orders are commonly used to document information about wind
turbine operation and maintenance. This includes details about proactive and
reactive wind turbine downtimes, such as preventative and corrective
maintenance. However, the information contained in maintenance work orders is
often unstructured and difficult to analyze, making it challenging for
decision-makers to use this information for optimizing operation and
maintenance. To address this issue, this work presents three different
approaches to calculate reliability key performance indicators from maintenance
work orders. The first approach involves manual labeling of the maintenance
work orders by domain experts, using the schema defined in an industrial
guideline to assign the label accordingly. The second approach involves the
development of a model that automatically labels the maintenance work orders
using text classification methods. The third technique uses an AI-assisted
tagging tool to tag and structure the raw maintenance information contained in
the maintenance work orders. The resulting calculated reliability key
performance indicator of the first approach are used as a benchmark for
comparison with the results of the second and third approaches. The quality and
time spent are considered as criteria for evaluation. Overall, these three
methods make extracting maintenance information from maintenance work orders
more efficient, enable the assessment of reliability key performance indicators
and therefore support the optimization of wind turbine operation and
maintenance.
</p>
</div>
</dd>
<dt><a name="item303">[303]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04065" title="Abstract">arXiv:2311.04065</a> [<a href="/pdf/2311.04065" title="Download PDF">pdf</a>, <a href="/format/2311.04065" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Study of the One-Dimensional Heat-Conduction Equation with Radiation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Halic%2C+M">Mihai Halic</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Classical Analysis and ODEs (math.CA)

</div>
<p class="mathjax">We consider a boundary value problem (BVP) modelling one-dimensional
heat-conduction with radiation, which is derived from the Stefan-Boltzmann law.
The problem strongly depends on the parameters, making difficult to estimate
the solution. We use an analytical approach to determine upper and lower bounds
to the exact solution of the BVP, which allows estimating the latter. Finally,
we support our theoretical arguments with numerical data, by implementing them
into the MAPLE computer program.
</p>
</div>
</dd>
<dt><a name="item304">[304]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04066" title="Abstract">arXiv:2311.04066</a> [<a href="/pdf/2311.04066" title="Download PDF">pdf</a>, <a href="/format/2311.04066" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Can CLIP Help Sound Source Localization?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Park%2C+S">Sooyoung Park</a>, 
<a href="/search/cs?searchtype=author&query=Senocak%2C+A">Arda Senocak</a>, 
<a href="/search/cs?searchtype=author&query=Chung%2C+J+S">Joon Son Chung</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> WACV 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Multimedia (cs.MM); Sound (cs.SD); Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">Large-scale pre-trained image-text models demonstrate remarkable versatility
across diverse tasks, benefiting from their robust representational
capabilities and effective multimodal alignment. We extend the application of
these models, specifically CLIP, to the domain of sound source localization.
Unlike conventional approaches, we employ the pre-trained CLIP model without
explicit text input, relying solely on the audio-visual correspondence. To this
end, we introduce a framework that translates audio signals into tokens
compatible with CLIP's text encoder, yielding audio-driven embeddings. By
directly using these embeddings, our method generates audio-grounded masks for
the provided audio, extracts audio-grounded image features from the highlighted
regions, and aligns them with the audio-driven embeddings using the
audio-visual correspondence objective. Our findings suggest that utilizing
pre-trained image-text models enable our model to generate more complete and
compact localization maps for the sounding objects. Extensive experiments show
that our method outperforms state-of-the-art approaches by a significant
margin.
</p>
</div>
</dd>
<dt><a name="item305">[305]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04067" title="Abstract">arXiv:2311.04067</a> [<a href="/pdf/2311.04067" title="Download PDF">pdf</a>, <a href="/format/2311.04067" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multitask Multimodal Prompted Training for Interactive Embodied Task  Completion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pantazopoulos%2C+G">Georgios Pantazopoulos</a>, 
<a href="/search/cs?searchtype=author&query=Nikandrou%2C+M">Malvina Nikandrou</a>, 
<a href="/search/cs?searchtype=author&query=Parekh%2C+A">Amit Parekh</a>, 
<a href="/search/cs?searchtype=author&query=Hemanthage%2C+B">Bhathiya Hemanthage</a>, 
<a href="/search/cs?searchtype=author&query=Eshghi%2C+A">Arash Eshghi</a>, 
<a href="/search/cs?searchtype=author&query=Konstas%2C+I">Ioannis Konstas</a>, 
<a href="/search/cs?searchtype=author&query=Rieser%2C+V">Verena Rieser</a>, 
<a href="/search/cs?searchtype=author&query=Lemon%2C+O">Oliver Lemon</a>, 
<a href="/search/cs?searchtype=author&query=Suglia%2C+A">Alessandro Suglia</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> EMNLP 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Interactive and embodied tasks pose at least two fundamental challenges to
existing Vision &amp; Language (VL) models, including 1) grounding language in
trajectories of actions and observations, and 2) referential disambiguation. To
tackle these challenges, we propose an Embodied MultiModal Agent (EMMA): a
unified encoder-decoder model that reasons over images and trajectories, and
casts action prediction as multimodal text generation. By unifying all tasks as
text generation, EMMA learns a language of actions which facilitates transfer
across tasks. Different to previous modular approaches with independently
trained components, we use a single multitask model where each task contributes
to goal completion. EMMA performs on par with similar models on several VL
benchmarks and sets a new state-of-the-art performance (36.81% success rate) on
the Dialog-guided Task Completion (DTC), a benchmark to evaluate dialog-guided
agents in the Alexa Arena
</p>
</div>
</dd>
<dt><a name="item306">[306]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04069" title="Abstract">arXiv:2311.04069</a> [<a href="/pdf/2311.04069" title="Download PDF">pdf</a>, <a href="/ps/2311.04069" title="Download PostScript">ps</a>, <a href="/format/2311.04069" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LISBET: a self-supervised Transformer model for the automatic  segmentation of social behavior motifs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chindemi%2C+G">Giuseppe Chindemi</a>, 
<a href="/search/cs?searchtype=author&query=Girard%2C+B">Benoit Girard</a>, 
<a href="/search/cs?searchtype=author&query=Bellone%2C+C">Camilla Bellone</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG); Quantitative Methods (q-bio.QM); Machine Learning (stat.ML)

</div>
<p class="mathjax">Social behavior, defined as the process by which individuals act and react in
response to others, is crucial for the function of societies and holds profound
implications for mental health. To fully grasp the intricacies of social
behavior and identify potential therapeutic targets for addressing social
deficits, it is essential to understand its core principles. Although machine
learning algorithms have made it easier to study specific aspects of complex
behavior, current methodologies tend to focus primarily on single-animal
behavior. In this study, we introduce LISBET (seLf-supervIsed Social BEhavioral
Transformer), a model designed to detect and segment social interactions. Our
model eliminates the need for feature selection and extensive human annotation
by using self-supervised learning to detect and quantify social behaviors from
dynamic body parts tracking data. LISBET can be used in hypothesis-driven mode
to automate behavior classification using supervised finetuning, and in
discovery-driven mode to segment social behavior motifs using unsupervised
learning. We found that motifs recognized using the discovery-driven approach
not only closely match the human annotations but also correlate with the
electrophysiological activity of dopaminergic neurons in the Ventral Tegmental
Area (VTA). We hope LISBET will help the community improve our understanding of
social behaviors and their neural underpinnings.
</p>
</div>
</dd>
<dt><a name="item307">[307]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04071" title="Abstract">arXiv:2311.04071</a> [<a href="/pdf/2311.04071" title="Download PDF">pdf</a>, <a href="/format/2311.04071" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Energy-based Calibrated VAE with Test Time Free Lunch
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Luo%2C+Y">Yihong Luo</a>, 
<a href="/search/cs?searchtype=author&query=Qiu%2C+S">Siya Qiu</a>, 
<a href="/search/cs?searchtype=author&query=Tao%2C+X">Xingjian Tao</a>, 
<a href="/search/cs?searchtype=author&query=Cai%2C+Y">Yujun Cai</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+J">Jing Tang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> work in progress
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">In this paper, we propose a novel Energy-Calibrated Generative Model that
utilizes a Conditional EBM for enhancing Variational Autoencoders (VAEs). VAEs
are sampling efficient but often suffer from blurry generation results due to
the lack of training in the generative direction. On the other hand,
Energy-Based Models (EBMs) can generate high-quality samples but require
expensive Markov Chain Monte Carlo (MCMC) sampling. To address these issues, we
introduce a Conditional EBM for calibrating the generative direction during
training, without requiring it for test time sampling. Our approach enables the
generative model to be trained upon data and calibrated samples with adaptive
weight, thereby enhancing efficiency and effectiveness without necessitating
MCMC sampling in the inference phase. We also show that the proposed approach
can be extended to calibrate normalizing flows and variational posterior.
Moreover, we propose to apply the proposed method to zero-shot image
restoration via neural transport prior and range-null theory. We demonstrate
the effectiveness of the proposed method through extensive experiments in
various applications, including image generation and zero-shot image
restoration. Our method shows state-of-the-art performance over single-step
non-adversarial generation.
</p>
</div>
</dd>
<dt><a name="item308">[308]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04072" title="Abstract">arXiv:2311.04072</a> [<a href="/pdf/2311.04072" title="Download PDF">pdf</a>, <a href="/format/2311.04072" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Beyond Imitation: Leveraging Fine-grained Quality Signals for Alignment
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Guo%2C+G">Geyang Guo</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+R">Ranchi Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+T">Tianyi Tang</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+W+X">Wayne Xin Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Wen%2C+J">Ji-Rong Wen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Alignment with human preference is a desired property of large language
models (LLMs). Currently, the main alignment approach is based on reinforcement
learning from human feedback (RLHF). Despite the effectiveness of RLHF, it is
intricate to implement and train, thus recent studies explore how to develop
alternative alignment approaches based on supervised fine-tuning (SFT). A major
limitation of SFT is that it essentially does imitation learning, which cannot
fully understand what are the expected behaviors. To address this issue, we
propose an improved alignment approach named FIGA. Different from prior
methods, we incorporate fine-grained (i.e., token or phrase level) quality
signals that are derived by contrasting good and bad responses. Our approach
has made two major contributions. Firstly, we curate a refined alignment
dataset that pairs initial responses and the corresponding revised ones.
Secondly, we devise a new loss function can leverage fine-grained quality
signals to instruct the learning of LLMs for alignment. Extensive experiments
have demonstrated the effectiveness of our approaches by comparing a number of
competitive baselines.
</p>
</div>
</dd>
<dt><a name="item309">[309]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04076" title="Abstract">arXiv:2311.04076</a> [<a href="/pdf/2311.04076" title="Download PDF">pdf</a>, <a href="/format/2311.04076" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Do LLMs exhibit human-like response biases? A case study in survey  design
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tjuatja%2C+L">Lindia Tjuatja</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+V">Valerie Chen</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+S+T">Sherry Tongshuang Wu</a>, 
<a href="/search/cs?searchtype=author&query=Talwalkar%2C+A">Ameet Talwalkar</a>, 
<a href="/search/cs?searchtype=author&query=Neubig%2C+G">Graham Neubig</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">As large language models (LLMs) become more capable, there is growing
excitement about the possibility of using LLMs as proxies for humans in
real-world tasks where subjective labels are desired, such as in surveys and
opinion polling. One widely-cited barrier to the adoption of LLMs is their
sensitivity to prompt wording -- but interestingly, humans also display
sensitivities to instruction changes in the form of response biases. As such,
we argue that if LLMs are going to be used to approximate human opinions, it is
necessary to investigate the extent to which LLMs also reflect human response
biases, if at all. In this work, we use survey design as a case study, where
human response biases caused by permutations in wordings of ``prompts'' have
been extensively studied. Drawing from prior work in social psychology, we
design a dataset and propose a framework to evaluate whether LLMs exhibit
human-like response biases in survey questionnaires. Our comprehensive
evaluation of nine models shows that popular open and commercial LLMs generally
fail to reflect human-like behavior. These inconsistencies tend to be more
prominent in models that have been instruction fine-tuned. Furthermore, even if
a model shows a significant change in the same direction as humans, we find
that perturbations that are not meant to elicit significant changes in humans
may also result in a similar change, suggesting that such a result could be
partially due to other spurious correlations. These results highlight the
potential pitfalls of using LLMs to substitute humans in parts of the
annotation pipeline, and further underscore the importance of finer-grained
characterizations of model behavior. Our code, dataset, and collected samples
are available at https://github.com/lindiatjuatja/BiasMonkey
</p>
</div>
</dd>
<dt><a name="item310">[310]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04077" title="Abstract">arXiv:2311.04077</a> [<a href="/pdf/2311.04077" title="Download PDF">pdf</a>, <a href="/format/2311.04077" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deep Neural Network based Optimal Control of Greenhouses
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Sathyanarayanan%2C+K+K">Kiran Kumar Sathyanarayanan</a>, 
<a href="/search/eess?searchtype=author&query=Sauerteig%2C+P">Philipp Sauerteig</a>, 
<a href="/search/eess?searchtype=author&query=Streif%2C+S">Stefan Streif</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">Automatic control of greenhouse crop production is of great interest owing to
the increasing energy and labor costs. Hierarchical Model Predictive Control
(HMPC) is a multi-level control strategy for regulating environmental
conditions in a greenhouse through energy-efficient operation and resource
utilization. We suggest in this work to use two-level HMPC, where the upper
level generates suitable reference trajectories based on day-ahead predictions.
These references are tracked down in the lower level using Nonlinear Model
Predictive Control (NMPC). In order to apply HMPC, a model of the crop dynamics
is essential. However, the complex nature of the underlying model including
discontinuities and nonlinearities results in intractable computational
complexity and long sampling times. In this paper, we propose to use NMPC as a
data generator to learn the tracking control policy using deep neural networks.
Then, the references are tracked using the trained Deep Neural Network (DNN) to
reduce the computational burden. The efficiency of our approach under real-time
disturbances is demonstrated by means of a simulation study.
</p>
</div>
</dd>
<dt><a name="item311">[311]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04078" title="Abstract">arXiv:2311.04078</a> [<a href="/pdf/2311.04078" title="Download PDF">pdf</a>, <a href="/format/2311.04078" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Lightweight and Secure PUF-Based Authentication and Key-exchange  Protocol for IoT Devices
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gupta%2C+C">Chandranshu Gupta</a>, 
<a href="/search/cs?searchtype=author&query=Varshney%2C+G">Gaurav Varshney</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">The Internet of Things (IoT) has improved people's lives by seamlessly
integrating into many facets of modern life and facilitating information
sharing across platforms. Device Authentication and Key exchange are major
challenges for the IoT. High computational resource requirements for
cryptographic primitives and message transmission during Authentication make
the existing methods like PKI and IBE not suitable for these resource
constrained devices. PUF appears to offer a practical and economical security
mechanism in place of typically sophisticated cryptosystems like PKI and IBE.
PUF provides an unclonable and tamper sensitive unique signature based on the
PUF chip by using manufacturing process variability. Therefore, in this study,
we use lightweight bitwise XOR, hash function, and PUF to Authenticate IoT
devices. Despite several studies employing the PUF to authenticate
communication between IoT devices, to the authors' knowledge, existing
solutions require intermediary gateway and internet capabilities by the IoT
device to directly interact with a Server for Authentication and hence, are not
scalable when the IoT device works on different technologies like BLE, Zigbee,
etc. To address the aforementioned issue, we present a system in which the IoT
device does not require a continuous active internet connection to communicate
with the server in order to Authenticate itself. The results of a thorough
security study are validated against adversarial attacks and PUF modeling
attacks. For formal security validation, the AVISPA verification tool is also
used. Performance study recommends this protocol's lightweight characteristics.
The proposed protocol's acceptability and defenses against adversarial assaults
are supported by a prototype developed with ESP32.
</p>
</div>
</dd>
<dt><a name="item312">[312]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04079" title="Abstract">arXiv:2311.04079</a> [<a href="/pdf/2311.04079" title="Download PDF">pdf</a>, <a href="/format/2311.04079" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Augmenting Lane Perception and Topology Understanding with Standard  Definition Navigation Maps
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Luo%2C+K+Z">Katie Z Luo</a>, 
<a href="/search/cs?searchtype=author&query=Weng%2C+X">Xinshuo Weng</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+S">Shuang Wu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jie Li</a>, 
<a href="/search/cs?searchtype=author&query=Weinberger%2C+K+Q">Kilian Q Weinberger</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yue Wang</a>, 
<a href="/search/cs?searchtype=author&query=Pavone%2C+M">Marco Pavone</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Autonomous driving has traditionally relied heavily on costly and
labor-intensive High Definition (HD) maps, hindering scalability. In contrast,
Standard Definition (SD) maps are more affordable and have worldwide coverage,
offering a scalable alternative. In this work, we systematically explore the
effect of SD maps for real-time lane-topology understanding. We propose a novel
framework to integrate SD maps into online map prediction and propose a
Transformer-based encoder, SD Map Encoder Representations from transFormers, to
leverage priors in SD maps for the lane-topology prediction task. This
enhancement consistently and significantly boosts (by up to 60%) lane detection
and topology prediction on current state-of-the-art online map prediction
methods without bells and whistles and can be immediately incorporated into any
Transformer-based lane-topology method. Code is available at
https://github.com/NVlabs/SMERF.
</p>
</div>
</dd>
<dt><a name="item313">[313]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04082" title="Abstract">arXiv:2311.04082</a> [<a href="/pdf/2311.04082" title="Download PDF">pdf</a>, <a href="/format/2311.04082" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Time-Efficient Reinforcement Learning with Stochastic Stateful Policies
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Al-Hafez%2C+F">Firas Al-Hafez</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+G">Guoping Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Peters%2C+J">Jan Peters</a>, 
<a href="/search/cs?searchtype=author&query=Tateo%2C+D">Davide Tateo</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Stateful policies play an important role in reinforcement learning, such as
handling partially observable environments, enhancing robustness, or imposing
an inductive bias directly into the policy structure. The conventional method
for training stateful policies is Backpropagation Through Time (BPTT), which
comes with significant drawbacks, such as slow training due to sequential
gradient propagation and the occurrence of vanishing or exploding gradients.
The gradient is often truncated to address these issues, resulting in a biased
policy update. We present a novel approach for training stateful policies by
decomposing the latter into a stochastic internal state kernel and a stateless
policy, jointly optimized by following the stateful policy gradient. We
introduce different versions of the stateful policy gradient theorem, enabling
us to easily instantiate stateful variants of popular reinforcement learning
and imitation learning algorithms. Furthermore, we provide a theoretical
analysis of our new gradient estimator and compare it with BPTT. We evaluate
our approach on complex continuous control tasks, e.g., humanoid locomotion,
and demonstrate that our gradient estimator scales effectively with task
complexity while offering a faster and simpler alternative to BPTT.
</p>
</div>
</dd>
<dt><a name="item314">[314]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04083" title="Abstract">arXiv:2311.04083</a> [<a href="/pdf/2311.04083" title="Download PDF">pdf</a>, <a href="/ps/2311.04083" title="Download PostScript">ps</a>, <a href="/format/2311.04083" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Formulating and Heuristic Solving of Contact Problems in Hybrid  Data-Driven Computational Mechanics
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Gebhardt%2C+C+G">Cristian Guillermo Gebhardt</a>, 
<a href="/search/math?searchtype=author&query=Lange%2C+S">Senta Lange</a>, 
<a href="/search/math?searchtype=author&query=Steinbach%2C+M+C">Marc Christian Steinbach</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 23 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">In this work we consider the hybrid Data-Driven Computational Mechanics
(DDCM) approach, in which a smooth constitutive manifold is reconstructed to
obtain a well-behaved nonlinear optimization problem (NLP) rather than the much
harder discrete-continous NLP (DCNLP) of the direct DDCM approach. The key
focus is on the addition of geometric inequality constraints to the hybrid DDCM
formulation. Therein, the required constraint force leads to a contact problem
in the form of a mathematical program with complementarity constraints (MPCC),
a problem class that is still less complex than the DCNLP. For this MPCC we
propose a heuristic quick-shot solution approach, which can produce verifiable
solutions by solving up to four NLPs. We perform various numerical experiments
on three different contact problems of increasing difficulty to demonstrate the
potential and limitations of this approach.
</p>
</div>
</dd>
<dt><a name="item315">[315]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04085" title="Abstract">arXiv:2311.04085</a> [<a href="/pdf/2311.04085" title="Download PDF">pdf</a>, <a href="/format/2311.04085" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Categorical Model for Retrosynthetic Reaction Analysis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gale%2C+E">Ella Gale</a>, 
<a href="/search/cs?searchtype=author&query=Lobski%2C+L">Leo Lobski</a>, 
<a href="/search/cs?searchtype=author&query=Zanasi%2C+F">Fabio Zanasi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 22 pages, 3 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>; Category Theory (math.CT)

</div>
<p class="mathjax">We introduce a mathematical framework for retrosynthetic analysis, an
important research method in synthetic chemistry. Our approach represents
molecules and their interaction using string diagrams in layered props - a
recently introduced categorical model for partial explanations in scientific
reasoning. Such principled approach allows one to model features currently not
available in automated retrosynthesis tools, such as chirality, reaction
environment and protection-deprotection steps.
</p>
</div>
</dd>
<dt><a name="item316">[316]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04088" title="Abstract">arXiv:2311.04088</a> [<a href="/pdf/2311.04088" title="Download PDF">pdf</a>, <a href="/format/2311.04088" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Personality Style Recognition via Machine Learning: Identifying  Anaclitic and Introjective Personality Styles from Patients&#x27; Speech
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bitew%2C+S+K">Semere Kiros Bitew</a>, 
<a href="/search/cs?searchtype=author&query=Schelstraete%2C+V">Vincent Schelstraete</a>, 
<a href="/search/cs?searchtype=author&query=Zaporojets%2C+K">Klim Zaporojets</a>, 
<a href="/search/cs?searchtype=author&query=Van+Nieuwenhove%2C+K">Kimberly Van Nieuwenhove</a>, 
<a href="/search/cs?searchtype=author&query=Meganck%2C+R">Reitske Meganck</a>, 
<a href="/search/cs?searchtype=author&query=Develder%2C+C">Chris Develder</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">In disentangling the heterogeneity observed in psychopathology, personality
of the patients is considered crucial. While it has been demonstrated that
personality traits are reflected in the language used by a patient, we
hypothesize that this enables automatic inference of the personality type
directly from speech utterances, potentially more accurately than through a
traditional questionnaire-based approach explicitly designed for personality
classification. To validate this hypothesis, we adopt natural language
processing (NLP) and standard machine learning tools for classification. We
test this on a dataset of recorded clinical diagnostic interviews (CDI) on a
sample of 79 patients diagnosed with major depressive disorder (MDD) -- a
condition for which differentiated treatment based on personality styles has
been advocated -- and classified into anaclitic and introjective personality
styles. We start by analyzing the interviews to see which linguistic features
are associated with each style, in order to gain a better understanding of the
styles. Then, we develop automatic classifiers based on (a) standardized
questionnaire responses; (b) basic text features, i.e., TF-IDF scores of words
and word sequences; (c) more advanced text features, using LIWC (linguistic
inquiry and word count) and context-aware features using BERT (bidirectional
encoder representations from transformers); (d) audio features. We find that
automated classification with language-derived features (i.e., based on LIWC)
significantly outperforms questionnaire-based classification models.
Furthermore, the best performance is achieved by combining LIWC with the
questionnaire features. This suggests that more work should be put into
developing linguistically based automated techniques for characterizing
personality, however questionnaires still to some extent complement such
methods.
</p>
</div>
</dd>
<dt><a name="item317">[317]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04091" title="Abstract">arXiv:2311.04091</a> [<a href="/pdf/2311.04091" title="Download PDF">pdf</a>, <a href="/format/2311.04091" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Proceedings of the 5th International Workshop on Reading Music Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Calvo-Zaragoza%2C+J">Jorge Calvo-Zaragoza</a>, 
<a href="/search/cs?searchtype=author&query=Pacha%2C+A">Alexander Pacha</a>, 
<a href="/search/cs?searchtype=author&query=Shatri%2C+E">Elona Shatri</a> (Eds.)
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Proceedings edited by Jorge Calvo-Zaragoza, Alexander Pacha and Elona Shatri
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Information Retrieval (cs.IR); Machine Learning (cs.LG); Sound (cs.SD); Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">The International Workshop on Reading Music Systems (WoRMS) is a workshop
that tries to connect researchers who develop systems for reading music, such
as in the field of Optical Music Recognition, with other researchers and
practitioners that could benefit from such systems, like librarians or
musicologists. The relevant topics of interest for the workshop include, but
are not limited to: Music reading systems; Optical music recognition; Datasets
and performance evaluation; Image processing on music scores; Writer
identification; Authoring, editing, storing and presentation systems for music
scores; Multi-modal systems; Novel input-methods for music to produce written
music; Web-based Music Information Retrieval services; Applications and
projects; Use-cases related to written music.
<br />These are the proceedings of the 5th International Workshop on Reading Music
Systems, held in Milan, Italy on Nov. 4th 2023.
</p>
</div>
</dd>
<dt><a name="item318">[318]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04092" title="Abstract">arXiv:2311.04092</a> [<a href="/pdf/2311.04092" title="Download PDF">pdf</a>, <a href="/format/2311.04092" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Solvable Polynomial Ideals: The Ideal Reflection for Program Analysis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cyphert%2C+J">John Cyphert</a>, 
<a href="/search/cs?searchtype=author&query=Kincaid%2C+Z">Zachary Kincaid</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Programming Languages (cs.PL)</span>

</div>
<p class="mathjax">This paper presents a program analysis method that generates program
summaries involving polynomial arithmetic. Our approach builds on prior
techniques that use solvable polynomial maps for summarizing loops. These
techniques are able to generate all polynomial invariants for a restricted
class of programs, but cannot be applied to programs outside of this class --
for instance, programs with nested loops, conditional branching, unstructured
control flow, etc. There currently lacks approaches to apply these prior
methods to the case of general programs. This paper bridges that gap. Instead
of restricting the kinds of programs we can handle, our method abstracts every
loop into a model that can be solved with prior techniques, bringing to bear
prior work on solvable polynomial maps to general programs. While no method can
generate all polynomial invariants for arbitrary programs, our method
establishes its merit through a monotonicty result. We have implemented our
techniques, and tested them on a suite of benchmarks from the literature. Our
experiments indicate our techniques show promise on challenging verification
tasks requiring non-linear reasoning.
</p>
</div>
</dd>
<dt><a name="item319">[319]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04095" title="Abstract">arXiv:2311.04095</a> [<a href="/pdf/2311.04095" title="Download PDF">pdf</a>, <a href="/format/2311.04095" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Image-Pointcloud Fusion based Anomaly Detection using PD-REAL Dataset
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Qin%2C+J">Jianjian Qin</a>, 
<a href="/search/cs?searchtype=author&query=Gu%2C+C">Chunzhi Gu</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+J">Jun Yu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+C">Chao Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">We present PD-REAL, a novel large-scale dataset for unsupervised anomaly
detection (AD) in the 3D domain. It is motivated by the fact that 2D-only
representations in the AD task may fail to capture the geometric structures of
anomalies due to uncertainty in lighting conditions or shooting angles. PD-REAL
consists entirely of Play-Doh models for 15 object categories and focuses on
the analysis of potential benefits from 3D information in a controlled
environment. Specifically, objects are first created with six types of
anomalies, such as dent, crack, or perforation, and then photographed under
different lighting conditions to mimic real-world inspection scenarios. To
demonstrate the usefulness of 3D information, we use a commercially available
RealSense camera to capture RGB and depth images. Compared to the existing 3D
dataset for AD tasks, the data acquisition of PD-REAL is significantly cheaper,
easily scalable and easier to control variables. Extensive evaluations with
state-of-the-art AD algorithms on our dataset demonstrate the benefits as well
as challenges of using 3D information. Our dataset can be downloaded from
https://github.com/Andy-cs008/PD-REAL
</p>
</div>
</dd>
<dt><a name="item320">[320]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04096" title="Abstract">arXiv:2311.04096</a> [<a href="/pdf/2311.04096" title="Download PDF">pdf</a>, <a href="/format/2311.04096" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Imitation learning for sim-to-real transfer of robotic cutting policies  based on residual Gaussian process disturbance force model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hathaway%2C+J">Jamie Hathaway</a>, 
<a href="/search/cs?searchtype=author&query=Stolkin%2C+R">Rustam Stolkin</a>, 
<a href="/search/cs?searchtype=author&query=Rastegarpanah%2C+A">Alireza Rastegarpanah</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 9 figures, submitted to IEEE Robotics and Automation Letters (RA-L)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Robotic cutting, or milling, plays a significant role in applications such as
disassembly, decommissioning, and demolition. Planning and control of cutting
in real-world scenarios in uncertain environments is a complex task, with the
potential to benefit from simulated training environments. This letter focuses
on sim-to-real transfer for robotic cutting policies, addressing the need for
effective policy transfer from simulation to practical implementation. We
extend our previous domain generalisation approach to learning cutting tasks
based on a mechanistic model-based simulation framework, by proposing a hybrid
approach for sim-to-real transfer based on a milling process force model and
residual Gaussian process (GP) force model, learned from either single or
multiple real-world cutting force examples. We demonstrate successful
sim-to-real transfer of a robotic cutting policy without the need for
fine-tuning on the real robot setup. The proposed approach autonomously adapts
to materials with differing structural and mechanical properties. Furthermore,
we demonstrate the proposed method outperforms fine-tuning or re-training
alone.
</p>
</div>
</dd>
<dt><a name="item321">[321]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04098" title="Abstract">arXiv:2311.04098</a> [<a href="/pdf/2311.04098" title="Download PDF">pdf</a>, <a href="/format/2311.04098" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DeepPatent2: A Large-Scale Benchmarking Corpus for Technical Drawing  Understanding
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ajayi%2C+K">Kehinde Ajayi</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+X">Xin Wei</a>, 
<a href="/search/cs?searchtype=author&query=Gryder%2C+M">Martin Gryder</a>, 
<a href="/search/cs?searchtype=author&query=Shields%2C+W">Winston Shields</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+J">Jian Wu</a>, 
<a href="/search/cs?searchtype=author&query=Jones%2C+S+M">Shawn M. Jones</a>, 
<a href="/search/cs?searchtype=author&query=Kucer%2C+M">Michal Kucer</a>, 
<a href="/search/cs?searchtype=author&query=Oyen%2C+D">Diane Oyen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Recent advances in computer vision (CV) and natural language processing have
been driven by exploiting big data on practical applications. However, these
research fields are still limited by the sheer volume, versatility, and
diversity of the available datasets. CV tasks, such as image captioning, which
has primarily been carried out on natural images, still struggle to produce
accurate and meaningful captions on sketched images often included in
scientific and technical documents. The advancement of other tasks such as 3D
reconstruction from 2D images requires larger datasets with multiple
viewpoints. We introduce DeepPatent2, a large-scale dataset, providing more
than 2.7 million technical drawings with 132,890 object names and 22,394
viewpoints extracted from 14 years of US design patent documents. We
demonstrate the usefulness of DeepPatent2 with conceptual captioning. We
further provide the potential usefulness of our dataset to facilitate other
research areas such as 3D image reconstruction and image retrieval.
</p>
</div>
</dd>
<dt><a name="item322">[322]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04107" title="Abstract">arXiv:2311.04107</a> [<a href="/pdf/2311.04107" title="Download PDF">pdf</a>, <a href="/format/2311.04107" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Interactive Semantic Map Representation for Skill-based Visual Object  Navigation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zemskova%2C+T">Tatiana Zemskova</a>, 
<a href="/search/cs?searchtype=author&query=Staroverov%2C+A">Aleksei Staroverov</a>, 
<a href="/search/cs?searchtype=author&query=Muravyev%2C+K">Kirill Muravyev</a>, 
<a href="/search/cs?searchtype=author&query=Yudin%2C+D">Dmitry Yudin</a>, 
<a href="/search/cs?searchtype=author&query=Panov%2C+A">Aleksandr Panov</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Visual object navigation using learning methods is one of the key tasks in
mobile robotics. This paper introduces a new representation of a scene semantic
map formed during the embodied agent interaction with the indoor environment.
It is based on a neural network method that adjusts the weights of the
segmentation model with backpropagation of the predicted fusion loss values
during inference on a regular (backward) or delayed (forward) image sequence.
We have implemented this representation into a full-fledged navigation approach
called SkillTron, which can select robot skills from end-to-end policies based
on reinforcement learning and classic map-based planning methods. The proposed
approach makes it possible to form both intermediate goals for robot
exploration and the final goal for object navigation. We conducted intensive
experiments with the proposed approach in the Habitat environment, which showed
a significant superiority in navigation quality metrics compared to
state-of-the-art approaches. The developed code and used custom datasets are
publicly available at github.com/AIRI-Institute/skill-fusion.
</p>
</div>
</dd>
<dt><a name="item323">[323]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04108" title="Abstract">arXiv:2311.04108</a> [<a href="/pdf/2311.04108" title="Download PDF">pdf</a>, <a href="/format/2311.04108" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Early Microbenchmark Catches the Bug -- Studying Performance Issues  Using Micro- and Application Benchmarks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Japke%2C+N">Nils Japke</a>, 
<a href="/search/cs?searchtype=author&query=Witzko%2C+C">Christoph Witzko</a>, 
<a href="/search/cs?searchtype=author&query=Grambow%2C+M">Martin Grambow</a>, 
<a href="/search/cs?searchtype=author&query=Bermbach%2C+D">David Bermbach</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted for publication in 2023 IEEE/ACM 16th International Conference on Utility and Cloud Computing
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>

</div>
<p class="mathjax">An application's performance regressions can be detected by both application
or microbenchmarks. While application benchmarks stress the system under test
by sending synthetic but realistic requests which, e.g., simulate real user
traffic, microbenchmarks evaluate the performance on a subroutine level by
calling the function under test repeatedly.
<br />In this paper, we use a testbed microservice application which includes three
performance issues to study the detection capabilities of both approaches. In
extensive benchmarking experiments, we increase the severity of each
performance issue stepwise, run both an application benchmark and the
microbenchmark suite, and check at which point each benchmark detects the
performance issue. Our results show that microbenchmarks detect all three
issues earlier, some even at the lowest severity level. Application benchmarks,
however, raised false positive alarms, wrongly detected performance
improvements, and detected the performance issues later.
</p>
</div>
</dd>
<dt><a name="item324">[324]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04109" title="Abstract">arXiv:2311.04109</a> [<a href="/pdf/2311.04109" title="Download PDF">pdf</a>, <a href="/format/2311.04109" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Do Language Models Learn Semantics of Code? A Case Study in  Vulnerability Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Steenhoek%2C+B">Benjamin Steenhoek</a>, 
<a href="/search/cs?searchtype=author&query=Rahman%2C+M+M">Md Mahbubur Rahman</a>, 
<a href="/search/cs?searchtype=author&query=Sharmin%2C+S">Shaila Sharmin</a>, 
<a href="/search/cs?searchtype=author&query=Le%2C+W">Wei Le</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Cryptography and Security (cs.CR)

</div>
<p class="mathjax">Recently, pretrained language models have shown state-of-the-art performance
on the vulnerability detection task. These models are pretrained on a large
corpus of source code, then fine-tuned on a smaller supervised vulnerability
dataset. Due to the different training objectives and the performance of the
models, it is interesting to consider whether the models have learned the
semantics of code relevant to vulnerability detection, namely bug semantics,
and if so, how the alignment to bug semantics relates to model performance. In
this paper, we analyze the models using three distinct methods:
interpretability tools, attention analysis, and interaction matrix analysis. We
compare the models' influential feature sets with the bug semantic features
which define the causes of bugs, including buggy paths and Potentially
Vulnerable Statements (PVS). We find that (1) better-performing models also
aligned better with PVS, (2) the models failed to align strongly to PVS, and
(3) the models failed to align at all to buggy paths. Based on our analysis, we
developed two annotation methods which highlight the bug semantics inside the
model's inputs. We evaluated our approach on four distinct transformer models
and four vulnerability datasets and found that our annotations improved the
models' performance in the majority of settings - 11 out of 16, with up to 9.57
points improvement in F1 score compared to conventional fine-tuning. We further
found that with our annotations, the models aligned up to 232% better to
potentially vulnerable statements. Our findings indicate that it is helpful to
provide the model with information of the bug semantics, that the model can
attend to it, and motivate future work in learning more complex path-based bug
semantics. Our code and data are available at
https://figshare.com/s/4a16a528d6874aad51a0.
</p>
</div>
</dd>
<dt><a name="item325">[325]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04124" title="Abstract">arXiv:2311.04124</a> [<a href="/pdf/2311.04124" title="Download PDF">pdf</a>, <a href="/format/2311.04124" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Unveiling Safety Vulnerabilities of Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kour%2C+G">George Kour</a>, 
<a href="/search/cs?searchtype=author&query=Zalmanovici%2C+M">Marcel Zalmanovici</a>, 
<a href="/search/cs?searchtype=author&query=Zwerdling%2C+N">Naama Zwerdling</a>, 
<a href="/search/cs?searchtype=author&query=Goldbraich%2C+E">Esther Goldbraich</a>, 
<a href="/search/cs?searchtype=author&query=Fandina%2C+O+N">Ora Nova Fandina</a>, 
<a href="/search/cs?searchtype=author&query=Anaby-Tavor%2C+A">Ateret Anaby-Tavor</a>, 
<a href="/search/cs?searchtype=author&query=Raz%2C+O">Orna Raz</a>, 
<a href="/search/cs?searchtype=author&query=Farchi%2C+E">Eitan Farchi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To be published in GEM workshop. Conference on Empirical Methods in Natural Language Processing (EMNLP). 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">As large language models become more prevalent, their possible harmful or
inappropriate responses are a cause for concern. This paper introduces a unique
dataset containing adversarial examples in the form of questions, which we call
AttaQ, designed to provoke such harmful or inappropriate responses. We assess
the efficacy of our dataset by analyzing the vulnerabilities of various models
when subjected to it. Additionally, we introduce a novel automatic approach for
identifying and naming vulnerable semantic regions - input semantic areas for
which the model is likely to produce harmful outputs. This is achieved through
the application of specialized clustering techniques that consider both the
semantic similarity of the input attacks and the harmfulness of the model's
responses. Automatically identifying vulnerable semantic regions enhances the
evaluation of model weaknesses, facilitating targeted improvements to its
safety mechanisms and overall reliability.
</p>
</div>
</dd>
<dt><a name="item326">[326]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04126" title="Abstract">arXiv:2311.04126</a> [<a href="/pdf/2311.04126" title="Download PDF">pdf</a>, <a href="/ps/2311.04126" title="Download PostScript">ps</a>, <a href="/format/2311.04126" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> From Diagram to Deployment: Translating BPMN Collaborations into X-Klaim  for Efficient Multi-Robot System Programming
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bourr%2C+K">Khalid Bourr</a>, 
<a href="/search/cs?searchtype=author&query=Tiezzi%2C+F">Francesco Tiezzi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Software Engineering (cs.SE)

</div>
<p class="mathjax">This paper introduces a novel method for translating Business Process Model
and Notation (BPMN) diagrams into executable X-Klaim code for Multi-Robot
Systems (MRSs). Merging the clarity of BPMN with the operational strength of
X-Klaim, we enable the design and execution of complex robotic interactions
without requiring in-depth knowledge of the underlying programming language
from the users. Our approach maintains the BPMN model's core design principles
and logic in the translation to X-Klaim, thus enhancing the readability and
maintainability of MRS applications. We offer a series of translated examples,
address optimization strategies, and introduce the B2XKLAIM tool, which
automates the conversion process. This method aims to streamline MRS
programming and improve collaboration between roboticists and domain experts
throughout the design and implementation stages.
</p>
</div>
</dd>
<dt><a name="item327">[327]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04128" title="Abstract">arXiv:2311.04128</a> [<a href="/pdf/2311.04128" title="Download PDF">pdf</a>, <a href="/format/2311.04128" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Generative learning for nonlinear dynamics
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gilpin%2C+W">William Gilpin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 23 pages, 4 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Chaotic Dynamics (nlin.CD); Computational Physics (physics.comp-ph)

</div>
<p class="mathjax">Modern generative machine learning models demonstrate surprising ability to
create realistic outputs far beyond their training data, such as photorealistic
artwork, accurate protein structures, or conversational text. These successes
suggest that generative models learn to effectively parametrize and sample
arbitrarily complex distributions. Beginning half a century ago, foundational
works in nonlinear dynamics used tools from information theory to infer
properties of chaotic attractors from time series, motivating the development
of algorithms for parametrizing chaos in real datasets. In this perspective, we
aim to connect these classical works to emerging themes in large-scale
generative statistical learning. We first consider classical attractor
reconstruction, which mirrors constraints on latent representations learned by
state space models of time series. We next revisit early efforts to use
symbolic approximations to compare minimal discrete generators underlying
complex processes, a problem relevant to modern efforts to distill and
interpret black-box statistical models. Emerging interdisciplinary works bridge
nonlinear dynamics and learning theory, such as operator-theoretic methods for
complex fluid flows, or detection of broken detailed balance in biological
datasets. We anticipate that future machine learning techniques may revisit
other classical concepts from nonlinear dynamics, such as transinformation
decay and complexity-entropy tradeoffs.
</p>
</div>
</dd>
<dt><a name="item328">[328]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04131" title="Abstract">arXiv:2311.04131</a> [<a href="/pdf/2311.04131" title="Download PDF">pdf</a>, <a href="/format/2311.04131" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Locating Cross-Task Sequence Continuation Circuits in Transformers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lan%2C+M">Michael Lan</a>, 
<a href="/search/cs?searchtype=author&query=Barez%2C+F">Fazl Barez</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">While transformer models exhibit strong capabilities on linguistic tasks,
their complex architectures make them difficult to interpret. Recent work has
aimed to reverse engineer transformer models into human-readable
representations called circuits that implement algorithmic functions. We extend
this research by analyzing and comparing circuits for similar sequence
continuation tasks, which include increasing sequences of digits, number words,
and months. Through the application of circuit analysis techniques, we identify
key sub-circuits responsible for detecting sequence members and for predicting
the next member in a sequence. Our analysis reveals that semantically related
sequences rely on shared circuit subgraphs with analogous roles. Overall,
documenting shared computational structures enables better prediction of model
behaviors, identification of errors, and safer editing procedures. This
mechanistic understanding of transformers is a critical step towards building
more robust, aligned, and interpretable language models.
</p>
</div>
</dd>
<dt><a name="item329">[329]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04133" title="Abstract">arXiv:2311.04133</a> [<a href="/pdf/2311.04133" title="Download PDF">pdf</a>, <a href="/format/2311.04133" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Simple Bundles of Complex Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Benatti%2C+A">Alexandre Benatti</a>, 
<a href="/search/cs?searchtype=author&query=da+F.+Costa%2C+L">Luciano da F. Costa</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 29 pages, 21 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>

</div>
<p class="mathjax">Complex networks can be used to represent and model an ample diversity of
abstract and real-world systems and structures. A good deal of the research on
these structures has focused on specific topological properties, including node
degree, shortest paths, and modularity. In the present work, we develop an
approach aimed at identifying and characterizing simple bundles of
interconnections between pairs of nodes (source and destination) in complex
networks. More specifically, simple bundles can be understood as corresponding
to the bundle of paths obtained while traveling through successive
neighborhoods after departing from a given source node. Because no node appears
more than once along a given bundle, these structures have been said to be
simple, in analogy to the concept of a simple path. In addition to describing
simple bundles and providing a possible methodology for their identification,
we also consider how their respective effective width can be estimated in terms
of diffusion flow and exponential entropy of transition probabilities. The
potential of the concepts and methods described in this work is then
illustrated respectively to the characterization and analysis of
model-theoretic networks, with several interesting results.
</p>
</div>
</dd>
<dt><a name="item330">[330]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04139" title="Abstract">arXiv:2311.04139</a> [<a href="/pdf/2311.04139" title="Download PDF">pdf</a>, <a href="/ps/2311.04139" title="Download PostScript">ps</a>, <a href="/format/2311.04139" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Modelling Sentiment Analysis: LLMs and data augmentation techniques
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Prades%2C+G+S">Guillem Senabre Prades</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 4 pages. For more information check the github link in the conclusion. Enjoy!
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">This paper provides different approaches for a binary sentiment
classification on a small training dataset. LLMs that provided state-of-the-art
results in sentiment analysis and similar domains are being used, such as BERT,
RoBERTa and XLNet.
</p>
</div>
</dd>
<dt><a name="item331">[331]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04140" title="Abstract">arXiv:2311.04140</a> [<a href="/pdf/2311.04140" title="Download PDF">pdf</a>, <a href="/format/2311.04140" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Nearly Linear-Time Distributed Algorithm for Exact Maximum Matching
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yamaguchi%2C+T+I+N+K+Y">Taisuke Izumi Naoki Kitamura Yutaro Yamaguchi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>

</div>
<p class="mathjax">In this paper, we propose a randomized $\tilde{O}(\Mmax)$-round algorithm for
the maximum cardinality matching problem in the CONGEST model, where $\Mmax$
means the maximum size of a matching of the input graph $G$. The proposed
algorithm substantially improves the current best worst-case running time. The
key technical ingredient is a new randomized algorithm of finding an augmenting
path of length $\ell$ with high probability within $\tilde{O}(\ell)$ rounds,
which positively settles an open problem left in the prior work by Ahmadi and
Kuhn [DISC'20].
<br />The idea of our augmenting path algorithm is based on a recent result by
Kitamura and Izumi [IEICE Trans.'22], which efficiently identifies a sparse
substructure of the input graph containing an augmenting path, following a new
concept called \emph{alternating base trees}. Their algorithm, however, resorts
to a centralized approach of collecting the entire information of the
substructure into a single vertex for constructing an augmenting path. The
technical highlight of this paper is to provide a fully-decentralized
counterpart of such a centralized method. To develop the algorithm, we prove
several new structural properties of alternating base trees, which are of
independent interest.
</p>
</div>
</dd>
<dt><a name="item332">[332]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04142" title="Abstract">arXiv:2311.04142</a> [<a href="/pdf/2311.04142" title="Download PDF">pdf</a>, <a href="/format/2311.04142" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> What is Lost in Knowledge Distillation?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mohanty%2C+M">Manas Mohanty</a>, 
<a href="/search/cs?searchtype=author&query=Roosta%2C+T">Tanya Roosta</a>, 
<a href="/search/cs?searchtype=author&query=Passban%2C+P">Peyman Passban</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at the 3rd workshop on efficient natural language and speech processing (ENLSP, NeurIPS 2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Deep neural networks (DNNs) have improved NLP tasks significantly, but
training and maintaining such networks could be costly. Model compression
techniques, such as, knowledge distillation (KD), have been proposed to address
the issue; however, the compression process could be lossy. Motivated by this,
our work investigates how a distilled student model differs from its teacher,
if the distillation process causes any information losses, and if the loss
follows a specific pattern. Our experiments aim to shed light on the type of
tasks might be less or more sensitive to KD by reporting data points on the
contribution of different factors, such as the number of layers or attention
heads. Results such as ours could be utilized when determining effective and
efficient configurations to achieve optimal information transfers between
larger (teacher) and smaller (student) models.
</p>
</div>
</dd>
<dt><a name="item333">[333]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04144" title="Abstract">arXiv:2311.04144</a> [<a href="/pdf/2311.04144" title="Download PDF">pdf</a>, <a href="/ps/2311.04144" title="Download PostScript">ps</a>, <a href="/format/2311.04144" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A new fast numerical method for the generalized Rosen-Zener model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Bonhomme%2C+C">Christian Bonhomme</a>, 
<a href="/search/math?searchtype=author&query=Pozza%2C+S">Stefano Pozza</a>, 
<a href="/search/math?searchtype=author&query=Van+Buggenhout%2C+N">Niel Van Buggenhout</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">In quantum mechanics, the Rosen-Zener model represents a two-level quantum
system. Its generalization to multiple degenerate sets of states leads to
larger non-autonomous linear system of ordinary differential equations (ODEs).
We propose a new method for computing the solution operator of this system of
ODEs. This new method is based on a recently introduced expression of the
solution in terms of an infinite matrix equation, which can be efficiently
approximated by combining truncation, fixed point iterations, and low-rank
approximation. This expression is possible thanks to the so-called
$\star$-product approach for linear ODEs. In the numerical experiments, the new
method's computing time scales linearly with the model's size. We provide a
first partial explanation of this linear behavior.
</p>
</div>
</dd>
<dt><a name="item334">[334]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04145" title="Abstract">arXiv:2311.04145</a> [<a href="/pdf/2311.04145" title="Download PDF">pdf</a>, <a href="/format/2311.04145" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> I2VGen-XL: High-Quality Image-to-Video Synthesis via Cascaded Diffusion  Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+S">Shiwei Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jiayu Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yingya Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+K">Kang Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+H">Hangjie Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Qin%2C+Z">Zhiwu Qin</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xiang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+D">Deli Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+J">Jingren Zhou</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project page: <a href="https://i2vgen-xl.github.io">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Video synthesis has recently made remarkable strides benefiting from the
rapid development of diffusion models. However, it still encounters challenges
in terms of semantic accuracy, clarity and spatio-temporal continuity. They
primarily arise from the scarcity of well-aligned text-video data and the
complex inherent structure of videos, making it difficult for the model to
simultaneously ensure semantic and qualitative excellence. In this report, we
propose a cascaded I2VGen-XL approach that enhances model performance by
decoupling these two factors and ensures the alignment of the input data by
utilizing static images as a form of crucial guidance. I2VGen-XL consists of
two stages: i) the base stage guarantees coherent semantics and preserves
content from input images by using two hierarchical encoders, and ii) the
refinement stage enhances the video's details by incorporating an additional
brief text and improves the resolution to 1280$\times$720. To improve the
diversity, we collect around 35 million single-shot text-video pairs and 6
billion text-image pairs to optimize the model. By this means, I2VGen-XL can
simultaneously enhance the semantic accuracy, continuity of details and clarity
of generated videos. Through extensive experiments, we have investigated the
underlying principles of I2VGen-XL and compared it with current top methods,
which can demonstrate its effectiveness on diverse data. The source code and
models will be publicly available at \url{https://i2vgen-xl.github.io}.
</p>
</div>
</dd>
<dt><a name="item335">[335]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04147" title="Abstract">arXiv:2311.04147</a> [<a href="/pdf/2311.04147" title="Download PDF">pdf</a>, <a href="/format/2311.04147" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multi-resolution Time-Series Transformer for Long-term Forecasting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yitian Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+L">Liheng Ma</a>, 
<a href="/search/cs?searchtype=author&query=Pal%2C+S">Soumyasundar Pal</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yingxue Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Coates%2C+M">Mark Coates</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">The performance of transformers for time-series forecasting has improved
significantly. Recent architectures learn complex temporal patterns by
segmenting a time-series into patches and using the patches as tokens. The
patch size controls the ability of transformers to learn the temporal patterns
at different frequencies: shorter patches are effective for learning localized,
high-frequency patterns, whereas mining long-term seasonalities and trends
requires longer patches. Inspired by this observation, we propose a novel
framework, Multi-resolution Time-Series Transformer (MTST), which consists of a
multi-branch architecture for simultaneous modeling of diverse temporal
patterns at different resolutions. In contrast to many existing time-series
transformers, we employ relative positional encoding, which is better suited
for extracting periodic components at different scales. Extensive experiments
on several real-world datasets demonstrate the effectiveness of MTST in
comparison to state-of-the-art forecasting techniques.
</p>
</div>
</dd>
<dt><a name="item336">[336]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04148" title="Abstract">arXiv:2311.04148</a> [<a href="/pdf/2311.04148" title="Download PDF">pdf</a>, <a href="/format/2311.04148" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Contactless Fingerprint Biometric Anti-Spoofing: An Unsupervised Deep  Learning Approach
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Adami%2C+B">Banafsheh Adami</a>, 
<a href="/search/cs?searchtype=author&query=Karimian%2C+N">Nima Karimian</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Cryptography and Security (cs.CR); Machine Learning (cs.LG)

</div>
<p class="mathjax">Contactless fingerprint recognition offers a higher level of user comfort and
addresses hygiene concerns more effectively. However, it is also more
vulnerable to presentation attacks such as photo paper, paper-printout, and
various display attacks, which makes it more challenging to implement in
biometric systems compared to contact-based modalities. Limited research has
been conducted on presentation attacks in contactless fingerprint systems, and
these studies have encountered challenges in terms of generalization and
scalability since both bonafide samples and presentation attacks are utilized
during training model. Although this approach appears promising, it lacks the
ability to handle unseen attacks, which is a crucial factor for developing PAD
methods that can generalize effectively. We introduced an innovative
anti-spoofing approach that combines an unsupervised autoencoder with a
convolutional block attention module to address the limitations of existing
methods. Our model is exclusively trained on bonafide images without exposure
to any spoofed samples during the training phase. It is then evaluated against
various types of presentation attack images in the testing phase. The scheme we
proposed has achieved an average BPCER of 0.96\% with an APCER of 1.6\% for
presentation attacks involving various types of spoofed samples.
</p>
</div>
</dd>
<dt><a name="item337">[337]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04149" title="Abstract">arXiv:2311.04149</a> [<a href="/pdf/2311.04149" title="Download PDF">pdf</a>, <a href="/format/2311.04149" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> HyperS2V: A Framework for Structural Representation of Nodes in Hyper  Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+S">Shu Liu</a>, 
<a href="/search/cs?searchtype=author&query=Lai%2C+C">Cameron Lai</a>, 
<a href="/search/cs?searchtype=author&query=Toriumi%2C+F">Fujio Toriumi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">In contrast to regular (simple) networks, hyper networks possess the ability
to depict more complex relationships among nodes and store extensive
information. Such networks are commonly found in real-world applications, such
as in social interactions. Learning embedded representations for nodes involves
a process that translates network structures into more simplified spaces,
thereby enabling the application of machine learning approaches designed for
vector data to be extended to network data. Nevertheless, there remains a need
to delve into methods for learning embedded representations that prioritize
structural aspects. This research introduces HyperS2V, a node embedding
approach that centers on the structural similarity within hyper networks.
Initially, we establish the concept of hyper-degrees to capture the structural
properties of nodes within hyper networks. Subsequently, a novel function is
formulated to measure the structural similarity between different hyper-degree
values. Lastly, we generate structural embeddings utilizing a multi-scale
random walk framework. Moreover, a series of experiments, both intrinsic and
extrinsic, are performed on both toy and real networks. The results underscore
the superior performance of HyperS2V in terms of both interpretability and
applicability to downstream tasks.
</p>
</div>
</dd>
<dt><a name="item338">[338]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04150" title="Abstract">arXiv:2311.04150</a> [<a href="/pdf/2311.04150" title="Download PDF">pdf</a>, <a href="/format/2311.04150" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> What Makes a Fantastic Passenger-Car Driver in Urban Contexts?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yu%2C+Y">Yueteng Yu</a>, 
<a href="/search/cs?searchtype=author&query=Yi%2C+Z">Zhijie Yi</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+X">Xinyu Yang</a>, 
<a href="/search/cs?searchtype=author&query=Chu%2C+M">Mengdi Chu</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+J">Junrong Lu</a>, 
<a href="/search/cs?searchtype=author&query=Chang%2C+X">Xiang Chang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yiyao Liu</a>, 
<a href="/search/cs?searchtype=author&query=Qin%2C+J">Jingli Qin</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+Y">Ye Jin</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+J">Jialin Song</a>, 
<a href="/search/cs?searchtype=author&query=Gu%2C+X">Xingrui Gu</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+J">Jirui Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+G">Guyue Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Gong%2C+J">Jiangtao Gong</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">The accurate evaluation of the quality of driving behavior is crucial for
optimizing and implementing autonomous driving technology in practice. However,
there is no comprehensive understanding of good driving behaviors currently. In
this paper, we sought to understand driving behaviors from the perspectives of
both drivers and passengers. We invited 10 expert drivers and 14 novice drivers
to complete a 5.7-kilometer urban road driving task. After the experiments, we
conducted semi-structured interviews with 24 drivers and 48 of their passengers
(two passengers per driver). Through the analysis of interview data, we found
passengers' assessing logic of driving behaviors, divers' considerations and
efforts to achieve good driving, and gaps between these perspectives. Our
research provided insights into a systematic evaluation of autonomous driving
and the design implications for future autonomous vehicles.
</p>
</div>
</dd>
<dt><a name="item339">[339]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04154" title="Abstract">arXiv:2311.04154</a> [<a href="/pdf/2311.04154" title="Download PDF">pdf</a>, <a href="/format/2311.04154" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> High-fidelity 3D Reconstruction of Plants using Neural Radiance Field
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hu%2C+K">Kewei Hu</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+Y">Ying Wei</a>, 
<a href="/search/cs?searchtype=author&query=Pan%2C+Y">Yaoqiang Pan</a>, 
<a href="/search/cs?searchtype=author&query=Kang%2C+H">Hanwen Kang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+C">Chao Chen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Robotics (cs.RO)

</div>
<p class="mathjax">Accurate reconstruction of plant phenotypes plays a key role in optimising
sustainable farming practices in the field of Precision Agriculture (PA).
Currently, optical sensor-based approaches dominate the field, but the need for
high-fidelity 3D reconstruction of crops and plants in unstructured
agricultural environments remains challenging. Recently, a promising
development has emerged in the form of Neural Radiance Field (NeRF), a novel
method that utilises neural density fields. This technique has shown impressive
performance in various novel vision synthesis tasks, but has remained
relatively unexplored in the agricultural context. In our study, we focus on
two fundamental tasks within plant phenotyping: (1) the synthesis of 2D
novel-view images and (2) the 3D reconstruction of crop and plant models. We
explore the world of neural radiance fields, in particular two SOTA methods:
Instant-NGP, which excels in generating high-quality images with impressive
training and inference speed, and Instant-NSR, which improves the reconstructed
geometry by incorporating the Signed Distance Function (SDF) during training.
In particular, we present a novel plant phenotype dataset comprising real plant
images from production environments. This dataset is a first-of-its-kind
initiative aimed at comprehensively exploring the advantages and limitations of
NeRF in agricultural contexts. Our experimental results show that NeRF
demonstrates commendable performance in the synthesis of novel-view images and
is able to achieve reconstruction results that are competitive with Reality
Capture, a leading commercial software for 3D Multi-View Stereo (MVS)-based
reconstruction. However, our study also highlights certain drawbacks of NeRF,
including relatively slow training speeds, performance limitations in cases of
insufficient sampling, and challenges in obtaining geometry quality in complex
setups.
</p>
</div>
</dd>
<dt><a name="item340">[340]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04155" title="Abstract">arXiv:2311.04155</a> [<a href="/pdf/2311.04155" title="Download PDF">pdf</a>, <a href="/format/2311.04155" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Black-Box Prompt Optimization: Aligning Large Language Models without  Model Training
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cheng%2C+J">Jiale Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xiao Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+K">Kehan Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Ke%2C+P">Pei Ke</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Hongning Wang</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+Y">Yuxiao Dong</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+J">Jie Tang</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+M">Minlie Huang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> work in progress
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Large language models (LLMs) have shown impressive success in various
applications. However, these models are often not well aligned with human
intents, which calls for additional treatments on them, that is, the alignment
problem. To make LLMs better follow user instructions, existing alignment
methods mostly focus on further training them. However, the extra training of
LLMs are usually expensive in terms of GPU compute; worse still, LLMs of
interest are oftentimes not accessible for user-demanded training, such as
GPTs. In this work, we take a different perspective -- Black-Box Prompt
Optimization (BPO) -- to perform alignments. The idea is to optimize user
prompts to suit LLMs' input understanding, so as to best realize users' intents
without updating LLMs' parameters. BPO is model-agnostic and the empirical
results demonstrate that the BPO-aligned ChatGPT yields a 22\% increase in the
win rate against its original version, and 10\% for GPT-4. Importantly, the
\model-aligned LLMs can outperform the same models aligned by PPO and DPO, and
it also brings additional performance gains when combining \model with PPO or
DPO. Code and datasets are released at https://github.com/thu-coai/BPO.
</p>
</div>
</dd>
<dt><a name="item341">[341]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04157" title="Abstract">arXiv:2311.04157</a> [<a href="/pdf/2311.04157" title="Download PDF">pdf</a>, <a href="/format/2311.04157" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Simple Interpretable Transformer for Fine-Grained Image Classification  and Analysis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Paul%2C+D">Dipanjyoti Paul</a>, 
<a href="/search/cs?searchtype=author&query=Chowdhury%2C+A">Arpita Chowdhury</a>, 
<a href="/search/cs?searchtype=author&query=Xiong%2C+X">Xinqi Xiong</a>, 
<a href="/search/cs?searchtype=author&query=Chang%2C+F">Feng-Ju Chang</a>, 
<a href="/search/cs?searchtype=author&query=Carlyn%2C+D">David Carlyn</a>, 
<a href="/search/cs?searchtype=author&query=Stevens%2C+S">Samuel Stevens</a>, 
<a href="/search/cs?searchtype=author&query=Provost%2C+K">Kaiya Provost</a>, 
<a href="/search/cs?searchtype=author&query=Karpatne%2C+A">Anuj Karpatne</a>, 
<a href="/search/cs?searchtype=author&query=Carstens%2C+B">Bryan Carstens</a>, 
<a href="/search/cs?searchtype=author&query=Rubenstein%2C+D">Daniel Rubenstein</a>, 
<a href="/search/cs?searchtype=author&query=Stewart%2C+C">Charles Stewart</a>, 
<a href="/search/cs?searchtype=author&query=Berger-Wolf%2C+T">Tanya Berger-Wolf</a>, 
<a href="/search/cs?searchtype=author&query=Su%2C+Y">Yu Su</a>, 
<a href="/search/cs?searchtype=author&query=Chao%2C+W">Wei-Lun Chao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">We present a novel usage of Transformers to make image classification
interpretable. Unlike mainstream classifiers that wait until the last
fully-connected layer to incorporate class information to make predictions, we
investigate a proactive approach, asking each class to search for itself in an
image. We realize this idea via a Transformer encoder-decoder inspired by
DEtection TRansformer (DETR). We learn ``class-specific'' queries (one for each
class) as input to the decoder, enabling each class to localize its patterns in
an image via cross-attention. We name our approach INterpretable TRansformer
(INTR), which is fairly easy to implement and exhibits several compelling
properties. We show that INTR intrinsically encourages each class to attend
distinctively; the cross-attention weights thus provide a faithful
interpretation of the prediction. Interestingly, via ``multi-head''
cross-attention, INTR could identify different ``attributes'' of a class,
making it particularly suitable for fine-grained classification and analysis,
which we demonstrate on eight datasets. Our code and pre-trained model are
publicly accessible at https://github.com/Imageomics/INTR.
</p>
</div>
</dd>
<dt><a name="item342">[342]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04158" title="Abstract">arXiv:2311.04158</a> [<a href="/pdf/2311.04158" title="Download PDF">pdf</a>, <a href="/format/2311.04158" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Computing Approximate $\ell_p$ Sensitivities
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Padmanabhan%2C+S">Swati Padmanabhan</a>, 
<a href="/search/cs?searchtype=author&query=Woodruff%2C+D+P">David P. Woodruff</a>, 
<a href="/search/cs?searchtype=author&query=Qiuyi">Qiuyi</a> (Richard)
<a href="/search/cs?searchtype=author&query=Zhang">Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Data Structures and Algorithms (cs.DS); Machine Learning (stat.ML)

</div>
<p class="mathjax">Recent works in dimensionality reduction for regression tasks have introduced
the notion of sensitivity, an estimate of the importance of a specific
datapoint in a dataset, offering provable guarantees on the quality of the
approximation after removing low-sensitivity datapoints via subsampling.
However, fast algorithms for approximating $\ell_p$ sensitivities, which we
show is equivalent to approximate $\ell_p$ regression, are known for only the
$\ell_2$ setting, in which they are termed leverage scores.
<br />In this work, we provide efficient algorithms for approximating $\ell_p$
sensitivities and related summary statistics of a given matrix. In particular,
for a given $n \times d$ matrix, we compute $\alpha$-approximation to its
$\ell_1$ sensitivities at the cost of $O(n/\alpha)$ sensitivity computations.
For estimating the total $\ell_p$ sensitivity (i.e. the sum of $\ell_p$
sensitivities), we provide an algorithm based on importance sampling of
$\ell_p$ Lewis weights, which computes a constant factor approximation to the
total sensitivity at the cost of roughly $O(\sqrt{d})$ sensitivity
computations. Furthermore, we estimate the maximum $\ell_1$ sensitivity, up to
a $\sqrt{d}$ factor, using $O(d)$ sensitivity computations. We generalize all
these results to $\ell_p$ norms for $p &gt; 1$. Lastly, we experimentally show
that for a wide class of matrices in real-world datasets, the total sensitivity
can be quickly approximated and is significantly smaller than the theoretical
prediction, demonstrating that real-world datasets have low intrinsic effective
dimensionality.
</p>
</div>
</dd>
<dt><a name="item343">[343]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04160" title="Abstract">arXiv:2311.04160</a> [<a href="/pdf/2311.04160" title="Download PDF">pdf</a>, <a href="/format/2311.04160" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> &quot;Tell me about that church&quot;: Exploring the Design and User Experience of  In-Vehicle Multi-modal Intuitive Interface in the Context of Driving Scenario
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yu%2C+Y">Yueteng Yu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Burnett%2C+G">Gary Burnett</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">Intuitive interaction has long been seen as a highly user-friendly method.
There are attempts to implement intuitive interfaces in vehicles in both
research and industrial, such as voice commands. However, there is a lack of
exploration in the in-vehicle multi-modal intuitive interaction, especially
under a dynamic driving scenario. In this research, we conducted a design
workshop (N=6) to understand user's needs and designers' considerations on the
in-vehicle multi-modal intuitive interface, based on which we implemented our
design on both a simulator and a real autonomous vehicle using Wizard-of-Oz. We
conducted a user experiment (N=12) on the simulator to explore determinants of
users' acceptance, experience, and behavior. We figured that acceptance was
significantly influenced by six determinants. Drivers' behavior has an obvious
pattern of change. Drivers have been proven to have less workload but
distractions were also reported. Our findings offered empirical evidence which
could give insights into future vehicle design.
</p>
</div>
</dd>
<dt><a name="item344">[344]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04163" title="Abstract">arXiv:2311.04163</a> [<a href="/pdf/2311.04163" title="Download PDF">pdf</a>, <a href="/format/2311.04163" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Outliers with Opposing Signals Have an Outsized Effect on Neural Network  Optimization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rosenfeld%2C+E">Elan Rosenfeld</a>, 
<a href="/search/cs?searchtype=author&query=Risteski%2C+A">Andrej Risteski</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV); Machine Learning (stat.ML)

</div>
<p class="mathjax">We identify a new phenomenon in neural network optimization which arises from
the interaction of depth and a particular heavy-tailed structure in natural
data. Our result offers intuitive explanations for several previously reported
observations about network training dynamics. In particular, it implies a
conceptually new cause for progressive sharpening and the edge of stability; we
also highlight connections to other concepts in optimization and generalization
including grokking, simplicity bias, and Sharpness-Aware Minimization.
<br />Experimentally, we demonstrate the significant influence of paired groups of
outliers in the training data with strong opposing signals: consistent, large
magnitude features which dominate the network output throughout training and
provide gradients which point in opposite directions. Due to these outliers,
early optimization enters a narrow valley which carefully balances the opposing
groups; subsequent sharpening causes their loss to rise rapidly, oscillating
between high on one group and then the other, until the overall loss spikes. We
describe how to identify these groups, explore what sets them apart, and
carefully study their effect on the network's optimization and behavior. We
complement these experiments with a mechanistic explanation on a toy example of
opposing signals and a theoretical analysis of a two-layer linear network on a
simple model. Our finding enables new qualitative predictions of training
behavior which we confirm experimentally. It also provides a new lens through
which to study and improve modern training practices for stochastic
optimization, which we highlight via a case study of Adam versus SGD.
</p>
</div>
</dd>
<dt><a name="item345">[345]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04164" title="Abstract">arXiv:2311.04164</a> [<a href="/pdf/2311.04164" title="Download PDF">pdf</a>, <a href="/format/2311.04164" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Models towards Risk Behavior Prediction and Analysis: A Netherlands Case  study
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Adekunle%2C+O">Onaopepo Adekunle</a>, 
<a href="/search/cs?searchtype=author&query=Riedl%2C+A">Arno Riedl</a>, 
<a href="/search/cs?searchtype=author&query=Dumontier%2C+M">Michel Dumontier</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Engineering, Finance, and Science (cs.CE)</span>

</div>
<p class="mathjax">In many countries financial service providers have to elicit their customers
risk preferences, when offering products and services. For instance, in the
Netherlands pension funds will be legally obliged to factor in their clients
risk preferences when devising their investment strategies. Therefore,
assessing and measuring the risk preferences of individuals is critical for the
analysis of individuals' behavior and policy prescriptions. In the psychology
and economics, a number of methods to elicit risk preferences have been
developed using hypothetical scenarios and economic experiments. These methods
of eliciting individual risk preferences are usually applied to small samples
because they are expensive and the implementation can be complex and not
suitable when large cohorts need to be measured. A large number of supervised
learning models ranging from linear regression to support vector machines are
used to predict risk preference measures using socio-economic register data
such as age, gender, migration background and other demographic variables in
combination with data on income, wealth, pension fund contributions, and other
financial data. The employed machine learning models cover a range of
assumptions and properties as well as a diverse set of regression metrics. The
optimum model is selected using the metrics and interpretability of the model.
The optimal models are lasso regression and gradient boosting machines with
mean average percentage error of about 30%. This is important as it helps to
estimate risk attitudes without actually measuring them. It should be noted
that with the current accuracy the tested models are not ready for deployment
for applications that require high accuracy. However, the results do indicate
which models should be used in situations that do not require the most accurate
predictions such as augmentation data for pensions' recommendation.
</p>
</div>
</dd>
<dt><a name="item346">[346]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04166" title="Abstract">arXiv:2311.04166</a> [<a href="/pdf/2311.04166" title="Download PDF">pdf</a>, <a href="/format/2311.04166" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Perturbed examples reveal invariances shared by language models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rawal%2C+R">Ruchit Rawal</a>, 
<a href="/search/cs?searchtype=author&query=Toneva%2C+M">Mariya Toneva</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">An explosion of work in language is leading to ever-increasing numbers of
available natural language processing models, with little understanding of how
new models compare to better-understood models. One major reason for this
difficulty is saturating benchmark datasets, which may not reflect well
differences in model performance in the wild. In this work, we propose a novel
framework for comparing two natural language processing models by revealing
their shared invariance to interpretable input perturbations that are designed
to target a specific linguistic capability (e.g., Synonym-Invariance,
Typo-Invariance). Via experiments on models from within the same and across
different architecture families, this framework offers a number of insights
about how changes in models (e.g., distillation, increase in size, amount of
pre-training) affect multiple well-defined linguistic capabilities.
Furthermore, we also demonstrate how our framework can enable evaluation of the
invariances shared between models that are available as commercial black-box
APIs (e.g., InstructGPT family) and models that are relatively better
understood (e.g., GPT-2). Across several experiments, we observe that large
language models share many of the invariances encoded by models of various
sizes, whereas the invariances encoded by large language models are only shared
by other large models. Possessing a wide variety of invariances may be a key
reason for the recent successes of large language models, and our framework can
shed light on the types of invariances that are retained by or emerge in new
models.
</p>
</div>
</dd>
<dt><a name="item347">[347]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04171" title="Abstract">arXiv:2311.04171</a> [<a href="/pdf/2311.04171" title="Download PDF">pdf</a>, <a href="/format/2311.04171" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> HADES: Fast Singularity Detection with Local Measure Comparison
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lim%2C+U">Uzu Lim</a>, 
<a href="/search/cs?searchtype=author&query=Oberhauser%2C+H">Harald Oberhauser</a>, 
<a href="/search/cs?searchtype=author&query=Nanda%2C+V">Vidit Nanda</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Algebraic Topology (math.AT); Differential Geometry (math.DG); Statistics Theory (math.ST)

</div>
<p class="mathjax">We introduce Hades, an unsupervised algorithm to detect singularities in
data. This algorithm employs a kernel goodness-of-fit test, and as a
consequence it is much faster and far more scaleable than the existing
topology-based alternatives. Using tools from differential geometry and optimal
transport theory, we prove that Hades correctly detects singularities with high
probability when the data sample lives on a transverse intersection of
equidimensional manifolds. In computational experiments, Hades recovers
singularities in synthetically generated data, branching points in road network
data, intersection rings in molecular conformation space, and anomalies in
image data.
</p>
</div>
</dd>
<dt><a name="item348">[348]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04172" title="Abstract">arXiv:2311.04172</a> [<a href="/pdf/2311.04172" title="Download PDF">pdf</a>, <a href="/format/2311.04172" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Measure transport via polynomial density surrogates
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Westermann%2C+J">Josephine Westermann</a>, 
<a href="/search/math?searchtype=author&query=Zech%2C+J">Jakob Zech</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 51 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Statistics Theory (math.ST)

</div>
<p class="mathjax">We discuss an algorithm to compute transport maps that couple the uniform
measure on $[0,1]^d$ with a specified target distribution $\pi$ on $[0,1]^d$.
The primary objectives are either to sample from or to compute expectations
w.r.t. $\pi$. The method is based on leveraging a polynomial surrogate of the
target density, which is obtained by a least-squares or interpolation
approximation. We discuss the design and construction of suitable sparse
approximation spaces, and provide a complete error and cost analysis for target
densities belonging to certain smoothness classes. Further, we explore the
relation between our proposed algorithm and related approaches that aim to find
suitable transports via optimization over a class of parametrized transports.
Finally, we discuss the efficient implementation of our algorithm and report on
numerical experiments which confirm our theory.
</p>
</div>
</dd>
<dt><a name="item349">[349]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04177" title="Abstract">arXiv:2311.04177</a> [<a href="/pdf/2311.04177" title="Download PDF">pdf</a>, <a href="/format/2311.04177" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Enhancing LLM Intelligence with ARM-RAG: Auxiliary Rationale Memory for  Retrieval Augmented Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Melz%2C+E">Eric Melz</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Large Language Models (LLMs) are smart but forgetful. Recent studies, (e.g.,
(Bubeck et al., 2023)) on modern LLMs have shown that they are capable of
performing amazing tasks typically necessitating human-level intelligence.
However, unlike humans, frozen LLMs do not improve over time; they neither
acquire new knowledge nor learn from their successes or failures. Some
approaches to improving the intelligence of LLMs include fine-tuning models
based on problem-solving performance (Zelikman et al., 2022), and building
bigger and more sophisticated models (Bubeck et al., 2023). However, these
methods have the drawback of requiring substantial data and computational
resources to retrain existing models. In this paper, we explore the use of
Retrieval Augmented Generation, also known as RAG (Lewis et al., 2021) to
improve problem-solving performance. We propose ARM-RAG (Auxiliary Rationale
Memory for Retrieval Augmented Generation), a system that learns from its
successes without incurring high training costs. We demonstrate that the
storage and subsequent retrieval of reasoning chains have a positive influence
on performance in grade-school math problems.
</p>
</div>
</dd>
<dt><a name="item350">[350]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04179" title="Abstract">arXiv:2311.04179</a> [<a href="/pdf/2311.04179" title="Download PDF">pdf</a>, <a href="/ps/2311.04179" title="Download PostScript">ps</a>, <a href="/format/2311.04179" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On Leakage in Machine Learning Pipelines
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sasse%2C+L">Leonard Sasse</a>, 
<a href="/search/cs?searchtype=author&query=Nicolaisen-Sobesky%2C+E">Eliana Nicolaisen-Sobesky</a>, 
<a href="/search/cs?searchtype=author&query=Dukart%2C+J">Juergen Dukart</a>, 
<a href="/search/cs?searchtype=author&query=Eickhoff%2C+S+B">Simon B. Eickhoff</a>, 
<a href="/search/cs?searchtype=author&query=G%C3%B6tz%2C+M">Michael G&#xf6;tz</a>, 
<a href="/search/cs?searchtype=author&query=Hamdan%2C+S">Sami Hamdan</a>, 
<a href="/search/cs?searchtype=author&query=Komeyer%2C+V">Vera Komeyer</a>, 
<a href="/search/cs?searchtype=author&query=Kulkarni%2C+A">Abhijit Kulkarni</a>, 
<a href="/search/cs?searchtype=author&query=Lahnakoski%2C+J">Juha Lahnakoski</a>, 
<a href="/search/cs?searchtype=author&query=Love%2C+B+C">Bradley C. Love</a>, 
<a href="/search/cs?searchtype=author&query=Raimondo%2C+F">Federico Raimondo</a>, 
<a href="/search/cs?searchtype=author&query=Patil%2C+K+R">Kaustubh R. Patil</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> first draft
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Machine learning (ML) provides powerful tools for predictive modeling. ML's
popularity stems from the promise of sample-level prediction with applications
across a variety of fields from physics and marketing to healthcare. However,
if not properly implemented and evaluated, ML pipelines may contain leakage
typically resulting in overoptimistic performance estimates and failure to
generalize to new data. This can have severe negative financial and societal
implications. Our aim is to expand understanding associated with causes leading
to leakage when designing, implementing, and evaluating ML pipelines.
Illustrated by concrete examples, we provide a comprehensive overview and
discussion of various types of leakage that may arise in ML pipelines.
</p>
</div>
</dd>
<dt><a name="item351">[351]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04180" title="Abstract">arXiv:2311.04180</a> [<a href="/pdf/2311.04180" title="Download PDF">pdf</a>, <a href="/format/2311.04180" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Polyregular functions on unordered trees of bounded height
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Boja%C5%84czyk%2C+M">Miko&#x142;aj Boja&#x144;czyk</a>, 
<a href="/search/cs?searchtype=author&query=Klin%2C+B">Bartek Klin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Authors' version of a paper published at 51st ACM SIGPLAN Symposium on Principles of Programming Languages (POPL 2024)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>; Formal Languages and Automata Theory (cs.FL)

</div>
<p class="mathjax">We consider injective first-order interpretations that input and output trees
of bounded height. The corresponding functions have polynomial output size,
since a first-order interpretation can use a k-tuple of input nodes to
represent a single output node. We prove that the equivalence problem for such
functions is decidable, i.e. given two such interpretations, one can decide
whether, for every input tree, the two output trees are isomorphic.
<br />We also give a calculus of typed functions and combinators which derives
exactly injective first-order interpretations for unordered trees of bounded
height. The calculus is based on a type system, where the type constructors are
products, coproducts and a monad of multisets. Thanks to our results about
tree-to-tree interpretations, the equivalence problem is decidable for this
calculus.
<br />As an application, we show that the equivalence problem is decidable for
first-order interpretations between classes of graphs that have bounded
tree-depth. In all cases studied in this paper, first-order logic and MSO have
the same expressive power, and hence all results apply also to MSO
interpretations.
</p>
</div>
</dd>
<dt><a name="item352">[352]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04181" title="Abstract">arXiv:2311.04181</a> [<a href="/pdf/2311.04181" title="Download PDF">pdf</a>, <a href="/format/2311.04181" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A First Look At NAT64 Deployment In-The-Wild
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hsu%2C+A">Amanda Hsu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+F">Frank Li</a>, 
<a href="/search/cs?searchtype=author&query=Pearce%2C+P">Paul Pearce</a>, 
<a href="/search/cs?searchtype=author&query=Gasser%2C+O">Oliver Gasser</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>

</div>
<p class="mathjax">IPv6 is a fundamentally different Internet Protocol than IPv4, and IPv6-only
networks cannot, by default, communicate with the IPv4 Internet. This lack of
interoperability necessitates complex mechanisms for incremental deployment and
bridging networks so that non-dual-stack systems can interact with the whole
Internet. NAT64 is one such bridging mechanism by which a network allows
IPv6-only clients to connect to the entire Internet, leveraging DNS to identify
IPv4-only networks, inject IPv6 response addresses pointing to an internal
gateway, and seamlessly translate connections. To date, our understanding of
NAT64 deployments is limited; what little information exists is largely
qualitative, taken from mailing lists and informal discussions.
<br />In this work, we present a first look at the active measurement of NAT64
deployment on the Internet focused on deployment prevalence, configuration, and
security. We seek to measure NAT64 via two distinct large-scale measurements:
1) open resolvers on the Internet, and 2) client measurements from RIPE Atlas.
For both datasets, we broadly find that despite substantial anecdotal reports
of NAT64 deployment, measurable deployments are exceedingly sparse. While our
measurements do not preclude the large-scale deployment of NAT64, they do point
to substantial challenges in measuring deployments with our existing best-known
methods. Finally, we also identify problems in NAT64 deployments, with gateways
not following the RFC specification and also posing potential security risks.
</p>
</div>
</dd>
<dt><a name="item353">[353]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04189" title="Abstract">arXiv:2311.04189</a> [<a href="/pdf/2311.04189" title="Download PDF">pdf</a>, <a href="/ps/2311.04189" title="Download PostScript">ps</a>, <a href="/format/2311.04189" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SpaDeLeF: A Dataset for Hierarchical Classification of Lexical Functions  for Collocations in Spanish
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kostiuk%2C+Y">Yevhen Kostiuk</a>, 
<a href="/search/cs?searchtype=author&query=Sidorov%2C+G">Grigori Sidorov</a>, 
<a href="/search/cs?searchtype=author&query=Kolesnikova%2C+O">Olga Kolesnikova</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">In natural language processing (NLP), lexical function is a concept to
unambiguously represent semantic and syntactic features of words and phrases in
text first crafted in the Meaning-Text Theory. Hierarchical classification of
lexical functions involves organizing these features into a tree-like hierarchy
of categories or labels. This is a challenging task as it requires a good
understanding of the context and the relationships among words and phrases in
text. It also needs large amounts of labeled data to train language models
effectively. In this paper, we present a dataset of most frequent Spanish
verb-noun collocations and sentences where they occur, each collocation is
assigned to one of 37 lexical functions defined as classes for a hierarchical
classification task. Each class represents a relation between the noun and the
verb in a collocation involving their semantic and syntactic features. We
combine the classes in a tree-based structure, and introduce classification
objectives for each level of the structure. The dataset was created by
dependency tree parsing and matching of the phrases in Spanish news. We provide
baselines and data splits for each objective.
</p>
</div>
</dd>
<dt><a name="item354">[354]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04190" title="Abstract">arXiv:2311.04190</a> [<a href="/pdf/2311.04190" title="Download PDF">pdf</a>, <a href="/format/2311.04190" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Spatio-Temporal Anomaly Detection with Graph Networks for Data Quality  Monitoring of the Hadron Calorimeter
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Asres%2C+M+W">Mulugeta Weldezgina Asres</a>, 
<a href="/search/cs?searchtype=author&query=Omlin%2C+C+W">Christian Walter Omlin</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+L">Long Wang</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+D">David Yu</a>, 
<a href="/search/cs?searchtype=author&query=Parygin%2C+P">Pavel Parygin</a>, 
<a href="/search/cs?searchtype=author&query=Dittmann%2C+J">Jay Dittmann</a>, 
<a href="/search/cs?searchtype=author&query=Karapostoli%2C+G">Georgia Karapostoli</a>, 
<a href="/search/cs?searchtype=author&query=Seidel%2C+M">Markus Seidel</a>, 
<a href="/search/cs?searchtype=author&query=Venditti%2C+R">Rosamaria Venditti</a>, 
<a href="/search/cs?searchtype=author&query=Lambrecht%2C+L">Luka Lambrecht</a>, 
<a href="/search/cs?searchtype=author&query=Usai%2C+E">Emanuele Usai</a>, 
<a href="/search/cs?searchtype=author&query=Ahmad%2C+M">Muhammad Ahmad</a>, 
<a href="/search/cs?searchtype=author&query=Menendez%2C+J+F">Javier Fernandez Menendez</a>, 
<a href="/search/cs?searchtype=author&query=Maeshima%2C+K">Kaori Maeshima</a>, 
the <a href="/search/cs?searchtype=author&query=CMS-HCAL+Collaboration">CMS-HCAL Collaboration</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 23 pages, 15 figures, 3 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">The compact muon solenoid (CMS) experiment is a general-purpose detector for
high-energy collision at the large hadron collider (LHC) at CERN. It employs an
online data quality monitoring (DQM) system to promptly spot and diagnose
particle data acquisition problems to avoid data quality loss. In this study,
we present semi-supervised spatio-temporal anomaly detection (AD) monitoring
for the physics particle reading channels of the hadronic calorimeter (HCAL) of
the CMS using three-dimensional digi-occupancy map data of the DQM. We propose
the GraphSTAD system, which employs convolutional and graph neural networks to
learn local spatial characteristics induced by particles traversing the
detector, and global behavior owing to shared backend circuit connections and
housing boxes of the channels, respectively. Recurrent neural networks capture
the temporal evolution of the extracted spatial features. We have validated the
accuracy of the proposed AD system in capturing diverse channel fault types
using the LHC Run-2 collision data sets. The GraphSTAD system has achieved
production-level accuracy and is being integrated into the CMS core production
system--for real-time monitoring of the HCAL. We have also provided a
quantitative performance comparison with alternative benchmark models to
demonstrate the promising leverage of the presented system.
</p>
</div>
</dd>
<dt><a name="item355">[355]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04192" title="Abstract">arXiv:2311.04192</a> [<a href="/pdf/2311.04192" title="Download PDF">pdf</a>, <a href="/format/2311.04192" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> JaSPICE: Automatic Evaluation Metric Using Predicate-Argument Structures  for Image Captioning Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wada%2C+Y">Yuiga Wada</a>, 
<a href="/search/cs?searchtype=author&query=Kaneda%2C+K">Kanta Kaneda</a>, 
<a href="/search/cs?searchtype=author&query=Sugiura%2C+K">Komei Sugiura</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at CoNLL 2023. Project page: <a href="https://yuiga.dev/jaspice/en">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Computation and Language (cs.CL)

</div>
<p class="mathjax">Image captioning studies heavily rely on automatic evaluation metrics such as
BLEU and METEOR. However, such n-gram-based metrics have been shown to
correlate poorly with human evaluation, leading to the proposal of alternative
metrics such as SPICE for English; however, no equivalent metrics have been
established for other languages. Therefore, in this study, we propose an
automatic evaluation metric called JaSPICE, which evaluates Japanese captions
based on scene graphs. The proposed method generates a scene graph from
dependencies and the predicate-argument structure, and extends the graph using
synonyms. We conducted experiments employing 10 image captioning models trained
on STAIR Captions and PFN-PIC and constructed the Shichimi dataset, which
contains 103,170 human evaluations. The results showed that our metric
outperformed the baseline metrics for the correlation coefficient with the
human evaluation.
</p>
</div>
</dd>
<dt><a name="item356">[356]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04193" title="Abstract">arXiv:2311.04193</a> [<a href="/pdf/2311.04193" title="Download PDF">pdf</a>, <a href="/format/2311.04193" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Selective Visual Representations Improve Convergence and Generalization  for Embodied AI
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Eftekhar%2C+A">Ainaz Eftekhar</a>, 
<a href="/search/cs?searchtype=author&query=Zeng%2C+K">Kuo-Hao Zeng</a>, 
<a href="/search/cs?searchtype=author&query=Duan%2C+J">Jiafei Duan</a>, 
<a href="/search/cs?searchtype=author&query=Farhadi%2C+A">Ali Farhadi</a>, 
<a href="/search/cs?searchtype=author&query=Kembhavi%2C+A">Ani Kembhavi</a>, 
<a href="/search/cs?searchtype=author&query=Krishna%2C+R">Ranjay Krishna</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> See project website: <a href="https://embodied-codebook.github.io">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Embodied AI models often employ off the shelf vision backbones like CLIP to
encode their visual observations. Although such general purpose representations
encode rich syntactic and semantic information about the scene, much of this
information is often irrelevant to the specific task at hand. This introduces
noise within the learning process and distracts the agent's focus from
task-relevant visual cues. Inspired by selective attention in humans-the
process through which people filter their perception based on their
experiences, knowledge, and the task at hand-we introduce a parameter-efficient
approach to filter visual stimuli for embodied AI. Our approach induces a
task-conditioned bottleneck using a small learnable codebook module. This
codebook is trained jointly to optimize task reward and acts as a
task-conditioned selective filter over the visual observation. Our experiments
showcase state-of-the-art performance for object goal navigation and object
displacement across 5 benchmarks, ProcTHOR, ArchitecTHOR, RoboTHOR, AI2-iTHOR,
and ManipulaTHOR. The filtered representations produced by the codebook are
also able generalize better and converge faster when adapted to other
simulation environments such as Habitat. Our qualitative analyses show that
agents explore their environments more effectively and their representations
retain task-relevant information like target object recognition while ignoring
superfluous information about other objects. Code and pretrained models are
available at our project website: https://embodied-codebook.github.io.
</p>
</div>
</dd>
<dt><a name="item357">[357]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04194" title="Abstract">arXiv:2311.04194</a> [<a href="/pdf/2311.04194" title="Download PDF">pdf</a>, <a href="/format/2311.04194" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Quantization-aware Neural Architectural Search for Intrusion Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Acharya%2C+R+Y">Rabin Yu Acharya</a>, 
<a href="/search/cs?searchtype=author&query=Jeune%2C+L+L">Laurens Le Jeune</a>, 
<a href="/search/cs?searchtype=author&query=Mentens%2C+N">Nele Mentens</a>, 
<a href="/search/cs?searchtype=author&query=Ganji%2C+F">Fatemeh Ganji</a>, 
<a href="/search/cs?searchtype=author&query=Forte%2C+D">Domenic Forte</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">Deploying machine learning-based intrusion detection systems (IDSs) on
hardware devices is challenging due to their limited computational resources,
power consumption, and network connectivity. Hence, there is a significant need
for robust, deep learning models specifically designed with such constraints in
mind. In this paper, we present a design methodology that automatically trains
and evolves quantized neural network (NN) models that are a thousand times
smaller than state-of-the-art NNs but can efficiently analyze network data for
intrusion at high accuracy. In this regard, the number of LUTs utilized by this
network when deployed to an FPGA is between 2.3x and 8.5x smaller with
performance comparable to prior work.
</p>
</div>
</dd>
<dt><a name="item358">[358]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04196" title="Abstract">arXiv:2311.04196</a> [<a href="/pdf/2311.04196" title="Download PDF">pdf</a>, <a href="/format/2311.04196" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> JPAVE: A Generation and Classification-based Model for Joint Product  Attribute Prediction and Value Extraction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Deng%2C+Z">Zhongfen Deng</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+H">Hao Peng</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+T">Tao Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+S">Shuaiqi Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+W">Wenting Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yibo Wang</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+P+S">Philip S. Yu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by 2023 IEEE International Conference on Big Data
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Product attribute value extraction is an important task in e-Commerce which
can help several downstream applications such as product search and
recommendation. Most previous models handle this task using sequence labeling
or question answering method which rely on the sequential position information
of values in the product text and are vulnerable to data discrepancy between
training and testing. This limits their generalization ability to real-world
scenario in which each product can have multiple descriptions across various
shopping platforms with different composition of text and style. They also have
limited zero-shot ability to new values. In this paper, we propose a multi-task
learning model with value generation/classification and attribute prediction
called JPAVE to predict values without the necessity of position information of
values in the text. Furthermore, the copy mechanism in value generator and the
value attention module in value classifier help our model address the data
discrepancy issue by only focusing on the relevant part of input text and
ignoring other information which causes the discrepancy issue such as sentence
structure in the text. Besides, two variants of our model are designed for
open-world and closed-world scenarios. In addition, copy mechanism introduced
in the first variant based on value generation can improve its zero-shot
ability for identifying unseen values. Experimental results on a public dataset
demonstrate the superiority of our model compared with strong baselines and its
generalization ability of predicting new values.
</p>
</div>
</dd>
<dt><a name="item359">[359]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04199" title="Abstract">arXiv:2311.04199</a> [<a href="/pdf/2311.04199" title="Download PDF">pdf</a>, <a href="/format/2311.04199" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exploring Recommendation Capabilities of GPT-4V(ision): A Preliminary  Case Study
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhou%2C+P">Peilin Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+M">Meng Cao</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+Y">You-Liang Huang</a>, 
<a href="/search/cs?searchtype=author&query=Ye%2C+Q">Qichen Ye</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+P">Peiyan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Junling Liu</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+Y">Yueqi Xie</a>, 
<a href="/search/cs?searchtype=author&query=Hua%2C+Y">Yining Hua</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+J">Jaeboum Kim</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> In Progress
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Computation and Language (cs.CL)

</div>
<p class="mathjax">Large Multimodal Models (LMMs) have demonstrated impressive performance
across various vision and language tasks, yet their potential applications in
recommendation tasks with visual assistance remain unexplored. To bridge this
gap, we present a preliminary case study investigating the recommendation
capabilities of GPT-4V(ison), a recently released LMM by OpenAI. We construct a
series of qualitative test samples spanning multiple domains and employ these
samples to assess the quality of GPT-4V's responses within recommendation
scenarios. Evaluation results on these test samples prove that GPT-4V has
remarkable zero-shot recommendation abilities across diverse domains, thanks to
its robust visual-text comprehension capabilities and extensive general
knowledge. However, we have also identified some limitations in using GPT-4V
for recommendations, including a tendency to provide similar responses when
given similar inputs. This report concludes with an in-depth discussion of the
challenges and research opportunities associated with utilizing GPT-4V in
recommendation scenarios. Our objective is to explore the potential of
extending LMMs from vision and language tasks to recommendation tasks. We hope
to inspire further research into next-generation multimodal generative
recommendation models, which can enhance user experiences by offering greater
diversity and interactivity. All images and prompts used in this report will be
accessible at https://github.com/PALIN2018/Evaluate_GPT-4V_Rec.
</p>
</div>
</dd>
<dt><a name="item360">[360]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04204" title="Abstract">arXiv:2311.04204</a> [<a href="/pdf/2311.04204" title="Download PDF">pdf</a>, <a href="/format/2311.04204" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Sharp Thresholds Imply Circuit Lower Bounds: from random 2-SAT to  Planted Clique
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gamarnik%2C+D">David Gamarnik</a>, 
<a href="/search/cs?searchtype=author&query=Mossel%2C+E">Elchanan Mossel</a>, 
<a href="/search/cs?searchtype=author&query=Zadik%2C+I">Ilias Zadik</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 29 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Complexity (cs.CC)</span>; Probability (math.PR); Statistics Theory (math.ST)

</div>
<p class="mathjax">We show that sharp thresholds for Boolean functions directly imply
average-case circuit lower bounds. More formally we show that any Boolean
function exhibiting a sharp enough threshold at \emph{arbitrary} critical
density cannot be computed by Boolean circuits of bounded depth and polynomial
size.
<br />Our general result implies new average-case bounded depth circuit lower
bounds in a variety of settings.
<br />(a) ($k$-cliques) For $k=\Theta(n)$, we prove that any circuit of depth $d$
deciding the presence of a size $k$ clique in a random graph requires
exponential-in-$n^{\Theta(1/d)}$ size. To the best of our knowledge, this is
the first exponential size lower bound for bounded depth (not necessarily
monotone) circuits solving the fundamental $k$-clique problem (for any
$k=k_n$), even for worst-case input graphs.
<br />(b)(random 2-SAT) We prove that any circuit of depth $d$ deciding the
satisfiability of a random 2-SAT formula requires
exponential-in-$n^{\Theta(1/d)}$ size. To the best of our knowledge, this is
the first bounded depth circuit lower bound for random $k$-SAT for any value of
$k \geq 2.$ Our results also provide the first rigorous lower bound in
agreement with a conjectured ``computational hardness'' of random $k$-SAT
around its satisfiability threshold.
<br />(c)(Statistical estimation -- planted $k$-clique) Over the recent years,
multiple statistical estimation problems have also been proven to exhibit a
``statistical'' sharp threshold, called the All-or-Nothing (AoN) phenomenon. We
show that AoN also implies circuit lower bounds for statistical problems. As a
simple corollary of that, we prove that any circuit of depth $d$ that solves to
information-theoretic optimality a ``dense'' variant of the celebrated planted
$k$-clique problem requires exponential-in-$n^{\Theta(1/d)}$ size.
</p>
</div>
</dd>
<dt><a name="item361">[361]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04205" title="Abstract">arXiv:2311.04205</a> [<a href="/pdf/2311.04205" title="Download PDF">pdf</a>, <a href="/format/2311.04205" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Rephrase and Respond: Let Large Language Models Ask Better Questions for  Themselves
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Deng%2C+Y">Yihe Deng</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+W">Weitong Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Z">Zixiang Chen</a>, 
<a href="/search/cs?searchtype=author&query=Gu%2C+Q">Quanquan Gu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 32 pages, 9 figures, 22 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Misunderstandings arise not only in interpersonal communication but also
between humans and Large Language Models (LLMs). Such discrepancies can make
LLMs interpret seemingly unambiguous questions in unexpected ways, yielding
incorrect responses. While it is widely acknowledged that the quality of a
prompt, such as a question, significantly impacts the quality of the response
provided by LLMs, a systematic method for crafting questions that LLMs can
better comprehend is still underdeveloped. In this paper, we present a method
named `Rephrase and Respond' (RaR), which allows LLMs to rephrase and expand
questions posed by humans and provide responses in a single prompt. This
approach serves as a simple yet effective prompting method for improving
performance. We also introduce a two-step variant of RaR, where a rephrasing
LLM first rephrases the question and then passes the original and rephrased
questions together to a different responding LLM. This facilitates the
effective utilization of rephrased questions generated by one LLM with another.
Our experiments demonstrate that our methods significantly improve the
performance of different models across a wide range to tasks. We further
provide a comprehensive comparison between RaR and the popular Chain-of-Thought
(CoT) methods, both theoretically and empirically. We show that RaR is
complementary to CoT and can be combined with CoT to achieve even better
performance. Our work not only contributes to enhancing LLM performance
efficiently and effectively but also sheds light on a fair evaluation of LLM
capabilities. Data and codes are available at
https://github.com/uclaml/Rephrase-and-Respond.
</p>
</div>
</dd>
<dt><a name="item362">[362]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04207" title="Abstract">arXiv:2311.04207</a> [<a href="/pdf/2311.04207" title="Download PDF">pdf</a>, <a href="/format/2311.04207" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deep Hashing via Householder Quantization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Schwengber%2C+L+R">Lucas R. Schwengber</a>, 
<a href="/search/cs?searchtype=author&query=Resende%2C+L">Lucas Resende</a>, 
<a href="/search/cs?searchtype=author&query=Orenstein%2C+P">Paulo Orenstein</a>, 
<a href="/search/cs?searchtype=author&query=Oliveira%2C+R+I">Roberto I. Oliveira</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Information Retrieval (cs.IR)

</div>
<p class="mathjax">Hashing is at the heart of large-scale image similarity search, and recent
methods have been substantially improved through deep learning techniques. Such
algorithms typically learn continuous embeddings of the data. To avoid a
subsequent costly binarization step, a common solution is to employ loss
functions that combine a similarity learning term (to ensure similar images are
grouped to nearby embeddings) and a quantization penalty term (to ensure that
the embedding entries are close to binarized entries, e.g., -1 or 1). Still,
the interaction between these two terms can make learning harder and the
embeddings worse. We propose an alternative quantization strategy that
decomposes the learning problem in two stages: first, perform similarity
learning over the embedding space with no quantization; second, find an optimal
orthogonal transformation of the embeddings so each coordinate of the embedding
is close to its sign, and then quantize the transformed embedding through the
sign function. In the second step, we parametrize orthogonal transformations
using Householder matrices to efficiently leverage stochastic gradient descent.
Since similarity measures are usually invariant under orthogonal
transformations, this quantization strategy comes at no cost in terms of
performance. The resulting algorithm is unsupervised, fast, hyperparameter-free
and can be run on top of any existing deep hashing or metric learning
algorithm. We provide extensive experimental results showing that this approach
leads to state-of-the-art performance on widely used image datasets, and,
unlike other quantization strategies, brings consistent improvements in
performance to existing deep hashing algorithms.
</p>
</div>
</dd>
<dt><a name="item363">[363]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04210" title="Abstract">arXiv:2311.04210</a> [<a href="/pdf/2311.04210" title="Download PDF">pdf</a>, <a href="/ps/2311.04210" title="Download PostScript">ps</a>, <a href="/format/2311.04210" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Bayesian Approach for Simultaneously Radial Kernel Parameter Tuning in  the Partition of Unity Method
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Cavoretto%2C+R">Roberto Cavoretto</a>, 
<a href="/search/math?searchtype=author&query=De+Rossi%2C+A">Alessandra De Rossi</a>, 
<a href="/search/math?searchtype=author&query=Lancellotti%2C+S">Sandro Lancellotti</a>, 
<a href="/search/math?searchtype=author&query=Romaniello%2C+F">Federico Romaniello</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">In this paper, Bayesian optimisation is used to simultaneously search the
optimal values of the shape parameter and the radius in radial basis function
partition of unity interpolation problem. It is a probabilistic iterative
approach that models the error function with a step-by-step self-updated
Gaussian process, whereas partition of unity leverages a mesh-free method that
allows us to reduce cost-intensive computations when the number of scattered
data is very large, as the entire domain is decomposed into several smaller
subdomains of variable radius. Numerical experiments on the scattered data
interpolation problem show that the combination of these two tools sharply
reduces the search time with respect to other techniques such as the leave one
out cross validation.
</p>
</div>
</dd>
<dt><a name="item364">[364]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04212" title="Abstract">arXiv:2311.04212</a> [<a href="/pdf/2311.04212" title="Download PDF">pdf</a>, <a href="/format/2311.04212" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Video Instance Matting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jiachen Li</a>, 
<a href="/search/cs?searchtype=author&query=Henschel%2C+R">Roberto Henschel</a>, 
<a href="/search/cs?searchtype=author&query=Goel%2C+V">Vidit Goel</a>, 
<a href="/search/cs?searchtype=author&query=Ohanyan%2C+M">Marianna Ohanyan</a>, 
<a href="/search/cs?searchtype=author&query=Navasardyan%2C+S">Shant Navasardyan</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+H">Humphrey Shi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Conventional video matting outputs one alpha matte for all instances
appearing in a video frame so that individual instances are not distinguished.
While video instance segmentation provides time-consistent instance masks,
results are unsatisfactory for matting applications, especially due to applied
binarization. To remedy this deficiency, we propose Video Instance
Matting~(VIM), that is, estimating alpha mattes of each instance at each frame
of a video sequence. To tackle this challenging problem, we present MSG-VIM, a
Mask Sequence Guided Video Instance Matting neural network, as a novel baseline
model for VIM. MSG-VIM leverages a mixture of mask augmentations to make
predictions robust to inaccurate and inconsistent mask guidance. It
incorporates temporal mask and temporal feature guidance to improve the
temporal consistency of alpha matte predictions. Furthermore, we build a new
benchmark for VIM, called VIM50, which comprises 50 video clips with multiple
human instances as foreground objects. To evaluate performances on the VIM
task, we introduce a suitable metric called Video Instance-aware Matting
Quality~(VIMQ). Our proposed model MSG-VIM sets a strong baseline on the VIM50
benchmark and outperforms existing methods by a large margin. The project is
open-sourced at https://github.com/SHI-Labs/VIM.
</p>
</div>
</dd>
<dt><a name="item365">[365]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04215" title="Abstract">arXiv:2311.04215</a> [<a href="/pdf/2311.04215" title="Download PDF">pdf</a>, <a href="/format/2311.04215" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Wearable data from subjects playing Super Mario, sitting university  exams, or performing physical exercise help detect acute mood episodes via  self-supervised learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Corponi%2C+F">Filippo Corponi</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+B+M">Bryan M. Li</a>, 
<a href="/search/cs?searchtype=author&query=Anmella%2C+G">Gerard Anmella</a>, 
<a href="/search/cs?searchtype=author&query=Valenzuela-Pascual%2C+C">Cl&#xe0;udia Valenzuela-Pascual</a>, 
<a href="/search/cs?searchtype=author&query=Mas%2C+A">Ariadna Mas</a>, 
<a href="/search/cs?searchtype=author&query=Pacchiarotti%2C+I">Isabella Pacchiarotti</a>, 
<a href="/search/cs?searchtype=author&query=Valent%C3%AD%2C+M">Marc Valent&#xed;</a>, 
<a href="/search/cs?searchtype=author&query=Grande%2C+I">Iria Grande</a>, 
<a href="/search/cs?searchtype=author&query=Benabarre%2C+A">Antonio Benabarre</a>, 
<a href="/search/cs?searchtype=author&query=Garriga%2C+M">Marina Garriga</a>, 
<a href="/search/cs?searchtype=author&query=Vieta%2C+E">Eduard Vieta</a>, 
<a href="/search/cs?searchtype=author&query=Young%2C+A+H">Allan H Young</a>, 
<a href="/search/cs?searchtype=author&query=Lawrie%2C+S+M">Stephen M. Lawrie</a>, 
<a href="/search/cs?searchtype=author&query=Whalley%2C+H+C">Heather C. Whalley</a>, 
<a href="/search/cs?searchtype=author&query=Hidalgo-Mazzei%2C+D">Diego Hidalgo-Mazzei</a>, 
<a href="/search/cs?searchtype=author&query=Vergari%2C+A">Antonio Vergari</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Signal Processing (eess.SP)

</div>
<p class="mathjax">Personal sensing, leveraging data passively and near-continuously collected
with wearables from patients in their ecological environment, is a promising
paradigm to monitor mood disorders (MDs), a major determinant of worldwide
disease burden. However, collecting and annotating wearable data is very
resource-intensive. Studies of this kind can thus typically afford to recruit
only a couple dozens of patients. This constitutes one of the major obstacles
to applying modern supervised machine learning techniques to MDs detection. In
this paper, we overcome this data bottleneck and advance the detection of MDs
acute episode vs stable state from wearables data on the back of recent
advances in self-supervised learning (SSL). This leverages unlabelled data to
learn representations during pre-training, subsequently exploited for a
supervised task. First, we collected open-access datasets recording with an
Empatica E4 spanning different, unrelated to MD monitoring, personal sensing
tasks -- from emotion recognition in Super Mario players to stress detection in
undergraduates -- and devised a pre-processing pipeline performing on-/off-body
detection, sleep-wake detection, segmentation, and (optionally) feature
extraction. With 161 E4-recorded subjects, we introduce E4SelfLearning, the
largest to date open access collection, and its pre-processing pipeline.
Second, we show that SSL confidently outperforms fully-supervised pipelines
using either our novel E4-tailored Transformer architecture (E4mer) or
classical baseline XGBoost: 81.23% against 75.35% (E4mer) and 72.02% (XGBoost)
correctly classified recording segments from 64 (half acute, half stable)
patients. Lastly, we illustrate that SSL performance is strongly associated
with the specific surrogate task employed for pre-training as well as with
unlabelled data availability.
</p>
</div>
</dd>
<dt><a name="item366">[366]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04218" title="Abstract">arXiv:2311.04218</a> [<a href="/pdf/2311.04218" title="Download PDF">pdf</a>, <a href="/format/2311.04218" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Garment Sewing Pattern Reconstruction from a Single Image
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+L">Lijuan Liu</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+X">Xiangyu Xu</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+Z">Zhijie Lin</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+J">Jiabin Liang</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+S">Shuicheng Yan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ACM Transactions on Graphics (SIGGRAPH Asia) 2023; Project page at: <a href="https://sewformer.github.io">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Graphics (cs.GR); Machine Learning (cs.LG); Multimedia (cs.MM)

</div>
<p class="mathjax">Garment sewing pattern represents the intrinsic rest shape of a garment, and
is the core for many applications like fashion design, virtual try-on, and
digital avatars. In this work, we explore the challenging problem of recovering
garment sewing patterns from daily photos for augmenting these applications. To
solve the problem, we first synthesize a versatile dataset, named SewFactory,
which consists of around 1M images and ground-truth sewing patterns for model
training and quantitative evaluation. SewFactory covers a wide range of human
poses, body shapes, and sewing patterns, and possesses realistic appearances
thanks to the proposed human texture synthesis network. Then, we propose a
two-level Transformer network called Sewformer, which significantly improves
the sewing pattern prediction performance. Extensive experiments demonstrate
that the proposed framework is effective in recovering sewing patterns and well
generalizes to casually-taken human photos. Code, dataset, and pre-trained
models are available at: https://sewformer.github.io.
</p>
</div>
</dd>
<dt><a name="item367">[367]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04219" title="Abstract">arXiv:2311.04219</a> [<a href="/pdf/2311.04219" title="Download PDF">pdf</a>, <a href="/format/2311.04219" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> OtterHD: A High-Resolution Multi-modality Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+B">Bo Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+P">Peiyuan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+J">Jingkang Yang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yuanhan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Pu%2C+F">Fanyi Pu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Ziwei Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Early Technical Report
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">In this paper, we present OtterHD-8B, an innovative multimodal model evolved
from Fuyu-8B, specifically engineered to interpret high-resolution visual
inputs with granular precision. Unlike conventional models that are constrained
by fixed-size vision encoders, OtterHD-8B boasts the ability to handle flexible
input dimensions, ensuring its versatility across various inference
requirements. Alongside this model, we introduce MagnifierBench, an evaluation
framework designed to scrutinize models' ability to discern minute details and
spatial relationships of small objects. Our comparative analysis reveals that
while current leading models falter on this benchmark, OtterHD-8B, particularly
when directly processing high-resolution inputs, outperforms its counterparts
by a substantial margin. The findings illuminate the structural variances in
visual information processing among different models and the influence that the
vision encoders' pre-training resolution disparities have on model
effectiveness within such benchmarks. Our study highlights the critical role of
flexibility and high-resolution input capabilities in large multimodal models
and also exemplifies the potential inherent in the Fuyu architecture's
simplicity for handling complex visual data.
</p>
</div>
</dd>
</dl>
<h3>Cross-lists for Wed,  8 Nov 23</h3>
<dl>
<dt><a name="item368">[368]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03370" title="Abstract">arXiv:2311.03370</a> (cross-list from physics.ao-ph) [<a href="/pdf/2311.03370" title="Download PDF">pdf</a>, <a href="/format/2311.03370" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CMIP X-MOS: Improving Climate Models with Extreme Model Output  Statistics
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Morozov%2C+V">Vsevolod Morozov</a>, 
<a href="/search/physics?searchtype=author&query=Galliamov%2C+A">Artem Galliamov</a>, 
<a href="/search/physics?searchtype=author&query=Lukashevich%2C+A">Aleksandr Lukashevich</a>, 
<a href="/search/physics?searchtype=author&query=Kurdukova%2C+A">Antonina Kurdukova</a>, 
<a href="/search/physics?searchtype=author&query=Maximov%2C+Y">Yury Maximov</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Atmospheric and Oceanic Physics (physics.ao-ph)</span>; Machine Learning (cs.LG); Applications (stat.AP)

</div>
<p class="mathjax">Climate models are essential for assessing the impact of greenhouse gas
emissions on our changing climate and the resulting increase in the frequency
and severity of natural disasters. Despite the widespread acceptance of climate
models produced by the Coupled Model Intercomparison Project (CMIP), they still
face challenges in accurately predicting climate extremes, which pose most
significant threats to both people and the environment. To address this
limitation and improve predictions of natural disaster risks, we introduce
Extreme Model Output Statistics (X-MOS). This approach utilizes deep regression
techniques to precisely map CMIP model outputs to real measurements obtained
from weather stations, which results in a more accurate analysis of the XXI
climate extremes. In contrast to previous research, our study places a strong
emphasis on enhancing the estimation of the tails of future climate parameter
distributions. The latter supports decision-makers, enabling them to better
assess climate-related risks across the globe.
</p>
</div>
</dd>
<dt><a name="item369">[369]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03377" title="Abstract">arXiv:2311.03377</a> (cross-list from physics.med-ph) [<a href="/pdf/2311.03377" title="Download PDF">pdf</a>, <a href="/format/2311.03377" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Fundamental Limits of Light-Wave Sensing for Non-Contact Respiration  Monitoring
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Martin%2C+B">Brenden Martin</a>, 
<a href="/search/physics?searchtype=author&query=Islam%2C+M+Z">Md Zobaer Islam</a>, 
<a href="/search/physics?searchtype=author&query=Gotcher%2C+C">Carly Gotcher</a>, 
<a href="/search/physics?searchtype=author&query=Martinez%2C+T">Tyler Martinez</a>, 
<a href="/search/physics?searchtype=author&query=Ekin%2C+S">Sabit Ekin</a>, 
<a href="/search/physics?searchtype=author&query=O%27Hara%2C+J+F">John F. O&#x27;Hara</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 11 figures (except photos of authors)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Medical Physics (physics.med-ph)</span>; Systems and Control (eess.SY); Optics (physics.optics)

</div>
<p class="mathjax">An experimental testbed has been constructed to assess the capabilities of
Light-Wave Sensing, a promising new vitals monitoring approach. A Light-Wave
Sensing apparatus utilizes infrared radiation to contactlessly monitor the
subtle respiratory motions of a subject from meters away. A
respiration-simulating robot was programmed to produce controllable, humanlike
chest displacement patterns for accuracy analysis. Estimation of respiration
rate within tenths of a breath per minute has been demonstrated with the
testbed, establishing the tenability of the method for use in commercial
non-contact respiration monitoring equipment, and setting practical
expectations on the usable range of this sensing modality. An analytical model
is then presented to guide hardware selection, and used to derive the absolute
range limitations of Light-Wave Sensing.
</p>
</div>
</dd>
<dt><a name="item370">[370]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03378" title="Abstract">arXiv:2311.03378</a> (cross-list from physics.ao-ph) [<a href="/pdf/2311.03378" title="Download PDF">pdf</a>, <a href="/format/2311.03378" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Transferability and explainability of deep learning emulators for  regional climate model projections: Perspectives for future applications
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Bano-Medina%2C+J">Jorge Bano-Medina</a>, 
<a href="/search/physics?searchtype=author&query=Iturbide%2C+M">Maialen Iturbide</a>, 
<a href="/search/physics?searchtype=author&query=Fernandez%2C+J">Jesus Fernandez</a>, 
<a href="/search/physics?searchtype=author&query=Gutierrez%2C+J+M">Jose Manuel Gutierrez</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to Artificial Intelligence for the Earth Systems
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Atmospheric and Oceanic Physics (physics.ao-ph)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Regional climate models (RCMs) are essential tools for simulating and
studying regional climate variability and change. However, their high
computational cost limits the production of comprehensive ensembles of regional
climate projections covering multiple scenarios and driving Global Climate
Models (GCMs) across regions. RCM emulators based on deep learning models have
recently been introduced as a cost-effective and promising alternative that
requires only short RCM simulations to train the models. Therefore, evaluating
their transferability to different periods, scenarios, and GCMs becomes a
pivotal and complex task in which the inherent biases of both GCMs and RCMs
play a significant role. Here we focus on this problem by considering the two
different emulation approaches proposed in the literature (PP and MOS,
following the terminology introduced in this paper). In addition to standard
evaluation techniques, we expand the analysis with methods from the field of
eXplainable Artificial Intelligence (XAI), to assess the physical consistency
of the empirical links learnt by the models. We find that both approaches are
able to emulate certain climatological properties of RCMs for different periods
and scenarios (soft transferability), but the consistency of the emulation
functions differ between approaches. Whereas PP learns robust and physically
meaningful patterns, MOS results are GCM-dependent and lack physical
consistency in some cases. Both approaches face problems when transferring the
emulation function to other GCMs, due to the existence of GCM-dependent biases
(hard transferability). This limits their applicability to build ensembles of
regional climate projections. We conclude by giving some prospects for future
applications.
</p>
</div>
</dd>
<dt><a name="item371">[371]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03389" title="Abstract">arXiv:2311.03389</a> (cross-list from eess.AS) [<a href="/pdf/2311.03389" title="Download PDF">pdf</a>, <a href="/format/2311.03389" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning Disentangled Speech Representations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Brima%2C+Y">Yusuf Brima</a>, 
<a href="/search/eess?searchtype=author&query=Krumnack%2C+U">Ulf Krumnack</a>, 
<a href="/search/eess?searchtype=author&query=Pika%2C+S">Simone Pika</a>, 
<a href="/search/eess?searchtype=author&query=Heidemann%2C+G">Gunther Heidemann</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Machine Learning (cs.LG); Sound (cs.SD)

</div>
<p class="mathjax">Disentangled representation learning from speech remains limited despite its
importance in many application domains. A key challenge is the lack of speech
datasets with known generative factors to evaluate methods. This paper proposes
SynSpeech: a novel synthetic speech dataset with ground truth factors enabling
research on disentangling speech representations. We plan to present a
comprehensive study evaluating supervised techniques using established
supervised disentanglement metrics. This benchmark dataset and framework
address the gap in the rigorous evaluation of state-of-the-art disentangled
speech representation learning methods. Our findings will provide insights to
advance this underexplored area and enable more robust speech representations.
</p>
</div>
</dd>
<dt><a name="item372">[372]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03400" title="Abstract">arXiv:2311.03400</a> (cross-list from quant-ph) [<a href="/pdf/2311.03400" title="Download PDF">pdf</a>, <a href="/format/2311.03400" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> QOMIC: Quantum optimization for motif identification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Ngo%2C+H+M">Hoang M. Ngo</a>, 
<a href="/search/quant-ph?searchtype=author&query=Khatib%2C+T">Tamim Khatib</a>, 
<a href="/search/quant-ph?searchtype=author&query=Thai%2C+M+T">My T. Thai</a>, 
<a href="/search/quant-ph?searchtype=author&query=Kahveci%2C+T">Tamer Kahveci</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Emerging Technologies (cs.ET)

</div>
<p class="mathjax">Network motif identification problem aims to find topological patterns in
biological networks. Identifying non-overlapping motifs is a computationally
challenging problem using classical computers. Quantum computers enable solving
high complexity problems which do not scale using classical computers. In this
paper, we develop the first quantum solution, called QOMIC (Quantum
Optimization for Motif IdentifiCation), to the motif identification problem.
QOMIC transforms the motif identification problem using a integer model, which
serves as the foundation to develop our quantum solution. We develop and
implement the quantum circuit to find motif locations in the given network
using this model. Our experiments demonstrate that QOMIC outperforms the
existing solutions developed for the classical computer, in term of motif
counts. We also observe that QOMIC can efficiently find motifs in human
regulatory networks associated with five neurodegenerative diseases:
Alzheimers, Parkinsons, Huntingtons, Amyotrophic Lateral Sclerosis (ALS), and
Motor Neurone Disease (MND).
</p>
</div>
</dd>
<dt><a name="item373">[373]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03409" title="Abstract">arXiv:2311.03409</a> (cross-list from q-bio.BM) [<a href="/pdf/2311.03409" title="Download PDF">pdf</a>, <a href="/format/2311.03409" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Visualizing DNA reaction trajectories with deep graph embedding  approaches
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-bio?searchtype=author&query=Zhang%2C+C">Chenwei Zhang</a>, 
<a href="/search/q-bio?searchtype=author&query=Duc%2C+K+D">Khanh Dao Duc</a>, 
<a href="/search/q-bio?searchtype=author&query=Condon%2C+A">Anne Condon</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Published in Machine Learning for Structural Biology Workshop, NeurIPS, 2022
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Biomolecules (q-bio.BM)</span>; Artificial Intelligence (cs.AI); Human-Computer Interaction (cs.HC); Machine Learning (cs.LG)

</div>
<p class="mathjax">Synthetic biologists and molecular programmers design novel nucleic acid
reactions, with many potential applications. Good visualization tools are
needed to help domain experts make sense of the complex outputs of folding
pathway simulations of such reactions. Here we present ViDa, a new approach for
visualizing DNA reaction folding trajectories over the energy landscape of
secondary structures. We integrate a deep graph embedding model with common
dimensionality reduction approaches, to map high-dimensional data onto 2D
Euclidean space. We assess ViDa on two well-studied and contrasting DNA
hybridization reactions. Our preliminary results suggest that ViDa's
visualization successfully separates trajectories with different folding
mechanisms, thereby providing useful insight to users, and is a big improvement
over the current state-of-the-art in DNA kinetics visualization.
</p>
</div>
</dd>
<dt><a name="item374">[374]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03411" title="Abstract">arXiv:2311.03411</a> (cross-list from q-bio.QM) [<a href="/pdf/2311.03411" title="Download PDF">pdf</a>, <a href="/format/2311.03411" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ViDa: Visualizing DNA hybridization trajectories with  biophysics-informed deep graph embeddings
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-bio?searchtype=author&query=Zhang%2C+C">Chenwei Zhang</a>, 
<a href="/search/q-bio?searchtype=author&query=Lovrod%2C+J">Jordan Lovrod</a>, 
<a href="/search/q-bio?searchtype=author&query=Beronov%2C+B">Boyan Beronov</a>, 
<a href="/search/q-bio?searchtype=author&query=Duc%2C+K+D">Khanh Dao Duc</a>, 
<a href="/search/q-bio?searchtype=author&query=Condon%2C+A">Anne Condon</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to Machine Learning in Computational Biology as Oral presentation and PMLR acceptance
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantitative Methods (q-bio.QM)</span>; Artificial Intelligence (cs.AI); Human-Computer Interaction (cs.HC); Machine Learning (cs.LG); Biomolecules (q-bio.BM)

</div>
<p class="mathjax">Visualization tools can help synthetic biologists and molecular programmers
understand the complex reactive pathways of nucleic acid reactions, which can
be designed for many potential applications and can be modelled using a
continuous-time Markov chain (CTMC). Here we present ViDa, a new visualization
approach for DNA reaction trajectories that uses a 2D embedding of the
secondary structure state space underlying the CTMC model. To this end, we
integrate a scattering transform of the secondary structure adjacency, a
variational autoencoder, and a nonlinear dimensionality reduction method. We
augment the training loss with domain-specific supervised terms that capture
both thermodynamic and kinetic features. We assess ViDa on two well-studied DNA
hybridization reactions. Our results demonstrate that the domain-specific
features lead to significant quality improvements over the state-of-the-art in
DNA state space visualization, successfully separating different folding
pathways and thus providing useful insights into dominant reaction mechanisms.
</p>
</div>
</dd>
<dt><a name="item375">[375]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03419" title="Abstract">arXiv:2311.03419</a> (cross-list from eess.AS) [<a href="/pdf/2311.03419" title="Download PDF">pdf</a>, <a href="/format/2311.03419" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Personalizing Keyword Spotting with Speaker Information
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Labrador%2C+B">Beltr&#xe1;n Labrador</a>, 
<a href="/search/eess?searchtype=author&query=Zhu%2C+P">Pai Zhu</a>, 
<a href="/search/eess?searchtype=author&query=Zhao%2C+G">Guanlong Zhao</a>, 
<a href="/search/eess?searchtype=author&query=Scarpati%2C+A+S">Angelo Scorza Scarpati</a>, 
<a href="/search/eess?searchtype=author&query=Wang%2C+Q">Quan Wang</a>, 
<a href="/search/eess?searchtype=author&query=Lozano-Diez%2C+A">Alicia Lozano-Diez</a>, 
<a href="/search/eess?searchtype=author&query=Park%2C+A">Alex Park</a>, 
<a href="/search/eess?searchtype=author&query=Moreno%2C+I+L">Ignacio L&#xf3;pez Moreno</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Machine Learning (cs.LG); Sound (cs.SD)

</div>
<p class="mathjax">Keyword spotting systems often struggle to generalize to a diverse population
with various accents and age groups. To address this challenge, we propose a
novel approach that integrates speaker information into keyword spotting using
Feature-wise Linear Modulation (FiLM), a recent method for learning from
multiple sources of information. We explore both Text-Dependent and
Text-Independent speaker recognition systems to extract speaker information,
and we experiment on extracting this information from both the input audio and
pre-enrolled user audio. We evaluate our systems on a diverse dataset and
achieve a substantial improvement in keyword detection accuracy, particularly
among underrepresented speaker groups. Moreover, our proposed approach only
requires a small 1% increase in the number of parameters, with a minimum impact
on latency and computational cost, which makes it a practical solution for
real-world applications.
</p>
</div>
</dd>
<dt><a name="item376">[376]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03421" title="Abstract">arXiv:2311.03421</a> (cross-list from q-bio.NC) [<a href="/pdf/2311.03421" title="Download PDF">pdf</a>, <a href="/ps/2311.03421" title="Download PostScript">ps</a>, <a href="/format/2311.03421" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Hopfield-Enhanced Deep Neural Networks for Artifact-Resilient Brain  State Decoding
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-bio?searchtype=author&query=Marin-Llobet%2C+A">Arnau Marin-Llobet</a>, 
<a href="/search/q-bio?searchtype=author&query=Manasanch%2C+A">Arnau Manasanch</a>, 
<a href="/search/q-bio?searchtype=author&query=Sanchez-Vives%2C+M+V">Maria V. Sanchez-Vives</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neurons and Cognition (q-bio.NC)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">The study of brain states, ranging from highly synchronous to asynchronous
neuronal patterns like the sleep-wake cycle, is fundamental for assessing the
brain's spatiotemporal dynamics and their close connection to behavior.
However, the development of new techniques to accurately identify them still
remains a challenge, as these are often compromised by the presence of noise,
artifacts, and suboptimal recording quality. In this study, we propose a
two-stage computational framework combining Hopfield Networks for artifact data
preprocessing with Convolutional Neural Networks (CNNs) for classification of
brain states in rat neural recordings under different levels of anesthesia. To
evaluate the robustness of our framework, we deliberately introduced noise
artifacts into the neural recordings. We evaluated our hybrid Hopfield-CNN
pipeline by benchmarking it against two comparative models: a standalone CNN
handling the same noisy inputs, and another CNN trained and tested on
artifact-free data. Performance across various levels of data compression and
noise intensities showed that our framework can effectively mitigate artifacts,
allowing the model to reach parity with the clean-data CNN at lower noise
levels. Although this study mainly benefits small-scale experiments, the
findings highlight the necessity for advanced deep learning and Hopfield
Network models to improve scalability and robustness in diverse real-world
settings.
</p>
</div>
</dd>
<dt><a name="item377">[377]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03429" title="Abstract">arXiv:2311.03429</a> (cross-list from q-bio.GN) [<a href="/pdf/2311.03429" title="Download PDF">pdf</a>, <a href="/format/2311.03429" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ProPath: Disease-Specific Protein Language Model for Variant  Pathogenicity
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-bio?searchtype=author&query=Zhan%2C+H">Huixin Zhan</a>, 
<a href="/search/q-bio?searchtype=author&query=Zijun">Zijun</a> (Frank)
<a href="/search/q-bio?searchtype=author&query=Zhang">Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by MLCB 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Genomics (q-bio.GN)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Clinical variant classification of pathogenic versus benign genetic variants
remains a pivotal challenge in clinical genetics. Recently, the proposition of
protein language models has improved the generic variant effect prediction
(VEP) accuracy via weakly-supervised or unsupervised training. However, these
VEPs are not disease-specific, limiting their adaptation at point-of-care. To
address this problem, we propose a disease-specific \textsc{pro}tein language
model for variant \textsc{path}ogenicity, termed ProPath, to capture the
pseudo-log-likelihood ratio in rare missense variants through a siamese
network. We evaluate the performance of ProPath against pre-trained language
models, using clinical variant sets in inherited cardiomyopathies and
arrhythmias that were not seen during training. Our results demonstrate that
ProPath surpasses the pre-trained ESM1b with an over $5\%$ improvement in AUC
across both datasets. Furthermore, our model achieved the highest performances
across all baselines for both datasets. Thus, our ProPath offers a potent
disease-specific variant effect prediction, particularly valuable for disease
associations and clinical applicability.
</p>
</div>
</dd>
<dt><a name="item378">[378]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03469" title="Abstract">arXiv:2311.03469</a> (cross-list from eess.SP) [<a href="/pdf/2311.03469" title="Download PDF">pdf</a>, <a href="/format/2311.03469" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Combinatorial Hodge Theory in Simplicial Signal Processing -- DAFx2023  Lecture Notes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Essl%2C+G">Georg Essl</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 33 pages, 40 figures. arXiv admin note: substantial text overlap with <a href="/abs/2211.05821">arXiv:2211.05821</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Sound (cs.SD); Audio and Speech Processing (eess.AS); Combinatorics (math.CO)

</div>
<p class="mathjax">Lecture notes of a tutorial on Combinatorial Hodge Theory in Simplicial
Signal Processing held at international conference for digital audio effects
(DAFx-23) in Copenhagen, Denmark.
</p>
</div>
</dd>
<dt><a name="item379">[379]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03483" title="Abstract">arXiv:2311.03483</a> (cross-list from math.ST) [<a href="/pdf/2311.03483" title="Download PDF">pdf</a>, <a href="/ps/2311.03483" title="Download PostScript">ps</a>, <a href="/format/2311.03483" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Hebbian learning inspired estimation of the linear regression parameters  from queries
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Schmidt-Hieber%2C+J">Johannes Schmidt-Hieber</a>, 
<a href="/search/math?searchtype=author&query=Koolen%2C+W+M">Wouter M Koolen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 34 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Statistics Theory (math.ST)</span>; Machine Learning (cs.LG); Neural and Evolutionary Computing (cs.NE)

</div>
<p class="mathjax">Local learning rules in biological neural networks (BNNs) are commonly
referred to as Hebbian learning. [26] links a biologically motivated Hebbian
learning rule to a specific zeroth-order optimization method. In this work, we
study a variation of this Hebbian learning rule to recover the regression
vector in the linear regression model. Zeroth-order optimization methods are
known to converge with suboptimal rate for large parameter dimension compared
to first-order methods like gradient descent, and are therefore thought to be
in general inferior. By establishing upper and lower bounds, we show, however,
that such methods achieve near-optimal rates if only queries of the linear
regression loss are available. Moreover, we prove that this Hebbian learning
rule can achieve considerably faster rates than any non-adaptive method that
selects the queries independently of the data.
</p>
</div>
</dd>
<dt><a name="item380">[380]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03500" title="Abstract">arXiv:2311.03500</a> (cross-list from eess.IV) [<a href="/pdf/2311.03500" title="Download PDF">pdf</a>, <a href="/ps/2311.03500" title="Download PostScript">ps</a>, <a href="/format/2311.03500" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Predicting Age from White Matter Diffusivity with Residual Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Gao%2C+C">Chenyu Gao</a>, 
<a href="/search/eess?searchtype=author&query=Kim%2C+M+E">Michael E. Kim</a>, 
<a href="/search/eess?searchtype=author&query=Lee%2C+H+H">Ho Hin Lee</a>, 
<a href="/search/eess?searchtype=author&query=Yang%2C+Q">Qi Yang</a>, 
<a href="/search/eess?searchtype=author&query=Khairi%2C+N+M">Nazirah Mohd Khairi</a>, 
<a href="/search/eess?searchtype=author&query=Kanakaraj%2C+P">Praitayini Kanakaraj</a>, 
<a href="/search/eess?searchtype=author&query=Newlin%2C+N+R">Nancy R. Newlin</a>, 
<a href="/search/eess?searchtype=author&query=Archer%2C+D+B">Derek B. Archer</a>, 
<a href="/search/eess?searchtype=author&query=Jefferson%2C+A+L">Angela L. Jefferson</a>, 
<a href="/search/eess?searchtype=author&query=Taylor%2C+W+D">Warren D. Taylor</a>, 
<a href="/search/eess?searchtype=author&query=Boyd%2C+B+D">Brian D. Boyd</a>, 
<a href="/search/eess?searchtype=author&query=Beason-Held%2C+L+L">Lori L. Beason-Held</a>, 
<a href="/search/eess?searchtype=author&query=Resnick%2C+S+M">Susan M. Resnick</a>, 
The <a href="/search/eess?searchtype=author&query=BIOCARD+Study+Team">BIOCARD Study Team</a>, 
<a href="/search/eess?searchtype=author&query=Huo%2C+Y">Yuankai Huo</a>, 
<a href="/search/eess?searchtype=author&query=Van+Schaik%2C+K+D">Katherine D. Van Schaik</a>, 
<a href="/search/eess?searchtype=author&query=Schilling%2C+K+G">Kurt G. Schilling</a>, 
<a href="/search/eess?searchtype=author&query=Moyer%2C+D">Daniel Moyer</a>, 
<a href="/search/eess?searchtype=author&query=I%C5%A1gum%2C+I">Ivana I&#x161;gum</a>, 
<a href="/search/eess?searchtype=author&query=Landman%2C+B+A">Bennett A. Landman</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> SPIE Medical Imaging: Image Processing. San Diego, CA. February 2024 (accepted as a poster presentation)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV); Neurons and Cognition (q-bio.NC)

</div>
<p class="mathjax">Imaging findings inconsistent with those expected at specific chronological
age ranges may serve as early indicators of neurological disorders and
increased mortality risk. Estimation of chronological age, and deviations from
expected results, from structural MRI data has become an important task for
developing biomarkers that are sensitive to such deviations. Complementary to
structural analysis, diffusion tensor imaging (DTI) has proven effective in
identifying age-related microstructural changes within the brain white matter,
thereby presenting itself as a promising additional modality for brain age
prediction. Although early studies have sought to harness DTI's advantages for
age estimation, there is no evidence that the success of this prediction is
owed to the unique microstructural and diffusivity features that DTI provides,
rather than the macrostructural features that are also available in DTI data.
Therefore, we seek to develop white-matter-specific age estimation to capture
deviations from normal white matter aging. Specifically, we deliberately
disregard the macrostructural information when predicting age from DTI scalar
images, using two distinct methods. The first method relies on extracting only
microstructural features from regions of interest. The second applies 3D
residual neural networks (ResNets) to learn features directly from the images,
which are non-linearly registered and warped to a template to minimize
macrostructural variations. When tested on unseen data, the first method yields
mean absolute error (MAE) of 6.11 years for cognitively normal participants and
MAE of 6.62 years for cognitively impaired participants, while the second
method achieves MAE of 4.69 years for cognitively normal participants and MAE
of 4.96 years for cognitively impaired participants. We find that the ResNet
model captures subtler, non-macrostructural features for brain age prediction.
</p>
</div>
</dd>
<dt><a name="item381">[381]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03508" title="Abstract">arXiv:2311.03508</a> (cross-list from q-bio.NC) [<a href="/pdf/2311.03508" title="Download PDF">pdf</a>, <a href="/format/2311.03508" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Astrocytes as a mechanism for meta-plasticity and contextually-guided  network function
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-bio?searchtype=author&query=Gong%2C+L">Lulu Gong</a>, 
<a href="/search/q-bio?searchtype=author&query=Pasqualetti%2C+F">Fabio Pasqualetti</a>, 
<a href="/search/q-bio?searchtype=author&query=Papouin%2C+T">Thomas Papouin</a>, 
<a href="/search/q-bio?searchtype=author&query=Ching%2C+S">ShiNung Ching</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 40 pages, 14 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neurons and Cognition (q-bio.NC)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Astrocytes are a highly expressed and highly enigmatic cell-type in the
mammalian brain. Traditionally viewed as a mediator of basic physiological
sustenance, it is increasingly recognized that astrocytes may play a more
direct role in neural computation. A conceptual challenge to this idea is the
fact that astrocytic activity takes a very different form than that of neurons,
and in particular, occurs at orders-of-magnitude slower time-scales. In the
current paper, we engage how such time-scale separation may endow astrocytes
with the capability to enable learning in context-dependent settings, where
fluctuations in task parameters may occur much more slowly than within-task
requirements. This idea is based on the recent supposition that astrocytes,
owing to their sensitivity to a host of physiological covariates, may be
particularly well poised to modulate the dynamics of neural circuits in
functionally salient ways. We pose a general model of neural-synaptic-astrocyte
interaction and use formal analysis to characterize how astrocytic modulation
may constitute a form of meta-plasticity, altering the ways in which synapses
and neurons adapt as a function of time. We then embed this model in a
bandit-based reinforcement learning task environment, and show how the presence
of time-scale separated astrocytic modulation enables learning over multiple
fluctuating contexts. Indeed, these networks learn far more reliably versus
dynamically homogenous networks and conventional non-network-based bandit
algorithms. Our results indicate how the presence of neural-astrocyte
interaction in the brain may benefit learning over different time-scale and the
conveyance of task relevant contextual information onto circuit dynamics.
</p>
</div>
</dd>
<dt><a name="item382">[382]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03512" title="Abstract">arXiv:2311.03512</a> (cross-list from quant-ph) [<a href="/pdf/2311.03512" title="Download PDF">pdf</a>, <a href="/ps/2311.03512" title="Download PostScript">ps</a>, <a href="/format/2311.03512" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards the Impossibility of Quantum Public Key Encryption with  Classical Keys from One-Way Functions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Bouaziz--Ermann%2C+S">Samuel Bouaziz--Ermann</a>, 
<a href="/search/quant-ph?searchtype=author&query=Grilo%2C+A+B">Alex B. Grilo</a>, 
<a href="/search/quant-ph?searchtype=author&query=Vergnaud%2C+D">Damien Vergnaud</a>, 
<a href="/search/quant-ph?searchtype=author&query=Vu%2C+Q">Quoc-Huy Vu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Cryptography and Security (cs.CR)

</div>
<p class="mathjax">There has been a recent interest in proposing quantum protocols whose
security relies on weaker computational assumptions than their classical
counterparts. Importantly to our work, it has been recently shown that
public-key encryption (PKE) from one-way functions (OWF) is possible if we
consider quantum public keys. Notice that we do not expect classical PKE from
OWF given the impossibility results of Impagliazzo and Rudich (STOC'89).
However, the distribution of quantum public keys is a challenging task.
Therefore, the main question that motivates our work is if quantum PKE from OWF
is possible if we have classical public keys. Such protocols are impossible if
ciphertexts are also classical, given the impossibility result of Austrin et
al. (CRYPTO'22) of quantum enhanced key-agreement (KA) with classical
communication. In this paper, we focus on black-box separation for PKE with
classical public key and quantum ciphertext from OWF under the polynomial
compatibility conjecture, first introduced in Austrin et al.. More precisely,
we show the separation when the decryption algorithm of the PKE does not query
the OWF. We prove our result by extending the techniques of Austrin et al. and
we show an attack for KA in an extended classical communication model where the
last message in the protocol can be a quantum state.
</p>
</div>
</dd>
<dt><a name="item383">[383]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03578" title="Abstract">arXiv:2311.03578</a> (cross-list from hep-lat) [<a href="/pdf/2311.03578" title="Download PDF">pdf</a>, <a href="/format/2311.03578" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Generative Diffusion Models for Lattice Field Theory
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/hep-lat?searchtype=author&query=Wang%2C+L">Lingxiao Wang</a>, 
<a href="/search/hep-lat?searchtype=author&query=Aarts%2C+G">Gert Aarts</a>, 
<a href="/search/hep-lat?searchtype=author&query=Zhou%2C+K">Kai Zhou</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages, 3 figures, accepted at the NeurIPS 2023 workshop "Machine Learning and the Physical Sciences". Some contents overlap with <a href="/abs/2309.17082">arXiv:2309.17082</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">High Energy Physics - Lattice (hep-lat)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">This study delves into the connection between machine learning and lattice
field theory by linking generative diffusion models (DMs) with stochastic
quantization, from a stochastic differential equation perspective. We show that
DMs can be conceptualized by reversing a stochastic process driven by the
Langevin equation, which then produces samples from an initial distribution to
approximate the target distribution. In a toy model, we highlight the
capability of DMs to learn effective actions. Furthermore, we demonstrate its
feasibility to act as a global sampler for generating configurations in the
two-dimensional $\phi^4$ quantum lattice field theory.
</p>
</div>
</dd>
<dt><a name="item384">[384]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03595" title="Abstract">arXiv:2311.03595</a> (cross-list from econ.GN) [<a href="/pdf/2311.03595" title="Download PDF">pdf</a>, <a href="/format/2311.03595" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Brief for the Canada House of Commons Study on the Implications of  Artificial Intelligence Technologies for the Canadian Labor Force: Generative  Artificial Intelligence Shatters Models of AI and Labor
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/econ?searchtype=author&query=Frank%2C+M+R">Morgan R. Frank</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">General Economics (econ.GN)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Exciting advances in generative artificial intelligence (AI) have sparked
concern for jobs, education, productivity, and the future of work. As with past
technologies, generative AI may not lead to mass unemployment. But, unlike past
technologies, generative AI is creative, cognitive, and potentially ubiquitous
which makes the usual assumptions of automation predictions ill-suited for
today. Existing projections suggest that generative AI will impact workers in
occupations that were previously considered immune to automation. As AI's full
set of capabilities and applications emerge, policy makers should promote
workers' career adaptability. This goal requires improved data on job
separations and unemployment by locality and job titles in order to identify
early-indicators for the workers facing labor disruption. Further, prudent
policy should incentivize education programs to accommodate learning with AI as
a tool while preparing students for the demands of the future of work.
</p>
</div>
</dd>
<dt><a name="item385">[385]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03652" title="Abstract">arXiv:2311.03652</a> (cross-list from physics.ao-ph) [<a href="/pdf/2311.03652" title="Download PDF">pdf</a>, <a href="/format/2311.03652" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Machine Learning Parameterization of the Multi-scale Kain-Fritsch (MSKF)  Convection Scheme
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Zhong%2C+X">Xiaohui Zhong</a>, 
<a href="/search/physics?searchtype=author&query=Yu%2C+X">Xing Yu</a>, 
<a href="/search/physics?searchtype=author&query=Li%2C+H">Hao Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Atmospheric and Oceanic Physics (physics.ao-ph)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Warm-sector heavy rainfall often occurs along the coast of South China, and
it is usually localized and long-lasting, making it challenging to predict.
High-resolution numerical weather prediction (NWP) models are increasingly used
to better resolve topographic features and forecast such high-impact weather
events. However, when the grid spacing becomes comparable to the length scales
of convection, known as the gray zone, the turbulent eddies in the atmospheric
boundary layer are only partially resolved and parameterized to some extent.
Whether using a convection parameterization (CP) scheme in the gray zone
remains controversial. Scale-aware CP schemes are developed to enhance the
representation of convective transport within the gray zone. The multi-scale
Kain-Fritsch (MSKF) scheme includes modifications that allow for its effective
implementation at a grid resolution as high as 2 km. In recent years, there has
been an increasing application of machine learning (ML) models to various
domains of atmospheric sciences, including the replacement of physical
parameterizations with ML models. This work proposes a multi-output
bidirectional long short-term memory (Bi-LSTM) model as a replace the
scale-aware MSKF CP scheme. The Weather Research and Forecast (WRF) model is
used to generate training and testing data over South China at a horizontal
resolution of 5 km. Furthermore, the WRF model is coupled with the ML based CP
scheme and compared with WRF simulations with original MSKF scheme. The results
demonstrate that the Bi-LSTM model can achieve high accuracy, indicating the
potential use of ML models to substitute the MSKF scheme in the gray zone.
</p>
</div>
</dd>
<dt><a name="item386">[386]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03666" title="Abstract">arXiv:2311.03666</a> (cross-list from math.OC) [<a href="/pdf/2311.03666" title="Download PDF">pdf</a>, <a href="/format/2311.03666" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Stochastic Control with Distributionally Robust Constraints for  Cyber-Physical Systems Vulnerable to Attacks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Venkatesh%2C+N">Nishanth Venkatesh</a>, 
<a href="/search/math?searchtype=author&query=Dave%2C+A">Aditya Dave</a>, 
<a href="/search/math?searchtype=author&query=Faros%2C+I">Ioannis Faros</a>, 
<a href="/search/math?searchtype=author&query=Malikopoulos%2C+A+A">Andreas A. Malikopoulos</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 2 Figures with 3 sub-figures each, submitted to the ECC 2024 conference for review
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Systems and Control (eess.SY)

</div>
<p class="mathjax">In this paper, we investigate the control of a cyber-physical system (CPS)
while accounting for its vulnerability to external attacks. We formulate a
constrained stochastic problem with a robust constraint to ensure robust
operation against potential attacks. We seek to minimize the expected cost
subject to a constraint limiting the worst-case expected damage an attacker can
impose on the CPS. We present a dynamic programming decomposition to compute
the optimal control strategy in this robust-constrained formulation and prove
its recursive feasibility. We also illustrate the utility of our results by
applying them to a numerical simulation.
</p>
</div>
</dd>
<dt><a name="item387">[387]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03689" title="Abstract">arXiv:2311.03689</a> (cross-list from math.OC) [<a href="/pdf/2311.03689" title="Download PDF">pdf</a>, <a href="/ps/2311.03689" title="Download PostScript">ps</a>, <a href="/format/2311.03689" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A note on the convergence of the monotone inclusion version of the  primal-dual hybrid gradient algorithm
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Nurbekyan%2C+L">Levon Nurbekyan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Numerical Analysis (math.NA)

</div>
<p class="mathjax">The note contains a direct extension of the Chambolle and Pock convergence
proof of the primal-dual hybrid gradient (PDHG) algorithm to the case of
monotone inclusions.
</p>
</div>
</dd>
<dt><a name="item388">[388]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03694" title="Abstract">arXiv:2311.03694</a> (cross-list from physics.flu-dyn) [<a href="/pdf/2311.03694" title="Download PDF">pdf</a>, <a href="/format/2311.03694" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Accelerating the Galerkin Reduced-Order Model with the Tensor  Decomposition for Turbulent Flows
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Tsai%2C+P">Ping-Hsuan Tsai</a> (1), 
<a href="/search/physics?searchtype=author&query=Fischer%2C+P">Paul Fischer</a> (1), 
<a href="/search/physics?searchtype=author&query=Solomonik%2C+E">Edgar Solomonik</a> (1) ((1) University of Illinois Urbana--Champaign )
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 26 pages, 38 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Fluid Dynamics (physics.flu-dyn)</span>; Numerical Analysis (math.NA)

</div>
<p class="mathjax">Galerkin-based reduced-order models (G-ROMs) have provided efficient and
accurate approximations of laminar flows. In order to capture the complex
dynamics of the turbulent flows, standard G-ROMs require a relatively large
number of reduced basis functions (on the order of hundreds and even
thousands). Although the resulting G-ROM is still relatively low-dimensional
compared to the full-order model (FOM), its computational cost becomes
prohibitive due to the 3rd-order convection tensor contraction. The tensor
requires storage of $N^3$ entries with a corresponding work of $2N^3$
operations per timestep, which makes such ROMs impossible to use in realistic
applications, such as control of turbulent flows. In this paper, we focus on
the scenario where the G-ROM requires large $N$ values and propose a novel
approach that utilizes the CANDECOMC/PARAFAC decomposition (CPD), a tensor
decomposition technique, to accelerate the G-ROM by approximating the 3rd-order
convection tensor by a sum of $R$ rank-1 tensors. In addition, we show that the
tensor is partially skew-symmetric and derive two conditions for the CP
decomposition for preserving the skew-symmetry. Moreover, we investigate the
G-ROM with the singular value decomposition (SVD). The G-ROM with CP
decomposition is investigated in several flow configurations from 2D periodic
flow to 3D turbulent flows. Our numerical investigation shows CPD-ROM achieves
at least a factor of 10 speedup. Additionally, the skew-symmetry preserving
CPD-ROM is more stable and allows the usage of smaller rank $R$. Moreover, from
the singular value behavior, the advection tensor formed using the $H^1_0$-POD
basis has a low-rank structure, and is preserved even in higher Reynolds
numbers. Furthermore, for a given level of accuracy, the CP decomposition is
more efficient in size and cost than the SVD.
</p>
</div>
</dd>
<dt><a name="item389">[389]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03713" title="Abstract">arXiv:2311.03713</a> (cross-list from quant-ph) [<a href="/pdf/2311.03713" title="Download PDF">pdf</a>, <a href="/format/2311.03713" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multimodal deep representation learning for quantum cross-platform  verification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Qian%2C+Y">Yang Qian</a>, 
<a href="/search/quant-ph?searchtype=author&query=Du%2C+Y">Yuxuan Du</a>, 
<a href="/search/quant-ph?searchtype=author&query=He%2C+Z">Zhenliang He</a>, 
<a href="/search/quant-ph?searchtype=author&query=Hsieh%2C+M">Min-hsiu Hsieh</a>, 
<a href="/search/quant-ph?searchtype=author&query=Tao%2C+D">Dacheng Tao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
<p class="mathjax">Cross-platform verification, a critical undertaking in the realm of
early-stage quantum computing, endeavors to characterize the similarity of two
imperfect quantum devices executing identical algorithms, utilizing minimal
measurements. While the random measurement approach has been instrumental in
this context, the quasi-exponential computational demand with increasing qubit
count hurdles its feasibility in large-qubit scenarios. To bridge this
knowledge gap, here we introduce an innovative multimodal learning approach,
recognizing that the formalism of data in this task embodies two distinct
modalities: measurement outcomes and classical description of compiled circuits
on explored quantum devices, both enriched with unique information. Building
upon this insight, we devise a multimodal neural network to independently
extract knowledge from these modalities, followed by a fusion operation to
create a comprehensive data representation. The learned representation can
effectively characterize the similarity between the explored quantum devices
when executing new quantum algorithms not present in the training data. We
evaluate our proposal on platforms featuring diverse noise models, encompassing
system sizes up to 50 qubits. The achieved results demonstrate a
three-orders-of-magnitude improvement in prediction accuracy compared to the
random measurements and offer compelling evidence of the complementary roles
played by each modality in cross-platform verification. These findings pave the
way for harnessing the power of multimodal learning to overcome challenges in
wider quantum system learning tasks.
</p>
</div>
</dd>
<dt><a name="item390">[390]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03723" title="Abstract">arXiv:2311.03723</a> (cross-list from quant-ph) [<a href="/pdf/2311.03723" title="Download PDF">pdf</a>, <a href="/ps/2311.03723" title="Download PostScript">ps</a>, <a href="/format/2311.03723" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Generalized Hybrid Search and Applications to Blockchain and Hash  Function Security
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Cojocaru%2C+A">Alexandru Cojocaru</a>, 
<a href="/search/quant-ph?searchtype=author&query=Garay%2C+J">Juan Garay</a>, 
<a href="/search/quant-ph?searchtype=author&query=Song%2C+F">Fang Song</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Cryptography and Security (cs.CR)

</div>
<p class="mathjax">In this work we first examine the hardness of solving various search problems
by hybrid quantum-classical strategies, namely, by algorithms that have both
quantum and classical capabilities. We then construct a hybrid
quantum-classical search algorithm and analyze its success probability.
Regarding the former, for search problems that are allowed to have multiple
solutions and in which the input is sampled according to arbitrary
distributions we establish their hybrid quantum-classical query complexities --
i.e., given a fixed number of classical and quantum queries, determine what is
the probability of solving the search task. At a technical level, our results
generalize the framework for hybrid quantum-classical search algorithms
proposed by Rosmanis. Namely, for an arbitrary distribution $D$ on Boolean
functions, the probability an algorithm equipped with $\tau_c$ classical and
$\tau_q$ quantum queries succeeds in finding a preimage of $1$ for a function
sampled from $D$ is at most $\nu_D \cdot(2\sqrt{\tau_c} + 2\tau_q + 1)^2$,
where $\nu_D$ captures the average (over $D$) fraction of preimages of $1$. As
applications of our hardness results, we first revisit and generalize the
security of the Bitcoin protocol called the Bitcoin backbone, to a setting
where the adversary has both quantum and classical capabilities, presenting a
new hybrid honest majority condition necessary for the protocol to properly
operate. Secondly, we examine the generic security of hash functions against
hybrid adversaries. Regarding our second contribution, we design a hybrid
algorithm which first spends all of its classical queries and in the second
stage runs a ``modified Grover'' where the initial state depends on the
distribution $D$. We show how to analyze its success probability for arbitrary
target distributions and, importantly, its optimality for the uniform and the
Bernoulli distribution cases.
</p>
</div>
</dd>
<dt><a name="item391">[391]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03724" title="Abstract">arXiv:2311.03724</a> (cross-list from math.OC) [<a href="/pdf/2311.03724" title="Download PDF">pdf</a>, <a href="/ps/2311.03724" title="Download PostScript">ps</a>, <a href="/format/2311.03724" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On convergence analysis of feedback control with integral action and  discontinuous relay perturbation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Ruderman%2C+M">Michael Ruderman</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, 8 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Systems and Control (eess.SY)

</div>
<p class="mathjax">We consider third-order dynamic systems which have integral feedback action
and discontinuous relay disturbance. More specifically for applications, our
focus is on the integral plus state-feedback control of motion systems with
discontinuous Coulomb-type friction. We resume the attractive stiction region,
where the hybrid system has also solutions in Filippov sense and the motion
trajectories remain in an idle state (that we call `stiction') until the
sliding-mode condition becomes violated by an integral action. We analyze the
conditions for occurrence of the slowly converging stick-slip cycles. We also
show that the hybrid system is globally but only asymptotically and almost
always not exponentially stable. A particular case of exponential convergence
can appear for some initial values, assuming the characteristic equation of the
linear subsystem has only the real roots. Illustrative numerical examples are
provided alongside with the developed analysis.
</p>
</div>
</dd>
<dt><a name="item392">[392]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03738" title="Abstract">arXiv:2311.03738</a> (cross-list from astro-ph.SR) [<a href="/pdf/2311.03738" title="Download PDF">pdf</a>, <a href="/format/2311.03738" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> deep-REMAP: Parameterization of Stellar Spectra Using Regularized  Multi-Task Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/astro-ph?searchtype=author&query=Gilda%2C+S">Sankalp Gilda</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 main pages + 2 figures. Accepted to the ML4PS workshop at NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Solar and Stellar Astrophysics (astro-ph.SR)</span>; Astrophysics of Galaxies (astro-ph.GA); Instrumentation and Methods for Astrophysics (astro-ph.IM); Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Traditional spectral analysis methods are increasingly challenged by the
exploding volumes of data produced by contemporary astronomical surveys. In
response, we develop deep-Regularized Ensemble-based Multi-task Learning with
Asymmetric Loss for Probabilistic Inference ($\rm{deep-REMAP}$), a novel
framework that utilizes the rich synthetic spectra from the PHOENIX library and
observational data from the MARVELS survey to accurately predict stellar
atmospheric parameters. By harnessing advanced machine learning techniques,
including multi-task learning and an innovative asymmetric loss function,
$\rm{deep-REMAP}$ demonstrates superior predictive capabilities in determining
effective temperature, surface gravity, and metallicity from observed spectra.
Our results reveal the framework's effectiveness in extending to other stellar
libraries and properties, paving the way for more sophisticated and automated
techniques in stellar characterization.
</p>
</div>
</dd>
<dt><a name="item393">[393]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03757" title="Abstract">arXiv:2311.03757</a> (cross-list from stat.ML) [<a href="/pdf/2311.03757" title="Download PDF">pdf</a>, <a href="/format/2311.03757" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Manifold learning: what, how, and why
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Meil%C4%83%2C+M">Marina Meil&#x103;</a>, 
<a href="/search/stat?searchtype=author&query=Zhang%2C+H">Hanyu Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Manifold learning (ML), known also as non-linear dimension reduction, is a
set of methods to find the low dimensional structure of data. Dimension
reduction for large, high dimensional data is not merely a way to reduce the
data; the new representations and descriptors obtained by ML reveal the
geometric shape of high dimensional point clouds, and allow one to visualize,
de-noise and interpret them. This survey presents the principles underlying ML,
the representative methods, as well as their statistical foundations from a
practicing statistician's perspective. It describes the trade-offs, and what
theory tells us about the parameter and algorithmic choices we make in order to
obtain reliable conclusions.
</p>
</div>
</dd>
<dt><a name="item394">[394]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03821" title="Abstract">arXiv:2311.03821</a> (cross-list from q-bio.NC) [<a href="/pdf/2311.03821" title="Download PDF">pdf</a>, <a href="/format/2311.03821" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Positive Competitive Networks for Sparse Reconstruction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-bio?searchtype=author&query=Centorrino%2C+V">Veronica Centorrino</a>, 
<a href="/search/q-bio?searchtype=author&query=Gokhale%2C+A">Anand Gokhale</a>, 
<a href="/search/q-bio?searchtype=author&query=Davydov%2C+A">Alexander Davydov</a>, 
<a href="/search/q-bio?searchtype=author&query=Russo%2C+G">Giovanni Russo</a>, 
<a href="/search/q-bio?searchtype=author&query=Bullo%2C+F">Francesco Bullo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 25 pages, 10 Figure, 1 Table
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neurons and Cognition (q-bio.NC)</span>; Systems and Control (eess.SY); Optimization and Control (math.OC)

</div>
<p class="mathjax">We propose, and analyze, a continuous-time firing-rate neural network, the
positive firing-rate competitive network (PFCN), to tackle sparse
reconstruction problems with non-negativity constraints. These problems, which
involve approximating a given input stimulus from a dictionary using a set of
sparse (active) neurons, play a key role in a wide range of domains spanning
e.g., neuroscience, signal processing, and machine learning. First, by
leveraging the theory of proximal operators, we introduce a result relating the
equilibria of a family of continuous-time firing-rate neural networks to the
optimal solutions of sparse reconstruction problems. Then, we give rigorous
conditions for the convergence of the PFCN to the equilibrium. Specifically, we
show that the convergence: (i) only depends on a property of the dictionary;
(ii) is linear-exponential, in the sense that initially the convergence rate is
at most linear and then, after a transient, it becomes exponential. To obtain
our main theorem, we also prove a number of technical results to assess certain
contractivity properties of the dynamics of our interest. Finally, we validate
the effectiveness of our approach via a numerical example.
</p>
</div>
</dd>
<dt><a name="item395">[395]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03834" title="Abstract">arXiv:2311.03834</a> (cross-list from physics.soc-ph) [<a href="/pdf/2311.03834" title="Download PDF">pdf</a>, <a href="/format/2311.03834" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Universal productivity patterns in research careers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Sunahara%2C+A+S">Andre S. Sunahara</a>, 
<a href="/search/physics?searchtype=author&query=Perc%2C+M">Matjaz Perc</a>, 
<a href="/search/physics?searchtype=author&query=Ribeiro%2C+H+V">Haroldo V. Ribeiro</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 two-column pages, 2 figures, supplementary information; accepted for publication in Physical Review Research
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Physics and Society (physics.soc-ph)</span>; Social and Information Networks (cs.SI)

</div>
<p class="mathjax">A common expectation is that career productivity peaks rather early and then
gradually declines with seniority. But whether this holds true is still an open
question. Here we investigate the productivity trajectories of almost 8,500
scientists from over fifty disciplines using methods from time series analysis,
dimensionality reduction, and network science, showing that there exist six
universal productivity patterns in research. Based on clusters of productivity
trajectories and network representations where researchers with similar
productivity patterns are connected, we identify constant, u-shaped,
decreasing, periodic-like, increasing, and canonical productivity patterns,
with the latter two describing almost three-fourths of researchers. In fact, we
find that canonical curves are the most prevalent, but contrary to
expectations, productivity peaks occur much more frequently around mid-career
rather than early. These results outline the boundaries of possible career
paths in science and caution against the adoption of stereotypes in tenure and
funding decisions.
</p>
</div>
</dd>
<dt><a name="item396">[396]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03835" title="Abstract">arXiv:2311.03835</a> (cross-list from astro-ph.IM) [<a href="/pdf/2311.03835" title="Download PDF">pdf</a>, <a href="/format/2311.03835" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An operator-splitting numerical scheme for relativistic  magnetohydrodynamics
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/astro-ph?searchtype=author&query=Phillips%2C+D">David Phillips</a>, 
<a href="/search/astro-ph?searchtype=author&query=Komissarov%2C+S">Serguei Komissarov</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to proceedings of Astronum-23 conference
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Instrumentation and Methods for Astrophysics (astro-ph.IM)</span>; High Energy Astrophysical Phenomena (astro-ph.HE); Numerical Analysis (math.NA)

</div>
<p class="mathjax">We describe a novel operator-splitting approach to numerical relativistic
magnetohydrodynamics designed to expand its applicability to the domain of
ultra-high magnetisation. In this approach, the electromagnetic field is split
into the force-free component, governed by the equations of force-free
degenerate electrodynamics (FFDE), and the perturbation component, governed by
the perturbation equations derived from the full system of relativistic
magnetohydrodynamics (RMHD). The combined system of the FFDE and perturbation
equations is integrated simultaneously, for which various numerical techniques
developed for hyperbolic conservation laws can be used. At the end of every
time-step of numerical integration, the force-free and the perturbation
components of the electromagnetic field are recombined and the result is
regarded as the initial value of the force-free component for the next
time-step, whereas the initial value of the perturbation component is set to
zero. To explore the potential of this approach, we build a 3rd-order WENO
code, which was used to carry out 1D and 2D test simulations. Their results
show that this operator-splitting approach allows us to bypass the stiffness of
RMHD in the ultra-high-magnetisation regime where the perturbation component
becomes very small. At the same time, the cod
</p>
</div>
</dd>
<dt><a name="item397">[397]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03845" title="Abstract">arXiv:2311.03845</a> (cross-list from math.OC) [<a href="/pdf/2311.03845" title="Download PDF">pdf</a>, <a href="/format/2311.03845" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On Matrices over a Polynomial Ring with Restricted Subdeterminants
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Celaya%2C+M">Marcel Celaya</a>, 
<a href="/search/math?searchtype=author&query=Kuhlmann%2C+S">Stefan Kuhlmann</a>, 
<a href="/search/math?searchtype=author&query=Weismantel%2C+R">Robert Weismantel</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Data Structures and Algorithms (cs.DS); Combinatorics (math.CO)

</div>
<p class="mathjax">This paper introduces a framework to study discrete optimization problems
which are parametric in the following sense: their constraint matrices
correspond to matrices over the ring $\mathbb{Z}[x]$ of polynomials in one
variable. We investigate in particular matrices whose subdeterminants all lie
in a fixed set $S\subseteq\mathbb{Z}[x]$. Such matrices, which we call totally
$S$-modular matrices, are closed with respect to taking submatrices, so it is
natural to look at minimally non-totally $S$-modular matrices which we call
forbidden minors for $S$. Among other results, we prove that if $S$ is finite,
then the set of all determinants attained by a forbidden minor for $S$ is also
finite. Specializing to the integers, we subsequently obtain the following
positive complexity result: for all but finitely many values of
$a\in\mathbb{Z}$, if a totally $\pm\{0,1,a,a+1,2a+1\}$-modular constraint
matrix has entries in $a$ and $a+1$, then the corresponding recognition problem
and the integer linear optimization problem can be solved in polynomial time.
</p>
</div>
</dd>
<dt><a name="item398">[398]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03884" title="Abstract">arXiv:2311.03884</a> (cross-list from eess.IV) [<a href="/pdf/2311.03884" title="Download PDF">pdf</a>, <a href="/format/2311.03884" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MeVGAN: GAN-based Plugin Model for Video Generation with Applications in  Colonoscopy
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Struski%2C+%C5%81">&#x141;ukasz Struski</a>, 
<a href="/search/eess?searchtype=author&query=Urba%C5%84czyk%2C+T">Tomasz Urba&#x144;czyk</a>, 
<a href="/search/eess?searchtype=author&query=Bucki%2C+K">Krzysztof Bucki</a>, 
<a href="/search/eess?searchtype=author&query=Cupia%C5%82%2C+B">Bart&#x142;omiej Cupia&#x142;</a>, 
<a href="/search/eess?searchtype=author&query=Kaczy%C5%84ska%2C+A">Aneta Kaczy&#x144;ska</a>, 
<a href="/search/eess?searchtype=author&query=Spurek%2C+P">Przemys&#x142;aw Spurek</a>, 
<a href="/search/eess?searchtype=author&query=Tabor%2C+J">Jacek Tabor</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Video generation is important, especially in medicine, as much data is given
in this form. However, video generation of high-resolution data is a very
demanding task for generative models, due to the large need for memory. In this
paper, we propose Memory Efficient Video GAN (MeVGAN) - a Generative
Adversarial Network (GAN) which uses plugin-type architecture. We use a
pre-trained 2D-image GAN and only add a simple neural network to construct
respective trajectories in the noise space, so that the trajectory forwarded
through the GAN model constructs a real-life video. We apply MeVGAN in the task
of generating colonoscopy videos. Colonoscopy is an important medical
procedure, especially beneficial in screening and managing colorectal cancer.
However, because colonoscopy is difficult and time-consuming to learn,
colonoscopy simulators are widely used in educating young colonoscopists. We
show that MeVGAN can produce good quality synthetic colonoscopy videos, which
can be potentially used in virtual simulators.
</p>
</div>
</dd>
<dt><a name="item399">[399]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03906" title="Abstract">arXiv:2311.03906</a> (cross-list from quant-ph) [<a href="/pdf/2311.03906" title="Download PDF">pdf</a>, <a href="/format/2311.03906" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SymPhase: Phase Symbolization for Fast Simulation of Stabilizer Circuits
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Fang%2C+W">Wang Fang</a>, 
<a href="/search/quant-ph?searchtype=author&query=Ying%2C+M">Mingsheng Ying</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, 3 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Emerging Technologies (cs.ET)

</div>
<p class="mathjax">This paper proposes an efficient stabilizer circuit simulation algorithm that
only traverses the circuit forward once. We introduce phase symbolization into
stabilizer generators, which allows possible Pauli faults in the circuit to be
accumulated explicitly as symbolic expressions in the phases of stabilizer
generators. This way, the measurement outcomes are also symbolic expressions,
and we can sample them by substituting the symbolic variables with concrete
values, without traversing the circuit repeatedly. We show how to integrate
symbolic phases into the stabilizer tableau and maintain them efficiently using
bit-vector encoding. A new data layout of the stabilizer tableau in memory is
proposed, which improves the performance of our algorithm (and other stabilizer
simulation algorithms based on the stabilizer tableau). We implement our
algorithm and data layout in a Julia package named \texttt{SymPhase.jl}, and
compare it with Stim, the state-of-the-art simulator, on several benchmarks. We
show that \texttt{SymPhase.jl} has superior performance in terms of sampling
time, which is crucial for generating a large number of samples for further
analysis.
</p>
</div>
</dd>
<dt><a name="item400">[400]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03937" title="Abstract">arXiv:2311.03937</a> (cross-list from physics.soc-ph) [<a href="/pdf/2311.03937" title="Download PDF">pdf</a>, <a href="/format/2311.03937" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Geometry of commutes in the universality of percolating traffic flows
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Ebrahimabadi%2C+S">Sasan Ebrahimabadi</a>, 
<a href="/search/physics?searchtype=author&query=Hosseiny%2C+A">Ali Hosseiny</a>, 
<a href="/search/physics?searchtype=author&query=Fan%2C+J">Jingfang Fan</a>, 
<a href="/search/physics?searchtype=author&query=Saberi%2C+A+A">Abbas Ali Saberi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, 7 Figs, 1 Table (to appear in Phys. Rev. E)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Physics and Society (physics.soc-ph)</span>; Disordered Systems and Neural Networks (cond-mat.dis-nn); Statistical Mechanics (cond-mat.stat-mech); Numerical Analysis (math.NA)

</div>
<p class="mathjax">Traffic congestion is a major problem in megacities which increases vehicle
emissions and degrades ambient air quality. Various models have been developed
to address the universal features of traffic jams. These models range from
micro car-following models to macro collective dynamic models. Here, we study
the macrostructure of congested traffic influenced by the complex geometry of
the commute. Our main focus is on the dynamics of traffic patterns in Paris,
and Los Angeles each with distinct urban structures. We analyze the complexity
of the giant traffic clusters based on a percolation framework during rush
hours in the mornings, evenings, and holidays. We uncover that the universality
described by several critical exponents of traffic patterns is highly
correlated with the geometry of commute and the underlying urban structure. Our
findings might have broad implications for developing a greener, healthier, and
more sustainable future city.
</p>
</div>
</dd>
<dt><a name="item401">[401]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03977" title="Abstract">arXiv:2311.03977</a> (cross-list from quant-ph) [<a href="/pdf/2311.03977" title="Download PDF">pdf</a>, <a href="/ps/2311.03977" title="Download PostScript">ps</a>, <a href="/format/2311.03977" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A quantum central path algorithm for linear optimization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Augustino%2C+B">Brandon Augustino</a>, 
<a href="/search/quant-ph?searchtype=author&query=Leng%2C+J">Jiaqi Leng</a>, 
<a href="/search/quant-ph?searchtype=author&query=Nannicini%2C+G">Giacomo Nannicini</a>, 
<a href="/search/quant-ph?searchtype=author&query=Terlaky%2C+T">Tam&#xe1;s Terlaky</a>, 
<a href="/search/quant-ph?searchtype=author&query=Wu%2C+X">Xiaodi Wu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Data Structures and Algorithms (cs.DS); Optimization and Control (math.OC)

</div>
<p class="mathjax">We propose a novel quantum algorithm for solving linear optimization problems
by quantum-mechanical simulation of the central path. While interior point
methods follow the central path with an iterative algorithm that works with
successive linearizations of the perturbed KKT conditions, we perform a single
simulation working directly with the nonlinear complementarity equations.
Combining our approach with iterative refinement techniques, we obtain an exact
solution to a linear optimization problem involving $m$ constraints and $n$
variables using at most $\mathcal{O} \left( (m + n) \text{nnz} (A) \kappa
(\mathcal{M}) L \cdot \text{polylog} \left(m, n, \kappa (\mathcal{M}) \right)
\right)$ elementary gates and $\mathcal{O} \left( \text{nnz} (A) L \right)$
classical arithmetic operations, where $ \text{nnz} (A)$ is the total number of
non-zero elements found in the constraint matrix, $L$ denotes binary input
length of the problem data, and $\kappa (\mathcal{M})$ is a condition number
that depends only on the problem data.
</p>
</div>
</dd>
<dt><a name="item402">[402]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03992" title="Abstract">arXiv:2311.03992</a> (cross-list from stat.ML) [<a href="/pdf/2311.03992" title="Download PDF">pdf</a>, <a href="/format/2311.03992" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Bandit Pareto Set Identification: the Fixed Budget Setting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Kone%2C+C">Cyrille Kone</a>, 
<a href="/search/stat?searchtype=author&query=Kaufmann%2C+E">Emilie Kaufmann</a>, 
<a href="/search/stat?searchtype=author&query=Richert%2C+L">Laura Richert</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 42 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">We study a multi-objective pure exploration problem in a multi-armed bandit
model. Each arm is associated to an unknown multi-variate distribution and the
goal is to identify the distributions whose mean is not uniformly worse than
that of another distribution: the Pareto optimal set. We propose and analyze
the first algorithms for the \emph{fixed budget} Pareto Set Identification
task. We propose Empirical Gap Elimination, a family of algorithms combining a
careful estimation of the ``hardness to classify'' each arm in or out of the
Pareto set with a generic elimination scheme. We prove that two particular
instances, EGE-SR and EGE-SH, have a probability of error that decays
exponentially fast with the budget, with an exponent supported by an
information theoretic lower-bound. We complement these findings with an
empirical study using real-world and synthetic datasets, which showcase the
good performance of our algorithms.
</p>
</div>
</dd>
<dt><a name="item403">[403]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04008" title="Abstract">arXiv:2311.04008</a> (cross-list from q-fin.RM) [<a href="/pdf/2311.04008" title="Download PDF">pdf</a>, <a href="/format/2311.04008" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Joint model for longitudinal and spatio-temporal survival data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-fin?searchtype=author&query=Medina-Olivares%2C+V">Victor Medina-Olivares</a>, 
<a href="/search/q-fin?searchtype=author&query=Lindgren%2C+F">Finn Lindgren</a>, 
<a href="/search/q-fin?searchtype=author&query=Calabrese%2C+R">Raffaella Calabrese</a>, 
<a href="/search/q-fin?searchtype=author&query=Crook%2C+J">Jonathan Crook</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Risk Management (q-fin.RM)</span>; Computational Engineering, Finance, and Science (cs.CE); Machine Learning (cs.LG); Machine Learning (stat.ML)

</div>
<p class="mathjax">In credit risk analysis, survival models with fixed and time-varying
covariates are widely used to predict a borrower's time-to-event. When the
time-varying drivers are endogenous, modelling jointly the evolution of the
survival time and the endogenous covariates is the most appropriate approach,
also known as the joint model for longitudinal and survival data. In addition
to the temporal component, credit risk models can be enhanced when including
borrowers' geographical information by considering spatial clustering and its
variation over time. We propose the Spatio-Temporal Joint Model (STJM) to
capture spatial and temporal effects and their interaction. This Bayesian
hierarchical joint model reckons the survival effect of unobserved
heterogeneity among borrowers located in the same region at a particular time.
To estimate the STJM model for large datasets, we consider the Integrated
Nested Laplace Approximation (INLA) methodology. We apply the STJM to predict
the time to full prepayment on a large dataset of 57,258 US mortgage borrowers
with more than 2.5 million observations. Empirical results indicate that
including spatial effects consistently improves the performance of the joint
model. However, the gains are less definitive when we additionally include
spatio-temporal interactions.
</p>
</div>
</dd>
<dt><a name="item404">[404]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04035" title="Abstract">arXiv:2311.04035</a> (cross-list from stat.ML) [<a href="/pdf/2311.04035" title="Download PDF">pdf</a>, <a href="/format/2311.04035" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Discordance Minimization-based Imputation Algorithms for Missing Values  in Rating Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Park%2C+Y+W">Young Woong Park</a>, 
<a href="/search/stat?searchtype=author&query=Kim%2C+J">Jinhak Kim</a>, 
<a href="/search/stat?searchtype=author&query=Zhu%2C+D">Dan Zhu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Ratings are frequently used to evaluate and compare subjects in various
applications, from education to healthcare, because ratings provide succinct
yet credible measures for comparing subjects. However, when multiple rating
lists are combined or considered together, subjects often have missing ratings,
because most rating lists do not rate every subject in the combined list. In
this study, we propose analyses on missing value patterns using six real-world
data sets in various applications, as well as the conditions for applicability
of imputation algorithms. Based on the special structures and properties
derived from the analyses, we propose optimization models and algorithms that
minimize the total rating discordance across rating providers to impute missing
ratings in the combined rating lists, using only the known rating information.
The total rating discordance is defined as the sum of the pairwise discordance
metric, which can be written as a quadratic function. Computational experiments
based on real-world and synthetic rating data sets show that the proposed
methods outperform the state-of-the-art general imputation methods in the
literature in terms of imputation accuracy.
</p>
</div>
</dd>
<dt><a name="item405">[405]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04047" title="Abstract">arXiv:2311.04047</a> (cross-list from physics.chem-ph) [<a href="/pdf/2311.04047" title="Download PDF">pdf</a>, <a href="/format/2311.04047" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Extracting human interpretable structure-property relationships in  chemistry using XAI and large language models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Wellawatte%2C+G+P">Geemi P. Wellawatte</a>, 
<a href="/search/physics?searchtype=author&query=Schwaller%2C+P">Philippe Schwaller</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Chemical Physics (physics.chem-ph)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Explainable Artificial Intelligence (XAI) is an emerging field in AI that
aims to address the opaque nature of machine learning models. Furthermore, it
has been shown that XAI can be used to extract input-output relationships,
making them a useful tool in chemistry to understand structure-property
relationships. However, one of the main limitations of XAI methods is that they
are developed for technically oriented users. We propose the XpertAI framework
that integrates XAI methods with large language models (LLMs) accessing
scientific literature to generate accessible natural language explanations of
raw chemical data automatically. We conducted 5 case studies to evaluate the
performance of XpertAI. Our results show that XpertAI combines the strengths of
LLMs and XAI tools in generating specific, scientific, and interpretable
explanations.
</p>
</div>
</dd>
<dt><a name="item406">[406]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04049" title="Abstract">arXiv:2311.04049</a> (cross-list from eess.IV) [<a href="/pdf/2311.04049" title="Download PDF">pdf</a>, <a href="/format/2311.04049" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> 3D EAGAN: 3D edge-aware attention generative adversarial network for  prostate segmentation in transrectal ultrasound images
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Liu%2C+M">Mengqing Liu</a>, 
<a href="/search/eess?searchtype=author&query=Shao%2C+X">Xiao Shao</a>, 
<a href="/search/eess?searchtype=author&query=Jiang%2C+L">Liping Jiang</a>, 
<a href="/search/eess?searchtype=author&query=Wu%2C+K">Kaizhi Wu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Automatic prostate segmentation in TRUS images has always been a challenging
problem, since prostates in TRUS images have ambiguous boundaries and
inhomogeneous intensity distribution. Although many prostate segmentation
methods have been proposed, they still need to be improved due to the lack of
sensibility to edge information. Consequently, the objective of this study is
to devise a highly effective prostate segmentation method that overcomes these
limitations and achieves accurate segmentation of prostates in TRUS images. A
3D edge-aware attention generative adversarial network (3D EAGAN)-based
prostate segmentation method is proposed in this paper, which consists of an
edge-aware segmentation network (EASNet) that performs the prostate
segmentation and a discriminator network that distinguishes predicted prostates
from real prostates. The proposed EASNet is composed of an
encoder-decoder-based U-Net backbone network, a detail compensation module,
four 3D spatial and channel attention modules, an edge enhance module, and a
global feature extractor. The detail compensation module is proposed to
compensate for the loss of detailed information caused by the down-sampling
process of the encoder. The features of the detail compensation module are
selectively enhanced by the 3D spatial and channel attention module.
Furthermore, an edge enhance module is proposed to guide shallow layers in the
EASNet to focus on contour and edge information in prostates. Finally, features
from shallow layers and hierarchical features from the decoder module are fused
through the global feature extractor to predict the segmentation prostates.
</p>
</div>
</dd>
<dt><a name="item407">[407]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04081" title="Abstract">arXiv:2311.04081</a> (cross-list from eess.IV) [<a href="/pdf/2311.04081" title="Download PDF">pdf</a>, <a href="/format/2311.04081" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning Super-Resolution Ultrasound Localization Microscopy from  Radio-Frequency Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Hahne%2C+C">Christopher Hahne</a>, 
<a href="/search/eess?searchtype=author&query=Chabouh%2C+G">Georges Chabouh</a>, 
<a href="/search/eess?searchtype=author&query=Couture%2C+O">Olivier Couture</a>, 
<a href="/search/eess?searchtype=author&query=Sznitman%2C+R">Raphael Sznitman</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> IEEE International Ultrasonics Symposium (IUS), 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV); Medical Physics (physics.med-ph)

</div>
<p class="mathjax">Ultrasound Localization Microscopy (ULM) enables imaging of vascular
structures in the micrometer range by accumulating contrast agent particle
locations over time. Precise and efficient target localization accuracy remains
an active research topic in the ULM field to further push the boundaries of
this promising medical imaging technology. Existing work incorporates
Delay-And-Sum (DAS) beamforming into particle localization pipelines, which
ultimately determines the ULM image resolution capability. In this paper we
propose to feed unprocessed Radio-Frequency (RF) data into a super-resolution
network while bypassing DAS beamforming and its limitations. To facilitate
this, we demonstrate label projection and inverse point transformation between
B-mode and RF coordinate space as required by our approach. We assess our
method against state-of-the-art techniques based on a public dataset featuring
in silico and in vivo data. Results from our RF-trained network suggest that
excluding DAS beamforming offers a great potential to optimize on the ULM
resolution performance.
</p>
</div>
</dd>
<dt><a name="item408">[408]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04135" title="Abstract">arXiv:2311.04135</a> (cross-list from quant-ph) [<a href="/pdf/2311.04135" title="Download PDF">pdf</a>, <a href="/format/2311.04135" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Random Natural Gradient
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Kolotouros%2C+I">Ioannis Kolotouros</a>, 
<a href="/search/quant-ph?searchtype=author&query=Wallden%2C+P">Petros Wallden</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 20 pages, 7 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Data Structures and Algorithms (cs.DS)

</div>
<p class="mathjax">Hybrid quantum-classical algorithms appear to be the most promising approach
for near-term quantum applications. An important bottleneck is the classical
optimization loop, where the multiple local minima and the emergence of barren
plateaux make these approaches less appealing. To improve the optimization the
Quantum Natural Gradient (QNG) method [Quantum 4, 269 (2020)] was introduced -
a method that uses information about the local geometry of the quantum
state-space. While the QNG-based optimization is promising, in each step it
requires more quantum resources, since to compute the QNG one requires $O(m^2)$
quantum state preparations, where $m$ is the number of parameters in the
parameterized circuit. In this work we propose two methods that reduce the
resources/state preparations required for QNG, while keeping the advantages and
performance of the QNG-based optimization. Specifically, we first introduce the
Random Natural Gradient (RNG) that uses random measurements and the classical
Fisher information matrix (as opposed to the quantum Fisher information used in
QNG). The essential quantum resources reduce to linear $O(m)$ and thus offer a
quadratic "speed-up", while in our numerical simulations it matches QNG in
terms of accuracy. We give some theoretical arguments for RNG and then
benchmark the method with the QNG on both classical and quantum problems.
Secondly, inspired by stochastic-coordinate methods, we propose a novel
approximation to the QNG which we call Stochastic-Coordinate Quantum Natural
Gradient that optimizes only a small (randomly sampled) fraction of the total
parameters at each iteration. This method also performs equally well in our
benchmarks, while it uses fewer resources than the QNG.
</p>
</div>
</dd>
<dt><a name="item409">[409]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04153" title="Abstract">arXiv:2311.04153</a> (cross-list from astro-ph.CO) [<a href="/pdf/2311.04153" title="Download PDF">pdf</a>, <a href="/format/2311.04153" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Kernel-, mean- and noise-marginalised Gaussian processes for exoplanet  transits and $H_0$ inference
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/astro-ph?searchtype=author&query=Kroupa%2C+N">Namu Kroupa</a>, 
<a href="/search/astro-ph?searchtype=author&query=Yallup%2C+D">David Yallup</a>, 
<a href="/search/astro-ph?searchtype=author&query=Handley%2C+W">Will Handley</a>, 
<a href="/search/astro-ph?searchtype=author&query=Hobson%2C+M">Michael Hobson</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 17 pages, 11 figures, submitted to Monthly Notices of the Royal Astronomical Society
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cosmology and Nongalactic Astrophysics (astro-ph.CO)</span>; Earth and Planetary Astrophysics (astro-ph.EP); Instrumentation and Methods for Astrophysics (astro-ph.IM); Machine Learning (cs.LG); Machine Learning (stat.ML)

</div>
<p class="mathjax">Using a fully Bayesian approach, Gaussian Process regression is extended to
include marginalisation over the kernel choice and kernel hyperparameters. In
addition, Bayesian model comparison via the evidence enables direct kernel
comparison. The calculation of the joint posterior was implemented with a
transdimensional sampler which simultaneously samples over the discrete kernel
choice and their hyperparameters by embedding these in a higher-dimensional
space, from which samples are taken using nested sampling. This method was
explored on synthetic data from exoplanet transit light curve simulations. The
true kernel was recovered in the low noise region while no kernel was preferred
for larger noise. Furthermore, inference of the physical exoplanet
hyperparameters was conducted. In the high noise region, either the bias in the
posteriors was removed, the posteriors were broadened or the accuracy of the
inference was increased. In addition, the uncertainty in mean function
predictive distribution increased due to the uncertainty in the kernel choice.
Subsequently, the method was extended to marginalisation over mean functions
and noise models and applied to the inference of the present-day Hubble
parameter, $H_0$, from real measurements of the Hubble parameter as a function
of redshift, derived from the cosmologically model-independent cosmic
chronometer and {\Lambda}CDM-dependent baryon acoustic oscillation
observations. The inferred $H_0$ values from the cosmic chronometers, baryon
acoustic oscillations and combined datasets are $H_0$ = 66$\pm$6 km/s/Mpc,
$H_0$ = 67$\pm$10 km/s/Mpc and $H_0$ = 69$\pm$6 km/s/Mpc, respectively. The
kernel posterior of the cosmic chronometers dataset prefers a non-stationary
linear kernel. Finally, the datasets are shown to be not in tension with
ln(R)=12.17$\pm$0.02.
</p>
</div>
</dd>
<dt><a name="item410">[410]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04161" title="Abstract">arXiv:2311.04161</a> (cross-list from math.OC) [<a href="/pdf/2311.04161" title="Download PDF">pdf</a>, <a href="/format/2311.04161" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Breaking the Heavy-Tailed Noise Barrier in Stochastic Optimization  Problems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Puchkin%2C+N">Nikita Puchkin</a>, 
<a href="/search/math?searchtype=author&query=Gorbunov%2C+E">Eduard Gorbunov</a>, 
<a href="/search/math?searchtype=author&query=Kutuzov%2C+N">Nikolay Kutuzov</a>, 
<a href="/search/math?searchtype=author&query=Gasnikov%2C+A">Alexander Gasnikov</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 62 pages, 2 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Data Structures and Algorithms (cs.DS); Machine Learning (cs.LG); Statistics Theory (math.ST)

</div>
<p class="mathjax">We consider stochastic optimization problems with heavy-tailed noise with
structured density. For such problems, we show that it is possible to get
faster rates of convergence than $\mathcal{O}(K^{-2(\alpha - 1)/\alpha})$, when
the stochastic gradients have finite moments of order $\alpha \in (1, 2]$. In
particular, our analysis allows the noise norm to have an unbounded
expectation. To achieve these results, we stabilize stochastic gradients, using
smoothed medians of means. We prove that the resulting estimates have
negligible bias and controllable variance. This allows us to carefully
incorporate them into clipped-SGD and clipped-SSTM and derive new
high-probability complexity bounds in the considered setup.
</p>
</div>
</dd>
</dl>
<h3>Replacements for Wed,  8 Nov 23</h3>
<dl>
<dt><a name="item411">[411]</a>&nbsp;  <span class="list-identifier"><a href="/abs/1903.07993" title="Abstract">arXiv:1903.07993</a> (replaced) [<a href="/pdf/1903.07993" title="Download PDF">pdf</a>, <a href="/format/1903.07993" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Parameter Synthesis for Markov Models: Covering the Parameter Space
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Junges%2C+S">Sebastian Junges</a>, 
<a href="/search/cs?searchtype=author&query=%C3%81brah%C3%A1m%2C+E">Erika &#xc1;brah&#xe1;m</a>, 
<a href="/search/cs?searchtype=author&query=Hensel%2C+C">Christian Hensel</a>, 
<a href="/search/cs?searchtype=author&query=Jansen%2C+N">Nils Jansen</a>, 
<a href="/search/cs?searchtype=author&query=Katoen%2C+J">Joost-Pieter Katoen</a>, 
<a href="/search/cs?searchtype=author&query=Quatmann%2C+T">Tim Quatmann</a>, 
<a href="/search/cs?searchtype=author&query=Volk%2C+M">Matthias Volk</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 86 pages. Preprint of accepted FMSD Journal Paper
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>; Systems and Control (eess.SY)

</div>
</div>
</dd>
<dt><a name="item412">[412]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2001.11906" title="Abstract">arXiv:2001.11906</a> (replaced) [<a href="/pdf/2001.11906" title="Download PDF">pdf</a>, <a href="/format/2001.11906" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Zeta Functions and the (Linear) Logic of Markov Processes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Seiller%2C+T">Thomas Seiller</a> (CNRS, LIPN)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>; Dynamical Systems (math.DS); Logic (math.LO); Probability (math.PR)

</div>
</div>
</dd>
<dt><a name="item413">[413]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2004.14254" title="Abstract">arXiv:2004.14254</a> (replaced) [<a href="/pdf/2004.14254" title="Download PDF">pdf</a>, <a href="/ps/2004.14254" title="Download PostScript">ps</a>, <a href="/format/2004.14254" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Hierarchical Reinforcement Learning for Automatic Disease Diagnosis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhong%2C+C">Cheng Zhong</a>, 
<a href="/search/cs?searchtype=author&query=Liao%2C+K">Kangenbei Liao</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+W">Wei Chen</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Q">Qianlong Liu</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+B">Baolin Peng</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+X">Xuanjing Huang</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+J">Jiajie Peng</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+Z">Zhongyu Wei</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, 3 figures, 4 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computation and Language (cs.CL)

</div>
</div>
</dd>
<dt><a name="item414">[414]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2007.04874" title="Abstract">arXiv:2007.04874</a> (replaced) [<a href="/pdf/2007.04874" title="Download PDF">pdf</a>, <a href="/ps/2007.04874" title="Download PostScript">ps</a>, <a href="/format/2007.04874" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CompRes: A Dataset for Narrative Structure in News
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Levi%2C+E">Effi Levi</a>, 
<a href="/search/cs?searchtype=author&query=Mor%2C+G">Guy Mor</a>, 
<a href="/search/cs?searchtype=author&query=Shenhav%2C+S">Shaul Shenhav</a>, 
<a href="/search/cs?searchtype=author&query=Sheafer%2C+T">Tamir Sheafer</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Please refer to a more recent and updated paper (and a link to the dataset) at <a href="/abs/2210.03028">arXiv:2210.03028</a>. Accpted to the First Joint Workshop on Narrative Understanding, Storylines, and Events, ACL 2020
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item415">[415]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2012.04634" title="Abstract">arXiv:2012.04634</a> (replaced) [<a href="/pdf/2012.04634" title="Download PDF">pdf</a>, <a href="/format/2012.04634" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Accurate 3D Object Detection using Energy-Based Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gustafsson%2C+F+K">Fredrik K. Gustafsson</a>, 
<a href="/search/cs?searchtype=author&query=Danelljan%2C+M">Martin Danelljan</a>, 
<a href="/search/cs?searchtype=author&query=Sch%C3%B6n%2C+T+B">Thomas B. Sch&#xf6;n</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> CVPR Workshops 2021. Code is available at <a href="https://github.com/fregu856/ebms_3dod">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG); Robotics (cs.RO); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item416">[416]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2012.08026" title="Abstract">arXiv:2012.08026</a> (replaced) [<a href="/e-print/2012.08026" title="Download source">src</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Classification of Smoking and Calling using Deep Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+M">Miaowei Wang</a>, 
<a href="/search/cs?searchtype=author&query=Mohacey%2C+A+W">Alexander William Mohacey</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Hongyu Wang</a>, 
<a href="/search/cs?searchtype=author&query=Apfel%2C+J">James Apfel</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This paper is not well-prepared for the peer-review accept
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item417">[417]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2101.02320" title="Abstract">arXiv:2101.02320</a> (replaced) [<a href="/pdf/2101.02320" title="Download PDF">pdf</a>, <a href="/format/2101.02320" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Scale-free tree network with an ultra-large diameter
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Ma%2C+F">Fei Ma</a>, 
<a href="/search/math?searchtype=author&query=Wang%2C+P">Ping Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Combinatorics (math.CO)</span>; Discrete Mathematics (cs.DM)

</div>
</div>
</dd>
<dt><a name="item418">[418]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2110.00604" title="Abstract">arXiv:2110.00604</a> (replaced) [<a href="/pdf/2110.00604" title="Download PDF">pdf</a>, <a href="/format/2110.00604" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Inexact bilevel stochastic gradient methods for constrained and  unconstrained lower-level problems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Giovannelli%2C+T">Tommaso Giovannelli</a>, 
<a href="/search/math?searchtype=author&query=Kent%2C+G+D">Griffin Dean Kent</a>, 
<a href="/search/math?searchtype=author&query=Vicente%2C+L+N">Luis Nunes Vicente</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Machine Learning (cs.LG); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item419">[419]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2110.11048" title="Abstract">arXiv:2110.11048</a> (replaced) [<a href="/pdf/2110.11048" title="Download PDF">pdf</a>, <a href="/format/2110.11048" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> K-Lane: Lidar Lane Dataset and Benchmark for Urban Roads and Highways
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Paek%2C+D">Donghee Paek</a>, 
<a href="/search/cs?searchtype=author&query=Kong%2C+S">Seung-Hyun Kong</a>, 
<a href="/search/cs?searchtype=author&query=Wijaya%2C+K+T">Kevin Tirta Wijaya</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 20 pages, 20 figures, 11 tables
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> 2022 IEEE/CVF Conference on Computer Vision and Pattern
  Recognition (CVPR) Workshop on Autonomous Driving (WAD)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Robotics (cs.RO)

</div>
</div>
</dd>
<dt><a name="item420">[420]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2110.11948" title="Abstract">arXiv:2110.11948</a> (replaced) [<a href="/pdf/2110.11948" title="Download PDF">pdf</a>, <a href="/format/2110.11948" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning Proposals for Practical Energy-Based Regression
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gustafsson%2C+F+K">Fredrik K. Gustafsson</a>, 
<a href="/search/cs?searchtype=author&query=Danelljan%2C+M">Martin Danelljan</a>, 
<a href="/search/cs?searchtype=author&query=Sch%C3%B6n%2C+T+B">Thomas B. Sch&#xf6;n</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> AISTATS 2022. Code is available at <a href="https://github.com/fregu856/ebms_proposals">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item421">[421]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2111.11104" title="Abstract">arXiv:2111.11104</a> (replaced) [<a href="/pdf/2111.11104" title="Download PDF">pdf</a>, <a href="/format/2111.11104" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Hierarchical Text Classification As Sub-Hierarchy Sequence Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Im%2C+S">SangHun Im</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+G">Gibaeg Kim</a>, 
<a href="/search/cs?searchtype=author&query=Oh%2C+H">Heung-Seon Oh</a>, 
<a href="/search/cs?searchtype=author&query=Jo%2C+S">Seongung Jo</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+D">Donghwan Kim</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages, 5 figures, Published at AAAI23
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Proceedings of the AAAI Conference on Artificial Intelligence,
  37(11), 12933-12941 (2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item422">[422]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2112.08440" title="Abstract">arXiv:2112.08440</a> (replaced) [<a href="/pdf/2112.08440" title="Download PDF">pdf</a>, <a href="/format/2112.08440" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Climate-Invariant Machine Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Beucler%2C+T">Tom Beucler</a>, 
<a href="/search/cs?searchtype=author&query=Gentine%2C+P">Pierre Gentine</a>, 
<a href="/search/cs?searchtype=author&query=Yuval%2C+J">Janni Yuval</a>, 
<a href="/search/cs?searchtype=author&query=Gupta%2C+A">Ankitesh Gupta</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+L">Liran Peng</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+J">Jerry Lin</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+S">Sungduk Yu</a>, 
<a href="/search/cs?searchtype=author&query=Rasp%2C+S">Stephan Rasp</a>, 
<a href="/search/cs?searchtype=author&query=Ahmed%2C+F">Fiaz Ahmed</a>, 
<a href="/search/cs?searchtype=author&query=O%27Gorman%2C+P+A">Paul A. O&#x27;Gorman</a>, 
<a href="/search/cs?searchtype=author&query=Neelin%2C+J+D">J. David Neelin</a>, 
<a href="/search/cs?searchtype=author&query=Lutsko%2C+N+J">Nicholas J. Lutsko</a>, 
<a href="/search/cs?searchtype=author&query=Pritchard%2C+M">Michael Pritchard</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 30+30 pages, 8+15 figures, 1+3 tables in the main text + supplementary materials. Submitted to Science Advances on July 12th, 2023. Revised on Nov 6th, 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Atmospheric and Oceanic Physics (physics.ao-ph); Computational Physics (physics.comp-ph)

</div>
</div>
</dd>
<dt><a name="item423">[423]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2203.03897" title="Abstract">arXiv:2203.03897</a> (replaced) [<a href="/pdf/2203.03897" title="Download PDF">pdf</a>, <a href="/format/2203.03897" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Geodesic Multi-Modal Mixup for Robust Fine-Tuning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Oh%2C+C">Changdae Oh</a>, 
<a href="/search/cs?searchtype=author&query=So%2C+J">Junhyuk So</a>, 
<a href="/search/cs?searchtype=author&query=Byun%2C+H">Hoyoon Byun</a>, 
<a href="/search/cs?searchtype=author&query=Lim%2C+Y">YongTaek Lim</a>, 
<a href="/search/cs?searchtype=author&query=Shin%2C+M">Minchul Shin</a>, 
<a href="/search/cs?searchtype=author&query=Jeon%2C+J">Jong-June Jeon</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+K">Kyungwoo Song</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To appear at NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Computation and Language (cs.CL); Information Retrieval (cs.IR); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item424">[424]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2203.13908" title="Abstract">arXiv:2203.13908</a> (replaced) [<a href="/pdf/2203.13908" title="Download PDF">pdf</a>, <a href="/format/2203.13908" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On efficient algorithms for computing near-best polynomial  approximations to high-dimensional, Hilbert-valued functions from limited  samples
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Adcock%2C+B">Ben Adcock</a>, 
<a href="/search/math?searchtype=author&query=Brugiapaglia%2C+S">Simone Brugiapaglia</a>, 
<a href="/search/math?searchtype=author&query=Dexter%2C+N">Nick Dexter</a>, 
<a href="/search/math?searchtype=author&query=Moraga%2C+S">Sebastian Moraga</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item425">[425]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2203.16664" title="Abstract">arXiv:2203.16664</a> (replaced) [<a href="/pdf/2203.16664" title="Download PDF">pdf</a>, <a href="/ps/2203.16664" title="Download PostScript">ps</a>, <a href="/format/2203.16664" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Semi-explicit integration of second order for weakly coupled  poroelasticity
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Altmann%2C+R">R. Altmann</a>, 
<a href="/search/math?searchtype=author&query=Maier%2C+R">R. Maier</a>, 
<a href="/search/math?searchtype=author&query=Unger%2C+B">B. Unger</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
</div>
</dd>
<dt><a name="item426">[426]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2204.10581" title="Abstract">arXiv:2204.10581</a> (replaced) [<a href="/pdf/2204.10581" title="Download PDF">pdf</a>, <a href="/format/2204.10581" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FAIR4Cov: Fused Audio Instance and Representation for COVID-19 Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Truong%2C+T">Tuan Truong</a>, 
<a href="/search/cs?searchtype=author&query=Lenga%2C+M">Matthias Lenga</a>, 
<a href="/search/cs?searchtype=author&query=Serrurier%2C+A">Antoine Serrurier</a>, 
<a href="/search/cs?searchtype=author&query=Mohammadi%2C+S">Sadegh Mohammadi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Audio and Speech Processing (eess.AS)

</div>
</div>
</dd>
<dt><a name="item427">[427]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2205.01141" title="Abstract">arXiv:2205.01141</a> (replaced) [<a href="/pdf/2205.01141" title="Download PDF">pdf</a>, <a href="/format/2205.01141" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Efficient quantum algorithm for nonlinear reaction-diffusion equations  and energy estimation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=An%2C+D">Dong An</a>, 
<a href="/search/quant-ph?searchtype=author&query=Fang%2C+D">Di Fang</a>, 
<a href="/search/quant-ph?searchtype=author&query=Jordan%2C+S">Stephen Jordan</a>, 
<a href="/search/quant-ph?searchtype=author&query=Liu%2C+J">Jin-Peng Liu</a>, 
<a href="/search/quant-ph?searchtype=author&query=Low%2C+G+H">Guang Hao Low</a>, 
<a href="/search/quant-ph?searchtype=author&query=Wang%2C+J">Jiasu Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 61 pages, 5 figures. Published in Communications in Mathematical Physics
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Mathematical Physics (math-ph); Numerical Analysis (math.NA)

</div>
</div>
</dd>
<dt><a name="item428">[428]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2205.02901" title="Abstract">arXiv:2205.02901</a> (replaced) [<a href="/pdf/2205.02901" title="Download PDF">pdf</a>, <a href="/format/2205.02901" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Geometric Methods for Adjoint Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Tran%2C+B">Brian Tran</a>, 
<a href="/search/math?searchtype=author&query=Leok%2C+M">Melvin Leok</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 61 pages, 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Numerical Analysis (math.NA); Symplectic Geometry (math.SG)

</div>
</div>
</dd>
<dt><a name="item429">[429]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2205.15623" title="Abstract">arXiv:2205.15623</a> (replaced) [<a href="/pdf/2205.15623" title="Download PDF">pdf</a>, <a href="/format/2205.15623" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> k-Means Maximum Entropy Exploration
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nedergaard%2C+A">Alexander Nedergaard</a>, 
<a href="/search/cs?searchtype=author&query=Cook%2C+M">Matthew Cook</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item430">[430]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2206.04507" title="Abstract">arXiv:2206.04507</a> (replaced) [<a href="/pdf/2206.04507" title="Download PDF">pdf</a>, <a href="/ps/2206.04507" title="Download PostScript">ps</a>, <a href="/format/2206.04507" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Software Mitigation of RISC-V Spectre Attacks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=B%C4%83lucea%2C+R">Ruxandra B&#x103;lucea</a>, 
<a href="/search/cs?searchtype=author&query=Irofti%2C+P">Paul Irofti</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Operating Systems (cs.OS)

</div>
</div>
</dd>
<dt><a name="item431">[431]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2206.08171" title="Abstract">arXiv:2206.08171</a> (replaced) [<a href="/pdf/2206.08171" title="Download PDF">pdf</a>, <a href="/format/2206.08171" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> K-Radar: 4D Radar Object Detection for Autonomous Driving in Various  Weather Conditions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Paek%2C+D">Dong-Hee Paek</a>, 
<a href="/search/cs?searchtype=author&query=Kong%2C+S">Seung-Hyun Kong</a>, 
<a href="/search/cs?searchtype=author&query=Wijaya%2C+K+T">Kevin Tirta Wijaya</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at NeurIPS 2022 Datasets and Benchmarks Track
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Proceedings of the Neural Information Processing Systems Track on
  Datasets and Benchmarks (NeurIPS Datasets and Benchmarks 2022)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item432">[432]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2206.09798" title="Abstract">arXiv:2206.09798</a> (replaced) [<a href="/pdf/2206.09798" title="Download PDF">pdf</a>, <a href="/format/2206.09798" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Using Sum-Product Networks to Assess Uncertainty in Deep Active Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Khosravani%2C+M">Mohamadsadegh Khosravani</a>, 
<a href="/search/cs?searchtype=author&query=Zilles%2C+S">Sandra Zilles</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 15 pages,9 figures, 4 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Information Theory (cs.IT)

</div>
</div>
</dd>
<dt><a name="item433">[433]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2206.10540" title="Abstract">arXiv:2206.10540</a> (replaced) [<a href="/pdf/2206.10540" title="Download PDF">pdf</a>, <a href="/format/2206.10540" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Rethinking Symbolic Regression Datasets and Benchmarks for Scientific  Discovery
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Matsubara%2C+Y">Yoshitomo Matsubara</a>, 
<a href="/search/cs?searchtype=author&query=Chiba%2C+N">Naoya Chiba</a>, 
<a href="/search/cs?searchtype=author&query=Igarashi%2C+R">Ryo Igarashi</a>, 
<a href="/search/cs?searchtype=author&query=Ushiku%2C+Y">Yoshitaka Ushiku</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Preprint. Code and datasets are available at <a href="https://github.com/omron-sinicx/srsd-benchmark">this https URL</a> <a href="https://huggingface.co/datasets/yoshitomo-matsubara/srsd-feynman_easy">this https URL</a> <a href="https://huggingface.co/datasets/yoshitomo-matsubara/srsd-feynman_medium">this https URL</a> <a href="https://huggingface.co/datasets/yoshitomo-matsubara/srsd-feynman_hard">this https URL</a> and another three sets of SRSD datasets with dummy variables (See Appendix)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Neural and Evolutionary Computing (cs.NE); Symbolic Computation (cs.SC)

</div>
</div>
</dd>
<dt><a name="item434">[434]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2206.15251" title="Abstract">arXiv:2206.15251</a> (replaced) [<a href="/pdf/2206.15251" title="Download PDF">pdf</a>, <a href="/ps/2206.15251" title="Download PostScript">ps</a>, <a href="/format/2206.15251" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Menger&#x27;s Theorem for Temporal Paths (Not Walks)
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ibiapina%2C+A">Allen Ibiapina</a>, 
<a href="/search/cs?searchtype=author&query=Lopes%2C+R">Raul Lopes</a>, 
<a href="/search/cs?searchtype=author&query=Marino%2C+A">Andrea Marino</a>, 
<a href="/search/cs?searchtype=author&query=Silva%2C+A">Ana Silva</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Discrete Mathematics (cs.DM)</span>; Combinatorics (math.CO)

</div>
</div>
</dd>
<dt><a name="item435">[435]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2207.02062" title="Abstract">arXiv:2207.02062</a> (replaced) [<a href="/pdf/2207.02062" title="Download PDF">pdf</a>, <a href="/format/2207.02062" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Image Amodal Completion: A Survey
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ao%2C+J">Jiayang Ao</a>, 
<a href="/search/cs?searchtype=author&query=Ke%2C+Q">Qiuhong Ke</a>, 
<a href="/search/cs?searchtype=author&query=Ehinger%2C+K+A">Krista A. Ehinger</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at Computer Vision and Image Understanding. See <a href="https://doi.org/10.1016/j.cviu.2023.103661">this https URL</a> for the final version
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item436">[436]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2207.04591" title="Abstract">arXiv:2207.04591</a> (replaced) [<a href="/pdf/2207.04591" title="Download PDF">pdf</a>, <a href="/format/2207.04591" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Hybrid iLQR Model Predictive Control for Contact Implicit Stabilization  on Legged Robots
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kong%2C+N+J">Nathan J. Kong</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+C">Chuanzheng Li</a>, 
<a href="/search/cs?searchtype=author&query=Johnson%2C+A+M">Aaron M. Johnson</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> in IEEE Transactions on Robotics, 2023. arXiv admin note: substantial text overlap with <a href="/abs/2103.14584">arXiv:2103.14584</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
</div>
</dd>
<dt><a name="item437">[437]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2207.09429" title="Abstract">arXiv:2207.09429</a> (replaced) [<a href="/pdf/2207.09429" title="Download PDF">pdf</a>, <a href="/ps/2207.09429" title="Download PostScript">ps</a>, <a href="/format/2207.09429" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Prior-Independent Auctions for Heterogeneous Bidders
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Guruganesh%2C+G">Guru Guruganesh</a>, 
<a href="/search/cs?searchtype=author&query=Mehta%2C+A">Aranyak Mehta</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+D">Di Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+K">Kangning Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Full version of a paper in the Proceedings of the 2024 Annual ACM-SIAM Symposium on Discrete Algorithms (SODA)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>

</div>
</div>
</dd>
<dt><a name="item438">[438]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2208.06318" title="Abstract">arXiv:2208.06318</a> (replaced) [<a href="/pdf/2208.06318" title="Download PDF">pdf</a>, <a href="/ps/2208.06318" title="Download PostScript">ps</a>, <a href="/format/2208.06318" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Code Summarization of APIs Based on Unofficial Documentation  Using NLP Techniques
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Naghshzan%2C+A">AmirHossein Naghshzan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item439">[439]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2208.14228" title="Abstract">arXiv:2208.14228</a> (replaced) [<a href="/pdf/2208.14228" title="Download PDF">pdf</a>, <a href="/format/2208.14228" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> EasyScale: Accuracy-consistent Elastic Training for Deep Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+M">Mingzhen Li</a>, 
<a href="/search/cs?searchtype=author&query=Xiao%2C+W">Wencong Xiao</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+B">Biao Sun</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+H">Hanyu Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+H">Hailong Yang</a>, 
<a href="/search/cs?searchtype=author&query=Ren%2C+S">Shiru Ren</a>, 
<a href="/search/cs?searchtype=author&query=Luan%2C+Z">Zhongzhi Luan</a>, 
<a href="/search/cs?searchtype=author&query=Jia%2C+X">Xianyan Jia</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yi Liu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yong Li</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+W">Wei Lin</a>, 
<a href="/search/cs?searchtype=author&query=Qian%2C+D">Depei Qian</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To be appeared at SC'23. Link: <a href="https://sc23.supercomputing.org/presentation/?id=pap262">this https URL</a>&amp;sess=sess168
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>

</div>
</div>
</dd>
<dt><a name="item440">[440]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2208.14741" title="Abstract">arXiv:2208.14741</a> (replaced) [<a href="/pdf/2208.14741" title="Download PDF">pdf</a>, <a href="/format/2208.14741" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Failed Goal Aware Hindsight Experience Replay
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kim%2C+T">Taeyoung Kim</a>, 
<a href="/search/cs?searchtype=author&query=Har%2C+D">Dongsoo Har</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> RiTA accepted
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item441">[441]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2208.14960" title="Abstract">arXiv:2208.14960</a> (replaced) [<a href="/pdf/2208.14960" title="Download PDF">pdf</a>, <a href="/format/2208.14960" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Stationary Kernels and Gaussian Processes on Lie Groups and their  Homogeneous Spaces I: the compact case
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Azangulov%2C+I">Iskander Azangulov</a>, 
<a href="/search/stat?searchtype=author&query=Smolensky%2C+A">Andrei Smolensky</a>, 
<a href="/search/stat?searchtype=author&query=Terenin%2C+A">Alexander Terenin</a>, 
<a href="/search/stat?searchtype=author&query=Borovitskiy%2C+V">Viacheslav Borovitskiy</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Methodology (stat.ME)</span>; Machine Learning (cs.LG); Statistics Theory (math.ST); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item442">[442]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2209.01375" title="Abstract">arXiv:2209.01375</a> (replaced) [<a href="/pdf/2209.01375" title="Download PDF">pdf</a>, <a href="/format/2209.01375" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Variational Approach for Joint Image Recovery and Feature Extraction  Based on Spatially-Varying Generalised Gaussian Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chouzenoux%2C+E">Emilie Chouzenoux</a>, 
<a href="/search/cs?searchtype=author&query=Corbineau%2C+M">Marie-Caroline Corbineau</a>, 
<a href="/search/cs?searchtype=author&query=Pesquet%2C+J">Jean-Christophe Pesquet</a>, 
<a href="/search/cs?searchtype=author&query=Scrivanti%2C+G">Gabriele Scrivanti</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Numerical Analysis (math.NA)

</div>
</div>
</dd>
<dt><a name="item443">[443]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2209.06579" title="Abstract">arXiv:2209.06579</a> (replaced) [<a href="/pdf/2209.06579" title="Download PDF">pdf</a>, <a href="/format/2209.06579" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> C^2:Co-design of Robots via Concurrent Networks Coupling Online and  Offline Reinforcement Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+C">Ci Chen</a>, 
<a href="/search/cs?searchtype=author&query=Xiang%2C+P">Pingyu Xiang</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+H">Haojian Lu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yue Wang</a>, 
<a href="/search/cs?searchtype=author&query=Xiong%2C+R">Rong Xiong</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
</div>
</dd>
<dt><a name="item444">[444]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2209.09326" title="Abstract">arXiv:2209.09326</a> (replaced) [<a href="/pdf/2209.09326" title="Download PDF">pdf</a>, <a href="/format/2209.09326" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Sparse Interaction Additive Networks via Feature Interaction Detection  and Sparse Selection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Enouen%2C+J">James Enouen</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yan Liu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item445">[445]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2209.15042" title="Abstract">arXiv:2209.15042</a> (replaced) [<a href="/pdf/2209.15042" title="Download PDF">pdf</a>, <a href="/format/2209.15042" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Generalizability of Adversarial Robustness Under Distribution Shifts
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Alhamoud%2C+K">Kumail Alhamoud</a>, 
<a href="/search/cs?searchtype=author&query=Hammoud%2C+H+A+A+K">Hasan Abed Al Kader Hammoud</a>, 
<a href="/search/cs?searchtype=author&query=Alfarra%2C+M">Motasem Alfarra</a>, 
<a href="/search/cs?searchtype=author&query=Ghanem%2C+B">Bernard Ghanem</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> TMLR 2023 (Featured Certification)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item446">[446]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2210.00901" title="Abstract">arXiv:2210.00901</a> (replaced) [<a href="/pdf/2210.00901" title="Download PDF">pdf</a>, <a href="/format/2210.00901" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the Salient Limitations of the Methods of Assembly Theory and their  Classification of Molecular Biosignatures
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Uthamacumaran%2C+A">Abicumaran Uthamacumaran</a>, 
<a href="/search/cs?searchtype=author&query=Abrah%C3%A3o%2C+F+S">Felipe S. Abrah&#xe3;o</a>, 
<a href="/search/cs?searchtype=author&query=Kiani%2C+N+A">Narsis A. Kiani</a>, 
<a href="/search/cs?searchtype=author&query=Zenil%2C+H">Hector Zenil</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 25 pages + 13 from the appendix, 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>

</div>
</div>
</dd>
<dt><a name="item447">[447]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2210.01984" title="Abstract">arXiv:2210.01984</a> (replaced) [<a href="/pdf/2210.01984" title="Download PDF">pdf</a>, <a href="/ps/2210.01984" title="Download PostScript">ps</a>, <a href="/format/2210.01984" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Manipulation and Peer Mechanisms: A Survey
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Olckers%2C+M">Matthew Olckers</a>, 
<a href="/search/cs?searchtype=author&query=Walsh%2C+T">Toby Walsh</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computer Science and Game Theory (cs.GT); General Economics (econ.GN)

</div>
</div>
</dd>
<dt><a name="item448">[448]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2210.05046" title="Abstract">arXiv:2210.05046</a> (replaced) [<a href="/pdf/2210.05046" title="Download PDF">pdf</a>, <a href="/format/2210.05046" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Data-Driven Feedback Linearization using the Koopman Generator
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Gadginmath%2C+D">Darshan Gadginmath</a>, 
<a href="/search/math?searchtype=author&query=Krishnan%2C+V">Vishaal Krishnan</a>, 
<a href="/search/math?searchtype=author&query=Pasqualetti%2C+F">Fabio Pasqualetti</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Systems and Control (eess.SY)

</div>
</div>
</dd>
<dt><a name="item449">[449]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2210.05431" title="Abstract">arXiv:2210.05431</a> (replaced) [<a href="/pdf/2210.05431" title="Download PDF">pdf</a>, <a href="/format/2210.05431" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Non-Asymptotic Analysis of a UCB-based Top Two Algorithm
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Jourdan%2C+M">Marc Jourdan</a>, 
<a href="/search/stat?searchtype=author&query=Degenne%2C+R">R&#xe9;my Degenne</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 32 pages, 5 figures, 3 tables. To be published in the Thirty-seventh Conference on Neural Information Processing Systems
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item450">[450]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2210.09364" title="Abstract">arXiv:2210.09364</a> (replaced) [<a href="/pdf/2210.09364" title="Download PDF">pdf</a>, <a href="/format/2210.09364" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Probabilistic Categorical Adversarial Attack &amp; Adversarial Training
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+H">Han Xu</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+P">Pengfei He</a>, 
<a href="/search/cs?searchtype=author&query=Ren%2C+J">Jie Ren</a>, 
<a href="/search/cs?searchtype=author&query=Wan%2C+Y">Yuxuan Wan</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zitao Liu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+H">Hui Liu</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+J">Jiliang Tang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Cryptography and Security (cs.CR)

</div>
</div>
</dd>
<dt><a name="item451">[451]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2210.09721" title="Abstract">arXiv:2210.09721</a> (replaced) [<a href="/pdf/2210.09721" title="Download PDF">pdf</a>, <a href="/ps/2210.09721" title="Download PostScript">ps</a>, <a href="/format/2210.09721" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An incremental input-to-state stability condition for a generic class of  recurrent neural networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=D%27Amico%2C+W">William D&#x27;Amico</a>, 
<a href="/search/eess?searchtype=author&query=La+Bella%2C+A">Alessio La Bella</a>, 
<a href="/search/eess?searchtype=author&query=Farina%2C+M">Marcello Farina</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
</div>
</dd>
<dt><a name="item452">[452]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2210.10514" title="Abstract">arXiv:2210.10514</a> (replaced) [<a href="/pdf/2210.10514" title="Download PDF">pdf</a>, <a href="/format/2210.10514" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Future of Consumer Edge-AI Computing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Laskaridis%2C+S">Stefanos Laskaridis</a>, 
<a href="/search/cs?searchtype=author&query=Venieris%2C+S+I">Stylianos I. Venieris</a>, 
<a href="/search/cs?searchtype=author&query=Kouris%2C+A">Alexandros Kouris</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+R">Rui Li</a>, 
<a href="/search/cs?searchtype=author&query=Lane%2C+N+D">Nicholas D. Lane</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Under review
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item453">[453]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2210.11877" title="Abstract">arXiv:2210.11877</a> (replaced) [<a href="/pdf/2210.11877" title="Download PDF">pdf</a>, <a href="/format/2210.11877" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Multi-Arm Robotic Platform for Scientific Exploration
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Marinho%2C+M+M">Murilo Marques Marinho</a>, 
<a href="/search/cs?searchtype=author&query=Quiroz-Oma%C3%B1a%2C+J+J">Juan Jos&#xe9; Quiroz-Oma&#xf1;a</a>, 
<a href="/search/cs?searchtype=author&query=Harada%2C+K">Kanako Harada</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted on RAM 2023, 10 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
</div>
</dd>
<dt><a name="item454">[454]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2210.12040" title="Abstract">arXiv:2210.12040</a> (replaced) [<a href="/pdf/2210.12040" title="Download PDF">pdf</a>, <a href="/ps/2210.12040" title="Download PostScript">ps</a>, <a href="/format/2210.12040" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Neuro-Symbolic Causal Reasoning Meets Signaling Game for Emergent  Semantic Communications
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Thomas%2C+C+K">Christo Kurisummoottil Thomas</a>, 
<a href="/search/cs?searchtype=author&query=Saad%2C+W">Walid Saad</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computation and Language (cs.CL); Information Theory (cs.IT)

</div>
</div>
</dd>
<dt><a name="item455">[455]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2210.16534" title="Abstract">arXiv:2210.16534</a> (replaced) [<a href="/pdf/2210.16534" title="Download PDF">pdf</a>, <a href="/ps/2210.16534" title="Download PostScript">ps</a>, <a href="/format/2210.16534" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Improved Approximation Algorithms for Capacitated Vehicle Routing with  Fixed Capacity
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhao%2C+J">Jingyang Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Xiao%2C+M">Mingyu Xiao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>

</div>
</div>
</dd>
<dt><a name="item456">[456]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2211.03392" title="Abstract">arXiv:2211.03392</a> (replaced) [<a href="/pdf/2211.03392" title="Download PDF">pdf</a>, <a href="/ps/2211.03392" title="Download PostScript">ps</a>, <a href="/format/2211.03392" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A tight upper bound on the number of non-zero weights of a quasi-cyclic  code
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xiaoxiao Li</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+M">Minjia Shi</a>, 
<a href="/search/cs?searchtype=author&query=Ling%2C+S">San Ling</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>

</div>
</div>
</dd>
<dt><a name="item457">[457]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2211.03418" title="Abstract">arXiv:2211.03418</a> (replaced) [<a href="/pdf/2211.03418" title="Download PDF">pdf</a>, <a href="/ps/2211.03418" title="Download PostScript">ps</a>, <a href="/format/2211.03418" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Quantum Radiance Fields: A Quantum-Powered Photorealistic Rendering
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">YuanFu Yang</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+M">Min Sun</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item458">[458]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2211.03584" title="Abstract">arXiv:2211.03584</a> (replaced) [<a href="/pdf/2211.03584" title="Download PDF">pdf</a>, <a href="/ps/2211.03584" title="Download PostScript">ps</a>, <a href="/format/2211.03584" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MARS: Message Passing for Antenna and RF Chain Selection for Hybrid  Beamforming in MIMO Communication Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shen%2C+L">Li-Hsiang Shen</a>, 
<a href="/search/cs?searchtype=author&query=Lo%2C+Y">Yen-Chun Lo</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+K">Kai-Ten Feng</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+S">Sau-Hsuan Wu</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+L">Lie-Liang Yang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
</div>
</dd>
<dt><a name="item459">[459]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2211.05536" title="Abstract">arXiv:2211.05536</a> (replaced) [<a href="/pdf/2211.05536" title="Download PDF">pdf</a>, <a href="/format/2211.05536" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Data-based Transfer Stabilization in Linear Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Li%2C+L">Lidong Li</a>, 
<a href="/search/eess?searchtype=author&query=De+Persis%2C+C">Claudio De Persis</a>, 
<a href="/search/eess?searchtype=author&query=Tesi%2C+P">Pietro Tesi</a>, 
<a href="/search/eess?searchtype=author&query=Monshizadeh%2C+N">Nima Monshizadeh</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Optimization and Control (math.OC)

</div>
</div>
</dd>
<dt><a name="item460">[460]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2211.05608" title="Abstract">arXiv:2211.05608</a> (replaced) [<a href="/pdf/2211.05608" title="Download PDF">pdf</a>, <a href="/format/2211.05608" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Finitary Simulation of Infinitary $&#x3b2;$-Reduction via Taylor  Expansion, and Applications
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cerda%2C+R">R&#xe9;my Cerda</a>, 
<a href="/search/cs?searchtype=author&query=Auclair%2C+L+V">Lionel Vaux Auclair</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 44 pages. Accepted by Logical Methods in Computer Science
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>; Logic (math.LO)

</div>
</div>
</dd>
<dt><a name="item461">[461]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2211.10955" title="Abstract">arXiv:2211.10955</a> (replaced) [<a href="/pdf/2211.10955" title="Download PDF">pdf</a>, <a href="/format/2211.10955" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> When Noisy Labels Meet Long Tail Dilemmas: A Representation Calibration  Method
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+M">Manyi Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+X">Xuyang Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Yao%2C+J">Jun Yao</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+C">Chun Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+W">Weiran Huang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted as an ICCV 2023 oral paper
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item462">[462]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2211.13709" title="Abstract">arXiv:2211.13709</a> (replaced) [<a href="/pdf/2211.13709" title="Download PDF">pdf</a>, <a href="/format/2211.13709" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Undesirable biases in NLP: Addressing challenges of measurement
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=van+der+Wal%2C+O">Oskar van der Wal</a>, 
<a href="/search/cs?searchtype=author&query=Bachmann%2C+D">Dominik Bachmann</a>, 
<a href="/search/cs?searchtype=author&query=Leidinger%2C+A">Alina Leidinger</a>, 
<a href="/search/cs?searchtype=author&query=van+Maanen%2C+L">Leendert van Maanen</a>, 
<a href="/search/cs?searchtype=author&query=Zuidema%2C+W">Willem Zuidema</a>, 
<a href="/search/cs?searchtype=author&query=Schulz%2C+K">Katrin Schulz</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item463">[463]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2211.14317" title="Abstract">arXiv:2211.14317</a> (replaced) [<a href="/pdf/2211.14317" title="Download PDF">pdf</a>, <a href="/format/2211.14317" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Hard to Track Objects with Irregular Motions and Similar Appearances?  Make It Easier by Buffering the Matching Space
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+F">Fan Yang</a>, 
<a href="/search/cs?searchtype=author&query=Odashima%2C+S">Shigeyuki Odashima</a>, 
<a href="/search/cs?searchtype=author&query=Masui%2C+S">Shoichi Masui</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+S">Shan Jiang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to WACV 2023. arXiv admin note: text overlap with <a href="/abs/2211.13509">arXiv:2211.13509</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> wacv 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Multimedia (cs.MM)

</div>
</div>
</dd>
<dt><a name="item464">[464]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2211.16412" title="Abstract">arXiv:2211.16412</a> (replaced) [<a href="/pdf/2211.16412" title="Download PDF">pdf</a>, <a href="/format/2211.16412" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Procedural Image Programs for Representation Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Baradad%2C+M">Manel Baradad</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+C">Chun-Fu Chen</a>, 
<a href="/search/cs?searchtype=author&query=Wulff%2C+J">Jonas Wulff</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+T">Tongzhou Wang</a>, 
<a href="/search/cs?searchtype=author&query=Feris%2C+R">Rogerio Feris</a>, 
<a href="/search/cs?searchtype=author&query=Torralba%2C+A">Antonio Torralba</a>, 
<a href="/search/cs?searchtype=author&query=Isola%2C+P">Phillip Isola</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 29 pages, Accepted in the Conference on Neural Information Processing Systems 2022 (NeurIPS 2022)
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> NeurIPS 2022
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item465">[465]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2211.16583" title="Abstract">arXiv:2211.16583</a> (replaced) [<a href="/pdf/2211.16583" title="Download PDF">pdf</a>, <a href="/format/2211.16583" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Offline Policy Evaluation and Optimization under Confounding
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Kausik%2C+C">Chinmaya Kausik</a>, 
<a href="/search/stat?searchtype=author&query=Lu%2C+Y">Yangyi Lu</a>, 
<a href="/search/stat?searchtype=author&query=Tan%2C+K">Kevin Tan</a>, 
<a href="/search/stat?searchtype=author&query=Makar%2C+M">Maggie Makar</a>, 
<a href="/search/stat?searchtype=author&query=Wang%2C+Y">Yixin Wang</a>, 
<a href="/search/stat?searchtype=author&query=Tewari%2C+A">Ambuj Tewari</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Overhauled terminology and presentation, strengthened presentation of results
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item466">[466]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2212.01545" title="Abstract">arXiv:2212.01545</a> (replaced) [<a href="/pdf/2212.01545" title="Download PDF">pdf</a>, <a href="/format/2212.01545" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Generalized Scalarization Method for Evolutionary Multi-Objective  Optimization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zheng%2C+R">Ruihao Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zhenkun Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Correct some typos. (Accepted for presentation at Thirty-Seventh AAAI Conference on Artificial Intelligence (AAAI-23))
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neural and Evolutionary Computing (cs.NE)</span>

</div>
</div>
</dd>
<dt><a name="item467">[467]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2212.04922" title="Abstract">arXiv:2212.04922</a> (replaced) [<a href="/pdf/2212.04922" title="Download PDF">pdf</a>, <a href="/format/2212.04922" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Doubly Robust Kernel Statistics for Testing Distributional Treatment  Effects
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Fawkes%2C+J">Jake Fawkes</a>, 
<a href="/search/stat?searchtype=author&query=Hu%2C+R">Robert Hu</a>, 
<a href="/search/stat?searchtype=author&query=Evans%2C+R+J">Robin J. Evans</a>, 
<a href="/search/stat?searchtype=author&query=Sejdinovic%2C+D">Dino Sejdinovic</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, Preprint
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item468">[468]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2212.05404" title="Abstract">arXiv:2212.05404</a> (replaced) [<a href="/pdf/2212.05404" title="Download PDF">pdf</a>, <a href="/format/2212.05404" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Cap2Aug: Caption guided Image to Image data Augmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Roy%2C+A">Aniket Roy</a>, 
<a href="/search/cs?searchtype=author&query=Shah%2C+A">Anshul Shah</a>, 
<a href="/search/cs?searchtype=author&query=Shah%2C+K">Ketul Shah</a>, 
<a href="/search/cs?searchtype=author&query=Roy%2C+A">Anirban Roy</a>, 
<a href="/search/cs?searchtype=author&query=Chellappa%2C+R">Rama Chellappa</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item469">[469]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2212.08324" title="Abstract">arXiv:2212.08324</a> (replaced) [<a href="/pdf/2212.08324" title="Download PDF">pdf</a>, <a href="/format/2212.08324" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Mobile Augmented Reality with Federated Learning in the Metaverse
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhou%2C+X">Xinyu Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+J">Jun Zhao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Cryptography and Security (cs.CR)

</div>
</div>
</dd>
<dt><a name="item470">[470]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2212.09462" title="Abstract">arXiv:2212.09462</a> (replaced) [<a href="/pdf/2212.09462" title="Download PDF">pdf</a>, <a href="/format/2212.09462" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Latent Diffusion for Language Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lovelace%2C+J">Justin Lovelace</a>, 
<a href="/search/cs?searchtype=author&query=Kishore%2C+V">Varsha Kishore</a>, 
<a href="/search/cs?searchtype=author&query=Wan%2C+C">Chao Wan</a>, 
<a href="/search/cs?searchtype=author&query=Shekhtman%2C+E">Eliot Shekhtman</a>, 
<a href="/search/cs?searchtype=author&query=Weinberger%2C+K+Q">Kilian Q. Weinberger</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item471">[471]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2212.11111" title="Abstract">arXiv:2212.11111</a> (replaced) [<a href="/pdf/2212.11111" title="Download PDF">pdf</a>, <a href="/format/2212.11111" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Splitting Schemes for Coupled Differential Equations: Block Schur-Based  Approaches and Partial Jacobi Approximation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Nuca%2C+R">Roberto Nuca</a>, 
<a href="/search/math?searchtype=author&query=Storvik%2C+E">Erlend Storvik</a>, 
<a href="/search/math?searchtype=author&query=Radu%2C+F+A">Florin A. Radu</a>, 
<a href="/search/math?searchtype=author&query=Icardi%2C+M">Matteo Icardi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Computational Physics (physics.comp-ph)

</div>
</div>
</dd>
<dt><a name="item472">[472]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2212.12317" title="Abstract">arXiv:2212.12317</a> (replaced) [<a href="/pdf/2212.12317" title="Download PDF">pdf</a>, <a href="/format/2212.12317" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Matching Cuts in Graphs of High Girth and H-Free Graphs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Feghali%2C+C">Carl Feghali</a>, 
<a href="/search/math?searchtype=author&query=Lucke%2C+F">Felicia Lucke</a>, 
<a href="/search/math?searchtype=author&query=Paulusma%2C+D">Daniel Paulusma</a>, 
<a href="/search/math?searchtype=author&query=Ries%2C+B">Bernard Ries</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Combinatorics (math.CO)</span>; Computational Complexity (cs.CC); Discrete Mathematics (cs.DM); Data Structures and Algorithms (cs.DS)

</div>
</div>
</dd>
<dt><a name="item473">[473]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2212.13519" title="Abstract">arXiv:2212.13519</a> (replaced) [<a href="/pdf/2212.13519" title="Download PDF">pdf</a>, <a href="/format/2212.13519" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Electrochemical transport modelling and open-source simulation of  pore-scale solid-liquid systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Barnett%2C+R">Robert Barnett</a>, 
<a href="/search/math?searchtype=author&query=Municchi%2C+F">Federico Municchi</a>, 
<a href="/search/math?searchtype=author&query=King%2C+J">John King</a>, 
<a href="/search/math?searchtype=author&query=Icardi%2C+M">Matteo Icardi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Computational Physics (physics.comp-ph); Fluid Dynamics (physics.flu-dyn)

</div>
</div>
</dd>
<dt><a name="item474">[474]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.03338" title="Abstract">arXiv:2301.03338</a> (replaced) [<a href="/pdf/2301.03338" title="Download PDF">pdf</a>, <a href="/format/2301.03338" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Topologically Regularized Data Embeddings
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Heiter%2C+E">Edith Heiter</a>, 
<a href="/search/cs?searchtype=author&query=Vandaele%2C+R">Robin Vandaele</a>, 
<a href="/search/cs?searchtype=author&query=De+Bie%2C+T">Tijl De Bie</a>, 
<a href="/search/cs?searchtype=author&query=Saeys%2C+Y">Yvan Saeys</a>, 
<a href="/search/cs?searchtype=author&query=Lijffijt%2C+J">Jefrey Lijffijt</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 52 pages, preprint, under review
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item475">[475]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.09702" title="Abstract">arXiv:2301.09702</a> (replaced) [<a href="/pdf/2301.09702" title="Download PDF">pdf</a>, <a href="/format/2301.09702" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Illumination Variation Correction Using Image Synthesis For Unsupervised  Domain Adaptive Person Re-Identification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Guo%2C+J">Jiaqi Guo</a>, 
<a href="/search/eess?searchtype=author&query=Reibman%2C+A+R">Amy R. Reibman</a>, 
<a href="/search/eess?searchtype=author&query=Delp%2C+E+J">Edward J. Delp</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 5 figures, 5 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item476">[476]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.09881" title="Abstract">arXiv:2301.09881</a> (replaced) [<a href="/pdf/2301.09881" title="Download PDF">pdf</a>, <a href="/format/2301.09881" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fever: Optimal Responsive View Synchronisation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lewis-Pye%2C+A">Andrew Lewis-Pye</a>, 
<a href="/search/cs?searchtype=author&query=Abraham%2C+I">Ittai Abraham</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>

</div>
</div>
</dd>
<dt><a name="item477">[477]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.10884" title="Abstract">arXiv:2301.10884</a> (replaced) [<a href="/pdf/2301.10884" title="Download PDF">pdf</a>, <a href="/format/2301.10884" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Break It Down: Evidence for Structural Compositionality in Neural  Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lepori%2C+M+A">Michael A. Lepori</a>, 
<a href="/search/cs?searchtype=author&query=Serre%2C+T">Thomas Serre</a>, 
<a href="/search/cs?searchtype=author&query=Pavlick%2C+E">Ellie Pavlick</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item478">[478]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.03679" title="Abstract">arXiv:2302.03679</a> (replaced) [<a href="/pdf/2302.03679" title="Download PDF">pdf</a>, <a href="/format/2302.03679" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> How Reliable is Your Regression Model&#x27;s Uncertainty Under Real-World  Distribution Shifts?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gustafsson%2C+F+K">Fredrik K. Gustafsson</a>, 
<a href="/search/cs?searchtype=author&query=Danelljan%2C+M">Martin Danelljan</a>, 
<a href="/search/cs?searchtype=author&query=Sch%C3%B6n%2C+T+B">Thomas B. Sch&#xf6;n</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> TMLR, 2023. Code is available at <a href="https://github.com/fregu856/regression_uncertainty">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item479">[479]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.04178" title="Abstract">arXiv:2302.04178</a> (replaced) [<a href="/pdf/2302.04178" title="Download PDF">pdf</a>, <a href="/format/2302.04178" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DynGFN: Towards Bayesian Inference of Gene Regulatory Networks with  GFlowNets
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Atanackovic%2C+L">Lazar Atanackovic</a>, 
<a href="/search/cs?searchtype=author&query=Tong%2C+A">Alexander Tong</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+B">Bo Wang</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+L+J">Leo J. Lee</a>, 
<a href="/search/cs?searchtype=author&query=Bengio%2C+Y">Yoshua Bengio</a>, 
<a href="/search/cs?searchtype=author&query=Hartford%2C+J">Jason Hartford</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item480">[480]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.07025" title="Abstract">arXiv:2302.07025</a> (replaced) [<a href="/pdf/2302.07025" title="Download PDF">pdf</a>, <a href="/format/2302.07025" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Optimal Transport for Change Detection on LiDAR Point Clouds
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fiorucci%2C+M">Marco Fiorucci</a>, 
<a href="/search/cs?searchtype=author&query=Naylor%2C+P">Peter Naylor</a>, 
<a href="/search/cs?searchtype=author&query=Yamada%2C+M">Makoto Yamada</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This project has received funding from the European Union's Horizon 2020 research and innovation programme under grant agreement No101027956
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> IGARSS 2023 - 2023 IEEE International Geoscience and Remote
  Sensing Symposium, Pasadena, CA, USA, 2023, pp. 982-985
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG); Image and Video Processing (eess.IV)

</div>
</div>
</dd>
<dt><a name="item481">[481]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.09043" title="Abstract">arXiv:2302.09043</a> (replaced) [<a href="/pdf/2302.09043" title="Download PDF">pdf</a>, <a href="/format/2302.09043" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Self-Supervised Representation Learning from Temporal Ordering of  Automated Driving Sequences
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lang%2C+C">Christopher Lang</a>, 
<a href="/search/cs?searchtype=author&query=Braun%2C+A">Alexander Braun</a>, 
<a href="/search/cs?searchtype=author&query=Schillingmann%2C+L">Lars Schillingmann</a>, 
<a href="/search/cs?searchtype=author&query=Haug%2C+K">Karsten Haug</a>, 
<a href="/search/cs?searchtype=author&query=Valada%2C+A">Abhinav Valada</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 7 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item482">[482]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.11522" title="Abstract">arXiv:2302.11522</a> (replaced) [<a href="/pdf/2302.11522" title="Download PDF">pdf</a>, <a href="/ps/2302.11522" title="Download PostScript">ps</a>, <a href="/format/2302.11522" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Evaluation of Extra Pixel Interpolation with Mask Processing for Medical  Image Segmentation with Deep Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Rukundo%2C+O">Olivier Rukundo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages, 10 figure, 7 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item483">[483]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.12000" title="Abstract">arXiv:2302.12000</a> (replaced) [<a href="/pdf/2302.12000" title="Download PDF">pdf</a>, <a href="/format/2302.12000" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Graph Construction using Principal Axis Trees for Simple Graph  Convolution
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Alshammari%2C+M">Mashaan Alshammari</a>, 
<a href="/search/cs?searchtype=author&query=Stavrakakis%2C+J">John Stavrakakis</a>, 
<a href="/search/cs?searchtype=author&query=Ahmed%2C+A+F">Adel F. Ahmed</a>, 
<a href="/search/cs?searchtype=author&query=Takatsuka%2C+M">Masahiro Takatsuka</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Information Retrieval (cs.IR); Neural and Evolutionary Computing (cs.NE)

</div>
</div>
</dd>
<dt><a name="item484">[484]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.13976" title="Abstract">arXiv:2302.13976</a> (replaced) [<a href="/pdf/2302.13976" title="Download PDF">pdf</a>, <a href="/ps/2302.13976" title="Download PostScript">ps</a>, <a href="/format/2302.13976" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Counterexample to the L&#xe9;vy Flight Foraging Hypothesis in the Narrow  Capture Framework
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cond-mat?searchtype=author&query=Tzou%2C+J+C">J.C. Tzou</a>, 
<a href="/search/cond-mat?searchtype=author&query=Tzou%2C+L">Leo Tzou</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Statistical Mechanics (cond-mat.stat-mech)</span>; Numerical Analysis (math.NA)

</div>
</div>
</dd>
<dt><a name="item485">[485]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.00307" title="Abstract">arXiv:2303.00307</a> (replaced) [<a href="/pdf/2303.00307" title="Download PDF">pdf</a>, <a href="/format/2303.00307" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Access-based Lightweight Physical Layer Authentication for the Internet  of Things Devices
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Khan%2C+S">Saud Khan</a>, 
<a href="/search/cs?searchtype=author&query=Thapa%2C+C">Chandra Thapa</a>, 
<a href="/search/cs?searchtype=author&query=Durrani%2C+S">Salman Durrani</a>, 
<a href="/search/cs?searchtype=author&query=Camtepe%2C+S">Seyit Camtepe</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted for publication in IEEE Internet of Things Journal
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Networking and Internet Architecture (cs.NI); Signal Processing (eess.SP)

</div>
</div>
</dd>
<dt><a name="item486">[486]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.00333" title="Abstract">arXiv:2303.00333</a> (replaced) [<a href="/pdf/2303.00333" title="Download PDF">pdf</a>, <a href="/format/2303.00333" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Competence-Based Analysis of Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Davies%2C+A">Adam Davies</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+J">Jize Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Zhai%2C+C">ChengXiang Zhai</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item487">[487]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.03283" title="Abstract">arXiv:2303.03283</a> (replaced) [<a href="/pdf/2303.03283" title="Download PDF">pdf</a>, <a href="/format/2303.03283" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The AI Ghostwriter Effect: When Users Do Not Perceive Ownership of  AI-Generated Text But Self-Declare as Authors
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Draxler%2C+F">Fiona Draxler</a>, 
<a href="/search/cs?searchtype=author&query=Werner%2C+A">Anna Werner</a>, 
<a href="/search/cs?searchtype=author&query=Lehmann%2C+F">Florian Lehmann</a>, 
<a href="/search/cs?searchtype=author&query=Hoppe%2C+M">Matthias Hoppe</a>, 
<a href="/search/cs?searchtype=author&query=Schmidt%2C+A">Albrecht Schmidt</a>, 
<a href="/search/cs?searchtype=author&query=Buschek%2C+D">Daniel Buschek</a>, 
<a href="/search/cs?searchtype=author&query=Welsch%2C+R">Robin Welsch</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Pre-print; currently under review
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Computation and Language (cs.CL)

</div>
</div>
</dd>
<dt><a name="item488">[488]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.06596" title="Abstract">arXiv:2303.06596</a> (replaced) [<a href="/pdf/2303.06596" title="Download PDF">pdf</a>, <a href="/format/2303.06596" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Amodal Intra-class Instance Segmentation: Synthetic Datasets and  Benchmark
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ao%2C+J">Jiayang Ao</a>, 
<a href="/search/cs?searchtype=author&query=Ke%2C+Q">Qiuhong Ke</a>, 
<a href="/search/cs?searchtype=author&query=Ehinger%2C+K+A">Krista A. Ehinger</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at WACV 2024. Datasets are available at <a href="https://github.com/saraao/amodal-dataset">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item489">[489]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.09354" title="Abstract">arXiv:2303.09354</a> (replaced) [<a href="/pdf/2303.09354" title="Download PDF">pdf</a>, <a href="/format/2303.09354" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The NCI Imaging Data Commons as a platform for reproducible research in  computational pathology
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Schacherer%2C+D+P">Daniela P. Schacherer</a>, 
<a href="/search/cs?searchtype=author&query=Herrmann%2C+M+D">Markus D. Herrmann</a>, 
<a href="/search/cs?searchtype=author&query=Clunie%2C+D+A">David A. Clunie</a>, 
<a href="/search/cs?searchtype=author&query=H%C3%B6fener%2C+H">Henning H&#xf6;fener</a>, 
<a href="/search/cs?searchtype=author&query=Clifford%2C+W">William Clifford</a>, 
<a href="/search/cs?searchtype=author&query=Longabaugh%2C+W+J+R">William J.R. Longabaugh</a>, 
<a href="/search/cs?searchtype=author&query=Pieper%2C+S">Steve Pieper</a>, 
<a href="/search/cs?searchtype=author&query=Kikinis%2C+R">Ron Kikinis</a>, 
<a href="/search/cs?searchtype=author&query=Fedorov%2C+A">Andrey Fedorov</a>, 
<a href="/search/cs?searchtype=author&query=Homeyer%2C+A">Andr&#xe9; Homeyer</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, 5 figures; improved manuscript, new experiments with P100 GPU
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Comput Methods Programs Biomed (2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item490">[490]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.10093" title="Abstract">arXiv:2303.10093</a> (replaced) [<a href="/pdf/2303.10093" title="Download PDF">pdf</a>, <a href="/format/2303.10093" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Investigating the Role of Attribute Context in Vision-Language Models  for Object Recognition and Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Buettner%2C+K">Kyle Buettner</a>, 
<a href="/search/cs?searchtype=author&query=Kovashka%2C+A">Adriana Kovashka</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at Winter Conference on Applications of Computer Vision (WACV), 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item491">[491]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.12040" title="Abstract">arXiv:2303.12040</a> (replaced) [<a href="/pdf/2303.12040" title="Download PDF">pdf</a>, <a href="/ps/2303.12040" title="Download PostScript">ps</a>, <a href="/format/2303.12040" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Roots and Requirements for Collaborative AIs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Stefik%2C+M">Mark Stefik</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 24 pages, 2 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
</div>
</dd>
<dt><a name="item492">[492]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.13764" title="Abstract">arXiv:2303.13764</a> (replaced) [<a href="/pdf/2303.13764" title="Download PDF">pdf</a>, <a href="/format/2303.13764" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GQE-Net: A Graph-based Quality Enhancement Network for Point Cloud Color  Attribute
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Xing%2C+J">Jinrui Xing</a>, 
<a href="/search/eess?searchtype=author&query=Yuan%2C+H">Hui Yuan</a>, 
<a href="/search/eess?searchtype=author&query=Hamzaoui%2C+R">Raouf Hamzaoui</a>, 
<a href="/search/eess?searchtype=author&query=Liu%2C+H">Hao Liu</a>, 
<a href="/search/eess?searchtype=author&query=Hou%2C+J">Junhui Hou</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by IEEE TIP (DOI: 10.1109/TIP.2023.3330086)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item493">[493]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.15714" title="Abstract">arXiv:2303.15714</a> (replaced) [<a href="/pdf/2303.15714" title="Download PDF">pdf</a>, <a href="/format/2303.15714" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Explicit Planning Helps Language Models in Logical Reasoning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhao%2C+H">Hongyu Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+K">Kangrui Wang</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+M">Mo Yu</a>, 
<a href="/search/cs?searchtype=author&query=Mei%2C+H">Hongyuan Mei</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> EMNLP 2023 camera-ready; updated results on PrOntoQA with code bugs fixed
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item494">[494]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.16258" title="Abstract">arXiv:2303.16258</a> (replaced) [<a href="/pdf/2303.16258" title="Download PDF">pdf</a>, <a href="/format/2303.16258" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Optimisation via encodings: a renormalisation group perspective
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Klemm%2C+K">Konstantin Klemm</a>, 
<a href="/search/cs?searchtype=author&query=Mehta%2C+A">Anita Mehta</a>, 
<a href="/search/cs?searchtype=author&query=Stadler%2C+P+F">Peter F. Stadler</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 21 pages, 4 figures
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> J Phys A: Math Theor 56, 485001 (2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Disordered Systems and Neural Networks (cond-mat.dis-nn); Statistical Mechanics (cond-mat.stat-mech); Neural and Evolutionary Computing (cs.NE)

</div>
</div>
</dd>
<dt><a name="item495">[495]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.17963" title="Abstract">arXiv:2303.17963</a> (replaced) [<a href="/pdf/2303.17963" title="Download PDF">pdf</a>, <a href="/ps/2303.17963" title="Download PostScript">ps</a>, <a href="/format/2303.17963" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning-Based Optimal Control with Performance Guarantees for Unknown  Systems with Latent States
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Lefringhausen%2C+R">Robert Lefringhausen</a>, 
<a href="/search/eess?searchtype=author&query=Srithasan%2C+S">Supitsana Srithasan</a>, 
<a href="/search/eess?searchtype=author&query=Lederer%2C+A">Armin Lederer</a>, 
<a href="/search/eess?searchtype=author&query=Hirche%2C+S">Sandra Hirche</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Revised version with improved presentation and evaluation, submitted to the 22nd European Control Conference
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Machine Learning (cs.LG); Optimization and Control (math.OC); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item496">[496]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.01834" title="Abstract">arXiv:2304.01834</a> (replaced) [<a href="/pdf/2304.01834" title="Download PDF">pdf</a>, <a href="/format/2304.01834" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Neural Field Convolutions by Repeated Differentiation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nsampi%2C+N+E">Ntumba Elie Nsampi</a>, 
<a href="/search/cs?searchtype=author&query=Djeacoumar%2C+A">Adarsh Djeacoumar</a>, 
<a href="/search/cs?searchtype=author&query=Seidel%2C+H">Hans-Peter Seidel</a>, 
<a href="/search/cs?searchtype=author&query=Ritschel%2C+T">Tobias Ritschel</a>, 
<a href="/search/cs?searchtype=author&query=Leimk%C3%BChler%2C+T">Thomas Leimk&#xfc;hler</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Graphics (cs.GR)

</div>
</div>
</dd>
<dt><a name="item497">[497]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.03408" title="Abstract">arXiv:2304.03408</a> (replaced) [<a href="/pdf/2304.03408" title="Download PDF">pdf</a>, <a href="/format/2304.03408" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Dynamics of Finite Width Kernel and Prediction Fluctuations in Mean  Field Neural Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Bordelon%2C+B">Blake Bordelon</a>, 
<a href="/search/stat?searchtype=author&query=Pehlevan%2C+C">Cengiz Pehlevan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Advances in Neural Information Processing Systems 36 (2023) Camera Ready
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Disordered Systems and Neural Networks (cond-mat.dis-nn); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item498">[498]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.05028" title="Abstract">arXiv:2304.05028</a> (replaced) [<a href="/pdf/2304.05028" title="Download PDF">pdf</a>, <a href="/format/2304.05028" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An Empirical Evaluation of Columnar Storage Formats
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zeng%2C+X">Xinyu Zeng</a>, 
<a href="/search/cs?searchtype=author&query=Hui%2C+Y">Yulong Hui</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+J">Jiahong Shen</a>, 
<a href="/search/cs?searchtype=author&query=Pavlo%2C+A">Andrew Pavlo</a>, 
<a href="/search/cs?searchtype=author&query=McKinney%2C+W">Wes McKinney</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Huanchen Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 15 pages; typos corrected, missing figure legend added
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Databases (cs.DB)</span>

</div>
</div>
</dd>
<dt><a name="item499">[499]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.07126" title="Abstract">arXiv:2304.07126</a> (replaced) [<a href="/pdf/2304.07126" title="Download PDF">pdf</a>, <a href="/ps/2304.07126" title="Download PostScript">ps</a>, <a href="/format/2304.07126" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Decoding twisted permutation codes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Bailey%2C+R+F">Robert F. Bailey</a>, 
<a href="/search/math?searchtype=author&query=Nicholson%2C+K+B">Keenan B. Nicholson</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages, 1 figure
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Combinatorics (math.CO)</span>; Information Theory (cs.IT); Group Theory (math.GR)

</div>
</div>
</dd>
<dt><a name="item500">[500]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.07190" title="Abstract">arXiv:2304.07190</a> (replaced) [<a href="/pdf/2304.07190" title="Download PDF">pdf</a>, <a href="/format/2304.07190" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Completeness Theorems for Kleene algebra with tests and top
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pous%2C+D">Damien Pous</a>, 
<a href="/search/cs?searchtype=author&query=Wagemaker%2C+J">Jana Wagemaker</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Formal Languages and Automata Theory (cs.FL)</span>

</div>
</div>
</dd>
<dt><a name="item501">[501]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.10749" title="Abstract">arXiv:2304.10749</a> (replaced) [<a href="/pdf/2304.10749" title="Download PDF">pdf</a>, <a href="/format/2304.10749" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multi-scale Evolutionary Neural Architecture Search for Deep Spiking  Neural Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pan%2C+W">Wenxuan Pan</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+F">Feifei Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+G">Guobin Shen</a>, 
<a href="/search/cs?searchtype=author&query=Zeng%2C+Y">Yi Zeng</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neural and Evolutionary Computing (cs.NE)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item502">[502]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.11235" title="Abstract">arXiv:2304.11235</a> (replaced) [<a href="/pdf/2304.11235" title="Download PDF">pdf</a>, <a href="/format/2304.11235" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Spatial-Language Attention Policies for Efficient Robot Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Parashar%2C+P">Priyam Parashar</a>, 
<a href="/search/cs?searchtype=author&query=Jain%2C+V">Vidhi Jain</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xiaohan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Vakil%2C+J">Jay Vakil</a>, 
<a href="/search/cs?searchtype=author&query=Powers%2C+S">Sam Powers</a>, 
<a href="/search/cs?searchtype=author&query=Bisk%2C+Y">Yonatan Bisk</a>, 
<a href="/search/cs?searchtype=author&query=Paxton%2C+C">Chris Paxton</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item503">[503]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.11824" title="Abstract">arXiv:2304.11824</a> (replaced) [<a href="/pdf/2304.11824" title="Download PDF">pdf</a>, <a href="/format/2304.11824" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Shape from Shading for Robotic Manipulation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chaudhury%2C+A+N">Arkadeep Narayan Chaudhury</a>, 
<a href="/search/cs?searchtype=author&query=Keselman%2C+L">Leonid Keselman</a>, 
<a href="/search/cs?searchtype=author&query=Atkeson%2C+C+G">Christopher G. Atkeson</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project webpage: <a href="https://arkadeepnc.github.io/projects/active_workspace/index.html">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item504">[504]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.13105" title="Abstract">arXiv:2304.13105</a> (replaced) [<a href="/pdf/2304.13105" title="Download PDF">pdf</a>, <a href="/ps/2304.13105" title="Download PostScript">ps</a>, <a href="/format/2304.13105" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Attention-Enhanced Deep Learning for Device-Free Through-the-Wall  Presence Detection Using Indoor WiFi System
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shen%2C+L">Li-Hsiang Shen</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+K">Kuan-I Lu</a>, 
<a href="/search/cs?searchtype=author&query=Hsiao%2C+A">An-Hung Hsiao</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+K">Kai-Ten Feng</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item505">[505]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.13409" title="Abstract">arXiv:2304.13409</a> (replaced) [<a href="/pdf/2304.13409" title="Download PDF">pdf</a>, <a href="/format/2304.13409" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Efficient Explainable Face Verification based on Similarity Score  Argument Backpropagation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huber%2C+M">Marco Huber</a>, 
<a href="/search/cs?searchtype=author&query=Luu%2C+A+T">Anh Thi Luu</a>, 
<a href="/search/cs?searchtype=author&query=Terh%C3%B6rst%2C+P">Philipp Terh&#xf6;rst</a>, 
<a href="/search/cs?searchtype=author&query=Damer%2C+N">Naser Damer</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at WACV 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item506">[506]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.13972" title="Abstract">arXiv:2304.13972</a> (replaced) [<a href="/pdf/2304.13972" title="Download PDF">pdf</a>, <a href="/ps/2304.13972" title="Download PostScript">ps</a>, <a href="/format/2304.13972" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Convergence of Adam Under Relaxed Assumptions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Li%2C+H">Haochuan Li</a>, 
<a href="/search/math?searchtype=author&query=Rakhlin%2C+A">Alexander Rakhlin</a>, 
<a href="/search/math?searchtype=author&query=Jadbabaie%2C+A">Ali Jadbabaie</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 35 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Machine Learning (cs.LG); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item507">[507]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.01191" title="Abstract">arXiv:2305.01191</a> (replaced) [<a href="/pdf/2305.01191" title="Download PDF">pdf</a>, <a href="/format/2305.01191" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> EasyHeC: Accurate and Automatic Hand-eye Calibration via Differentiable  Rendering and Space Exploration
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+L">Linghao Chen</a>, 
<a href="/search/cs?searchtype=author&query=Qin%2C+Y">Yuzhe Qin</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+X">Xiaowei Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Su%2C+H">Hao Su</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project page: <a href="https://ootts.github.io/easyhec">this https URL</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> IEEE Robotics and Automation Letters 8 (2023) 7234 - 7241
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item508">[508]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.02535" title="Abstract">arXiv:2305.02535</a> (replaced) [<a href="/pdf/2305.02535" title="Download PDF">pdf</a>, <a href="/format/2305.02535" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the Unreasonable Effectiveness of Single Vector Krylov Methods for  Low-Rank Approximation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Meyer%2C+R+A">Raphael A. Meyer</a>, 
<a href="/search/cs?searchtype=author&query=Musco%2C+C">Cameron Musco</a>, 
<a href="/search/cs?searchtype=author&query=Musco%2C+C">Christopher Musco</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 41 pages, 7 figures. To appear at SODA 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>; Numerical Analysis (math.NA)

</div>
</div>
</dd>
<dt><a name="item509">[509]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.02646" title="Abstract">arXiv:2305.02646</a> (replaced) [<a href="/pdf/2305.02646" title="Download PDF">pdf</a>, <a href="/format/2305.02646" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Design and Detection of Unitary Constellations in Non-Coherent SIMO  Systems for Short Packet Communications
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Duong%2C+S+T">Son T. Duong</a>, 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+H+H">Ha H. Nguyen</a>, 
<a href="/search/cs?searchtype=author&query=Bedeer%2C+E">Ebrahim Bedeer</a>, 
<a href="/search/cs?searchtype=author&query=Barton%2C+R">Robert Barton</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, 10 figures, in preparation to submit to IEEE Transactions on Wireless Communications
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
</div>
</dd>
<dt><a name="item510">[510]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.03353" title="Abstract">arXiv:2305.03353</a> (replaced) [<a href="/pdf/2305.03353" title="Download PDF">pdf</a>, <a href="/format/2305.03353" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MindGames: Targeting Theory of Mind in Large Language Models with  Dynamic Epistemic Modal Logic
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sileo%2C+D">Damien Sileo</a>, 
<a href="/search/cs?searchtype=author&query=Lernould%2C+A">Antoine Lernould</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at EMNLP Findings 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item511">[511]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.03558" title="Abstract">arXiv:2305.03558</a> (replaced) [<a href="/pdf/2305.03558" title="Download PDF">pdf</a>, <a href="/format/2305.03558" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Blind identification of Ambisonic reduced room impulse response
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Kiti%C4%87%2C+S">Sr&#x111;an Kiti&#x107;</a>, 
<a href="/search/eess?searchtype=author&query=Daniel%2C+J">J&#xe9;r&#xf4;me Daniel</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted for publication at the IEEE/ACM Transactions on Audio, Speech, and Language Processing
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Sound (cs.SD); Signal Processing (eess.SP)

</div>
</div>
</dd>
<dt><a name="item512">[512]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.08463" title="Abstract">arXiv:2305.08463</a> (replaced) [<a href="/pdf/2305.08463" title="Download PDF">pdf</a>, <a href="/format/2305.08463" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Convergence Analysis of Mean Shift
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Yamasaki%2C+R">Ryoya Yamasaki</a>, 
<a href="/search/stat?searchtype=author&query=Tanaka%2C+T">Toshiyuki Tanaka</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 18 pages, 2 figures, preprint version
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item513">[513]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.08573" title="Abstract">arXiv:2305.08573</a> (replaced) [<a href="/pdf/2305.08573" title="Download PDF">pdf</a>, <a href="/format/2305.08573" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A graph convolutional autoencoder approach to model order reduction for  parametrized PDEs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Pichi%2C+F">Federico Pichi</a>, 
<a href="/search/math?searchtype=author&query=Moya%2C+B">Beatriz Moya</a>, 
<a href="/search/math?searchtype=author&query=Hesthaven%2C+J+S">Jan S. Hesthaven</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> <a href="https://github.com/fpichi/gca-rom">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item514">[514]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.09850" title="Abstract">arXiv:2305.09850</a> (replaced) [<a href="/pdf/2305.09850" title="Download PDF">pdf</a>, <a href="/format/2305.09850" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MINT: Multiplier-less INTeger Quantization for Energy Efficient Spiking  Neural Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yin%2C+R">Ruokai Yin</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yuhang Li</a>, 
<a href="/search/cs?searchtype=author&query=Moitra%2C+A">Abhishek Moitra</a>, 
<a href="/search/cs?searchtype=author&query=Panda%2C+P">Priyadarshini Panda</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages. Accepted to 29th Asia and South Pacific Design Automation Conference (ASP-DAC 2024), nominated for best paper award
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neural and Evolutionary Computing (cs.NE)</span>

</div>
</div>
</dd>
<dt><a name="item515">[515]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.11531" title="Abstract">arXiv:2305.11531</a> (replaced) [<a href="/pdf/2305.11531" title="Download PDF">pdf</a>, <a href="/format/2305.11531" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Generalizing to new geometries with Geometry-Aware Autoregressive Models  (GAAMs) for fast calorimeter simulation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Liu%2C+J">Junze Liu</a>, 
<a href="/search/physics?searchtype=author&query=Ghosh%2C+A">Aishik Ghosh</a>, 
<a href="/search/physics?searchtype=author&query=Smith%2C+D">Dylan Smith</a>, 
<a href="/search/physics?searchtype=author&query=Baldi%2C+P">Pierre Baldi</a>, 
<a href="/search/physics?searchtype=author&query=Whiteson%2C+D">Daniel Whiteson</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Instrumentation and Detectors (physics.ins-det)</span>; Machine Learning (cs.LG); High Energy Physics - Experiment (hep-ex); High Energy Physics - Phenomenology (hep-ph); Data Analysis, Statistics and Probability (physics.data-an)

</div>
</div>
</dd>
<dt><a name="item516">[516]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.11915" title="Abstract">arXiv:2305.11915</a> (replaced) [<a href="/pdf/2305.11915" title="Download PDF">pdf</a>, <a href="/format/2305.11915" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PINNs error estimates for nonlinear equations in $\mathbb{R}$-smooth  Banach spaces
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Gao%2C+J">Jiexing Gao</a>, 
<a href="/search/math?searchtype=author&query=Zakharian%2C+Y">Yurii Zakharian</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 25 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Functional Analysis (math.FA)</span>; Machine Learning (cs.LG); Numerical Analysis (math.NA)

</div>
</div>
</dd>
<dt><a name="item517">[517]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.12704" title="Abstract">arXiv:2305.12704</a> (replaced) [<a href="/pdf/2305.12704" title="Download PDF">pdf</a>, <a href="/format/2305.12704" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Rotation-Constrained Cross-View Feature Fusion for Multi-View  Appearance-based Gaze Estimation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hisadome%2C+Y">Yoichiro Hisadome</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+T">Tianyi Wu</a>, 
<a href="/search/cs?searchtype=author&query=Qin%2C+J">Jiawei Qin</a>, 
<a href="/search/cs?searchtype=author&query=Sugano%2C+Y">Yusuke Sugano</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by WACV2024. The code will be available at \url{<a href="https://github.com/ut-vision/Rot-MVGaze">this https URL</a>}
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item518">[518]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.13024" title="Abstract">arXiv:2305.13024</a> (replaced) [<a href="/pdf/2305.13024" title="Download PDF">pdf</a>, <a href="/ps/2305.13024" title="Download PostScript">ps</a>, <a href="/format/2305.13024" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Changing tools, changing habits, changing workflows: Recent evolutions  of the interlibrary loan service at ULiege Library
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Prosmans%2C+F">Fabienne Prosmans</a>, 
<a href="/search/cs?searchtype=author&query=Renaville%2C+F">Fran&#xe7;ois Renaville</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, with charts and tables
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Beyond the Library Collections:Proceedings of the 2022 Erasmus
  Staff Training Week at ULi\`ege Library (pp. 139-159)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Digital Libraries (cs.DL)</span>

</div>
</div>
</dd>
<dt><a name="item519">[519]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.14303" title="Abstract">arXiv:2305.14303</a> (replaced) [<a href="/pdf/2305.14303" title="Download PDF">pdf</a>, <a href="/format/2305.14303" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> QTSumm: Query-Focused Summarization over Tabular Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Y">Yilun Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Qi%2C+Z">Zhenting Qi</a>, 
<a href="/search/cs?searchtype=author&query=Nan%2C+L">Linyong Nan</a>, 
<a href="/search/cs?searchtype=author&query=Mi%2C+B">Boyu Mi</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yixin Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zou%2C+W">Weijin Zou</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+S">Simeng Han</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+R">Ruizhe Chen</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+X">Xiangru Tang</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+Y">Yumo Xu</a>, 
<a href="/search/cs?searchtype=author&query=Radev%2C+D">Dragomir Radev</a>, 
<a href="/search/cs?searchtype=author&query=Cohan%2C+A">Arman Cohan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at EMNLP 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item520">[520]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.14517" title="Abstract">arXiv:2305.14517</a> (replaced) [<a href="/pdf/2305.14517" title="Download PDF">pdf</a>, <a href="/format/2305.14517" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CongFu: Conditional Graph Fusion for Drug Synergy Prediction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tsepa%2C+O">Oleksii Tsepa</a>, 
<a href="/search/cs?searchtype=author&query=Naida%2C+B">Bohdan Naida</a>, 
<a href="/search/cs?searchtype=author&query=Goldenberg%2C+A">Anna Goldenberg</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+B">Bo Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Quantitative Methods (q-bio.QM)

</div>
</div>
</dd>
<dt><a name="item521">[521]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.14907" title="Abstract">arXiv:2305.14907</a> (replaced) [<a href="/pdf/2305.14907" title="Download PDF">pdf</a>, <a href="/format/2305.14907" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Coverage-based Example Selection for In-Context Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gupta%2C+S">Shivanshu Gupta</a>, 
<a href="/search/cs?searchtype=author&query=Gardner%2C+M">Matt Gardner</a>, 
<a href="/search/cs?searchtype=author&query=Singh%2C+S">Sameer Singh</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to EMNLP 2023 (Findings) Changelog: Added acknowledgments
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item522">[522]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.15947" title="Abstract">arXiv:2305.15947</a> (replaced) [<a href="/pdf/2305.15947" title="Download PDF">pdf</a>, <a href="/format/2305.15947" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Online learning of long-range dependencies
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zucchet%2C+N">Nicolas Zucchet</a>, 
<a href="/search/cs?searchtype=author&query=Meier%2C+R">Robert Meier</a>, 
<a href="/search/cs?searchtype=author&query=Schug%2C+S">Simon Schug</a>, 
<a href="/search/cs?searchtype=author&query=Mujika%2C+A">Asier Mujika</a>, 
<a href="/search/cs?searchtype=author&query=Sacramento%2C+J">Jo&#xe3;o Sacramento</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Neural and Evolutionary Computing (cs.NE)

</div>
</div>
</dd>
<dt><a name="item523">[523]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.16118" title="Abstract">arXiv:2305.16118</a> (replaced) [<a href="/pdf/2305.16118" title="Download PDF">pdf</a>, <a href="/ps/2305.16118" title="Download PostScript">ps</a>, <a href="/format/2305.16118" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Solving Infinite-State Games via Acceleration (Full Version)
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Heim%2C+P">Philippe Heim</a>, 
<a href="/search/cs?searchtype=author&query=Dimitrova%2C+R">Rayna Dimitrova</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This is a full version of paper accepted at POPL 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>

</div>
</div>
</dd>
<dt><a name="item524">[524]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.16792" title="Abstract">arXiv:2305.16792</a> (replaced) [<a href="/pdf/2305.16792" title="Download PDF">pdf</a>, <a href="/format/2305.16792" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Asynchronous Multiple LiDAR-Inertial Odometry using Point-wise  Inter-LiDAR Uncertainty Propagation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jung%2C+M">Minwoo Jung</a>, 
<a href="/search/cs?searchtype=author&query=Jung%2C+S">Sangwoo Jung</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+A">Ayoung Kim</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages, 10 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
</div>
</dd>
<dt><a name="item525">[525]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.17058" title="Abstract">arXiv:2305.17058</a> (replaced) [<a href="/pdf/2305.17058" title="Download PDF">pdf</a>, <a href="/format/2305.17058" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exact Bayesian Inference on Discrete Models via Probability Generating  Functions: A Probabilistic Programming Approach
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zaiser%2C+F">Fabian Zaiser</a>, 
<a href="/search/cs?searchtype=author&query=Murawski%2C+A+S">Andrzej S. Murawski</a>, 
<a href="/search/cs?searchtype=author&query=Ong%2C+L">Luke Ong</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> NeurIPS 2023 version
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Advances in Neural Information Processing Systems 36 (NeurIPS
  2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Programming Languages (cs.PL)</span>; Machine Learning (cs.LG); Computation (stat.CO); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item526">[526]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.17134" title="Abstract">arXiv:2305.17134</a> (replaced) [<a href="/pdf/2305.17134" title="Download PDF">pdf</a>, <a href="/format/2305.17134" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> NeuManifold: Neural Watertight Manifold Reconstruction with Efficient  and High-Quality Rendering Support
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wei%2C+X">Xinyue Wei</a>, 
<a href="/search/cs?searchtype=author&query=Xiang%2C+F">Fanbo Xiang</a>, 
<a href="/search/cs?searchtype=author&query=Bi%2C+S">Sai Bi</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+A">Anpei Chen</a>, 
<a href="/search/cs?searchtype=author&query=Sunkavalli%2C+K">Kalyan Sunkavalli</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+Z">Zexiang Xu</a>, 
<a href="/search/cs?searchtype=author&query=Su%2C+H">Hao Su</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project page: <a href="https://sarahweiii.github.io/neumanifold/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item527">[527]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.17275" title="Abstract">arXiv:2305.17275</a> (replaced) [<a href="/pdf/2305.17275" title="Download PDF">pdf</a>, <a href="/format/2305.17275" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Local Convergence of Gradient Methods for Min-Max Games: Partial  Curvature Generically Suffices
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Wang%2C+G">Guillaume Wang</a>, 
<a href="/search/math?searchtype=author&query=Chizat%2C+L">L&#xe9;na&#xef;c Chizat</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 37 pages, 2 figures, 2 tables, to appear in NeurIPS 2023 Proceedings
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Computer Science and Game Theory (cs.GT); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item528">[528]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.18729" title="Abstract">arXiv:2305.18729</a> (replaced) [<a href="/pdf/2305.18729" title="Download PDF">pdf</a>, <a href="/format/2305.18729" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Real-World Image Variation by Aligning Diffusion Inversion Chain
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yuechen Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Xing%2C+J">Jinbo Xing</a>, 
<a href="/search/cs?searchtype=author&query=Lo%2C+E">Eric Lo</a>, 
<a href="/search/cs?searchtype=author&query=Jia%2C+J">Jiaya Jia</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> NuerIPS 2023 Spotlight. 21 pages; Code: <a href="https://github.com/dvlab-research/RIVAL/">this https URL</a> Project page: <a href="https://rival-diff.github.io/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item529">[529]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.19303" title="Abstract">arXiv:2305.19303</a> (replaced) [<a href="/pdf/2305.19303" title="Download PDF">pdf</a>, <a href="/format/2305.19303" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MAGNet: Motif-Agnostic Generation of Molecules from Shapes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Hetzel%2C+L">Leon Hetzel</a>, 
<a href="/search/physics?searchtype=author&query=Sommer%2C+J">Johanna Sommer</a>, 
<a href="/search/physics?searchtype=author&query=Rieck%2C+B">Bastian Rieck</a>, 
<a href="/search/physics?searchtype=author&query=Theis%2C+F">Fabian Theis</a>, 
<a href="/search/physics?searchtype=author&query=G%C3%BCnnemann%2C+S">Stephan G&#xfc;nnemann</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Chemical Physics (physics.chem-ph)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item530">[530]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.19466" title="Abstract">arXiv:2305.19466</a> (replaced) [<a href="/pdf/2305.19466" title="Download PDF">pdf</a>, <a href="/format/2305.19466" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Impact of Positional Encoding on Length Generalization in  Transformers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kazemnejad%2C+A">Amirhossein Kazemnejad</a>, 
<a href="/search/cs?searchtype=author&query=Padhi%2C+I">Inkit Padhi</a>, 
<a href="/search/cs?searchtype=author&query=Ramamurthy%2C+K+N">Karthikeyan Natesan Ramamurthy</a>, 
<a href="/search/cs?searchtype=author&query=Das%2C+P">Payel Das</a>, 
<a href="/search/cs?searchtype=author&query=Reddy%2C+S">Siva Reddy</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at NeurIPS 2023; 15 pages and 22 pages Appendix
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item531">[531]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.00802" title="Abstract">arXiv:2306.00802</a> (replaced) [<a href="/pdf/2306.00802" title="Download PDF">pdf</a>, <a href="/format/2306.00802" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Birth of a Transformer: A Memory Viewpoint
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Bietti%2C+A">Alberto Bietti</a>, 
<a href="/search/stat?searchtype=author&query=Cabannes%2C+V">Vivien Cabannes</a>, 
<a href="/search/stat?searchtype=author&query=Bouchacourt%2C+D">Diane Bouchacourt</a>, 
<a href="/search/stat?searchtype=author&query=Jegou%2C+H">Herve Jegou</a>, 
<a href="/search/stat?searchtype=author&query=Bottou%2C+L">Leon Bottou</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Computation and Language (cs.CL); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item532">[532]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.00904" title="Abstract">arXiv:2306.00904</a> (replaced) [<a href="/pdf/2306.00904" title="Download PDF">pdf</a>, <a href="/format/2306.00904" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Interaction Measures, Partition Lattices and Kernel Tests for High-Order  Interactions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Liu%2C+Z">Zhaolu Liu</a>, 
<a href="/search/stat?searchtype=author&query=Peach%2C+R+L">Robert L. Peach</a>, 
<a href="/search/stat?searchtype=author&query=Mediano%2C+P+A+M">Pedro A.M. Mediano</a>, 
<a href="/search/stat?searchtype=author&query=Barahona%2C+M">Mauricio Barahona</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 22 pages, 9 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG); Statistics Theory (math.ST)

</div>
</div>
</dd>
<dt><a name="item533">[533]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.01747" title="Abstract">arXiv:2306.01747</a> (replaced) [<a href="/pdf/2306.01747" title="Download PDF">pdf</a>, <a href="/format/2306.01747" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> UMDFood: Vision-language models boost food composition compilation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ma%2C+P">Peihua Ma</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Y">Yixin Wu</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+N">Ning Yu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Backes%2C+M">Michael Backes</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Q">Qin Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+C">Cheng-I Wei</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, 9 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item534">[534]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.02063" title="Abstract">arXiv:2306.02063</a> (replaced) [<a href="/pdf/2306.02063" title="Download PDF">pdf</a>, <a href="/format/2306.02063" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exploring the Optimal Choice for Generative Processes in Diffusion  Models: Ordinary vs Stochastic Differential Equations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cao%2C+Y">Yu Cao</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Jingrun Chen</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+Y">Yixin Luo</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+X">Xiang Zhou</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item535">[535]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.02866" title="Abstract">arXiv:2306.02866</a> (replaced) [<a href="/pdf/2306.02866" title="Download PDF">pdf</a>, <a href="/format/2306.02866" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning Probabilistic Symmetrization for Architecture Agnostic  Equivariance
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kim%2C+J">Jinwoo Kim</a>, 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+T+D">Tien Dat Nguyen</a>, 
<a href="/search/cs?searchtype=author&query=Suleymanzade%2C+A">Ayhan Suleymanzade</a>, 
<a href="/search/cs?searchtype=author&query=An%2C+H">Hyeokjun An</a>, 
<a href="/search/cs?searchtype=author&query=Hong%2C+S">Seunghoon Hong</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 31 pages, 11 figures. This is a revised version of NeurIPS camera ready
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item536">[536]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.04061" title="Abstract">arXiv:2306.04061</a> (replaced) [<a href="/pdf/2306.04061" title="Download PDF">pdf</a>, <a href="/format/2306.04061" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deploying a Robust Active Preference Elicitation Algorithm on MTurk:  Experiment Design, Interface, and Evaluation for COVID-19 Patient  Prioritization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Johnston%2C+C+M">Caroline M. Johnston</a>, 
<a href="/search/cs?searchtype=author&query=Vossler%2C+P">Patrick Vossler</a>, 
<a href="/search/cs?searchtype=author&query=Blessenohl%2C+S">Simon Blessenohl</a>, 
<a href="/search/cs?searchtype=author&query=Vayanos%2C+P">Phebe Vayanos</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 5 figures, 1 table
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Proceedings of the 3rd ACM Conference on Equity and Access in
  Algorithms, Mechanisms, and Optimization (EAAMO 2023). Association for
  Computing Machinery, Article 31, (2023) 1-10
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item537">[537]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.04096" title="Abstract">arXiv:2306.04096</a> (replaced) [<a href="/pdf/2306.04096" title="Download PDF">pdf</a>, <a href="/format/2306.04096" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An enrichment approach for enhancing the expressivity of neural  operators with applications to seismology
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Haghighat%2C+E">Ehsan Haghighat</a>, 
<a href="/search/cs?searchtype=author&query=Waheed%2C+U+b">Umair bin Waheed</a>, 
<a href="/search/cs?searchtype=author&query=Karniadakis%2C+G">George Karniadakis</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computational Engineering, Finance, and Science (cs.CE); Computational Physics (physics.comp-ph)

</div>
</div>
</dd>
<dt><a name="item538">[538]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.04186" title="Abstract">arXiv:2306.04186</a> (replaced) [<a href="/pdf/2306.04186" title="Download PDF">pdf</a>, <a href="/format/2306.04186" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Self-supervised Audio Teacher-Student Transformer for Both Clip-level  and Frame-level Tasks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Li%2C+X">Xian Li</a>, 
<a href="/search/eess?searchtype=author&query=Shao%2C+N">Nian Shao</a>, 
<a href="/search/eess?searchtype=author&query=Li%2C+X">Xiaofei Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to IEEE TASLP. arXiv admin note: text overlap with <a href="/abs/2204.12076">arXiv:2204.12076</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item539">[539]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.05284" title="Abstract">arXiv:2306.05284</a> (replaced) [<a href="/pdf/2306.05284" title="Download PDF">pdf</a>, <a href="/format/2306.05284" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Simple and Controllable Music Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Copet%2C+J">Jade Copet</a>, 
<a href="/search/cs?searchtype=author&query=Kreuk%2C+F">Felix Kreuk</a>, 
<a href="/search/cs?searchtype=author&query=Gat%2C+I">Itai Gat</a>, 
<a href="/search/cs?searchtype=author&query=Remez%2C+T">Tal Remez</a>, 
<a href="/search/cs?searchtype=author&query=Kant%2C+D">David Kant</a>, 
<a href="/search/cs?searchtype=author&query=Synnaeve%2C+G">Gabriel Synnaeve</a>, 
<a href="/search/cs?searchtype=author&query=Adi%2C+Y">Yossi Adi</a>, 
<a href="/search/cs?searchtype=author&query=D%C3%A9fossez%2C+A">Alexandre D&#xe9;fossez</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Published at Neurips 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Audio and Speech Processing (eess.AS)

</div>
</div>
</dd>
<dt><a name="item540">[540]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.06538" title="Abstract">arXiv:2306.06538</a> (replaced) [<a href="/pdf/2306.06538" title="Download PDF">pdf</a>, <a href="/format/2306.06538" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Theory of shifts, shocks, and the intimate connections to $L^2$-type a  posteriori error analysis of numerical schemes for hyperbolic problems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Giesselmann%2C+J">Jan Giesselmann</a> (Technische Universit&#xe4;t Darmstadt), 
<a href="/search/math?searchtype=author&query=Krupa%2C+S+G">Sam G. Krupa</a> (Max Planck Institute for Mathematics in the Sciences)
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 87 pages, 14 figures, 3 tables. For associated MATLAB code, see the GitLab at <a href="https://git-ce.rwth-aachen.de/jan.giesselmann/shiftsshocksaposteriori.git">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Analysis of PDEs (math.AP)</span>; Numerical Analysis (math.NA)

</div>
</div>
</dd>
<dt><a name="item541">[541]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.07716" title="Abstract">arXiv:2306.07716</a> (replaced) [<a href="/pdf/2306.07716" title="Download PDF">pdf</a>, <a href="/format/2306.07716" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Dynamically Masked Discriminator for Generative Adversarial Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+W">Wentian Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+H">Haozhe Liu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+B">Bing Li</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+J">Jinheng Xie</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+Y">Yawen Huang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yuexiang Li</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+Y">Yefeng Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Ghanem%2C+B">Bernard Ghanem</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Updated v2 -- NeurIPS 2023 camera ready version
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item542">[542]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.09858" title="Abstract">arXiv:2306.09858</a> (replaced) [<a href="/pdf/2306.09858" title="Download PDF">pdf</a>, <a href="/format/2306.09858" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Prototype Learning for Explainable Brain Age Prediction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hesse%2C+L+S">Linde S. Hesse</a>, 
<a href="/search/cs?searchtype=author&query=Dinsdale%2C+N+K">Nicola K. Dinsdale</a>, 
<a href="/search/cs?searchtype=author&query=Namburete%2C+A+I+L">Ana I. L. Namburete</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted for presentation at WCAV 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item543">[543]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.10280" title="Abstract">arXiv:2306.10280</a> (replaced) [<a href="/pdf/2306.10280" title="Download PDF">pdf</a>, <a href="/format/2306.10280" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> OpenGSL: A Comprehensive Benchmark for Graph Structure Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Z">Zhiyao Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+S">Sheng Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Mao%2C+B">Bochao Mao</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+X">Xuanyi Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Jiawei Chen</a>, 
<a href="/search/cs?searchtype=author&query=Tan%2C+Q">Qiaoyu Tan</a>, 
<a href="/search/cs?searchtype=author&query=Zha%2C+D">Daochen Zha</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+Y">Yan Feng</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+C">Chun Chen</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+C">Can Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages, 4 figures. Accepted by NeurIPS Datasets and Benchmarks Track 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Social and Information Networks (cs.SI)

</div>
</div>
</dd>
<dt><a name="item544">[544]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.11412" title="Abstract">arXiv:2306.11412</a> (replaced) [<a href="/pdf/2306.11412" title="Download PDF">pdf</a>, <a href="/format/2306.11412" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Size Matters: Large Graph Generation with HiGGs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Davies%2C+A+O">Alex O. Davies</a>, 
<a href="/search/cs?searchtype=author&query=Ajmeri%2C+N+S">Nirav S. Ajmeri</a>, 
<a href="/search/cs?searchtype=author&query=Filho%2C+T+M+S">Telmo M. Silva Filho</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Presented at the NeurIPS 2023 Synthetic Data Generation with Generative AI workshop
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Social and Information Networks (cs.SI)

</div>
</div>
</dd>
<dt><a name="item545">[545]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.11604" title="Abstract">arXiv:2306.11604</a> (replaced) [<a href="/pdf/2306.11604" title="Download PDF">pdf</a>, <a href="/ps/2306.11604" title="Download PostScript">ps</a>, <a href="/format/2306.11604" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Composition of nested embeddings with an application to outlier removal
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chawla%2C+S">Shuchi Chawla</a>, 
<a href="/search/cs?searchtype=author&query=Sheridan%2C+K">Kristin Sheridan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 28 pages (including 2 appendices), 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>

</div>
</div>
</dd>
<dt><a name="item546">[546]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.11681" title="Abstract">arXiv:2306.11681</a> (replaced) [<a href="/pdf/2306.11681" title="Download PDF">pdf</a>, <a href="/format/2306.11681" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MoleCLUEs: Molecular Conformers Maximally In-Distribution for Predictive  Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Maser%2C+M">Michael Maser</a>, 
<a href="/search/cs?searchtype=author&query=Tagasovska%2C+N">Natasa Tagasovska</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+J+H">Jae Hyeon Lee</a>, 
<a href="/search/cs?searchtype=author&query=Watkins%2C+A">Andrew Watkins</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> NeurIPS 2023 AI for Science Workshop
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Quantitative Methods (q-bio.QM)

</div>
</div>
</dd>
<dt><a name="item547">[547]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.13258" title="Abstract">arXiv:2306.13258</a> (replaced) [<a href="/pdf/2306.13258" title="Download PDF">pdf</a>, <a href="/format/2306.13258" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fast Maximum $k$-Plex Algorithms Parameterized by Small Degeneracy Gaps
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zhengren Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Y">Yi Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+C">Chunyu Luo</a>, 
<a href="/search/cs?searchtype=author&query=Xiao%2C+M">Mingyu Xiao</a>, 
<a href="/search/cs?searchtype=author&query=Hao%2C+J">Jin-Kao Hao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> The paper extends the conference paper "A Fast Maximum $k$-Plex Algorithm Parameterized by the Degeneracy Gap", presented in the 32nd International Joint Conference on Artificial Intelligence (IJCAI'23) in Macao on 19th August 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>; Artificial Intelligence (cs.AI); Social and Information Networks (cs.SI)

</div>
</div>
</dd>
<dt><a name="item548">[548]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.14351" title="Abstract">arXiv:2306.14351</a> (replaced) [<a href="/pdf/2306.14351" title="Download PDF">pdf</a>, <a href="/ps/2306.14351" title="Download PostScript">ps</a>, <a href="/format/2306.14351" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Comparing Causal Frameworks: Potential Outcomes, Structural Models,  Graphs, and Abstractions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Ibeling%2C+D">Duligur Ibeling</a>, 
<a href="/search/stat?searchtype=author&query=Icard%2C+T">Thomas Icard</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Methodology (stat.ME)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Logic in Computer Science (cs.LO); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item549">[549]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.14411" title="Abstract">arXiv:2306.14411</a> (replaced) [<a href="/pdf/2306.14411" title="Download PDF">pdf</a>, <a href="/format/2306.14411" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Score-based Source Separation with Applications to Digital Communication  Signals
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jayashankar%2C+T">Tejas Jayashankar</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+G+C+F">Gary C.F. Lee</a>, 
<a href="/search/cs?searchtype=author&query=Lancho%2C+A">Alejandro Lancho</a>, 
<a href="/search/cs?searchtype=author&query=Weiss%2C+A">Amir Weiss</a>, 
<a href="/search/cs?searchtype=author&query=Polyanskiy%2C+Y">Yury Polyanskiy</a>, 
<a href="/search/cs?searchtype=author&query=Wornell%2C+G+W">Gregory W. Wornell</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 34 pages, 18 figures, for associated project webpage see <a href="https://alpha-rgs.github.io">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Signal Processing (eess.SP)

</div>
</div>
</dd>
<dt><a name="item550">[550]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.14770" title="Abstract">arXiv:2306.14770</a> (replaced) [<a href="/pdf/2306.14770" title="Download PDF">pdf</a>, <a href="/format/2306.14770" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ProtoDiff: Learning to Learn Prototypical Networks by Task-Guided  Diffusion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Du%2C+Y">Yingjun Du</a>, 
<a href="/search/cs?searchtype=author&query=Xiao%2C+Z">Zehao Xiao</a>, 
<a href="/search/cs?searchtype=author&query=Liao%2C+S">Shengcai Liao</a>, 
<a href="/search/cs?searchtype=author&query=Snoek%2C+C">Cees Snoek</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item551">[551]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.16819" title="Abstract">arXiv:2306.16819</a> (replaced) [<a href="/pdf/2306.16819" title="Download PDF">pdf</a>, <a href="/format/2306.16819" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Graph Denoising Diffusion for Inverse Protein Folding
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-bio?searchtype=author&query=Yi%2C+K">Kai Yi</a>, 
<a href="/search/q-bio?searchtype=author&query=Zhou%2C+B">Bingxin Zhou</a>, 
<a href="/search/q-bio?searchtype=author&query=Shen%2C+Y">Yiqing Shen</a>, 
<a href="/search/q-bio?searchtype=author&query=Li%C3%B2%2C+P">Pietro Li&#xf2;</a>, 
<a href="/search/q-bio?searchtype=author&query=Wang%2C+Y+G">Yu Guang Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantitative Methods (q-bio.QM)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item552">[552]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.17466" title="Abstract">arXiv:2306.17466</a> (replaced) [<a href="/pdf/2306.17466" title="Download PDF">pdf</a>, <a href="/format/2306.17466" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MedAugment: Universal Automatic Data Augmentation Plug-in for Medical  Image Analysis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Liu%2C+Z">Zhaoshan Liu</a>, 
<a href="/search/eess?searchtype=author&query=Lv%2C+Q">Qiujie Lv</a>, 
<a href="/search/eess?searchtype=author&query=Li%2C+Y">Yifan Li</a>, 
<a href="/search/eess?searchtype=author&query=Yang%2C+Z">Ziduo Yang</a>, 
<a href="/search/eess?searchtype=author&query=Shen%2C+L">Lei Shen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 26 pages, 10 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item553">[553]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.01050" title="Abstract">arXiv:2307.01050</a> (replaced) [<a href="/pdf/2307.01050" title="Download PDF">pdf</a>, <a href="/format/2307.01050" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Transport meets Variational Inference: Controlled Monte Carlo Diffusions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Vargas%2C+F">Francisco Vargas</a>, 
<a href="/search/stat?searchtype=author&query=Padhy%2C+S">Shreyas Padhy</a>, 
<a href="/search/stat?searchtype=author&query=Blessing%2C+D">Denis Blessing</a>, 
<a href="/search/stat?searchtype=author&query=N%C3%BCsken%2C+N">Nikolas N&#xfc;sken</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Workshop on New Frontiers in Learning, Control, and Dynamical Systems at the International Conference on Machine Learning (ICML), Honolulu, Hawaii, USA, 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item554">[554]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.03404" title="Abstract">arXiv:2307.03404</a> (replaced) [<a href="/pdf/2307.03404" title="Download PDF">pdf</a>, <a href="/format/2307.03404" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> RGB-D Mapping and Tracking in a Plenoxel Radiance Field
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Teigen%2C+A+L">Andreas L. Teigen</a>, 
<a href="/search/cs?searchtype=author&query=Park%2C+Y">Yeonsoo Park</a>, 
<a href="/search/cs?searchtype=author&query=Stahl%2C+A">Annette Stahl</a>, 
<a href="/search/cs?searchtype=author&query=Mester%2C+R">Rudolf Mester</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 2024 IEEE/CVF Winter Conference on Applications of Computer Vision (WACV) *The first two authors contributed equally to this paper
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Robotics (cs.RO)

</div>
</div>
</dd>
<dt><a name="item555">[555]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.04657" title="Abstract">arXiv:2307.04657</a> (replaced) [<a href="/pdf/2307.04657" title="Download PDF">pdf</a>, <a href="/format/2307.04657" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> BeaverTails: Towards Improved Safety Alignment of LLM via a  Human-Preference Dataset
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ji%2C+J">Jiaming Ji</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+M">Mickel Liu</a>, 
<a href="/search/cs?searchtype=author&query=Dai%2C+J">Juntao Dai</a>, 
<a href="/search/cs?searchtype=author&query=Pan%2C+X">Xuehai Pan</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+C">Chi Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Bian%2C+C">Ce Bian</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+C">Chi Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+R">Ruiyang Sun</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yizhou Wang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yaodong Yang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Published at NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item556">[556]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.04841" title="Abstract">arXiv:2307.04841</a> (replaced) [<a href="/pdf/2307.04841" title="Download PDF">pdf</a>, <a href="/format/2307.04841" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Loss Dynamics of Temporal Difference Reinforcement Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Bordelon%2C+B">Blake Bordelon</a>, 
<a href="/search/stat?searchtype=author&query=Masset%2C+P">Paul Masset</a>, 
<a href="/search/stat?searchtype=author&query=Kuo%2C+H">Henry Kuo</a>, 
<a href="/search/stat?searchtype=author&query=Pehlevan%2C+C">Cengiz Pehlevan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Advances in Neural Information Processing Systems 36 (2023) Camera Ready
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Disordered Systems and Neural Networks (cond-mat.dis-nn); Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item557">[557]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.05857" title="Abstract">arXiv:2307.05857</a> (replaced) [<a href="/pdf/2307.05857" title="Download PDF">pdf</a>, <a href="/format/2307.05857" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FAIRO: Fairness-aware Adaptation in Sequential-Decision Making for  Human-in-the-Loop Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhao%2C+T">Tianyu Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Taherisadr%2C+M">Mojtaba Taherisadr</a>, 
<a href="/search/cs?searchtype=author&query=Elmalaki%2C+S">Salma Elmalaki</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computers and Society (cs.CY)

</div>
</div>
</dd>
<dt><a name="item558">[558]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.07187" title="Abstract">arXiv:2307.07187</a> (replaced) [<a href="/pdf/2307.07187" title="Download PDF">pdf</a>, <a href="/format/2307.07187" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Erasing, Transforming, and Noising Defense Network for Occluded Person  Re-Identification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dong%2C+N">Neng Dong</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+L">Liyan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+S">Shuanglin Yan</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+H">Hao Tang</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+J">Jinhui Tang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item559">[559]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.07697" title="Abstract">arXiv:2307.07697</a> (replaced) [<a href="/pdf/2307.07697" title="Download PDF">pdf</a>, <a href="/format/2307.07697" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Think-on-Graph: Deep and Responsible Reasoning of Large Language Model  on Knowledge Graph
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sun%2C+J">Jiashuo Sun</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+C">Chengjin Xu</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+L">Lumingyuan Tang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Saizhuo Wang</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+C">Chen Lin</a>, 
<a href="/search/cs?searchtype=author&query=Gong%2C+Y">Yeyun Gong</a>, 
<a href="/search/cs?searchtype=author&query=Ni%2C+L+M">Lionel M. Ni</a>, 
<a href="/search/cs?searchtype=author&query=Shum%2C+H">Heung-Yeung Shum</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+J">Jian Guo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 30 pages, 13 figures, 20 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item560">[560]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.07870" title="Abstract">arXiv:2307.07870</a> (replaced) [<a href="/pdf/2307.07870" title="Download PDF">pdf</a>, <a href="/format/2307.07870" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Large Language Models as Superpositions of Cultural Perspectives
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kova%C4%8D%2C+G">Grgur Kova&#x10d;</a>, 
<a href="/search/cs?searchtype=author&query=Sawayama%2C+M">Masataka Sawayama</a>, 
<a href="/search/cs?searchtype=author&query=Portelas%2C+R">R&#xe9;my Portelas</a>, 
<a href="/search/cs?searchtype=author&query=Colas%2C+C">C&#xe9;dric Colas</a>, 
<a href="/search/cs?searchtype=author&query=Dominey%2C+P+F">Peter Ford Dominey</a>, 
<a href="/search/cs?searchtype=author&query=Oudeyer%2C+P">Pierre-Yves Oudeyer</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Preprint
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item561">[561]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.08304" title="Abstract">arXiv:2307.08304</a> (replaced) [<a href="/pdf/2307.08304" title="Download PDF">pdf</a>, <a href="/ps/2307.08304" title="Download PostScript">ps</a>, <a href="/format/2307.08304" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Efficient Computation of Counterfactual Bounds
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zaffalon%2C+M">Marco Zaffalon</a>, 
<a href="/search/cs?searchtype=author&query=Antonucci%2C+A">Alessandro Antonucci</a>, 
<a href="/search/cs?searchtype=author&query=Caba%C3%B1as%2C+R">Rafael Caba&#xf1;as</a>, 
<a href="/search/cs?searchtype=author&query=Huber%2C+D">David Huber</a>, 
<a href="/search/cs?searchtype=author&query=Azzimonti%2C+D">Dario Azzimonti</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
</div>
</dd>
<dt><a name="item562">[562]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.09212" title="Abstract">arXiv:2307.09212</a> (replaced) [<a href="/pdf/2307.09212" title="Download PDF">pdf</a>, <a href="/format/2307.09212" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> How Many Neurons Does it Take to Approximate the Maximum?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Safran%2C+I">Itay Safran</a>, 
<a href="/search/cs?searchtype=author&query=Reichman%2C+D">Daniel Reichman</a>, 
<a href="/search/cs?searchtype=author&query=Valiant%2C+P">Paul Valiant</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item563">[563]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.10222" title="Abstract">arXiv:2307.10222</a> (replaced) [<a href="/pdf/2307.10222" title="Download PDF">pdf</a>, <a href="/ps/2307.10222" title="Download PostScript">ps</a>, <a href="/format/2307.10222" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Techno-Utopians, Scammers, and Bullshitters: The Promise and Peril of  Web3 and Blockchain Technologies According to Operators and Venture Capital  Investors
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Winecoff%2C+A+A">Amy A. Winecoff</a>, 
<a href="/search/cs?searchtype=author&query=Lenhard%2C+J">Johannes Lenhard</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>; Human-Computer Interaction (cs.HC)

</div>
</div>
</dd>
<dt><a name="item564">[564]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.11225" title="Abstract">arXiv:2307.11225</a> (replaced) [<a href="/pdf/2307.11225" title="Download PDF">pdf</a>, <a href="/ps/2307.11225" title="Download PostScript">ps</a>, <a href="/format/2307.11225" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Small But Unwieldy: A Lower Bound on Adjacency Labels for Small Classes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Bonnet%2C+%C3%89">&#xc9;douard Bonnet</a>, 
<a href="/search/math?searchtype=author&query=Duron%2C+J">Julien Duron</a>, 
<a href="/search/math?searchtype=author&query=Sylvester%2C+J">John Sylvester</a>, 
<a href="/search/math?searchtype=author&query=Zamaraev%2C+V">Viktor Zamaraev</a>, 
<a href="/search/math?searchtype=author&query=Zhukovskii%2C+M">Maksim Zhukovskii</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 25 pages, 1 figure, shortened abstract
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Combinatorics (math.CO)</span>; Discrete Mathematics (cs.DM); Data Structures and Algorithms (cs.DS)

</div>
</div>
</dd>
<dt><a name="item565">[565]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.11363" title="Abstract">arXiv:2307.11363</a> (replaced) [<a href="/pdf/2307.11363" title="Download PDF">pdf</a>, <a href="/format/2307.11363" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Convergent Authalic Energy Minimization for Disk Area-Preserving  Parameterizations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Liu%2C+S">Shu-Yung Liu</a>, 
<a href="/search/math?searchtype=author&query=Yueh%2C+M">Mei-Heng Yueh</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 21 pages, 7 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
</div>
</dd>
<dt><a name="item566">[566]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.11620" title="Abstract">arXiv:2307.11620</a> (replaced) [<a href="/pdf/2307.11620" title="Download PDF">pdf</a>, <a href="/format/2307.11620" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Offline Multi-Agent Reinforcement Learning with Implicit Global-to-Local  Value Regularization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xiangsen Wang</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+H">Haoran Xu</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+Y">Yinan Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Zhan%2C+X">Xianyuan Zhan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by the 37th Conference on Neural Information Processing Systems (NeurIPS 2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Multiagent Systems (cs.MA)

</div>
</div>
</dd>
<dt><a name="item567">[567]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.13214" title="Abstract">arXiv:2307.13214</a> (replaced) [<a href="/pdf/2307.13214" title="Download PDF">pdf</a>, <a href="/format/2307.13214" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FedMEKT: Distillation-based Embedding Knowledge Transfer for Multimodal  Federated Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Le%2C+H+Q">Huy Q. Le</a>, 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+M+N+H">Minh N. H. Nguyen</a>, 
<a href="/search/cs?searchtype=author&query=Thwal%2C+C+M">Chu Myaet Thwal</a>, 
<a href="/search/cs?searchtype=author&query=Qiao%2C+Y">Yu Qiao</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+C">Chaoning Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Hong%2C+C+S">Choong Seon Hong</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item568">[568]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.13813" title="Abstract">arXiv:2307.13813</a> (replaced) [<a href="/pdf/2307.13813" title="Download PDF">pdf</a>, <a href="/format/2307.13813" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> How to Scale Your EMA
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Busbridge%2C+D">Dan Busbridge</a>, 
<a href="/search/stat?searchtype=author&query=Ramapuram%2C+J">Jason Ramapuram</a>, 
<a href="/search/stat?searchtype=author&query=Ablin%2C+P">Pierre Ablin</a>, 
<a href="/search/stat?searchtype=author&query=Likhomanenko%2C+T">Tatiana Likhomanenko</a>, 
<a href="/search/stat?searchtype=author&query=Dhekane%2C+E+G">Eeshan Gunesh Dhekane</a>, 
<a href="/search/stat?searchtype=author&query=Suau%2C+X">Xavier Suau</a>, 
<a href="/search/stat?searchtype=author&query=Webb%2C+R">Russ Webb</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Spotlight at NeurIPS 2023, 53 pages, 32 figures, 17 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item569">[569]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.16096" title="Abstract">arXiv:2307.16096</a> (replaced) [<a href="/pdf/2307.16096" title="Download PDF">pdf</a>, <a href="/ps/2307.16096" title="Download PostScript">ps</a>, <a href="/format/2307.16096" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> D-STAR: Dual Simultaneously Transmitting and Reflecting Reconfigurable  Intelligent Surfaces for Joint Uplink/Downlink Transmission
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shen%2C+L">Li-Hsiang Shen</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+P">Po-Chen Wu</a>, 
<a href="/search/cs?searchtype=author&query=Ku%2C+C">Chia-Jou Ku</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yu-Ting Li</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+K">Kai-Ten Feng</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yuanwei Liu</a>, 
<a href="/search/cs?searchtype=author&query=Hanzo%2C+L">Lajos Hanzo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 30 pages, 10 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
</div>
</dd>
<dt><a name="item570">[570]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.00987" title="Abstract">arXiv:2308.00987</a> (replaced) [<a href="/pdf/2308.00987" title="Download PDF">pdf</a>, <a href="/format/2308.00987" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Percolation in higher order networks via mapping to chygraphs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cond-mat?searchtype=author&query=Vazquez%2C+A">Alexei Vazquez</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 4 figures, ref to github repository
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Disordered Systems and Neural Networks (cond-mat.dis-nn)</span>; Statistical Mechanics (cond-mat.stat-mech); Data Structures and Algorithms (cs.DS); Social and Information Networks (cs.SI); Physics and Society (physics.soc-ph)

</div>
</div>
</dd>
<dt><a name="item571">[571]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.01751" title="Abstract">arXiv:2308.01751</a> (replaced) [<a href="/pdf/2308.01751" title="Download PDF">pdf</a>, <a href="/format/2308.01751" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ManiVault: A Flexible and Extensible Visual Analytics Framework for  High-Dimensional Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Vieth%2C+A">Alexander Vieth</a>, 
<a href="/search/cs?searchtype=author&query=Kroes%2C+T">Thomas Kroes</a>, 
<a href="/search/cs?searchtype=author&query=Thijssen%2C+J">Julian Thijssen</a>, 
<a href="/search/cs?searchtype=author&query=van+Lew%2C+B">Baldur van Lew</a>, 
<a href="/search/cs?searchtype=author&query=Eggermont%2C+J">Jeroen Eggermont</a>, 
<a href="/search/cs?searchtype=author&query=Basu%2C+S">Soumyadeep Basu</a>, 
<a href="/search/cs?searchtype=author&query=Eisemann%2C+E">Elmar Eisemann</a>, 
<a href="/search/cs?searchtype=author&query=Vilanova%2C+A">Anna Vilanova</a>, 
<a href="/search/cs?searchtype=author&query=H%C3%B6llt%2C+T">Thomas H&#xf6;llt</a>, 
<a href="/search/cs?searchtype=author&query=Lelieveldt%2C+B">Boudewijn Lelieveldt</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages paper (incl. 2 pages references and acknowledgements), 2 pages supplement
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> IEEE Transactions on Visualization and Computer Graphics
  (Proceedings of IEEE VIS 2023), 30(2), 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Graphics (cs.GR)

</div>
</div>
</dd>
<dt><a name="item572">[572]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.03427" title="Abstract">arXiv:2308.03427</a> (replaced) [<a href="/pdf/2308.03427" title="Download PDF">pdf</a>, <a href="/format/2308.03427" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> TPTU: Large Language Model-based AI Agents for Task Planning and Tool  Usage
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ruan%2C+J">Jingqing Ruan</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yihong Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+B">Bin Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+Z">Zhiwei Xu</a>, 
<a href="/search/cs?searchtype=author&query=Bao%2C+T">Tianpeng Bao</a>, 
<a href="/search/cs?searchtype=author&query=Du%2C+G">Guoqing Du</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+S">Shiwei Shi</a>, 
<a href="/search/cs?searchtype=author&query=Mao%2C+H">Hangyu Mao</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Ziyue Li</a>, 
<a href="/search/cs?searchtype=author&query=Zeng%2C+X">Xingyu Zeng</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+R">Rui Zhao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted in NeurIPS-2023 Workshop on Foundation Models for Decision Making
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
</div>
</dd>
<dt><a name="item573">[573]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.03920" title="Abstract">arXiv:2308.03920</a> (replaced) [<a href="/pdf/2308.03920" title="Download PDF">pdf</a>, <a href="/format/2308.03920" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Control of Vortex Dynamics using Invariants
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Krishna%2C+K">Kartik Krishna</a>, 
<a href="/search/physics?searchtype=author&query=Nair%2C+A+G">Aditya G. Nair</a>, 
<a href="/search/physics?searchtype=author&query=Krishnan%2C+A">Anand Krishnan</a>, 
<a href="/search/physics?searchtype=author&query=Brunton%2C+S+L">Steven L. Brunton</a>, 
<a href="/search/physics?searchtype=author&query=Kaiser%2C+E">Eurika Kaiser</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Fluid Dynamics (physics.flu-dyn)</span>; Systems and Control (eess.SY); Dynamical Systems (math.DS); Optimization and Control (math.OC); Chaotic Dynamics (nlin.CD)

</div>
</div>
</dd>
<dt><a name="item574">[574]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.07763" title="Abstract">arXiv:2308.07763</a> (replaced) [<a href="/pdf/2308.07763" title="Download PDF">pdf</a>, <a href="/format/2308.07763" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Online Universal Dirichlet Factor Portfolios
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-fin?searchtype=author&query=Parthasarathy%2C+P">Purushottam Parthasarathy</a>, 
<a href="/search/q-fin?searchtype=author&query=Bhardwaj%2C+A">Avinash Bhardwaj</a>, 
<a href="/search/q-fin?searchtype=author&query=Hanawal%2C+M+K">Manjesh K. Hanawal</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Portfolio Management (q-fin.PM)</span>; Computational Engineering, Finance, and Science (cs.CE); Mathematical Finance (q-fin.MF)

</div>
</div>
</dd>
<dt><a name="item575">[575]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.07928" title="Abstract">arXiv:2308.07928</a> (replaced) [<a href="/pdf/2308.07928" title="Download PDF">pdf</a>, <a href="/ps/2308.07928" title="Download PostScript">ps</a>, <a href="/format/2308.07928" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the generalized vectorization and its inverse
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Curtarelli%2C+V">Vitor Curtarelli</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
</div>
</dd>
<dt><a name="item576">[576]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.09000" title="Abstract">arXiv:2308.09000</a> (replaced) [<a href="/pdf/2308.09000" title="Download PDF">pdf</a>, <a href="/format/2308.09000" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DealMVC: Dual Contrastive Calibration for Multi-view Clustering
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+X">Xihong Yang</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+J">Jiaqi Jin</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Siwei Wang</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+K">Ke Liang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yue Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wen%2C+Y">Yi Wen</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+S">Suyuan Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+S">Sihang Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xinwang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+E">En Zhu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item577">[577]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.09025" title="Abstract">arXiv:2308.09025</a> (replaced) [<a href="/pdf/2308.09025" title="Download PDF">pdf</a>, <a href="/format/2308.09025" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SR-GAN for SR-gamma: super resolution of photon calorimeter images at  collider experiments
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/hep-ex?searchtype=author&query=Erdmann%2C+J">Johannes Erdmann</a>, 
<a href="/search/hep-ex?searchtype=author&query=van+der+Graaf%2C+A">Aaron van der Graaf</a>, 
<a href="/search/hep-ex?searchtype=author&query=Mausolf%2C+F">Florian Mausolf</a>, 
<a href="/search/hep-ex?searchtype=author&query=Nackenhorst%2C+O">Olaf Nackenhorst</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 26 pages, 13 figures
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Eur. Phys. J. C 83 (2023) 1001
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">High Energy Physics - Experiment (hep-ex)</span>; Computer Vision and Pattern Recognition (cs.CV); Instrumentation and Detectors (physics.ins-det)

</div>
</div>
</dd>
<dt><a name="item578">[578]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.09068" title="Abstract">arXiv:2308.09068</a> (replaced) [<a href="/pdf/2308.09068" title="Download PDF">pdf</a>, <a href="/ps/2308.09068" title="Download PostScript">ps</a>, <a href="/format/2308.09068" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Close to optimal column approximations with a single SVD
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Osinsky%2C+A">Alexander Osinsky</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
</div>
</dd>
<dt><a name="item579">[579]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.09394" title="Abstract">arXiv:2308.09394</a> (replaced) [<a href="/pdf/2308.09394" title="Download PDF">pdf</a>, <a href="/format/2308.09394" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An Eigenvalue-Free Implementation of the Log-Conformation Formulation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Becker%2C+F">Florian Becker</a>, 
<a href="/search/physics?searchtype=author&query=Rauthmann%2C+K">Katharina Rauthmann</a>, 
<a href="/search/physics?searchtype=author&query=Pauli%2C+L">Lutz Pauli</a>, 
<a href="/search/physics?searchtype=author&query=Knechtges%2C+P">Philipp Knechtges</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 23 pages, 6 figures, 6 tables
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Journal of Non-Newtonian Fluid Mechanics 322 (2023) 105133
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Fluid Dynamics (physics.flu-dyn)</span>; Numerical Analysis (math.NA)

</div>
</div>
</dd>
<dt><a name="item580">[580]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10364" title="Abstract">arXiv:2308.10364</a> (replaced) [<a href="/pdf/2308.10364" title="Download PDF">pdf</a>, <a href="/format/2308.10364" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SE(3) Equivariant Augmented Coupling Flows
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Midgley%2C+L+I">Laurence I. Midgley</a>, 
<a href="/search/cs?searchtype=author&query=Stimper%2C+V">Vincent Stimper</a>, 
<a href="/search/cs?searchtype=author&query=Antor%C3%A1n%2C+J">Javier Antor&#xe1;n</a>, 
<a href="/search/cs?searchtype=author&query=Mathieu%2C+E">Emile Mathieu</a>, 
<a href="/search/cs?searchtype=author&query=Sch%C3%B6lkopf%2C+B">Bernhard Sch&#xf6;lkopf</a>, 
<a href="/search/cs?searchtype=author&query=Hern%C3%A1ndez-Lobato%2C+J+M">Jos&#xe9; Miguel Hern&#xe1;ndez-Lobato</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computational Physics (physics.comp-ph)

</div>
</div>
</dd>
<dt><a name="item581">[581]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10544" title="Abstract">arXiv:2308.10544</a> (replaced) [<a href="/pdf/2308.10544" title="Download PDF">pdf</a>, <a href="/format/2308.10544" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Accelerated Model Training via Bayesian Data Selection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Deng%2C+Z">Zhijie Deng</a>, 
<a href="/search/cs?searchtype=author&query=Cui%2C+P">Peng Cui</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+J">Jun Zhu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item582">[582]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.11110" title="Abstract">arXiv:2308.11110</a> (replaced) [<a href="/pdf/2308.11110" title="Download PDF">pdf</a>, <a href="/format/2308.11110" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A novel analysis of utility in privacy pipelines, using Kronecker  products and quantitative information flow
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Alvim%2C+M+S">M&#xe1;rio S. Alvim</a>, 
<a href="/search/cs?searchtype=author&query=Fernandes%2C+N">Natasha Fernandes</a>, 
<a href="/search/cs?searchtype=author&query=McIver%2C+A">Annabelle McIver</a>, 
<a href="/search/cs?searchtype=author&query=Morgan%2C+C">Carroll Morgan</a>, 
<a href="/search/cs?searchtype=author&query=Nunes%2C+G+H">Gabriel H. Nunes</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
</div>
</dd>
<dt><a name="item583">[583]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.11849" title="Abstract">arXiv:2308.11849</a> (replaced) [<a href="/pdf/2308.11849" title="Download PDF">pdf</a>, <a href="/format/2308.11849" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Mobile Data-Driven Hierarchical Deep Reinforcement Learning Approach  for Real-time Demand-Responsive Railway Rescheduling and Station Overcrowding  Mitigation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Liu%2C+E">Enze Liu</a>, 
<a href="/search/eess?searchtype=author&query=Lin%2C+Z">Zhiyuan Lin</a>, 
<a href="/search/eess?searchtype=author&query=Wang%2C+J+Y+T">Judith Y.T. Wang</a>, 
<a href="/search/eess?searchtype=author&query=Chen%2C+H">Hong Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 42 pages,20 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item584">[584]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.12688" title="Abstract">arXiv:2308.12688</a> (replaced) [<a href="/pdf/2308.12688" title="Download PDF">pdf</a>, <a href="/format/2308.12688" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Whombat: An open-source annotation tool for machine learning development  in bioacoustics
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Balvanera%2C+S+M">Santiago Martinez Balvanera</a>, 
<a href="/search/cs?searchtype=author&query=Mac+Aodha%2C+O">Oisin Mac Aodha</a>, 
<a href="/search/cs?searchtype=author&query=Weldy%2C+M+J">Matthew J. Weldy</a>, 
<a href="/search/cs?searchtype=author&query=Pringle%2C+H">Holly Pringle</a>, 
<a href="/search/cs?searchtype=author&query=Browning%2C+E">Ella Browning</a>, 
<a href="/search/cs?searchtype=author&query=Jones%2C+K+E">Kate E. Jones</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 17 pages, 2 figures, 2 tables, to be submitted to Methods in Ecology and Evolution
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Audio and Speech Processing (eess.AS)

</div>
</div>
</dd>
<dt><a name="item585">[585]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.12736" title="Abstract">arXiv:2308.12736</a> (replaced) [<a href="/pdf/2308.12736" title="Download PDF">pdf</a>, <a href="/format/2308.12736" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FastSurfer-HypVINN: Automated sub-segmentation of the hypothalamus and  adjacent structures on high-resolutional brain MRI
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Estrada%2C+S">Santiago Estrada</a>, 
<a href="/search/cs?searchtype=author&query=K%C3%BCgler%2C+D">David K&#xfc;gler</a>, 
<a href="/search/cs?searchtype=author&query=Bahrami%2C+E">Emad Bahrami</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+P">Peng Xu</a>, 
<a href="/search/cs?searchtype=author&query=Mousa%2C+D">Dilshad Mousa</a>, 
<a href="/search/cs?searchtype=author&query=Breteler%2C+M+M+B">Monique M.B. Breteler</a>, 
<a href="/search/cs?searchtype=author&query=Aziz%2C+N+A">N. Ahmad Aziz</a>, 
<a href="/search/cs?searchtype=author&query=Reuter%2C+M">Martin Reuter</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted in Imaging Neuroscience
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item586">[586]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.14132" title="Abstract">arXiv:2308.14132</a> (replaced) [<a href="/pdf/2308.14132" title="Download PDF">pdf</a>, <a href="/format/2308.14132" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Detecting Language Model Attacks with Perplexity
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Alon%2C+G">Gabriel Alon</a>, 
<a href="/search/cs?searchtype=author&query=Kamfonas%2C+M">Michael Kamfonas</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Cryptography and Security (cs.CR); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item587">[587]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.14889" title="Abstract">arXiv:2308.14889</a> (replaced) [<a href="/pdf/2308.14889" title="Download PDF">pdf</a>, <a href="/format/2308.14889" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Scalable and Configurable Tracking for Any Rowhammer Threshold
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Saxena%2C+A">Anish Saxena</a>, 
<a href="/search/cs?searchtype=author&query=Qureshi%2C+M">Moinuddin Qureshi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Hardware Architecture (cs.AR)

</div>
</div>
</dd>
<dt><a name="item588">[588]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.15873" title="Abstract">arXiv:2308.15873</a> (replaced) [<a href="/pdf/2308.15873" title="Download PDF">pdf</a>, <a href="/format/2308.15873" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Minimum Width for Deep, Narrow MLP: A Diffeomorphism Approach
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hwang%2C+G">Geonho Hwang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Geometric Topology (math.GT)

</div>
</div>
</dd>
<dt><a name="item589">[589]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.00317" title="Abstract">arXiv:2309.00317</a> (replaced) [<a href="/pdf/2309.00317" title="Download PDF">pdf</a>, <a href="/format/2309.00317" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Text-based Approach For Link Prediction on Wikipedia Articles
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tran%2C+A+H">Anh Hoang Tran</a>, 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+T+M">Tam Minh Nguyen</a>, 
<a href="/search/cs?searchtype=author&query=Luu%2C+S+T">Son T. Luu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by DSAA 2023 Conference in the DSAA Student Competition Section
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
</div>
</dd>
<dt><a name="item590">[590]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.00543" title="Abstract">arXiv:2309.00543</a> (replaced) [<a href="/pdf/2309.00543" title="Download PDF">pdf</a>, <a href="/format/2309.00543" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Curating Naturally Adversarial Datasets for Learning-Enabled Medical  Cyber-Physical Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pugh%2C+S">Sydney Pugh</a>, 
<a href="/search/cs?searchtype=author&query=Ruchkin%2C+I">Ivan Ruchkin</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+I">Insup Lee</a>, 
<a href="/search/cs?searchtype=author&query=Weimer%2C+J">James Weimer</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item591">[591]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.02026" title="Abstract">arXiv:2309.02026</a> (replaced) [<a href="/pdf/2309.02026" title="Download PDF">pdf</a>, <a href="/format/2309.02026" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AutonomROS: A ReconROS-based Autonomous Driving Unit
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lienen%2C+C">Christian Lienen</a>, 
<a href="/search/cs?searchtype=author&query=Brede%2C+M">Mathis Brede</a>, 
<a href="/search/cs?searchtype=author&query=Karger%2C+D">Daniel Karger</a>, 
<a href="/search/cs?searchtype=author&query=Koch%2C+K">Kevin Koch</a>, 
<a href="/search/cs?searchtype=author&query=Logan%2C+D">Dalisha Logan</a>, 
<a href="/search/cs?searchtype=author&query=Mazur%2C+J">Janet Mazur</a>, 
<a href="/search/cs?searchtype=author&query=Nowosad%2C+A+P">Alexander Philipp Nowosad</a>, 
<a href="/search/cs?searchtype=author&query=Schnelle%2C+A">Alexander Schnelle</a>, 
<a href="/search/cs?searchtype=author&query=Waizy%2C+M">Mohness Waizy</a>, 
<a href="/search/cs?searchtype=author&query=Platzner%2C+M">Marco Platzner</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
</div>
</dd>
<dt><a name="item592">[592]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.02422" title="Abstract">arXiv:2309.02422</a> (replaced) [<a href="/pdf/2309.02422" title="Download PDF">pdf</a>, <a href="/format/2309.02422" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Maximum Mean Discrepancy Meets Neural Networks: The  Radon-Kolmogorov-Smirnov Test
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Paik%2C+S">Seunghoon Paik</a>, 
<a href="/search/stat?searchtype=author&query=Celentano%2C+M">Michael Celentano</a>, 
<a href="/search/stat?searchtype=author&query=Green%2C+A">Alden Green</a>, 
<a href="/search/stat?searchtype=author&query=Tibshirani%2C+R+J">Ryan J. Tibshirani</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG); Methodology (stat.ME)

</div>
</div>
</dd>
<dt><a name="item593">[593]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.03783" title="Abstract">arXiv:2309.03783</a> (replaced) [<a href="/pdf/2309.03783" title="Download PDF">pdf</a>, <a href="/ps/2309.03783" title="Download PostScript">ps</a>, <a href="/format/2309.03783" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Not your private t&#xea;te-&#xe0;-t&#xea;te: leveraging the power of higher-order  networks to study animal communication
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-bio?searchtype=author&query=Iacopini%2C+I">Iacopo Iacopini</a>, 
<a href="/search/q-bio?searchtype=author&query=Foote%2C+J+R">Jennifer R Foote</a>, 
<a href="/search/q-bio?searchtype=author&query=Fefferman%2C+N+H">Nina H Fefferman</a>, 
<a href="/search/q-bio?searchtype=author&query=Derryberry%2C+E+P">Elizabeth P Derryberry</a>, 
<a href="/search/q-bio?searchtype=author&query=Silk%2C+M+J">Matthew J Silk</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Populations and Evolution (q-bio.PE)</span>; Social and Information Networks (cs.SI); Quantitative Methods (q-bio.QM)

</div>
</div>
</dd>
<dt><a name="item594">[594]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.04037" title="Abstract">arXiv:2309.04037</a> (replaced) [<a href="/pdf/2309.04037" title="Download PDF">pdf</a>, <a href="/format/2309.04037" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SRN-SZ: Deep Leaning-Based Scientific Error-bounded Lossy Compression  with Super-resolution Neural Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jinyang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Di%2C+S">Sheng Di</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+S">Sian Jin</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+K">Kai Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+X">Xin Liang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Z">Zizhong Chen</a>, 
<a href="/search/cs?searchtype=author&query=Cappello%2C+F">Franck Cappello</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Distributed, Parallel, and Cluster Computing (cs.DC); Information Theory (cs.IT)

</div>
</div>
</dd>
<dt><a name="item595">[595]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.04190" title="Abstract">arXiv:2309.04190</a> (replaced) [<a href="/pdf/2309.04190" title="Download PDF">pdf</a>, <a href="/format/2309.04190" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SegmentAnything helps microscopy images based automatic and quantitative  organoid detection and analysis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Xing%2C+X">Xiaodan Xing</a>, 
<a href="/search/eess?searchtype=author&query=Tang%2C+C">Chunling Tang</a>, 
<a href="/search/eess?searchtype=author&query=Guo%2C+Y">Yunzhe Guo</a>, 
<a href="/search/eess?searchtype=author&query=Kurniawan%2C+N">Nicholas Kurniawan</a>, 
<a href="/search/eess?searchtype=author&query=Yang%2C+G">Guang Yang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> submitted to SPIE: Medical Imaging 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV); Quantitative Methods (q-bio.QM)

</div>
</div>
</dd>
<dt><a name="item596">[596]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.04352" title="Abstract">arXiv:2309.04352</a> (replaced) [<a href="/pdf/2309.04352" title="Download PDF">pdf</a>, <a href="/format/2309.04352" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SHAPE: A Framework for Evaluating the Ethicality of Influence
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bezou-Vrakatseli%2C+E">Elfia Bezou-Vrakatseli</a>, 
<a href="/search/cs?searchtype=author&query=Br%C3%BCckner%2C+B">Benedikt Br&#xfc;ckner</a>, 
<a href="/search/cs?searchtype=author&query=Thorburn%2C+L">Luke Thorburn</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> An earlier version of this paper was accepted at EUMAS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Multiagent Systems (cs.MA)</span>

</div>
</div>
</dd>
<dt><a name="item597">[597]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.05139" title="Abstract">arXiv:2309.05139</a> (replaced) [<a href="/pdf/2309.05139" title="Download PDF">pdf</a>, <a href="/format/2309.05139" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Skeleton-based Approach For Rock Crack Detection Towards A Climbing  Robot Application
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Roberts%2C+J+S">Josselin Somerville Roberts</a>, 
<a href="/search/cs?searchtype=author&query=Giacomelli%2C+P">Paul-Emile Giacomelli</a>, 
<a href="/search/cs?searchtype=author&query=Gozlan%2C+Y">Yoni Gozlan</a>, 
<a href="/search/cs?searchtype=author&query=Di%2C+J">Julia Di</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> IEEE IRC 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Robotics (cs.RO)

</div>
</div>
</dd>
<dt><a name="item598">[598]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.06782" title="Abstract">arXiv:2309.06782</a> (replaced) [<a href="/pdf/2309.06782" title="Download PDF">pdf</a>, <a href="/format/2309.06782" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Improved particle-flow event reconstruction with scalable neural  networks for current and future particle detectors
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Pata%2C+J">Joosep Pata</a>, 
<a href="/search/physics?searchtype=author&query=Wulff%2C+E">Eric Wulff</a>, 
<a href="/search/physics?searchtype=author&query=Mokhtar%2C+F">Farouk Mokhtar</a>, 
<a href="/search/physics?searchtype=author&query=Southwick%2C+D">David Southwick</a>, 
<a href="/search/physics?searchtype=author&query=Zhang%2C+M">Mengke Zhang</a>, 
<a href="/search/physics?searchtype=author&query=Girone%2C+M">Maria Girone</a>, 
<a href="/search/physics?searchtype=author&query=Duarte%2C+J">Javier Duarte</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 19 pages, 7 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Analysis, Statistics and Probability (physics.data-an)</span>; Machine Learning (cs.LG); High Energy Physics - Experiment (hep-ex); Instrumentation and Detectors (physics.ins-det); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item599">[599]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.07289" title="Abstract">arXiv:2309.07289</a> (replaced) [<a href="/pdf/2309.07289" title="Download PDF">pdf</a>, <a href="/format/2309.07289" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> User Training with Error Augmentation for Electromyogram-based Gesture  Classification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bicer%2C+Y">Yunus Bicer</a>, 
<a href="/search/cs?searchtype=author&query=Smedemark-Margulies%2C+N">Niklas Smedemark-Margulies</a>, 
<a href="/search/cs?searchtype=author&query=Celik%2C+B">Basak Celik</a>, 
<a href="/search/cs?searchtype=author&query=Sunger%2C+E">Elifnur Sunger</a>, 
<a href="/search/cs?searchtype=author&query=Orendorff%2C+R">Ryan Orendorff</a>, 
<a href="/search/cs?searchtype=author&query=Naufel%2C+S">Stephanie Naufel</a>, 
<a href="/search/cs?searchtype=author&query=Imbiriba%2C+T">Tales Imbiriba</a>, 
<a href="/search/cs?searchtype=author&query=Erdo%C4%9Fmu%C5%9F%2C+D">Deniz Erdo&#x11f;mu&#x15f;</a>, 
<a href="/search/cs?searchtype=author&query=Tunik%2C+E">Eugene Tunik</a>, 
<a href="/search/cs?searchtype=author&query=Yarossi%2C+M">Mathew Yarossi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 10 figures. V2: Fix latex characters in author name
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Machine Learning (cs.LG); Signal Processing (eess.SP)

</div>
</div>
</dd>
<dt><a name="item600">[600]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.11523" title="Abstract">arXiv:2309.11523</a> (replaced) [<a href="/pdf/2309.11523" title="Download PDF">pdf</a>, <a href="/format/2309.11523" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> RMT: Retentive Networks Meet Vision Transformers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fan%2C+Q">Qihang Fan</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+H">Huaibo Huang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+M">Mingrui Chen</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+H">Hongmin Liu</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+R">Ran He</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Fix the bug in the UperNet. Code will be released at <a href="https://github.com/qhfan/RMT">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item601">[601]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13057" title="Abstract">arXiv:2309.13057</a> (replaced) [<a href="/pdf/2309.13057" title="Download PDF">pdf</a>, <a href="/ps/2309.13057" title="Download PostScript">ps</a>, <a href="/format/2309.13057" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Return on Investment in AI Ethics: A Holistic Framework
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bevilacqua%2C+M">Marialena Bevilacqua</a>, 
<a href="/search/cs?searchtype=author&query=Berente%2C+N">Nicholas Berente</a>, 
<a href="/search/cs?searchtype=author&query=Domin%2C+H">Heather Domin</a>, 
<a href="/search/cs?searchtype=author&query=Goehring%2C+B">Brian Goehring</a>, 
<a href="/search/cs?searchtype=author&query=Rossi%2C+F">Francesca Rossi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> A subsequent version of this paper will be published in the Hawaii International Conference on System Sciences (HICSS) 2024 Proceedings
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>

</div>
</div>
</dd>
<dt><a name="item602">[602]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13762" title="Abstract">arXiv:2309.13762</a> (replaced) [<a href="/pdf/2309.13762" title="Download PDF">pdf</a>, <a href="/format/2309.13762" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Veer: Verifying Equivalence of Workflow Versions in Iterative Data  Analytics (Extended Version)
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Alsudais%2C+S">Sadeem Alsudais</a>, 
<a href="/search/cs?searchtype=author&query=Kumar%2C+A">Avinash Kumar</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+C">Chen Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Databases (cs.DB)</span>

</div>
</div>
</dd>
<dt><a name="item603">[603]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15601" title="Abstract">arXiv:2309.15601</a> (replaced) [<a href="/pdf/2309.15601" title="Download PDF">pdf</a>, <a href="/format/2309.15601" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Study on Tiny YOLO for Resource Constrained Xray Threat Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ambati%2C+R">Raghav Ambati</a>, 
<a href="/search/cs?searchtype=author&query=Borthakur%2C+A">Ayon Borthakur</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Paper Accepted in AI-ML Systems '23, SAI4E Workshop, Bangalore
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neural and Evolutionary Computing (cs.NE)</span>

</div>
</div>
</dd>
<dt><a name="item604">[604]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.00496" title="Abstract">arXiv:2310.00496</a> (replaced) [<a href="/pdf/2310.00496" title="Download PDF">pdf</a>, <a href="/format/2310.00496" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Sparsity Roofline: Understanding the Hardware Limits of Sparse  Neural Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shinn%2C+C">Cameron Shinn</a>, 
<a href="/search/cs?searchtype=author&query=McCarthy%2C+C">Collin McCarthy</a>, 
<a href="/search/cs?searchtype=author&query=Muralidharan%2C+S">Saurav Muralidharan</a>, 
<a href="/search/cs?searchtype=author&query=Osama%2C+M">Muhammad Osama</a>, 
<a href="/search/cs?searchtype=author&query=Owens%2C+J+D">John D. Owens</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item605">[605]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.01258" title="Abstract">arXiv:2310.01258</a> (replaced) [<a href="/pdf/2310.01258" title="Download PDF">pdf</a>, <a href="/format/2310.01258" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MobileNVC: Real-time 1080p Neural Video Compression on a Mobile Device
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=van+Rozendaal%2C+T">Ties van Rozendaal</a>, 
<a href="/search/eess?searchtype=author&query=Singhal%2C+T">Tushar Singhal</a>, 
<a href="/search/eess?searchtype=author&query=Le%2C+H">Hoang Le</a>, 
<a href="/search/eess?searchtype=author&query=Sautiere%2C+G">Guillaume Sautiere</a>, 
<a href="/search/eess?searchtype=author&query=Said%2C+A">Amir Said</a>, 
<a href="/search/eess?searchtype=author&query=Buska%2C+K">Krishna Buska</a>, 
<a href="/search/eess?searchtype=author&query=Raha%2C+A">Anjuman Raha</a>, 
<a href="/search/eess?searchtype=author&query=Kalatzis%2C+D">Dimitris Kalatzis</a>, 
<a href="/search/eess?searchtype=author&query=Mehta%2C+H">Hitarth Mehta</a>, 
<a href="/search/eess?searchtype=author&query=Mayer%2C+F">Frank Mayer</a>, 
<a href="/search/eess?searchtype=author&query=Zhang%2C+L">Liang Zhang</a>, 
<a href="/search/eess?searchtype=author&query=Nagel%2C+M">Markus Nagel</a>, 
<a href="/search/eess?searchtype=author&query=Wiggers%2C+A">Auke Wiggers</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Matches version published at WACV 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item606">[606]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.02641" title="Abstract">arXiv:2310.02641</a> (replaced) [<a href="/pdf/2310.02641" title="Download PDF">pdf</a>, <a href="/format/2310.02641" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deformation-Invariant Neural Network and Its Applications in Distorted  Image Restoration and Analysis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Han Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Q">Qiguang Chen</a>, 
<a href="/search/cs?searchtype=author&query=Lui%2C+L+M">Lok Ming Lui</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Image and Video Processing (eess.IV)

</div>
</div>
</dd>
<dt><a name="item607">[607]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.02643" title="Abstract">arXiv:2310.02643</a> (replaced) [<a href="/pdf/2310.02643" title="Download PDF">pdf</a>, <a href="/ps/2310.02643" title="Download PostScript">ps</a>, <a href="/format/2310.02643" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Online Algorithms for Spectral Hypergraph Sparsification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Soma%2C+T">Tasuku Soma</a>, 
<a href="/search/cs?searchtype=author&query=Tung%2C+K+C">Kam Chuen Tung</a>, 
<a href="/search/cs?searchtype=author&query=Yoshida%2C+Y">Yuichi Yoshida</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Improved the number of hyperedges from the previous version
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>

</div>
</div>
</dd>
<dt><a name="item608">[608]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.03598" title="Abstract">arXiv:2310.03598</a> (replaced) [<a href="/pdf/2310.03598" title="Download PDF">pdf</a>, <a href="/format/2310.03598" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Divide, Conquer and Verify: Improving Symbolic Execution Performance
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Scherb%2C+C">Christopher Scherb</a>, 
<a href="/search/cs?searchtype=author&query=Heitz%2C+L+B">Luc Bryan Heitz</a>, 
<a href="/search/cs?searchtype=author&query=Grieder%2C+H">Hermann Grieder</a>, 
<a href="/search/cs?searchtype=author&query=Mattmann%2C+O">Olivier Mattmann</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Symbolic Computation (cs.SC); Systems and Control (eess.SY)

</div>
</div>
</dd>
<dt><a name="item609">[609]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.03735" title="Abstract">arXiv:2310.03735</a> (replaced) [<a href="/pdf/2310.03735" title="Download PDF">pdf</a>, <a href="/format/2310.03735" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An Uncertainty Principle for the Curvelet Transform, and the  Infeasibility of Quantum Algorithms for Finding Short Lattice Vectors
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Liu%2C+Y">Yi-Kai Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> v2: 23 pages, 2 figures, slightly improved results, reorganized some sections, added appendix
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Cryptography and Security (cs.CR)

</div>
</div>
</dd>
<dt><a name="item610">[610]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.04411" title="Abstract">arXiv:2310.04411</a> (replaced) [<a href="/pdf/2310.04411" title="Download PDF">pdf</a>, <a href="/format/2310.04411" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Understanding, Predicting and Better Resolving Q-Value Divergence in  Offline-RL
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yue%2C+Y">Yang Yue</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+R">Rui Lu</a>, 
<a href="/search/cs?searchtype=author&query=Kang%2C+B">Bingyi Kang</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+S">Shiji Song</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+G">Gao Huang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 31 pages, 20 figures
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item611">[611]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.05166" title="Abstract">arXiv:2310.05166</a> (replaced) [<a href="/pdf/2310.05166" title="Download PDF">pdf</a>, <a href="/format/2310.05166" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Corrected Expected Improvement Acquisition Function Under Noisy  Observations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhou%2C+H">Han Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+X">Xingchen Ma</a>, 
<a href="/search/cs?searchtype=author&query=Blaschko%2C+M+B">Matthew B Blaschko</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item612">[612]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.05309" title="Abstract">arXiv:2310.05309</a> (replaced) [<a href="/pdf/2310.05309" title="Download PDF">pdf</a>, <a href="/format/2310.05309" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Optimizing Solution-Samplers for Combinatorial Problems: The Landscape  of Policy-Gradient Methods
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Caramanis%2C+C">Constantine Caramanis</a>, 
<a href="/search/cs?searchtype=author&query=Fotakis%2C+D">Dimitris Fotakis</a>, 
<a href="/search/cs?searchtype=author&query=Kalavasis%2C+A">Alkis Kalavasis</a>, 
<a href="/search/cs?searchtype=author&query=Kontonis%2C+V">Vasilis Kontonis</a>, 
<a href="/search/cs?searchtype=author&query=Tzamos%2C+C">Christos Tzamos</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Data Structures and Algorithms (cs.DS); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item613">[613]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.06827" title="Abstract">arXiv:2310.06827</a> (replaced) [<a href="/pdf/2310.06827" title="Download PDF">pdf</a>, <a href="/format/2310.06827" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Teaching Language Models to Hallucinate Less with Synthetic Tasks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jones%2C+E">Erik Jones</a>, 
<a href="/search/cs?searchtype=author&query=Palangi%2C+H">Hamid Palangi</a>, 
<a href="/search/cs?searchtype=author&query=Sim%C3%B5es%2C+C">Clarisse Sim&#xf5;es</a>, 
<a href="/search/cs?searchtype=author&query=Chandrasekaran%2C+V">Varun Chandrasekaran</a>, 
<a href="/search/cs?searchtype=author&query=Mukherjee%2C+S">Subhabrata Mukherjee</a>, 
<a href="/search/cs?searchtype=author&query=Mitra%2C+A">Arindam Mitra</a>, 
<a href="/search/cs?searchtype=author&query=Awadallah%2C+A">Ahmed Awadallah</a>, 
<a href="/search/cs?searchtype=author&query=Kamar%2C+E">Ece Kamar</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item614">[614]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.08006" title="Abstract">arXiv:2310.08006</a> (replaced) [<a href="/pdf/2310.08006" title="Download PDF">pdf</a>, <a href="/ps/2310.08006" title="Download PostScript">ps</a>, <a href="/format/2310.08006" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MCPNS: A Macropixel Collocated Position and Its Neighbors Search for  Plenoptic 2.0 Video Coding
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Van+Duong%2C+V">Vinh Van Duong</a>, 
<a href="/search/cs?searchtype=author&query=Huu%2C+T+N">Thuc Nguyen Huu</a>, 
<a href="/search/cs?searchtype=author&query=Yim%2C+J">Jonghoon Yim</a>, 
<a href="/search/cs?searchtype=author&query=Jeon%2C+B">Byeungwoo Jeon</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Under review
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Multimedia (cs.MM)</span>

</div>
</div>
</dd>
<dt><a name="item615">[615]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.08157" title="Abstract">arXiv:2310.08157</a> (replaced) [<a href="/pdf/2310.08157" title="Download PDF">pdf</a>, <a href="/ps/2310.08157" title="Download PostScript">ps</a>, <a href="/format/2310.08157" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MCRepair: Multi-Chunk Program Repair via Patch Optimization with Buggy  Block
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kim%2C+J">Jisung Kim</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+B">Byeongjung Lee</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 3 pages
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> This is the revised manuscript of the conference paper published
  in the 38th ACM/SIGAPP Symposium on Applied Computing (SAC 2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
</div>
</dd>
<dt><a name="item616">[616]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.08812" title="Abstract">arXiv:2310.08812</a> (replaced) [<a href="/pdf/2310.08812" title="Download PDF">pdf</a>, <a href="/format/2310.08812" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Nonlinear Method for time series forecasting using VMD-GARCH-LSTM  model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Gui%2C+Z">Zhengtao Gui</a>, 
<a href="/search/stat?searchtype=author&query=Li%2C+H">Haoyuan Li</a>, 
<a href="/search/stat?searchtype=author&query=Xu%2C+S">Sijie Xu</a>, 
<a href="/search/stat?searchtype=author&query=Chen%2C+Y">Yu Chen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Methodology (stat.ME)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item617">[617]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.09478" title="Abstract">arXiv:2310.09478</a> (replaced) [<a href="/pdf/2310.09478" title="Download PDF">pdf</a>, <a href="/format/2310.09478" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MiniGPT-v2: large language model as a unified interface for  vision-language multi-task learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Jun Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+D">Deyao Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+X">Xiaoqian Shen</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xiang Li</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zechun Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+P">Pengchuan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Krishnamoorthi%2C+R">Raghuraman Krishnamoorthi</a>, 
<a href="/search/cs?searchtype=author&query=Chandra%2C+V">Vikas Chandra</a>, 
<a href="/search/cs?searchtype=author&query=Xiong%2C+Y">Yunyang Xiong</a>, 
<a href="/search/cs?searchtype=author&query=Elhoseiny%2C+M">Mohamed Elhoseiny</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item618">[618]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.10149" title="Abstract">arXiv:2310.10149</a> (replaced) [<a href="/e-print/2310.10149" title="Download source">src</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Recursive Segmentation Living Image: An eXplainable AI (XAI) Approach  for Computing Structural Beauty of Images or the Livingness of Space
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Qianxiang%2C+Y">Yao Qianxiang</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+B">Bin Jiang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> There are some problems with the paper
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item619">[619]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.11807" title="Abstract">arXiv:2310.11807</a> (replaced) [<a href="/pdf/2310.11807" title="Download PDF">pdf</a>, <a href="/format/2310.11807" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning Global Quantum Properties from Local Measurements with Neural  Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Wu%2C+Y">Ya-Dong Wu</a>, 
<a href="/search/quant-ph?searchtype=author&query=Zhu%2C+Y">Yan Zhu</a>, 
<a href="/search/quant-ph?searchtype=author&query=Wang%2C+Y">Yuexuan Wang</a>, 
<a href="/search/quant-ph?searchtype=author&query=Chiribella%2C+G">Giulio Chiribella</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item620">[620]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.12425" title="Abstract">arXiv:2310.12425</a> (replaced) [<a href="/pdf/2310.12425" title="Download PDF">pdf</a>, <a href="/ps/2310.12425" title="Download PostScript">ps</a>, <a href="/format/2310.12425" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Automated Repair of Declarative Software Specifications in the Era of  Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hasan%2C+M+R">Md Rashedul Hasan</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jiawei Li</a>, 
<a href="/search/cs?searchtype=author&query=Ahmed%2C+I">Iftekhar Ahmed</a>, 
<a href="/search/cs?searchtype=author&query=Bagheri%2C+H">Hamid Bagheri</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 Pages with reference, 4 Tables, 2 Figures, 2 Listings
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item621">[621]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.12567" title="Abstract">arXiv:2310.12567</a> (replaced) [<a href="/pdf/2310.12567" title="Download PDF">pdf</a>, <a href="/format/2310.12567" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Safety-Gymnasium: A Unified Safe Reinforcement Learning Benchmark
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ji%2C+J">Jiaming Ji</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+B">Borong Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+J">Jiayi Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Pan%2C+X">Xuehai Pan</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+W">Weidong Huang</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+R">Ruiyang Sun</a>, 
<a href="/search/cs?searchtype=author&query=Geng%2C+Y">Yiran Geng</a>, 
<a href="/search/cs?searchtype=author&query=Zhong%2C+Y">Yifan Zhong</a>, 
<a href="/search/cs?searchtype=author&query=Dai%2C+J">Juntao Dai</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yaodong Yang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Published at NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item622">[622]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.12798" title="Abstract">arXiv:2310.12798</a> (replaced) [<a href="/pdf/2310.12798" title="Download PDF">pdf</a>, <a href="/format/2310.12798" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MolCA: Molecular Graph-Language Modeling with Cross-Modal Projector and  Uni-Modal Adapter
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zhiyuan Liu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+S">Sihang Li</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+Y">Yanchen Luo</a>, 
<a href="/search/cs?searchtype=author&query=Fei%2C+H">Hao Fei</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+Y">Yixin Cao</a>, 
<a href="/search/cs?searchtype=author&query=Kawaguchi%2C+K">Kenji Kawaguchi</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xiang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Chua%2C+T">Tat-Seng Chua</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> EMNLP main conference. 9 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Multimedia (cs.MM)

</div>
</div>
</dd>
<dt><a name="item623">[623]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.14122" title="Abstract">arXiv:2310.14122</a> (replaced) [<a href="/pdf/2310.14122" title="Download PDF">pdf</a>, <a href="/format/2310.14122" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Beyond Yes and No: Improving Zero-Shot LLM Rankers via Scoring  Fine-Grained Relevance Labels
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhuang%2C+H">Honglei Zhuang</a>, 
<a href="/search/cs?searchtype=author&query=Qin%2C+Z">Zhen Qin</a>, 
<a href="/search/cs?searchtype=author&query=Hui%2C+K">Kai Hui</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+J">Junru Wu</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+L">Le Yan</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xuanhui Wang</a>, 
<a href="/search/cs?searchtype=author&query=Bendersky%2C+M">Michael Bendersky</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>

</div>
</div>
</dd>
<dt><a name="item624">[624]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.14918" title="Abstract">arXiv:2310.14918</a> (replaced) [<a href="/pdf/2310.14918" title="Download PDF">pdf</a>, <a href="/format/2310.14918" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ARNIQA: Learning Distortion Manifold for Image Quality Assessment
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Agnolucci%2C+L">Lorenzo Agnolucci</a>, 
<a href="/search/cs?searchtype=author&query=Galteri%2C+L">Leonardo Galteri</a>, 
<a href="/search/cs?searchtype=author&query=Bertini%2C+M">Marco Bertini</a>, 
<a href="/search/cs?searchtype=author&query=Del+Bimbo%2C+A">Alberto Del Bimbo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> WACV2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item625">[625]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.15015" title="Abstract">arXiv:2310.15015</a> (replaced) [<a href="/pdf/2310.15015" title="Download PDF">pdf</a>, <a href="/ps/2310.15015" title="Download PostScript">ps</a>, <a href="/format/2310.15015" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Leveraging Deep Learning for Abstractive Code Summarization of  Unofficial Documentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Naghshzan%2C+A">AmirHossein Naghshzan</a>, 
<a href="/search/cs?searchtype=author&query=Guerrouj%2C+L">Latifa Guerrouj</a>, 
<a href="/search/cs?searchtype=author&query=Baysal%2C+O">Olga Baysal</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item626">[626]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.15106" title="Abstract">arXiv:2310.15106</a> (replaced) [<a href="/pdf/2310.15106" title="Download PDF">pdf</a>, <a href="/format/2310.15106" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Theoretical Analysis of the Radio Map Estimation Problem
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Romero%2C+D">Daniel Romero</a>, 
<a href="/search/cs?searchtype=author&query=Ha%2C+T+N">Tien Ngoc Ha</a>, 
<a href="/search/cs?searchtype=author&query=Shrestha%2C+R">Raju Shrestha</a>, 
<a href="/search/cs?searchtype=author&query=Franceschetti%2C+M">Massimo Franceschetti</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
</div>
</dd>
<dt><a name="item627">[627]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.15642" title="Abstract">arXiv:2310.15642</a> (replaced) [<a href="/pdf/2310.15642" title="Download PDF">pdf</a>, <a href="/format/2310.15642" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GitBug-Actions: Building Reproducible Bug-Fix Benchmarks with GitHub  Actions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Saavedra%2C+N">Nuno Saavedra</a>, 
<a href="/search/cs?searchtype=author&query=Silva%2C+A">Andr&#xe9; Silva</a>, 
<a href="/search/cs?searchtype=author&query=Monperrus%2C+M">Martin Monperrus</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
</div>
</dd>
<dt><a name="item628">[628]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.16507" title="Abstract">arXiv:2310.16507</a> (replaced) [<a href="/pdf/2310.16507" title="Download PDF">pdf</a>, <a href="/ps/2310.16507" title="Download PostScript">ps</a>, <a href="/format/2310.16507" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Information-theoretical analysis of event-triggered molecular  communication
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Labidi%2C+W">Wafa Labidi</a>, 
<a href="/search/cs?searchtype=author&query=Deppe%2C+C">Christian Deppe</a>, 
<a href="/search/cs?searchtype=author&query=Boche%2C+H">Holger Boche</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>

</div>
</div>
</dd>
<dt><a name="item629">[629]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.16559" title="Abstract">arXiv:2310.16559</a> (replaced) [<a href="/pdf/2310.16559" title="Download PDF">pdf</a>, <a href="/ps/2310.16559" title="Download PostScript">ps</a>, <a href="/format/2310.16559" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multi-structure Objects Points-to Analysis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=An%2C+X">Xun An</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Programming Languages (cs.PL)</span>

</div>
</div>
</dd>
<dt><a name="item630">[630]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.16858" title="Abstract">arXiv:2310.16858</a> (replaced) [<a href="/pdf/2310.16858" title="Download PDF">pdf</a>, <a href="/format/2310.16858" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> 4D-Editor: Interactive Object-level Editing in Dynamic Neural Radiance  Fields via Semantic Distillation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jiang%2C+D">Dadong Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Ke%2C+Z">Zhihui Ke</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+X">Xiaobo Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+X">Xidong Shi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project page: <a href="https://patrickddj.github.io/4D-Editor">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item631">[631]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.17273" title="Abstract">arXiv:2310.17273</a> (replaced) [<a href="/pdf/2310.17273" title="Download PDF">pdf</a>, <a href="/format/2310.17273" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Looping in the Human: Collaborative and Explainable Bayesian  Optimization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Adachi%2C+M">Masaki Adachi</a>, 
<a href="/search/cs?searchtype=author&query=Planden%2C+B">Brady Planden</a>, 
<a href="/search/cs?searchtype=author&query=Howey%2C+D+A">David A. Howey</a>, 
<a href="/search/cs?searchtype=author&query=Muandet%2C+K">Krikamol Muandet</a>, 
<a href="/search/cs?searchtype=author&query=Osborne%2C+M+A">Michael A. Osborne</a>, 
<a href="/search/cs?searchtype=author&query=Chau%2C+S+L">Siu Lun Chau</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 22 pages, 9 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Human-Computer Interaction (cs.HC); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item632">[632]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.17599" title="Abstract">arXiv:2310.17599</a> (replaced) [<a href="/pdf/2310.17599" title="Download PDF">pdf</a>, <a href="/ps/2310.17599" title="Download PostScript">ps</a>, <a href="/format/2310.17599" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Time-dependent electromagnetic scattering from dispersive materials
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Nick%2C+J">J&#xf6;rg Nick</a>, 
<a href="/search/math?searchtype=author&query=Burkhard%2C+S">Selina Burkhard</a>, 
<a href="/search/math?searchtype=author&query=Lubich%2C+C">Christian Lubich</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: text overlap with <a href="/abs/2103.08930">arXiv:2103.08930</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
</div>
</dd>
<dt><a name="item633">[633]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.18581" title="Abstract">arXiv:2310.18581</a> (replaced) [<a href="/pdf/2310.18581" title="Download PDF">pdf</a>, <a href="/format/2310.18581" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Accelerating LLaMA Inference by Enabling Intermediate Layer Decoding via  Instruction Tuning with LITE
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Varshney%2C+N">Neeraj Varshney</a>, 
<a href="/search/cs?searchtype=author&query=Chatterjee%2C+A">Agneet Chatterjee</a>, 
<a href="/search/cs?searchtype=author&query=Parmar%2C+M">Mihir Parmar</a>, 
<a href="/search/cs?searchtype=author&query=Baral%2C+C">Chitta Baral</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item634">[634]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.18620" title="Abstract">arXiv:2310.18620</a> (replaced) [<a href="/pdf/2310.18620" title="Download PDF">pdf</a>, <a href="/format/2310.18620" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ODM3D: Alleviating Foreground Sparsity for Semi-Supervised Monocular 3D  Object Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+W">Weijia Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+D">Dongnan Liu</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+C">Chao Ma</a>, 
<a href="/search/cs?searchtype=author&query=Cai%2C+W">Weidong Cai</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by WACV 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item635">[635]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.18651" title="Abstract">arXiv:2310.18651</a> (replaced) [<a href="/pdf/2310.18651" title="Download PDF">pdf</a>, <a href="/ps/2310.18651" title="Download PostScript">ps</a>, <a href="/format/2310.18651" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LG-Self: Local-Global Self-Supervised Visual Representation Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Javidani%2C+A">Ali Javidani</a>, 
<a href="/search/cs?searchtype=author&query=Sadeghi%2C+M+A">Mohammad Amin Sadeghi</a>, 
<a href="/search/cs?searchtype=author&query=Araabi%2C+B+N">Babak Nadjar Araabi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item636">[636]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.18725" title="Abstract">arXiv:2310.18725</a> (replaced) [<a href="/pdf/2310.18725" title="Download PDF">pdf</a>, <a href="/format/2310.18725" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Evolution of the Interplay Between Input Distributions and Linear  Regions in Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Qi%2C+X">Xuan Qi</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+Y">Yi Wei</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Under review
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item637">[637]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.19005" title="Abstract">arXiv:2310.19005</a> (replaced) [<a href="/pdf/2310.19005" title="Download PDF">pdf</a>, <a href="/format/2310.19005" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Kernel-based Joint Multiple Graph Learning and Clustering of Graph  Signals
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Alizade%2C+M+H">Mohamad H. Alizade</a>, 
<a href="/search/eess?searchtype=author&query=Einizade%2C+A">Aref Einizade</a>, 
<a href="/search/eess?searchtype=author&query=Giraldo%2C+J+H">Jhony H. Giraldo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages, 3 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item638">[638]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.19102" title="Abstract">arXiv:2310.19102</a> (replaced) [<a href="/pdf/2310.19102" title="Download PDF">pdf</a>, <a href="/format/2310.19102" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Atom: Low-bit Quantization for Efficient and Accurate LLM Serving
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Y">Yilong Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+C">Chien-Yu Lin</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+K">Kan Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Ye%2C+Z">Zihao Ye</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+L">Lequn Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+S">Size Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Ceze%2C+L">Luis Ceze</a>, 
<a href="/search/cs?searchtype=author&query=Krishnamurthy%2C+A">Arvind Krishnamurthy</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+T">Tianqi Chen</a>, 
<a href="/search/cs?searchtype=author&query=Kasikci%2C+B">Baris Kasikci</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item639">[639]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.19109" title="Abstract">arXiv:2310.19109</a> (replaced) [<a href="/pdf/2310.19109" title="Download PDF">pdf</a>, <a href="/ps/2310.19109" title="Download PostScript">ps</a>, <a href="/format/2310.19109" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Dynamic Task and Weight Prioritization Curriculum Learning for  Multimodal Imagery
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Alsan%2C+H+F">Huseyin Fuat Alsan</a>, 
<a href="/search/cs?searchtype=author&query=Arsan%2C+T">Taner Arsan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item640">[640]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.19253" title="Abstract">arXiv:2310.19253</a> (replaced) [<a href="/pdf/2310.19253" title="Download PDF">pdf</a>, <a href="/format/2310.19253" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Flow-based distributionally robust optimization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+C">Chen Xu</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+J">Jonghyeok Lee</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+X">Xiuyuan Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+Y">Yao Xie</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Methodology (stat.ME); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item641">[641]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.19685" title="Abstract">arXiv:2310.19685</a> (replaced) [<a href="/pdf/2310.19685" title="Download PDF">pdf</a>, <a href="/format/2310.19685" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DGFN: Double Generative Flow Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lau%2C+E">Elaine Lau</a>, 
<a href="/search/cs?searchtype=author&query=Vemgal%2C+N">Nikhil Vemgal</a>, 
<a href="/search/cs?searchtype=author&query=Precup%2C+D">Doina Precup</a>, 
<a href="/search/cs?searchtype=author&query=Bengio%2C+E">Emmanuel Bengio</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to NeurIPS 2023 Workshop
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Biomolecules (q-bio.BM)

</div>
</div>
</dd>
<dt><a name="item642">[642]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.19695" title="Abstract">arXiv:2310.19695</a> (replaced) [<a href="/pdf/2310.19695" title="Download PDF">pdf</a>, <a href="/format/2310.19695" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deep-learning-based decomposition of overlapping-sparse images:  application at the vertex of neutrino interactions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Alonso-Monsalve%2C+S">Sa&#xfa;l Alonso-Monsalve</a>, 
<a href="/search/cs?searchtype=author&query=Sgalaberna%2C+D">Davide Sgalaberna</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+X">Xingyu Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Molines%2C+A">Adrien Molines</a>, 
<a href="/search/cs?searchtype=author&query=McGrew%2C+C">Clark McGrew</a>, 
<a href="/search/cs?searchtype=author&query=Rubbia%2C+A">Andr&#xe9; Rubbia</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 15 pages, 6 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG); High Energy Physics - Experiment (hep-ex)

</div>
</div>
</dd>
<dt><a name="item643">[643]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.20060" title="Abstract">arXiv:2310.20060</a> (replaced) [<a href="/pdf/2310.20060" title="Download PDF">pdf</a>, <a href="/format/2310.20060" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AdaSub: Stochastic Optimization Using Second-Order Information in  Low-Dimensional Subspaces
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=da+Mata%2C+J+V+G">Jo&#xe3;o Victor Galv&#xe3;o da Mata</a>, 
<a href="/search/math?searchtype=author&query=Andersen%2C+M+S">Martin S. Andersen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Published in: 2023 IEEE 10th International Conference on Data Science and Advanced Analytics (DSAA)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Machine Learning (cs.LG); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item644">[644]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.20246" title="Abstract">arXiv:2310.20246</a> (replaced) [<a href="/pdf/2310.20246" title="Download PDF">pdf</a>, <a href="/format/2310.20246" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Breaking Language Barriers in Multilingual Mathematical Reasoning:  Insights and Observations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+N">Nuo Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+Z">Zinan Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+N">Ning Wu</a>, 
<a href="/search/cs?searchtype=author&query=Gong%2C+M">Ming Gong</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+Y">Yangqiu Song</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+D">Dongmei Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jia Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Work in Progress
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item645">[645]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.20327" title="Abstract">arXiv:2310.20327</a> (replaced) [<a href="/pdf/2310.20327" title="Download PDF">pdf</a>, <a href="/format/2310.20327" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Improving Entropy-Based Test-Time Adaptation from a Clustering View
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lin%2C+G">Guoliang Lin</a>, 
<a href="/search/cs?searchtype=author&query=Lai%2C+H">Hanjiang Lai</a>, 
<a href="/search/cs?searchtype=author&query=Pan%2C+Y">Yan Pan</a>, 
<a href="/search/cs?searchtype=author&query=Yin%2C+J">Jian Yin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
</div>
</dd>
<dt><a name="item646">[646]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.20587" title="Abstract">arXiv:2310.20587</a> (replaced) [<a href="/pdf/2310.20587" title="Download PDF">pdf</a>, <a href="/format/2310.20587" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Unleashing the Power of Pre-trained Language Models for Offline  Reinforcement Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shi%2C+R">Ruizhe Shi</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yuyao Liu</a>, 
<a href="/search/cs?searchtype=author&query=Ze%2C+Y">Yanjie Ze</a>, 
<a href="/search/cs?searchtype=author&query=Du%2C+S+S">Simon S. Du</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+H">Huazhe Xu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 19 pages, 9 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item647">[647]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.00136" title="Abstract">arXiv:2311.00136</a> (replaced) [<a href="/pdf/2311.00136" title="Download PDF">pdf</a>, <a href="/format/2311.00136" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Neuroformer: Multimodal and Multitask Generative Pretraining for Brain  Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-bio?searchtype=author&query=Antoniades%2C+A">Antonis Antoniades</a>, 
<a href="/search/q-bio?searchtype=author&query=Yu%2C+Y">Yiyi Yu</a>, 
<a href="/search/q-bio?searchtype=author&query=Canzano%2C+J">Joseph Canzano</a>, 
<a href="/search/q-bio?searchtype=author&query=Wang%2C+W">William Wang</a>, 
<a href="/search/q-bio?searchtype=author&query=Smith%2C+S+L">Spencer LaVere Smith</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages for main paper. 22 pages in total. 13 figures, 1 table
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neurons and Cognition (q-bio.NC)</span>; Machine Learning (cs.LG); Neural and Evolutionary Computing (cs.NE)

</div>
</div>
</dd>
<dt><a name="item648">[648]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.00386" title="Abstract">arXiv:2311.00386</a> (replaced) [<a href="/pdf/2311.00386" title="Download PDF">pdf</a>, <a href="/format/2311.00386" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the Integration of Self-Sovereign Identity with TLS 1.3 Handshake to  Build Trust in IoT Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Perugini%2C+L">Leonardo Perugini</a>, 
<a href="/search/cs?searchtype=author&query=Vesco%2C+A">Andrea Vesco</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
</div>
</dd>
<dt><a name="item649">[649]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.00660" title="Abstract">arXiv:2311.00660</a> (replaced) [<a href="/pdf/2311.00660" title="Download PDF">pdf</a>, <a href="/format/2311.00660" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> TPSeNCE: Towards Artifact-Free Realistic Rain Generation for Deraining  and Object Detection in Rain
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zheng%2C+S">Shen Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+C">Changjie Lu</a>, 
<a href="/search/cs?searchtype=author&query=Narasimhan%2C+S+G">Srinivasa G. Narasimhan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> WACV 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item650">[650]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.00729" title="Abstract">arXiv:2311.00729</a> (replaced) [<a href="/pdf/2311.00729" title="Download PDF">pdf</a>, <a href="/format/2311.00729" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ZEETAD: Adapting Pretrained Vision-Language Model for Zero-Shot  End-to-End Temporal Action Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Phan%2C+T">Thinh Phan</a>, 
<a href="/search/cs?searchtype=author&query=Vo%2C+K">Khoa Vo</a>, 
<a href="/search/cs?searchtype=author&query=Le%2C+D">Duy Le</a>, 
<a href="/search/cs?searchtype=author&query=Doretto%2C+G">Gianfranco Doretto</a>, 
<a href="/search/cs?searchtype=author&query=Adjeroh%2C+D">Donald Adjeroh</a>, 
<a href="/search/cs?searchtype=author&query=Le%2C+N">Ngan Le</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item651">[651]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.00814" title="Abstract">arXiv:2311.00814</a> (replaced) [<a href="/pdf/2311.00814" title="Download PDF">pdf</a>, <a href="/format/2311.00814" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Investigating Self-Supervised Deep Representations for EEG-based  Auditory Attention Decoding
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Thakkar%2C+K">Karan Thakkar</a>, 
<a href="/search/cs?searchtype=author&query=Hai%2C+J">Jiarui Hai</a>, 
<a href="/search/cs?searchtype=author&query=Elhilali%2C+M">Mounya Elhilali</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to ICASSP 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Audio and Speech Processing (eess.AS)

</div>
</div>
</dd>
<dt><a name="item652">[652]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.00855" title="Abstract">arXiv:2311.00855</a> (replaced) [<a href="/pdf/2311.00855" title="Download PDF">pdf</a>, <a href="/format/2311.00855" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Multi-Agent Reinforcement Learning Framework for Evaluating the U.S.  Ending the HIV Epidemic Plan
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sharma%2C+D">Dinesh Sharma</a>, 
<a href="/search/cs?searchtype=author&query=Shah%2C+A">Ankit Shah</a>, 
<a href="/search/cs?searchtype=author&query=Gopalappa%2C+C">Chaitra Gopalappa</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Added acknowledgement
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Machine Learning (cs.LG); Multiagent Systems (cs.MA)

</div>
</div>
</dd>
<dt><a name="item653">[653]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.00975" title="Abstract">arXiv:2311.00975</a> (replaced) [<a href="/pdf/2311.00975" title="Download PDF">pdf</a>, <a href="/format/2311.00975" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Autonomous Learning of Generative Models with Chemical Reaction Network  Ensembles
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-bio?searchtype=author&query=Poole%2C+W">William Poole</a>, 
<a href="/search/q-bio?searchtype=author&query=Ouldridge%2C+T+E">Thomas E. Ouldridge</a>, 
<a href="/search/q-bio?searchtype=author&query=Gopalkrishnan%2C+M">Manoj Gopalkrishnan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Molecular Networks (q-bio.MN)</span>; Emerging Technologies (cs.ET); Machine Learning (cs.LG); Neural and Evolutionary Computing (cs.NE); Systems and Control (eess.SY); Biological Physics (physics.bio-ph)

</div>
</div>
</dd>
<dt><a name="item654">[654]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01305" title="Abstract">arXiv:2311.01305</a> (replaced) [<a href="/pdf/2311.01305" title="Download PDF">pdf</a>, <a href="/format/2311.01305" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AWEQ: Post-Training Quantization with Activation-Weight Equalization for  Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+B">Baisong Li</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xingwang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+H">Haixiao Xu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL)

</div>
</div>
</dd>
<dt><a name="item655">[655]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01442" title="Abstract">arXiv:2311.01442</a> (replaced) [<a href="/pdf/2311.01442" title="Download PDF">pdf</a>, <a href="/format/2311.01442" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deep Double Descent for Time Series Forecasting: Avoiding Undertrained  Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Assandri%2C+V">Valentino Assandri</a>, 
<a href="/search/cs?searchtype=author&query=Heshmati%2C+S">Sam Heshmati</a>, 
<a href="/search/cs?searchtype=author&query=Yaman%2C+B">Burhaneddin Yaman</a>, 
<a href="/search/cs?searchtype=author&query=Iakovlev%2C+A">Anton Iakovlev</a>, 
<a href="/search/cs?searchtype=author&query=Repetur%2C+A+E">Ariel Emiliano Repetur</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item656">[656]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01479" title="Abstract">arXiv:2311.01479</a> (replaced) [<a href="/pdf/2311.01479" title="Download PDF">pdf</a>, <a href="/format/2311.01479" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Detecting Out-of-Distribution Through the Lens of Neural Collapse
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+L">Litian Liu</a>, 
<a href="/search/cs?searchtype=author&query=Qin%2C+Y">Yao Qin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Image and Video Processing (eess.IV)

</div>
</div>
</dd>
<dt><a name="item657">[657]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01522" title="Abstract">arXiv:2311.01522</a> (replaced) [<a href="/pdf/2311.01522" title="Download PDF">pdf</a>, <a href="/format/2311.01522" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An Efficient Detection and Control System for Underwater Docking using  Machine Learning and Realistic Simulation: A Comprehensive Approach
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chavez-Galaviz%2C+J">Jalil Chavez-Galaviz</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jianwen Li</a>, 
<a href="/search/cs?searchtype=author&query=Bergman%2C+M">Matthew Bergman</a>, 
<a href="/search/cs?searchtype=author&query=Mengdibayev%2C+M">Miras Mengdibayev</a>, 
<a href="/search/cs?searchtype=author&query=Mahmoudian%2C+N">Nina Mahmoudian</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item658">[658]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01739" title="Abstract">arXiv:2311.01739</a> (replaced) [<a href="/pdf/2311.01739" title="Download PDF">pdf</a>, <a href="/format/2311.01739" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Efficient Algorithms for Monte Carlo Particle Transport on AI  Accelerator Hardware
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tramm%2C+J">John Tramm</a>, 
<a href="/search/cs?searchtype=author&query=Allen%2C+B">Bryce Allen</a>, 
<a href="/search/cs?searchtype=author&query=Yoshii%2C+K">Kazutomo Yoshii</a>, 
<a href="/search/cs?searchtype=author&query=Siegel%2C+A">Andrew Siegel</a>, 
<a href="/search/cs?searchtype=author&query=Wilson%2C+L">Leighton Wilson</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>; Performance (cs.PF)

</div>
</div>
</dd>
<dt><a name="item659">[659]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01767" title="Abstract">arXiv:2311.01767</a> (replaced) [<a href="/pdf/2311.01767" title="Download PDF">pdf</a>, <a href="/format/2311.01767" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PPTC Benchmark: Evaluating Large Language Models for PowerPoint Task  Completion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Guo%2C+Y">Yiduo Guo</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zekai Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+Y">Yaobo Liang</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+D">Dongyan Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Duan%2C+N">Nan Duan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> LLM evaluation, PPT task completion
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item660">[660]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01804" title="Abstract">arXiv:2311.01804</a> (replaced) [<a href="/pdf/2311.01804" title="Download PDF">pdf</a>, <a href="/format/2311.01804" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> inkn&#x27;hue: Enhancing Manga Colorization from Multiple Priors with  Alignment Multi-Encoder VAE
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jiramahapokee%2C+T">Tawin Jiramahapokee</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv preprint. Project page: <a href="https://github.com/rossiyareich/inknhue">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Image and Video Processing (eess.IV)

</div>
</div>
</dd>
<dt><a name="item661">[661]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01929" title="Abstract">arXiv:2311.01929</a> (replaced) [<a href="/pdf/2311.01929" title="Download PDF">pdf</a>, <a href="/format/2311.01929" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ProS: Facial Omni-Representation Learning via Prototype-based  Self-Distillation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Di%2C+X">Xing Di</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+Y">Yiyu Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xiaoming Liu</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+Y">Yu Cheng</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This paper has been accepted in WACV2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item662">[662]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01940" title="Abstract">arXiv:2311.01940</a> (replaced) [<a href="/pdf/2311.01940" title="Download PDF">pdf</a>, <a href="/format/2311.01940" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Balanced independent sets and colorings of hypergraphs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Dhawan%2C+A">Abhishek Dhawan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Combinatorics (math.CO)</span>; Discrete Mathematics (cs.DM)

</div>
</div>
</dd>
<dt><a name="item663">[663]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02117" title="Abstract">arXiv:2311.02117</a> (replaced) [<a href="/pdf/2311.02117" title="Download PDF">pdf</a>, <a href="/format/2311.02117" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Cooperative Network Learning for Large-Scale and Decentralized Graphs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+Q">Qiang Wu</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+Y">Yiming Huang</a>, 
<a href="/search/cs?searchtype=author&query=Zeng%2C+Y">Yujie Zeng</a>, 
<a href="/search/cs?searchtype=author&query=Teng%2C+Y">Yijie Teng</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+F">Fang Zhou</a>, 
<a href="/search/cs?searchtype=author&query=L%C3%BC%2C+L">Linyuan L&#xfc;</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Social and Information Networks (cs.SI)

</div>
</div>
</dd>
<dt><a name="item664">[664]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02171" title="Abstract">arXiv:2311.02171</a> (replaced) [<a href="/pdf/2311.02171" title="Download PDF">pdf</a>, <a href="/format/2311.02171" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Emergence of Abstract State Representations in Embodied Sequence  Modeling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yun%2C+T">Tian Yun</a>, 
<a href="/search/cs?searchtype=author&query=Zeng%2C+Z">Zilai Zeng</a>, 
<a href="/search/cs?searchtype=author&query=Handa%2C+K">Kunal Handa</a>, 
<a href="/search/cs?searchtype=author&query=Thapliyal%2C+A+V">Ashish V. Thapliyal</a>, 
<a href="/search/cs?searchtype=author&query=Pang%2C+B">Bo Pang</a>, 
<a href="/search/cs?searchtype=author&query=Pavlick%2C+E">Ellie Pavlick</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+C">Chen Sun</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing (EMNLP 2023). Project webpage: <a href="https://abstract-state-seqmodel.github.io/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item665">[665]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02747" title="Abstract">arXiv:2311.02747</a> (replaced) [<a href="/pdf/2311.02747" title="Download PDF">pdf</a>, <a href="/format/2311.02747" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Attention Modules Improve Image-Level Anomaly Detection for Industrial  Inspection: A DifferNet Case Study
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Silva%2C+A+L+B+V+e">Andr&#xe9; Luiz Buarque Vieira e Silva</a>, 
<a href="/search/cs?searchtype=author&query=Sim%C3%B5es%2C+F">Francisco Sim&#xf5;es</a>, 
<a href="/search/cs?searchtype=author&query=Kowerko%2C+D">Danny Kowerko</a>, 
<a href="/search/cs?searchtype=author&query=Schlosser%2C+T">Tobias Schlosser</a>, 
<a href="/search/cs?searchtype=author&query=Battisti%2C+F">Felipe Battisti</a>, 
<a href="/search/cs?searchtype=author&query=Teichrieb%2C+V">Veronica Teichrieb</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at WACV 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item666">[666]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02811" title="Abstract">arXiv:2311.02811</a> (replaced) [<a href="/pdf/2311.02811" title="Download PDF">pdf</a>, <a href="/format/2311.02811" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Contour Algorithm for Connectivity
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Du%2C+Z">Zhihui Du</a>, 
<a href="/search/cs?searchtype=author&query=Rodriguez%2C+O+A">Oliver Alvarado Rodriguez</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+F">Fuhuan Li</a>, 
<a href="/search/cs?searchtype=author&query=Dindoost%2C+M">Mohammad Dindoost</a>, 
<a href="/search/cs?searchtype=author&query=Bader%2C+D+A">David A. Bader</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 30th IEEE International Conference on High Performance Computing, Data, and Analytics, Goa, India, December 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>; Data Structures and Algorithms (cs.DS)

</div>
</div>
</dd>
<dt><a name="item667">[667]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02831" title="Abstract">arXiv:2311.02831</a> (replaced) [<a href="/pdf/2311.02831" title="Download PDF">pdf</a>, <a href="/format/2311.02831" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SemanticTopoLoop: Semantic Loop Closure With 3D Topological Graph Based  on Quadric-Level Object Map
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cao%2C+Z">Zhenzhong Cao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Robotics (cs.RO)

</div>
</div>
</dd>
<dt><a name="item668">[668]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02849" title="Abstract">arXiv:2311.02849</a> (replaced) [<a href="/pdf/2311.02849" title="Download PDF">pdf</a>, <a href="/format/2311.02849" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Co-training and Co-distillation for Quality Improvement and Compression  of Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lee%2C+H">Hayeon Lee</a>, 
<a href="/search/cs?searchtype=author&query=Hou%2C+R">Rui Hou</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+J">Jongpil Kim</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+D">Davis Liang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Hongbo Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Hwang%2C+S+J">Sung Ju Hwang</a>, 
<a href="/search/cs?searchtype=author&query=Min%2C+A">Alexander Min</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Findings of EMNLP 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item669">[669]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02877" title="Abstract">arXiv:2311.02877</a> (replaced) [<a href="/pdf/2311.02877" title="Download PDF">pdf</a>, <a href="/format/2311.02877" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Inner-IoU: More Effective Intersection over Union Loss with Auxiliary  Bounding Box
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Hao Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+C">Cong Xu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+S">Shuaijie Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item670">[670]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02901" title="Abstract">arXiv:2311.02901</a> (replaced) [<a href="/pdf/2311.02901" title="Download PDF">pdf</a>, <a href="/format/2311.02901" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Pseudorandom Isometries
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Ananth%2C+P">Prabhanjan Ananth</a>, 
<a href="/search/quant-ph?searchtype=author&query=Gulati%2C+A">Aditya Gulati</a>, 
<a href="/search/quant-ph?searchtype=author&query=Kaleoglu%2C+F">Fatih Kaleoglu</a>, 
<a href="/search/quant-ph?searchtype=author&query=Lin%2C+Y">Yao-Ting Lin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Computational Complexity (cs.CC); Cryptography and Security (cs.CR)

</div>
</div>
</dd>
<dt><a name="item671">[671]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03054" title="Abstract">arXiv:2311.03054</a> (replaced) [<a href="/pdf/2311.03054" title="Download PDF">pdf</a>, <a href="/format/2311.03054" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AnyText: Multilingual Visual Text Generation And Editing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tuo%2C+Y">Yuxiang Tuo</a>, 
<a href="/search/cs?searchtype=author&query=Xiang%2C+W">Wangmeng Xiang</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+J">Jun-Yan He</a>, 
<a href="/search/cs?searchtype=author&query=Geng%2C+Y">Yifeng Geng</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+X">Xuansong Xie</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item672">[672]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03071" title="Abstract">arXiv:2311.03071</a> (replaced) [<a href="/pdf/2311.03071" title="Download PDF">pdf</a>, <a href="/format/2311.03071" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> OrthoNets: Orthogonal Channel Attention Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Salman%2C+H">Hadi Salman</a>, 
<a href="/search/cs?searchtype=author&query=Parks%2C+C">Caleb Parks</a>, 
<a href="/search/cs?searchtype=author&query=Swan%2C+M">Matthew Swan</a>, 
<a href="/search/cs?searchtype=author&query=Gauch%2C+J">John Gauch</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> IEEE BigData 2023
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> IEEE BigData 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item673">[673]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03076" title="Abstract">arXiv:2311.03076</a> (replaced) [<a href="/pdf/2311.03076" title="Download PDF">pdf</a>, <a href="/format/2311.03076" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SugarViT -- Multi-objective Regression of UAV Images with Vision  Transformers and Deep Label Distribution Learning Demonstrated on Disease  Severity Prediction in Sugar Beet
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=G%C3%BCnder%2C+M">Maurice G&#xfc;nder</a>, 
<a href="/search/cs?searchtype=author&query=Yamati%2C+F+R+I">Facundo Ram&#xf3;n Ispizua Yamati</a>, 
<a href="/search/cs?searchtype=author&query=Alc%C3%A1ntara%2C+A+A+B">Abel Andree Barreto Alc&#xe1;ntara</a>, 
<a href="/search/cs?searchtype=author&query=Mahlein%2C+A">Anne-Katrin Mahlein</a>, 
<a href="/search/cs?searchtype=author&query=Sifa%2C+R">Rafet Sifa</a>, 
<a href="/search/cs?searchtype=author&query=Bauckhage%2C+C">Christian Bauckhage</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> submitted to Computers and Electronics in Agriculture
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item674">[674]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03285" title="Abstract">arXiv:2311.03285</a> (replaced) [<a href="/pdf/2311.03285" title="Download PDF">pdf</a>, <a href="/format/2311.03285" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> S-LoRA: Serving Thousands of Concurrent LoRA Adapters
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sheng%2C+Y">Ying Sheng</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+S">Shiyi Cao</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+D">Dacheng Li</a>, 
<a href="/search/cs?searchtype=author&query=Hooper%2C+C">Coleman Hooper</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+N">Nicholas Lee</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+S">Shuo Yang</a>, 
<a href="/search/cs?searchtype=author&query=Chou%2C+C">Christopher Chou</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+B">Banghua Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+L">Lianmin Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Keutzer%2C+K">Kurt Keutzer</a>, 
<a href="/search/cs?searchtype=author&query=Gonzalez%2C+J+E">Joseph E. Gonzalez</a>, 
<a href="/search/cs?searchtype=author&query=Stoica%2C+I">Ion Stoica</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Distributed, Parallel, and Cluster Computing (cs.DC)

</div>
</div>
</dd>
<dt><a name="item675">[675]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03287" title="Abstract">arXiv:2311.03287</a> (replaced) [<a href="/pdf/2311.03287" title="Download PDF">pdf</a>, <a href="/format/2311.03287" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Holistic Analysis of Hallucination in GPT-4V(ision): Bias and  Interference Challenges
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cui%2C+C">Chenhang Cui</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Y">Yiyang Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+X">Xinyu Yang</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+S">Shirley Wu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+L">Linjun Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zou%2C+J">James Zou</a>, 
<a href="/search/cs?searchtype=author&query=Yao%2C+H">Huaxiu Yao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computation and Language (cs.CL); Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item676">[676]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03292" title="Abstract">arXiv:2311.03292</a> (replaced) [<a href="/pdf/2311.03292" title="Download PDF">pdf</a>, <a href="/ps/2311.03292" title="Download PostScript">ps</a>, <a href="/format/2311.03292" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Data Science from 1963 to 2012
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Alvarado%2C+R+C">Rafael C. Alvarado</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 48 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">General Literature (cs.GL)</span>; Digital Libraries (cs.DL)

</div>
</div>
</dd>
<dt><a name="item677">[677]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03300" title="Abstract">arXiv:2311.03300</a> (replaced) [<a href="/pdf/2311.03300" title="Download PDF">pdf</a>, <a href="/format/2311.03300" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Faster Run-to-Run Feedforward Control of Electromechanical Switching  Devices: a Sensitivity-Based Approach
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Ramirez-Laboreo%2C+E">Edgar Ramirez-Laboreo</a> (1), 
<a href="/search/eess?searchtype=author&query=Moya-Lasheras%2C+E">Eduardo Moya-Lasheras</a> (1), 
<a href="/search/eess?searchtype=author&query=Serrano-Seco%2C+E">Eloy Serrano-Seco</a> (1) ((1) Universidad de Zaragoza)
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages, 4 figures. Version submitted to the 22nd European Control Conference (ECC) to be held in Stockholm, Sweden, in July 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
</div>
</dd>
</dl>
<ul>
<li><a href="/list/cs/new?skip=0&amp;show=2000">New submissions</a></li>
<li><a href="#item368">Cross-lists</a></li>
<li><a href="#item411">Replacements</a></li>
</ul>
<small>[ total of 677 entries:  <b>1-677</b>  ]</small><br />
<small>[ showing up to 2000 entries per page:  <a href="/list/cs/new?skip=0&amp;show=1000">fewer</a> |  <font color="#999999">more</font> ]</small><br />
</div>
<br/><small><a id="mathjax_toggle" href="javascript:setMathjaxCookie()">Disable MathJax</a> (<a href="/help/mathjax">What is MathJax?</a>)</small><script type="text/javascript" language="javascript">mathjaxToggle();</script>

<hr />
<p>Links to:
<a href="/" accesskey="a">arXiv</a>,
<a href="/form/cs">form interface</a>,
<a href="/find/cs">find</a>,
<a href="/archive/cs">cs</a>, <a href="/list/cs/recent">recent</a>, <a href="/list/cs/2311">2311</a>,
<a href="/help/contact">contact</a>,
<a href="/help/" accesskey="h"><span class="accesskey">h</span>elp</a>&nbsp;
<small>(<a href="/help/accesskeys">Access key</a> information)</small>
</p>
<hr />
</div>
</div>
 <footer style="clear: both;">
      <div class="columns is-desktop" role="navigation" aria-label="Secondary" style="margin: -0.75em -0.75em 0.75em -0.75em">
        <!-- Macro-Column 1 -->
        <div class="column" style="padding: 0;">
          <div class="columns">
            <div class="column">
              <ul style="list-style: none; line-height: 2;">
                <li><a href="https://arxiv.org/about">About</a></li>
                <li><a href="https://arxiv.org/help">Help</a></li>
              </ul>
            </div>
            <div class="column">
              <ul style="list-style: none; line-height: 2;">
                <li>
                  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon filter-black" role="presentation"><title>contact arXiv</title><desc>Click here to contact arXiv</desc><path d="M502.3 190.8c3.9-3.1 9.7-.2 9.7 4.7V400c0 26.5-21.5 48-48 48H48c-26.5 0-48-21.5-48-48V195.6c0-5 5.7-7.8 9.7-4.7 22.4 17.4 52.1 39.5 154.1 113.6 21.1 15.4 56.7 47.8 92.2 47.6 35.7.3 72-32.8 92.3-47.6 102-74.1 131.6-96.3 154-113.7zM256 320c23.2.4 56.6-29.2 73.4-41.4 132.7-96.3 142.8-104.7 173.4-128.7 5.8-4.5 9.2-11.5 9.2-18.9v-19c0-26.5-21.5-48-48-48H48C21.5 64 0 85.5 0 112v19c0 7.4 3.4 14.3 9.2 18.9 30.6 23.9 40.7 32.4 173.4 128.7 16.8 12.2 50.2 41.8 73.4 41.4z"/></svg>
                  <a href="https://arxiv.org/help/contact"> Contact</a>
                </li>
                <li>
                  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon filter-black" role="presentation"><title>subscribe to arXiv mailings</title><desc>Click here to subscribe</desc><path d="M476 3.2L12.5 270.6c-18.1 10.4-15.8 35.6 2.2 43.2L121 358.4l287.3-253.2c5.5-4.9 13.3 2.6 8.6 8.3L176 407v80.5c0 23.6 28.5 32.9 42.5 15.8L282 426l124.6 52.2c14.2 6 30.4-2.9 33-18.2l72-432C515 7.8 493.3-6.8 476 3.2z"/></svg>
                  <a href="https://arxiv.org/help/subscribe"> Subscribe</a>
                </li>
              </ul>
            </div>
          </div>
        </div>
        <!-- End Macro-Column 1 -->
        <!-- Macro-Column 2 -->
        <div class="column" style="padding: 0;">
          <div class="columns">
            <div class="column">
              <ul style="list-style: none; line-height: 2;">
                <li><a href="https://arxiv.org/help/license">Copyright</a></li>
                <li><a href="https://arxiv.org/help/policies/privacy_policy">Privacy Policy</a></li>
              </ul>
            </div>
            <div class="column sorry-app-links">
              <ul style="list-style: none; line-height: 2;">
                <li><a href="https://arxiv.org/help/web_accessibility">Web Accessibility Assistance</a></li>
                <li>
                  <p class="help">
                    <a class="a11y-main-link" href="https://status.arxiv.org" target="_blank">arXiv Operational Status <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 256 512" class="icon filter-dark_grey" role="presentation"><path d="M224.3 273l-136 136c-9.4 9.4-24.6 9.4-33.9 0l-22.6-22.6c-9.4-9.4-9.4-24.6 0-33.9l96.4-96.4-96.4-96.4c-9.4-9.4-9.4-24.6 0-33.9L54.3 103c9.4-9.4 24.6-9.4 33.9 0l136 136c9.5 9.4 9.5 24.6.1 34z"/></svg></a><br>
                    Get status notifications via
                    <a class="is-link" href="https://subscribe.sorryapp.com/24846f03/email/new" target="_blank"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon filter-black" role="presentation"><path d="M502.3 190.8c3.9-3.1 9.7-.2 9.7 4.7V400c0 26.5-21.5 48-48 48H48c-26.5 0-48-21.5-48-48V195.6c0-5 5.7-7.8 9.7-4.7 22.4 17.4 52.1 39.5 154.1 113.6 21.1 15.4 56.7 47.8 92.2 47.6 35.7.3 72-32.8 92.3-47.6 102-74.1 131.6-96.3 154-113.7zM256 320c23.2.4 56.6-29.2 73.4-41.4 132.7-96.3 142.8-104.7 173.4-128.7 5.8-4.5 9.2-11.5 9.2-18.9v-19c0-26.5-21.5-48-48-48H48C21.5 64 0 85.5 0 112v19c0 7.4 3.4 14.3 9.2 18.9 30.6 23.9 40.7 32.4 173.4 128.7 16.8 12.2 50.2 41.8 73.4 41.4z"/></svg>email</a>
                    or <a class="is-link" href="https://subscribe.sorryapp.com/24846f03/slack/new" target="_blank"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512" class="icon filter-black" role="presentation"><path d="M94.12 315.1c0 25.9-21.16 47.06-47.06 47.06S0 341 0 315.1c0-25.9 21.16-47.06 47.06-47.06h47.06v47.06zm23.72 0c0-25.9 21.16-47.06 47.06-47.06s47.06 21.16 47.06 47.06v117.84c0 25.9-21.16 47.06-47.06 47.06s-47.06-21.16-47.06-47.06V315.1zm47.06-188.98c-25.9 0-47.06-21.16-47.06-47.06S139 32 164.9 32s47.06 21.16 47.06 47.06v47.06H164.9zm0 23.72c25.9 0 47.06 21.16 47.06 47.06s-21.16 47.06-47.06 47.06H47.06C21.16 243.96 0 222.8 0 196.9s21.16-47.06 47.06-47.06H164.9zm188.98 47.06c0-25.9 21.16-47.06 47.06-47.06 25.9 0 47.06 21.16 47.06 47.06s-21.16 47.06-47.06 47.06h-47.06V196.9zm-23.72 0c0 25.9-21.16 47.06-47.06 47.06-25.9 0-47.06-21.16-47.06-47.06V79.06c0-25.9 21.16-47.06 47.06-47.06 25.9 0 47.06 21.16 47.06 47.06V196.9zM283.1 385.88c25.9 0 47.06 21.16 47.06 47.06 0 25.9-21.16 47.06-47.06 47.06-25.9 0-47.06-21.16-47.06-47.06v-47.06h47.06zm0-23.72c-25.9 0-47.06-21.16-47.06-47.06 0-25.9 21.16-47.06 47.06-47.06h117.84c25.9 0 47.06 21.16 47.06 47.06 0 25.9-21.16 47.06-47.06 47.06H283.1z"/></svg>slack</a>
                  </p>
                </li>
              </ul>
            </div>
          </div>
        </div> <!-- end MetaColumn 2 -->
        <!-- End Macro-Column 2 -->
      </div>
    </footer>
</body>
</html>
